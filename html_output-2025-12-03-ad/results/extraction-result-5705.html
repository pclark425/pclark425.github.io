<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5705 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5705</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5705</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-116.html">extraction-schema-116</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <p><strong>Paper ID:</strong> paper-268387676</p>
                <p><strong>Paper Title:</strong> Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences</p>
                <p><strong>Paper Abstract:</strong> Background Telemedicine has experienced rapid growth in recent years, aiming to enhance medical efficiency and reduce the workload of healthcare professionals. During the COVID-19 pandemic in 2019, it became especially crucial, enabling remote screenings and access to healthcare services while maintaining social distancing. Online consultation platforms have emerged, but the demand has strained the availability of medical professionals, directly leading to research and development in automated medical consultation. Specifically, there is a need for efficient and accurate medical dialogue summarization algorithms to condense lengthy conversations into shorter versions focused on relevant medical facts. The success of large language models like generative pre-trained transformer (GPT)-3 has recently prompted a paradigm shift in natural language processing (NLP) research. In this paper, we will explore its impact on medical dialogue summarization. Methods We present the performance and evaluation results of two approaches on a medical dialogue dataset. The first approach is based on fine-tuned pre-trained language models, such as bert-based summarization (BERTSUM) and bidirectional auto-regressive Transformers (BART). The second approach utilizes a large language models (LLMs) GPT-3.5 with inter-context learning (ICL). Evaluation is conducted using automated metrics such as ROUGE and BERTScore. Results In comparison to the BART and ChatGPT models, the summaries generated by the BERTSUM model not only exhibit significantly lower ROUGE and BERTScore values but also fail to pass the testing for any of the metrics in manual evaluation. On the other hand, the BART model achieved the highest ROUGE and BERTScore values among all evaluated models, surpassing ChatGPT. Its ROUGE-1, ROUGE-2, ROUGE-L, and BERTScore values were 14.94%, 53.48%, 32.84%, and 6.73% higher respectively than ChatGPT’s best results. However, in the manual evaluation by medical experts, the summaries generated by the BART model exhibit satisfactory performance only in the “Readability” metric, with less than 30% passing the manual evaluation in other metrics. When compared to the BERTSUM and BART models, the ChatGPT model was evidently more favored by human medical experts. Conclusion On one hand, the GPT-3.5 model can manipulate the style and outcomes of medical dialogue summaries through various prompts. The generated content is not only better received than results from certain human experts but also more comprehensible, making it a promising avenue for automated medical dialogue summarization. On the other hand, automated evaluation mechanisms like ROUGE and BERTScore fall short in fully assessing the outputs of large language models like GPT-3.5. Therefore, it is necessary to research more appropriate evaluation criteria.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5705.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5705.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt_T</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Technical task-decomposition prompt (Prompt_T)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A structured, multi-part prompt that decomposes the medical dialogue summarization task into six sub-parts (e.g., Chief complaint, Present medical history, Auxiliary examination, Diagnosis, Recommendation) and provides contextual example variables (e.g., {ls_symptom}, {ls_aux_test}) to guide ChatGPT's output.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Medical dialogue summarization (IMCS-V2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate a concise medical report / summary from multi-turn doctor-patient dialogues in the IMCS-V2 Chinese pediatric dataset; evaluated with ROUGE (1/2/L), BERTScore and medical expert human evaluation (Contains Key Result, Coherence, Usefulness, Readability).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Task-decomposition prompt: split the requested summary into six named parts with instructions and examples for each part; include domain-specific example lists (variables such as {ls_symptom} and {ls_aux_test}) to provide contextual anchors; prompts given in Chinese; used as in-context examples to steer output structure and content.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Prompt_S (a simple prompt that gives minimal guidance; e.g., just labels like 'Auxiliary examination' and 'Diagnosis' without multi-part decomposition or example variable lists).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ChatGPT with Prompt_T (configuration Prompt_T.7: Temperature=0.1, Top_p=0.1) — ROUGE-1: 48.19, ROUGE-2: 25.41, ROUGE-L: 40.81, BERTScore: 73.38; high human-evaluator approval (medical experts favored ChatGPT summaries, many 'Strongly Agree' responses, especially under Prompt_T).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Same model with Prompt_S.7 (Temperature=0.1, Top_p=0.1) — ROUGE-1: 44.27, ROUGE-2: 21.95, ROUGE-L: 36.91, BERTScore: 71.49; BART model (fine-tuned) — ROUGE-1: 55.39, ROUGE-2: 40.38, ROUGE-L: 54.21, BERTScore: 78.32; although BART outperforms ChatGPT on automatic metrics, ChatGPT (Prompt_T) outperforms BART by human evaluation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>+3.92 ROUGE-1 and +3.90 ROUGE-L (Prompt_T.7 vs Prompt_S.7) in the reported configurations; ChatGPT(Prompt_T.7) still ~7.20 ROUGE-1 points lower than BART (automatic metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper attributes Prompt_T's advantage to clearer task structure and contextual examples (e.g., symptom and examination lists) that guide the model to produce more informative, organized, and medically-relevant content. Task decomposition helps the model focus on specific sub-goals (chief complaint, history, exams, diagnosis, recommendations), improving human-perceived usefulness and coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>Despite Prompt_T improving ChatGPT's automatic metrics relative to Prompt_S and improving human preference, it did not allow ChatGPT to surpass the fine-tuned BART model on automatic metrics (ROUGE/BERTScore). The authors also note remaining issues under Prompt_T (overly long 'Chief complaint', hallucinated suggested tests) showing that better prompt structure does not fully eliminate errors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5705.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5705.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt_S</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simple prompt (Prompt_S)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A minimal/simple prompt used with ChatGPT that contains basic labels (e.g., 'Auxiliary examination', 'Diagnosis') without multi-part decomposition or contextual example variables.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Medical dialogue summarization (IMCS-V2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same medical summarization task: generate a concise medical report from doctor-patient dialogues and evaluate by ROUGE/BERTScore and human expert ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Simple prompt: provide minimal structuring cues (short labels for sections) and request a summary; no task decomposition nor domain example lists; Chinese-language prompt in dataset context.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Prompt_T (technical, decomposed prompt with examples and variables).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Best reported Prompt_S configuration (Prompt_S.7: Temperature=0.1, Top_p=0.1) — ROUGE-1: 44.27, ROUGE-2: 21.95, ROUGE-L: 36.91, BERTScore: 71.49.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Worse than Prompt_T.7 (ROUGE-1: 48.19 etc.). Compared to fine-tuned BART (ROUGE-1: 55.39), Prompt_S ChatGPT performance is substantially lower on automatic metrics; human evaluation also favored the Prompt_T outputs over Prompt_S.</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>Prompt_S.7 → Prompt_T.7 yields +3.92 ROUGE-1 and +3.90 ROUGE-L (same numeric comparison as above) indicating the simple-to-technical prompt change effect in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (relative to Prompt_T)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Minimal guidance leads to less structured outputs and lower automatic scores and human preference; the paper suggests that explicit sectioning and examples are necessary to obtain more useful medical summaries from ChatGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5705.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5705.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Temperature/Top_p</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Decoding hyperparameters: Temperature and Top_p</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generation-decoders settings used with ChatGPT to control randomness (Temperature) and nucleus sampling diversity (Top_p); the study varied these to examine effect on summary quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Medical dialogue summarization (IMCS-V2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same task; evaluated how generation randomness/diversity parameters affect summary automatic scores and qualitative behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompt-response format with varying decoding hyperparameters. The paper tested seven combinations (see Table 5): combinations included (Temperature, Top_p) pairs like (1.0,1.0), (0.7,1.0), (0.1,1.0), (0.5,0.5), (1.0,0.1), (0.7,0.1), (0.1,0.1) across both Prompt_S and Prompt_T families.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Observed best automatic results generally occur at low Temperature and low Top_p (e.g., Prompt_T.7: Temperature=0.1, Top_p=0.1 — ROUGE-1 48.19, ROUGE-L 40.81). Higher Temperature/Top_p settings (e.g., 1.0,1.0) produced lower ROUGE scores in the tested runs (Prompt_S.1 ROUGE-1=43.69; Prompt_T.1 ROUGE-1=47.21).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Within Prompt_T family: Prompt_T.1 (1.0,1.0) ROUGE-1=47.21 → Prompt_T.7 (0.1,0.1) ROUGE-1=48.19 (increase ≈ +0.98 ROUGE-1). Within Prompt_S family: Prompt_S.1 (1.0,1.0) ROUGE-1=43.69 → Prompt_S.6/7 (lower settings) ROUGE-1≈44.28/44.27 (increase ≈ +0.59).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>Modest but consistent gains observed when lowering Temperature and Top_p (examples: +0.98 ROUGE-1 in Prompt_T family; +0.59 ROUGE-1 in Prompt_S family).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved (lower Temperature & lower Top_p → higher ROUGE scores / more conservative and relevant outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Authors explain higher Temperature and Top_p increase creativity/diversity and can introduce medically-inaccurate or less relevant content (examples: model sometimes outputs a medication recommendation as a 'diagnosis'); lowering these parameters makes generation more conservative and aligned with input, increasing ROUGE and human-relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>Effect sizes are modest and not sufficient alone to exceed fine-tuned model (BART) automatic metrics; even with low Temperature/Top_p some factual errors (hallucinated tests or overly long sections) persisted.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5705.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5705.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>In-Context Learning (ICL) with GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using demonstration examples or prompt-based context (ICL) with GPT-3.5/ChatGPT to perform medical summarization without task-specific fine-tuning; in this paper ICL is part of Method B.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Medical dialogue summarization (IMCS-V2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate clinical summaries from dialogues using in-context demonstrations plus prompt engineering (Prompt_S and Prompt_T variants) to elicit desired output.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>ICL: provide context/demonstrations (examples) and engineered prompts to let the pre-trained model produce summaries without full supervised fine-tuning; combined with varying prompts and decoding parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Fine-tuned PLMs (BERTSUM, BART) which were trained/finetuned end-to-end on the task vs ICL-based ChatGPT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ICL-based ChatGPT with Prompt_T.7 achieved ROUGE-1: 48.19, ROUGE-2: 25.41, ROUGE-L: 40.81, BERTScore: 73.38 and was preferred by human medical experts over BERTSUM and BART outputs despite lower automatic scores than BART.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Fine-tuned BART attained higher automatic metrics (ROUGE-1: 55.39 etc.) but lower human-evaluator preference; BERTSUM performed poorly on both automatic and human evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>ICL combined with good prompt design (Prompt_T) and tuned decoding parameters yields several-point ROUGE gains over simpler prompt variants; exact gain depends on prompt and decoding configuration (see Prompt_T vs Prompt_S comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved (when combined with task-decomposition prompts and low-temperature/top_p decoding)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>ICL allows leveraging GPT-3.5's pre-trained knowledge and instruction-following behavior; when paired with structured prompts and examples it produces summaries that humans find more coherent and useful than some fine-tuned models, possibly because it better integrates world knowledge and verbose explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>ICL/prompting did not match the fine-tuned BART on automatic metrics (ROUGE/BERTScore), demonstrating that prompt-based ICL improvements do not always translate to higher n-gram overlap scores and that automatic metrics may undervalue human-preferred outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A survey for in-context learning <em>(Rating: 2)</em></li>
                <li>ImpressionGPT: an iterative optimizing framework for radiology report summarization with chatGPT <em>(Rating: 2)</em></li>
                <li>Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat <em>(Rating: 2)</em></li>
                <li>GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5705",
    "paper_id": "paper-268387676",
    "extraction_schema_id": "extraction-schema-116",
    "extracted_data": [
        {
            "name_short": "Prompt_T",
            "name_full": "Technical task-decomposition prompt (Prompt_T)",
            "brief_description": "A structured, multi-part prompt that decomposes the medical dialogue summarization task into six sub-parts (e.g., Chief complaint, Present medical history, Auxiliary examination, Diagnosis, Recommendation) and provides contextual example variables (e.g., {ls_symptom}, {ls_aux_test}) to guide ChatGPT's output.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5)",
            "model_size": null,
            "task_name": "Medical dialogue summarization (IMCS-V2)",
            "task_description": "Generate a concise medical report / summary from multi-turn doctor-patient dialogues in the IMCS-V2 Chinese pediatric dataset; evaluated with ROUGE (1/2/L), BERTScore and medical expert human evaluation (Contains Key Result, Coherence, Usefulness, Readability).",
            "problem_format": "Task-decomposition prompt: split the requested summary into six named parts with instructions and examples for each part; include domain-specific example lists (variables such as {ls_symptom} and {ls_aux_test}) to provide contextual anchors; prompts given in Chinese; used as in-context examples to steer output structure and content.",
            "comparison_format": "Prompt_S (a simple prompt that gives minimal guidance; e.g., just labels like 'Auxiliary examination' and 'Diagnosis' without multi-part decomposition or example variable lists).",
            "performance": "ChatGPT with Prompt_T (configuration Prompt_T.7: Temperature=0.1, Top_p=0.1) — ROUGE-1: 48.19, ROUGE-2: 25.41, ROUGE-L: 40.81, BERTScore: 73.38; high human-evaluator approval (medical experts favored ChatGPT summaries, many 'Strongly Agree' responses, especially under Prompt_T).",
            "performance_comparison": "Same model with Prompt_S.7 (Temperature=0.1, Top_p=0.1) — ROUGE-1: 44.27, ROUGE-2: 21.95, ROUGE-L: 36.91, BERTScore: 71.49; BART model (fine-tuned) — ROUGE-1: 55.39, ROUGE-2: 40.38, ROUGE-L: 54.21, BERTScore: 78.32; although BART outperforms ChatGPT on automatic metrics, ChatGPT (Prompt_T) outperforms BART by human evaluation metrics.",
            "format_effect_size": "+3.92 ROUGE-1 and +3.90 ROUGE-L (Prompt_T.7 vs Prompt_S.7) in the reported configurations; ChatGPT(Prompt_T.7) still ~7.20 ROUGE-1 points lower than BART (automatic metrics).",
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "The paper attributes Prompt_T's advantage to clearer task structure and contextual examples (e.g., symptom and examination lists) that guide the model to produce more informative, organized, and medically-relevant content. Task decomposition helps the model focus on specific sub-goals (chief complaint, history, exams, diagnosis, recommendations), improving human-perceived usefulness and coherence.",
            "counterexample_or_null_result": "Despite Prompt_T improving ChatGPT's automatic metrics relative to Prompt_S and improving human preference, it did not allow ChatGPT to surpass the fine-tuned BART model on automatic metrics (ROUGE/BERTScore). The authors also note remaining issues under Prompt_T (overly long 'Chief complaint', hallucinated suggested tests) showing that better prompt structure does not fully eliminate errors.",
            "uuid": "e5705.0",
            "source_info": {
                "paper_title": "Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Prompt_S",
            "name_full": "Simple prompt (Prompt_S)",
            "brief_description": "A minimal/simple prompt used with ChatGPT that contains basic labels (e.g., 'Auxiliary examination', 'Diagnosis') without multi-part decomposition or contextual example variables.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5)",
            "model_size": null,
            "task_name": "Medical dialogue summarization (IMCS-V2)",
            "task_description": "Same medical summarization task: generate a concise medical report from doctor-patient dialogues and evaluate by ROUGE/BERTScore and human expert ratings.",
            "problem_format": "Simple prompt: provide minimal structuring cues (short labels for sections) and request a summary; no task decomposition nor domain example lists; Chinese-language prompt in dataset context.",
            "comparison_format": "Prompt_T (technical, decomposed prompt with examples and variables).",
            "performance": "Best reported Prompt_S configuration (Prompt_S.7: Temperature=0.1, Top_p=0.1) — ROUGE-1: 44.27, ROUGE-2: 21.95, ROUGE-L: 36.91, BERTScore: 71.49.",
            "performance_comparison": "Worse than Prompt_T.7 (ROUGE-1: 48.19 etc.). Compared to fine-tuned BART (ROUGE-1: 55.39), Prompt_S ChatGPT performance is substantially lower on automatic metrics; human evaluation also favored the Prompt_T outputs over Prompt_S.",
            "format_effect_size": "Prompt_S.7 → Prompt_T.7 yields +3.92 ROUGE-1 and +3.90 ROUGE-L (same numeric comparison as above) indicating the simple-to-technical prompt change effect in this study.",
            "format_effect_direction": "reduced (relative to Prompt_T)",
            "explanation_or_hypothesis": "Minimal guidance leads to less structured outputs and lower automatic scores and human preference; the paper suggests that explicit sectioning and examples are necessary to obtain more useful medical summaries from ChatGPT.",
            "counterexample_or_null_result": null,
            "uuid": "e5705.1",
            "source_info": {
                "paper_title": "Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Temperature/Top_p",
            "name_full": "Decoding hyperparameters: Temperature and Top_p",
            "brief_description": "Generation-decoders settings used with ChatGPT to control randomness (Temperature) and nucleus sampling diversity (Top_p); the study varied these to examine effect on summary quality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5)",
            "model_size": null,
            "task_name": "Medical dialogue summarization (IMCS-V2)",
            "task_description": "Same task; evaluated how generation randomness/diversity parameters affect summary automatic scores and qualitative behaviour.",
            "problem_format": "Prompt-response format with varying decoding hyperparameters. The paper tested seven combinations (see Table 5): combinations included (Temperature, Top_p) pairs like (1.0,1.0), (0.7,1.0), (0.1,1.0), (0.5,0.5), (1.0,0.1), (0.7,0.1), (0.1,0.1) across both Prompt_S and Prompt_T families.",
            "comparison_format": null,
            "performance": "Observed best automatic results generally occur at low Temperature and low Top_p (e.g., Prompt_T.7: Temperature=0.1, Top_p=0.1 — ROUGE-1 48.19, ROUGE-L 40.81). Higher Temperature/Top_p settings (e.g., 1.0,1.0) produced lower ROUGE scores in the tested runs (Prompt_S.1 ROUGE-1=43.69; Prompt_T.1 ROUGE-1=47.21).",
            "performance_comparison": "Within Prompt_T family: Prompt_T.1 (1.0,1.0) ROUGE-1=47.21 → Prompt_T.7 (0.1,0.1) ROUGE-1=48.19 (increase ≈ +0.98 ROUGE-1). Within Prompt_S family: Prompt_S.1 (1.0,1.0) ROUGE-1=43.69 → Prompt_S.6/7 (lower settings) ROUGE-1≈44.28/44.27 (increase ≈ +0.59).",
            "format_effect_size": "Modest but consistent gains observed when lowering Temperature and Top_p (examples: +0.98 ROUGE-1 in Prompt_T family; +0.59 ROUGE-1 in Prompt_S family).",
            "format_effect_direction": "improved (lower Temperature & lower Top_p → higher ROUGE scores / more conservative and relevant outputs)",
            "explanation_or_hypothesis": "Authors explain higher Temperature and Top_p increase creativity/diversity and can introduce medically-inaccurate or less relevant content (examples: model sometimes outputs a medication recommendation as a 'diagnosis'); lowering these parameters makes generation more conservative and aligned with input, increasing ROUGE and human-relevance.",
            "counterexample_or_null_result": "Effect sizes are modest and not sufficient alone to exceed fine-tuned model (BART) automatic metrics; even with low Temperature/Top_p some factual errors (hallucinated tests or overly long sections) persisted.",
            "uuid": "e5705.2",
            "source_info": {
                "paper_title": "Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "ICL",
            "name_full": "In-Context Learning (ICL) with GPT-3.5",
            "brief_description": "Using demonstration examples or prompt-based context (ICL) with GPT-3.5/ChatGPT to perform medical summarization without task-specific fine-tuning; in this paper ICL is part of Method B.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5)",
            "model_size": null,
            "task_name": "Medical dialogue summarization (IMCS-V2)",
            "task_description": "Generate clinical summaries from dialogues using in-context demonstrations plus prompt engineering (Prompt_S and Prompt_T variants) to elicit desired output.",
            "problem_format": "ICL: provide context/demonstrations (examples) and engineered prompts to let the pre-trained model produce summaries without full supervised fine-tuning; combined with varying prompts and decoding parameters.",
            "comparison_format": "Fine-tuned PLMs (BERTSUM, BART) which were trained/finetuned end-to-end on the task vs ICL-based ChatGPT prompting.",
            "performance": "ICL-based ChatGPT with Prompt_T.7 achieved ROUGE-1: 48.19, ROUGE-2: 25.41, ROUGE-L: 40.81, BERTScore: 73.38 and was preferred by human medical experts over BERTSUM and BART outputs despite lower automatic scores than BART.",
            "performance_comparison": "Fine-tuned BART attained higher automatic metrics (ROUGE-1: 55.39 etc.) but lower human-evaluator preference; BERTSUM performed poorly on both automatic and human evaluations.",
            "format_effect_size": "ICL combined with good prompt design (Prompt_T) and tuned decoding parameters yields several-point ROUGE gains over simpler prompt variants; exact gain depends on prompt and decoding configuration (see Prompt_T vs Prompt_S comparisons).",
            "format_effect_direction": "improved (when combined with task-decomposition prompts and low-temperature/top_p decoding)",
            "explanation_or_hypothesis": "ICL allows leveraging GPT-3.5's pre-trained knowledge and instruction-following behavior; when paired with structured prompts and examples it produces summaries that humans find more coherent and useful than some fine-tuned models, possibly because it better integrates world knowledge and verbose explanations.",
            "counterexample_or_null_result": "ICL/prompting did not match the fine-tuned BART on automatic metrics (ROUGE/BERTScore), demonstrating that prompt-based ICL improvements do not always translate to higher n-gram overlap scores and that automatic metrics may undervalue human-preferred outputs.",
            "uuid": "e5705.3",
            "source_info": {
                "paper_title": "Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A survey for in-context learning",
            "rating": 2,
            "sanitized_title": "a_survey_for_incontext_learning"
        },
        {
            "paper_title": "ImpressionGPT: an iterative optimizing framework for radiology report summarization with chatGPT",
            "rating": 2,
            "sanitized_title": "impressiongpt_an_iterative_optimizing_framework_for_radiology_report_summarization_with_chatgpt"
        },
        {
            "paper_title": "Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat",
            "rating": 2,
            "sanitized_title": "clinical_note_generation_from_doctorpatient_conversations_using_large_language_models_insights_from_mediqachat"
        },
        {
            "paper_title": "GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning",
            "rating": 1,
            "sanitized_title": "gersteinlab_at_mediqachat_2023_clinical_note_summarization_from_doctorpatient_conversations_through_finetuning_and_incontext_learning"
        }
    ],
    "cost": 0.01641425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences</p>
<p>Yong Liu 
Department of Computer Science
Sichuan University
No. 24, South Sec-tion 1, 1st Ring Road610065Chendu, SichuanChina</p>
<p>Shenggen Ju 
Department of Computer Science
Sichuan University
No. 24, South Sec-tion 1, 1st Ring Road610065Chendu, SichuanChina</p>
<p>Department of Computer Science
Sichuan University
No. 24, South Sec-tion 1, 1st Ring Road610065Chendu, SichuanChina</p>
<p>Junfeng Wang 
Department of Computer Science
Sichuan University
No. 24, South Sec-tion 1, 1st Ring Road610065Chendu, SichuanChina</p>
<p>Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences
D1B141EF4225EAF0DAD838EC3B7B990610.1186/s12911-024-02481-8Received: 2 October 2023 Accepted: 11 March 2024Internet HealthcareLarge language modelsChatGPTAutomated medical consultationMedical dialogue summarization
Background Telemedicine has experienced rapid growth in recent years, aiming to enhance medical efficiency and reduce the workload of healthcare professionals.During the COVID-19 pandemic in 2019, it became especially crucial, enabling remote screenings and access to healthcare services while maintaining social distancing.Online consultation platforms have emerged, but the demand has strained the availability of medical professionals, directly leading to research and development in automated medical consultation.Specifically, there is a need for efficient and accurate medical dialogue summarization algorithms to condense lengthy conversations into shorter versions focused on relevant medical facts.The success of large language models like generative pre-trained transformer (GPT)-3 has recently prompted a paradigm shift in natural language processing (NLP) research.In this paper, we will explore its impact on medical dialogue summarization.MethodsWe present the performance and evaluation results of two approaches on a medical dialogue dataset.The first approach is based on fine-tuned pre-trained language models, such as bert-based summarization (BERT-SUM) and bidirectional auto-regressive Transformers (BART).The second approach utilizes a large language models (LLMs) GPT-3.5 with inter-context learning (ICL).Evaluation is conducted using automated metrics such as ROUGE and BERTScore.ResultsIn comparison to the BART and ChatGPT models, the summaries generated by the BERTSUM model not only exhibit significantly lower ROUGE and BERTScore values but also fail to pass the testing for any of the metrics in manual evaluation.On the other hand, the BART model achieved the highest ROUGE and BERTScore values among all evaluated models, surpassing ChatGPT.Its ROUGE-1, ROUGE-2, ROUGE-L, and BERTScore values were 14.94%, 53.48%, 32.84%, and 6.73% higher respectively than ChatGPT's best results.However, in the manual evaluation by medical experts, the summaries generated by the BART model exhibit satisfactory performance only in the "Readability" metric, with less than 30% passing the manual evaluation in other metrics.When compared to the BERTSUM and BART models, the ChatGPT model was evidently more favored by human medical experts.ConclusionOn one hand, the GPT-3.5 model can manipulate the style and outcomes of medical dialogue summaries through various prompts.The generated content is not only better received than results from certain human experts but also more comprehensible, making it a promising avenue for automated medical dialogue summarization.On the other hand, automated evaluation mechanisms like ROUGE and BERTScore fall short in fully assessing † Shenggen Ju and Junfeng Wang contributed equally to this work.</p>
<p>Background</p>
<p>As healthcare evolves towards a patient-centered delivery model, online searching and accessing health information can fulfill patients' needs for prognosis and treatment information [1,2].Furthermore, with the rapid development of "Internet plus Healthcare" online consultation platforms are emerging, allowing doctors to diagnose diseases and provide relevant medical advice through remote conversations with patients.On the one hand, this enhances the efficiency of the healthcare system and alleviates some of the burden on medical professionals, enabling them to invest more energy in improving patient care and minimizing time spent on irrelevant matters [3,4].On the other hand, it enables effective patient screening, maintains social distancing, and protects clinical doctors and communities from infections, while still offering personalized healthcare and medical services [5].During the COVID-19 pandemic, influenced by policies and the pandemic's impact, the demand for online consultations has rapidly increased.This has irrevocably altered the status of telemedicine in the U.S. healthcare system and has been widely adopted across global healthcare systems [6].Summarizing conversations on remote medical platforms can bring about several benefits.For instance, Both doctors and patients can refer to important parts or conclusions from past interactions.This not only allows patients to quickly access the results they are concerned about but also enables doctors to learn from the experiences and approaches of other medical professionals when dealing with similar issues.Medical text summarization algorithms related to medical dialogue summaries are techniques that automatically extract key information from various medical data sources such as medical literature, electronic health records, and medical dialogue, and generate concise summaries.These algorithms mainly include two types: extractive summarization and abstractive summarization.</p>
<p>Extractive summarization selects content based on importance or keywords in the text.The generation process does not involve creating new sentences or phrases; it simply selects and combines existing content from the original text to generate a summary.It often treats summarization as a sequence labeling task, where each sentence is labeled with a binary classification tag of "yes" or "no", and the summarization process can be viewed as the selection of sentence classification labels.BERTSUM is a text summarization model based on bidirectional encoder representation from Transformers (BERT).It aims to leverage the powerful representation capabilities of BERT to generate concise summaries from input text [7].A hierarchical encoder-tagger model enhanced with a memory module was proposed to identify important utterances in dialogues between patients and doctors, thereby accomplishing the task of medical dialogue summarization [8].However, this method selects essential sentences from the original text to form concise summaries, maintaining interpretability and accuracy, however, it lacks the ability to generate new sentences, potentially resulting in less smooth and coherent summaries [8].</p>
<p>The abstractive summary uses natural language generation techniques to create new sentences or phrases by understanding the semantics and context of the original text in order to generate a summary.Abstractive summarization can typically express information more freely, rather than relying solely on the extraction of content from the original text.Kundan et al. [9] proposed a bidirectional LSTM-based encoder-decoder model with attention.It is used to extract important phrases related to each section of the summary and concatenate these relevant phrases together to generate a summary sentence for each cluster.The BART model combines the encoder-decoder architecture of Transformer with a pre-training task involving denoising autoencoders.This structure helps the model capture complex relationships between input data in text generation tasks [10].A simple yet general two-stage fine-tuning method is proposed to deal with input length limitations of the model, enabling the step-by-step generation of medical dialogue summaries [11].George et al. [12] proposed a sequenceto-sequence architecture for summarizing medical dialogues by integrating medical domain knowledge from the Unified Medical Language System (UMLS).Medical concepts from the references are encoded to distinguish important medical concepts, and combining an end-toend approach to explicitly model a switching variable, induce a mixed model of copying, generating, and negation to obtain medical dialogue summaries [13].The abstractive summary algorithm uses deep learning techniques such as RNN or Transformer to generate new, fluent, and coherent summaries, and ensures accuracy while avoiding the generation of unreasonable summaries when dealing with complex medical texts [11,14].The success of Transformer is attributed to their high degree of parallelism and self-attention mechanism.Building upon this foundation, the BERT model improved the architecture and achieved universal language representations through unsupervised pre-training on large-scale corpora [15].This study inspired a great deal of subsequent work, establishing the "pre-training and fine-tuning" learning paradigm, and introducing different architectures such as BART [16] and GPT-2 [17] that can be used to fine-tune downstream tasks.As the scale of parameters continues to increase to hundreds of billions, and training on massive data, large language models such as GPT are eventually generated, including GPT-3 and GPT-4 [18].</p>
<p>In recent years, LLMs provides opportunities for instructional fine-tuning through reinforcement learning from human feedback (RLHF) [19] to adapt to a variety of NLP tasks while aligning the model with human intent.They excel in areas such as education, healthcare, text generation and human-computer interaction.Summarization based on LLMs employs ICL and pre-trained language models (PLMs) to generate clinical notes, the results show that the ICL-based approach is as wellreceived as human-written notes.This makes it a promising approach for automatically generating notes in medical dialogues [20].Expert validation demonstrates that clinical notes generated by ICL in GPT-4 outperform all traditional fine-tuned models [21].The applicability of large language models in radiology report summarization tasks was explored by optimizing input prompts based on a small number of existing samples and an iterative approach [22].ChatGPT allows doctors to input specific information and medical concepts related to patients and generate formal patient discharge summaries.Automating this process can reduce the workload of junior doctors, giving them more time to provide patient care and seek training opportunities [23].</p>
<p>In this paper, We utilized two different approaches to generate medical dialogue summaries on a publicly available medical conversation dataset.Method A involves fine-tuning PLMs such as BERTSUM [7] and BART [16], while Method B utilizes the large language model Chat-GPT based on ICL [24], whose processing flow is shown in Fig. 1.For Method B, we first fine-tune the relevant parameters of the ChatGPT model and then explore using the model's prompt engineering functionality to generate medical dialogue summaries, and finally measure the ability of ChatGPT to generate medical dialogue summaries by automatic and human evaluation criteria.</p>
<p>Methods</p>
<p>Model Transformer</p>
<p>The "Transformer" model has become a foundational deep learning architecture for natural language processing [25].As shown in Fig. 2, the Transformer model is composed of encoder and decoder layers.Each of the encoder layer has a multi-head self-focusing and position-wise feed-forward network (FFN) sub-layer.The Fig. 1 The processing flow of generating summaries from doctor-patient dialogues using ChatGPT multi-head attention mechanism utilizes parallel scaled dot-product attention functions to focus on different subspaces and positions in the input data.By calculating the attention between query (Q), keys (K), and values (V), the results are as follows:</p>
<p>In Eq. ( 1), a set of queries , keys and values are packed together into a matrices Q, K and V.In addition, d k usu- ally refers to the dimension of the key vector, which can be used as a scaling factor to avoid excessive dot products.ReLU activation is used in the FFN sub-layer.In addition, layer normalization and a residual connection link the two sub-layers and can be used to tackle gradient issues , thus, stable network training can be obtained.Each decoder layer includes three sub-layers: an FFN sub-layer and two attention sub-layers.The decoder self-attention sub-layer uses a mask function to prevent attending to unseen future tokens.The encoder-decoder attention layer enables the (1)
Attention(Q, K , V ) = softmax QK T d k V
decoder to focus on essential parts of the source sequence and capture the encoder-decoder relationship.</p>
<p>Given an input sequence of symbol representations X = [x 1 , x 2 , ..., x n ] and a real output sequence Y = [y 1 , y 2 , ..., y m ] .We assume that the last position of each input sequence is a special "[END]" flag.The encoder maps X to a sequence of continuous representations H = [h 1 , h 2 , ..., h n ] .Given H, the decoder then generates a predicted output sequence Ŷ = ŷ1 , ŷ2 , ..., ŷk .Therefore, during training, the model minimizes the cross-entropy loss between the predicted sequence Ŷ and the real out- put sequence Y, as shown in Eq. ( 2), where k represents the number of target sequences.At each step, the model is auto-regressive [26], which means that it utilizes the previously generated symbols as additional input when generating the next symbol in the sequence.This enables the model to contextually understand and produce coherent outputs in a step-by-step manner.</p>
<p>( The Transformer's impact on natural language processing has been profound, inspiring the development of modern NLP models such as BERT [15], GPT [17], RoBERTa [27], and T5 [28], all built on the Transformer architecture.
) L Ŷ , Y = − m i=1 ŷi logy i2</p>
<p>BERT</p>
<p>BERT is an important language model based on the Transformer architecture, it is trained to learn general language representations and capture contextual semantics, which has had a profound impact on NLP research and applications [29][30][31].As shown in Fig. 3, the basic BERT structure is made up of multiple layers of Transformer and includes two pre-training tasks: mask language model (MLM) and next sentence prediction (NSP).Taking NSP as an example, the main elements are divided three parts as follows:</p>
<p>• Input layer.For a given input text that has undergone masking and is represented as
x = [x 1 x 2 ...x n ] and x ′ = [x ′ 1 x ′ 2 ...x ′ m ]
, the following processing results in the BERT input representation e.</p>
<p>In Eq. ( 3), [CLS] represents the special token marking the beginning of a text sequence, and [SEP] represents a separator marker between text sequences.</p>
<p>(3) The application of BERT in medical document summarization accelerates the acquisition [32,33], processing and application of medical information [34,35], improving the efficiency and accuracy of healthcare and medical research [36].It brings a broader development space for (5) [15] the medical field, and is expected to promote the innovation of medical information processing and application in the future [37].
X = [CLS]x 1 x 2 ...x n [SEP]x ′ 1 x ′ 2 ...x ′ m [SEP]h = Transformer (e) (6) P = Softmax h 0 W p + b 0</p>
<p>BERTSUM</p>
<p>BERTSUM is a text summarization model based on BERT which aims to generate concise summaries from input text by leveraging BERT's powerful representation capabilities.The model utilizes BERT's encoder to obtain semantic vector representations for sentence-level segments in the input text.The training of BERTSUM occurs in two stages: pre-training of the BERT model on unsupervised tasks and supervised fine-tuning with datasets containing human summaries.During fine-tuning, the model optimizes the similarity between generated and original summaries as the loss function [7].</p>
<p>As shown in Fig. 4, in the context of encoding multiple sentences, an [CLS] token is inserted before each sentence, and a [SEP] token is inserted at the end of each sentence.In vanilla BERT, [CLS] is used to aggregate features from a single sentence or a pair of sentences.Therefore, by using multiple [CLS] tokens to fine-tune the model and based on these tokens, it is possible to obtain sentence features in ascending order.The BERT sentence vectors undergo additional summarization-specific layers to capture document-level features for summary extraction.The resulting values are then passed through the sigmoid function, which maps them to a range between 0 and 1.Therefore, each sentence is assigned a predicted score Ŷ .The model's loss is the binary classification entropy between Ŷ and the gold label Y. (
) Ŷ = σ (W o T i + b o )7</p>
<p>BART</p>
<p>BART is an NLP pre-trained model proposed by Facebook AI for pre-training the bidirectional and autoregressive combined model Transformers [16].The main idea is to combine the encoder-decoder structure of Transformer with the pre-training task of denoising auto-encoder.BART uses an encoder-decoder structure similar to Transformer.The encoder is responsible for mapping the input sequence to an intermediate representation, and the decoder then maps this intermediate representation back to the original input space.This structure can help the model capture complex relationships between inputs.In the text generation task, the input of the encoder is the input text as the condition, and the decoder generates the corresponding target text in an auto-regressive way, as shown in Fig. 5.</p>
<p>The BART model has acquired a substantial amount of basic language knowledge during the pre-training phase, so during downstream tasks (such as text classification, named entity recognition, question answering system, document summarization, etc.), we only need to fine-tune the model, without needing to train   [16] the model from scratch.This greatly saves training time and improves the performance of the model.</p>
<p>ChatGPT and prompt ChatGPT</p>
<p>ChatGPT is a powerful language model developed by OpenAI based on the Transformer architecture, which can be implemented in three steps [19].</p>
<p>Step 1, Collect demonstration data and train a supervised policy.Step 2, Collect comparison data and train a reward model.</p>
<p>Step 3, Optimize the reward model using proximal policy optimization (PPO) [38].Figure 6 illustrates the relevant process of Step 2, where annotators annotate the data in the candidate dataset according to their respective standards and manually rank them based on the scores.Then, they input the rankings into a reward model to predict the preferences of the manual annotations.</p>
<p>The loss function used during training is shown in formula (8).</p>
<p>where r θ x, y is the scalar output of the reward model for prompt x and completion y with parameters θ , y w is the preferred completion out of the pair of y w and y l , and D is the comparison dataset.</p>
<p>As a generative model, ChatGPT can produce text sequences given an initial prompt.It comes in different versions, with each new iteration being more capable and better at handling complex language tasks [39].ChatGPT finds applications in various fields [40], including tutoring and education [41], translation [42], healthcare [43], and medicine [44][45][46].</p>
<p>Regarding medical text summarization, users can utilize ChatGPT to understand and condense lengthy medical reports or research papers [47].By using a relevant portion of the text as a prompt, the model can provide (8)
Loss(θ ) = − 1 K 2 E x, y w , y l ∼ D log σ r θ x, y w − r θ x, y l
a concise summary tailored to the user's needs [48].For example, a user studying heart disease could prompt the model to generate a simplified summary of coronary artery disease and its causes.</p>
<p>Prompts for large language models</p>
<p>In ChatGPT or other GPT models, "prompt" refers to the initial text or request entered into the model.This can be a question, part of a sentence, or even a word.The model generates or continues text based on this initial prompt, with the goal of producing fast responses that are consistent in terms of grammar, context, and style.It achieves this by relying on the language patterns and associations learned during the pre-training phase, as well as the more specific guidance acquired during the fine-tuning phase.By optimizing the design of prompt, users can better guide models to produce outputs that meet their specific needs.We try to provide some reference content as follows:</p>
<p>• Define the task or objective.Clearly specify the task or objective you want the model to accomplish.This could be answering questions, generating articles,etc.• Understand the model's capabilities.Familiarize yourself with the limitations and strengths of the model.Different models perform differently on tasks, and understanding their capabilities helps guide them effectively.• Choose appropriate length and format.Determine the length and format of the prompt.Sometimes, concise prompts are more effective, but for certain tasks, a more detailed description or context may be necessary.• Grammar and format.Ensure the prompt is grammatically correct and adheres to the input format expected by the model.This increases the likelihood of the model understanding and generating correct output.</p>
<p>Fig. 6 Training Process of the reward model (RM)</p>
<p>• Provide relevant information.If specific background or contextual information is required, make sure to include it in the prompt.This helps the model better understand the task or question.• Iterate for optimization.Iterate through different prompts, observe the model's responses, and adjust based on the results.This is an iterative process that gradually improves the model's performance.• Evaluate and adjust.Assess whether the generated text aligns with expectations and adjust or improve prompts as needed.Continuous evaluation of outputs guides the optimization process.</p>
<p>Follow the above description, users can better guide models to produce outputs that meet their specific needs.Overall, prompt is an important factor in driving GPT models to produce specific outputs, and users can carefully design prompt to get the best model output [49].</p>
<p>Experiments Dataset</p>
<p>We utilized the data provided by the School of Data Science at Fudan University, which was constructed under the guidance of medical experts from Fudan University Medical School and named IMCS-V2.This dataset has collected authentic online medical dialogues and subjected them to multi-level human annotations.The aim is to facilitate open evaluation against the Chinese biomedical language understanding evaluation (CBLUE) benchmark and thereby advance the fields of intelligent healthcare and medical language understanding.The IMCS-V2 dataset comprises 4,116 medical-patient dialogue samples that have undergone meticulous annotations, and detailed statistical data are presented in the following Table 1.In addition, this dataset encompasses 10 pediatric diseases, and the disease distribution is shown in Fig. 7.</p>
<p>The dataset used in this paper is a publicly available dataset designed for a medical natural language processing competition.The task involves generating medical reports from multi-turn doctor-patient dialogues.However, due to the competition's requirements, the summary portions of the test set have been omitted.This limitation prevents us from comparing it with the summaries generated by ChatGPT.Therefore, only (4116 -811)=3305 samples out of the original 4116 samples are available for the final training and testing.We migrate the first 500 samples (sorted by file name) from the valid set as the new test set, and then combine the first 167 samples from the training set (sorted by file name) with the remaining samples from the valid dataset to form a new valid dataset consisting of 500 samples.In the end, train set has 2305 samples, valid and test sets have 500 samples respectively.Since the samples distribution in the original train and valid sets were randomly generated by the organizer, we did not carry out random selection in the process of data  migration, but only extracted according to the order of file names.</p>
<p>Experimental environment and model parameter settings</p>
<p>In this paper, all the experiments were conducted on two NVIDIA GeForce RTX 3090 GPUs with 24GB of memory and using the python language on the PyCharm platform.The relevant environment settings required for the experiment are shown in  8, and technical type, denoted as Prompt_T, as shown in Fig. 9.In Fig. 8, Prompt_S does not use complicated prompts, but indicates "Medical examination names" in the "Auxiliary examination" part, and "The most relevant diagnostic name" in the "Diagnosis" part, in the hope that ChatGPT can return relevant results.Since this article is based on research using a Chinese medical dialogue dataset, the prompts used by ChatGPT are written in Chinese.Actually, ChatGPT itself supports multiple languages, so you can also write prompts in English, and simply include an additional instruction for ChatGPT to provide medical dialogue summaries in Chinese.Please note that there will be several instances of Chinese content in this text, along with corresponding English explanations, just to make it clearer for readers who use different languages.In Fig. 9, taking advantage of the idea of task decomposition, we use Prompt_T to split the summary into six parts, each with related more detailed sub-prompts.For example, the "Chief complaint: Not exceeding 20 words, including symptoms such as {ls_symptom} as an example, generated based on the doctor-patient dialogue, and the duration of symptoms.".Symptoms are stored in the variable {ls_symptom}, which mainly refers to symptoms of childhood diseases related to the dataset, including "fever", "cough", "sore throat", "runny nose", "abdominal pain", "diarrhea", etc. Please refer to Fig. 10 for detailed explanations.The purpose of this approach is to try to give ChatGPT, in this way, a contextual example of similar symptoms of the disease, so that it can give a better description of the patient's symptoms.Similarly, in the "Auxiliary examination" part, "generate the most relevant medical examination names, using {ls_aux_test} as an example".The variable {ls_aux_ test} stores some medical examination names, such as "complete blood count", "urinalysis", "stool routine", "chlamydia", "liver function", "kidney function", etc.Eventually, ChatGPT is expected to give a better name for the auxiliary examinations performed by the patient based on the content of this variable {ls_aux_test}.For the rest of Fig. 9, some give specific examples, such as the "Diagnosis" part, and some give relevant explanations, such as the "Present medical history" part.For details, please refer to   the corresponding contents in Fig. 10, which will not be repeated here.</p>
<p>Evaluation metrics Automatic evaluation metrics</p>
<p>In this paper, the ROUGE-1, ROUGE-2, ROUGE-L [50] and BERTScore [51] as automatic evaluation metrics.Given a reference summary x = (x 1 , . . ., x k ) and a can- didate summary x = x1 , . . ., xk .By embedding model generate reference summary vector X = (X 1 , . . ., X m ) and candidate summary vector X = X1 , . . ., Xm , respectively.</p>
<p>ROUGE-n represents an n-gram recall measure comparing a reference summary to the corresponding candidate summary.The computation of ROUGE-n is as follows:</p>
<p>Where n denotes the length of the n-gram, so gram n represents the 1-gram or 2-gram, and Count match gram n ∈ x, x signifies the maximum num- ber of 1-gram or 2-gram co-occurring in a reference summary and the corresponding candidate summary.</p>
<p>(9)
P ROUGE−n = Count match gram n ∈ x, x Count gram n ∈ x R ROUGE−n = Count match gram n ∈ x, x Count gram n ∈ x F ROUGE−n = 2 * P ROUGE−n * R ROUGE−n P ROUGE−n + R ROUGE−n
Fig. 8 A simple for medical dialogue summarization without any complex parameter variables, abbreviated as Prompt_S Fig. 9 A technical prompt for medical dialogue summarization with some parameter variables, abbreviated as prompt_T</p>
<p>We known that the longer the Longest Common Subsequence (LCS) of two summary sentences, the more similar the two summaries are.We employ the ROUGE-L to measure the similarity between a reference summary and the corresponding candidate summary.The calculation is as follows:</p>
<p>Where LCS x, x is the length of a longest common subsequence of the reference summary and the corresponding candidate summary.|x| is the length of the reference summary and x is the length of the candidate summary.</p>
<p>BERTScore computes the complete score by matching each token in candidate summary x to a token in reference summary x to calculate precision, and each (10)
P ROUGE−L = LCS x, x x R ROUGE−L = LCS x, x|x|F ROUGE−L = 2 * P ROUGE−L * R ROUGE−L P ROUGE−L + R ROUGE−L
token in reference summary x to a token in candidate summary x to calculate recall .</p>
<p>Where COS X i , Xj is the cosine similarity of a refer- ence summary x and a candidate summary x is given by the formula
X T i Xj �X i � Xj
. |x| is the length of the reference sum- mary and x is the length of the candidate summary.</p>
<p>Human evaluation metrics</p>
<p>We recruited three domain experts with medical training, and each of them individually annotated 100 randomly (11)  selected medical dialog samples from the dataset.In total, we collected 300 annotations, with three annotations for each sample.Contains Key Result, Coherence, Usefulness and Readability as human evaluation metrics [48].
COS X i , Xj = X T i Xj �X i � Xj P BERT = 1 x xj ∈x max x i ∈x COS X i , Xj R BERT = 1 |x| x i ∈x max xj ∈x COS X i , Xj F BERT = * P BERT * R BERT P BERT + R BERT</p>
<p>Results</p>
<p>In Table 5, "Prompt_S" and "Prompt_T" represent the use of simple and technical prompt modes in ChatGPT.The combinations of "Temperature" and "Top_p" parameters for these two different prompts can be adjusted to modify the generation results of the ChatGPT model, catering to the requirements of medical dialogue summaries.The "Temperature" parameter is used to control the randomness and creativity of generated text, while the "Top_p" parameter is used to control the diversity of generated text.A higher "Top_p" value results in more diverse text, and a lower "Top_p" value results in more consistent text.Higher "Temperature" and higher "Top_p" values create more randomness and creativity, but may result in generated content that is less relevant to the input.From Fig. 11, it can be seen that when Tempera-ture=1.0 and Top_p=1.0,ChatGPT generated a medication recommendation as the diagnosis result.When Temperature=0.7 and Top_p=1.0,ChatGPT generated a medication name as the diagnosis result.</p>
<p>Although this situation is relatively rare and doesn't happen every time, it indirectly confirms that excessively high Temperature and Top_p parameter values may have a negative impact on the summary results.Conversely, lower "Temperature" and lower "Top_p" values make the generated content more conservative and relevant, but potentially less innovative.These parameters can be adjusted according to the actual situation of the specific application and requirements.As shown in Fig. 12, when parameters "Temperature" and "Top_p" are set between 0.1 and 1, the variation trend of the ROUGE score is basically consistent with the characteristics of parameters "Temperature" and "Top_p" themselves, especially with the decrease of the value of the "Top_p" parameter, the ROUGE-1 and ROUGE-L scores increase.</p>
<p>The results from Table 6 indicate that when ChatGPT is in modes "Prompt_S" and "Prompt_T", which correspond to "Temperature=1.0"and "Top_p=1.0"the ROUGE-1 and ROUGE-L scores are the lowest.When "Tempera-ture=0.1" and "Top_p=0.1",the ROUGE-1 and ROUGE-L scores the highest.This indicates that adjusting the "Temperature" and "Top_p" parameters appropriately based on their characteristics can indeed influence the final ROUGE results.Furthermore, using "Prompt_T" as ChatGPT's prompt yields significantly better results compared to using "Prompt_S".This indicates that welldesigned prompts can significantly enhance the performance of ChatGPT in generating summaries.</p>
<p>We randomly selected 100 sets of medical dialogue summaries generated by the BERTSUM, BART, and ChatGPT models, where ChatGPT used prompts Prompt_S.7 and Prompt_T.7 to generate the medical dialogue summaries.Nevertheless, the pre-trained model approach based on BART outperformed the best results obtained with ChatGPT in both prompt modes, and was 14.94% better than the highest value corresponding to ChatGPT on the ROUGE-1 score and 32.84% better than the highest score corresponding to ChatGPT on the ROUGE-L score.From Table 7, it is evident that the dialogue summaries generated by  the BART model outperform BERTSUM and ChatGPT in terms of automatic evaluation metrics, with higher ROUGE-1, ROUGE-2, ROUGE-L, and BERTScore scores.However, the effect of ChatGPT is much better than BERTSUM and BART models under the human evaluation metrics.</p>
<p>Discussion</p>
<p>Comparison between automatic evaluation metrics and human evaluation metrics</p>
<p>As depicted in sub-figures (a) and (b) of Fig. 13, medical experts showed high approval of the summary quality generated by ChatGPT, with higher approval rates in Prompt_T compared to Prompt_S.As depicted in subfigure (c) of Fig. 13.Except for the "Readability" metric, the other three metrics had barely passed the medical experts' evaluation, with less than 30% of the summaries meeting the criteria.In contrast, the summaries generated by ChatGPT completely passed the medical experts' evaluation, with many of them being rated as "Strongly Agree" as shown in sub-figures (a) and (b) of Fig. 13.Sub-figure (d) in Fig. 13 illustrates that medical experts have rated the medical dialogue summaries generated by the BERTSUM model as mostly "Strongly Disagree" on almost all human evaluation metrics.This indicates that such summaries have no reference value for users.Additionally, from Figs. 14 and 15, we can observe that the summaries generated by the BART model are The "Temperature" parameter controls the level of randomness and creativity in the generated text, while the "Top_p" parameter influences the diversity of the generated content.A higher "Top_p" value leads to more diverse text, whereas a lower value results in more consistent text.Elevated values for both "Temperature" and "Top_p" introduce greater randomness and creativity but may reduce the relevance of the generated content to the input.Conversely, lower values for both parameters make the generated content more conservative and relevant but potentially less innovative relatively short.After conducting statistical analysis, it was found that the manually annotated summaries in the original dataset had an average length of 100 words, while the average length of summaries generated by the BART model was only 60 words.This discrepancy could possibly be attributed to the influence of the style of manual annotations.Although the generated summaries may appear concise, they tend to overlook crucial information, leading to a reduction in their overall informative value.In contrast, ChatGPT generates summaries of approximately 200 words, which are perceived by human experts as more comprehensive, effective, and valuable.</p>
<p>A few real-world examples of BART and ChatGPT models on medical dialog summaries</p>
<p>As shown in Fig. 16, the "Recommendation" part of the manual summary lists "aluminum magnesium carbonate tablets" alongside "probiotics" and "montmorillonite powder for children" as medications, without clearly specifying whether "aluminum magnesium carbonate tablets" is intended for the patient's child or the patient themselves, this lack of clarity could lead to misunderstanding.On the other hand, the "Recommendation" part of ChatGPT's summary clearly states, "patients can use aluminum magnesium carbonate tablets to neutralize stomach acid", indicating that ChatGPT can significantly determine that the medication is for the patient themselves, not their child.Additionally, in Fig. 17, the "Recommendation" part of ChatGPT's summary includes advice such as "to maintain the baby's water intake, you can give an appropriate amount of oral rehydration salt solution", which was not explicitly mentioned in the original conversation.However, medical experts recognize that ChatGPT's generated advice is entirely consistent with medical knowledge, given the context of the original conversation where it mentions about the child's dehydration due to frequent diarrhea after feeding.In this context, ChatGPT provides more reasonable recommendations than the manual summary.In Fig. 14, the "Diagnosis" output from the BART summary is "Upper respiratory infection" while the correct diagnosis should be related to a disease associated with "Diarrhea".This incorrect diagnosis is a significant discrepancy in the BART summary.Additionally, the BART summary is overly concise, leading to the omission of some potentially important information.In the "Recommendation" part, BART's summary only mentions the recommendation of "Oral montmorillonite powder".However, the original conversation actually includes additional recommendations such as "routine stool examination and other relevant examination" and "avoid eating greasy, spicy and irritating food,and feed more liquid food".The exclusion of these important recommendations in the BART summary results in the loss of crucial information and diminishes the overall usefulness of the summary.In Fig. 15, the BART summary closely resembles the manual summary, and its ROUGE-1 score is also high.However, in terms of practical effectiveness, especially in the "Recommendation" part where the content is "Continue to take oral medications for cold medicine", such content provides a rather vague recommendation and lacks useful information.On the other hand, the ChatGPT summary offers more detailed advice.In addition to recommending the medication "spleen ammonia peptide freeze-dried powder", it also suggests "atomization" and "make some pear tea for the baby to drink".In Fig. 18, the main issues with the summaries generated by ChatGPT are: (1).The "Chief complaint" part is overly lengthy.(2).In the "Auxiliary examination" part, there are suggestions for examinations that did not actually occur.However, despite these issues, they do not affect the understanding of the generated summaries by both the medical professionals and patients.In summary, these examples illustrate that ChatGPT can significantly enhance the accuracy and specificity of recommendations by considering contextual information and generating more appropriate advice than manual summaries.Moreover, ChatGPT proves to be more effective and valuable in generating summaries compared to BERTSUM and BART.However, this also serves as a reminder that when assessing the quality of summaries, it is essential to consider not only automatic evaluation metrics such as ROUGE but also conduct comprehensive analyses, taking into account the actual content and application scenarios.By taking a holistic approach to evaluation, we can better understand the capabilities and Fig. 14 From the perspective of ROUGE-1 score, the BART summary here shows a high similarity to the manual summary.However, there are significant issues with the BART summary.Firstly, in the "Diagnosis" part, the BART summary incorrectly states the diagnosis as "Upper respiratory infection", while the correct diagnosis in the manual summary is "Diarrhea".Secondly, the entire summary is too brief, leading to the omission of some potentially important information.For instance, in the "Recommendation" part, the BART summary only mentions the recommendation of "Oral montmorillonite powder".Although ChartGPT's ROUGE-1 score is lower than BART's, the resulting summary is highly detailed and semantically consistent with the original conversation data, such as "routine stool examination and other relevant examinations" and "avoid eating greasy, spicy and irritating food, and feed more liquid food" Fig. 15 From the perspective of ROUGE-1 score, the summary generated by BART is highly similar to the manual summary.However, in terms of practical effectiveness, especially in the "Recommendation" part where the content is "Continue to take oral medications for cold medicines", such content provides a rather vague recommendation and lacks useful information.On the other hand, the advice given by ChatGPT is more detailed and valuable.For instance, in addition to recommending the medication "spleen ammonia peptide freeze-dried powder", it also suggests "atomization" and "make some pear tea for the baby to drink".Such specific and practical information can offer more assistance and guidance to the readers Fig. 16 The manual summary mistakenly leads people believe that magnesium carbonate tablets" is intended for children, but in reality, it is meant for parents of children.On the other hand, ChatGPTis able to distinguish between different patients in the context of the conversation, i.e. the user of the drug is clearly distinguished by "children" and "patient", where "children" means the sick child and "patient" means the parents of the sick child.For example, "patients can use aluminum magnesium carbonate tablets to neutralize stomach acid" limitations of language models such as ChatGPT, and ensure that their outputs align with real-world use cases and human expectations.ChatGPT's ability to provide contextually relevant and useful recommendations highlights its potential in various natural language processing tasks, and it emphasizes the importance of evaluation practices in the development and deployment of AI systems.</p>
<p>Conclusion</p>
<p>The study compares the performance of the BART, Chat-GPT, and BERTSUM models in generating medical dialogue summaries.The results indicate that summaries generated by the BERTSUM model exhibit notably lower ROUGE and BERTScore scores, and fail human evaluation across all metrics.Conversely, the BART model achieves the highest ROUGE and BERTScore scores, outperforming ChatGPT.It is ROUGE-1, ROUGE-2, ROUGE-L, and BERTScore scores surpass ChatGPT's best results by 14.94%, 53.48%, 32.84%, and 6.73% respectively.However, in human evaluation by medical experts, BART's summaries perform well only in "Readability" with less than 30% passing evaluation in other metrics.</p>
<p>Compared to BERTSUM and BART, the ChatGPT model is preferred by human medical experts.In conclusion, ChatGPT can manipulate medical dialogue summary style and outcomes using various prompts.The generated content is not only better received than certain human experts' results but also more comprehensible, showing promise for automated medical dialogue summarization.However, automatic evaluation metrics such as ROUGE and BERTScore may have limitations when it comes to comprehensively assessing the outputs of large language models like ChatGPT, therefore, further research is needed to explore more suitable evaluation metrics.Additionally, there are still some issues with the medical dialogue summaries generated by ChatGPT, such as overly lengthy "Chief Complaint" part and the inclusion of certain tests in the "Auxiliary examination" part that did not actually occur, and one more, improperly configured fine-tuning parameters for ChatGPT can indeed lead to incorrect results.In conclusion, ChatGPT's performance in medical conversation summarization is influenced by various factors.Therefore, future research needs to further identify the key factors affecting model output results and solve them systematically step by step.Fig. 17 In the original conversation, it is evident that the child is suffering from diarrhea with watery stools.Generally, in such cases, doctors would recommend oral rehydration with a saline solution to the patient to prevent dehydration.However, this advice is not evident from the manual summary, primarily because the original text did not mention the relevant content of oral rehydration.On the other hand, ChatGPT can directly provide a reasonable recommendation.Such as "to maintain the baby's water intake, you can give an appropriate amount of oral rehydration salt solution"</p>
<p>Limitations</p>
<p>Although the dataset used in this article is a publicly available dataset designed for medical natural language processing competitions, which avoids the legal and ethical issues associated with using patient data, protecting sensitive patient data remains a critical area worthy of research and attention.Due to the focus and space limitations of this study, only brief discussions are provided here.We look forward to conducting more detailed research in the future.</p>
<p>It is noteworthy that 87.8% of survey respondents expressed concerns that chatbots could be utilized for data collection or user manipulation [52].While Chat-GPT diligently focuses on ensuring safe conversations and effectively guards against direct prompts used in data extraction attacks during training, there remains a potential vulnerability known as "jailbreaking" that can circumvent its ethical safeguards.As an illustration, ChatGPT may occasionally disclose private details while operating in its "Developer Mode" under a jailbreaking prompt [53].As the landscape of AI evolves, traditional approaches to information security become outdated.A rule-based strategy is no longer sufficient in the face of generative AI tools [54].Timo et al. propose that establishing flexible regulatory mechanisms and legal frameworks is crucial, and when regulating the technology and applications of LLMs, it is essential to consider the rapid development of technology and the constantly changing legal environment.Furthermore, cybersecurity vulnerabilities in LLMs can lead to breaches and malicious attacks, necessitating the establishment of minimum security standards and the provision of appropriate training for healthcare professionals [55].</p>
<p>Fig. 18 The main issues with the summaries generated by ChatGPT are: (1).The "Chief Complaint" part is overly lengthy.(2).In the "Auxiliary examination" part, there are suggestions for examinations that did not actually occur.However, despite these issues, they do not affect the understanding of the generated summaries by both the medical professionals and patients</p>
<p>In conclusion, we believe that relying solely on LLMs providers to protect patient privacy data is insufficient.At the very least, the following key aspects should be considered:
•
Fig. 2
2
Fig. 2 The Transformer -model architecture.The creation of this figure is based on Fig. 1 in the paper[25]</p>
<p>( 4 )
4
e = InputRepresentation (X) • BERT encoder layer.In this layer, the input representation e is encoded by L layers Transformer to obtain a contextual semantic representation of the input text: where h ∈ R N ×d , N represents the maximum length of the sequence, and d represents the hidden layer dimension of BERT.• The output layer.In the NSP task, BERT uses the hidden layer of the [CLS] position as the semantic representation of the context consisting of the first component h 0 of h, and finally predicts the classifi- cation probability P of the input text through a fully connected layer: where P ∈ R 2 , W p ∈ R d×2 represents the weight of the fully connected layer, and b 0 ∈ R 2 represents the bias of the fully connected layer.Classification probability P is used to calculate cross-entropy loss with the real label y.The final model parameters are updated based on this loss.</p>
<p>Fig. 3
3
Fig.3 The overview architecture of the BERT model.The creation of this figure is based on Fig.1in the paper[15]</p>
<p>Fig. 4
4
Fig.4 The overview architecture of the BERTSUM model.The creation of this figure is based on Fig.1in the paper[7]</p>
<p>Fig. 5
5
Fig. 5 Example of a task used by the BART model for text generation.The creation of this figure is based on Fig. 3 in the paper[16]</p>
<p>Fig. 7
7
Fig.7 The proportion distribution of the 10 pediatric diseases in the IMCS-V2 medical dialogue dataset</p>
<p>Fig. 10
10
Fig. 10 Detailed description of the parameters related to prompt_T</p>
<p>Fig. 11
11
Fig. 11 Higher values of the Temperature and Top_P parameters may lead to partial summary results generated by ChatGPT that may be inconsistent with the actual situation</p>
<p>Fig. 13
13
Fig.13 Human evaluation of summaries generated by ChatGPT, BART, and BERTSUM models, with average scores on four evaluation metrics: Contains Key Result, Coherence, Usefulness, and Readability.Sub-figures (a) and (b) demonstrate that summaries generated by ChatGPT achieved favorable results in the human evaluation metrics, especially under the Prompt_T condition, with a substantial proportion of "Strongly Agree" in all metrics.However, sub-figure (c) indicates that the BART model performed poorly in the human evaluation metrics, except for the "Readability" metric.sub-figure(d)  shows that the BERTSUM model exhibited very poor performance across all metrics, almost entirely in the "Strongly Disagree" state</p>
<p>Table 1
1
Detailed statistics on the IMCS-V2 medical dialogue dataset
Statistical indicatorsValueTotal Diseases10Total Dialogues4116Total Sentences164731Average Sentences/Per Dialog40Average Words/Per Dialog523</p>
<p>Table 2 .
2
The data is divided into a training set of 2305, a verification set of 500 and a test set of 500.In this paper, abstracts are divided into two types: extractive summarization and abstractive summarization.BERTSUM model is the representative of extractive summarization, while BART model and Chat-GPT are the representatives of abstractive summarization.The training parameters of BERTSUM model are shown in Table 3, and the training parameters of BART model are shown in Table 4.</p>
<p>Prompt settings for summarizationFigures 8, 9 and 10 show prompt settings related to Chat-GPT model.The prompts in this paper are divided into two types: simple type, denoted as Prompt_S, as shown in Fig.</p>
<p>Table 2
2
Hardware and software environment
DeviceCongigurationOperating systemUbuntu 20.04.6 LTSProcessorIntel Xeon(R)Gold6133 CPU® 2.50GHzGPURTX 3090 (24GB)*2FrameworkPytorchCompilersPyCharmScripting languagePython 3.8</p>
<p>Table 3
3
Hyper-parameters of BERTSUM, in the case of multiple candidate parameter values, the ultimately chosen parameter value is displayed in bold
ParametersValuesencoder(classifier/transformer/rnn)batch size(1000/2000/3000)train steps10,000dropout0.1learning rate2e −3 • min step −0.5 , step • warmup −1.5warmup(1000/10,000)optimizeradam</p>
<p>Table 4
4
Hyper-parameters of BART
ParametersValuesbatch_size32epochs3max_input_length521max_target_length150learning_rate1e-04warmup_steps10weight_decay0.001metric_for_best_modelROUGE-1</p>
<p>Table 5
5
Temperature and Top_p parameter combinations for ChatGPT's prompt model, such as Prompt_S and Prompt_T
Prompt ModelTemperatureTop_pPrompt_S.11.01.0Prompt_S.20.71.0Prompt_S.30.11.0Prompt_S.40.50.5Prompt_S.51.00.1Prompt_S.60.70.1Prompt_S.70.10.1Prompt_T.11.01.0Prompt_T.20.71.0Prompt_T.30.11.0Prompt_T.40.50.5Prompt_T.51.00.1Prompt_T.60.70.1Prompt_T.70.10.1</p>
<p>Table 6
6
Rouge and BERTScore scores for ChatGPT's prompt model, such as Prompt_S and Prompt_T
Prompt ModelROUGE-1ROUGE-2ROUGE-LBERTScorePrompt_S.143.6921.7435.7871.43Prompt_S.244.0922.0136.5471.47Prompt_S.343.9221.6936.5971.31Prompt_S.444.1721.8436.6771.42Prompt_S.544.1821.8836.8771.40Prompt_S.644.2821.9436.8971.48Prompt_S.744.2721.9536.9171.49Prompt_T.147.2125.8339.4173.34Prompt_T.247.8426.3140.3573.38Prompt_T.347.9725.4640.5973.32Prompt_T.448.0725.5040.5773.36Prompt_T.548.1125.4040.7373.37Prompt_T.648.0725.3940.6973.37Prompt_T.748.1925.4140.8173.38</p>
<p>Table 7
7
Automatic evaluation metrics for BERTSUM, BART, and ChatGPT summaries, such as comparisons of ROUGE-1, ROUGE-2, ROUGE-L and BERTScore scores
ModelROUGE-1 ROUGE-2 ROUGE-L BERTScoreBERTSUM_Classifier34.5113.9424.4763.53BERTSUM_Transfromer 33.5213.2124.0663.21BERTSUM_RNN33.7313.6224.1763.18BART55.3940.3854.2178.32ChatGPT(Prompt_T.7) 48.1925.4140.8173.38</p>
<p>The continuous improvement of regulatory mechanisms and legal standards permeates the entire process of model creation, deployment, and version updates.Considering the significant costs involved in LLMs training, LLMs providers need to enhance the adaptability of models, especially those that have completed training, in terms of technological innovations and changes in the legal environment.• Both LLMs providers and data providers must adhere to relevant data security usage standards before inputting medical data into model training, including the use of authorization and authentication tools designed to prevent sensitive information leakage, as well as implementing filtering or encryption measures for medical sensitive data.• Healthcare institutions need to strictly regulate the use of data and provide rigorous training for healthcare professionals to ensure compliance with relevant laws, behavioral norms, and security standards when using medical data on LLMs.</p>
<p>AcknowledgementsThe authors would like to express their gratitude to the School of Data Science at Fudan University for their contribution in creating the Intelligent Medical Consultation System dataset (IMCS-V2), as well as to Alibaba Cloud for providing data storage, download, and task support.Availability of data and materialsThe datasets supporting the conclusions of this study can be found at IMCS-V2-MRG.zip.Prompt Settings related to medical report generated code is placed on https:// github.com/ gamel iu007/ Prompt-for-Medic al-Report.Additionally, the other relevant source code mentioned in this paper can be referred to in the respective papers of the models.FundingThis work was partially supported by the key project of the National Natural Science Foundation under Grant No. 62137001.AbbreviationsGPTGenerative pre-trained transformer; NLP Natural language processing; BERTSUM Bert-based summarization;DeclarationsEthics approval and consent to participate Not applicable.Consent for publicationNot applicable.Competing interestsThe authors declare no competing interests.Publisher's NoteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
A scoping review of consumer needs for cancer information. H S Jo, K Park, S M Jung, Patient Educ Couns. 10272019</p>
<p>Hesse Online health information seeking among US adults: measuring progress toward a healthy people 2020 objective. L J Finney Rutten, K D Blake, A J Greenberg-Worisek, S V Allen, R P Moser, Public Health Rep. 13462019</p>
<p>A survey on medical document summarization. R Jain, A Jangra, S Saha, A Jatowt, arXiv:2212.016692022arXiv preprint</p>
<p>Few-shot fine-tuning SOTA summarization models for medical dialogues. D F Navarro, M Dras, S Berkovsky, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop2022</p>
<p>Virtually perfect? Telemedicine for COVID-19. J E Hollander, B G Carr, N Engl J Med. 382182020</p>
<p>COVID-19 transforms health care through telemedicine: evidence from the field. D M Mann, J Chen, R Chunara, P A Testa, O Nov, J Am Med Inform Assoc. 2772020</p>
<p>Fine-tune BERT for extractive summarization. Y Liu, arXiv:1903.103182019arXiv preprint</p>
<p>Summarizing medical conversations via identifying important utterances. Y Song, Y Tian, N Wang, F Xia, Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational Linguistics2020</p>
<p>Generating SOAP notes from doctor-patient conversations using modular summarization techniques. K Krishna, S Khosla, J P Bigham, Z C Lipton, arXiv:2005.017952020arXiv preprint</p>
<p>fairseq: a fast, extensible toolkit for sequence modeling. M Ott, S Edunov, A Baevski, A Fan, S Gross, N Ng, arXiv:1904.010382019arXiv preprint</p>
<p>Leveraging pretrained models for automatic summarization of doctor-patient conversations. L Zhang, R Negrinho, A Ghosh, V Jagannathan, H R Hassanzadeh, T Schaaf, arXiv:2109.121742021arXiv preprint</p>
<p>MedicalSum: A Guided Clinical Abstractive Summarization Model for Generating Medical Reports from Patient-Doctor Conversations. G Michalopoulos, K Williams, G Singh, T Lin, Findings of the Association for Computational Linguistics: EMNLP 2022. 2022</p>
<p>summarize: Global summarization of medical dialogue by exploiting local structures. A Joshi, N Katariya, X Amatriain, Kannan A Dr, arXiv:2009.086662020arXiv preprint</p>
<p>Joint summarization-entailment optimization for consumer health question understanding. K Mrini, F Dernoncourt, Chang W Farcas, E Nakashole, N , Proceedings of the Second Workshop on Natural Language Processing for Medical Conversations. the Second Workshop on Natural Language Processing for Medical Conversations2021</p>
<p>Pre-training of deep bidirectional transformers for language understanding. J Devlin, M W Chang, K Lee, K Toutanova, Bert, arXiv:1810.048052018arXiv preprint</p>
<p>Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. M Lewis, Y Liu, N Goyal, M Ghazvininejad, Mohamed A Levy, O , arXiv:1910.134612019arXiv preprint</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI Blog. 1892019</p>
<p>Linguistic ambiguity analysis in ChatGPT. M Ortega-Martín, Ó García-Sierra, A Ardoiz, J Álvarez, J C Armenteros, A Alonso, arXiv:2302.064262023arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, Adv Neural Inf Process Syst. 352022</p>
<p>Clinical Note Generation from Doctor-Patient Conversations using Large Language Models: Insights from MEDIQA-Chat. J Giorgi, A Toma, R Xie, S Chen, K R An, G X Zheng, arXiv:2305.022202023arXiv preprint</p>
<p>GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning. X Tang, Tran A Tan, J Gerstein, M , arXiv:2305.050012023arXiv preprint</p>
<p>ImpressionGPT: an iterative optimizing framework for radiology report summarization with chatGPT. C Ma, Z Wu, J Wang, S Xu, Y Wei, Z Liu, arXiv:2304.084482023arXiv preprint</p>
<p>ChatGPT: the future of discharge summaries? Lancet Digit Health. S B Patel, K Lam, 20235</p>
<p>A survey for in-context learning. Q Dong, L Li, D Dai, C Zheng, Z Wu, B Chang, arXiv:2301.002342022arXiv preprint</p>
<p>Attention is All you Need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Advances in Neural Information Processing Systems. Curran Associates, Inc201730</p>
<p>Generating sequences with recurrent neural networks. A Graves, arXiv:1308.08502013arXiv preprint</p>
<p>A robustly optimized bert pretraining approach. Y Liu, M Ott, N Goyal, J Du, M Joshi, D Chen, arXiv:1907.116922019arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, J Mach Learn Res. 2112020</p>
<p>DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. V Sanh, L Debut, J Chaumond, T Wolf, arXiv:1910.011082019arXiv preprint</p>
<p>Mobilebert: a compact taskagnostic bert for resource-limited devices. Z Sun, H Yu, X Song, R Liu, Y Yang, D Zhou, arXiv:2004.029842020arXiv preprint</p>
<p>Enhanced language representation with informative entities. Z Zhang, X Han, Z Liu, X Jiang, M Sun, Q Liu, Ernie, arXiv:1905.071292019arXiv preprint</p>
<p>Discriminative marginalized probabilistic neural method for multi-document summarization of medical literature. G Moro, L Ragazzi, L Valgimigli, D Freddi, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics20221</p>
<p>Globalizing BERT-based transformer architectures for long document summarization. Q Grail, J Perez, E Gaussier, Proceedings of the 16th conference of the European chapter of the Association for Computational Linguistics: Main volume. the 16th conference of the European chapter of the Association for Computational Linguistics: Main volume2021</p>
<p>Automatic text summarization of covid-19 medical research articles using bert and gpt-2. V Kieuvongngam, B Tan, Y Niu, arXiv:2006.019972020arXiv preprint</p>
<p>Attention-based clinical note summarization. N Kanwal, G Rizzo, 10.1145/3477314.3507256Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing. the 37th ACM/SIGAPP Symposium on Applied Computing20223507256</p>
<p>Ms2: Multi-document summarization of medical studies. J Deyoung, I Beltagy, M Van Zuylen, B Kuehl, L L Wang, arXiv:2104.064862021arXiv preprint</p>
<p>Biomedical text summarization: a graphbased ranking approach. S Gupta, A Sharaff, N K Nagwani, Applied Information Processing Systems: Proceedings of ICCET 2021. Springer2022</p>
<p>Proximal policy optimization algorithms. J Schulman, F Wolski, P Dhariwal, A Radford, O Klimov, arXiv:1707.063472017arXiv preprint</p>
<p>The role of ChatGPT in data science: how ai-assisted conversational interfaces are revolutionizing the field. H Hassani, E S Silva, Big Data Cogn Comput. 72622023</p>
<p>ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing. B D Lund, T Wang, N R Mannuru, B Nie, S Shimray, Z Wang, J Assoc Inf Sci Technol. 7452023</p>
<p>ChatGPT: Fundamentals, applications and social impacts. M Abdullah, A Madain, Y Jararweh, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS). IEEE2022</p>
<p>Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. D Baidoo-Anu, Owusu Ansah, L , J AI. 712023</p>
<p>Is ChatGPT a good translator? A preliminary study. W Jiao, W Wang, Huang Jt, X Wang, Z Tu, arXiv:2301.087452023arXiv preprint</p>
<p>Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. M Cascella, J Montomoli, V Bellini, E Bignami, J Med Syst. 471332023</p>
<p>ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations. T Dave, S A Athaluri, S Singh, Front Artif Intell. 611695952023</p>
<p>The potential impact of ChatGPT in clinical and translational medicine. V W Xue, P Lei, W C Cho, 10.1002/ctm2.1216Clin Transl Med. 1332023</p>
<p>Potential use cases for ChatGPT in radiology reporting. A A Elkassem, A D Smith, 10.2214/AJR.23.29198Am J Roentgenol. 2023</p>
<p>Summarizing, simplifying, and synthesizing medical evidence using gpt-3 (with varying success). C Shaib, M L Li, S Joseph, I J Marshall, J J Li, B C Wallace, arXiv:2305.062992023arXiv preprint</p>
<p>Summary of ChatGPT-Related research and perspective towards the future of large language models. Y Liu, T Han, S Ma, J Zhang, Y Yang, J Tian, arXiv:2304.018522023arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. C Y Lin, Text summarization branches out. BarcelonaAssociation for Computational Linguistics2004</p>
<p>Bertscore: evaluating text generation with bert. T Zhang, V Kishore, F Wu, K Q Weinberger, Y Artzi, arXiv:1904.096752019arXiv preprint</p>
<p>Do ChatGPT and other AI chatbots pose a cybersecurity risk?: An exploratory study. G Sebastian, Int J Secur Priv Pervasive Comput. 1512023</p>
<p>Multi-step jailbreaking privacy attacks on chatgpt. H Li, D Guo, Fan W Xu, M Song, Y , arXiv:2304.051972023arXiv preprint</p>
<p>From ChatGPT to HackGPT: Meeting the Cybersecurity Threat of Generative AI. K Renaud, M Warkentin, G Westerman, 2023MIT Sloan Management Review</p>
<p>The challenges for regulating medical use of ChatGPT and other large language models. T Minssen, E Vayena, I G Cohen, 10.1001/jama.2023.9651JAMA. 2023</p>            </div>
        </div>

    </div>
</body>
</html>