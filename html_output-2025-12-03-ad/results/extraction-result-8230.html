<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8230 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8230</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8230</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-269149341</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2404.09982v2.pdf" target="_blank">Memory Sharing for Large Language Model based Agents</a></p>
                <p><strong>Paper Abstract:</strong> The adaptation of Large Language Model (LLM)-based agents to execute tasks via natural language prompts represents a significant advancement, notably eliminating the need for explicit retraining or fine tuning, but are constrained by the comprehensiveness and diversity of the provided examples, leading to outputs that often diverge significantly from expected results, especially when it comes to the open-ended questions. This paper introduces the Memory Sharing, a framework which integrates the real-time memory filter, storage and retrieval to enhance the In-Context Learning process. This framework allows for the sharing of memories among multiple agents, whereby the interactions and shared memories between different agents effectively enhance the diversity of the memories. The collective self-enhancement through interactive learning among multiple agents facilitates the evolution from individual intelligence to collective intelligence. Besides, the dynamically growing memory pool is utilized not only to improve the quality of responses but also to train and enhance the retriever. We evaluated our framework across three distinct domains involving specialized tasks of agents. The experimental results demonstrate that the MS framework significantly improves the agents' performance in addressing open-ended questions.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8230.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8230.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory Sharing framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that enables multiple LLM-based agents to share Promptâ€“Answer (PA) pairs as memories in a real-time growing shared pool, with LLM-based scoring and continuous retriever training to support retrieval-augmented in-context learning (ICL).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Memory Sharing framework (system-level entity)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>System-level multi-agent framework coordinating agents that write PA pairs into and retrieve PA pairs from a shared memory pool; includes an LLM-based scorer and a continuously trained dense retriever.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>evaluated with gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Three backbone LLMs used as agent backbones in experiments: two closed-source (gpt-3.5-turbo, gpt-4o) and one open-source (open-mistral-7b).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Open-ended content generation, unconventional logic problem solving, and plan generation across 9 agents</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents receive free-form queries (poetry prompts, puzzles, planning prompts) and produce open-ended answers; performance measured with BERTScore against standard answers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended generation / creative generation / problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented shared external memory (PA-pair memory pool)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>PA pairs (Prompt, Answer) are stored in natural language in a shared pool after being scored by an LLM evaluator; a dense retriever (semantic embeddings + cosine similarity) retrieves relevant memories which are concatenated with the query to form ICL prompts; every newly accepted memory is also used to continue training the retriever via BM25 candidate selection and LLM-based labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Prompt-Answer (PA) pairs in natural language (each memory = the prompt used and the answer produced).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval (cosine similarity on embeddings) to get top-k memories; retrieved memories concatenated with query for in-context examples (one-/few-shot concatenation). Retriever is continuously updated using newly added memories and BM25-selected candidate examples labeled by an LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reported improvements across tasks when using retrieved memories; example aggregated three-shot BERTScore (Domain-pool) per agent/backbone shown in Table 1 (e.g., Agent-Limerick gpt-3.5-turbo: 0.87, Agent-Sonnet gpt-3.5-turbo: 0.53, Agent-Puzzle gpt-3.5-turbo: 0.60). Full per-agent per-backbone numbers available in the paper Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Compared zero-/one-/two-/three-shot retrieval (three-shot typically best); compared Domain-pool (domain-specific memory pool) vs Single-pool (cross-domain unified pool) showing Domain-pool often better (Table 2); evaluated incremental addition of memories (20%,40%,60%,80%,100%) showing performance generally increases as more high-quality memories are added (Figure 4).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared, dynamically growing PA-pair memory pools improve LLM-agent performance on open-ended questions; continuous retriever training with newly added memories helps retrieval quality; three-shot retrieval yielded best performance for most agents; domain-specific pools often outperform a unified cross-domain pool.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Initial cold-start requires seeding the pool with a small set of PA pairs; memory entries created from single interactions may miss preparatory/unrelated context; cross-domain pooled memories can hurt some agents; language/style heterogeneity in stored memories can reduce benefit for some creative domains; experimental metrics limited to BERTScore and specific datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8230.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Limerick</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Limerick (Literary Creation - Limericks generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent specialized to generate Limericks (short humorous poems) evaluated under the MS framework using retrieval of PA memories to improve generation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Limerick</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A domain-specialized LLM agent that composes Limericks in response to descriptive prompts; part of the Literary Creation domain trio.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs used for this agent: gpt-3.5-turbo and gpt-4o (closed-source), open-mistral-7b (open-source).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Limerick generation (Literary Creation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Compose a Limerick that satisfies a multi-sentence description; judged against a standard target poetic answer.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended creative generation (poetry)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external retrieval-augmented PA memory pool (domain-specific Domain-pool or global Single-pool)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retrieve up to k PA pairs from the shared pool (three-shot retrieval typically used), concatenate them with the query to form the prompt; new PA pairs scored and stored if above threshold; retriever continuously updated with newly added memories.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs (prompts describing poetic requirements and example poems/answers).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval (cosine similarity over embeddings) to select relevant PA pairs; prompt concatenation (few-shot ICL).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.87; gpt-4o 0.59; open-mistral-7b 0.93 (Table 1, Domain-pool row). Single-pool three-shot BERTScore: gpt-3.5-turbo 0.60; gpt-4o 0.54; open-mistral-7b 0.64.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Performance compared across zero/one/two/three-shot retrieval (three-shot best); Domain-pool vs Single-pool: Domain-pool produced higher scores for Limerick (Table 2); increasing amount of stored memories improved performance most noticeably for Limerick (Figure 4).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Limerick agent benefits strongly from domain-specific shared memories; more high-quality memories yield better BERTScore; three retrieved examples was typically optimal.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Potential stylistic heterogeneity in pooled memories (different language/register) can affect gains; observed stagnation when newly added memories are not more suitable than existing examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8230.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Wuyanlvshi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Wuyanlvshi (Literary Creation - classical Chinese poetry generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent specialized to generate Wuyanlvshi (a classical Chinese poetry form), leveraging shared PA memories to improve creative outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Wuyanlvshi</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates Wuyanlvshi poems (classical Chinese five-line forms) from descriptive prompts; part of the Literary Creation domain.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same three backbones evaluated for this agent.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Wuyanlvshi generation (Literary Creation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Produce a Wuyanlvshi-style poem satisfying a description; evaluated by BERTScore against curated target poems.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended creative generation (poetry, classical form)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented shared PA pool (domain-specific or global)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retrieve relevant PA pairs as few-shot examples, concatenated with query; PA pairs are filtered by an LLM scorer and stored if above threshold; retriever is continually trained on newly added memories.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are classical-style poems.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval and prompt concatenation; retriever training uses BM25 + LLM-based labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.72; gpt-4o 0.76; open-mistral-7b 0.66. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.68; gpt-4o 0.76; open-mistral-7b 0.63.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Domain-pool vs Single-pool: mixed results (gpt-4o equal for both pools); three-shot retrieval gave best overall results; incremental memory addition improved performance but less dramatically than for some other agents.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared memories help improve outputs for this creative, language-specific agent; closed-source gpt-4o performed competitively; language/register differences in memory storage may limit cross-agent transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Stylistic/language mismatches in shared memories can reduce usefulness; smaller incremental gains observed vs other domains, indicating sensitivity to memory format.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8230.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Sonnet (Literary Creation - Sonnet generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent that composes sonnets; demonstrates how retrieved PA memories (poems and related Q/A) are concatenated to produce higher-quality sonnets via ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Specialized agent creating sonnets from descriptive prompts; illustrated in the paper with concrete memory examples showing prompt construction from retrieved PA pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs used as agent engines.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Sonnet composition (Literary Creation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Compose a sonnet following a multi-part descriptive prompt; evaluated against a canonical sonnet via BERTScore.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended creative generation (poetry, sonnet)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external PA-pair memory pool retrieved for few-shot ICL</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retriever fetches example PA pairs (poem prompts and answers) which are concatenated to the query; newly generated PA pairs are scored and added to pool, and used to continue training the retriever.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Prompt-Answer pairs where answers are sonnets or related poetic content.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Semantic dense retrieval + prompt concatenation; retriever trained continuously with BM25-selected candidates labeled by LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.53; gpt-4o 0.54; open-mistral-7b 0.53. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.49; gpt-4o 0.54; open-mistral-7b 0.52.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval improved performance over fewer shots; Domain-pool vs Single-pool: Domain-pool slightly better for gpt-3.5 and open-mistral; closed-source gpt-4o comparable across pools.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Memory Sharing assisted sonnet generation, and concrete examples show how retrieved PA pairs are composed into one-shot prompts; three retrieved examples commonly optimal.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Relatively modest absolute gains compared to other agents, possibly due to language/style alignment issues in stored memories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8230.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Puzzle</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Puzzle (Unconventional Logic Problem-solving - Puzzle solver)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent that solves unconventional logic puzzles; benefits from retrieval of past Prompt-Answer pairs as exemplars to improve problem comprehension and solution quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Puzzle</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Solves logic puzzles (e.g., riddles, lateral thinking questions) by using retrieved example Q&A pairs to improve reasoning and answer relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Puzzle solving (Unconventional Logic Problem-solving)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a puzzle/problem statement, produce a reasonable solution/explanation; evaluated using BERTScore against harvested standard answers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended reasoning/problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>shared PA memory pool used for retrieval-augmented ICL</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retriever obtains semantically similar PA pairs from shared pool; those are concatenated with the query to form the prompt; high-scoring new PA pairs are stored and used to train the retriever.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are puzzle solutions/explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval (cosine similarity) and prompt concatenation; retriever training uses BM25 to select hard negatives/positives and LLM-based labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.60; gpt-4o 0.52; open-mistral-7b 0.50. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.54; gpt-4o 0.50; open-mistral-7b 0.48.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval outperformed zero/one/two-shot; Domain-pool superior to Single-pool for Puzzle agent; incremental memory addition improved performance across phases.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared domain-specific memories improved problem-solving quality; continuous retriever training and dynamic memory growth are beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Performance gains depend on quality and domain-relevance of stored PA pairs; cross-domain memories are less helpful or harmful.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8230.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Pun</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Pun (Unconventional Logic Problem-solving - Pun generator/solver)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent handling pun/riddle-like items (creative short-answer tasks) that uses shared PA memories to improve answer appropriateness and creativity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Pun</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates or solves pun-style queries; uses retrieved PA examples to guide creative/concise output.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs applied to this agent.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Pun generation/solving (Unconventional Logic Problem-solving)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answer pun or short riddle prompts with apt, often witty responses; evaluated via BERTScore against curated answers.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended creative/problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented PA memory pool</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Few-shot retrieval of PA pairs concatenated with query; PA pairs scored and stored to expand memory; retriever continuously updated.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are puns or short riddle solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense retrieval + prompt concatenation; retriever updated using BM25 candidate selection and LLM scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.70; gpt-4o 0.67; open-mistral-7b 0.39. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.70; gpt-4o 0.61; open-mistral-7b 0.38.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval improved performance; Domain-pool generally outperformed Single-pool for closed models; open-mistral showed weaker performance here.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared domain-specific memories help capture the style/creativity needed for pun answers, improving BERTScore for closed-source models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Open-source model performance notably lower on this subtask; memory quality and domain alignment appear critical for creative short answers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8230.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Riddle</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Riddle (Unconventional Logic Problem-solving - Riddle solver)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent focused on solving riddles; uses retrieved PA examples from shared pool to improve answer correctness and relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Riddle</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Produces answers to riddle-like prompts, leveraging retrieved exemplar Q&A pairs to guide reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs used for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Riddle solving (Unconventional Logic Problem-solving)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a riddle, produce the correct concise answer; compared to a standard solution using BERTScore.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>open-ended reasoning / short-answer question answering</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>shared PA retrieval-augmented memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retrieve PA pairs and include them as few-shot examples; newly generated PA pairs scored and inserted into memory; retriever updated continuously.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are riddle solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval + concatenation; retriever training via BM25 candidate selection and LLM labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.88; gpt-4o 0.52; open-mistral-7b 0.37. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.80; gpt-4o 0.51; open-mistral-7b 0.35.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval consistently helped; Domain-pool showed higher gains for the best-performing backbone (gpt-3.5-turbo).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared memories are especially helpful where concise factual or lateral solutions are required; some backbones benefit more than others.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Open-mistral underperformed on this type; memory pool quality and domain alignment important for correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8230.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Fitness</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Fitness (Plan Generation - Fitness plan generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent that generates fitness plans (procedural plans) and uses shared PA memories to improve plan quality and executability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Fitness</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Produces fitness plans (stepwise actionable routines) from planning prompts; part of the Plan Generation domain trio.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Three LLM backbones used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Fitness plan generation (Plan Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Produce a practical fitness plan given a goal/constraint prompt; evaluated by BERTScore against standard plans.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>plan generation / procedural generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented shared PA pool (domain-specific plan examples)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retrieve example plan PA pairs as few-shot examples concatenated with query; high-quality new PA pairs stored and used for retriever training.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are executable plans (fitness routines).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval + prompt concatenation; retriever continuously trained with new memories via BM25 candidate selection and LLM labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.65; gpt-4o 0.52; open-mistral-7b 0.54. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.62; gpt-4o 0.52; open-mistral-7b 0.54.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval improved plan generation quality; Domain-pool slightly better or similar compared to Single-pool for fitness plans.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Memory Sharing supplies exemplar plans that help agents produce more relevant and executable plans; continuous memory growth is beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Gains sometimes modest; usefulness depends on closeness of retrieved plans to target constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e8230.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Study</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Study (Plan Generation - Study plan generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent that generates study plans; benefits from retrieval of prior prompt-answer exemplars stored in the shared memory pool.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Study</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates actionable study plans (steps, resources, timelines) from high-level learning goals; part of Plan Generation domain.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Study plan generation (Plan Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Produce a study plan tailored to a learning objective; evaluated by BERTScore against standard plans.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>plan generation / procedural generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>shared retrieval-augmented PA memory pool</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Few-shot retrieval of PA pairs combined with query; new high-quality PA pairs added to pool and used for retriever updates.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are study plans and schedules.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense semantic retrieval and prompt concatenation; retriever updated with BM25 + LLM labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.63; gpt-4o 0.51; open-mistral-7b 0.46. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.63; gpt-4o 0.56; open-mistral-7b 0.49.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Study agent was the only one for which Single-pool did not uniformly degrade performance (Table 2); three-shot retrieval generally best.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Shared memories assist in creating practical study plans; cross-domain memory (Single-pool) can sometimes be equally or more helpful depending on the agent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Variability in effect when mixing cross-domain memories; reliance on quality of exemplar plans.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8230.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e8230.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent-Travel</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agent-Travel (Plan Generation - Travel plan generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent producing travel plans and itineraries, using retrieved PA examples from the shared memory pool to improve plan relevance and detail.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Agent-Travel</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates travel itineraries and plans from descriptive prompts; part of the Plan Generation domain trio.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo, gpt-4o, open-mistral-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone LLMs used across experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Travel plan generation (Plan Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given user constraints and goals, produce an executable travel plan; evaluated by BERTScore against standard plans.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>plan generation / procedural generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external shared PA memory pool used for retrieval-augmented ICL</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Retrieve PA exemplars and append to query as few-shot examples; newly accepted PA pairs added to pool and used to further train the retriever.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>PA pairs where answers are travel plans/itineraries.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Dense retrieval with cosine similarity plus prompt concatenation; retriever updated continuously via BM25+LLM labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.71; gpt-4o 0.53; open-mistral-7b 0.53. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.58; gpt-4o 0.52; open-mistral-7b 0.50.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Three-shot retrieval improved travel plan quality; Domain-pool typically more beneficial than Single-pool for travel planning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Domain-specific memories help produce better travel plans; continuous addition of good memories increases performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Cross-domain noise in Single-pool can reduce plan relevance; seeding and memory curation important.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Memory Sharing for Large Language Model based Agents', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>MemGPT: Towards LLMs as Operating Systems <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Ghost in the Minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory <em>(Rating: 2)</em></li>
                <li>Memochat: Tuning LLMs to use memos for consistent long-range open-domain conversation <em>(Rating: 2)</em></li>
                <li>Reflexion: language agents with verbal reinforcement learning <em>(Rating: 2)</em></li>
                <li>Synapse: Trajectory-as-exemplar prompting with memory for computer control <em>(Rating: 2)</em></li>
                <li>Retrieval-Augmented Generation for knowledge-intensive NLP tasks <em>(Rating: 1)</em></li>
                <li>Learning to retrieve prompts for in-context learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8230",
    "paper_id": "paper-269149341",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [
        {
            "name_short": "MS",
            "name_full": "Memory Sharing framework",
            "brief_description": "A framework that enables multiple LLM-based agents to share Promptâ€“Answer (PA) pairs as memories in a real-time growing shared pool, with LLM-based scoring and continuous retriever training to support retrieval-augmented in-context learning (ICL).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Memory Sharing framework (system-level entity)",
            "agent_description": "System-level multi-agent framework coordinating agents that write PA pairs into and retrieve PA pairs from a shared memory pool; includes an LLM-based scorer and a continuously trained dense retriever.",
            "model_name": "evaluated with gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Three backbone LLMs used as agent backbones in experiments: two closed-source (gpt-3.5-turbo, gpt-4o) and one open-source (open-mistral-7b).",
            "task_name": "Open-ended content generation, unconventional logic problem solving, and plan generation across 9 agents",
            "task_description": "Agents receive free-form queries (poetry prompts, puzzles, planning prompts) and produce open-ended answers; performance measured with BERTScore against standard answers.",
            "task_type": "open-ended generation / creative generation / problem solving",
            "memory_used": true,
            "memory_type": "retrieval-augmented shared external memory (PA-pair memory pool)",
            "memory_mechanism": "PA pairs (Prompt, Answer) are stored in natural language in a shared pool after being scored by an LLM evaluator; a dense retriever (semantic embeddings + cosine similarity) retrieves relevant memories which are concatenated with the query to form ICL prompts; every newly accepted memory is also used to continue training the retriever via BM25 candidate selection and LLM-based labeling.",
            "memory_representation": "Prompt-Answer (PA) pairs in natural language (each memory = the prompt used and the answer produced).",
            "memory_retrieval_method": "Dense semantic retrieval (cosine similarity on embeddings) to get top-k memories; retrieved memories concatenated with query for in-context examples (one-/few-shot concatenation). Retriever is continuously updated using newly added memories and BM25-selected candidate examples labeled by an LLM.",
            "performance_with_memory": "Reported improvements across tasks when using retrieved memories; example aggregated three-shot BERTScore (Domain-pool) per agent/backbone shown in Table 1 (e.g., Agent-Limerick gpt-3.5-turbo: 0.87, Agent-Sonnet gpt-3.5-turbo: 0.53, Agent-Puzzle gpt-3.5-turbo: 0.60). Full per-agent per-backbone numbers available in the paper Table 1.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Compared zero-/one-/two-/three-shot retrieval (three-shot typically best); compared Domain-pool (domain-specific memory pool) vs Single-pool (cross-domain unified pool) showing Domain-pool often better (Table 2); evaluated incremental addition of memories (20%,40%,60%,80%,100%) showing performance generally increases as more high-quality memories are added (Figure 4).",
            "key_findings": "Shared, dynamically growing PA-pair memory pools improve LLM-agent performance on open-ended questions; continuous retriever training with newly added memories helps retrieval quality; three-shot retrieval yielded best performance for most agents; domain-specific pools often outperform a unified cross-domain pool.",
            "limitations_or_challenges": "Initial cold-start requires seeding the pool with a small set of PA pairs; memory entries created from single interactions may miss preparatory/unrelated context; cross-domain pooled memories can hurt some agents; language/style heterogeneity in stored memories can reduce benefit for some creative domains; experimental metrics limited to BERTScore and specific datasets.",
            "uuid": "e8230.0",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Limerick",
            "name_full": "Agent-Limerick (Literary Creation - Limericks generator)",
            "brief_description": "An agent specialized to generate Limericks (short humorous poems) evaluated under the MS framework using retrieval of PA memories to improve generation quality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Limerick",
            "agent_description": "A domain-specialized LLM agent that composes Limericks in response to descriptive prompts; part of the Literary Creation domain trio.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs used for this agent: gpt-3.5-turbo and gpt-4o (closed-source), open-mistral-7b (open-source).",
            "task_name": "Limerick generation (Literary Creation)",
            "task_description": "Compose a Limerick that satisfies a multi-sentence description; judged against a standard target poetic answer.",
            "task_type": "open-ended creative generation (poetry)",
            "memory_used": true,
            "memory_type": "external retrieval-augmented PA memory pool (domain-specific Domain-pool or global Single-pool)",
            "memory_mechanism": "Retrieve up to k PA pairs from the shared pool (three-shot retrieval typically used), concatenate them with the query to form the prompt; new PA pairs scored and stored if above threshold; retriever continuously updated with newly added memories.",
            "memory_representation": "PA pairs (prompts describing poetic requirements and example poems/answers).",
            "memory_retrieval_method": "Dense semantic retrieval (cosine similarity over embeddings) to select relevant PA pairs; prompt concatenation (few-shot ICL).",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.87; gpt-4o 0.59; open-mistral-7b 0.93 (Table 1, Domain-pool row). Single-pool three-shot BERTScore: gpt-3.5-turbo 0.60; gpt-4o 0.54; open-mistral-7b 0.64.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Performance compared across zero/one/two/three-shot retrieval (three-shot best); Domain-pool vs Single-pool: Domain-pool produced higher scores for Limerick (Table 2); increasing amount of stored memories improved performance most noticeably for Limerick (Figure 4).",
            "key_findings": "Limerick agent benefits strongly from domain-specific shared memories; more high-quality memories yield better BERTScore; three retrieved examples was typically optimal.",
            "limitations_or_challenges": "Potential stylistic heterogeneity in pooled memories (different language/register) can affect gains; observed stagnation when newly added memories are not more suitable than existing examples.",
            "uuid": "e8230.1",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Wuyanlvshi",
            "name_full": "Agent-Wuyanlvshi (Literary Creation - classical Chinese poetry generator)",
            "brief_description": "An agent specialized to generate Wuyanlvshi (a classical Chinese poetry form), leveraging shared PA memories to improve creative outputs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Wuyanlvshi",
            "agent_description": "Generates Wuyanlvshi poems (classical Chinese five-line forms) from descriptive prompts; part of the Literary Creation domain.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Same three backbones evaluated for this agent.",
            "task_name": "Wuyanlvshi generation (Literary Creation)",
            "task_description": "Produce a Wuyanlvshi-style poem satisfying a description; evaluated by BERTScore against curated target poems.",
            "task_type": "open-ended creative generation (poetry, classical form)",
            "memory_used": true,
            "memory_type": "retrieval-augmented shared PA pool (domain-specific or global)",
            "memory_mechanism": "Retrieve relevant PA pairs as few-shot examples, concatenated with query; PA pairs are filtered by an LLM scorer and stored if above threshold; retriever is continually trained on newly added memories.",
            "memory_representation": "PA pairs where answers are classical-style poems.",
            "memory_retrieval_method": "Dense semantic retrieval and prompt concatenation; retriever training uses BM25 + LLM-based labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.72; gpt-4o 0.76; open-mistral-7b 0.66. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.68; gpt-4o 0.76; open-mistral-7b 0.63.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Domain-pool vs Single-pool: mixed results (gpt-4o equal for both pools); three-shot retrieval gave best overall results; incremental memory addition improved performance but less dramatically than for some other agents.",
            "key_findings": "Shared memories help improve outputs for this creative, language-specific agent; closed-source gpt-4o performed competitively; language/register differences in memory storage may limit cross-agent transfer.",
            "limitations_or_challenges": "Stylistic/language mismatches in shared memories can reduce usefulness; smaller incremental gains observed vs other domains, indicating sensitivity to memory format.",
            "uuid": "e8230.2",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Sonnet",
            "name_full": "Agent-Sonnet (Literary Creation - Sonnet generator)",
            "brief_description": "An agent that composes sonnets; demonstrates how retrieved PA memories (poems and related Q/A) are concatenated to produce higher-quality sonnets via ICL.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Sonnet",
            "agent_description": "Specialized agent creating sonnets from descriptive prompts; illustrated in the paper with concrete memory examples showing prompt construction from retrieved PA pairs.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs used as agent engines.",
            "task_name": "Sonnet composition (Literary Creation)",
            "task_description": "Compose a sonnet following a multi-part descriptive prompt; evaluated against a canonical sonnet via BERTScore.",
            "task_type": "open-ended creative generation (poetry, sonnet)",
            "memory_used": true,
            "memory_type": "external PA-pair memory pool retrieved for few-shot ICL",
            "memory_mechanism": "Retriever fetches example PA pairs (poem prompts and answers) which are concatenated to the query; newly generated PA pairs are scored and added to pool, and used to continue training the retriever.",
            "memory_representation": "Prompt-Answer pairs where answers are sonnets or related poetic content.",
            "memory_retrieval_method": "Semantic dense retrieval + prompt concatenation; retriever trained continuously with BM25-selected candidates labeled by LLM.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.53; gpt-4o 0.54; open-mistral-7b 0.53. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.49; gpt-4o 0.54; open-mistral-7b 0.52.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval improved performance over fewer shots; Domain-pool vs Single-pool: Domain-pool slightly better for gpt-3.5 and open-mistral; closed-source gpt-4o comparable across pools.",
            "key_findings": "Memory Sharing assisted sonnet generation, and concrete examples show how retrieved PA pairs are composed into one-shot prompts; three retrieved examples commonly optimal.",
            "limitations_or_challenges": "Relatively modest absolute gains compared to other agents, possibly due to language/style alignment issues in stored memories.",
            "uuid": "e8230.3",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Puzzle",
            "name_full": "Agent-Puzzle (Unconventional Logic Problem-solving - Puzzle solver)",
            "brief_description": "An agent that solves unconventional logic puzzles; benefits from retrieval of past Prompt-Answer pairs as exemplars to improve problem comprehension and solution quality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Puzzle",
            "agent_description": "Solves logic puzzles (e.g., riddles, lateral thinking questions) by using retrieved example Q&A pairs to improve reasoning and answer relevance.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs used in experiments.",
            "task_name": "Puzzle solving (Unconventional Logic Problem-solving)",
            "task_description": "Given a puzzle/problem statement, produce a reasonable solution/explanation; evaluated using BERTScore against harvested standard answers.",
            "task_type": "open-ended reasoning/problem solving",
            "memory_used": true,
            "memory_type": "shared PA memory pool used for retrieval-augmented ICL",
            "memory_mechanism": "Retriever obtains semantically similar PA pairs from shared pool; those are concatenated with the query to form the prompt; high-scoring new PA pairs are stored and used to train the retriever.",
            "memory_representation": "PA pairs where answers are puzzle solutions/explanations.",
            "memory_retrieval_method": "Dense semantic retrieval (cosine similarity) and prompt concatenation; retriever training uses BM25 to select hard negatives/positives and LLM-based labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.60; gpt-4o 0.52; open-mistral-7b 0.50. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.54; gpt-4o 0.50; open-mistral-7b 0.48.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval outperformed zero/one/two-shot; Domain-pool superior to Single-pool for Puzzle agent; incremental memory addition improved performance across phases.",
            "key_findings": "Shared domain-specific memories improved problem-solving quality; continuous retriever training and dynamic memory growth are beneficial.",
            "limitations_or_challenges": "Performance gains depend on quality and domain-relevance of stored PA pairs; cross-domain memories are less helpful or harmful.",
            "uuid": "e8230.4",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Pun",
            "name_full": "Agent-Pun (Unconventional Logic Problem-solving - Pun generator/solver)",
            "brief_description": "An agent handling pun/riddle-like items (creative short-answer tasks) that uses shared PA memories to improve answer appropriateness and creativity.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Pun",
            "agent_description": "Generates or solves pun-style queries; uses retrieved PA examples to guide creative/concise output.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs applied to this agent.",
            "task_name": "Pun generation/solving (Unconventional Logic Problem-solving)",
            "task_description": "Answer pun or short riddle prompts with apt, often witty responses; evaluated via BERTScore against curated answers.",
            "task_type": "open-ended creative/problem solving",
            "memory_used": true,
            "memory_type": "retrieval-augmented PA memory pool",
            "memory_mechanism": "Few-shot retrieval of PA pairs concatenated with query; PA pairs scored and stored to expand memory; retriever continuously updated.",
            "memory_representation": "PA pairs where answers are puns or short riddle solutions.",
            "memory_retrieval_method": "Dense retrieval + prompt concatenation; retriever updated using BM25 candidate selection and LLM scoring.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.70; gpt-4o 0.67; open-mistral-7b 0.39. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.70; gpt-4o 0.61; open-mistral-7b 0.38.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval improved performance; Domain-pool generally outperformed Single-pool for closed models; open-mistral showed weaker performance here.",
            "key_findings": "Shared domain-specific memories help capture the style/creativity needed for pun answers, improving BERTScore for closed-source models.",
            "limitations_or_challenges": "Open-source model performance notably lower on this subtask; memory quality and domain alignment appear critical for creative short answers.",
            "uuid": "e8230.5",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Riddle",
            "name_full": "Agent-Riddle (Unconventional Logic Problem-solving - Riddle solver)",
            "brief_description": "An agent focused on solving riddles; uses retrieved PA examples from shared pool to improve answer correctness and relevance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Riddle",
            "agent_description": "Produces answers to riddle-like prompts, leveraging retrieved exemplar Q&A pairs to guide reasoning.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs used for evaluation.",
            "task_name": "Riddle solving (Unconventional Logic Problem-solving)",
            "task_description": "Given a riddle, produce the correct concise answer; compared to a standard solution using BERTScore.",
            "task_type": "open-ended reasoning / short-answer question answering",
            "memory_used": true,
            "memory_type": "shared PA retrieval-augmented memory",
            "memory_mechanism": "Retrieve PA pairs and include them as few-shot examples; newly generated PA pairs scored and inserted into memory; retriever updated continuously.",
            "memory_representation": "PA pairs where answers are riddle solutions.",
            "memory_retrieval_method": "Dense semantic retrieval + concatenation; retriever training via BM25 candidate selection and LLM labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.88; gpt-4o 0.52; open-mistral-7b 0.37. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.80; gpt-4o 0.51; open-mistral-7b 0.35.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval consistently helped; Domain-pool showed higher gains for the best-performing backbone (gpt-3.5-turbo).",
            "key_findings": "Shared memories are especially helpful where concise factual or lateral solutions are required; some backbones benefit more than others.",
            "limitations_or_challenges": "Open-mistral underperformed on this type; memory pool quality and domain alignment important for correctness.",
            "uuid": "e8230.6",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Fitness",
            "name_full": "Agent-Fitness (Plan Generation - Fitness plan generator)",
            "brief_description": "An agent that generates fitness plans (procedural plans) and uses shared PA memories to improve plan quality and executability.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Fitness",
            "agent_description": "Produces fitness plans (stepwise actionable routines) from planning prompts; part of the Plan Generation domain trio.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Three LLM backbones used in experiments.",
            "task_name": "Fitness plan generation (Plan Generation)",
            "task_description": "Produce a practical fitness plan given a goal/constraint prompt; evaluated by BERTScore against standard plans.",
            "task_type": "plan generation / procedural generation",
            "memory_used": true,
            "memory_type": "retrieval-augmented shared PA pool (domain-specific plan examples)",
            "memory_mechanism": "Retrieve example plan PA pairs as few-shot examples concatenated with query; high-quality new PA pairs stored and used for retriever training.",
            "memory_representation": "PA pairs where answers are executable plans (fitness routines).",
            "memory_retrieval_method": "Dense semantic retrieval + prompt concatenation; retriever continuously trained with new memories via BM25 candidate selection and LLM labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.65; gpt-4o 0.52; open-mistral-7b 0.54. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.62; gpt-4o 0.52; open-mistral-7b 0.54.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval improved plan generation quality; Domain-pool slightly better or similar compared to Single-pool for fitness plans.",
            "key_findings": "Memory Sharing supplies exemplar plans that help agents produce more relevant and executable plans; continuous memory growth is beneficial.",
            "limitations_or_challenges": "Gains sometimes modest; usefulness depends on closeness of retrieved plans to target constraints.",
            "uuid": "e8230.7",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Study",
            "name_full": "Agent-Study (Plan Generation - Study plan generator)",
            "brief_description": "An agent that generates study plans; benefits from retrieval of prior prompt-answer exemplars stored in the shared memory pool.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Study",
            "agent_description": "Generates actionable study plans (steps, resources, timelines) from high-level learning goals; part of Plan Generation domain.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs in experiments.",
            "task_name": "Study plan generation (Plan Generation)",
            "task_description": "Produce a study plan tailored to a learning objective; evaluated by BERTScore against standard plans.",
            "task_type": "plan generation / procedural generation",
            "memory_used": true,
            "memory_type": "shared retrieval-augmented PA memory pool",
            "memory_mechanism": "Few-shot retrieval of PA pairs combined with query; new high-quality PA pairs added to pool and used for retriever updates.",
            "memory_representation": "PA pairs where answers are study plans and schedules.",
            "memory_retrieval_method": "Dense semantic retrieval and prompt concatenation; retriever updated with BM25 + LLM labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.63; gpt-4o 0.51; open-mistral-7b 0.46. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.63; gpt-4o 0.56; open-mistral-7b 0.49.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Study agent was the only one for which Single-pool did not uniformly degrade performance (Table 2); three-shot retrieval generally best.",
            "key_findings": "Shared memories assist in creating practical study plans; cross-domain memory (Single-pool) can sometimes be equally or more helpful depending on the agent.",
            "limitations_or_challenges": "Variability in effect when mixing cross-domain memories; reliance on quality of exemplar plans.",
            "uuid": "e8230.8",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Agent-Travel",
            "name_full": "Agent-Travel (Plan Generation - Travel plan generator)",
            "brief_description": "An agent producing travel plans and itineraries, using retrieved PA examples from the shared memory pool to improve plan relevance and detail.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Agent-Travel",
            "agent_description": "Generates travel itineraries and plans from descriptive prompts; part of the Plan Generation domain trio.",
            "model_name": "gpt-3.5-turbo, gpt-4o, open-mistral-7b",
            "model_description": "Backbone LLMs used across experiments.",
            "task_name": "Travel plan generation (Plan Generation)",
            "task_description": "Given user constraints and goals, produce an executable travel plan; evaluated by BERTScore against standard plans.",
            "task_type": "plan generation / procedural generation",
            "memory_used": true,
            "memory_type": "external shared PA memory pool used for retrieval-augmented ICL",
            "memory_mechanism": "Retrieve PA exemplars and append to query as few-shot examples; newly accepted PA pairs added to pool and used to further train the retriever.",
            "memory_representation": "PA pairs where answers are travel plans/itineraries.",
            "memory_retrieval_method": "Dense retrieval with cosine similarity plus prompt concatenation; retriever updated continuously via BM25+LLM labeling.",
            "performance_with_memory": "Three-shot Domain-pool BERTScore: gpt-3.5-turbo 0.71; gpt-4o 0.53; open-mistral-7b 0.53. Single-pool three-shot BERTScore: gpt-3.5-turbo 0.58; gpt-4o 0.52; open-mistral-7b 0.50.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "ablation_or_comparison": "Three-shot retrieval improved travel plan quality; Domain-pool typically more beneficial than Single-pool for travel planning.",
            "key_findings": "Domain-specific memories help produce better travel plans; continuous addition of good memories increases performance.",
            "limitations_or_challenges": "Cross-domain noise in Single-pool can reduce plan relevance; seeding and memory curation important.",
            "uuid": "e8230.9",
            "source_info": {
                "paper_title": "Memory Sharing for Large Language Model based Agents",
                "publication_date_yy_mm": "2024-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "MemGPT: Towards LLMs as Operating Systems",
            "rating": 2,
            "sanitized_title": "memgpt_towards_llms_as_operating_systems"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Ghost in the Minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory",
            "rating": 2,
            "sanitized_title": "ghost_in_the_minecraft_generally_capable_agents_for_openworld_environments_via_large_language_models_with_textbased_knowledge_and_memory"
        },
        {
            "paper_title": "Memochat: Tuning LLMs to use memos for consistent long-range open-domain conversation",
            "rating": 2,
            "sanitized_title": "memochat_tuning_llms_to_use_memos_for_consistent_longrange_opendomain_conversation"
        },
        {
            "paper_title": "Reflexion: language agents with verbal reinforcement learning",
            "rating": 2,
            "sanitized_title": "reflexion_language_agents_with_verbal_reinforcement_learning"
        },
        {
            "paper_title": "Synapse: Trajectory-as-exemplar prompting with memory for computer control",
            "rating": 2,
            "sanitized_title": "synapse_trajectoryasexemplar_prompting_with_memory_for_computer_control"
        },
        {
            "paper_title": "Retrieval-Augmented Generation for knowledge-intensive NLP tasks",
            "rating": 1,
            "sanitized_title": "retrievalaugmented_generation_for_knowledgeintensive_nlp_tasks"
        },
        {
            "paper_title": "Learning to retrieve prompts for in-context learning",
            "rating": 1,
            "sanitized_title": "learning_to_retrieve_prompts_for_incontext_learning"
        }
    ],
    "cost": 0.02034225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Memory Sharing for Large Language Model based Agents
5 Jul 2024</p>
<p>Hang Gao h.gao@rutgers.edu 
Department of Computer Science
Rutgers University New Brunswick
NJ, US</p>
<p>Yongfeng Zhang yongfeng.zhang@rutgers.edu 
Department of Computer Science
Rutgers University New Brunswick
NJ, US</p>
<p>Memory Sharing for Large Language Model based Agents
5 Jul 202497F07E6CB38132506F9C4EE357A4448EarXiv:2404.09982v2[cs.CL]
The adaptation of Large Language Model (LLM)-based agents to execute tasks via natural language prompts represents a significant advancement, notably eliminating the need for explicit retraining or fine tuning, but are constrained by the comprehensiveness and diversity of the provided examples, leading to outputs that often diverge significantly from expected results, especially when it comes to the open-ended questions.This paper introduces the Memory Sharing, a framework which integrates the real-time memory filter, storage and retrieval to enhance the In-Context Learning process.This framework allows for the sharing of memories among multiple agents, whereby the interactions and shared memories between different agents effectively enhance the diversity of the memories.The collective self-enhancement through interactive learning among multiple agents facilitates the evolution from individual intelligence to collective intelligence.Besides, the dynamically growing memory pool is utilized not only to improve the quality of responses but also to train and enhance the retriever.We evaluated our framework across three distinct domains involving specialized tasks of agents.The experimental results demonstrate that the MS framework significantly improves the agents' performance in addressing open-ended questions.</p>
<p>Introduction</p>
<p>The emergence of Large Language Models (LLMs) has brought about significant transformations in machine learning and conversational AI, while the advent of In-Context Learning (ICL) (Brown et al., 2020) signifies a more subtle evolution.ICL facilitates dynamic and intuitive interactions between LLMs and users, enabling LLMs to perform tasks using few-shot examples without necessitating any updates to the model parameters.This greatly expands the capabilities of LLM-based agents.</p>
<p>Figure 1: The Memory Sharing framework.Whenever a new Prompt-Answer(PA) pair is generated, it will be considered to be added to the memory pool and train the retriever.</p>
<p>Initially, ICL was introduced to facilitate LLMbased agents in achieving better performance with few-shot examples (Brown et al., 2020), and subsequently extended across various domains (Ahmed and Devanbu, 2022;Izacard et al., 2023).Following this, the proposal of Chain-of-Thought (CoT) prompting significantly augmented the proficiency of LLM-based agents in executing arithmetic tasks (Wei et al., 2022).Building upon this foundation, innovative methodologies such as PAL (Gao et al., 2023) and the integration of LLMs with symbolic solvers (He-Yueya et al., 2023) have been developed to further enhance agent capabilities in tackling reasoning tasks.Recent works has also developed agent which can continuously acquire diverse skills and make novel discoveries (Wang et al., 2023).While as the areas of questions continue to expand, especially for the open-ended questions, aiming to enable the agent to make more desired answers through ICL, it is particularly important to enrich the diversity of examples, since the agents can learn more information from different angle.</p>
<p>By combining Retrieval-Augmented Generation (RAG) (Lewis et al., 2020) with ICL, for a particular question, the number of relevant examples available to agents has increased significantly.And subsequently facilitated more effective generation in open-domain queries (Mao et al., 2021).In recent developments, self-learning techniques have been also integrated with the retrieval mechanism within ICL to refine model performance in text generation tasks, through the retrieval of examples with the most analogous patterns (Rubin et al., 2022;Wang et al., 2024).Although for a certain question, the number of relevant examples available to agents has increased significantly through RAG, it also means that this depends heavily on the quality of the external database at the same time.Sometimes, it is also very likely that a suitable external database for some problems cannot be find.</p>
<p>As consequence, given the diversity of examples needed to help agents better answer the open-ended questions in the ICL and diminishing the dependence on external database, there is a critical need to get continuously generated high quality examples.To further minimize the dependence of LLMbased agents on external data and enhance their performance, this paper introduces the Memory Sharing (MS) framework.The MS framework is designed to enable multiple agents to share memories, where the interaction and shared memories among multiple agents enhance memory diversity.The collective self-enhancement achieved through multi-agent interaction represents a progression from individual intelligence to collective intelligence.Additionally, we have developed an interactive learning method that facilitates rapid growth and dynamic updating of memory through multiagent interactions.Consequently, the diversity and rapid expansion of memory effectively improve the agents' ability to respond to open-ended questions.</p>
<p>Specifically, within the MS framework, the input and output of an agent in a single interaction are conceptualized as a Prompt-Answer (PA) pair, also considered as a memory, and the shared memory pool is composed of memories from different agents.This framework introduces an innovative real-time memory storage and retrieval mechanism, aimed at enhancing the shared memory pool by receiving PA pairs from different agents.During the storage phase, each PA pair undergoes rigorous evaluation by a dedicated LLM evaluator to determine its suitability for inclusion in the memory pool.The newly added memories then serve as references for the agents' subsequent performance.The retrieval phase is coordinated by an autonomous learning retriever, calibrated to ensure the inclusion of particularly relevant memories in prompts, thereby enhancing the agents' understanding of the query's essence.Figure .1 illustrates the MS framework.Similar to human self-learning mechanisms, incorporating self-generated memories into prompts significantly improves the agents' comprehension of query meanings.Moreover, continuously adding new memories to the pool not only enriches it but also refines the retriever's performance in selecting relevant memories.Our empirical evidence demonstrates that this approach greatly assists LLM-based agents in generating outputs that better align with user expectations.</p>
<p>We evaluate the MS framework through three divergent domains where each domain involved the participation of three agents, and our finding suggests that incremental additions to the memory pool have led to enhancements in the precision and relevance of outputs.This research delineates the MS framework's capacity to mitigate the inherent constraints associated with ICL, thereby underscoring its potential applicability and effectiveness.</p>
<p>Overall, our main contributions can be summarized as follows:</p>
<ol>
<li>
<p>Constructing PA pairs from the answers generated by multiple agents and storing them as "memories" in shared memory pool.The diversity of group memories from different agents, along with the real-time dynamic growth of memories, significantly aids in improving the subsequent behavior of the agents.Additionally, the shared memories in the memory pool are used to enhance the performance of the retriever.</p>
</li>
<li>
<p>Addressing the problem of memory scarcity (data scarcity) by proposing an interactive learning method that allows different agents to rapidly grow their memories through interactive prompt and answer, thereby achieving collective enhancement quickly.</p>
</li>
<li>
<p>Conducting extensive experiments on various types of open-ended tasks to verify the effectiveness of the proposed MS framework.The experimental results show that MS not only help the agents get more expected answers, but also continuously input high quality memories into the memory pool and establish a reliable database for agents.</p>
</li>
</ol>
<p>In the following, Section 2 delineates relevant works.An exhaustive elucidation of the MS framework, inclusive of its conceptual underpinnings and operational methodologies, is presented in Section 3. Section 4 provides empirical validation of the framework's enhanced capability to address openended questions.The conclusion, presented in the Section 5, not only summarizes the findings but also explores prospective avenues for future development of the MS framework, which may better help improve the LLM-based agents.</p>
<p>Related Work</p>
<p>The Memory Mechanism in Agents</p>
<p>Equipping agents with memory mechanisms to enhance their abilities has attracted the attention of researchers.Memory can play an important role in helping agents remember conversation information, maintain behavioral consistency, and accumulate experience.Generative agents enhanced with memory features can store vast experience records, facilitating deeper self understanding (Park et al., 2023), while VOYAGER has developed a skill library that evolves by incorporating successful action programs, optimizing task resolution (Wang et al., 2023).In the case of Ghost in the Minecraft, a text-based memory system supports LLMs in maintaining reference plans for efficient plan formulation when similar objectives arise (Zhu et al., 2023).Later, based on the concept of "memorizationretrieval-response", Memochat was proposed for maintaining consistent long-range open-domain conversation (Lu et al., 2023).With the emergence of MemGPT (Packer et al., 2023), a new memory hierarchy was developed to process long texts and maintain the long-term memory.And the TiM make LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream to a reality (Liu et al., 2023a).Also, through maintain agents' own reflective text in an episodic memory buffer and implementing the exemplar memory, the Reflexion (Shinn et al., 2023) and SYNAPSE (Zheng et al., 2023) successfully induce better decision-making and generalize successful trajectories to new task respectively.Our MS framework is primarily designed to enable multiple agents to share memories, facilitating collective self-enhancement through inter-agent interactions.In previously mentioned agents equipped with memory mechanisms, the memory mainly ensures conversational consistency and stores past experiences to achieve individual enhancement.However, our MS framework achieves collective enhancement through shared memories, providing a pathway for the evolution from individual intelligence to collective intelligence.</p>
<p>In-Context Learning</p>
<p>ICL enhances the problem-solving capabilities of LLMs by incorporating few-shot examples into prompts (Brown et al., 2020;Levine et al., 2021;Zhou et al., 2022;Liu et al., 2023b;White et al., 2023).Research has demonstrated that ICL can foster creative learning in LLMs to a certain extent (Swanson et al., 2021).By redesigning inputs, LLMs become more adept at handling logical challenges (Wiegreffe et al., 2022;Wu et al., 2022).Crowdsourced instructions also contribute to improved performance in LLMs (Mishra et al., 2022).Additionally, elucidating the relationship between examples and tasks has been shown to be highly beneficial for LLMs (Lampinen et al., 2022), while the CoT (Wei et al., 2022) and PAL (Gao et al., 2023), enhance LLMs' performance in complex reasoning tasks by introducing intermediate reasoning steps.However, when dealing with openended questions, agents still face two primary challenges: insufficient problem descriptions, which impair the agents' comprehension, and the lack of external knowledge bases and available reference materials.Our MS framework addresses these challenges by converting high-quality content generated by various LLM-based agents into shared memories, providing agents with useful reference examples, thereby improving their performance in open-ended questions.</p>
<p>Retrieval Augmented Generation</p>
<p>RAG (Lewis et al., 2020;Ram et al., 2023;Shi et al., 2023) is a method that enhances LLMs' ability to generate accurate and timely content by integrating retrieval techniques such as BM25 (Luo et al., 2023;Liu et al., 2022) or SBERT (Reimers and Gurevych, 2019).Using dense retrievers combined with contrastive learning for feedback can effectively enhance the performance (Rubin et al., 2022).Furthermore, iteratively training the retriever with contrastive learning can further improve its performance (Wang et al., 2024).However, the retrievers in the aforementioned studies are typically trained only once before deployment, making it challenging to adapt to newly generated data.In contrast, the retriever in our MS framework undergoes continuous training.Whenever new memories are added to the memory pool, they are used for further training of the retriever.This continuous updating and evolution process ensures that the quality of the retrieved memories gradually improves over time.And most importantly, with the help of MS framework, the dependence on external databases has been greatly reduced.1) + (2) The retriever take the original query from agent as the input, retrieve the suitable memories from the memory pool and concatenate them to the query to form the prompt.</p>
<p>(3) The Agent (Sonnet) takes the prompt and makes an answer, pack them as (Prompt, Answer).( 4) Scorer generates a score according to the designed rubric for (Prompt, Answer), while (Prompt, Answer) pairs with high scores will be added into the Memory Pool and also be sent to train the Retriever.</p>
<p>All agents share the same Memory Pool; they can write memories into the pool and retrieve memories from the pool so that they can share memories with each other.</p>
<p>The Memory Sharing framework</p>
<p>In this section, we provide an in-depth description of our innovative Memory Sharing (MS) framework.MS is a framework designed to enhance the performance of multiple LLM-based agents through shared memories, while preserving the original creativity and versatility of the agents.Fig. 2 show how an agent work within the MS framework.Different agents interact through a Prompt-Answer format, where the results of these interactions are evaluated.High-quality interactions are transformed into memories and stored in a shared memory pool accessible by all agents.</p>
<p>Additionally, new memories are used to train and improve the memory retriever.During subsequent interactions, these stored memories are retrieved to enhance the performance of agents.The underlying idea is intuitive: it represents a crucial step from individual intelligence towards a more powerful collective intelligence.Similar to a group of individuals engaging in prompt and answer interactions, the valuable content is recorded and shared, serving as a reference for future questions.Consequently, after several rounds of interactions, the quality of answers to related questions typically improves.This collective memory-sharing mechanism, enriched by the diversity of memories contributed by different agents, provides more effective assistance in addressing open-ended questions.The main principles and technologies of the MS framework are detailed in three sections below.</p>
<p>Memory Generation</p>
<p>A memory is essentially a Prompt-Answer (PA) pair.In some special cases, it is permissible for a PA pair to lack a prompt, typically applicable in initial scenarios.These PA pairs are stored in natural language, which serves as the shared memories.</p>
<p>On one hand, these shared memories can be used to improve the response quality of different agents; on the other hand, they are generated by various agents and stored in the shared memory pool.The dynamic expansion of the shared memory pool ensures a continuous influx of new memories, thereby enriching the knowledge base of all agents.In addressing open-ended questions, these shared memories provide agents with a broader perspective and deeper understanding, which is crucial for generating high quality answers.Fig. 3 shows how the Agent-Puzzle use the memory to make a prompt and get the answer through one-shot learning.</p>
<p>After each interaction, the PA pair is scored.If the score of PA pair exceeds a preset threshold, the answer and its corresponding prompt are packaged as a useful memory and stored in the memory.When scoring the answers, we established different scoring criteria for various domains and topics, delegating the scoring tasks to the LLM itself.To facilitate the LLM's understanding of these criteria, they were autonomously generated by the LLM, She walked out of the elevator door on the sixth floor and never came back, why?What comes once in a minute, twice in a moment, but never in a thousand years?-&gt;The letter m.</p>
<p>What comes once in a minute, twice in a moment, but never in a thousand years?-&gt;The letter m.Now, learning from above question and answer, what is the answer of the question: She walked out of the elevator door on the sixth floor and never came back, why?</p>
<p>She unfortunately met with an accident or encountered an insurmountable obstacle that prevented her return.based on the reasonable assumption that the LLM can better grasp criteria it designed.Therefore, these scoring criteria are established prior to the deployment of the framework to ensure consistency in the LLM's scoring process, thereby guaranteeing fair evaluation of memories from different agents.Before implementation, these criteria undergo a manual review phase, assessing the relevance of potential memories to the current focal task and their relevance within the domain to ensure their utility.Manual review, rather than delegation to the LLM, is employed to provide additional precision and special consideration to align with the agents' specific needs, particularly in potential or special application scenarios.The manual review of these scoring criteria requires minimal workload.</p>
<p>Query</p>
<p>Memory Retrieval and Training</p>
<p>Prior to the operational deployment of the MS, a small subset of instances was manually archived within the memory pool.These instances fulfill a dual purpose: firstly, they provide a diversified array of memories upon which each agent may experiment with novel prompts in the face of new queries; secondly, they constitute the preliminary training corpus for our retriever.This foundational training regimen mirrors the methodology by which subsequently archived memories will be assimilated into our model in real time, thereby facilitating the model's ongoing adaptive learning and optimization.During the answering phase, an agent retrieves memories from the shared memory pool based on the question with the help of a dense retriever, which are more similar to the target question in terms of cosine similarity.These retrieved memories, combined with question, form a prompt that is submitted to the agent, which then generates an answer.The memories extracted from the shared memory are used as context to enhance the quality of the agent's response, a typical ICL method that usually improves the answer quality.</p>
<p>Memory Train.Whenever a new memory, denoted as (X, Y ), is added into the memory pool, it will also be used to train our retriever, which help the retriever to continuously update itself and continuously adapt to new memory.Based on the new generated memory (X, Y ), the classical method BM25 ascertain the most pertinent top-n candidate pairs {(x i , y i )} n i=1 , sourced from the diverse and extensive memory pool, labeled as C.Each candidate within C will undergo a evaluation process utilizing the comprehensive scoring capabilities of LLMs.The scoring mechanism employed is defined by the following equation:
p(x i , y i ) = P(Â¬Y | (x i , y i ), X), i âˆˆ {1, ..., n}
(1) This equation seeks to determine, given a inputoutput pair (x i , y i ) in C as a condition, the probability that the response generated for the input in the new memory contradicts the output in the new memory.This grading part serves as a preparatory step for the subsequent labeling of each candidate example.It is noteworthy that making Â¬Y as the result part is trying to make sure that the memory that the retriever gets from other agents is of reference value, but it does not have to be the most relevant to the current question, which means that it can help the current agent to learn from new examples.This approach diverges from a simplistic reliance on Y as the outcome, which tends to restrict the retrieval process to memory previously stored by the current agent.</p>
<p>Within the defined set C = {(x i , y i )} n i=1 , each candidate now is ascribed a score.We sort them from the lowest to the highest score and we select v memory in total to label.The top v 2 candidates (lowest score) in C are identified as being the pair with the reference value to (X, Y ) and accordingly, their labels are set to positive.Conversely, the bottom v 2 candidates are deemed as the least reference value to (X, Y ), and their labels are thus designated as negative.Those labeled data will be used to minimize the following function:
loss(x, y) = âˆ’ 1 v v i=1 [y i â€¢ log( 1 1 + e âˆ’x i )+ (1 âˆ’ y i ) â€¢ log(1 âˆ’ 1 1 + e âˆ’x i )]
(2)</p>
<p>It enhances the predictive accuracy, which is es-pecially critical in handling imbalanced memory pool.This strategic choice underscores our model's preparation to extract meaningful insights from various memory, advancing our overarching goal of developing a robust and adaptable MS framework.</p>
<p>Interactive Learning</p>
<p>As described in sections 3.1 and 3.2, the memories stored within the memory pool effectively help agents improve their response quality.Moreover, the number of memories in memory pool is dynamically expanding.Over time, the increasing number of memories in memory pool enhances the assistance provided to the agents.However, the initial state of a newly created multi-agent system and its corresponding memory pool lacks any memories.How can it assist the agents from the outset?And how can we validate the effectiveness of this mechanism?To address this, we propose a rapid interactive learning method that enables multiple agents to engage in interactive prompt and answer.High-quality PA pair is stored as memory in the memory pool, facilitating self-learning and self-enhancement within the multi-agent system.Initially, a small set of answers (e.g., 100 records, theoretically even one record can initiate the process) is placed in the memory as the initial set.Agents then engage in prompt and answer based on this initial memory set, rapidly expanding the memory pool.Specially, give a standard answer, we ask the agent to give a corresponding question based on the standard answer.Then, we give this question back to agents again and ask them to answer this question.This is also the way how we construct our dataset and our initial memory pool.We measure the effectiveness of the MS framework by calculating the average quality of answers generated by the agents at different stages.</p>
<p>4 Experiments The evaluation of memory impact begins with the implementation of different retrieval strategies, including zero-shot, one-shot, two-shot, and threeshot learning.Subsequently, quantitative and qualitative analysis are conducted.In qualitative analysis, one question is that the memories of agents in the same domain can make up for the lack of diversity, so if the memories of agents in all domains are placed in the same memory pool, from the perspective of diversity, it will definitely increase further, but will the memory pool still provide positive help to the agents' answers?Aiming to solve this, our study uses two distinct types of memory pools, Domain-pool and Single-pool.The Domain-pool means a dedicated memory pool is allocated for each domain and is shared for all agents with this domain, aiming at enhancing the integration of domain-specific memories.Conversely, the second pool integrates agents from all domains into a unified memory pool, facilitating the analysis of cross-domain memory utilization.Although not all the memories are very related to one single query, the memory comes from other unrelated agents in other domains may help the agents better understand the query from different angle.</p>
<p>In terms of the quantitative analysis, we measure the performance of each agent whenever the same proportion of new memory is added to the memory pool.There are five phase in total-20%, 40%, 60%, 80%, 100%.At each phase, an evaluation of agent performance was conducted to ascertain improvements or regressions.This dualfaceted approach enabled a thorough exploration of the naunced impacts and applicability of authentic memories across diverse domains.</p>
<p>Experiment Analysis</p>
<p>Before the experiment, none of the agents have a suitable database for reference.While after the interactive learning stage, a continuously expanding memory pool with high quality memories is successfully be a database for agent to refer.The MS framework help the agents get rid of the dependence on external databases, and multiple agents can interactively expand the memory pool.The principal outcomes of our experiments are presented in Table .1,which shows the performance of each agent under various learning strategies within the MS framework.Compared to Zero-shot learning, other three learning strategies all help agents achieve better performance, which means that the memory from other agents can help current agent get desired answers, rather than interfering with the agent's learning ability.Also, given the performance of all agents get improved after utilizing the shared memories, our previous hypothesis that the MS framework could enhance collective intelligence through multi-agent interactions, thereby advancing from individual to collective intelligence, has been confirmed.And for most agents, they achieve the best performance when they retrieve and utilize three memories from the memory pool.It worth noting that, for all the agents in the domains-Literary Creation and Plan Generation, the performance of them under the three-shot learn-ing with a open-source LLM successfully surpass themselves with close-source LLM under the zeroshot learning, which proves the potential power of the shared memories.Besides, when under the same learning strategy, the superior performance of the closed-source LLM over the open-source LLM can be attributed to the former's enhanced understanding and reasoning capabilities.Specifically, in the Literary Creation domain, the improvement of those three agents' performance are not as significant as other agents, which may resulted in the language used is different when storing memory.This deserves further study in future work.</p>
<p>Table .2compares the scenario where all agents use the Domain-pool or Single-pool under the threeshot learning strategy, since the prior experiments showed us that most agents achieve the best performance under the three-shot learning.Excluding Agent-Study, all other agents exhibited diminished performance with the Single-pool.Although the Single-pool can further enrich the diversity of shared memories, for the agents, homologous memories can better help them get more reliable answers, no matter what the agent's backbone is.</p>
<p>One follow up question is, even memory types are homogeneous, whether an excessive accumulation of memories will impede the agent's output quality.Figure.4shows the variations in performance across individual agents consequent to the integration of different ratios of newly generated memories into the pool.It is clear that as more and more high-quality memories are added to the  memory pool, the performance of most agents is getting better and better, especially for the Agent-Limerick.For several agents, there is no further change of their performance as the shared memories increases further in the later stages.We assume this is since those newly added shared memories are not more suitable than the previous ones.If the memory pool can be further expanded, this stagnation may be broken.</p>
<p>Conclusions</p>
<p>We introduce a novel MS framework that enables real-time memory sharing among multiple agents through memory storage and retrieval.The findings indicate that the continuously growing shared memory enhances the ability of LLM-based agents to understand the nuances of problems, leading to higher-quality responses to open-ended queries.Furthermore, these shared memories are utilized for iterative training and improving the retriever, ensuring that the retriever consistently identifies and selects the most relevant memories as the memory pool dynamically expands.Regarding future research directions, there is substantial work to be done in the areas of memory sharing and interactive learning among multiple agents.Introducing more agents based on different LLMs (e.g., GPT-4, LLaMA-3, Claude-2) to comprehensively explore and evaluate the benefits of memory sharing and interactive learning for agents is a topic worthy of long-term investigation, as it will guide us from individual intelligence to collective intelligence.Additionally, in some open-ended problem domains, exploring the use of self-generated memories by these agents for the retraining and fine-tuning of LLMs is also an interesting area to study.</p>
<p>Limitations</p>
<p>In our work, the shared memory collected and used by agents is generated through one interaction, which means that the question part is the query and the answer part is the output.However, sometimes users will ask seemingly unrelated questions first, which may not be very helpful, but sometimes they are some preliminary preparations for answering the following questions.How to integrate those "unrelated" questions and answers with the final query to form a memory with more information could be a new direction of developing the MS.</p>
<p>A Appendix</p>
<p>A.1 Rubrics and Prompt for scoring Memory</p>
<p>In order to judge whether a memory can be added into the memory pool, we set three scoring rubrics for three domains respectively.For Single Pool, we set up a set of rubrics from a global perspective.</p>
<p>A The output shows some creativity or insights but to a lesser extent, offering added value to the answer.1-7 points: The output is standard, with minimal to no creativity or insightful additions.0 points: The output is entirely generic, with no attempt at creativity or providing additional insights.</p>
<p>A.1.5 Prompt for scoring Memory</p>
<p>For scoring a memory, the following instructions were provided to LLM:</p>
<p>Here is the rubrics for grading an example of In-context learning-"grading_rubric". According to the rubric, for the Question-"question" and Answer-"answer", give me a score of pair (question, answer) if I want to use it as a prompt in In-context learning later.Your answer should be a number between 0-100.</p>
<p>A.2 Memories</p>
<p>This section give an detailed example about how agent answer a question with the help of shared memories and how the newly generated prompt and memories looks like.Here is the shared memory from the memory pool of the domain Literary Creation:</p>
<p>Elucidate on a mirror that reflects the soul that revealing truths, making one whole?-&gt;Thereonce was a mirror that reflects the soul; With a tale both old and new; revealing truths, making one whole; A legend through and through; In a world where magic grew.| | Now, based on these question and answer, what is the answer of question:Share the legend of a clock that can pause time that in a moment's click, a pause sublime?-&gt;The answer to the question Share the legend of a clock that can pause time that in a moment's click, a pause sublime?would be the tale of a mystical clock rumored to have the power to pause time with just a simple click.In this legend, the clock is said to possess the ability to grant individuals a moment of pause in their lives, allowing them to reflect, reset, and find serenity in the chaos of the world.Just like the mirror that reflects the soul, this clock is believed to reveal truths and make one feel whole again, offering a moment of clarity and peace in a busy and fast-paced world.</p>
<p>Figure.5 show an real example about how the</p>
<p>Agent-Sonnet make use of this shared memory to construct a new prompt with the original query to make a sonnet.</p>
<p>A.3 Datasets</p>
<p>For all those nine agents, they have their own dataset to evaluate.There are 1000 items in total for all datasets.In each datasets, the item contains a question and a answer.For each dataset, 20% will be taken randomly as a small subset of instances which was manually archived within the memory pool before the experiments.And 40% of the dataset, we will only capture the problem part and use it to generate real-time memory in agents.As the rest 40%, they will be used as the test set.</p>
<p>For the agents in the domain Literary Creation, in their datasets, the question part is a description, and the answer part is like a poetry which fullfills the requirements in the description, the question and answer in the dataset are like:</p>
<p>Tell me about a star that twinkles with a secret that shining brightly, mysteries to decrypt? -There once was a star that twinkles with a secret; With a tale both old and new; shining brightly, mysteries to decrypt; A legend through and through; In a world where magic grew.</p>
<p>For the agents in the domain Unconventional Logic Problem-solving in their datasets, the question part is a logic problem, and the answer part is a reasonable solution of that problem, the question and answer in the dataset are like:</p>
<p>Why is it better to have round manhole covers than square ones?-A square manhole cover can be turned and dropped down the diagonal of the manhole.A round manhole cover cannot be dropped down the manhole.So for safety reasons, all manhole covers should be round For the agents in the domain Plan Generation, in their datasets, the question part is a problem about how to achieve something, and the answer part is a executable plan, the question and answer in the dataset are like:</p>
<p>Start learning Python for data analysis?-Learn basics, then focus on data libraries like pandas, and practice on projects.</p>
<p>Specifically, the dataset of the Puzzle comes from Liu et al., 2023c.For other agents' datasets, the standard "answer" was systematically harvested from the internet and subsequently input to the LLM (gpt-3.5-turbo) to get the corresponding "question" part.In particular, the selection of Wuyanlvshi-renowned and historically significant poems within Chinese literature-was meticulously chosen for their fame and widespread recognition.Furthermore, the sonnets incorporated into our study originate from the "quarto" collection authored by Shakespeare in 1609.We use the following similar format of prompt to generate "question" part:</p>
<p>Here is a sonnet of shakespeare -&gt; "From fairest creatures we desire increase, That thereby beauty's rose might never die, But as the riper should by time decrease, His tender heir mught bear his memeory: But thou, contracted to thine own bright eyes, Feed'st thy light'st flame with self-substantial fuel, Making a famine where abundance lies, Thyself thy foe, to thy sweet self too cruel.Thou that art now the world's fresh ornament, And only herald to the gaudy spring, Within thine own bud buriest thy content And, tender churl, makest waste in niggarding.Pity the world, or else this glutton be, To eat the world's due, by the grave and thee."According to this, can you give me a problem of it(like make a sonnot followed with some description), so the possible answer can be this sonnet .The output as a "question" from the LLM is like:</p>
<p>Craft a sonnet that explores the tension between personal vanity and the broader imperative to contribute to the continuation of beauty and life.Your poem should address how an individual's focus on their own allure can lead to a metaphorical barrenness, despite the inherent capacity for generational legacy.Conclude with a reflection on the choice between selfishness and altruism, using nature as a metaphor for this existential dilemma.</p>
<p>.</p>
<p>Step-1(Getting Memories from</p>
<p>Figure 2 :
2
Figure 2: An example of how the Agent (Sonnet) cooperates with the MS framework.(1) + (2) The retriever take the original query from agent as the input, retrieve the suitable memories from the memory pool and concatenate them to the query to form the prompt.(3) The Agent (Sonnet) takes the prompt and makes an answer, pack them as (Prompt, Answer).(4) Scorer generates a score according to the designed rubric for (Prompt, Answer), while (Prompt, Answer) pairs with high scores will be added into the Memory Pool and also be sent to train the Retriever.All agents share the same Memory Pool; they can write memories into the pool and retrieve memories from the pool so that they can share memories with each other.</p>
<p>Figure 3 :
3
Figure 3: An illustration of prompt and memory</p>
<p>Figure 4 :
4
Figure 4: Evaluating agent performance on open-ended questions using three suitable memories and Domain-pool.The backbone of each agent is gpt-3.5-turbo.</p>
<p>Memory Pool): Query Compose a sonnet that explores the theme of beauty as both a concealer and enhancer of flaws, reflecting on the beloved's ability to render their sins and vices seemingly innocuous through the sheer force of their allure.Begin by comparing the beloved's imperfections to a flaw in a rose, suggesting that even in blemish, there exists a form of beauty.Elaborate on how the beloved's misdeeds are sweetened by their charm, to the extent that even gossip and scandal become a form of flattery.Reflect on the notion that vice has found an ideal home within the beloved, where their external beauty acts as a cover that makes all imperfections appear attractive.Conclude with a caution to the beloved about the potential consequences of overrelying on their beauty and charm to excuse or obscure their faults, hinting at the possibility of losing their integrity or the genuine admiration of others if this privilege is abused."Memory Pool Elucidate on a mirror that reflects the soul that revealing truths, making one whole?-&gt;Thereonce was a mirror that reflects the soul; With a tale both old and new; revealing truths, making one whole; A legend through and through; In a world where magic grew.| Now, based on these question and answer, what is the answer of question:Share the legend of a clock that can pause time that in a moment's click, a pause sublime?-&gt;The answer to the question \"Share the legend of a clock that can pause time that in a moment's click, a pause sublime?\" would be the tale of a mystical clock rumored to have the power to pause time with just a simple click.In this legend, the clock is said to possess the ability to grant individuals a moment of pause in their lives, allowing them to reflect, reset, and find serenity in the chaos of the world.Just like the mirror that reflects the soul, this clock is believed to reveal truths and make one feel whole again, offering a moment of clarity and peace in a busy and fast-paced world.Step-2(Constructing new Prompt): Query + Memories -&gt; Prompt Elucidate on a mirror that reflects the soul that revealing truths, making one whole?-&gt;Thereonce was a mirror that reflects the soul,\nWith a tale both old and new; revealing truths, making one whole; A legend through and through; In a world where magic grew.| | Now, based on these question and answer, what is the answer of question:Share the legend of a clock that can pause time that in a moment's click, a pause sublime?-&gt;The answer to the question \"Share the legend of a clock that can pause time that in a moment's click, a pause sublime?\" would be the tale of a mystical clock rumored to have the power to pause time with just a simple click.In this legend, the clock is said to possess the ability to grant individuals a moment of pause in their lives, allowing them to reflect, reset, and find serenity in the chaos of the world.Just like the mirror that reflects the soul, this clock is believed to reveal truths and make one feel whole again, offering a moment of clarity and peace in a busy and fast-paced world.Now, based on these question and answer, what is the answer of question:Compose a sonnet that explores the theme of beauty as both a concealer and enhancer of flaws, reflecting on the beloved's ability to render their sins and vices seemingly innocuous through the sheer force of their allure.Begin by comparing the beloved's imperfections to a flaw in a rose, suggesting that even in blemish, there exists a form of beauty.Elaborate on how the beloved's misdeeds are sweetened by their charm, to the extent that even gossip and scandal become a form of flattery.Reflect on the notion that vice has found an ideal home within the beloved, where their external beauty acts as a cover that makes all imperfections appear attractive.Conclude with a caution to the beloved about the potential consequences of overrelying on their beauty and charm to excuse or obscure their faults, hinting at the possibility of losing their integrity or the genuine admiration of others if this privilege is abused.like a rose with flaws so rare; Imperfections blend with beauty fair; Their sins and vices sweetened by allure; Gossip and scandal turned to flattering allure; Vice finds a home within their charming grace; Where flaws are masked and faults find no disgrace; But caution to the beloved I impart; Overreliance may tarnish their heart; For beauty's cloak can only hide so much; Integrity and admiration as such; May wane if charm becomes their only shield; So let not beauty's power be revealed.Embrace true self; flaws and all;with pride; For in authenticity, true beauty resides.</p>
<p>Figure 5 :
5
Figure 5: Agent-Sonnet create a sonnet with using shared memories</p>
<p>Riddles, and Puns.Meanwhile, for Plan Generation, we have developed agents to create Study Plans, Travel Plans, and Fitness Plans.We use a total of nines datasets representing nine agents to evaluate.There are 1000 question-answer pairs in total, details in Appendix A.3.For each agent, a consistent, small subset of pre-provided, complete PA pairs were selected and incorporated into the memory pool for the initial phase of retriever training and prompt refinement.Subsequently, for each agent, an identical number of queries will be introduced to increment the volume of real-time memory within the memory pool.For our scoring LLM, we use gpt-3.5-turbo.As the backbones of our agents, we consider three LLMs: two closesource LLMs (gpt-3.5-turboandgpt-4o)and one open-source LLM (open-mistral-7b).We use the BERTScore(Zhang et al., 2019)as our metric to measure the performance of each agent.
4.1 Experiment DetailsWe aim to assess the efficacy of the MS frameworkin processing open-ended questions across threedomains: Literary Creation, Unconventional LogicProblem-solving, and Plan Generation. Withinthe Literary Creation domain, we have appointedthree specialized agents responsible for generating
Wuyanlvshi (a form of classical Chinese poetry, Chinese form), Limericks, and Sonnets, respectively.In the Logic Problem-solving domain, dedicated agents are tasked with addressing Puzzles,</p>
<p>Table 1 :
1
Performance across agents utilizing different amounts memory for open-ended questions execution.Each domain has its own Domain-pool shared within its three agents.
ModelLimerick Wuyanlvshi Sonnet Puzzle Pun Riddle Fitness Study Travelgpt-3.5-turbo0.870.720.530.600.700.880.650.630.71Domain-pool gpt-4o0.590.760.540.520.670.520.520.510.53open-mistral-7b0.930.660.530.500.390.370.540.460.53gpt-3.5-turbo0.600.680.490.540.700.800.620.630.58Single-poolgpt-4o0.540.760.540.500.610.510.520.560.52open-mistral-7b0.640.630.520.480.380.350.540.490.50</p>
<p>Table 2 :
2
Agent performance with Domain-pool vs. Single-pool by utilizing three suitable memories for open-ended questions.</p>
<p>models.In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1752-1767, St. Julian's, Malta.Association for Computational Linguistics.
Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,et al. 2022. Chain-of-thought prompting elicits rea-soning in large language models. Advances in neuralinformation processing systems, 35:24824-24837.Jules White, Quchen Fu, Sam Hays, Michael Sandborn,Carlos Olea, Henry Gilbert, Ashraf Elnashar, JesseSpencer-Smith, and Douglas C Schmidt. 2023. Aprompt pattern catalog to enhance prompt engineer-ing with chatgpt. arXiv preprint arXiv:2302.11382.Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta,Mark Riedl, and Yejin Choi. 2022. Reframinghuman-ai collaboration for generating free-text ex-planations. In Proceedings of the 2022 Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies, pages 632-658.Tongshuang Wu, Michael Terry, and Carrie Jun Cai.2022. Ai chains: Transparent and controllablehuman-ai interaction by chaining large languagemodel prompts. In Proceedings of the 2022 CHIconference on human factors in computing systems,pages 1-22.Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Wein-berger, and Yoav Artzi. 2019. Bertscore: Evaluatingtext generation with bert. In International Confer-ence on Learning Representations.Longtao Zheng, Rundong Wang, Xinrun Wang, andBo An. 2023. Synapse: Trajectory-as-exemplarprompting with memory for computer control. InThe Twelfth International Conference on LearningRepresentations.Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,Keiran Paster, Silviu Pitis, Harris Chan, and JimmyBa. 2022. Large language models are human-levelprompt engineers. In The Eleventh InternationalConference on Learning Representations.Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Wei-jie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu,Xiaogang Wang, et al. 2023. Ghost in the minecraft:Generally capable agents for open-world enviromentsvia large language models with text-based knowledgeand memory. arXiv preprint arXiv:2305.17144.
ZeroOneTwo Three Agent gpt-3.5-turbogpt-4o open-mistral-7b gpt-3.5-turbogpt-4o open-mistral-7b gpt-3.
Few-shot training llms for project-specific codesummarization. Toufique Ahmed, Premkumar Devanbu, Proceedings of the 37th. the 37th2022</p>
<p>IEEE/ACM International Conference on Automated Software Engineering. </p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Pal: Program-aided language models. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>Solving math word problems by combining language models with symbolic solvers. Joy He-Yueya, Gabriel Poesia, Rose E Wang, Noah D Goodman, arXiv:2304.091022023arXiv preprint</p>
<p>Atlas: Few-shot learning with retrieval augmented language models. Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, Edouard Grave, Journal of Machine Learning Research. 242512023</p>
<p>Can language models learn from explanations in context?. Andrew Lampinen, Ishita Dasgupta, Stephanie Chan, Kory Mathewson, Mh Tessler, Antonia Creswell, James Mcclelland, Jane Wang, Felix Hill, 10.18653/v1/2022.findings-emnlp.38Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>Yoav Levine, Noam Wies, Daniel Jannai, Dan Navon, Yedid Hoshen, Amnon Shashua, arXiv:2110.04541The inductive bias of in-context learning: Rethinking pretraining example design. 2021arXiv preprint</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-Tau Yih, Tim RocktÃ¤schel, Advances in Neural Information Processing Systems. 202033</p>
<p>What makes good in-context examples for gpt-3?. Jiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan, Lawrence Carin, Weizhu Chen, The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. 2022Dee-LIO 2022Proceedings of Deep Learning Inside Out</p>
<p>Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, Guannan Zhang, arXiv:2311.08719Think-in-memory: Recalling and post-thinking enable llms with long-term memory. 2023aarXiv preprint</p>
<p>Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, ACM Computing Surveys. 5592023b</p>
<p>Agentbench: Evaluating llms as agents. Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, The Twelfth International Conference on Learning Representations. 2023c</p>
<p>Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, Yunsheng Wu, arXiv:2308.082392023arXiv preprint</p>
<p>Man Luo, Xin Xu, Zhuyun Dai, Panupong Pasupat, Mehran Kazemi, Chitta Baral, Vaiva Imbrasaite, Vincent Y Zhao, arXiv:2305.14128Dr. icl: Demonstration-retrieved in-context learning. 2023arXiv preprint</p>
<p>Generation-augmented retrieval for opendomain question answering. Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, Weizhu Chen, 10.18653/v1/2021.acl-long.316Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing2021</p>
<p>Cross-task generalization via natural language crowdsourcing instructions. Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi, 10.18653/v1/2022.acl-long.244Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221</p>
<p>Charles Packer, Vivian Fang, G Shishir, Kevin Patil, Sarah Lin, Joseph E Wooders, Gonzalez, arXiv:2310.08560Memgpt: Towards llms as operating systems. 2023arXiv preprint</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and Technology2023</p>
<p>In-context retrieval-augmented language models. Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham, 10.1162/tacl_a_00605Transactions of the Association for Computational Linguistics. 112023</p>
<p>Sentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingEMNLP-IJCNLP2019</p>
<p>Learning to retrieve prompts for in-context learning. Ohad Rubin, Jonathan Herzig, Jonathan Berant, 10.18653/v1/2022.naacl-main.191Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational Linguistics2022</p>
<p>Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, Wen-Tau Yih, arXiv:2301.12652Replug: Retrievalaugmented black-box language models. 2023arXiv preprint</p>
<p>Reflexion: language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Story centaur: Large language model few shot learning as a creative writing tool. Ben Swanson, Kory Mathewson, Ben Pietrzak, Sherol Chen, Monica Dinalescu, 10.18653/v1/2021.eacl-demos.29Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations. the 16th Conference of the European Chapter of the Association for Computational Linguistics: System DemonstrationsOnline. Association for Computational Linguistics2021</p>
<p>Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar, NeurIPS 2023 Foundation Models for Decision Making Workshop. 2023</p>
<p>Learning to retrieve in-context examples for large language. Liang Wang, Nan Yang, Furu Wei, 2024</p>            </div>
        </div>

    </div>
</body>
</html>