<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-989 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-989</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-989</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-edc07047cd45e90aff0556ab10b16740a8110e61</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/edc07047cd45e90aff0556ab10b16740a8110e61" target="_blank">Invariant Structure Learning for Better Generalization and Causal Explainability</a></p>
                <p><strong>Paper Venue:</strong> Trans. Mach. Learn. Res.</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a novel framework, Invariant Structure Learning (ISL), that is designed to improve causal structure discovery by utilizing generalization as an indication, and extends ISL to a self-supervised learning setting where accurate causal structureiscovery does not rely on any labels.</p>
                <p><strong>Paper Abstract:</strong> Learning the causal structure behind data is invaluable for improving generalization and obtaining high-quality explanations. We propose a novel framework, Invariant Structure Learning (ISL), that is designed to improve causal structure discovery by utilizing generalization as an indication. ISL splits the data into different environments, and learns a structure that is invariant to the target across different environments by imposing a consistency constraint. An aggregation mechanism then selects the optimal classifier based on a graph structure that reflects the causal mechanisms in the data more accurately compared to the structures learnt from individual environments. Furthermore, we extend ISL to a self-supervised learning setting where accurate causal structure discovery does not rely on any labels. This self-supervised ISL utilizes invariant causality proposals by iteratively setting different nodes as targets. On synthetic and real-world datasets, we demonstrate that ISL accurately discovers the causal structure, outperforms alternative methods, and yields superior generalization for datasets with significant distribution shifts.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e989.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e989.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ISL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Structure Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that learns causal DAG structure by training per-environment structure learners while enforcing an invariant representation (shared first layer) for predicting a target; aggregates environment-specific DAGs to remove spurious, environment-specific edges and improve OOD generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Structure Learning (ISL)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ISL partitions training data into multiple environments (either from known data sources or via unsupervised clustering). For each environment it fits a DNN-based structural model (a reconstruction objective for all variables) with a DAG acyclicity constraint (NOTEARS-style h(W) = Tr(exp(W o W)) - d). A shared first-layer parameter block theta_1^Y across environment-specific modules is enforced so that the representation used to predict Y is identical across environments. The optimization minimizes per-environment predictive risk for Y plus per-environment DAG reconstruction loss with sparsity regularization; augmented Lagrangian (for DAG-acyclicity) and L-BFGS-B solver are used. After convergence, edges are summarized from the shared theta_1^Y (thresholded) and aggregated across environments by keeping overlapping edges. In self-supervised mode ISL (1) iteratively treats each node as a target to propose invariant parents (invariant causality proposals) and (2) aggregates proposals to form a candidate graph, then constrains the DAG search by deactivating weights for non-proposed edges and re-optimizing the DAG objective to obtain a final DAG.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic multi-environment datasets; real-world datasets split into environments (Boston Housing, Insurance, Sachs); training environments built by data source or k-means clustering</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets split into multiple environments (each environment is static, non-interactive); environment construction can be supervised (known data source) or unsupervised (k-means on raw data or representations). Not an open-ended interactive lab; active interventions are not performed during learning (counterfactual/interventional evaluation is simulated afterwards).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects and downweights spurious/distractor variables by exploiting invariance across environments: variables whose predictive relevance varies across environments are de-emphasized; sparsity (L1) on shared theta_1^Y encourages conservative parent selection; in self-supervised mode, non-proposed edges are deactivated (set to zero) to restrict the search space.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific spurious correlations (contextual/descendant correlates of Y whose conditional dependence with Y varies across environments), irrelevant/weakly correlated variables, measurement noise (implicitly via reconstruction/noise modeling).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Invariance check across environments: variables whose contribution to predicting Y is inconsistent across environments are considered spurious; operationalized by sharing the first-layer representation across per-environment learners and selecting parents that remain predictive under this invariant constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>L1 sparsity regularization on the shared theta_1^Y (selective shrinkage), thresholding adjacency weights from theta_1^Y to remove small edges, and deactivating (fixing to zero) parameters corresponding to non-proposed edges during the self-supervised constrained DAG optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>OOD evaluation and counterfactual simulations: validate candidate causal parents by measuring predictive performance on OOD test sets and by simulating counterfactual changes to variables; if performance degrades or counterfactual predictions are poor for edges that are not invariant, those edges are effectively refuted; aggregation across environments also removes non-overlapping (spurious) edges.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Synthetic supervised: ISL OOD MSE as low as 0.010 (3-node setting) and SHD 0 in many synthetic settings; large OOD improvements over baselines (e.g., up to ~83% MSE reduction vs MLP and ~96% vs CASTLE in some experiments). Real-world: Boston MED MSE 0.05 vs MLP 0.16; self-supervised Sachs: ISL found 8 correct edges with SHD=8 (best in table).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>When invariant constraint is disabled (e=1 environment) performance degrades: example synthetic setting e=1 MSE 0.110 / SHD 2 vs e=2 MSE 0.022 / SHD 0 (Table 4 ablation).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td>varied across synthetic experiments; s in {1,...,10} (e.g., up to 10 distractor nodes in 20-node graphs)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Enforcing an invariant representation across environments yields more accurate discovery of causal parents of Y and markedly better OOD prediction; aggregation of overlapping edges across environments removes environment-specific spurious edges; self-supervised iterative targeting plus constrained re-optimization further improves DAG accuracy; ISL consistently lowers SHD and OOD MSE compared to NOTEARS(-MLP), CASTLE and black-box baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e989.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e989.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ISL-SS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ISL (Self-Supervised two-step pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The self-supervised ISL variant that first proposes invariant parents by iteratively setting each variable as target, then constrains DAG learning by deactivating non-proposed edges and re-optimizing to obtain a DAG.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ISL (self-supervised two-step procedure: invariant causality proposal + constrained graph discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Step 1: Build multiple environments. Iteratively set each node as Y and run ISL to propose invariant parents (candidate Pa(X_i)). Step 2: Aggregate proposed parents into an initial (possibly non-DAG) graph; create a binary adjacency W' where non-proposed edges are fixed at zero by deactivating corresponding first-layer parameters; run constrained NOTEARS-style DAG optimization (with acyclicity constraint and sparsity) over this reduced parameter space to obtain the final DAG. This reduces search space and stabilizes learning versus directly learning a full DAG from reconstruction loss.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same as ISL: synthetic multi-environment datasets; real-world datasets (Sachs, Insurance) split into environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational non-interactive environments; the iteration over targets simulates virtual experiments (each node treated as target) but no active interventions are executed in data collection.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Candidate selection via invariance proposals: only variables that remain predictive across environments when treated as target are retained as candidate parents; non-candidate edges are deactivated (hard-zeroed) to prevent spurious edges from being learned in the final DAG.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-dependent spurious correlations (variables correlated with a target in some but not all environments), noisy/non-informative variables.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Invariance-based proposal: variables that consistently contribute to prediction when chosen as target across environments are detected as potential causal parents; inconsistency flags spuriousness.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Hard deactivation: set first-layer parameter rows to zero for edges not proposed in Step 1; combined with sparsity regularization during final optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>By construction, edges that are not proposed (i.e., not invariant) are removed from the final search space and thus cannot appear in the final DAG; the final DAG is validated by OOD and edge-correctness metrics on benchmarks (e.g., Sachs, Insurance).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Self-supervised results: on Sachs ISL produced 12 total edges with 8 correct (SHD=8), outperforming multiple baselines; on Insurance ISL found 31 correct edges with SHD=27 (best among compared methods).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The two-stage self-supervised pipeline stabilizes DAG learning by pruning the candidate parent set using invariance proposals, reducing the search space and improving DAG accuracy compared to direct reconstruction-based DAG learners.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e989.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e989.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A principle and optimization objective that looks for predictors whose optimality (e.g., classifier) is invariant across multiple environments, intended to prefer causal predictors over spurious correlates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Invariant risk minimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>IRM formalizes the idea of learning predictors that are simultaneously optimal across multiple training environments by enforcing invariance constraints (e.g., shared optimal classifier across environments). It is an objective for learning invariant representations and predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General multi-environment observational settings (as described conceptually; not a specific virtual lab in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not an interactive lab; IRM assumes availability of different environments (contexts) and uses them to identify invariant predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection via invariance principle: spurious features that are not stable across environments are downweighted since they do not yield invariant optimal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific spurious correlations and non-invariant associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Variables that fail to produce invariant optimal predictors across environments are considered spurious; operationalized via constrained optimization that requires a single classifier to be optimal across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Implicit via optimization: the invariant objective discourages reliance on features that vary in predictive power across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Features whose predictive power cannot be made invariant across environments are effectively ruled out as causal predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as conceptual motivation for ISL: invariance across environments is a powerful signal to distinguish causal parents from spurious correlates; ISL builds on the IRM idea by using invariance as a constraint in DAG learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e989.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e989.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CASTLE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CASTLE (Regularization via auxiliary causal graph discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that uses auxiliary causal-graph-based reconstruction as regularization to improve supervised prediction generalization, by incorporating a learned SEM reconstruction objective into predictor training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Castle: Regularization via auxiliary causal graph discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CASTLE</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CASTLE jointly learns an auxiliary SEM-style reconstruction objective (a graph-based reconstruction) together with a predictor; the reconstruction acts as a regularizer intended to bias learning toward causal structure and improve generalization. It does not, however, explicitly output a DAG in the form ISL does.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Applied on the same synthetic and real-world datasets as baselines in this paper (observational, multi-environment splits)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets split into environments; CASTLE is used as a supervised baseline and does not require interactive experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>partially</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Implicit regularization: reconstructing SEM dynamics encourages learning features consistent with an underlying causal mechanism, which can reduce reliance on spurious correlates, but CASTLE may still absorb spurious correlations according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious correlates and irrelevant features that can be suppressed via SEM reconstruction regularizer in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>No explicit detection mechanism; relies on the auxiliary reconstruction loss to discourage fitting spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Regularization (auxiliary reconstruction loss and standard weight penalties) to bias learning away from spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In experiments CASTLE sometimes improves ID performance but can fail OOD: e.g., on some synthetic settings CASTLE OOD MSE was higher than ISL (Table 1); on counterfactual experiments CASTLE performed worse at counterfactual predictions when spurious variables were the source (Table 2: e.g., MSE 0.471 for spurious S1 vs ISL 0.012).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CASTLE uses SEM reconstruction as regularization to improve supervised generalization but does not explicitly produce a DAG and can still absorb spurious correlations; ISL outperforms CASTLE especially under OOD and for counterfactual predictions arising from spurious variables.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e989.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e989.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS-MLP / NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NOTEARS and NOTEARS-MLP (DAG learning via continuous optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>NOTEARS casts DAG structure learning as a continuous constrained optimization problem with an acyclicity differentiable constraint; NOTEARS-MLP extends this to non-linear structural functions using neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dags with no tears: Continuous optimization for structure learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS / NOTEARS-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>NOTEARS frames structure learning as minimizing a reconstruction (or likelihood) objective over observational data subject to a smooth acyclicity constraint h(W)=0, enabling use of continuous optimization methods. NOTEARS-MLP extends the model class to neural-network parameterized conditional distributions (non-linear SEMs).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Used as baseline on synthetic datasets and real-world datasets (observational, multi-environment splits) in the paper's experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets; NOTEARS variants operate on pooled data and do not incorporate multi-environment invariance constraints by default.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Not specifically designed to address environment-dependent spurious correlations; may absorb spurious correlates because training is ERM-based.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Structural learning via reconstruction/objective minimization plus acyclicity constraint; not an invariance-based detector of spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Standard sparsity regularization (L1/L2) on adjacency weights, and acyclicity constraint; no explicit cross-environment downweighting.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In experiments NOTEARS-MLP often had higher SHD and worse OOD MSE than ISL (e.g., synthetic 3-node OOD MSE 0.191 and average SHD 2 vs ISL OOD MSE 0.010 and SHD 0; real-world Boston MED MSE 0.12 vs ISL 0.05).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NOTEARS-family provides scalable differentiable DAG optimization but, as an ERM-style method, it does not exploit invariance across environments and can therefore absorb spurious environment-specific correlations; ISL augments NOTEARS-style constraints with invariance and environment aggregation to mitigate this.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e989.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e989.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DARING</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DARING (Differentiable causal discovery with residual independence)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable causal discovery method that enforces independent residuals constraints to facilitate DAG learning and help identify causal directions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Daring: Differentiable causal discovery with residual independence.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DARING</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DARING uses differentiable optimization for structure learning and incorporates constraints that encourage residuals (errors after structural predictions) to be independent, a property expected under correct causal modeling, which helps guiding DAG discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Used as a baseline in self-supervised DAG discovery experiments (e.g., Sachs dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational datasets; not an interactive experiment environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>partially</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Residual independence constraints can reduce the chance of fitting spurious relationships that leave structured residual dependence, but DARING does not explicitly use multi-environment invariance to detect environment-specific distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding/modeled-as-structured residual dependence and spurious associations that produce dependent residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Encourages residual independence as a criterion for correct edges; spurious edges that do not produce independent residuals are disfavored.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Optimization penalizes structures that violate residual independence; no explicit per-feature downweighting across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Used in Sachs comparison: DARING found 15 edges with 7 correct (SHD=11), which ISL outperformed (ISL correct edges=8, SHD=8).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Residual independence is a useful structural constraint to help DAG discovery, but without explicit multi-environment invariance it may be less effective at removing environment-specific spurious correlates than methods that directly exploit invariance (like ISL).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Invariant Structure Learning for Better Generalization and Causal Explainability', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Invariant risk minimization <em>(Rating: 2)</em></li>
                <li>Dags with no tears: Continuous optimization for structure learning. <em>(Rating: 2)</em></li>
                <li>Learning sparse nonparametric dags. <em>(Rating: 1)</em></li>
                <li>Castle: Regularization via auxiliary causal graph discovery <em>(Rating: 2)</em></li>
                <li>Daring: Differentiable causal discovery with residual independence. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-989",
    "paper_id": "paper-edc07047cd45e90aff0556ab10b16740a8110e61",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "ISL",
            "name_full": "Invariant Structure Learning",
            "brief_description": "A framework that learns causal DAG structure by training per-environment structure learners while enforcing an invariant representation (shared first layer) for predicting a target; aggregates environment-specific DAGs to remove spurious, environment-specific edges and improve OOD generalization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Invariant Structure Learning (ISL)",
            "method_description": "ISL partitions training data into multiple environments (either from known data sources or via unsupervised clustering). For each environment it fits a DNN-based structural model (a reconstruction objective for all variables) with a DAG acyclicity constraint (NOTEARS-style h(W) = Tr(exp(W o W)) - d). A shared first-layer parameter block theta_1^Y across environment-specific modules is enforced so that the representation used to predict Y is identical across environments. The optimization minimizes per-environment predictive risk for Y plus per-environment DAG reconstruction loss with sparsity regularization; augmented Lagrangian (for DAG-acyclicity) and L-BFGS-B solver are used. After convergence, edges are summarized from the shared theta_1^Y (thresholded) and aggregated across environments by keeping overlapping edges. In self-supervised mode ISL (1) iteratively treats each node as a target to propose invariant parents (invariant causality proposals) and (2) aggregates proposals to form a candidate graph, then constrains the DAG search by deactivating weights for non-proposed edges and re-optimizing the DAG objective to obtain a final DAG.",
            "environment_name": "Synthetic multi-environment datasets; real-world datasets split into environments (Boston Housing, Insurance, Sachs); training environments built by data source or k-means clustering",
            "environment_description": "Observational datasets split into multiple environments (each environment is static, non-interactive); environment construction can be supervised (known data source) or unsupervised (k-means on raw data or representations). Not an open-ended interactive lab; active interventions are not performed during learning (counterfactual/interventional evaluation is simulated afterwards).",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects and downweights spurious/distractor variables by exploiting invariance across environments: variables whose predictive relevance varies across environments are de-emphasized; sparsity (L1) on shared theta_1^Y encourages conservative parent selection; in self-supervised mode, non-proposed edges are deactivated (set to zero) to restrict the search space.",
            "spurious_signal_types": "Environment-specific spurious correlations (contextual/descendant correlates of Y whose conditional dependence with Y varies across environments), irrelevant/weakly correlated variables, measurement noise (implicitly via reconstruction/noise modeling).",
            "detection_method": "Invariance check across environments: variables whose contribution to predicting Y is inconsistent across environments are considered spurious; operationalized by sharing the first-layer representation across per-environment learners and selecting parents that remain predictive under this invariant constraint.",
            "downweighting_method": "L1 sparsity regularization on the shared theta_1^Y (selective shrinkage), thresholding adjacency weights from theta_1^Y to remove small edges, and deactivating (fixing to zero) parameters corresponding to non-proposed edges during the self-supervised constrained DAG optimization.",
            "refutation_method": "OOD evaluation and counterfactual simulations: validate candidate causal parents by measuring predictive performance on OOD test sets and by simulating counterfactual changes to variables; if performance degrades or counterfactual predictions are poor for edges that are not invariant, those edges are effectively refuted; aggregation across environments also removes non-overlapping (spurious) edges.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Synthetic supervised: ISL OOD MSE as low as 0.010 (3-node setting) and SHD 0 in many synthetic settings; large OOD improvements over baselines (e.g., up to ~83% MSE reduction vs MLP and ~96% vs CASTLE in some experiments). Real-world: Boston MED MSE 0.05 vs MLP 0.16; self-supervised Sachs: ISL found 8 correct edges with SHD=8 (best in table).",
            "performance_without_robustness": "When invariant constraint is disabled (e=1 environment) performance degrades: example synthetic setting e=1 MSE 0.110 / SHD 2 vs e=2 MSE 0.022 / SHD 0 (Table 4 ablation).",
            "has_ablation_study": true,
            "number_of_distractors": "varied across synthetic experiments; s in {1,...,10} (e.g., up to 10 distractor nodes in 20-node graphs)",
            "key_findings": "Enforcing an invariant representation across environments yields more accurate discovery of causal parents of Y and markedly better OOD prediction; aggregation of overlapping edges across environments removes environment-specific spurious edges; self-supervised iterative targeting plus constrained re-optimization further improves DAG accuracy; ISL consistently lowers SHD and OOD MSE compared to NOTEARS(-MLP), CASTLE and black-box baselines.",
            "uuid": "e989.0",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "ISL-SS",
            "name_full": "ISL (Self-Supervised two-step pipeline)",
            "brief_description": "The self-supervised ISL variant that first proposes invariant parents by iteratively setting each variable as target, then constrains DAG learning by deactivating non-proposed edges and re-optimizing to obtain a DAG.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "ISL (self-supervised two-step procedure: invariant causality proposal + constrained graph discovery)",
            "method_description": "Step 1: Build multiple environments. Iteratively set each node as Y and run ISL to propose invariant parents (candidate Pa(X_i)). Step 2: Aggregate proposed parents into an initial (possibly non-DAG) graph; create a binary adjacency W' where non-proposed edges are fixed at zero by deactivating corresponding first-layer parameters; run constrained NOTEARS-style DAG optimization (with acyclicity constraint and sparsity) over this reduced parameter space to obtain the final DAG. This reduces search space and stabilizes learning versus directly learning a full DAG from reconstruction loss.",
            "environment_name": "Same as ISL: synthetic multi-environment datasets; real-world datasets (Sachs, Insurance) split into environments",
            "environment_description": "Observational non-interactive environments; the iteration over targets simulates virtual experiments (each node treated as target) but no active interventions are executed in data collection.",
            "handles_distractors": true,
            "distractor_handling_technique": "Candidate selection via invariance proposals: only variables that remain predictive across environments when treated as target are retained as candidate parents; non-candidate edges are deactivated (hard-zeroed) to prevent spurious edges from being learned in the final DAG.",
            "spurious_signal_types": "Environment-dependent spurious correlations (variables correlated with a target in some but not all environments), noisy/non-informative variables.",
            "detection_method": "Invariance-based proposal: variables that consistently contribute to prediction when chosen as target across environments are detected as potential causal parents; inconsistency flags spuriousness.",
            "downweighting_method": "Hard deactivation: set first-layer parameter rows to zero for edges not proposed in Step 1; combined with sparsity regularization during final optimization.",
            "refutation_method": "By construction, edges that are not proposed (i.e., not invariant) are removed from the final search space and thus cannot appear in the final DAG; the final DAG is validated by OOD and edge-correctness metrics on benchmarks (e.g., Sachs, Insurance).",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Self-supervised results: on Sachs ISL produced 12 total edges with 8 correct (SHD=8), outperforming multiple baselines; on Insurance ISL found 31 correct edges with SHD=27 (best among compared methods).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "The two-stage self-supervised pipeline stabilizes DAG learning by pruning the candidate parent set using invariance proposals, reducing the search space and improving DAG accuracy compared to direct reconstruction-based DAG learners.",
            "uuid": "e989.1",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "A principle and optimization objective that looks for predictors whose optimality (e.g., classifier) is invariant across multiple environments, intended to prefer causal predictors over spurious correlates.",
            "citation_title": "Invariant risk minimization",
            "mention_or_use": "mention",
            "method_name": "Invariant Risk Minimization (IRM)",
            "method_description": "IRM formalizes the idea of learning predictors that are simultaneously optimal across multiple training environments by enforcing invariance constraints (e.g., shared optimal classifier across environments). It is an objective for learning invariant representations and predictors.",
            "environment_name": "General multi-environment observational settings (as described conceptually; not a specific virtual lab in this paper)",
            "environment_description": "Not an interactive lab; IRM assumes availability of different environments (contexts) and uses them to identify invariant predictors.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection via invariance principle: spurious features that are not stable across environments are downweighted since they do not yield invariant optimal predictors.",
            "spurious_signal_types": "Environment-specific spurious correlations and non-invariant associations.",
            "detection_method": "Variables that fail to produce invariant optimal predictors across environments are considered spurious; operationalized via constrained optimization that requires a single classifier to be optimal across environments.",
            "downweighting_method": "Implicit via optimization: the invariant objective discourages reliance on features that vary in predictive power across environments.",
            "refutation_method": "Features whose predictive power cannot be made invariant across environments are effectively ruled out as causal predictors.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as conceptual motivation for ISL: invariance across environments is a powerful signal to distinguish causal parents from spurious correlates; ISL builds on the IRM idea by using invariance as a constraint in DAG learning.",
            "uuid": "e989.2",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "CASTLE",
            "name_full": "CASTLE (Regularization via auxiliary causal graph discovery)",
            "brief_description": "A method that uses auxiliary causal-graph-based reconstruction as regularization to improve supervised prediction generalization, by incorporating a learned SEM reconstruction objective into predictor training.",
            "citation_title": "Castle: Regularization via auxiliary causal graph discovery",
            "mention_or_use": "use",
            "method_name": "CASTLE",
            "method_description": "CASTLE jointly learns an auxiliary SEM-style reconstruction objective (a graph-based reconstruction) together with a predictor; the reconstruction acts as a regularizer intended to bias learning toward causal structure and improve generalization. It does not, however, explicitly output a DAG in the form ISL does.",
            "environment_name": "Applied on the same synthetic and real-world datasets as baselines in this paper (observational, multi-environment splits)",
            "environment_description": "Observational datasets split into environments; CASTLE is used as a supervised baseline and does not require interactive experiments.",
            "handles_distractors": "partially",
            "distractor_handling_technique": "Implicit regularization: reconstructing SEM dynamics encourages learning features consistent with an underlying causal mechanism, which can reduce reliance on spurious correlates, but CASTLE may still absorb spurious correlations according to the paper.",
            "spurious_signal_types": "Spurious correlates and irrelevant features that can be suppressed via SEM reconstruction regularizer in practice.",
            "detection_method": "No explicit detection mechanism; relies on the auxiliary reconstruction loss to discourage fitting spurious correlations.",
            "downweighting_method": "Regularization (auxiliary reconstruction loss and standard weight penalties) to bias learning away from spurious features.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In experiments CASTLE sometimes improves ID performance but can fail OOD: e.g., on some synthetic settings CASTLE OOD MSE was higher than ISL (Table 1); on counterfactual experiments CASTLE performed worse at counterfactual predictions when spurious variables were the source (Table 2: e.g., MSE 0.471 for spurious S1 vs ISL 0.012).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "CASTLE uses SEM reconstruction as regularization to improve supervised generalization but does not explicitly produce a DAG and can still absorb spurious correlations; ISL outperforms CASTLE especially under OOD and for counterfactual predictions arising from spurious variables.",
            "uuid": "e989.3",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "NOTEARS-MLP / NOTEARS",
            "name_full": "NOTEARS and NOTEARS-MLP (DAG learning via continuous optimization)",
            "brief_description": "NOTEARS casts DAG structure learning as a continuous constrained optimization problem with an acyclicity differentiable constraint; NOTEARS-MLP extends this to non-linear structural functions using neural networks.",
            "citation_title": "Dags with no tears: Continuous optimization for structure learning.",
            "mention_or_use": "use",
            "method_name": "NOTEARS / NOTEARS-MLP",
            "method_description": "NOTEARS frames structure learning as minimizing a reconstruction (or likelihood) objective over observational data subject to a smooth acyclicity constraint h(W)=0, enabling use of continuous optimization methods. NOTEARS-MLP extends the model class to neural-network parameterized conditional distributions (non-linear SEMs).",
            "environment_name": "Used as baseline on synthetic datasets and real-world datasets (observational, multi-environment splits) in the paper's experiments",
            "environment_description": "Observational datasets; NOTEARS variants operate on pooled data and do not incorporate multi-environment invariance constraints by default.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Not specifically designed to address environment-dependent spurious correlations; may absorb spurious correlates because training is ERM-based.",
            "detection_method": "Structural learning via reconstruction/objective minimization plus acyclicity constraint; not an invariance-based detector of spurious signals.",
            "downweighting_method": "Standard sparsity regularization (L1/L2) on adjacency weights, and acyclicity constraint; no explicit cross-environment downweighting.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In experiments NOTEARS-MLP often had higher SHD and worse OOD MSE than ISL (e.g., synthetic 3-node OOD MSE 0.191 and average SHD 2 vs ISL OOD MSE 0.010 and SHD 0; real-world Boston MED MSE 0.12 vs ISL 0.05).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "NOTEARS-family provides scalable differentiable DAG optimization but, as an ERM-style method, it does not exploit invariance across environments and can therefore absorb spurious environment-specific correlations; ISL augments NOTEARS-style constraints with invariance and environment aggregation to mitigate this.",
            "uuid": "e989.4",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "DARING",
            "name_full": "DARING (Differentiable causal discovery with residual independence)",
            "brief_description": "A differentiable causal discovery method that enforces independent residuals constraints to facilitate DAG learning and help identify causal directions.",
            "citation_title": "Daring: Differentiable causal discovery with residual independence.",
            "mention_or_use": "use",
            "method_name": "DARING",
            "method_description": "DARING uses differentiable optimization for structure learning and incorporates constraints that encourage residuals (errors after structural predictions) to be independent, a property expected under correct causal modeling, which helps guiding DAG discovery.",
            "environment_name": "Used as a baseline in self-supervised DAG discovery experiments (e.g., Sachs dataset)",
            "environment_description": "Observational datasets; not an interactive experiment environment.",
            "handles_distractors": "partially",
            "distractor_handling_technique": "Residual independence constraints can reduce the chance of fitting spurious relationships that leave structured residual dependence, but DARING does not explicitly use multi-environment invariance to detect environment-specific distractors.",
            "spurious_signal_types": "Confounding/modeled-as-structured residual dependence and spurious associations that produce dependent residuals.",
            "detection_method": "Encourages residual independence as a criterion for correct edges; spurious edges that do not produce independent residuals are disfavored.",
            "downweighting_method": "Optimization penalizes structures that violate residual independence; no explicit per-feature downweighting across environments.",
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Used in Sachs comparison: DARING found 15 edges with 7 correct (SHD=11), which ISL outperformed (ISL correct edges=8, SHD=8).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Residual independence is a useful structural constraint to help DAG discovery, but without explicit multi-environment invariance it may be less effective at removing environment-specific spurious correlates than methods that directly exploit invariance (like ISL).",
            "uuid": "e989.5",
            "source_info": {
                "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Invariant risk minimization",
            "rating": 2
        },
        {
            "paper_title": "Dags with no tears: Continuous optimization for structure learning.",
            "rating": 2
        },
        {
            "paper_title": "Learning sparse nonparametric dags.",
            "rating": 1
        },
        {
            "paper_title": "Castle: Regularization via auxiliary causal graph discovery",
            "rating": 2
        },
        {
            "paper_title": "Daring: Differentiable causal discovery with residual independence.",
            "rating": 2
        }
    ],
    "cost": 0.018226,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Invariant Structure Learning for Better Generalization and Causal Explainability</h1>
<p>Yunhao $\mathbf{G e}^{1,2}$, Sercan . Ark ${ }^{1}$, Jinsung Yoon ${ }^{1}$, Ao Xu ${ }^{2}$, Laurent Itti ${ }^{2}$, and Tomas Pfister ${ }^{1}$<br>${ }^{1}$ Google Cloud AI, Sunnyvale, CA, USA<br>${ }^{2}$ University of Southern California, Los Angeles, CA, USA<br>{yunhaoge, soarik, jinsungyoon, tpfister}@google.com,{yunhaoge, aosu, itti}@usc.edu</p>
<h4>Abstract</h4>
<p>Learning the causal structure behind data is invaluable for improving generalization and obtaining high-quality explanations. We propose a novel framework, Invariant Structure Learning (ISL), that is designed to improve causal structure discovery by utilizing generalization as an indication. ISL splits the data into different environments, and learns a structure that is invariant to the target across different environments by imposing a consistency constraint. An aggregation mechanism then selects the optimal classifier based on a graph structure that reflects the causal mechanisms in the data more accurately compared to the structures learnt from individual environments. Furthermore, we extend ISL to a self-supervised learning setting where accurate causal structure discovery does not rely on any labels. This self-supervised ISL utilizes invariant causality proposals by iteratively setting different nodes as targets. On synthetic and real-world datasets, we demonstrate that ISL accurately discovers the causal structure, outperforms alternative methods, and yields superior generalization for datasets with significant distribution shifts.</p>
<h2>1 Introduction</h2>
<p>Generalization is a fundamental problem in machine learning. High capacity models such as deep neural networks (DNNs) can be very effective in fitting to training data and this has fueled transformational progress in numerous domains where the i.i.d. assumption is mostly valid [54]. However, the performance of such models can be much worse on the out-of-distribution (OOD) test data, and this phenomena highlights the blind spots of conventional machine learning. This 'overfitting' phenomenon can be attributed mainly to over-parameterized models such as DNNs absorbing spurious correlations from the training data and resulting in biases unrelated to the causal relationships that truly drive the input-output mapping for both training and test samples [53, 42, 38, 11, 8]. Moreover, in most cases, the machine learning problem is underspecified, i.e. there are many distinct solutions that solve the problem by achieving equivalent held-out performance on i.i.d. data. Underspecification in practice can be an obstacle to reliable deployment of high capacity machine learning models in real world, as such models can exhibit unexpected behavior when the test data deviate from the training data [11, 5]. Various methods have been proposed towards reducing overfitting and mitigating underspecification: regularization approaches [6, 31, 48, 18] constrain the model training; data augmentation methods [51, 24] generate artificially-transformed samples invariant to labels; judicious DNN designs [4, 33, 21, 28] introduce appropriate inductive biases for data types of interest. Despite making significant improvements in some cases, these approaches don't tackle the fundamental challenge of discovering causal relationships that are consistent across the training and test data and basing the decision making on them. Learning the true causal relationships is fundamentally challenging [41]. It is infeasible to consider all combinations for factors of variation (such as shape, size, and color for an image), as it would be exponential in size ( $N^{M}$ samples with $M$ categorical features where each can take $N$ different values). Effective methods should reduce the</p>
<p>prohibitively-high data demand while accurately discovering the underlying mechanisms. Accurate discovery of causal relationships [44] would not only improve accuracy and reliability, but also enable explainable decision making, which is crucial for high-stakes applications such as healthcare or finance.</p>
<p>Causal discovery has been studied using various approaches. Interventional experiments [35] by randomized controlled trials is one direction, but often prohibitively costly. A more realistic and common setting is learning from observational data. Constraint-based algorithms [45; 46] directly conduct independence tests to detect causal structure. Score-based algorithms [10; 19] adopt score functions consistent with the conditional independence statistics, however, these can only find the Markov-equivalence class [15]. Functional causal models [43; 37] aim to identify the causal structure from the equivalence class, but the heuristic directed acyclic graph (DAG) search suffers from high computational cost and local optimality, especially when there is a larger number of nodes. To address this problem, NOTEARS [56] provides a differentiable optimization framework. NOTEARS-MLP [57] and Gran-DAG [26] extend NOTEARS to non-linear modeling with DNNs. DARING [16] uses constrains on independent residuals to facilitate DAG learning. However, these approaches rely on empirical risk minimization  not invariant risk minimization [5]  which can prevent the absorption of spurious correlations during DAG learning.</p>
<p>Our goal in this paper is to push the achievable accuracy and reliability by improving causal graph discovery. Motivated by the limitations of existing work mentioned above, we propose Invariant Structure Learning (ISL), a self-explainable decision framework that ties generalization and causal structure learning for reciprocity. Intuitively, better generalization should lead to more accurate causal structure learning, and an accurate causal structure should yield improved robustness and generalization. ISL encourages reinforcement between these two goals. Specifically, ISL uses generalization accuracy as a constraint to learn the invariant structure (as a DAG) that represents the causal relationship among variables. Take Fig. 1 as an example, where we simplify the object recognition task by using variables to represent the key factors: $X1$ object shape, $X2$ object texture (including color), $X3$ image background (as context), with the output label $Y$. Fig. 1 (a) shows the ground truth (GT) Structural Causal Model (SCM). During training, the data (Fig. 1 (b)) consist of samples from different environments. Baseline methods such as NOTEARS-MLP and CASTLE directly estimate the underlying causal structure, which leads to spurious correlations being absorbed, which in turn results in sub-optimal test accuracy. Our method ISL, on the other hand, learns the invariant structure that correctly identifies the causal structure and yields better test accuracy. Overall, our contributions are highlighted as:</p>
<ul>
<li>We propose Invariant Structure Learning (ISL), a novel learning framework that yields accurate causal explanations by mining the invariant causal structure underlying the training data, and generalizes well to unknown out-of-distribution test data.</li>
<li>We generalize ISL to self-supervised causal structure learning, which first treats the discovered invariant correlations as potential causal edges, and then uses a DAG constraint to finalize the causal structure.</li>
<li>We demonstrate the effectiveness of ISL on various synthetic and real-world datasets. ISL yields state-of-the-art causal graph discovery (clearly outperforming alternatives on real-world data) with a particularly prominent improvement for complex graphs structures. In addition, ISL improves the test prediction accuracy throughout, with especially large improvements in cases with significant data drifts (up to $\sim 80\%$ MSE reduction compared to alternatives).</li>
</ul>
<h2>2 Related Works</h2>
<p>Improving machine learning generalization. Many different approaches have been studied to improve generalization (i.e. bringing the test performance closer to training). Regularization methods [6; 31; 48; 18; 17; 49], early stopping [14], gradient clipping [34], batch normalization [20], data augmentation [51; 24] are among the most popular ones. These arent based on discovering the true relationship between the features. Towards generalization improvements with input feature discovery direction, supervised auto-encoders [27] add a reconstruction loss for the input features as a regularizer. Recently, some works [22; 7] combine causal discovery with model regularization for better generalization. CASTLE [25] implicitly uses underlying Structural Equation Model (SEM) reconstruction as the regularization to improve model generalization. However, it cant explicitly yield a DAG for the causal structure and it cant completely prevent learning spurious correlations.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A motivational example. (a) For the image label Y (here, "cow"), X1 and X2 represent the causal parents about the image details (here shape and texture), and X3 represents a factor that isn't causal to Y (here, background type). S() is sigmoid function. In this example, texture (X2) is twice as causal to Y than shape (X1). (b) The relationship between Y and X3 vary across environments; since the conditional dependence is not consistent across environments X3 may not be treated as a major causal factor for Y: (c) Our proposed method ISL yields more accurate discovery of the underlying causal relation: here correctly identifying X1 and X2 but not X3 as the causal factors of Y, improving the explanation quality and prediction accuracy.</p>
<p>ISL addresses these two challenges by learning the invariant structure across environments and outputting a DAG to describe the causal data structure, and eventually showing better generalization.</p>
<p>Causal structure discovery. Constraint-based causal discovery algorithms [45, 46], and some score-based methods [10, 19, 43, 37] conduct exhaustive and heuristic search for the DAG structure, yielding combinatorial explosion issue when they scale up to a larger number of the nodes. NOTEARS [56] proposes directly applying a standard numerical solver for constrained optimization to achieve a global approximate solution overcoming the scalability bottleneck. They formulate the structure learning problem as maximum likelihood estimation over observational data with the additional constraint that the weight matrix has to represent a DAG with the acyclicity and sparsity properties. NOTEARS-MLP [57] and Gran-DAG [26] extend NOTEARS to non-linear functions by using DNNs. RL-BIC [59] uses Reinforcement Learning to search for the DAG with the best scoring. GOLEM [32] applies a likelihood-based objective with soft sparsity and DAG constraints. These methods don't consider using the generalization quantification as an indication or constrain during DAG learning, which makes the learned DAG sometimes absorb biases and spurious correlations from data.</p>
<h1>3 Methodology</h1>
<p>In this section, we present the problem definition and discuss how spurious correlation can affect the model generalization, and how its influence can be alleviated. Then, we describe the proposed ISL framework for supervised learning setting, and later extend to self-supervised learning setting.</p>
<h3>3.1 Motivations</h3>
<p>Problem definition. Standard supervised learning is defined for a dataset with given input variables $\hat{X}\left(Y, X_{1}, X_{2}, \ldots X_{d}\right)$, including $\mathbf{X}={X i}<em Y="Y">{i=1}^{d} \in \mathcal{X}$ and $Y \in \mathcal{Y}$, the goal is to learn a predictive model $f</em>}: \mathcal{X} \rightarrow \mathcal{Y} . P_{\mathbf{X}, Y}$ denotes the joint distribution of the features and target, $\mathcal{D<em _test="{test" _text="\text">{\text {train }}$ denotes the training data with $N$ samples, and $\mathcal{D}</em>}}$ denotes the testing data. Ideally, we expect both $\mathcal{D<em _test="{test" _text="\text">{\text {train }}$ and $\mathcal{D}</em>$.}}$ to be i.i.d., sampled from the same distribution $P_{\mathbf{X}, Y}$. However, it is hard to satisfy this condition for real-world data. It becomes more severe when the model overfits to the training set or the training set doesn't reveal the underlying distribution $P_{\mathbf{X}, Y</p>
<p>Spurious correlations and causality. One perspective to explain poor generalization due to overfitting is models learning spurious correlations. Broadly, a correlation can be considered as spurious when the relationship doesnt hold across all samples in the same manner [5]. For example, for the image recognition task in Fig. 1(a), the model may use the green color of the grass to recognize cows, instead of complete profile of its shape. The correlation between green-colored grass and the cow label would be spurious and not consistent. In contrast, with causal learning, our goal is to learn stable and invariant relationships, that generalize well. Lets consider that there is a SCM defining how the random variables $\hat{X}$ ( $Y, X_{1}, X_{2}, \ldots X_{d}$ ) define each other. The target variable $Y$ is generated by a function $f_{Y}(P a(Y), u_{Y})$, where $P a(Y)$ denotes the causal parents of $Y$ in SCM. Non-parametric SEM [36] proves that if we use the causal parents of $Y$ as inputs to predict $Y$, the learned model would be optimal and generalize well on the unknown test set. Identifying causal parents of $Y$ from spurious correlations is the key to obtain better generalization and causal explainability.</p>
<p>Invariant structure across environments: An environment is used to distinguish different properties of data (such as the generative source characteristics), and can help reveal reasons for spurious correlations. An environment can be different devices for capturing the images, or the hospitals at which the patient data are collected. Broadly, it can be considered as a set of conditions, interpreted as 'context' of the data [30]. As an important indication of distinguishing causality from spurious correlations, the causal structure of $Y$ should be invariant across all possible environments. Our goal is to learn such invariant structure across environments, which should yield better generalization.</p>
<h1>3.2 Learning framework</h1>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Top: The proposed Invariant Structure Learning (ISL) framework. Given raw data, we build different environments using unsupervised clustering (unless data source information is provided). For different environments, each ISL module outputs a summarized DAG to represent the learned invariant structure. An aggregation mechanism then selects the optimal predictor based on a graph structure that reflects the causal mechanisms in the data more accurately. During training, the constraint on the $Y$ prediction across environments helps learn an invariant structure. Consequently, the learned DAG leads to a superior predictor. Bottom: Details of the ISL module. $\theta_{1}^{Y}$ is the invariant structure of $P a(Y)$ shared across all modules.</p>
<p>Fig. 2 shows the overall Invariant Structure Learning (ISL) framework. Given raw training data, we first build different environments. If we had the information on data generation and collection process, it would be simple to build different environments based on them. Without such information, we propose to build environments in an unsupervised way using unsupervised clustering, K-means [29], which clusters the raw data into different clusters that each representing an environment. The</p>
<p>clustering can be done for the raw data or learned representations (which would require an encoder to map raw data). To determine the number of clusters, we use Elbow [47] and Silhouette [39] methods. To balance the data size across environments, we use upsampling. We augment the data size to reach to $n$, the largest number of data samples in an environment. Fig. 2(top) depicts the environment building process, where each color represents a different source or generation method for the sample. In general, at least two diverse environments are sufficient to learn the invariant structure [5]. We show that ISL is robust to the number of environments and typically an intermediate value is optimal.</p>
<p>After assigning data samples to different environments, our goal is to learn the invariant structure that results in superior generalization for predicting $Y$. In each environment, using that environment's data, an ISL module (see Fig. 2(bottom)) independently learns a DAG which defines the variable relationship for that specific environment. To learn the invariant structure for predicting $Y$, we add a constraint among ISL modules that the parameters to reconstruct $Y$ should be identical across environments. The desiderata for invariance is expressed as a loss function over all environments in the training data. Ideally, the generalization goal would be minimization of an OOD risk $R^{O O D}(f)=$ $\max <em a="a" l="l">{e \in \epsilon</em>}} R^{e}(f(X))$ over all possible environments, not only the ones in the training data. We aim to approximate this with a tractable objective. We propose the risk under a certain environment $e$ as $R^{e}(f)=\mathbb{E<em 1="1">{X^{e}, Y^{e}}\left[\left(f\left(X^{e}, Y^{e}\right)\right)\right]$, where $l$ denotes the loss function. We decompose the objective function $f()$ into two components. The first is to find the representation of causal parents of $Y$ from given $X$, which can be considered as the invariant structure for $Y$ across environments. The second is to find the optimal classifier taking the learned $P a(Y)$ as input. To represent $f()$, we use a DNN with learnable parameters $\theta$, consisting: (i) $g()$ with parameters $\theta</em>$ to learn a representation of $P a(Y)$, and (ii) $h()$ that inputs the representation and yields the prediction for $Y$. To learn the representation of $P a(Y), g()$ should follow the causal structure of $Y$. Overall, the proposed objective to learn the invariant causal structure (as a DAG) is summarized as below:}^{Y</p>
<p>$$
\begin{array}{r}
\min <em 1="1">{\theta</em>(X)\right) \
\text { s.t. } \theta_{1}^{Y}, \theta_{r}^{Y}, \theta^{X}=\underset{\theta}{\arg \min } \sum_{e \in \epsilon_{a l l}} \mathcal{R}_{D A G}(\hat{X}, \theta)
\end{array}
$$}^{Y}, h} \sum_{e \in \epsilon_{a l l}} R^{e}\left(h \circ \theta_{1}^{Y</p>
<p>This objective is in bi-level optimization form. The outer loop is for the final goal of obtaining the predictive model for $Y$ to generalize well on all environments, requiring that $\theta_{1}^{Y}$ extract the representation of $P a(Y)$. The inter loop adds the constraint that $\theta_{1}^{Y}$ should be the invariant across all the environment during learning their DAGs. As shown in Fig. 2(b), we use a DNN to learn the SCM (represented as a DAG) of the dataset. The parameter of $\theta$ consists of three parts: first layer to reconstruct variable $\mathrm{Y}, \theta_{1}^{Y}$, rest layers to reconstruct variable $\mathrm{Y}, \theta_{r}^{Y}$, and layers to reconstruct other variables $\mathrm{X}, \theta^{X}$. We use the following objective function represented as the DAG loss $\mathcal{R}_{D A G}(\hat{X}, \theta)$ :</p>
<p>$$
\mathcal{R}<em c="c" e="e" r="r">{D A G}(\hat{X}, \theta)=\mathcal{L}</em>(\theta)
$$}(\hat{X}, \theta)+\rho / 2|h(W)|^{2}+\alpha h(W)+\beta \mathcal{L}_{\text {sparse }</p>
<p>where $\mathcal{L}<em F="F">{r e c}(\theta)=1 / 2 N|\hat{X}-\theta(\hat{X})|</em>\right)-d$, with $|\cdot|}^{2}$ and $h(W)=\operatorname{Tr}\left(e^{W \odot W<em A="A" D="D" G="G">{F}$ being the Frobenius norm, $\mathcal{L}</em>$ of $\theta$. Specifically, $[W]}=\rho / 2|h(W)|^{2}+\alpha h(W)$ denotes the constrain of DAG. $N$ denotes the number of samples, $\operatorname{Tr}()$ is the trace operator, $W$ is a $(d+1) \times(d+1)$ adjacency matrix ( $W \in \mathbb{R}^{(d+1) \times(d+1)}$ ) which represent the connnection strength between variables and the final DAG is summarized from $W$. [56] proves that $W$ is a DAG if and only if $h(W)=0 . W$ is summarized from the first layer $\theta_{1<em 2="2">{k, j}$ is the $L</em>}$ norm of the $k$-th row of the parameter matrix $\theta_{1}^{j} . \theta^{j}$ is the DNN parameters used to reconstruct variable $j$, that we decompose as the first layer $\theta_{1}^{j}$ and the remaining layers $\theta_{r}^{j}$ (Fig. 2(b)). $\mathcal{L<em 1="1">{\text {sparse }}(\theta)=\beta</em>\right|}\left|\theta_{1}^{Y<em 2="2">{1}+\beta</em>\right|}\left|\theta_{r}^{Y<em 3="3">{2}+\beta</em>\right|}\left|\theta^{X<em 4="4">{1}+\beta</em>\right|}\left|\theta^{X<em 1="1">{2}$, where $|\cdot|</em>$ and $|\cdot|<em 1="1">{2}$ denote $l</em>(X) \approx P a(X)\right)$, which is a constraint to learn the invariant structure of $Y$ prediction among environments. We simplify the training of Eq. 1 and the overall training objective of the proposed ISL is defined as:}$ and $l_{2}$ regularization, respectively, and $\beta_{i}$ are hyperparameters that can be optimized on validation set. Eq. 2 is a solution using Augmented Lagrangian [12] approach, where $\alpha&gt;0$ and $\rho&gt;0$ are gradually increased to find solutions that minimize $h(W)$. To learn the invariant structure across different environments, in all modules, we use a shared layer $\theta_{1}^{Y}$ to learn a representation of $P a(Y)$ given input feature $X$, $\left(\theta_{1}^{Y</p>
<p>$$
\min <em _epsilon__a="\epsilon_{a" _in="\in" e="e" l="l">{\theta, h} \sum</em>}}^{n}\left(R^{e}\left(h \circ \theta_{f}^{Y}(X)\right)+\gamma \mathcal{R<em 1="1">{D A G}^{e}\left(\hat{X}, \theta</em>\right)\right)
$$}^{Y}, \theta_{r}^{Y}, \theta^{X</p>
<p>where $\gamma$ is the trade-off parameter and $\mathcal{R}<em 1="1">{D A G}^{e}\left(\hat{X}, \theta</em>\right)$ is the invariant structure constraint. We propose solving this problem with a second order Newton method, L-BFGS-B [58].}^{Y}, \theta_{r}^{Y}, \theta^{X</p>
<p>Algorithm 1: Supervised Invariant Structure Learning
Input: Dataset $\mathcal{D}$
Output: DAG, $Y$ predictor $f(X)=h \circ \theta_{1}^{Y}(X)$
1 Build $n$ environments $\epsilon_{\text {all }}$, for each $e \in \epsilon_{\text {all }}, \rho^{e}=1, \alpha^{e}=0, h^{e}(W)=\infty$.
2 Termination conditions $h(W)<em _max="\max">{t o l}=10^{-8}, \rho</em>$ with $i=0$.
3 while $i<N_{M A X}$ and $\max _{e \in \epsilon_{a l i}}\left(h^{e}(W)\right)>h(W)}=10^{16}$, max iteration as $N_{M A X<em _epsilon__a="\epsilon_{a" _in="\in" e="e" i="i" l="l">{t o l}$ and $\min </em>$ do
$\mathrm{i}+=1$
4 for $e=1$ to $n$ do
$\left{\begin{array}{l}\text { Calculate } R^{e}\left(h \circ \theta_{1}^{Y}(X)\right) \text { and } \mathcal{R}}}\left(\rho^{e}\right)&lt;\rho_{\max <em 1="1">{D A G}^{e}\left(\hat{X}, \theta</em>\right.$
5 Summarize DAG from $\theta_{1}$
6 Fix all trainable parameters in Eq. 3 except $h$, fine-tune $h$ and obtain final $f(X)=h \circ \theta_{1}^{Y}(X)$.}^{Y}, \theta_{e}^{Y}, \theta^{X}\right) \text { in Eq. } 2 \ \text { Update } h, \theta_{1}^{Y}, \theta_{e}^{Y}, \theta_{e}^{Y}, \theta^{X} \text { with L-BFGS-B [58]; } \ \text { Calculate } W \text { from } \theta_{1}^{Y} ; \text { Update } h^{e}(W) ; \text { Update } \rho^{e} \text { and } \alpha^{e}\end{array</p>
<p>Algorithm 1 summarizes the training procedure. After DAG learning converges at all environments, we obtain the invariant structure of $Y$ prediction by first computing $Y$-related columns in adjacency matrix $W$ from shared $\theta_{1}^{Y}$, and then using a threshold to select the learned $P a(Y)$ ( $Y$-related DAG). For the final target, we fix all parameters in Eq. 3 except $h(\cdot)$, and fine-tune $h(\cdot)$. To obtain the overall DAG for the entire dataset, we aggregate the DAG across different environments by keeping only the overlapping edges across all environments.</p>
<h1>3.3 Generalizing to self-supervised setting</h1>
<p>In many scenarios, the target labels aren't available, rendering self-supervised causal graph discovery as an paramount problem. Conventional functional causal models, such as NOTEARS, aim to find a trade-off between three objectives, which are optimal to SEM: $X=X W$, whilst $W$ should both resemble a DAG and be sparse (see Eq. (3)). As all variables aren't distinguishable with equal importance, there is no prior knowledge about which nodes should be the source or target nodes. Due to the large variance among node distribution caused by variable semantic meaning, reconstruction accuracy driven learning is unstable, and sensitive to the variable distribution - some variables can be described using a simple distribution, while others may be hard to estimate due to the differences in data source. It can lead to a local minima, causing the learned DAG deviate from the real causal structure [23]. We propose a two-step DAG learning approach, as shown in Fig. 3.
Step 1. Invariant causality proposal: We first build multiple environments. Then, we iteratively set each node as $Y$ (Fig. 3) and run ISL to propose the invariant structure for $Y$ as candidate causal parents. ISL keeps the invariant variables that are important to prediction of $Y$ under the overall DAG
<img alt="img-2.jpeg" src="img-2.jpeg" />
(a) Step 1: Iteratively set each variable as target and propose an invariant structure for each variable.
<img alt="img-3.jpeg" src="img-3.jpeg" />
(b) Step 2: Aggregate all proposed causal parents for each variable into a single graph (may not be a DAG), then adjust the activation ability of DNN by de-activating all parameters that are related to the non-proposed edges, and lastly optimize Eq. 2 to obtain final DAG.</p>
<p>Figure 3: ISL in self-supervised setting. Algorithmic details are provided in the Appendix.</p>
<p>constrain. As such, the learned invariant structure corresponds to either true causal parents of $Y$ or the variables which have strong correlation with $Y$, thus treated as candidate of causal parents of $Y$ ).</p>
<p>Step 2. Constrained graph discovery: We aggregate the candidate causal parents of each variable in Step 1 and form an aggregated graph (Fig. 3), where there are bi-direction edges, which isn't allowed in a DAG. We can build a $(d+1) \times(d+1)$ binary adjacency matrix $W$ to represent the graph where $d+1$ represent the number of nodes. $j$-th column of $W$ represent the potential causal parents of node $j$. As described in Sec. 3.2, during DAG learning, for each variable $X_{j}$, we use a DNN $\theta^{j}$ to reconstruct $X_{j}$ given other variables. There is a corresponding mapping between the $j$-th column of $W$ and the first layer $\theta_{1}^{j}$ of DNN $\theta^{j}$ : the $k$-th row in the parameter matrix of $\theta_{1}^{j}$ encode the contribution of node $k$ to node $j$, which associate with the value of $\left[W_{k, j}\right]$. To narrow down the search space, if $\left[W_{k, j}\right]$ is 0 (node $k$ aren't potential causal parent of node $j$ summarized from Step 1), we deactivate the corresponding parameter by fixing the value of $k$-th row in $\theta_{1}^{j}$ as 0 . if $\left[W_{k, j}\right]$ is 1 , we don't add weight constraint to the first layer $\theta_{1}^{j}$ in the DAG. This is to narrow down the search space that help the DAG learning. We use the parameter modification as a constraint on DAG learning and run a constrained version of DAG learning (Eq. 2) to obtain the final DAG.
Algorithm. 2 summarizes the detailed pseudo code of the proposed two-stage DAG learning in self-supervised setting.</p>
<div class="codehilite"><pre><span></span><code><span class="nx">Algorithm</span><span class="w"> </span><span class="mi">2</span><span class="p">:</span><span class="w"> </span><span class="k">Self</span><span class="o">-</span><span class="nx">Supervised</span><span class="w"> </span><span class="nx">Invariant</span><span class="w"> </span><span class="nx">Structure</span><span class="w"> </span><span class="nx">Learning</span>
<span class="nx">Input</span><span class="p">:</span><span class="w"> </span><span class="nx">Dataset</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathcal</span><span class="p">{</span><span class="nx">D</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="nx">Output</span><span class="p">:</span><span class="w"> </span><span class="nx">DAG</span>
<span class="w">    </span><span class="err">\#</span><span class="w"> </span><span class="nx">Step</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="nx">Invariant</span><span class="w"> </span><span class="nx">causality</span><span class="w"> </span><span class="nx">proposal</span>
<span class="mi">1</span><span class="w"> </span><span class="nx">Build</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">n</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">environments</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">epsilon_</span><span class="p">{</span><span class="err">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="nx">all</span><span class="w"> </span><span class="p">}}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">2</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">X_</span><span class="p">{</span><span class="nx">i</span><span class="p">}=</span><span class="nx">X_</span><span class="p">{</span><span class="mi">1</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">X_</span><span class="p">{</span><span class="nx">d</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">do</span>
<span class="w">    </span><span class="nx">Set</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">Y</span><span class="p">=</span><span class="nx">X_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">run</span><span class="w"> </span><span class="nx">algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">(</span><span class="nx">main</span><span class="w"> </span><span class="nx">manuscript</span><span class="p">),</span><span class="w"> </span><span class="nx">select</span><span class="w"> </span><span class="nx">only</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">P</span><span class="w"> </span><span class="nx">a</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="nx">X_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="err">\#</span><span class="w"> </span><span class="nx">Step</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="nx">Constrained</span><span class="w"> </span><span class="nx">graph</span><span class="w"> </span><span class="nx">discovery</span>
<span class="mi">3</span><span class="w"> </span><span class="nx">Aggregate</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">operatorname</span><span class="p">{</span><span class="nx">Pa</span><span class="p">}</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="nx">X_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">each</span><span class="w"> </span><span class="nx">variable</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">form</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">initial</span><span class="w"> </span><span class="nx">graph</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">G</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">may</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">DAG</span><span class="p">).</span>
<span class="mi">4</span><span class="w"> </span><span class="nx">Summarize</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">initial</span><span class="w"> </span><span class="nx">adjacency</span><span class="w"> </span><span class="nx">matrix</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">W</span><span class="o">^</span><span class="p">{</span><span class="err">\</span><span class="nx">prime</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">5</span><span class="w"> </span><span class="nx">Add</span><span class="w"> </span><span class="nx">weight</span><span class="w"> </span><span class="kd">constraint</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">theta</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">based</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">W</span><span class="o">^</span><span class="p">{</span><span class="err">\</span><span class="nx">prime</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">6</span><span class="w"> </span><span class="nx">Run</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="nx">mining</span><span class="w"> </span><span class="p">(</span><span class="nx">Eq</span><span class="p">.</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">main</span><span class="w"> </span><span class="nx">manuscript</span><span class="p">)</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">optimize</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">theta</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">yield</span><span class="w"> </span><span class="nx">DAG</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">describe</span><span class="w"> </span><span class="nx">the</span>
<span class="w">    </span><span class="nx">approximated</span><span class="w"> </span><span class="nx">causal</span><span class="w"> </span><span class="nx">structure</span><span class="p">.</span>
</code></pre></div>

<h1>4 Experiments</h1>
<p>In this section, we evaluate the proposed ISL framework for causal explainability and better generalization. We conduct extensive experiments in two settings based on the availability of target labels: supervised learning tasks in Sec. 4.1 and self-supervised learning tasks in Sec. 4.2. Details and more results are provided in the Appendix.</p>
<p>Baselines: On causal explainability, we choose NOTEARS-MLP [57] as the baseline for learning the SCM which represented as a DAG. On target prediction, we choose a standard MLP and CASTLE [25] as the baseline methods.</p>
<p>Metrics: We evaluate the estimated Y-related DAG and whole DAG structure using Structural Hamming Distance (SHD): the number of missing, falsely detected or reversed edges, lower the better. We evaluate the target ( $Y$ ) prediction accuracy in Mean Squared Error (MSE). We compute SHD and the errors for multiple times and report the mean value.</p>
<h3>4.1 Supervised learning tasks</h3>
<h3>4.1.1 Synthetic data</h3>
<p>We first examine the performance of ISL in accurately discoverying the casual structure, as well as the target prediction performance using synthetic tabular datasets with known casual structure information as well as the target labels. We aim to mimic challenging scenarios encountered for data generation and collection processes in real world, that the data may consist of samples from different</p>
<p>Table 1: Synthetic tabular data experiments in supervised learning setting. Note that black-box MLP and CASTLE cant provide DAGs. ISL yields lower MSE for ID and OOD, and lower SHD.</p>
<table>
<thead>
<tr>
<th>Number of nodes</th>
<th>Metrics</th>
<th>MLP</th>
<th>NOTEARS-MLP</th>
<th>CASTLE</th>
<th>ISL (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td>$3(\mathrm{c}=2, \mathrm{~s}=1)$</td>
<td>ID MSE / OOD MSE</td>
<td>0.008 / 0.016</td>
<td>0.090 / 0.191</td>
<td>0.012 / 0.020</td>
<td>$\mathbf{0 . 0 0 5}$ / $\mathbf{0 . 0 1 0}$</td>
</tr>
<tr>
<td></td>
<td>Average SHD</td>
<td>-</td>
<td>2</td>
<td>-</td>
<td>$\mathbf{0}$</td>
</tr>
<tr>
<td>$4(\mathrm{c}=2, \mathrm{~s}=2)$</td>
<td>ID MSE / OOD MSE</td>
<td>0.006 / 0.014</td>
<td>0.082 / 0.152</td>
<td>0.019 / 0.032</td>
<td>$\mathbf{0 . 0 0 6}$ / $\mathbf{0 . 0 0 9}$</td>
</tr>
<tr>
<td></td>
<td>Average SHD</td>
<td>-</td>
<td>2</td>
<td>-</td>
<td>$\mathbf{0}$</td>
</tr>
<tr>
<td>$5(\mathrm{c}=3, \mathrm{~s}=2)$</td>
<td>ID MSE / OOD MSE</td>
<td>0.004 / 0.004</td>
<td>0.093 / 0.060</td>
<td>0.020 / 0.016</td>
<td>$\mathbf{0 . 0 0 4}$ / $\mathbf{0 . 0 0 4}$</td>
</tr>
<tr>
<td></td>
<td>Average SHD</td>
<td>-</td>
<td>3</td>
<td>-</td>
<td>$\mathbf{0}$</td>
</tr>
<tr>
<td>$9(\mathrm{c}=4, \mathrm{~s}=5)$</td>
<td>ID MSE / OOD MSE</td>
<td>0.006 / 0.031</td>
<td>0.061 / 0.174</td>
<td>0.025 / 0.160</td>
<td>$\mathbf{0 . 0 0 5}$ / $\mathbf{0 . 0 0 5}$</td>
</tr>
<tr>
<td></td>
<td>Average SHD</td>
<td>-</td>
<td>4</td>
<td>-</td>
<td>$\mathbf{0}$</td>
</tr>
<tr>
<td>$20(\mathrm{c}=10, \mathrm{~s}=10)$</td>
<td>ID MSE / OOD MSE</td>
<td>0.008 / 0.018</td>
<td>0.051 / 0.251</td>
<td>0.137 / 0.252</td>
<td>$\mathbf{0 . 0 0 8}$ / $\mathbf{0 . 0 0 7}$</td>
</tr>
<tr>
<td></td>
<td>Average SHD</td>
<td>-</td>
<td>9</td>
<td>-</td>
<td>$\mathbf{1}$</td>
</tr>
</tbody>
</table>
<p>environment sources, while the target-related causal structure is consistent in the entire dataset (e.g., Fig. 1). We construct the synthetic datasets in the following way (more details in Appendix):</p>
<ul>
<li>Step 1: We randomly sample an initial DAG $G^{i}$ following Erdos-Renyi or Scale-Free schema with different edge densities. We randomly select one node (which isnt the source node) as the target $Y$. We calculate the number of causal parent nodes $C$ of $Y, c$. If $c&lt;c_{\text {min }}$, we randomly add $c_{\text {min }}-c$ number of nodes into $C$ as the causal parents of $Y$.</li>
<li>Step 2: To simulate the spurious correlations, we create $s \in[1, \ldots k]$ new nodes $S$, now we obtain the GT DAG $G$. For all nodes $X$ except $Y$ and $S$, we define an ANM $X=F(X)+\epsilon$ to generate data on top of $G$, where $F$ is a two-layer MLP and $\epsilon$ is the external noise. $Y$ is generated from its causal parents $C, Y \sim P(Y=1 \mid \operatorname{sigmoid}(G(C)+\epsilon)) . G$ can be either linear (uniformly random weight matrix) or non-linear (same initialization method as $F$ ).</li>
<li>Step 3: We (uniformly) randomly select the number of environments $e$ from [2, 5]). For each environment, all nodes (except for $s$ added spurious correlation nodes $S$ ) in the GT DAG $G$ follows the ANM (defined in Step 2) but with different random seed and noise term. For $S$, their correlation to $Y$ isnt invariant among environments and controlled by a continuous variable $r \in[0,1]$. Specifically, for each node $S_{i}$ in $S, S \sim P(S=1 \mid Y=1)=r=P(S=0 \mid Y=0)$.</li>
<li>Step 4: We generate two different kinds of test set: In-distribution (ID) and Out-of-distribution (OOD). ID test set uses the same value of $r$ as training set, while OOD test set uses uniformly random sampled $r$, which represents the unknown test environments.</li>
</ul>
<p>We generate different sizes of graphs with $5 c$ and $s$ combinations (see Table. 1) (10 datasets with 1000 samples for each environment). Table 1 shows that ISL significantly outperforms others for both $Y$ prediction and $Y$-related DAG learning. Particularly for OOD, the outperformance is more prominent, up to $83 \%$ decrease in MSE compared to black-box MLP and $96 \%$ decrease compared to CASTLE. This is attributed to more accurate casual graph discovery (evident from lower SHD), allowing to capture dynamics consistent between ID and OOD data, and hence generalize better.</p>
<p>Table 2: Synthetic tabular data counterfactual simulation experiments. MSE is shown for various counterfactual outcomes, obtained by modifying the 'counterfactual source' variables.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Counterfactual source</th>
<th style="text-align: center;">MLP</th>
<th style="text-align: center;">NOTEARS-MLP</th>
<th style="text-align: center;">CASTLE</th>
<th style="text-align: center;">ISL (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Causal parent X1</td>
<td style="text-align: center;">0.021</td>
<td style="text-align: center;">0.280</td>
<td style="text-align: center;">0.034</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 6}$</td>
</tr>
<tr>
<td style="text-align: left;">Causal parent X2</td>
<td style="text-align: center;">0.043</td>
<td style="text-align: center;">0.301</td>
<td style="text-align: center;">0.064</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 2}$</td>
</tr>
<tr>
<td style="text-align: left;">Spurious correlation S1</td>
<td style="text-align: center;">0.184</td>
<td style="text-align: center;">30.962</td>
<td style="text-align: center;">0.471</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 2}$</td>
</tr>
</tbody>
</table>
<p>Counterfactual simulations: Besides the accurate predictions for test data, causal structure discovery is also notable for its capability of accurate modeling of counterfactual outcomes, i.e. predicting how the output would change with certain input changes. To demonstrate this, we design experiments by modifying the dataset used above. We randomly select a node $X_{i}$ from causal parents set $C$ or spurious correlation set $S$ and change the value of $X_{i}$ while keeping the other nodes unmodified. Then, we test the prediction accuracy on this dataset. Table. 2 shows that ISL yields more accurate</p>
<p>counterfactual outcomes, compared to alternatives. Particularly when the counterfactual source is spurious correlation variables, baseline methods are much worse at outcome predictions.</p>
<h1>4.1.2 Real-world data</h1>
<p>We perform supervised learning experiments on real-world datasets with GT causal structure: Boston Housing [9, 1] and Insurance [9, 2] datasets. For each, we randomly split the train/validation/test with the proportion $0.8 / 0.1 / 0.1$. We do multiple experiments and show the averaged performance. We consider the accuracy for $Y$ prediction and target-related DAG (causal parents of $Y$ ) learning. Specifically, Boston Housing contains information collected by the U.S Census Service concerning housing in Boston. There are 14 attributes including 1 binary variable and 506 samples in which the median value of homes (MED) is to be predicted. For ISL, we first calculate the Within-Cluster-Sum of Squared (WSS) errors for different values of $k$, and choose the $k$ for which the WSS starts to diminish. Based on this, we build $k=2$ environments. We obtain the $Y$-related GT DAG of Boston Housing from [50, 55]. Insurance dataset is based on a network for car insurance risk estimation. The network has 27 nodes and 52 edges with 20000 samples. The Insurance dataset provides the GT causal structure as a DAG. Three of the observable nodes ('PropCost', 'LiabilityCost' and 'MedCost') are designated as 'outputs'. Besides the designated output, we add other variables 'CarValue' (based on the importance for the task) as the target as well. For ISL, similarly, we use K-means clustering to build $k=3$ different environments. Table. 4 summarizes the results for $Y$ prediction and $Y$-related causal structure learning. We observe that ISL significantly outperforms black-box MLP in all cases (up to $74 \%$ MSE reduction), as well as NOTEARS-MLP and CASTLE. Fig. 4 (a) shows the visualization of the learned Y-related DAG.</p>
<p>Table 3: Supervised learning experiments on real-world data. Note that MLP and CASTLE cannot provide DAGs (and thus don't have SHD).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">MSE ( $\downarrow$ )</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">SHD ( $\downarrow$ )</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Dataset</td>
<td style="text-align: center;">Target</td>
<td style="text-align: center;">MLP</td>
<td style="text-align: center;">NOTEARS-MLP</td>
<td style="text-align: center;">CASTLE</td>
<td style="text-align: center;">ISL (Ours)</td>
<td style="text-align: center;">NOTEARS-MLP</td>
<td style="text-align: center;">ISL (Ours)</td>
</tr>
<tr>
<td style="text-align: center;">Boston Housing</td>
<td style="text-align: center;">MED</td>
<td style="text-align: center;">0.16</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">Insurance</td>
<td style="text-align: center;">'PropCost'</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'MedCost'</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">1.03</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'LiabilityCost'</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'CarValue'</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>Impact of the number of environments: We investigate the impact of the number of environments on Boston Housing and synthetic data. Table 4 shows the clear value of having multiple environments - with only one, the invariant constraint is not effective, yielding worse results. Increasing the number of environments has diminishing returns. More ablation studies are provided in the Appendix.</p>
<p>Table 4: The impact of number of environments for ISL in supervised learning setting.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: center;">Target</th>
<th style="text-align: center;">Metric</th>
<th style="text-align: center;">ISL $(\mathrm{e}=1)$</th>
<th style="text-align: center;">ISL $(\mathrm{e}=2)$</th>
<th style="text-align: center;">ISL $(\mathrm{e}=7)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Boston Housing</td>
<td style="text-align: center;">MED</td>
<td style="text-align: center;">MSE / SHD</td>
<td style="text-align: center;">$0.067 / 5$</td>
<td style="text-align: center;">$0.051 / 1$</td>
<td style="text-align: center;">$0.051 / 1$</td>
</tr>
<tr>
<td style="text-align: left;">Synthetic data (Fig. 1)</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">MSE / SHD</td>
<td style="text-align: center;">$0.110 / 2$</td>
<td style="text-align: center;">$0.022 / 0$</td>
<td style="text-align: center;">$0.020 / 0$</td>
</tr>
</tbody>
</table>
<h3>4.2 Self-supervised learning</h3>
<p>For self-supervised learning tasks, there is no target variable, and the goal is to learn accurate SCM, represented as a DAG, that represent the underlying causal structure of given dataset. We conduct experiments on two real-world datasets: Sachs [40, 3] and Insurance [9, 2] datasets. Sachs dataset is for the discovery of protein signaling network on expression levels of different proteins and phospholipids in human cells [40], and is a popular benchmark for causal graph discovery, containing both observational and interventional data. The true causal graph from [40] contains 11 nodes and 17 edges. We conduct our two-stage DAG learning based on ISL by building 3 environments and compare the DAG results with different baselines. Table. 5 shows that ISL outperforms all other methods in correct discovery of the GT DAG on both Sachs and Insurance. On the challenging</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: Visualization of discovered causal structure in (a) supervised and (b) self-supervised settings. Blue solid arrows are overlapped edges between our results and GT, red solid arrow denotes the edges that we can identify but with wrong direction, green solid arrow denotes our proposed edge that GT doesn't have, yellow dash arrows denotes our missing edges that GT contains.</p>
<p>Table 5: Self-supervised causal graph discovery on Sachs and Insurance.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Method</th>
<th>Total <br> Edges</th>
<th>Correct <br> Edges ( $\uparrow$ )</th>
<th>SHD ( $\downarrow$ )</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sachs</td>
<td>RL-BIC [59]</td>
<td>10</td>
<td>7</td>
<td>11</td>
</tr>
<tr>
<td></td>
<td>GraN-DAG [26]</td>
<td>10</td>
<td>5</td>
<td>13</td>
</tr>
<tr>
<td></td>
<td>NOTEARS-MLP [57]</td>
<td>11</td>
<td>6</td>
<td>11</td>
</tr>
<tr>
<td></td>
<td>DAG-GNN [52]</td>
<td>15</td>
<td>6</td>
<td>16</td>
</tr>
<tr>
<td></td>
<td>GOLEM [32]</td>
<td>11</td>
<td>6</td>
<td>14</td>
</tr>
<tr>
<td></td>
<td>NOTEARS [56]</td>
<td>20</td>
<td>6</td>
<td>19</td>
</tr>
<tr>
<td></td>
<td>ICA-LiNGAM [43]</td>
<td>8</td>
<td>4</td>
<td>14</td>
</tr>
<tr>
<td></td>
<td>CAM [13]</td>
<td>10</td>
<td>6</td>
<td>12</td>
</tr>
<tr>
<td></td>
<td>DARING [16]</td>
<td>15</td>
<td>7</td>
<td>11</td>
</tr>
<tr>
<td></td>
<td>ISL (Ours)</td>
<td>12</td>
<td>$\mathbf{8}$</td>
<td>$\mathbf{8}$</td>
</tr>
<tr>
<td>Insurance</td>
<td>NOTEARS-MLP [57]</td>
<td>35</td>
<td>18</td>
<td>39</td>
</tr>
<tr>
<td></td>
<td>NOTEARS [56]</td>
<td>24</td>
<td>10</td>
<td>46</td>
</tr>
<tr>
<td></td>
<td>ISL (Ours)</td>
<td>46</td>
<td>$\mathbf{3 1}$</td>
<td>$\mathbf{2 7}$</td>
</tr>
</tbody>
</table>
<p>Insurance data, the number of corrected edges is $72 \%$ higher for ISL, compared to NOTEARS-MLP. Fig. 4 (b) shows the visualization of the learned DAG on Insurance dataset.</p>
<h1>5 Conclusions</h1>
<p>We propose a novel method, ISL, for accurate causal structure discovery. The ISL framework is based on splitting the training data into different environments and learning the structure that is invariant to the selected target. We demonstrate the effectiveness of ISL in both supervised and self-supervised learning settings. On synthetic and real-world datasets, we show that ISL yields more accurate causal structure discovery compared to alternatives, which also results in superior generalization, especially against severe distribution shifts.</p>
<h1>References</h1>
<p>[1] http://lib.stat.cmu.edu/datasets/boston.
[2] https://link.springer.com/article/10.1023/A:1007421730016.
[3] https://www.science.org/doi/full/10.1126/science. 1105809.
[4] Sercan O. Arik and Tomas Pfister. Tabnet: Attentive interpretable tabular learning, 2019.
[5] Martin Arjovsky, Lon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.
[6] Devansh Arpit, Stanisaw Jastrzbski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S. Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, and Simon Lacoste-Julien. A closer look at memorization in deep networks, 2017.
[7] Mohammad Taha Bahadori, Krzysztof Chalupka, Edward Choi, Robert Chen, Walter F Stewart, and Jimeng Sun. Causal regularization. arXiv preprint arXiv:1702.02604, 2017.
[8] Peter L. Bartlett, Andrea Montanari, and Alexander Rakhlin. Deep learning: a statistical viewpoint. Acta Numerica, 30:87-201, 2021.
[9] John Binder, Daphne Koller, Stuart Russell, and Keiji Kanazawa. Adaptive probabilistic networks with hidden variables. Machine Learning, 29(2):213-244, 1997.
[10] David Maxwell Chickering. Optimal structure identification with greedy search. Journal of machine learning research, 3(Nov):507-554, 2002.
[11] Alexander D'Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein, Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean, Diana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy, Rory Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie Webster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, and D. Sculley. Underspecification presents challenges for credibility in modern machine learning, 2020.
[12] Michel Fortin and Roland Glowinski. Augmented Lagrangian methods: applications to the numerical solution of boundary-value problems. Elsevier, 2000.
[13] Clark Glymour, Kun Zhang, and Peter Spirtes. Review of causal discovery methods based on graphical models. Frontiers in genetics, 10:524, 2019.
[14] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.
[15] Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. A survey of learning causality with data: Problems and methods. ACM Computing Surveys (CSUR), 53(4):1-37, 2020.
[16] Yue He, Peng Cui, Zheyan Shen, Renzhe Xu, Furui Liu, and Yong Jiang. Daring: Differentiable causal discovery with residual independence. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining, pages 596-605, 2021.
[17] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012.
[18] Arthur E Hoerl and Robert W Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1):55-67, 1970.
[19] Biwei Huang, Kun Zhang, Yizhu Lin, Bernhard Schlkopf, and Clark Glymour. Generalized score functions for causal discovery. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining, pages 1551-1560, 2018.</p>
<p>[20] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448-456. PMLR, 2015.
[21] Max Jaderberg, Karen Simonyan, Andrew Zisserman, and Koray Kavukcuoglu. Spatial transformer networks, 2015.
[22] Dominik Janzing. Causal regularization. Advances in Neural Information Processing Systems, 32, 2019.
[23] Marcus Kaiser and Maksim Sipos. Unsuitability of notears for causal graph discovery. arXiv preprint arXiv:2104.05441, 2021.
[24] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25, 2012.
[25] Trent Kyono, Yao Zhang, and Mihaela van der Schaar. Castle: Regularization via auxiliary causal graph discovery. Advances in Neural Information Processing Systems, 33:1501-1512, 2020.
[26] Sbastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon Lacoste-Julien. Gradientbased neural dag learning. arXiv preprint arXiv:1906.02226, 2019.
[27] Lei Le, Andrew Patterson, and Martha White. Supervised autoencoders: Improving generalization performance with unsupervised regularizers. Advances in neural information processing systems, 31, 2018.
[28] Bryan Lim, Sercan O. Arik, Nicolas Loeff, and Tomas Pfister. Temporal fusion transformers for interpretable multi-horizon time series forecasting, 2019.
[29] Stuart Lloyd. Least squares quantization in pcm. IEEE transactions on information theory, 28(2):129-137, 1982.
[30] Luis Moneda. Exploring invariance in machine learning 2: Invariant risk minimization. Blogpost at lgmoneda.github.io, 2021.
[31] Andrew Y Ng. Feature selection, 11 vs. 12 regularization, and rotational invariance. In Proceedings of the twenty-first international conference on Machine learning, page 78, 2004.
[32] Ignavier Ng, AmirEmad Ghassami, and Kun Zhang. On the role of sparsity and dag constraints for learning linear dags. Advances in Neural Information Processing Systems, 33:17943-17954, 2020.
[33] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio, 2016.
[34] Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural networks. In International conference on machine learning, pages 1310-1318. PMLR, 2013.
[35] Judea Pearl. Causal inference in statistics: An overview. Statistics surveys, 3:96-146, 2009.
[36] Judea Pearl et al. Models, reasoning and inference. Cambridge, UK: CambridgeUniversityPress, 19:2, 2000.
[37] Jonas Peters, Joris M Mooij, Dominik Janzing, and Bernhard Schlkopf. Causal discovery with continuous additive noise models. 2014.
[38] Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural Information Processing Systems, 32, 2019.
[39] Peter J Rousseeuw. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. Journal of computational and applied mathematics, 20:53-65, 1987.</p>
<p>[40] Karen Sachs, Omar Perez, Dana Pe'er, Douglas A Lauffenburger, and Garry P Nolan. Causal protein-signaling networks derived from multiparameter single-cell data. Science, 308(5721):523-529, 2005.
[41] Bernhard Schlkopf. Causality for Machine Learning, page 765-804. Association for Computing Machinery, New York, NY, USA, 1 edition, 2022.
[42] Lukas Schott, Julius von Kgelgen, Frederik Truble, Peter Gehler, Chris Russell, Matthias Bethge, Bernhard Schlkopf, Francesco Locatello, and Wieland Brendel. Visual representation learning does not generalize strongly within the same domain, 2021.
[43] Shohei Shimizu, Patrik O Hoyer, Aapo Hyvrinen, Antti Kerminen, and Michael Jordan. A linear non-gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006.
[44] Donghee Shin. The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable ai. International Journal of Human-Computer Studies, 146:102551, 2021.
[45] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.
[46] Peter L Spirtes, Christopher Meek, and Thomas S Richardson. Causal inference in the presence of latent variables and selection bias. arXiv preprint arXiv:1302.4983, 2013.
[47] Robert L Thorndike. Who belongs in the family. In Psychometrika. Citeseer, 1953.
[48] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1):267-288, 1996.
[49] Stefan Wager, Sida Wang, and Percy S Liang. Dropout training as adaptive regularization. Advances in neural information processing systems, 26, 2013.
[50] Wenjuan Wei and Lu Feng. Nonlinear causal structure learning for mixed data. In 2021 IEEE International Conference on Data Mining (ICDM), pages 709-718. IEEE, 2021.
[51] Larry Yaeger, Richard Lyon, and Brandyn Webb. Effective training of a neural network character classifier for word recognition. Advances in neural information processing systems, 9, 1996.
[52] Yue Yu, Jie Chen, Tian Gao, and Mo Yu. Dag-gnn: Dag structure learning with graph neural networks. In International Conference on Machine Learning, pages 7154-7163. PMLR, 2019.
[53] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning (still) requires rethinking generalization. Commun. ACM, 64(3):107-115, feb 2021.
[54] Daniel Zhang, Saurabh Mishra, Erik Brynjolfsson, John Etchemendy, Deep Ganguli, Barbara Grosz, Terah Lyons, James Manyika, Juan Carlos Niebles, Michael Sellitto, Yoav Shoham, Jack Clark, and Raymond Perrault. The ai index 2021 annual report, 2021.
[55] Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Schlkopf. Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775, 2012.
[56] Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. Dags with no tears: Continuous optimization for structure learning. Advances in Neural Information Processing Systems, 31, 2018.
[57] Xun Zheng, Chen Dan, Bryon Aragam, Pradeep Ravikumar, and Eric Xing. Learning sparse nonparametric dags. In International Conference on Artificial Intelligence and Statistics, pages 3414-3425. PMLR, 2020.
[58] Ciyou Zhu, Richard H Byrd, Peihuang Lu, and Jorge Nocedal. Algorithm 778: L-bfgs-b: Fortran subroutines for large-scale bound-constrained optimization. ACM Transactions on mathematical software (TOMS), 23(4):550-560, 1997.
[59] Shengyu Zhu, Ignavier Ng, and Zhitang Chen. Causal discovery with reinforcement learning. arXiv preprint arXiv:1906.04477, 2019.</p>
<h1>Appendix</h1>
<h2>A Synthetic data creation</h2>
<p>The details of synthetic dataset creation are described below:</p>
<ul>
<li>Step 1: We randomly sample an initial DAG $G^{\prime}$ following Erdos-Renyi or Scale-Free schema with different edge densities. We randomly select one node (which isn't the source node) as the target $Y$. We calculate the number of causal parent nodes $C$ of $Y, c$. If $c&lt;c_{\text {min }}$, we randomly add $c_{\text {min }}-c$ number of nodes into $C$ as the causal parents of $Y$.</li>
<li>Step 2: To simulate the spurious correlations, we create $s \in[1, \ldots k]$ new nodes $S$, and these nodes act as causal descendants of $Y$. After defining the causal parents and descendants of $Y$, now we obtain the GT DAG $G$. For all nodes $X$ except $Y$ and $S$, we define an ANM $X=F(X)+\epsilon$ to generate data on top of $G$, where $F$ is a two-layer MLP whose parameters are uniformly sampled from $(-2,-0.5) \cup(0.5,2) . \epsilon$ is the external noise which is randomly sampled from Gaussian, Exponential and Uniform. $Y$ is generated from its causal parents $C$, $Y \sim P(Y=1 \mid \operatorname{sigmoid}(G(C)+\epsilon)) . G$ can be either linear (uniformly random weight matrix) or non-linear (same initialization method as $F$ ).</li>
<li>Step 3: We randomly select the number of environments $e$ from the uniform distribution of [2, 5]. For each environment, all nodes (except for $s$ added spurious correlation nodes $S$ ) in the GT DAG $G$ follows the ANM (defined in Step 2) but with different random seed and noise term. For $S$, their correlation to $Y$ isn't invariant among environments and controlled by a continuous variable $r \in[0,1]$. Specifically, for each node $S_{i}$ in $S, S \sim P(S=1 \mid Y=1)=r=P(S=0 \mid Y=0)$.</li>
<li>Step 4: We generate two different kinds of test set: In-distribution (ID) and Out-of-distribution (OOD). Both have the same number of environments with the training set. ID test set uses the same value of $r$ as training set, while OOD test set uses uniformly random sampled $r$, which represents the unknown test environments. $S \sim P(S=\hat{g}(Y) \mid Y)=r, P(S \sim$ random variable $)=1-\mathrm{r}$.</li>
</ul>
<h2>B Selection of ISL hyperparameters</h2>
<p>Thresholds: As described in Sec. 3.2 and Algorithm 1, after Eq. 3 converges at all environments, we employ a threshold $t$ to convert the adjacency matrix $W$ to a DAG. To find a proper threshold, we use the following strategy. We set a minimum edges number $E_{\text {min }}$ and a maximum edges number $E_{\text {max }}$ based on the dataset information. Usually, $E_{\text {min }}$ is half of the number of nodes $|E| / 2$ and $E_{\text {max }}$ is $5|E|$. We also set a range of threshold $t \in\left[t_{\text {min }}, t_{\text {max }}\right]$ and a step size $t_{s}$ base on the value range of $W$. Usually we use $t_{\text {min }}=\min (W)$ and $t_{\text {max }}=\max (W)$. Then, we employ a grid search over the range $\left[t_{\text {min }}, t_{\text {max }}\right]$ with a step size $t_{s}$, and keep the thresholds and corresponding DAG that satisfied the following requirements: (1) The graph after the filtering with threshold should be a DAG (no cyclicity). (2) The number of graph edges $E_{\text {min }}&lt;E&lt;E_{\text {max }} \mid$. For the selected threshold values and DAGs, we remove the duplicated group as different threshold may obtain the same DAG, which further refines the interval. Then, for each threshold, we use the selected $P a(Y)$ as input to train a one-layer MLP to predict $Y$ and select the threshold $t$ that has smallest $Y$ reconstruction error in the validation set.</p>
<p>Regularization coefficients: For training of ISL, we use different loss terms. The hyperparameter $\gamma$ controls the trade off between $Y$ reconstruction and DAG constrain among environments. As we decrease the value of $\gamma$, the training would focus more on the target $Y$ reconstruction. We also have 4 regularization hyperparameters: $\mathcal{L}<em 1="1">{\text {sparse }}(\theta)=\beta</em>\right|}\left|\theta_{1}^{\mathrm{T}<em 2="2">{1}+\beta</em>\right|}\left|\theta_{i}^{\mathrm{T}<em 3="3">{2}+\beta</em>\right|}\left|\theta^{\mathrm{X}<em 4="4">{1}+\beta</em>\right|}\left|\theta^{\mathrm{X}<em 1="1">{2}$, where $|\cdot|</em>$ and $|\cdot|<em 1="1">{2}$ denote $l</em>=0.01$ as reasonable choices across many different settings, although they are not extensively optimized.}$ and $l_{2}$ regularization. $\beta_{1}$ controls the importance of the $l_{1}$ regularization on the $\theta_{1}^{\mathrm{T}}$, increasing $\beta_{1}$ makes the selection of $P a(Y)$ more conservative (most of the values of the first column in $W$ would be zero). $\beta_{2}$ helps avoid overfitting of $h(\cdot) . \beta_{3}$ and $\beta_{4}$ controls the regularization on $\theta^{X}$. We choose the value of $\gamma$ and $\beta_{i}$ that achieves the smallest target Y reconstruction on the validation set. We find the parameters: $\gamma=1 ; \beta_{1}=0.001 ; \beta_{2}=0.01 ; \beta_{3}=0.01 ; \beta_{4</p>
<p>Table. 6 shows the results on Boston Housing for the prediction target of median value of homes (MED) ISL with different regression parameters. We demonstrate that the results are not too sensitive to the change of regularization. That is because the regularization coefficients mainly influence the DAG learning process, and we apply fine-tuning for $h(\cdot)$ after convergence of DAG learning, which provides a mechanism to mitigate the differences at the first training stage.</p>
<p>Table 6: Boston Housing median value of homes (MED) target prediction results by ISL with different regression parameters.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">$\gamma$</th>
<th style="text-align: center;">$\beta_{1}$</th>
<th style="text-align: center;">$\beta_{2}$</th>
<th style="text-align: center;">$\beta_{3}$</th>
<th style="text-align: center;">$\beta_{4}$</th>
<th style="text-align: center;">MSE $(\downarrow)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.052</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.054</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.057</td>
</tr>
</tbody>
</table>
<h1>C Building environments</h1>
<p>To show the efficacy of the proposed unsupervised environment building method based on k-means clustering, we present comparisons to the setting with the environment building based on known data source information, i.e. the data comes with the indication on how the environments are split based on data collection or generation process. Table. 7 shows that their difference is quite small (much smaller than the outperformance of ISL compared to the other methods) and the proposed ISL is highly effective and robust with unsupervised environment building by clustering.</p>
<p>Table 7: Unsupervised vs. supervised environment building for ISL on synthetic data. We observe very small difference between them, showing the efficacy of the proposed unsupervised environment construction mechanism.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Number of nodes</th>
<th style="text-align: center;">Metrics $(\downarrow)$</th>
<th style="text-align: center;">Supervised</th>
<th style="text-align: center;">Unsupervised</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$3(\mathrm{c}=2, \mathrm{~s}=1)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.005 \pm 0.0001$</td>
<td style="text-align: center;">$0.005 \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.010 \pm 0.0002$</td>
<td style="text-align: center;">$0.010 \pm 0.0002$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0 \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$4(\mathrm{c}=2, \mathrm{~s}=2)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.006 \pm 0.0002$</td>
<td style="text-align: center;">$0.006 \pm 0.0002$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.009 \pm 0.0001$</td>
<td style="text-align: center;">$0.009 \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0 \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$5(\mathrm{c}=3, \mathrm{~s}=2)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.004 \pm 0.0001$</td>
<td style="text-align: center;">$0.004 \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.004 \pm 0.0001$</td>
<td style="text-align: center;">$0.004 \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0 \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$9(\mathrm{c}=4, \mathrm{~s}=5)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.004 \pm 0.0006$</td>
<td style="text-align: center;">$0.004 \pm 0.0006$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.005 \pm 0.0001$</td>
<td style="text-align: center;">$0.005 \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">$0 \pm 0$</td>
<td style="text-align: center;">$0 \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$20(\mathrm{c}=10, \mathrm{~s}=10)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.007 \pm 0.0005$</td>
<td style="text-align: center;">$0.009 \pm 0.0005$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.007 \pm 0.0001$</td>
<td style="text-align: center;">$0.061 \pm 0.009$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$2 \pm 1$</td>
</tr>
</tbody>
</table>
<h2>D Error statistics</h2>
<p>In this section, we present the standard deviations for the errors to highlight the statistical significance of ISL improvements (Table. 8 and Table. 9). Overall, the improvements of ISL are much larger than the standard deviation values. In addition, the variance of performance is observed to be lower for ISL compared to the other methods, indicating its superiority in robustness.</p>
<h2>E Limitations and the societal impact</h2>
<p>In this paper, we propose a novel method for causal structure discovery, which can improve the explainability and generalization of key machine learning use cases. Lack of their explainability remains to be a bottleneck for widespread adoption of DNNs for many high-stakes applications, such as from Healthcare, Finance, Public Sector, Insurance, Legal etc. There are other forms of explainability methods used in practice, but since they cannot explicitly distinguish the causality from the correlations, there are many cases that they cannot satisfy the high bar for explainability in such applications. We believe that our method constitutes an important contribution towards this, as it can</p>
<p>Table 8: Supervised learning experiment results on real-world data along with their standard deviations. Note that MLP and CASTLE cannot provide DAGs (and thus don't have SHD values).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">MSE ( $\downarrow$ )</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">SHD ( $\downarrow$ )</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Dataset</td>
<td style="text-align: center;">Target</td>
<td style="text-align: center;">MLP</td>
<td style="text-align: center;">NOTEARS-MLP</td>
<td style="text-align: center;">CASTLE</td>
<td style="text-align: center;">ISL (Ours)</td>
<td style="text-align: center;">NOTEARS-MLP</td>
<td style="text-align: center;">ISL (Ours)</td>
</tr>
<tr>
<td style="text-align: center;">Boston Housing</td>
<td style="text-align: center;">MED</td>
<td style="text-align: center;">$0.16 \pm 0.02$</td>
<td style="text-align: center;">$0.12 \pm 0.03$</td>
<td style="text-align: center;">$0.10 \pm 0.01$</td>
<td style="text-align: center;">$\mathbf{0 . 0 5} \pm 0.008$</td>
<td style="text-align: center;">$2 \pm 0$</td>
<td style="text-align: center;">$\mathbf{1} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">Insurance</td>
<td style="text-align: center;">'PropCost'</td>
<td style="text-align: center;">$0.40 \pm 0.02$</td>
<td style="text-align: center;">$0.99 \pm 0.02$</td>
<td style="text-align: center;">$0.36 \pm 0.001$</td>
<td style="text-align: center;">$\mathbf{0 . 3 4} \pm 0.004$</td>
<td style="text-align: center;">$2 \pm 0$</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'MedCost'</td>
<td style="text-align: center;">$0.69 \pm 0.09$</td>
<td style="text-align: center;">$1.03 \pm 0.01$</td>
<td style="text-align: center;">$0.55 \pm 0.03$</td>
<td style="text-align: center;">$\mathbf{0 . 5 2} \pm 0.002$</td>
<td style="text-align: center;">$2 \pm 1$</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'LiabilityCost'</td>
<td style="text-align: center;">$0.94 \pm 0.08$</td>
<td style="text-align: center;">$0.39 \pm 0.01$</td>
<td style="text-align: center;">$0.38 \pm 0.06$</td>
<td style="text-align: center;">$\mathbf{0 . 2 5} \pm 0.0004$</td>
<td style="text-align: center;">$1 \pm 0$</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">'CarValue'</td>
<td style="text-align: center;">$0.23 \pm 0.01$</td>
<td style="text-align: center;">$0.60 \pm 0.05$</td>
<td style="text-align: center;">$0.23 \pm 0.03$</td>
<td style="text-align: center;">$\mathbf{0 . 2 3} \pm 0.0004$</td>
<td style="text-align: center;">$2 \pm 0$</td>
<td style="text-align: center;">$\mathbf{1} \pm 0$</td>
</tr>
</tbody>
</table>
<p>Table 9: Synthetic tabular data experiments in supervised learning setting. Note that black-box MLP and CASTLE can't provide DAGs. ISL yields lower MSE for ID and OOD, and lower SHD.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Number of nodes</th>
<th style="text-align: center;">Metrics $(\downarrow)$</th>
<th style="text-align: center;">MLP</th>
<th style="text-align: center;">NOTEARS-MLP</th>
<th style="text-align: center;">CASTLE</th>
<th style="text-align: center;">ISL (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$3(\mathrm{c}=2, \mathrm{~s}=1)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.008 \pm 0.002$</td>
<td style="text-align: center;">$0.101 \pm 0.010$</td>
<td style="text-align: center;">$0.016 \pm 0.007$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 5} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.016 \pm 0.002$</td>
<td style="text-align: center;">$0.195 \pm 0.005$</td>
<td style="text-align: center;">$0.017 \pm 0.004$</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 0} \pm 0.0002$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$2 \pm 0$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$4(\mathrm{c}=2, \mathrm{~s}=2)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.006 \pm 0.009$</td>
<td style="text-align: center;">$0.087 \pm 0.005$</td>
<td style="text-align: center;">$0.017 \pm 0.002$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 6} \pm 0.0002$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.040 \pm 0.022$</td>
<td style="text-align: center;">$0.174 \pm 0.024$</td>
<td style="text-align: center;">$0.036 \pm 0.010$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 9} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$2 \pm 0$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$5(\mathrm{c}=3, \mathrm{~s}=2)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.004 \pm 0.002$</td>
<td style="text-align: center;">$0.110 \pm 0.018$</td>
<td style="text-align: center;">$0.025 \pm 0.006$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 4} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.004 \pm 0.002$</td>
<td style="text-align: center;">$0.078 \pm 0.020$</td>
<td style="text-align: center;">$0.019 \pm 0.004$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 4} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$3 \pm 0$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$9(\mathrm{c}=4, \mathrm{~s}=5)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.012 \pm 0.006$</td>
<td style="text-align: center;">$0.070 \pm 0.010$</td>
<td style="text-align: center;">$0.034 \pm 0.010$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 4} \pm 0.0006$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.052 \pm 0.024$</td>
<td style="text-align: center;">$0.201 \pm 0.028$</td>
<td style="text-align: center;">$0.152 \pm 0.022$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 5} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$4 \pm 0$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{0} \pm 0$</td>
</tr>
<tr>
<td style="text-align: center;">$20(\mathrm{c}=10, \mathrm{~s}=10)$</td>
<td style="text-align: center;">ID MSE</td>
<td style="text-align: center;">$0.009 \pm 0.008$</td>
<td style="text-align: center;">$0.061 \pm 0.011$</td>
<td style="text-align: center;">$0.121 \pm 0.021$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 7} \pm 0.0005$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">OOD MSE</td>
<td style="text-align: center;">$0.094 \pm 0.061$</td>
<td style="text-align: center;">$0.303 \pm 0.050$</td>
<td style="text-align: center;">$0.272 \pm 0.046$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 7} \pm 0.0001$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Average SHD</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$9 \pm 0$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$\mathbf{1} \pm 0$</td>
</tr>
</tbody>
</table>
<p>be directly adopted to applications where obtaining accurate causal explanations is crucial. In some cases, causal explanations can uncover the undesired biases in the data such as when the dominant factor for the output label comes from one of the features that corresponds to a sensitive attribute such as gender. In these cases, the causal explanations can be further validated with additional analyses (as our model is still far away from achieving the perfect SHD of 0 on complex real-world data with many features), and if they seem to be convincing, further data manipulation or model debiasing actions can be performed. In addition to causal explainability, the improved generalization aspect is expected to play a major positive role, as the distribution differences between training and testing settings can sometimes hinder the reliability of machine learning models. In some applications where the data collection is limited to certain locations or times or subsets, our method can be utilized to enhance the performance of the trained models when they are deployed to operate for different locations or times or subsets.</p>
<p>Overall, we believe there is significant room for improvement in causal structure discovery. Especially for complex real-world data with many features, the obtained SHD values are not very low in the literature. Further research in unsupervised environment building with better representation learning, end-to-end approaches in combining graph discovery and supervised learning, and adding more nonlinearity to the model to make it higher capacity in a systematic way, can be promising towards this direction. We demonstrate the robustness of our model in various settings, but further exploration of theoretical convergence guarantee can be useful as well. Lastly, methods to improve hyperparameter tuning and model selection with small validation data, without relying on ground truth causal graph structure, would be of high value.</p>            </div>
        </div>

    </div>
</body>
</html>