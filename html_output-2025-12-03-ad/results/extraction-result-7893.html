<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7893 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7893</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7893</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-144.html">extraction-schema-144</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-85391ba692f1962f61c79f58d68f13229f8a8f51</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/85391ba692f1962f61c79f58d68f13229f8a8f51" target="_blank">ALCM: Autonomous LLM-Augmented Causal Discovery Framework</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms, and underscores new research directions in leveraging the causal reasoning capabilities of LLMs.</p>
                <p><strong>Paper Abstract:</strong> To perform effective causal inference in high-dimensional datasets, initiating the process with causal discovery is imperative, wherein a causal graph is generated based on observational data. However, obtaining a complete and accurate causal graph poses a formidable challenge, recognized as an NP- hard problem. Recently, the advent of Large Language Models (LLMs) has ushered in a new era, indicating their emergent capabilities and widespread applicability in facilitating causal reasoning across diverse domains, such as medicine, finance, and science. The expansive knowledge base of LLMs holds the potential to elevate the field of causal reasoning by offering interpretability, making inferences, generalizability, and uncovering novel causal structures. In this paper, we introduce a new framework, named Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize data-driven causal discovery algorithms and LLMs, automating the generation of a more resilient, accurate, and explicable causal graph. The ALCM consists of three integral components: causal structure learning, causal wrapper, and LLM-driven causal refiner. These components autonomously collaborate within a dynamic environment to address causal discovery questions and deliver plausible causal graphs. We evaluate the ALCM framework by implementing two demonstrations on seven well-known datasets. Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms. This study not only shows the effectiveness of the ALCM but also underscores new research directions in leveraging the causal reasoning capabilities of LLMs.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7893.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7893.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALCM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous LLM-Augmented Causal Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-component framework that combines conventional data-driven causal discovery algorithms with large language models (LLMs) to iteratively generate, validate, and refine causal graphs from observational data using contextual prompts and LLM reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>ALCM: Autonomous LLM-Augmented Causal Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ALCM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ALCM first constructs an initial causal graph using conventional causal discovery algorithms (PC, LiNGAM, NOTEARS or a hybrid). The graph is converted into contextual, causal-aware prompts by a Causal Wrapper and sent to an LLM-driven Refiner (e.g., GPT-4), which validates, reorients, removes, or adds edges and provides confidence estimates; iterative feedback yields a refined causal DAG.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Tabular observational datasets (variables/nodes), metadata/contextual descriptions, and the initial causal graph produced by classical causal discovery algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured causal graph (causal DAG) with edge orientations and optional confidence scores and textual explanations</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Causal-aware prompting that injects Instruction + Causal Context + Metadata + Question + Output format; optionally uses Chain-of-Thought (CoT) style reasoning and requests confidence estimates</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (used in experiments); framework supports other LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Seven benchmark datasets from BN repository and others: Asia, Cancer, Child, Insurance, Neuropathic, Sachs, Sangiovese</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1-score, Accuracy, Normalized Hamming Distance (NHD)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>ALCM implementations (ALCM-PC and ALCM-Hybrid) outperformed pure LLM baselines and conventional algorithms; ALCM-Hybrid achieved best results (e.g., accuracy up to 98.18% and NHD as low as 0.0122 on Neuropathic dataset; accuracy up to 96.6% on Asia), showing improved precision, recall, F1 and lower NHD compared to baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on LLM implicit knowledge which can overgeneralize or hallucinate leading to spurious edges; LLM-only approaches suffer scalability and precision problems; ALCM still depends on quality of initial data-driven graph and correct prompt engineering; model sizes/costs and domain coverage affect performance.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ALCM: Autonomous LLM-Augmented Causal Discovery Framework', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7893.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7893.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-driven Refiner</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-driven Refiner component of ALCM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A component that accepts contextualized prompts derived from an initial causal graph and uses an LLM to validate, reorient, remove, or add causal edges, detect hidden relationships, and attach confidence scores and textual rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>ALCM: Autonomous LLM-Augmented Causal Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM-driven Refiner</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each candidate edge or node the refiner receives a causal-aware prompt (instructions, algorithm context, metadata, question, desired output format) and uses the LLM to (1) assess validity, (2) detect hidden/unobserved influences, (3) reorient/remove/add edges, and (4) provide confidence/likelihood estimates; outputs are parsed and re-integrated into the causal graph.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Initial causal graph edges/nodes plus contextual metadata and dataset descriptions packaged as textual prompts</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Refined causal graph edits (add/remove/reorient edges), confidence scores and textual explanations/reasoning traces</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Causal-aware prompting; optionally Chain-of-Thought (CoT) style stepwise reasoning; explicit request for confidence or likelihood estimates; structured output format to facilitate NLP parsing</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (used in the paper's pipeline and ablations), other LLMs tested in ALCM-Hybrid experiments (Llama3.1, Gemma2, Mistral variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Same benchmark datasets used for ALCM experiments: Asia, Cancer, Child, Insurance, Neuropathic, Sachs, Sangiovese</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Effect on downstream graph metrics: Precision, Recall, F1-score, Accuracy, Normalized Hamming Distance (NHD); also qualitative confidence/language outputs</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>When integrated into ALCM, the LLM-driven Refiner improved graph metrics substantially relative to LLM-only and conventional baselines; e.g., ALCM-PC and ALCM-Hybrid that used GPT-4 refinements achieved large gains in precision/F1 and reductions in NHD.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>LLM refiner may introduce spurious edges by overgeneralization; relies on careful prompt design and post-processing/parsing of textual LLM outputs; potential brittleness across domains and sensitivity to LLM capability/size.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ALCM: Autonomous LLM-Augmented Causal Discovery Framework', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7893.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7893.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM pairwise causal prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based pairwise causal relationship prediction methods</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods that use LLMs to predict causal direction or presence between pairs of variables (A causes B?) using prompt-based queries and LLM knowledge, typically operating pairwise rather than producing full causal graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>ALCM: Autonomous LLM-Augmented Causal Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LLM pairwise causal prediction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompt LLMs with variable pairs (and optional context/metadata) to elicit judgments about causal direction or association; results aggregated to form pairwise causal judgments or used as priors/constraints for causal discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Variable names/descriptions, possibly sample statistics or short textual context; typically not full corpora but structured prompts for each variable pair</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Pairwise causal judgments (e.g., A->B, B->A, no causal link) often as textual labels or structured tokens</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Prompting and few-shot examples; direct question-answering per pair; sometimes aggregated with majority voting or calibration</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Mentioned generally (no specific corpus in this paper); evaluated on the same benchmark graph datasets for performance comparison in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Pairwise precision/recall, and how these pairwise outputs affect graph-level metrics (F1, NHD) when aggregated</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Paper reports that pure LLM pairwise approaches show scalability and precision problems: they often overgeneralize, leading to lower precision and higher NHD compared to hybrid/ALCM approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Poor scalability to full graph construction, lower precision and structural fidelity, tendency to overgeneralize/spurious edges, limited ability to reason about multivariate conditional independencies without auxiliary data-driven algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ALCM: Autonomous LLM-Augmented Causal Discovery Framework', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7893.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7893.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CORR2CAUSE fine-tuning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-tuning LLMs on the CORR2CAUSE benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced line of work that fine-tunes language models on the CORR2CAUSE dataset to improve LLM ability to distinguish causal statements from correlational ones.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>ALCM: Autonomous LLM-Augmented Causal Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Fine-tuning on CORR2CAUSE</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fine-tune LLMs on labeled datasets (CORR2CAUSE) that exemplify causal vs correlational statements to improve discrimination of causal language and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Text pairs/statements labeled for causal vs correlational relation (CORR2CAUSE dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>A fine-tuned LLM better able to classify or generate causal statements / judgments</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Fine-tuning (supervised) possibly combined with few-shot prompting at inference</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>CORR2CAUSE (benchmark dataset cited in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-specific classification metrics (e.g., accuracy, precision/recall on causal vs correlational labeling) — not detailed in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Mentioned as prior work to empower LLM causal reasoning; no quantitative results provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Fine-tuning on text benchmarks may not confer multivariate causal discovery capabilities from observational data and may not scale to full graph construction.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ALCM: Autonomous LLM-Augmented Causal Discovery Framework', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7893",
    "paper_id": "paper-85391ba692f1962f61c79f58d68f13229f8a8f51",
    "extraction_schema_id": "extraction-schema-144",
    "extracted_data": [
        {
            "name_short": "ALCM",
            "name_full": "Autonomous LLM-Augmented Causal Discovery Framework",
            "brief_description": "A multi-component framework that combines conventional data-driven causal discovery algorithms with large language models (LLMs) to iteratively generate, validate, and refine causal graphs from observational data using contextual prompts and LLM reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
            "authors": "Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani",
            "year": null,
            "method_name": "ALCM",
            "method_description": "ALCM first constructs an initial causal graph using conventional causal discovery algorithms (PC, LiNGAM, NOTEARS or a hybrid). The graph is converted into contextual, causal-aware prompts by a Causal Wrapper and sent to an LLM-driven Refiner (e.g., GPT-4), which validates, reorients, removes, or adds edges and provides confidence estimates; iterative feedback yields a refined causal DAG.",
            "input_type": "Tabular observational datasets (variables/nodes), metadata/contextual descriptions, and the initial causal graph produced by classical causal discovery algorithms",
            "output_type": "Structured causal graph (causal DAG) with edge orientations and optional confidence scores and textual explanations",
            "prompting_technique": "Causal-aware prompting that injects Instruction + Causal Context + Metadata + Question + Output format; optionally uses Chain-of-Thought (CoT) style reasoning and requests confidence estimates",
            "model_name": "GPT-4 (used in experiments); framework supports other LLMs",
            "model_size": null,
            "datasets_used": "Seven benchmark datasets from BN repository and others: Asia, Cancer, Child, Insurance, Neuropathic, Sachs, Sangiovese",
            "evaluation_metric": "Precision, Recall, F1-score, Accuracy, Normalized Hamming Distance (NHD)",
            "reported_results": "ALCM implementations (ALCM-PC and ALCM-Hybrid) outperformed pure LLM baselines and conventional algorithms; ALCM-Hybrid achieved best results (e.g., accuracy up to 98.18% and NHD as low as 0.0122 on Neuropathic dataset; accuracy up to 96.6% on Asia), showing improved precision, recall, F1 and lower NHD compared to baselines.",
            "limitations": "Relies on LLM implicit knowledge which can overgeneralize or hallucinate leading to spurious edges; LLM-only approaches suffer scalability and precision problems; ALCM still depends on quality of initial data-driven graph and correct prompt engineering; model sizes/costs and domain coverage affect performance.",
            "counterpoint": true,
            "uuid": "e7893.0",
            "source_info": {
                "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "LLM-driven Refiner",
            "name_full": "LLM-driven Refiner component of ALCM",
            "brief_description": "A component that accepts contextualized prompts derived from an initial causal graph and uses an LLM to validate, reorient, remove, or add causal edges, detect hidden relationships, and attach confidence scores and textual rationales.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
            "authors": "Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani",
            "year": null,
            "method_name": "LLM-driven Refiner",
            "method_description": "For each candidate edge or node the refiner receives a causal-aware prompt (instructions, algorithm context, metadata, question, desired output format) and uses the LLM to (1) assess validity, (2) detect hidden/unobserved influences, (3) reorient/remove/add edges, and (4) provide confidence/likelihood estimates; outputs are parsed and re-integrated into the causal graph.",
            "input_type": "Initial causal graph edges/nodes plus contextual metadata and dataset descriptions packaged as textual prompts",
            "output_type": "Refined causal graph edits (add/remove/reorient edges), confidence scores and textual explanations/reasoning traces",
            "prompting_technique": "Causal-aware prompting; optionally Chain-of-Thought (CoT) style stepwise reasoning; explicit request for confidence or likelihood estimates; structured output format to facilitate NLP parsing",
            "model_name": "GPT-4 (used in the paper's pipeline and ablations), other LLMs tested in ALCM-Hybrid experiments (Llama3.1, Gemma2, Mistral variants)",
            "model_size": null,
            "datasets_used": "Same benchmark datasets used for ALCM experiments: Asia, Cancer, Child, Insurance, Neuropathic, Sachs, Sangiovese",
            "evaluation_metric": "Effect on downstream graph metrics: Precision, Recall, F1-score, Accuracy, Normalized Hamming Distance (NHD); also qualitative confidence/language outputs",
            "reported_results": "When integrated into ALCM, the LLM-driven Refiner improved graph metrics substantially relative to LLM-only and conventional baselines; e.g., ALCM-PC and ALCM-Hybrid that used GPT-4 refinements achieved large gains in precision/F1 and reductions in NHD.",
            "limitations": "LLM refiner may introduce spurious edges by overgeneralization; relies on careful prompt design and post-processing/parsing of textual LLM outputs; potential brittleness across domains and sensitivity to LLM capability/size.",
            "counterpoint": true,
            "uuid": "e7893.1",
            "source_info": {
                "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "LLM pairwise causal prediction",
            "name_full": "LLM-based pairwise causal relationship prediction methods",
            "brief_description": "Methods that use LLMs to predict causal direction or presence between pairs of variables (A causes B?) using prompt-based queries and LLM knowledge, typically operating pairwise rather than producing full causal graphs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
            "authors": "Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani",
            "year": null,
            "method_name": "LLM pairwise causal prediction",
            "method_description": "Prompt LLMs with variable pairs (and optional context/metadata) to elicit judgments about causal direction or association; results aggregated to form pairwise causal judgments or used as priors/constraints for causal discovery.",
            "input_type": "Variable names/descriptions, possibly sample statistics or short textual context; typically not full corpora but structured prompts for each variable pair",
            "output_type": "Pairwise causal judgments (e.g., A-&gt;B, B-&gt;A, no causal link) often as textual labels or structured tokens",
            "prompting_technique": "Prompting and few-shot examples; direct question-answering per pair; sometimes aggregated with majority voting or calibration",
            "model_name": null,
            "model_size": null,
            "datasets_used": "Mentioned generally (no specific corpus in this paper); evaluated on the same benchmark graph datasets for performance comparison in experiments",
            "evaluation_metric": "Pairwise precision/recall, and how these pairwise outputs affect graph-level metrics (F1, NHD) when aggregated",
            "reported_results": "Paper reports that pure LLM pairwise approaches show scalability and precision problems: they often overgeneralize, leading to lower precision and higher NHD compared to hybrid/ALCM approaches.",
            "limitations": "Poor scalability to full graph construction, lower precision and structural fidelity, tendency to overgeneralize/spurious edges, limited ability to reason about multivariate conditional independencies without auxiliary data-driven algorithms.",
            "counterpoint": true,
            "uuid": "e7893.2",
            "source_info": {
                "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "CORR2CAUSE fine-tuning",
            "name_full": "Fine-tuning LLMs on the CORR2CAUSE benchmark",
            "brief_description": "A referenced line of work that fine-tunes language models on the CORR2CAUSE dataset to improve LLM ability to distinguish causal statements from correlational ones.",
            "citation_title": "",
            "mention_or_use": "mention",
            "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
            "authors": "Elahe Khatibi, Mahyar Abbasian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani",
            "year": null,
            "method_name": "Fine-tuning on CORR2CAUSE",
            "method_description": "Fine-tune LLMs on labeled datasets (CORR2CAUSE) that exemplify causal vs correlational statements to improve discrimination of causal language and reasoning.",
            "input_type": "Text pairs/statements labeled for causal vs correlational relation (CORR2CAUSE dataset)",
            "output_type": "A fine-tuned LLM better able to classify or generate causal statements / judgments",
            "prompting_technique": "Fine-tuning (supervised) possibly combined with few-shot prompting at inference",
            "model_name": null,
            "model_size": null,
            "datasets_used": "CORR2CAUSE (benchmark dataset cited in the paper)",
            "evaluation_metric": "Task-specific classification metrics (e.g., accuracy, precision/recall on causal vs correlational labeling) — not detailed in this paper",
            "reported_results": "Mentioned as prior work to empower LLM causal reasoning; no quantitative results provided in this paper.",
            "limitations": "Fine-tuning on text benchmarks may not confer multivariate causal discovery capabilities from observational data and may not scale to full graph construction.",
            "counterpoint": null,
            "uuid": "e7893.3",
            "source_info": {
                "paper_title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.0133085,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>ALCM: Autonomous LLM-Augmented Causal Discovery Framework</h1>
<p>Elahe Khatibi ${ }^{1}$, Mahyar Abbasian ${ }^{1}$, Zhongqi Yang ${ }^{1}$, Iman Azimi ${ }^{1}$, and Amir M. Rahmani ${ }^{1,2}$<br>${ }^{1}$ Department of Computer Science, University of California, Irvine, USA<br>${ }^{2}$ School of Nursing, University of California, Irvine, USA</p>
<h4>Abstract</h4>
<p>To perform effective causal inference in high-dimensional datasets, initiating the process with causal discovery is imperative, wherein a causal graph is generated based on observational data. However, obtaining a complete and accurate causal graph poses a formidable challenge, recognized as an NPhard problem. Recently, the advent of Large Language Models (LLMs) has ushered in a new era, indicating their emergent capabilities and widespread applicability in facilitating causal reasoning across diverse domains, such as medicine, finance, and science. The expansive knowledge base of LLMs holds the potential to elevate the field of causal reasoning by offering interpretability, making inferences, generalizability, and uncovering novel causal structures. In this paper, we introduce a new framework, named Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize data-driven causal discovery algorithms and LLMs, automating the generation of a more resilient, accurate, and explicable causal graph. The ALCM consists of three integral components: causal structure learning, causal wrapper, and LLM-driven causal refiner. These components autonomously collaborate within a dynamic environment to address causal discovery questions and deliver plausible causal graphs. We evaluate the ALCM framework by implementing two demonstrations on seven well-known datasets. Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms. This study not only shows the effectiveness of the ALCM but also underscores new research directions in leveraging the causal reasoning capabilities of LLMs.</p>
<p>Keywords: Large Language Models; Causal Reasoning; Causal Graph; Causal Discovery;</p>
<h2>1 Introduction</h2>
<p>The process of causal discovery, essential in various domains and scientific discoveries, seeks to reveal complex causal relationships in observational data [31, 32, 13]. For instance, in healthcare, this process is crucial and instrumental for pinpointing disease etiologies, devising effective interventions, and prevention strategies [49]. Subsequently, causal inference allows for the quantification of the influence exerted by different variables on one another, once a causal structure is identified. This phase, often referred to as causal estimation, relies on the construction of a preliminary causal</p>
<p>graph, which, despite its theoretical significance, poses considerable practical challenges, demanding substantial domain-specific expertise. In fact, studies using real-world datasets demonstrate that inferring causal graphs-which is the focus of this paper-from data is still a complex challenge in practical applications $[34,42,6]$. Causal discovery and causal inference, as highlighted in seminal works by Pearl and others [31, 32, 23, 13], are two key components of causal reasoning to address causal questions in diverse fields.</p>
<p>Within the literature, numerous studies have contributed significantly to the development of a variety of efficient causal discovery algorithms aimed at uncovering the underlying causal structure from observational data. This body of research can be broadly categorized into two main groups: conventional data-driven causal discovery algorithms and those based on LLMs [44]. Conventional causal discovery algorithms focus on learning the causal graph from samples of the joint probability distribution of observational data. They utilize various statistical techniques, including conditional independence tests, machine learning approaches, generative models, deep learning methodologies, and reinforcement learning strategies [35] to understand the joint distribution of observed variables and extract the causal connections among them. Subsequently, these algorithms assess how well the candidate causal graph aligns with the data [49, 14, 13].</p>
<p>Conventional causal discovery algorithms, despite being designed to be powerful and scalable, face several challenges. These include a heavy dependence on domain experts [12], who are often limited and inconsistent, and the issues of data bias, imbalance, and inadequacy which affect the accuracy of capturing true probability distributions [6]. Additionally, the use of static data can compromise model accuracy in dynamic environments, and the task of fully determining edge orientations is hindered by the presence of multiple equivalent Directed Acyclic Graphs (DAGs) $[6,35]$, which exponentially increase with the number of nodes [51], leading to inaccuracies and unreliability in the estimated causal graphs.</p>
<p>Recent advancements in Large Language Models (LLMs) have significantly impacted artificial intelligence, exhibiting notable reasoning capabilities [20, 45, 9, 22, 4]. These achievements stem from the extensive data used for training LLMs, essential for effective causal reasoning [20, 9]. However, current LLM-based causal reasoning research, mainly focusing on pairwise analysis, faces scalability issues as it struggles with the complexity of full causal graph construction and handling large datasets [43, 20, 6, 7, 30]. These models often fall short in accurately and efficiently inferring comprehensive causal relationships, especially in large-scale settings [7, 6, 23, 18]. Despite some efforts to integrate LLMs with causal discovery processes [43, 7, 39], challenges remain due to inherent limitations and the complexity of causal inference. A synergistic approach combining LLMs with other methods may provide a more nuanced and complete understanding of causal mechanisms and address these challenges effectively.</p>
<p>In this paper, we present an LLM-powered causal discovery framework-ALCM: a multi-component Autonomous LLM-Augmented Causal Discovery Framework. ALCM proposes a synergized reasoning method and entails three components: causal structure learning, causal wrapper, and LLMdriven refiner components to generate more accurate and robust causal graphs. ALCM is engineered to autonomously untangle causal structures by deciphering those causal relations embedded in observational data. ALCM capitalizes on observed data, data-driven causal reasoning algorithms, and the implicit knowledge embedded in LLMs to optimize and streamline the entire causal reasoning process. This approach aims to establish a more robust, applicable, and reliable foundation for causal reasoning and estimation as well. We conduct a comprehensive performance evaluation of ALCM, employing LLMs and assessing their capabilities on widely recognized benchmarks [36, 42]. We compare our framework with conventional causal discovery algorithms and LLMs prompting.</p>
<p>Furthermore, we implement an automatic pipeline for making the causal discovery an automatic task. Our contributions are as follows:</p>
<p>Our contributions in this work are as follows:</p>
<ul>
<li>Unified Framework for Enhanced Causal Discovery: We introduce the ALCM framework that synergistically integrates the strengths of conventional data-driven causal discovery (CCD) methods and Large Language Models (LLMs) to overcome the limitations of individual approaches by generating accurate, interpretable, and comprehensive causal graphs.</li>
<li>Dynamic, Scalable, and Autonomous Operations: ALCM demonstrates adaptability to dynamic data environments, autonomous operation without domain expertise dependency, and scalability across unseen datasets.</li>
<li>Improved Predictive Precision and Reliability: Leveraging the contextual reasoning capabilities of LLMs, the framework refines causal relationships with algorithmic rigor.</li>
<li>Comprehensive Graph Representation and Explainability: ALCM provides a fully automated pipeline for constructing and refining causal graphs. It ensures interpretability and explainability of results.</li>
<li>Benchmarking and Performance Validation: We extensively evaluate ALCM across multiple benchmark datasets, demonstrating its superior performance compared to the related works.</li>
</ul>
<p>This work advances the field of causal discovery by demonstrating the transformative potential of a unified framework that synthesizes the complementary capabilities of CCD and LLM-based approaches.</p>
<h1>2 Background and Related Work</h1>
<p>In this section, we outline the existing research on causal structure learning within the literature, delineating it into two primary groups: 1) Conventional data-driven causal discovery algorithms; and 2) Using LLMs for causal discovery.</p>
<p>1) Conventional data-driven causal discovery algorithms: conventional data-driven causal discovery algorithms are broadly classified into five categories as follows:</p>
<ul>
<li>
<p>Score-Based Algorithms: They operate on scores and engage in a comprehensive exploration of the entire space of potential Directed Acyclic Graphs (DAGs) to identify the most suitable graph for explaining the underlying data. Typically, such score-based approaches consist of two integral components: (i) a systematic search strategy tasked with navigating through the potential search states or the space of candidate graphs, denoted as G', and (ii) a score function designed to evaluate the viability of these candidate causal graphs. The synergy between the search strategy and the score function is instrumental in optimizing the exploration of all conceivable DAGs. A widely employed score function in the selection of causal models is the Bayesian Information Criterion (BIC) [14]. Some examples of scorebased algorithms are Greedy Equivalence Search (GES) [11], Fast Greedy Search (FGS) [33], and A* Search [48].</p>
</li>
<li>
<p>Constraint-Based Algorithms: This category, exemplified by Peter-Clark (PC) [38] algorithm, employs conditional independence (CI) tests to reveal the graph's skeleton and vstructures, ultimately returning the Directed Acyclic Graph (DAG) of the functional causal model while considering v-structures and doing edge-orientations [14]. Other constraint-bsaed algorithms are like Fast Causal Inference (FCI), Anytime FCI, RFCI, PC-stable, and so forth.</p>
</li>
<li>Hybrid Algorithms: Hybrid approaches are founded on the integration of various causal discovery methods, combining constraint-based, score-based, Functional Causal Model (FCM)based, gradient-based, and other techniques. This amalgamation reflects a comprehensive strategy that leverages the strengths of different methodologies to enhance the robustness and effectiveness of causal discovery in complex systems. Max-Min Hill Climbing (MMHC) [40]belonging to this category-stands out as a hybrid causal discovery technique that seamlessly integrates principles from both score-based and constraint-based algorithms. This hybrid approach combines the advantages of scoring methods and constraint-based strategies, offering a comprehensive and effective framework for uncovering causal relationships in complex systems.</li>
<li>Function-Based Algorithms: Approaches grounded in Functional Causal Models (FCM) delineate the causal connections between variables within a defined functional structure. In FCMs, variables are expressed as functions of their direct causes (parents), augmented by an independent noise term denoted as E. The distinguishing feature of FCM-based methodologies lies in their capacity to differentiate between various Directed Acyclic Graphs (DAGs) within the same equivalence class. This discrimination is achieved by introducing supplementary assumptions concerning data distributions and/or function classes. Several notable FCM-based causal discovery methodologies are introduced, including Linear Non-Gaussian Acyclic Model (LiNGAM) [37] and Structural Agnostic Modeling (SAM) [19]. SAM employs an adversarial learning methodology for causal graph identification. Specifically, SAM utilizes Generative Adversarial Neural Networks (GANs) to seek a Functional Causal Model (FCM) while ensuring the detection of sparse causal graphs through the incorporation of appropriate regularization terms. The optimization process involves a learning criterion that integrates distribution estimation, sparsity considerations, and acyclicity constraints. This holistic criterion facilitates end-to-end optimization of both the graph structure and associated parameters, accomplished through stochastic gradient descent.
The previous three-mentioned categories may be limited to the Markov equivalence class, posing constraints. Function-based algorithms like LiNGAM [44] aim to uniquely identify causal DAGs by exploiting data generative process asymmetries or causal footprints.</li>
<li>Optimization-Based Algorithms: Recent investigations in causal discovery have approached the structure learning problem by casting it as a continuous optimization task, employing the least squares objective and an algebraic representation of Directed Acyclic Graphs (DAGs). Notably, this transformation converts the combinatorial nature of the structure learning problem into a continuous framework, and solutions are obtained through the application of gradient-based optimization techniques. These methods exploit the gradients of an objective function concerning the parameterization of a DAG matrix to achieve effective structure learning. NOTEARS [51] is among the causal discovery algorithms that formulate the structure learning problem as a purely continuous constrained optimization task.</li>
</ul>
<p>2) Using LLM for causal discovery task: Leveraging recent advancements in LLMs and Natural Language Processing (NLP) presents an opportunity to offer enhanced capabilities in capturing causal concepts and relations while handling large-scale datasets more effectively [26, 10, 27]. This proficiency is rooted in the extensive training LLMs undergo on vast, high-quality datasets [18]. LLMs possess the ability to establish a comprehensive knowledge base across diverse domains, facilitating language understanding, ensuring generalizability, automating the causal reasoning pipeline, and enabling plausible reasoning. In this regard, the second group, namely using LLMs for causal discovery, is introduced. This group is classified into three major groups as follows:</p>
<ul>
<li>Fine-tuning: This category mainly focuses on fine-tuning LLMs to empower LLMs with causal-and-effect knowledge and address the causal reasoning challenges [17, 2, 16]. For instance, Jin et al. [17] introduce the CORR2CAUSE benchmark dataset on which they fine-tune their model. This is done to both asses and empower LLMs with causal reasoning ability. In fact, CORR2CAUSE dataset serves as a tool to evaluate the proficiency of LLMs in discerning causal relationships, particularly when the LLMs are fine-tuned to distinguish causation from correlational statements in the context of NLP.</li>
<li>Performance Evaluation: The second category focuses on using LLM for causal discovery and delves into emerging research that explores the causal analysis capabilities of Large Language Models. In contrast to causal discovery algorithms relying on statistical patterns in the data, this group utilizes LLMs to discover causal structures from variables. A majority of these methods solely utilize LLMs to predict pairwise causal relationships among a given set of variables $[47,24,20,41,30,6,50]$.</li>
<li>Prior or Posterior Knowledge: In the third category, focused on employing LLMs, the objective is either to assign direction to undirected edges generated by causal discovery algorithms or to impose constraints on the edge orientation and functionality of these algorithms. $[7,6,43]$.</li>
</ul>
<p>Despite these efforts from conventional data-driven causal discovery algorithms to propose robust, precise, adaptable, efficient, and scalable causal discovery algorithms, encountered limitations and inefficiencies persist. These challenges are as follows. 1) Real-world data, often sparse and insufficient for accurately capture authentic probability distributions [6]. 2) Sole reliance on precollected static data introduces accuracy risks, particularly when models must adapt to dynamic real-world data and unforeseen factors. 3) Inferring complete edge orientations from observed data is hindered by the existence of equivalent Directed Acyclic Graphs (DAGs) [6, 35]. 4) Algorithm dependence on domain knowledge experts, who may be scarce, time/resource-intensive, or exhibit variable quality across domains [12]. 5) Traditional causal discovery algorithms fall short in answering user-submitted causal questions due to a lack of proficiency in language understanding and processing. These challenges collectively contribute to diminished accuracy, incompleteness, and unreliability in the estimated causal graph.</p>
<p>On the other hand, significant advances have been made in utilizing LLMs for causal tasks. However, their inherent limitations in precision and complexity handling remain evident. These challenges are highlighted as follows. 1) LLMs inherently lack the precision necessary for accurately responding to complex, user-generated causal queries [41]. 2) LLMs are limited in their ability to dissect and comprehend nuanced causal concepts without additional data-driven causal reasoning algorithms. 3) There is a challenge in constructing complete causal graphs and unraveling intricate causal relations due to the oversimplified understanding of LLMs. 4) LLMs struggle</p>
<p>with handling extensive datasets, often failing to capture the depth and variability within them. These issues collectively hinder the effectiveness of LLMs in accurately and reliably determining causal relationships. Consequently, data-driven causal reasoning algorithms assume a critical role in mitigating the limitations of LLMs in causal tasks, offering nuanced comprehension of causal concepts, unraveling intricate causal relations, constructing complete causal graphs, and handling extensive datasets.</p>
<p>In light of these considerations, a unified, comprehensive causal framework that integrates LLMs with data-driven conventional causal discovery algorithms is required. To address this need, we propose the development of ALCM. ALCM aims to enhance the robustness and accuracy of causal discoveries by leveraging the conventional causal discovery algorithms and LLMs.</p>
<p>Table 1 indicates the capabilities of two distinct causal discovery methods-Conventional datadriven Causal Discovery (CCD), LLMs-based approaches, and ALCM framework-across essential functional attributes. Dynamic Data Adaptability [23, 5, 50] is the capability of a method to adjust to changing data, while Detection of Hidden Variables [23, 50] refers to identifying unobserved influencers within the dataset. Comprehensive Graph Model Representation [6] assesses the completeness of the depicted causal structure, and Predictive Accuracy [20, 39, 23, 43, 41, 30, 50] measures the success in forecasting the correct causal relations. CCD methods are limited by their reliance on pre-defined statistical models as well as domain knowledge expert validation, lacking adaptability to dynamic data, generalizability [20, 15] to unseen data, autonomy, and lack of accuracy. Similarly, while LLMs are adept at dynamicity of data, generalizability, and detecting hidden variables, they fall short in providing comprehensive graph model representations, interpretability, explainability, autonomy, and precision for causal discovery task. ALCM combining these strengths while enhancing user independence from expert validation [20] and interpretability [8] in causal discovery.</p>
<p>Table 1: Comparative Analysis of CCD, LLMs, and ALCM across Key Functional Attributes</p>
<table>
<thead>
<tr>
<th>Descriptive Attribute</th>
<th>CCD $^{1}$</th>
<th>LLMs</th>
<th>ALCM</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dynamic Data Adaptability</td>
<td>$\times$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Detection of Hidden Variables</td>
<td>$\times$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Comprehensive Graph Model Representation</td>
<td>$\checkmark$</td>
<td>$\times$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Predictive Accuracy</td>
<td>$\times$</td>
<td>$\times$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Autonomous Operation</td>
<td>$\times$</td>
<td>$\times$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Generalizability to Unseen Data</td>
<td>$\times$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Autonomous Expert Validation</td>
<td>$\times$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>Interpretability and Explainability</td>
<td>$\checkmark$</td>
<td>$\times$</td>
<td>$\checkmark$</td>
</tr>
</tbody>
</table>
<p>${ }^{1}$ CCD methods often rely on pre-defined statistical models and assumptions about the data generation process. ${ }^{2}$ LLMs-based methods may utilize vast amounts of data and natural language processing to infer causal relationships, potentially incorporating domain expertise. ${ }^{3}$ ALCM synthesizes the strengths of both CCDs and LLMs to uncover causal connections.</p>
<h1>3 Proposed Framework</h1>
<p>In this section, we present ALCM, an advanced causal discovery framework aimed to leverage the combined strengths of traditional causal discovery algorithms and LLMs. ALCM provide an automated pipeline constructing a comprehensive causal graph, refining it, and incorporating previously overlooked insights to enrich the resulting causal model. This integration aims to utilize the precision of conventional causal discovery algorithms in identifying data relationships, while also enhancing and validating these findings with insights from LLMs. Fig. 1 indicates an overview of the ALCM framework. The algorithmic perspective of the ALCM framework is detailed in Algorithm 1. The ALCM framework includes three principal components: Causal Structure Learning, Causal Wrapper, and LLM-driven Refiner. These components interact iteratively to enhance the causal discovery process, to clarify the functionality and definitions of the framework, we present and exemplify these components and their interconnections in the following.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: ALCM Architecture</p>
<h3>3.1 Causal Structure Learning</h3>
<p>The Causal Structure Learning component serves as the foundational data-driven module of the ALCM framework, responsible for generating the initial causal graph from observational datasets. This component identifies causal relationships among variables by analyzing probabilistic dependencies and independencies in the data, leveraging well-established conventional causal discovery methods. These methods typically infer causal graphs by estimating relationships between variables (nodes) and their potential causal links (edges), using statistical tests to determine conditional independencies and distinguish direct relationships from those mediated by other variables. Additionally, orientation rules are applied to establish causal directions, guided by assumptions such as</p>
<h1>Algorithm 1 ALCM</h1>
<p>Require: Observed dataset, $O$; Contextual Causal Information, $C$; Metadata, $M$
Ensure: Causal DAG, $D A G$
1: Initialize and run the selected data-driven causal discovery algorithm, $C D$, to generate an initial causal graph $G_{i} \leftarrow C D(O) \quad \triangleright$ Step 1: Generate the initial causal graph from observational data.
2: Generate the causal prompt by injecting $C$ and $M \triangleright$ Step 2: Prepare contextual information for refinement by LLM.
3: for each edge $z=\left(e_{i}, e_{j}\right)$ in $G_{i}$ do
4: if $z$ is validated by LLM-Driven Refiner then $\triangleright$ Step 3: Validate the existence of the causal edge using the LLM.</p>
<p>$$
G_{i} \leftarrow G_{i} \cup \emptyset
$$</p>
<p>$\triangleright$ If valid, retain the edge.
end if
7: if $z$ orientation is revised by LLM-Driven Refiner then $\triangleright$ Step 4: Adjust the edge direction if required.</p>
<p>$$
G_{i} \leftarrow z^{\prime} \cup G_{i}
$$</p>
<p>9: end if
10: if $z$ is removed by LLM-Driven Refiner then $\triangleright$ Step 5: Remove the edge if deemed invalid.</p>
<p>$$
G_{i} \leftarrow G_{i}-z^{\prime}
$$</p>
<p>12: end if
13: if a new edge $z^{\prime \prime}$ is added by LLM-Driven Refiner then $\quad \triangleright$ Step 6: Add a new edge identified by the LLM.</p>
<p>$$
G_{i} \leftarrow z^{\prime \prime} \cup G_{i}
$$</p>
<p>15: end if
16: end for
17: Return $G_{i}$</p>
<p>acyclicity or specific properties of the data distribution. Optimization techniques, including scoring functions-based methods (e.g., Bayesian Information Criterion (BIC) or likelihood-based scores), might be used to refine graph structures and select the most plausible causal model. To enhance robustness, the causal structure learning component integrates complementary methods to account for diverse data characteristics, such as linearity, non-linearity, or Gaussianity. The output of this component is an initial causal graph encapsulating key variables (nodes) and their inferred causal relationships (edges). The causal structure learning component directly influences the accuracy and reliability of both the final causal graph and future causal inferences drawn from the data.</p>
<p>For the implementation, we utilize three established causal discovery algorithms-Peter-Clark (PC) [38], Linear Non-Gaussian Acyclic Model (LiNGAM) [37], and Non-combinatorial Optimization via Trace Exponential and Augmented lagRangian for Structure learning (NOTEARS) [51]-each chosen for their distinct strengths and complementary characteristics.</p>
<p>The PC algorithm leverages conditional independence (CI) tests to construct a graph's skeleton and identify v-structures, offering a robust framework for causal inference when the underlying relationships can be uncovered through probabilistic dependencies. Its ability to handle discrete and continuous variables effectively makes it a reliable choice for datasets where independence testing plays a central role. LiNGAM, on the other hand, excels at uncovering linear causal relationships in datasets with non-Gaussian distributions. By utilizing Independent Component Analysis (ICA) for causal ordering, LiNGAM demonstrates superior performance in disentangling complex linear interactions. Its focus on exploiting the statistical properties of non-Gaussianity ensures that causal directions are accurately inferred, even in the presence of latent confounders. Complementing these approaches, NOTEARS offers a novel optimization-based framework that reformulates the combinatorial problem of DAG discovery into a continuous optimization task. By incorporating an acyclicity constraint into its objective function, NOTEARS efficiently learns causal structures while maintaining scalability to larger datasets. Its gradient-based methodology makes it particularly adept at handling high-dimensional data with intricate causal dependencies.</p>
<p>Building on the unique strengths of these three algorithms, we propose a hybrid method that combines PC, LiNGAM, and NOTEARS within a unified framework. This hybrid approach employs a majority-weighted voting mechanism to leverage the individual advantages of each algorithm dynamically. The weighting is determined based on their relative performance on specific datasets, ensuring that the final causal graph benefits from their collective expertise. This integration enhances the robustness and reliability of the causal discovery process, allowing the hybrid method to adapt to diverse data characteristics.</p>
<p>The causal structure learning component synthesizes an initial causal graph by combining the outputs of these algorithms, encapsulating the potential causal linkages identified from the dataset. This graph, which represents the key variables (nodes) and their inferred causal relationships (edges), is subsequently passed to the Causal Wrapper component for further contextualization and refinement, enabling downstream tasks to operate on a well-defined and accurate causal structure.</p>
<h1>3.2 Causal Wrapper</h1>
<p>The Causal Wrapper component serves as a critical intermediary or bridge between the causal structure learning and LLM-driven refiner components. This component encapsulates and translates the raw, initial causal graph into a series of contextual, causal-aware prompts (i.e., causal prompts). These prompts are fed to the LLM-driven refiner. The primary aim of these causal prompts is to</p>
<p>act as guides for the LLM-driven refiner, aiding it in comprehending the initial causal graph. Furthermore, these causal prompts direct the LLM-driven refiner to identify and integrate the relevant and updated causal background knowledge to make the solution more suited to the specific causal discovery problem at hand. Given these reasons, this prompting strategy ensures that the final causal graph is not only precise, but also robust and reflective of the underlying causal mechanisms within the dataset.</p>
<p>Equation 1 shows our causal-aware prompting strategy by infusing the context of problem and metadata information into the prompts. This prompting strategy was inspired by an effort by Kim et al. [21]. They demonstrated that contextual information is important in boosting the overall performance of LLMs' responses.</p>
<p>$$
\text { Causal }_{\text {prompt }}=\text { Instruction }+ \text { Causal Context }+ \text { Metadata }+ \text { Question }+ \text { Output format }
$$</p>
<p>This enhancement is accomplished by incorporating explicit elements into the prompt, with each edge being transformed into a causal prompt structured as follows:
Instructions: This section clarifies the role of LLMs, their objectives, and the expected behavior. Causal Context: It includes details about the selected causal discovery algorithm, such as its name and output. Metadata: This section outlines the dataset domain or variable names along with their descriptions. Question: It specifies the precise query, for example, whether A causes B. Output format: This delineates the desired format for the output.</p>
<p>Figure 2 illustrates an example of the causal wrapper's functionality. The causal structure learning component generates the initial causal graph by applying conventional causal discovery algorithms, such as Peter-Clark (PC), LiNGAM, or NOTEARS. These algorithms analyze the input observational dataset to uncover key variables (nodes) and their probabilistic dependencies, forming the skeleton of the initial graph. The nodes in this graph represent significant variables derived from the dataset, while the directed edges illustrate potential causal relationships. This foundational graph is then passed to the causal wrapper and subsequently refined by the LLM-driven refiner. Notably, the output can incorporate supplementary reasoning and confidence metrics to enhance interpretability. For instance, a simple instruction can prompt the LLM-driven refiner to engage in step-by-step reasoning using a Chain-of-Thought (CoT) approach [46]. Additionally, it can request the LLM to quantify its confidence level or provide a likelihood estimate for the generated outputs, using log-likelihood values or confidence percentages.</p>
<p>These prompts are critical for ensuring that the LLM comprehends the initial graph and integrates relevant causal knowledge effectively. For example, they direct the LLM to identify hidden causal relationships or validate existing edges by leveraging its contextual reasoning capabilities. This interaction facilitates the enhancement of the initial graph into a more accurate and robust representation of the underlying causal mechanisms. Once these causal prompts are generated, they are dispatched to the LLM-driven refiner component. This method ensures that the ALCM framework optimally utilizes LLMs for uncovering, refining, and validating causal relationships, thereby advancing the field of causal discovery with a high level of accuracy.</p>
<h1>3.3 LLM-driven Refiner</h1>
<p>The LLM-driven Refiner leverages advanced language models in the refinement and evaluation of causal graphs. This component receives a series of intricately designed, contextual causal prompts from the causal wrapper component, which serve as a nuanced guide for its operations.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Causal Prompt Demonstration</p>
<p>The LLM-driven Refiner evaluates each edge and node in the graph by applying advanced reasoning capabilities of LLMs (e.g., GPT-4). The process involves:</p>
<ol>
<li>Assessing the validity of existing causal relationships using contextual knowledge.</li>
<li>Detecting and integrating hidden causal relationships by reasoning over unobserved variables.</li>
<li>Reorienting or removing edges that do not align with domain knowledge or probabilistic dependencies.</li>
<li>Assigning confidence scores or likelihood estimates to refined relationships, ensuring interpretability and reliability.</li>
</ol>
<p>The LLM-driven Refiner verifies hidden causal relationships by leveraging advanced capabilities of LLMs to assess, validate, and refine the initial causal graph. This process begins with the causal prompts generated by the Causal Wrapper, which provide the LLM with explicit instructions, contextual metadata, and domain-specific information about the causal relationships. The LLM evaluates each edge in the graph based on its internal knowledge base and the provided context, determining whether the relationship is valid, needs reorientation, or should be removed. Furthermore, the LLM identifies potential hidden relationships by reasoning over unobserved variables and interactions that conventional algorithms may overlook. To ensure accuracy, the refined relationships are accompanied by confidence scores or likelihood estimates, enabling a structured and interpretable refinement process. Finally, these refined graphs are validated through crossreferencing with up-to-date domain knowledge, ensuring that the final output is both accurate and comprehensive.</p>
<p>The significance of the LLM-driven Refiner lies in its capacity to address and alleviate inherent limitations present in both the causal discovery algorithms and the datasets themselves. This component plays a pivotal role in uncovering and assimilating previously overlooked or concealed causal information, thereby elevating the accuracy and comprehensiveness of the causal graph. The identification and integration of hidden causal relationships into the graph are essential, as they can reveal causal connections or nodes that traditional causal discovery methods might miss or that dataset constraints could obscure. Upon completion of the refinement process, the results are saved, and various post-processing techniques are applied to generate the final graph. These techniques involve leveraging natural language processing (NLP) to parse and extract causal relationships</p>
<p>from textual responses provided by LLMs. Subsequently, these extracted relationships undergo validation and structuring to form a coherent causal graph.</p>
<h1>3.4 Interactions Between Components</h1>
<p>The Causal Structure Learning component generates the initial graph, providing a data-driven foundation. The Causal Wrapper transforms this graph into contextualized prompts, enabling the LLM to reason about relationships in a guided and structured manner. The LLM-driven Refiner refines and validates the graph, identifying hidden relationships and ensuring alignment with external knowledge. This iterative feedback loop ensures that the final causal graph is both accurate and interpretable, addressing limitations in traditional causal discovery methods and leveraging the strengths of LLMs.</p>
<h2>4 Implementation</h2>
<p>We elucidate the technical underpinnings and strategic choices behind the deployment of the ALCM framework. We provide two demonstrations of implementation of our framework to show that our framework can enhance the accuracy and generalizability.</p>
<h3>4.1 Implementation 1 (ALCM-PC)</h3>
<p>For the first implementation, we select the PC causal discovery algorithm for its robustness in handling large datasets and its efficiency in inferring causal structures through conditional independence (CI) tests. The algorithm constructs an undirected graph and iteratively removes edges by testing CI between variable pairs, conditioned on subsets of other variables, a process known as skeleton discovery. It then orients edges by detecting v-structures (triplets of nodes with specific dependency patterns) and ensuring acyclicity, resulting in a DAG that represents the causal relationships. The PC algorithm's ability to prune unnecessary connections makes it particularly effective for high-dimensional datasets, balancing computational efficiency with accuracy. For the causal wrapper component, we utilize causal prompt. We illustrate one example of our prompt in Figure 3. For LLM-driven refiner, we exploit OpenAI GPT-4 [29, 3] in our pipeline.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Prompt Template</p>
<h1>4.2 Implementation 2 (ALCM-Hybrid)</h1>
<p>For the second implementation, we present a hybrid causal discovery approach that integrates the strengths of three leading methods: Peter-Clark (PC) [38], LiNGAM [37], and NOTEARS [51]. These methods address different aspects of causal structure learning, and their combination provides a robust and accurate framework for causal discovery.</p>
<p>The PC method employs conditional independence (CI) tests to iteratively construct a causal graph by building its skeleton and identifying v-structures. This method is particularly effective for datasets with mixed discrete and continuous variables and excels in capturing probabilistic dependencies. Its iterative and constraint-based nature ensures computational efficiency, even in high-dimensional settings. In contrast, LiNGAM is specifically designed to uncover linear causal relationships in datasets with non-Gaussian distributions. By leveraging Independent Component Analysis (ICA), LiNGAM accurately identifies causal ordering and orients edges with high precision, even in the presence of latent confounders and linear dependencies. NOTEARS complements these approaches by reformulating causal discovery into a continuous optimization problem. By incorporating a differentiable acyclicity constraint, NOTEARS transforms the combinatorial problem of DAG discovery into a solvable optimization task, making it highly effective for datasets with intricate causal dependencies and scalable to high-dimensional data.</p>
<p>To leverage the unique strengths of these methods, we propose a hybrid approach that combines their outputs using dynamically assigned weights. These weights are determined based on a composite score for each method, which captures its performance on a given dataset. The composite score is defined as the difference between the Accuracy and NHD, balancing edge-specific performance and structural alignment with the ground truth. Formally, the composite score for a method is given by:</p>
<p>$$
\text { Composite }<em _method="{method" _text="\text">{\text {method }}=\text { Accuracy }</em>
$$}}-\mathrm{NHD}_{\text {method }</p>
<p>This score accounts for both the overall correctness of edge identification (via Accuracy) and the structural similarity of the causal graph (via NHD), ensuring that methods achieving both accurate and well-aligned graphs are given higher importance. The weights are derived by normalizing the composite scores across all methods:</p>
<p>$$
W_{\text {method }}=\frac{\text { Composite }<em _all="{all" _text="\text" methods="methods">{\text {method }}}{\sum</em>
$$}} \text { Composite }_{\text {method }}</p>
<p>where $W_{\text {method }}$ represents the weight assigned to a method, ensuring that the sum of all weights equals one.</p>
<p>To further enhance the adaptability of the hybrid approach, we introduce a neural networkbased architecture to dynamically learn these weights based on both method performance metrics and dataset-specific features. The neural network is designed to take as input the composite scores of the methods, along with features such as graph density, node degree distribution, and sparsity. Graph density quantifies how connected the graph is and is defined as the ratio of the number of edges to the maximum possible edges. Node degree distribution describes the variability in the number of connections per node, while sparsity measures the proportion of missing edges compared to a fully connected graph.</p>
<p>The architecture of the neural network consists of three layers: 1. An input layer with nine features, including the composite scores of the methods (Composite $\mathrm{P}<em _LiNGAM="{LiNGAM" _text="\text">{\mathrm{PC}}$, Composite ${ }</em>$ ) and six dataset-specific features such as graph density, average node degree, and sparsity. 2. Two hidden layers with 64 and 32 neurons, respectively, each using the Rectified Linear Unit (ReLU) activation function to capture non-linear relationships among the features. 3. An output layer with three neurons (one for each method), using a softmax activation to produce normalized weights for the methods. Formally, the neural network outputs the weights as follows:}}$, Composite ${ }_{\text {NOTEARS }</p>
<p>$$
\mathbf{W}=\operatorname{Softmax}\left(\mathbf{H}<em o="o">{2} \cdot \mathbf{W}</em>\right)
$$}+\mathbf{b}_{o</p>
<p>where $\mathbf{H}<em o="o">{2}$ represents the outputs from the second hidden layer, $\mathbf{W}</em>$ are the weights and biases of the output layer, and Softmax ensures the weights sum to one.}$ and $\mathbf{b}_{o</p>
<p>The neural network is trained on a dataset comprising simulated graphs with varying densities, node degrees, and sparsity levels. For each graph, the outputs of PC, LiNGAM, and NOTEARS are evaluated using Accuracy and NHD, and the composite scores are computed. The ground-truth weights for training are derived by normalizing these composite scores as described in Equation (3). The training objective minimizes the mean squared error (MSE) between the predicted weights and the ground-truth weights. Using the dynamically learned weights, the hybrid approach synthesizes a causal graph by aggregating the outputs of PC, LiNGAM, and NOTEARS. For each edge $e$, the final score is computed as:</p>
<p>$$
\text { Score }<em _method="{method" _text="\text">{e}=\sum</em>
$$}} W_{\text {method }} \cdot \mathbb{I}_{\text {method }(e)</p>
<p>Here, $\mathbb{I}_{\text {method }(e)}$ is an indicator function that equals 1 if the edge $e$ is identified by the method and 0 otherwise. Edges with scores exceeding a predefined threshold are retained in the hybrid causal graph. For edges uniquely identified by only one method, one LLM is employed as a decisive layer. The LLM evaluates these edges based on contextual knowledge and causal reasoning to ensure that only plausible causal links are included. The validated edges are then added to the hybrid graph, enhancing its comprehensiveness and accuracy.</p>
<p>The resulting hybrid causal graph is passed to the Causal Wrapper component, where it is further contextualized and refined using domain-specific templates and LLM-driven reasoning. This ensures that the final causal graph is robust, accurate, and adaptable to diverse data characteristics. By combining the strengths of traditional causal discovery methods with the adaptability of neural networks and the reasoning capabilities of LLMs, the hybrid approach achieves superior performance in causal discovery, setting a new benchmark for accuracy and robustness.</p>
<h1>5 Experiments</h1>
<p>In this section, we first present benchmark datasets used in our experiments. Next, we outline the evaluation metrics selected to measure the framework's performance in terms of accuracy, robustness, and reliability. Finally, we summarize the experimental results, demonstrating the effectiveness of the ALCM framework in generating and refining causal graphs, and its ability to reveal latent causal relationships, showcasing its advancement over existing methods.</p>
<h3>5.1 Benchmark Datasets</h3>
<p>We utilize six benchmark datasets and their ground truth causal graphs from the BN repository: Asia, Cancer, Child, Insurance, Sachs, Sangiovese [36, 25], and also the well-known Neuropathetic dataset [42] to evaluate the efficacy of the ALCM framework. These datasets are chosen for their diverse origins and complexities, covering a range of scenarios from medical studies to insurance modeling and genetic pathways. The importance of utilizing these benchmark datasets lies in their ability to provide a standardized basis for comparison, enabling the assessment of the ALCM framework's performance across varied domains and conditions. Table 2 indicates a summary of these datasets.</p>
<p>Table 2: Summary of Datasets</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">Domain</th>
<th style="text-align: center;">#Nodes</th>
<th style="text-align: center;">#Edges</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Asia</td>
<td style="text-align: left;">Social Science</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: left;">Cancer</td>
<td style="text-align: left;">Medical</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: left;">Child</td>
<td style="text-align: left;">Social Science</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">31</td>
</tr>
<tr>
<td style="text-align: left;">Insurance</td>
<td style="text-align: left;">Finance</td>
<td style="text-align: center;">27</td>
<td style="text-align: center;">43</td>
</tr>
<tr>
<td style="text-align: left;">Neuropathic</td>
<td style="text-align: left;">Medical</td>
<td style="text-align: center;">221</td>
<td style="text-align: center;">475</td>
</tr>
<tr>
<td style="text-align: left;">Sachs</td>
<td style="text-align: left;">Biological</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: left;">Sangiovese</td>
<td style="text-align: left;">Social Science</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">47</td>
</tr>
</tbody>
</table>
<p>To ensure these datasets are compatible with the input requirements of causal discovery algorithms within the ALCM framework, we implement a series of preprocessing techniques as part of the causal structure learning component. This preprocessing involves cleaning the data, handling missing values, and normalizing data formats, among other adjustments, to tailor the datasets for optimal processing. By meticulously preparing these datasets, we facilitate their effective use as inputs for the causal discovery algorithms, ensuring that the initial causal graphs generated are as accurate and informative as possible.</p>
<h1>5.2 Evaluation Metrics</h1>
<p>We select five metrics to assess the effectiveness and precision of the ALCM framework's causal discovery capabilities. The evaluation of the predicted causal graphs against the ground truth is paramount to validate the accuracy and reliability of our methodology. To this end, we employ five key metrics: precision, recall, F1-score, accuracy, and Normalized Hamming Distance (NHD), each selected for its ability to provide a comprehensive understanding of the framework's performance from different perspectives [49].</p>
<ul>
<li>Precision: measures the proportion of correctly identified causal relationships out of all relationships identified by the algorithm. This metric is crucial for ensuring that the causal links proposed by our framework are indeed valid, minimizing false positives.</li>
<li>Recall: assesses the fraction of true causal relationships that have been correctly identified by the algorithm, highlighting the framework's ability to uncover the full extent of causal connections present within the data.</li>
<li>F1-score: serves as a harmonic mean of precision and recall, offering a single metric that balances both the accuracy and completeness of the identified causal relationships. This is particularly useful for comparing the overall performance of different causal discovery approaches.</li>
<li>Accuracy: evaluates the overall correctness of the causal graph, including both the presence of true causal connections and the absence of false ones. This metric provides a straightforward assessment of the model's overall predictive performance.</li>
<li>Normalized Hamming Distance (NHD): quantifies the difference between the predicted causal graph and the ground truth by measuring the proportion of mismatched edges, adjusted for the size of the graph. NHD is instrumental in assessing the structural similarity of the causal graphs, offering insights into the nuanced differences that may not be captured by other metrics. In the context of a graph with $m$ nodes, the NHD between the predicted graph $\mathrm{G}_{\mathrm{p}}$ and the ground-truth graph G is determined by calculating the number of edges that exist in one graph but not the other. This count is then divided by the total number of all possible edges-this formula is defined in Equation 6. In essence, the NHD provides a normalized measure of dissimilarity, offering insights into the accuracy of the predicted graph compared to the ground-truth graph, accounting for the total potential edges in the graph with $m$ nodes.</li>
</ul>
<p>$$
N H D=\sum_{i=1}^{m} \sum_{j=1}^{m} \frac{1}{m^{2}} \cdot 1, \quad \text { where } G_{i j} \neq G_{p_{i j}}
$$</p>
<h3>5.3 Experimental Results</h3>
<p>In this section, we present the experimental results and a comprehensive analysis of the ALCM framework's performance compared to various causal discovery methods. These evaluations were conducted using seven benchmark datasets and five evaluation metrics: precision, recall, F1-score, accuracy, and Normalized Hamming Distance (NHD). The comparison encompasses traditional</p>
<p>causal discovery methods (PC, LiNGAM, NOTEARS), a hybrid method, and LLM-based approaches. Additionally, the ALCM-PC and ALCM-Hybrid implementations, described in Sections 4.1 and 4.2 , are included to demonstrate the benefits of integrating conventional algorithms with advanced refinement mechanisms.</p>
<p>Table 3 highlights the significant improvements achieved by the ALCM framework across all datasets. ALCM-PC and ALCM-Hybrid consistently outperform other methods in precision, recall, F1-score, and accuracy, while also achieving the lowest NHD values, which indicate a closer alignment with the ground truth causal graph. ALCM-Hybrid demonstrates the highest accuracy and F1-scores across all datasets, outperforming ALCM-PC and other methods due to its ability to integrate multiple causal discovery paradigms and incorporate LLM-driven contextual refinement. ALCM-PC, which builds upon the PC method as its backbone, also performs robustly by leveraging LLM-based refinements to improve accuracy and reduce structural mismatches in the resulting causal graphs.</p>
<p>The experimental results show that LLM-based approaches, while capable of identifying novel causal relationships, tend to exhibit lower precision and higher NHD values. This highlights a tendency of such approaches to overgeneralize causal relationships from input data, which may result in the identification of spurious edges. Conversely, traditional methods like PC, LiNGAM, and NOTEARS demonstrate varying levels of performance. PC is effective for simpler datasets, such as Asia, where probabilistic dependencies are more straightforward to infer. However, it struggles with more complex datasets, such as Neuropathic and Sachs, which involve intricate causal dependencies. LiNGAM, tailored for linear, non-Gaussian relationships, performs well on datasets adhering to its assumptions but exhibits higher NHD values and lower precision on datasets with more diverse causal structures. NOTEARS provides scalable and efficient causal discovery but also faces limitations in capturing complex interactions in highly nonlinear datasets.</p>
<p>The hybrid approach (ALCM-Hybrid) capitalizes on the unique strengths of PC, LiNGAM, and NOTEARS by combining them in a weighted majority voting framework. This method dynamically assigns weights to the contributions of each algorithm based on dataset-specific characteristics, enabling it to adapt to varying causal structures. The integration of these dynamically learned weights ensures that ALCM-Hybrid achieves robust and reliable causal graph construction, as evidenced by its superior performance in metrics such as precision (up to 0.95 ) and accuracy (up to $98.18 \%$ ). Furthermore, the incorporation of LLMs in the ALCM framework provides an additional layer of contextual reasoning and domain-specific validation. This is particularly beneficial for datasets with intricate causal dependencies, such as Sachs and Neuropathic, where conventional algorithms alone may fail to capture the nuanced relationships between variables. By blending algorithmic rigor with AI-driven insights, the ALCM framework establishes a new benchmark for accuracy and robustness in causal discovery.</p>
<p>These results indicate the transformative potential of combining traditional causal discovery algorithms with LLM-driven enhancements. The ALCM framework not only addresses the limitations of existing methodologies but also demonstrates its capacity to provide reliable, interpretable, and accurate causal graphs for diverse and complex datasets.</p>
<p>Table 3: Evaluation Results for Various Causal Discovery Methods</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Metrics</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Precision</td>
<td style="text-align: center;">Recall</td>
<td style="text-align: center;">F1-Score</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">NHD</td>
</tr>
<tr>
<td style="text-align: center;">Asia</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.375</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">33.33</td>
<td style="text-align: center;">0.1429</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.1818</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.2105</td>
<td style="text-align: center;">25.00</td>
<td style="text-align: center;">0.8824</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.1786</td>
<td style="text-align: center;">0.625</td>
<td style="text-align: center;">0.2778</td>
<td style="text-align: center;">53.57</td>
<td style="text-align: center;">0.4643</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.452</td>
<td style="text-align: center;">0.483</td>
<td style="text-align: center;">0.466</td>
<td style="text-align: center;">47.00</td>
<td style="text-align: center;">0.193</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.1428</td>
<td style="text-align: center;">0.2174</td>
<td style="text-align: center;">0.1742</td>
<td style="text-align: center;">16.00</td>
<td style="text-align: center;">0.75</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.5945</td>
<td style="text-align: center;">0.746</td>
<td style="text-align: center;">87.00</td>
<td style="text-align: center;">0.0893</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.942</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">0.0179</td>
</tr>
<tr>
<td style="text-align: center;">Cancer</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">33.33</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">0.6667</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.2857</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.4286</td>
<td style="text-align: center;">42.00</td>
<td style="text-align: center;">0.2111</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.158</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.261</td>
<td style="text-align: center;">21.4</td>
<td style="text-align: center;">0.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">0.667</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">85.71</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.924</td>
<td style="text-align: center;">90.32</td>
<td style="text-align: center;">0.0333</td>
</tr>
<tr>
<td style="text-align: center;">Child</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">27.00</td>
<td style="text-align: center;">0.121</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.14</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.224</td>
<td style="text-align: center;">56.00</td>
<td style="text-align: center;">0.8739</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.0474</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.0837</td>
<td style="text-align: center;">48.16</td>
<td style="text-align: center;">0.5184</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.3231</td>
<td style="text-align: center;">34.00</td>
<td style="text-align: center;">0.2875</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.0657</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.1156</td>
<td style="text-align: center;">29.21</td>
<td style="text-align: center;">0.8765</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.6185</td>
<td style="text-align: center;">0.764</td>
<td style="text-align: center;">78.89</td>
<td style="text-align: center;">0.047</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.8839</td>
<td style="text-align: center;">98.04</td>
<td style="text-align: center;">0.016</td>
</tr>
<tr>
<td style="text-align: center;">Insurance</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.2153</td>
<td style="text-align: center;">0.2692</td>
<td style="text-align: center;">0.2393</td>
<td style="text-align: center;">13.59</td>
<td style="text-align: center;">0.864</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">0.3462</td>
<td style="text-align: center;">0.1782</td>
<td style="text-align: center;">34.62</td>
<td style="text-align: center;">0.9022</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.0843</td>
<td style="text-align: center;">0.5577</td>
<td style="text-align: center;">0.1465</td>
<td style="text-align: center;">51.85</td>
<td style="text-align: center;">0.4815</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.25</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">30.00</td>
<td style="text-align: center;">0.315</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.069</td>
<td style="text-align: center;">0.5833</td>
<td style="text-align: center;">0.1234</td>
<td style="text-align: center;">22.9</td>
<td style="text-align: center;">0.862</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.857</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">94.8</td>
<td style="text-align: center;">0.054</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.9294</td>
<td style="text-align: center;">95.2</td>
<td style="text-align: center;">0.045</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Metrics</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Precision</td>
<td style="text-align: center;">Recall</td>
<td style="text-align: center;">F1-Score</td>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">NHD</td>
</tr>
<tr>
<td style="text-align: center;">Neuropathic</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.551</td>
<td style="text-align: center;">0.4954</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">0.1364</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.299</td>
<td style="text-align: center;">0.3184</td>
<td style="text-align: center;">0.3084</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">0.2632</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">55.00</td>
<td style="text-align: center;">0.1897</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.2831</td>
<td style="text-align: center;">0.202</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">0.4537</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.4355</td>
<td style="text-align: center;">0.4703</td>
<td style="text-align: center;">0.4522</td>
<td style="text-align: center;">53.21</td>
<td style="text-align: center;">0.1695</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">0.8846</td>
<td style="text-align: center;">0.6201</td>
<td style="text-align: center;">0.7291</td>
<td style="text-align: center;">89.26</td>
<td style="text-align: center;">0.0575</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.9773</td>
<td style="text-align: center;">0.9788</td>
<td style="text-align: center;">98.18</td>
<td style="text-align: center;">0.0122</td>
</tr>
<tr>
<td style="text-align: center;">Sachs</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.4167</td>
<td style="text-align: center;">0.5882</td>
<td style="text-align: center;">0.4878</td>
<td style="text-align: center;">80.91</td>
<td style="text-align: center;">0.209</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.1591</td>
<td style="text-align: center;">0.4118</td>
<td style="text-align: center;">0.2295</td>
<td style="text-align: center;">41.18</td>
<td style="text-align: center;">0.5704</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.0303</td>
<td style="text-align: center;">0.1176</td>
<td style="text-align: center;">0.0482</td>
<td style="text-align: center;">40.15</td>
<td style="text-align: center;">0.5985</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.351</td>
<td style="text-align: center;">43.00</td>
<td style="text-align: center;">0.2012</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.2081</td>
<td style="text-align: center;">0.6471</td>
<td style="text-align: center;">0.3149</td>
<td style="text-align: center;">63.24</td>
<td style="text-align: center;">0.9051</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">0.6117</td>
<td style="text-align: center;">0.7059</td>
<td style="text-align: center;">0.6554</td>
<td style="text-align: center;">87.5</td>
<td style="text-align: center;">0.1881</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.844</td>
<td style="text-align: center;">90.00</td>
<td style="text-align: center;">0.174</td>
</tr>
<tr>
<td style="text-align: center;">Sangiovese</td>
<td style="text-align: center;">PC</td>
<td style="text-align: center;">0.4348</td>
<td style="text-align: center;">0.1818</td>
<td style="text-align: center;">0.2564</td>
<td style="text-align: center;">14.71</td>
<td style="text-align: center;">0.5761</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LiNGAM</td>
<td style="text-align: center;">0.322</td>
<td style="text-align: center;">0.3455</td>
<td style="text-align: center;">0.3333</td>
<td style="text-align: center;">34.55</td>
<td style="text-align: center;">0.348</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">NOTEARS</td>
<td style="text-align: center;">0.2556</td>
<td style="text-align: center;">0.6182</td>
<td style="text-align: center;">0.3617</td>
<td style="text-align: center;">55.88</td>
<td style="text-align: center;">0.2412</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hybrid</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">44.06</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LLMs</td>
<td style="text-align: center;">0.288</td>
<td style="text-align: center;">0.6545</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">25.00</td>
<td style="text-align: center;">0.5143</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-PC</td>
<td style="text-align: center;">0.6548</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.7914</td>
<td style="text-align: center;">65.48</td>
<td style="text-align: center;">0.1381</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ALCM-Hybrid</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.903</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">0.065</td>
</tr>
</tbody>
</table>
<p>The results presented in Table 4 provide a detailed evaluation of the ALCM-Hybrid framework when integrated with five prominent LLMs, namely GPT-4, Llama3.1-8B, Llama3.1-70B, Gemma29B, and Ministral-7B, across seven benchmark datasets. This analysis complements the broader comparison shown in Table 3, focusing specifically on the metrics of accuracy and Normalized Hamming Distance (NHD) to evaluate predictive reliability and structural alignment of causal graphs with the ground truth. As expected, GPT-4 consistently achieves the highest accuracy and lowest NHD values across all datasets, demonstrating its ability to leverage extensive pre-trained knowledge for accurate causal inference. For instance, in the Asia dataset, GPT-4 achieves an accuracy of $96.55 \%$ with an NHD of 0.0179 , significantly outperforming smaller models.</p>
<p>Table 4: Accuracy and NHD Metrics for ALCM-Hybrid Across Five LLM Models</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Accuracy (\%)</th>
<th style="text-align: center;">NHD</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Asia</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">0.0179</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">94.32</td>
<td style="text-align: center;">0.0210</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">95.10</td>
<td style="text-align: center;">0.0192</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">94.80</td>
<td style="text-align: center;">0.0205</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">93.90</td>
<td style="text-align: center;">0.0223</td>
</tr>
<tr>
<td style="text-align: center;">Cancer</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">90.32</td>
<td style="text-align: center;">0.0333</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">88.40</td>
<td style="text-align: center;">0.0378</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">89.20</td>
<td style="text-align: center;">0.0355</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">88.60</td>
<td style="text-align: center;">0.0369</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">87.50</td>
<td style="text-align: center;">0.0385</td>
</tr>
<tr>
<td style="text-align: center;">Child</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">98.04</td>
<td style="text-align: center;">0.016</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">96.70</td>
<td style="text-align: center;">0.0205</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">97.20</td>
<td style="text-align: center;">0.0193</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">96.80</td>
<td style="text-align: center;">0.0201</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">96.00</td>
<td style="text-align: center;">0.0210</td>
</tr>
<tr>
<td style="text-align: center;">Insurance</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">95.2</td>
<td style="text-align: center;">0.045</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">94.80</td>
<td style="text-align: center;">0.0402</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">95.50</td>
<td style="text-align: center;">0.0389</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">94.90</td>
<td style="text-align: center;">0.0398</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">93.70</td>
<td style="text-align: center;">0.0415</td>
</tr>
<tr>
<td style="text-align: center;">Sachs</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">90.00</td>
<td style="text-align: center;">0.174</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">89.20</td>
<td style="text-align: center;">0.1790</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">89.70</td>
<td style="text-align: center;">0.1755</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">89.30</td>
<td style="text-align: center;">0.1780</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">88.50</td>
<td style="text-align: center;">0.1805</td>
</tr>
<tr>
<td style="text-align: center;">Neuropathic</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">98.18</td>
<td style="text-align: center;">0.0122</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">96.90</td>
<td style="text-align: center;">0.0188</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">97.40</td>
<td style="text-align: center;">0.0175</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">97.00</td>
<td style="text-align: center;">0.0182</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">96.20</td>
<td style="text-align: center;">0.0193</td>
</tr>
<tr>
<td style="text-align: center;">Sangiovese</td>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">0.065</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-8B</td>
<td style="text-align: center;">91.80</td>
<td style="text-align: center;">0.0701</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Llama3.1-70B</td>
<td style="text-align: center;">92.30</td>
<td style="text-align: center;">0.0685</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gemma2-9B</td>
<td style="text-align: center;">91.90</td>
<td style="text-align: center;">0.0699</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ministral-7B</td>
<td style="text-align: center;">90.70</td>
<td style="text-align: center;">0.0715</td>
</tr>
</tbody>
</table>
<p>The performance trends reveal that as model complexity and size decrease, there is a gradual decline in accuracy and an increase in NHD. Smaller models, such as Ministral-7B, while computationally efficient, exhibit limitations in capturing intricate causal dependencies, particularly in complex datasets like Cancer and Sachs. For example, in the Cancer dataset, Ministral-7B achieves an accuracy of 87.50</p>
<p>Llama3.1-70B and Gemma2-9B demonstrate competitive performance, approaching GPT-4's accuracy while maintaining slightly higher NHD values, indicating room for improvement in structural fidelity. The Insurance dataset, in particular, showcases consistent performance trends across all models, suggesting that even less complex LLMs can achieve reasonable results when the dataset complexity is moderate. Despite these observations, GPT-4's superior performance across all datasets highlights the benefits of advanced reasoning capabilities and large-scale pre-training in enhancing causal discovery tasks.</p>
<p>Overall, the results show the adaptability and robustness of the ALCM-Hybrid framework when paired with varying LLMs. While smaller models like Ministral-7B offer computational efficiency, they trade off precision and structural fidelity, making them less suitable for tasks requiring high accuracy. The synergy between ALCM-Hybrid and LLMs ensures robust causal inference, even when using less powerful models. These findings provide valuable insights into selecting the appropriate LLM for specific causal discovery tasks, balancing resource constraints and performance requirements. Table 4 should be placed immediately after Section 5.3 to maintain a logical flow</p>
<p>and provide a detailed breakdown of the experimental results.
We depict the causal graphs obtained by a couple of causal discovery methods on Sachs dataset in Figure 4. The Sachs dataset [36] includes data on 11 phosphorylated proteins and phospholipids from human immune cells, providing a basis for analyzing protein signaling pathways and constructing causal networks. It is especially valuable for causal discovery research, with data collected from cells under different experimental conditions, making it an excellent benchmark for testing causal discovery algorithms. Graph of ground truth, LLMs-based approach, PC, ALCM, ALCM-Hybrid are shown in Figures 4a, 4b, 4c, 4d, 4e, respectively.</p>            </div>
        </div>

    </div>
</body>
</html>