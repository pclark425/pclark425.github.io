<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6372 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6372</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6372</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-272753603</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.12393v1.pdf" target="_blank">Small Language Models are Equation Reasoners</a></p>
                <p><strong>Paper Abstract:</strong> Chain-of-Thought (CoT) reasoning has enabled Large Language Model (LLM) to achieve remarkable performance in various NLP tasks, including arithmetic problem-solving. However, this success does not generalize to small language model (sLM) like T5, due to their limited capacity and absence of emergent abilities associated with larger models. Recent works to enhance sLM through knowledge distillation have yielded some improvements but still face significant limitations, particularly high ambiguity from the variability in natural language expressions and substantial computational costs. In this paper, we investigate why sLM perform poorly on arithmetic reasoning tasks and hypothesize that natural language format variability introduces high ambiguity for these smaller models. Based on this hypothesis, we conduct experiments with equation-only format, which is a reasoning format that unifies arithmetic reasoning previously expressed in natural language formats into mathematical equations. Experiment results demonstrate that equation-only format effectively boosts the arithmetic reasoning abilities of sLM, especially in very small models like T5-Tiny.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6372.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6372.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5 (GSM8K experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Text-to-Text Transfer Transformer (T5) family evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper fine-tunes and evaluates multiple T5 model sizes (Base, Small, Mini, Tiny) on the GSM8K grade-school math dataset, comparing performance when inputs are presented in natural-language word-problem format versus a unified equation-only symbolic format.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Small Language Models are Equation Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5 (Base, Small, Mini, Tiny)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>encoder-decoder transformer (T5 family)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Base: 220M; Small: 60M; Mini: 31M; Tiny: 16M</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not specified in detail in this paper; uses standard T5 checkpoints (pretrained on general corpora) and then trained/finetuned for the GSM8K task (paper does not provide the pretraining corpora specifics).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step grade-school arithmetic word problems (arithmetic reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Comparison of natural-language word-problem format vs equation-only (symbolic equations using numbers and operation symbols)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>Grade-school / elementary-level multi-step problems (GSM8K)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Supervised fine-tuning / direct input-output training with two input formats: natural-language question and equation-only format. No chain-of-thought, few-shot, or self-consistency prompting was applied in the experiments described.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (exact answer correctness)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>T5-Base: Natural Language 13% → Equation Only 17%; T5-Small: 10% → 14%; T5-Mini: 8% → 11%; T5-Tiny: 7% → 10% (accuracy percentages on GSM8K as reported in Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>The paper inspects cross-attention score maps (Figure 2) and reports that in equation-only format, attention scores are stronger on paired tokens (e.g., 'times' ↔ '*', 'Half' ↔ '/2') and operation/variable symbols are better mapped; in natural-language format attention is more dispersed and often assigns high scores to tokens unrelated to the correct solution.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Primary failure mode identified is high ambiguity from natural-language variability: small models exhibit dispersed attention across irrelevant tokens, overlooking crucial numeric/operator tokens, leading to incorrect answers. The paper also notes that small models lack emergent abilities that help LLMs, which limits effectiveness of CoT-style approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Equation-only format yields consistent but modest absolute improvements across all tested sizes (roughly +3–4 percentage points). Overall accuracy remains low (<20%) for all sLM sizes; no emergent performance jump is observed within the tested parameter range (16M–220M).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Small Language Models are Equation Reasoners', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6372.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6372.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Equation-only format</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Equation-only symbolic input format for arithmetic problems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task-formatting method introduced in this paper that converts/represents arithmetic word problems as unified symbolic equations (numbers and operators) to reduce natural-language variability and ambiguity for small language models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Small Language Models are Equation Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K (used with equation-only representation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step arithmetic / word-problem solving reformatted into symbolic equations</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>symbolic equations (equation-only) instead of natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>Grade-school / elementary-level (GSM8K)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Format engineering: presenting the problem as an equation-only input to the model during training/evaluation instead of a natural-language prompt; this is not chain-of-thought prompting but a change in input representation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported improvements relative to natural-language format across T5 sizes (see T5 entry): up to +4 percentage points (e.g., T5-Base 13%→17%).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Attention visualizations show tighter, more relevant cross-attention alignments between tokens representing operations/variables in the equation-only format; the paper attributes better mapping of operator words to symbols and reduced attention dispersion to this format.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Does not eliminate all errors: overall accuracy remains low for very small models; equation-only reduces ambiguity but small models still have limited capacity and make arithmetic mistakes. The paper does not detail specific arithmetic error types (e.g., off-by-one) beyond general incorrect answers.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Equation-only format helps across all tested small sizes (from Tiny to Base) with roughly consistent absolute gains, but does not produce large emergent improvements as model size increases within the small-model regime.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Small Language Models are Equation Reasoners', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6372.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6372.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting / reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting technique that elicits step-by-step intermediate reasoning in large language models; referenced in the paper as effective for LLMs on arithmetic tasks but reported to not generalize to small models in the authors' view.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Small Language Models are Equation Reasoners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Chain-of-Thought prompting (technique)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>arithmetic reasoning / multi-step problem solving (in cited literature)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language with step-by-step (CoT) intermediate reasoning traces</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>various (used in LLM arithmetic benchmarks such as GSM8K in prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>chain-of-thought prompting (eliciting intermediate reasoning chains); referenced but not applied for sLMs in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (as reported in prior literature)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Paper states CoT has improved arithmetic performance for LLMs in prior work but 'does not function effectively in sLMs due to absence of emergent abilities at smaller scales' (no internal mechanistic probing of CoT in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Authors claim CoT is ineffective for small models (sLMs) because they lack the capacity/emergent abilities required to reliably produce or use stepwise reasoning; paper provides no additional empirical CoT failure taxonomy for sLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Described qualitatively: CoT benefits are associated with larger model scales (emergent abilities); paper claims sLMs do not exhibit these emergent improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Small Language Models are Equation Reasoners', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Emergent abilities of large language models <em>(Rating: 2)</em></li>
                <li>Selfconsistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>Distilling mathematical reasoning capabilities into small language models <em>(Rating: 2)</em></li>
                <li>Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes <em>(Rating: 2)</em></li>
                <li>Are nlp models really able to solve simple math word problems? <em>(Rating: 2)</em></li>
                <li>Evaluating mathematical reasoning of large language models: A focus on error identification and correction <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6372",
    "paper_id": "paper-272753603",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "T5 (GSM8K experiments)",
            "name_full": "Text-to-Text Transfer Transformer (T5) family evaluated on GSM8K",
            "brief_description": "This paper fine-tunes and evaluates multiple T5 model sizes (Base, Small, Mini, Tiny) on the GSM8K grade-school math dataset, comparing performance when inputs are presented in natural-language word-problem format versus a unified equation-only symbolic format.",
            "citation_title": "Small Language Models are Equation Reasoners",
            "mention_or_use": "use",
            "model_name": "T5 (Base, Small, Mini, Tiny)",
            "model_family": "encoder-decoder transformer (T5 family)",
            "model_size": "Base: 220M; Small: 60M; Mini: 31M; Tiny: 16M",
            "training_data_description": "Not specified in detail in this paper; uses standard T5 checkpoints (pretrained on general corpora) and then trained/finetuned for the GSM8K task (paper does not provide the pretraining corpora specifics).",
            "benchmark_name": "GSM8K",
            "task_type": "multi-step grade-school arithmetic word problems (arithmetic reasoning)",
            "problem_format": "Comparison of natural-language word-problem format vs equation-only (symbolic equations using numbers and operation symbols)",
            "difficulty_level": "Grade-school / elementary-level multi-step problems (GSM8K)",
            "prompting_method": "Supervised fine-tuning / direct input-output training with two input formats: natural-language question and equation-only format. No chain-of-thought, few-shot, or self-consistency prompting was applied in the experiments described.",
            "performance_metric": "accuracy (exact answer correctness)",
            "performance_value": "T5-Base: Natural Language 13% → Equation Only 17%; T5-Small: 10% → 14%; T5-Mini: 8% → 11%; T5-Tiny: 7% → 10% (accuracy percentages on GSM8K as reported in Table 1).",
            "internal_analysis": "The paper inspects cross-attention score maps (Figure 2) and reports that in equation-only format, attention scores are stronger on paired tokens (e.g., 'times' ↔ '*', 'Half' ↔ '/2') and operation/variable symbols are better mapped; in natural-language format attention is more dispersed and often assigns high scores to tokens unrelated to the correct solution.",
            "failure_modes": "Primary failure mode identified is high ambiguity from natural-language variability: small models exhibit dispersed attention across irrelevant tokens, overlooking crucial numeric/operator tokens, leading to incorrect answers. The paper also notes that small models lack emergent abilities that help LLMs, which limits effectiveness of CoT-style approaches.",
            "scaling_trend": "Equation-only format yields consistent but modest absolute improvements across all tested sizes (roughly +3–4 percentage points). Overall accuracy remains low (&lt;20%) for all sLM sizes; no emergent performance jump is observed within the tested parameter range (16M–220M).",
            "uuid": "e6372.0",
            "source_info": {
                "paper_title": "Small Language Models are Equation Reasoners",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Equation-only format",
            "name_full": "Equation-only symbolic input format for arithmetic problems",
            "brief_description": "A task-formatting method introduced in this paper that converts/represents arithmetic word problems as unified symbolic equations (numbers and operators) to reduce natural-language variability and ambiguity for small language models.",
            "citation_title": "Small Language Models are Equation Reasoners",
            "mention_or_use": "use",
            "model_name": null,
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8K (used with equation-only representation)",
            "task_type": "multi-step arithmetic / word-problem solving reformatted into symbolic equations",
            "problem_format": "symbolic equations (equation-only) instead of natural-language word problems",
            "difficulty_level": "Grade-school / elementary-level (GSM8K)",
            "prompting_method": "Format engineering: presenting the problem as an equation-only input to the model during training/evaluation instead of a natural-language prompt; this is not chain-of-thought prompting but a change in input representation.",
            "performance_metric": "accuracy",
            "performance_value": "Reported improvements relative to natural-language format across T5 sizes (see T5 entry): up to +4 percentage points (e.g., T5-Base 13%→17%).",
            "internal_analysis": "Attention visualizations show tighter, more relevant cross-attention alignments between tokens representing operations/variables in the equation-only format; the paper attributes better mapping of operator words to symbols and reduced attention dispersion to this format.",
            "failure_modes": "Does not eliminate all errors: overall accuracy remains low for very small models; equation-only reduces ambiguity but small models still have limited capacity and make arithmetic mistakes. The paper does not detail specific arithmetic error types (e.g., off-by-one) beyond general incorrect answers.",
            "scaling_trend": "Equation-only format helps across all tested small sizes (from Tiny to Base) with roughly consistent absolute gains, but does not produce large emergent improvements as model size increases within the small-model regime.",
            "uuid": "e6372.1",
            "source_info": {
                "paper_title": "Small Language Models are Equation Reasoners",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Chain-of-Thought (CoT)",
            "name_full": "Chain-of-Thought prompting / reasoning",
            "brief_description": "A prompting technique that elicits step-by-step intermediate reasoning in large language models; referenced in the paper as effective for LLMs on arithmetic tasks but reported to not generalize to small models in the authors' view.",
            "citation_title": "Small Language Models are Equation Reasoners",
            "mention_or_use": "mention",
            "model_name": "Chain-of-Thought prompting (technique)",
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": null,
            "task_type": "arithmetic reasoning / multi-step problem solving (in cited literature)",
            "problem_format": "natural-language with step-by-step (CoT) intermediate reasoning traces",
            "difficulty_level": "various (used in LLM arithmetic benchmarks such as GSM8K in prior work)",
            "prompting_method": "chain-of-thought prompting (eliciting intermediate reasoning chains); referenced but not applied for sLMs in this paper's experiments.",
            "performance_metric": "accuracy (as reported in prior literature)",
            "performance_value": null,
            "internal_analysis": "Paper states CoT has improved arithmetic performance for LLMs in prior work but 'does not function effectively in sLMs due to absence of emergent abilities at smaller scales' (no internal mechanistic probing of CoT in this paper).",
            "failure_modes": "Authors claim CoT is ineffective for small models (sLMs) because they lack the capacity/emergent abilities required to reliably produce or use stepwise reasoning; paper provides no additional empirical CoT failure taxonomy for sLMs.",
            "scaling_trend": "Described qualitatively: CoT benefits are associated with larger model scales (emergent abilities); paper claims sLMs do not exhibit these emergent improvements.",
            "uuid": "e6372.2",
            "source_info": {
                "paper_title": "Small Language Models are Equation Reasoners",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Emergent abilities of large language models",
            "rating": 2,
            "sanitized_title": "emergent_abilities_of_large_language_models"
        },
        {
            "paper_title": "Selfconsistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        },
        {
            "paper_title": "Distilling mathematical reasoning capabilities into small language models",
            "rating": 2,
            "sanitized_title": "distilling_mathematical_reasoning_capabilities_into_small_language_models"
        },
        {
            "paper_title": "Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes",
            "rating": 2,
            "sanitized_title": "distilling_stepbystep_outperforming_larger_language_models_with_less_training_data_and_smaller_model_sizes"
        },
        {
            "paper_title": "Are nlp models really able to solve simple math word problems?",
            "rating": 2,
            "sanitized_title": "are_nlp_models_really_able_to_solve_simple_math_word_problems"
        },
        {
            "paper_title": "Evaluating mathematical reasoning of large language models: A focus on error identification and correction",
            "rating": 2,
            "sanitized_title": "evaluating_mathematical_reasoning_of_large_language_models_a_focus_on_error_identification_and_correction"
        }
    ],
    "cost": 0.00901975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Small Language Models are Equation Reasoners
19 Sep 2024</p>
<p>Bumjun Kim 
Hongik University</p>
<p>Kunha Lee kunha98@gmail.com 
Sangmyung University
3 Ewha Womans University 4 Yonsei University 1</p>
<p>Juyeon Kim 
Sangam Lee salee@yonsei.ac.kr 
Small Language Models are Equation Reasoners
19 Sep 202402C7E0405EB2807C44D2FD06A4228714arXiv:2409.12393v1[cs.CL]
Chain-of-Thought (CoT) reasoning has enabled Large Language Model (LLM) to achieve remarkable performance in various NLP tasks, including arithmetic problem-solving.However, this success does not generalize to small language model (sLM) like T5, due to their limited capacity and absence of emergent abilities associated with larger models.Recent works to enhance sLM through knowledge distillation have yielded some improvements but still face significant limitations, particularly high ambiguity from the variability in natural language expressions and substantial computational costs.In this paper, we investigate why sLM perform poorly on arithmetic reasoning tasks and hypothesize that natural language format variability introduces high ambiguity for these smaller models.Based on this hypothesis, we conduct experiments with equation-only format, which is a reasoning format that unifies arithmetic reasoning previously expressed in natural language formats into mathematical equations.Experiment results demonstrate that equation-only format effectively boosts the arithmetic reasoning abilities of sLM, especially in very small models like T5-Tiny.Preprint.Under review.</p>
<p>Introduction</p>
<p>Large Language Model(LLM)'s reasoning ability through Chain-of-Thought (CoT) [9,15] have demonstrated remarkable performance on various NLP downsteam tasks.Especially in recent times, it also has shown good results in tasks like arithmetic tasks, which involve solving mathematical problems.However, while CoT has significantly enhanced the arithmetic performance of "Large" Language models [4,2,1,6], this improvement does not generalize to small Language Model(sLM) such as T5 [12] due to the absence of emergent abilities, which are often linked to model scaling laws.</p>
<p>While LLM offer superior performance, their tremendous computational and memory demands make it impractical for most real-world applications [18,16].In environments such as edge devices, mobile platforms, or real-time systems, the resources required to run these models are simply not available.As a result, sLM become crucial for extending the reach of advanced language technologies, offering more efficient solutions for resource-constrained settings.By enhancing the reasoning capabilities of sLM, we can close the gap between the high-level performance of LLM and the practical needs of realworld use cases, enabling the deployment of sophisticated reasoning models even in environments with limited computational power.Recent works have tried to enhance the arithmetic reasoning abilities of sLM by transferring the reasoning capabilities of LLM, through techniques such as knowledge distillation [8,19,7].These approaches have led to some performance improvements, but they still lack absolute performance.</p>
<p>To explore the potential of sLM performance on arithmetic reasoning tasks, in this paper, we hypothesize and experimentally analyze why sLM has not performed well on arithmetic reasoning tasks in existing methods.Our main hypothesis is "Natural language format cause high ambiguity for sLM".Let's consider the mathematical expression "1+1=2."In a natural language format, this concept can be expressed in various ways.For instance, it could be framed as: "If Tom has 1 donut and Mike has 1 piece of bread, what is the total amount of food they have?"Alternatively, it could be expressed as: "If Emily has 1 MacBook and James has the same number, what is the total number of laptops they own?"This variability in natural language formats can increase ambiguity for sLM, which have relatively lower capacity compared to LLM.</p>
<p>Based on this hypothesis, we conduct experiments with equation-only format, which is a reasoning format that unifies arithmetic reasoning previously expressed in natural language formats into mathematical equations.As shown in figure 1, it corresponds to each specific mathematical problem with only a single reasoning format, eliminating variability in format and preventing sLM from experiencing ambiguity.Our experiments have demonstrated the effectiveness of the equation-only format, showing that it is particularly effective in very small sLM like T5-Tiny with lower cost than existing methods.</p>
<p>Related Works</p>
<p>Large Language Model(LLM)</p>
<p>Large Language Models (LLMs), such as GPT-4 [1], Llama-3 [6] and PaLM-2 [2] have revolutionized the field of natural language processing (NLP) by significantly advancing the understanding and generation of human language.These LLMs demonstrate remarkable performance across diverse tasks, ranging from natural language understanding and generation to more complex reasoning tasks.However, due to the limitation of not being fine-tuned on task-specific datasets, LLM often performs unsatisfactorily on certain tasks in zero-shot settings [10].Despite these challenges, advances in prompt engineering techniques, such as in-context learning [3] and chain-of-thought reasoning [15], have enabled LLM to achieve state-of-the-art performance on numerous tasks without the need for additional fine-tuning.</p>
<p>Although LLMs have revolutionized the field of NLP, their immense computational and memory requirements make them unsuitable for many real-world applications [18,16].In resource-constrained environments like edge devices, mobile platforms, or real-time systems, the necessary resources to operate such large models are often unavailable.Consequently, sLMs play a pivotal role in bringing advanced language technologies to these settings, offering more efficient alternatives.We report the performance of each model per reasoning format as accuracy.</p>
<p>Model</p>
<p>Arithmetic Reasoning</p>
<p>Arithmetic reasoning has long been recognized as a particularly challenging task for language models.Unlike other tasks, where language models can leverage large datasets and contextual understanding, even advanced LLM have struggled with arithmetic problems without additional support.Recent works such as CoT [15] reasoning, have significantly improved the performance of LLMs on arithmetic tasks.By guiding models to reason through problems step-by-step, CoT allows them to break down complex problems into more manageable parts, improving accuracy on tasks that require logical progression, including arithmetic reasoning.Additionally, various techniques, such as problem decomposition [17] and self-consistency [13], have further enhanced the capabilities of LLM.These methods have enabled LLMs to achieve near-human-level performance on established benchmarks such as SVAMP [11] and GSM8K [5].These improvements highlight the potential of LLMs when equipped with advanced reasoning and prompting techniques.</p>
<p>While LLMs have made significant strides, challenges remain.Small Language Models (sLMs), such as T5-base and GPT-2, struggle with arithmetic tasks.Chain-of-thought [15], which has proven crucial to improving arithmetic reasoning in LLMs, does not function effectively in sLMs due to emergent abilities at smaller scales [14].</p>
<p>3 Experiments</p>
<p>Experimental Setting</p>
<p>Dataset In order to explore how language models can effectively solve mathematical problems, we utilized the widely recognized Grade School Math 8K dataset (GSM8K) [5].This dataset is designed to assess a model's arithmetic reasoning and problem-solving abilities using elementarylevel mathematical problems.As illustrated in Fig 1, the task requires the model to solve math equations described in natural language and provide the correct answer to the posed question.</p>
<p>Model In this work, we employed the T5 [12] model.This model processes all inputs and outputs in a text format, making it well-suited for natural language tasks.For emergent abilities to activate and for performance to improve, a model needs to exceed a certain size.sLM is less likely to exhibit these abilities, and thus the methods commonly used in LLMs may not function as intended.This experiment was conducted to investigate which approaches are more suitable for small models-base, small, mini, tiny-when solving arithmetic tasks.</p>
<p>Result</p>
<p>As shown in Table 1, the accuracy of the T5-base model increased from 13% to 17%, and the T5-small model improved from 10% to 14%.A similar trend is observed in T5-mini and T5-tiny.These results demonstrate a consistent performance improvement across all model sizes when using equations only, compared to training with the natural language format approach.Previously, it was widely assumed that using natural language format would be more effective, regardless of model size.</p>
<p>Because natural language is richer in information and language models are typically pre-trained on natural language datasets.However, the result of this experiment contradict that assumption.In fact, for smaller models, such as those below T5-base, it was found that using equations-symbols and numbers with consistent structure-was more effective than relying on natural language, which is Observing the attention score map for the problems where "Equation only" was correct and "Natural Language" was incorrect in Fig 2 , we found that the attention scores for paired tokens such as "times" and "*", or "Half" and "/2", were higher in equation-only format.Furthermore, when using natural language, model generally exhibited a dispersed attention score and often assigning high scores to tokens that were unrelated to the correct answer.This suggests that due to the inherent ambiguity of natural language, it is necessary to consider the entire context, which may lead to a tendency to overlook truly important tokens.</p>
<p>Conclusion</p>
<p>In this paper, we investigated why small language models (sLMs) perform poorly on arithmetic reasoning tasks and proposed that the variability in natural language formats introduces significant ambiguity for these models.To address this, we hypothesized that by reducing the ambiguity through an equation-only format, we could improve performance.Our experiments demonstrated that the equation-only format consistently outperformed natural language formats, especially in smaller models like T5-Tiny, which lack the capacity to handle the inherent ambiguity of natural language reasoning effectively.In equation-only format, it was observed in attention score map that various names of variable and operation symbols were better mapped than natural language format.</p>
<p>Finding of this work suggests that simplifying reasoning tasks into more structured formats like equations can significantly enhance the arithmetic capabilities of sLMs without increasing computational costs.This is especially beneficial in resource-constrained environments where large models like LLMs are impractical.By adopting such methods, sLMs can be better optimized for real-world applications, making advanced reasoning more accessible and efficient.Future work could explore the application of this approach to other reasoning tasks, potentially expanding the utility of sLMs in various domains.</p>
<p>Figure 1 :
1
Figure 1: Overview of our experiment.We conduct experiment with two format: natural language format and equation-only format.Equation-only format corresponds to each specific mathematical problem with only a single reasoning format, eliminating variability in format and preventing sLM from experiencing ambiguity.</p>
<p>Figure 2 :
2
Figure 2: Cross-attention score map of T5 model</p>
<p>Table 1 :
1
Performance comparison for the Natural Language Format and Equation Only for GSM8K.
ParamSize Natural Language (%) Equation Only(%)T5-Base220M0.130.17T5-Small60M0.100.14T5-Mini31M0.080.11T5-Tiny16M0.070.10</p>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. Gpt-4 technical report. 2023arXiv preprint</p>
<p>. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.104032023Palm 2 technical report. arXiv preprint</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M F Balcan, H Lin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec RadfordCurran Associates, Inc202033Ilya Sutskever, and Dario Amodei</p>
<p>Palm: Scaling language modeling with pathways. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Journal of Machine Learning Research. 242402023</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.141682021arXiv preprint</p>
<p>The llama 3 herd of models. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, arXiv:2407.217832024arXiv preprint</p>
<p>Large language models are reasoning teachers. Namgyu Ho, Laura Schmid, Se-Young Yun, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational Linguistics20231</p>
<p>Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay Krishna, Chen-Yu Lee, Tomas Pfister, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Evaluating mathematical reasoning of large language models: A focus on error identification and correction. Xiaoyuan Li, Wenjie Wang, Moxin Li, Junrong Guo, Yang Zhang, Fuli Feng, Findings of the Association for Computational Linguistics ACL 2024. Lun-Wei Ku, Andre Martins, Vivek Srikumar, Bangkok, ThailandAssociation for Computational LinguisticsAugust 2024and virtual meeting</p>
<p>Are nlp models really able to solve simple math word problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterHuman Language Technologies2021</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of machine learning research. 211402020</p>
<p>Selfconsistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai Hsin, Chi , Denny Zhou, ArXiv, abs/2203.111712022</p>
<p>Emergent abilities of large language models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Transactions on Machine Learning Research. 2022</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>A survey on knowledge distillation of large language models. Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, Tianyi Zhou, ArXiv, abs/2402.131162024</p>
<p>Least-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, arXiv:2205.106252022arXiv preprint</p>
<p>A survey on efficient inference for large language models. Zixuan Zhou, Xuefei Ning, Ke Hong, Tianyu Fu, Jiaming Xu, Shiyao Li, Yuming Lou, Luning Wang, Zhihang Yuan, Xiuhong Li, Shengen Yan, Guohao Dai, Xiao-Ping Zhang, Yuhan Dong, Yu Wang, ArXiv, abs/2404.142942024</p>
<p>Distilling mathematical reasoning capabilities into small language models. Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang, Neural Networks. 1065942024</p>            </div>
        </div>

    </div>
</body>
</html>