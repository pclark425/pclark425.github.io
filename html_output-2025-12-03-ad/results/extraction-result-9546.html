<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9546 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9546</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9546</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-270845479</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.19497v1.pdf" target="_blank">Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are increasingly utilized to assist in scientific and academic writing, helping authors enhance the coherence of their articles. Previous studies have highlighted stereotypes and biases present in LLM outputs, emphasizing the need to evaluate these models for their alignment with human narrative styles and potential gender biases. In this study, we assess the alignment of three prominent LLMs - Claude 3 Opus, Mistral AI Large, and Gemini 1.5 Flash - by analyzing their performance on benchmark text-generation tasks for scientific abstracts. We employ the Linguistic Inquiry and Word Count (LIWC) framework to extract lexical, psychological, and social features from the generated texts. Our findings indicate that, while these models generally produce text closely resembling human authored content, variations in stylistic features suggest significant gender biases. This research highlights the importance of developing LLMs that maintain a diversity of writing styles to promote inclusivity in academic discourse.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9546",
    "paper_id": "paper-270845479",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0037884999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts
27 Jun 2024</p>
<p>Naseela Pervez 
Information Sciences Institute
University of Southern
California</p>
<p>Alexander J Titus 
Information Sciences Institute
University of Southern
California</p>
<p>Iovine and Young Academy
University of Southern California</p>
<p>In Vivo Group</p>
<p>Inclusivity in Large Language Models: Personality Traits and Gender Bias in Scientific Abstracts
27 Jun 2024F8768D93A6738182C918660E9A4CB3CEarXiv:2406.19497v1[cs.CL]Large Language Models (LLMs)Text GenerationGender BiasLinguistic Inquiry and Word Count (LIWC)Computational Linguistics
Large language models (LLMs) are increasingly utilized to assist in scientific and academic writing, helping authors enhance the coherence of their articles.Previous studies have highlighted stereotypes and biases present in LLM outputs, emphasizing the need to evaluate these models for their alignment with human narrative styles and potential gender biases.In this study, we assess the alignment of three prominent LLMs-Claude 3 Opus, Mistral AI Large, and Gemini 1.5 Flash-by analyzing their performance on benchmark text-generation tasks for scientific abstracts.We employ the Linguistic Inquiry and Word Count (LIWC) framework to extract lexical, psychological, and social features from the generated texts.Our findings indicate that, while these models generally produce text closely resembling human-authored content, variations in stylistic features suggest significant gender biases.This research highlights the importance of developing LLMs that maintain a diversity of writing styles to promote inclusivity in academic discourse.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) have gained popularity in recent years for their performance on benchmark natural language processing (NLP) tasks including, but not limited to, text summarization, text generation, and question answering.LLMs have the ability to generate texts (stories) that are grammatically correct, and coherent and keep the readers engaged.It is likely that in the near future LLMs will be adopted as assistants for many writing tasks such as rewriting and improving the language of text (e.g.student essays, newspaper article, book writing).Scientific texts like abstracts, proposals, and journal publications use scientific jargon.However, due to the technical nature of scientific publications, to our knowledge, there are no full-text scientific articles that have been written by LLMs yet.In this paper we have proposed an evaluation framework that reflects the traits of LLM written text for scientific literature.</p>
<p>Although scientific papers are aimed at conveying a technique, research solution, or a research proposal, every author has a writing style.This writing style has an impact on their readership.In theoretical psychology, there are well-established frameworks that quantify a piece of writing by various features.These features are what can be called the "personality" of the text.</p>
<p>Like all texts, scientific texts have a personality and scientific authorship is male-dominated [1].It has been established that male authors have a higher readership and citation count as well [2].There are two aspects to this bias in research communities [3] -1. the established stereotype that males are better researchers than females, and 2. the writing style of males (informative) is appreciated over the writing style of female researchers (descriptive) [4,5].</p>
<p>Research communities have made efforts to reduce the gender gaps between males and females.This is reflected in the appointment of female faculty, promotion of male-female collaborations as well as high-prestige institutions hiring female researchers as project leads that have improved the representation of females in academia and improved the reach of female research [6].It is therefore crucial to ensure that LLMs used for scientific writing do not create, or exacerbate, a gender bias based on the writing style.In this paper, we have focused on the following research questions:</p>
<p>1.When prompted to re-write a piece of scientific text, do LLMs maintain the narrative style of the text, implying that it maintains the author's personality?2. Do LLMs alleviate or undermine the personality traits of a scientific text?Do they accentuate positive traits and diminish negative traits?</p>
<p>Related Work</p>
<p>The manner in which a narrative is constructed can significantly influence the impact and dissemination of scientific literature, with varying styles potentially affecting the learning process of readers [7,8].Gender differences in writing styles have been observed, with female authors often adopting a more intimate and engaged tone, while male authors tend to employ a more directive and informational approach [9].These stylistic disparities can inadvertently contribute to gender and prestige biases within the research community, potentially impacting the visibility and reception of similar research findings [10,11].However, it is crucial to prioritize the value and outcomes of research above stylistic preferences, fostering an inclusive appreciation for the diversity of writing styles in academic and scientific discourse.</p>
<p>In the realm of computational linguistics, the analysis of language goes beyond mere comprehension, delving into the intricate features that underpin it.This quantification of language has found diverse applications, including the identification of authors' genders, detection of underlying psychological issues, and recognition of hate speech, among others [12][13][14].Established frameworks in linguistics and psychology [15][16][17] have been instrumental in text analysis, providing tools to examine the narrative style of a text from a lexical, psychological and social perspective.Research in this field posits that the these characteristics of a text serve as a mirror to the author's thought processes and personality traits [18,19].Consequently, a comprehensive understanding of an author's personality can be gleaned from a thorough analysis of their writings.This approach offers a panoramic view of the author's persona, further enriching the field of text analysis.</p>
<p>Previous studies have demonstrated that language styles can be associated with the author's gender [20,21].Research has extensively examined the directive style is typically used by males and the involved style is often employed by females [22].Quantifying the narrative style of a text provides a framework for exploring gender differences in language use within STEM fields and the research community.Although research output should be valued regardless of writing style, directive writing tends to receive more citations due to its conciseness, which allows readers to grasp the content without extensive analysis [23].</p>
<p>Large language models (LLMs) are extensively utilized in text generation tasks, as discussed in Section 1.There have been instances where LLMs reflect stereotypes, leading to gender bias in various societal contexts [24].However, studies have shown that with the use of efficient prompts, the personality traits of LLMs, such as extroversion and neuroticism, can be effectively tuned [25].Understanding the linguistic markers of LLM-generated text which reflect the lexical and psychological personality traits is an active and ongoing area of research.</p>
<p>To understand the extent to which LLMs induce gender bias in generated text, we conducted a correlation analysis comparing lexical, psychological, and social features computed by LIWC [15] of scientific abstracts re-generated by LLMs with those of human-written abstracts.Our study further includes an examination of differences between human-written and LLM-generated scientific abstracts to identify and quantify the gender gaps in these features.</p>
<p>Methodology</p>
<p>In this section, we present the methodology and framework of our research (Figure 1).We provide a detailed discussion of the data used for analysis, the large language models (LLMs) employed for text regeneration, and the prompts provided to these LLMs.Additionally, we describe the framework utilized to compute the lexical and psychological traits of the text.Finally, we explain our approach to quantifying the alignment between human and LLM-generated text features.</p>
<p>Data</p>
<p>For the analysis presented in this paper, we focused exclusively on scientific abstracts rather than full-text articles.We selected a subset of 3,390 abstracts from the CORE dataset [26].Although the dataset includes author details, it does not provide gender information.To address this, we used the Python library, genderextractor, to assign genders to the authors 4 .Table 1 shows the distribution of publications among male-only, female-only, and mixed-gender authors.</p>
<p>Given that many publications have both male and female authors, for the analysis of male vs. female personality alignment, we considered only publications authored solely by males or solely by females (n=1,364).However, to evaluate the overall alignment between human and LLM-generated abstracts, we utilized the entire dataset.</p>
<p>Large Language Models</p>
<p>The use of large language models (LLMs) has become increasingly prevalent in various natural language processing tasks.In this paper, we are using LLMs to rewrite scientific abstracts of authors.For regenerating the text of human-written scientific abstracts, we utilized three LLMs: Claude 3 Opus5 , Mistral AI Large [27], and Gemini 1.5 Flash [28].These models were selected due to their popularity and high performance on benchmark text-generation tasks including but not limited to question answering, mathematical reasoning, diagram understanding.Their performance on these benchmarks not only surpasses traditional machine learning algorithms but also stands on par with each other, showcasing their advanced capabilities in generating coherent and contextually accurate text.</p>
<p>The following prompt was consistently employed across all three LLMs for the regeneration of scientific abstracts:</p>
<p>"Given the scientific abstract, imagine yourself to be an author and researcher, and rewrite this abstract.The abstract is : [content of the abstract]"</p>
<p>Linguistic Inquiry and Word Count (LIWC)</p>
<p>Linguistic Inquiry and Word Count LIWC [15] is a text analysis framework comprising thousands of dictionaries.The software quantifies the lexical, psychological, and social features of a text based on these dictionaries.In this study, we utilized the LIWC-22 [29] dictionary for research and analysis.Given our focus on scientific writing, we employed LIWC features pertinent to this domain; for instance, the curse feature is not relevant for quantifying scientific abstracts.</p>
<p>For our analysis, we selected features relevant to the narration of scientific texts, concentrating on narrow rather than broad categories of LIWC features.The specific features we focused on for this research are: Segment, WC, Analytic, Clout, Tone, affiliation, achieve, power, insight, cause, discrep, tentat, certitude, differ, tone pos,tone neg, emotion, emo pos, emo neg, emo anx, emo anger, emo sad, prosocial, polite, conflict, moral, comm, politic, ethnicity, tech, reward, risk, curiosity, allure.</p>
<p>Comparison Between Human-Written and LLM-Generated Scientific Abstracts</p>
<p>Our objective is to determine the alignment between human and LLM-generated texts by comparing various features.We conduct two primary types of analyses:</p>
<p>Correlation Analysis: We employ the Pearson correlation coefficient to assess the relationship between human-written abstracts and those regenerated by three LLMs: Claude 3 Opus, Gemini 1.5 Flash, and Mistral AI Large.Specifically, we compute the correlations for each LLM to determine how closely their generated texts align with human-authored texts.This correlation analysis allows us to evaluate the association of lexical, psychological, and social features between human and LLM-generated abstracts.By doing so, we can assess the extent to which these LLMs replicate human personality traits in their generated scientific abstracts.</p>
<p>T-Test Analysis: We use t-tests to find the differences in means for the features of the following scientific abstracts:</p>
<p>-Female-authored abstracts vs. male-authored abstracts (Human Female vs. Human Male).-LLM-generated abstracts for female authors vs. LLM-generated abstracts for male authors (AI Female vs. AI Male).</p>
<p>These analyses are conducted for all three LLMs.The results are presented in the following section.</p>
<p>Results</p>
<p>In this section, we detail how the lexical, psychological, and social features of LLMrewritten scientific abstracts, obtained from LIWC, differ from those written by humans.We explore these differences in two key aspects: humans vs. LLMs, which examines the alignment of LLM personality traits with human personality traits, and males vs. females, which investigates whether the narrative style of LLMs reflects any gender bias.</p>
<p>Humans vs LLMs: Correlation Analysis</p>
<p>To assess the alignment of LIWC features between human-generated and LLMgenerated scientific abstracts, we computed Pearson correlation coefficients across all pairs of features.Our focus, however, lies specifically on the diagonal elements of this correlation matrix.</p>
<p>Figure 3 displays the p-values of the Pearson correlation coefficients between pairs of LIWC features.The heatmap reveals that along the diagonal, all feature pairs have p-values less than 0.05.This indicates that the Pearson correlation coefficient for all diagonal elements (representing LIWC features of humans vs LLMs) across all LLMs is statistically significant (p value &lt; 0.05).</p>
<p>A higher positive Pearson correlation coefficient between two features indicates that when one feature's value increases, the other feature tends to increase as well.In our study, interpreting the diagonal elements, a higher positive correlation suggests greater alignment between human and LLM-generated abstracts in terms of these features.Conversely, a higher negative correlation coefficient indicates an inverse relationship between the two datasets.In this context, a positive coefficient signifies similarity in the expression of features between humans and LLMs, reflecting alignment in personality traits.Conversely, a negative coefficient suggests  divergence, implying contrasting expressions of these traits between humans and LLMs.</p>
<p>In our correlation analysis of LIWC features comparing human-generated and LLM-generated text, we observed a significant positive correlation among the diagonal elements.However, we found minimal to no correlation between other pairs of features.Specifically, the diagonal elements prominently exhibit a strong positive correlation (see Figure 2).</p>
<p>Table 2 presents Pearson correlation coefficients for LIWC features comparing human-generated texts with those produced by all LLMs.It is important to note that all correlations are statistically significant (p-value ¡ 0.05).The lexical feature WC (word count) shows a weaker positive correlation (0.35) for Claude Opus compared to Gemini and Mistral (refer to Table 2).</p>
<p>Across cognitive features in Table 2, there is a generally higher positive correlation, indicating alignment between LLMs and humans.Notably, the feature "certitude," reflecting confidence in text, particularly lacks strength in Gemini, suggesting that scientific abstracts generated by LLMs may not convey certitude similarly to human-authored text.</p>
<p>Regarding tone features, tone pos and tone neg exhibit strong positive correlations between humans and all three LLMs.However, features related to emotions relevant to scientific writing (emotion and emo pos) show positive correlations but not as pronounced.</p>
<p>Analysis of social process features such as 'prosocial', 'polite', 'conflict', 'moral', and 'comm' reveals consistently high positive correlation coefficients across all three LLMs.Claude Opus particularly stands out with the highest values, indicating its texts closely mirror human social processes.</p>
<p>Features reflecting motives in LLM-generated scientific abstracts-'reward', 'risk', 'curiosity', and 'allure'-also demonstrate high positive correlations with human-written abstracts, suggesting precise capture and reflection of textual motives by LLMs.</p>
<p>Lastly, general topic categories-'politic', 'ethnicity', and 'tech'-exhibit higher correlations between humans and LLMs, indicating accurate reflection of document categories in regenerated texts.Our findings demonstrate a strong positive correlation between LIWC features in human-written and LLM-generated scientific abstracts across all three LLM models.This suggests that LLMs effectively capture the lexical characteristics, psychological traits, and social dynamics observed in human-authored texts.</p>
<p>Gender Bias: Two Sample t-test</p>
<p>We conducted a two-sample t-test to compare the LIWC features between male and female authors.Among the 35 features analyzed, 15 features showed a statistically significant t-statistic value (p-value &lt; 0.05).Table 3 presents the t-statistic values for scientific abstracts written by humans, as well as those generated by Claude, Gemini, and Mistral.In the table, the significant values are highlighted in bold and italicized for clarity.</p>
<p>For the lexical features, both WC (word count) and tone are statistically significant.On average, female authors use 5.86 times more words than male authors, a pattern that is also observed in the LLM-generated texts, as shown in table 3. Additionally, male authors tend to have a more positive tone in their abstracts compared to female authors, approximately 4 times more.Although LLMs reflect this same trend, it is noteworthy that the difference is less pronounced, especially for Claude.This highlights an important observation: while LLMs generally follow the authors' personality traits in lexical features, they can sometimes underestimate or overestimate these features.Among the cognitive features, insight, cause, and differ are statistically significant.The scientific abstracts show that female authors use approximately seven times more insightful words such as "know," "think," and "feel" compared to male authors.This pattern is also reflected in the LLM-generated texts, with similar values (table 3).For the feature differ, the difference in writing style between males and females is consistent across all LLMs except Mistral, where the t-statistic is not significant.Interestingly, for the feature cause (causation), the difference between male and female narration is significant, with females using more causation-centric terms.However, this trend is not followed by any of the LLMs.Although not a drastic difference, but LLMs do introduce bias in terms of using causation-centric words that is found approximately twice more in females than males.</p>
<p>We found that the psychological process of affect is significantly represented by three features: tone pos, emotion, and emo pos (p &lt; 0.05).These features, out of the eight selected, were the only ones to show statistical significance.They reflect the positive tone and emotional content present in the text.Interestingly, both human authors and large language models (LLMs) consistently indicated that texts authored by males exhibited at least three times more positivity than those authored by females (Table 1).However, it is noteworthy that the LLMs, specifically Claude and Mistral, tended to overestimate the emotional content and positivity in texts authored by males.This overestimation could potentially amplify the perceived gender disparity between male and female authors in the field.</p>
<p>In the domain of social behavior processes, the categories prosocial, polite, and conflict are statistically significant.Notably, while the difference in narration style between males and females regarding conflict is non-significant, it becomes sig-nificant in the texts generated by large language models (LLMs).This suggests that female authors use a more conflicting style of writing compared to their male counterparts.Additionally, male authors tend to adopt a significantly more polite writing style, approximately five times more polite on average than females that is consistent with existing literature [23].However, this distinction is underestimated in LLM-generated abstracts, contributing to a gender gap in the portrayal of politeness in writing styles (see table 3).</p>
<p>Moving on to the motive category, we identified risk and curiosity as two significant features.Our analysis revealed that male authors used approximately twice as many risk-associated words compared to female authors.However, this difference was only statistically significant (p &lt; 0.05) in texts regenerated by Claude, and not in those regenerated by Gemini or Mistral.In addition to this, the analysis shows a significant (p value &lt; 0.05) difference between male and female re-written abstracts by LLMs for achieve category reflecting that females use approximately thrice more words reflecting achievement which is not reflected in the human authored articles.</p>
<p>Additionally, our analysis found no significant difference (p &gt; 0.05) between male and female authors in terms of reflecting curiosity in their narrative style.Nevertheless, LLMs indicated that male authors adopted a narrative style that reflected more curiosity than their female counterparts (Table 2).This finding highlights the potential for LLMs to further exacerbate the gender gap in scientific writing by perpetuating biased representations of author characteristics.</p>
<p>We did not observe a gender gap in the lexical features and cognitive processes of scientific abstracts when comparing human authors to LLM-generated texts.However, for the psychological processes of affect and motive, LLMs tend to amplify the gender gap observed between males and females for certain features.Additionally, while not drastic, a gender gap is also present in the politeness feature within the social behavior category.The t-statistics for these features indicate a significant difference (see Figure 4).</p>
<p>Conclusion and Future Works</p>
<p>The study analyzes the personality traits reflected by LLMs in the context of employing them for scientific writing.The analysis reveals that the lexical, psychological, and social traits of text generated by LLMs closely align with those of human-written text.Therefore, it can be concluded that LLMs have the capacity to depict traits similar to those of human authors and researchers.This is notable because there is a fierce debate in the academic and scientific community about the value of LLM-generated text.</p>
<p>The study analyzes the personality traits reflected by LLMs in the context of employing them for scientific writing.The analysis reveals that the lexical, psychological, and social traits of text generated by LLMs closely align with those of human-written text, indicating that LLMs can depict traits similar to those of human authors and researchers.Additionally, we discovered that male and female authors exhibit distinct differences in narrative styles, particularly in terms of politeness, conflict, and risk-related words.LLMs not only reflect but also magnify these differences, potentially perpetuating gender stereotypes in scientific writing.This highlights a critical area for improvement in LLM training and deployment to ensure fair and unbiased text generation.Future research should focus on refining LLM algorithms to minimize bias and enhance their ability to generate equitable representations across different genders.</p>
<p>Future work should focus on not only rewriting the abstracts but also generating the abstracts for the male vs female-authored full-text articles and analyzing the gender bias in this case.Additionally, studying gender bias for various academic disciplines and across time is also an important step in detecting and mitigating bias in research communities.This will contribute to identifying the pros and cons of AI resources and how they can be improved for academic and scientific disciplines.</p>
<p>Authors</p>
<p>Naseela Pervez received her M.S Computer Science from Viterbi School of Engineering, University of Southern California (USC).Currently, she is a pre-doctoral research staff at Management of Innovation, Entrepreneurial Research, and Venture Analysis (MINERVA) and Information Sciences Institute (ISI) at the University of Southern California (USC).Her research interests include natural language processing, network science, social sciences, and fairness and bias in AI.</p>
<p>Alexander J. Titus received his Ph.D. in Quantitative Biomedical Sciences from Dartmouth College.Currently, he is a Principal Scientist at the Information Sciences Institute and Research Faculty at the Iovine and Young Academy at the University of Southern California (USC), and Founder and Principal Investigator at the In Vivo Group.His research interests include the applications of artificial intelligence to the life sciences and responsible AI development.</p>
<p>Fig. 1 .
1
Fig. 1.Flowchart illustrating the comparison of LIWC features in scientific abstracts written by humans and rewritten by LLMs to assess personality alignment.This framework is adapted for male vs female comparison as well.</p>
<p>Fig. 2 .
2
Fig. 2. Heatmap representing the pearson correlation coefficient of LIWC features between humans and LLMs -Claude, Gemini, Mistral (left to right)</p>
<p>Fig. 3 .
3
Fig. 3. Heatmap representing the significance (p value) of pearson correlation coefficient of LIWC features between humans and LLMs -Claude, Gemini, Mistral (left to right)</p>
<p>Table 1 .
1
Distribution of Genders in Scientific Abstracts from the CORE Dataset
GenderCountFemale418Male946Mixed-Gender 2026</p>
<p>Table 2 .
2
Pearson correlation for humans vs LLMs
LIWCClaude Gemini MistralSegmentNaNNaN NaNWC0.350.800.86Analytic0.330.490.37Clout0.730.800.77Tone0.750.750.72affiliation0.600.730.71achieve0.650.650.66power0.810.810.80insight0.810.810.82cause0.700.750.70discrep0.220.220.22tentat0.580.710.60certitude0.510.430.48differ0.660.750.73tone pos0.680.690.66tone neg0.800.800.76emotion0.510.550.55emo pos0.480.560.54emo neg0.720.730.63emo anx0.860.880.88emo anger0.750.760.72emo sad0.530.520.31prosocial0.820.790.80polite0.640.640.63conflict0.820.790.78moral0.700.640.59comm0.650.610.66politic0.850.880.85ethnicity0.860.920.91tech0.860.910.89reward0.660.660.66risk0.850.850.84curiosity0.740.790.80allure0.630.620.62</p>
<p>Table 3 .
3
t-test statistics for Males vs Females
LIWCHuman Claude Gemini MistralSegmentNaN NaNNaN NaNWC-5.86 -4.66 -6.13 -6.31Analytic-1.13 -1.63 -1.74 -1.22Clout-0.71 -1.86 -1.69 -1.44Tone3.931.77 2.37 2.43affiliation0.19 -0.71 -0.571.57achieve-0.78 -3.22 -2.15 -2.67power-0.420.75 -0.51 -0.27insight-6.74 -6.66 -7.64 -6.98cause-2.27 -0.51 -1.56 -1.38discrep-0.35 -0.33 -3.010.73tentat-0.310.231.670.86certitude-0.01 -0.54 -1.66 -1.90differ-3.20 -2.17 -3.11-1.59tone pos3.88 2.21 2.04 2.01tone neg-1.25 -1.12 -0.77-0.7emotion3.335.8 3.73 5.05emo pos3.82 6.20 4.71 5.64emo neg0.961.301.401.01emo anx-0.08 -0.010.220.12emo anger -0.310.270.36 -0.61emo sad1.070.270.670.79prosocial3.15 3.00 2.961.57polite5.70 3.70 4.10 2.82conflict-1.95 -2.53 -2.58 -2.00moral-1.63 -0.920.11 -0.14comm1.08 -1.42 -0.84 -1.52politic-0.60 -0.85 -1.26 -1.45ethnicity0.37 -0.510.28 -0.13tech1.660.850.931.54reward-1.84 -1.73-.12 -1.46risk2.61 2.101.941.93curiosity1.06 3.75 2.60 2.66allure-1.77 -0.48-0.9-0.3
Fig. 4. t-statistic values of statistically significant features ('Tone', 'achieve', 'cause', 'emotion', 'emo pos','polite','curiosity') which reflects gender gaps between human and LLM texts.</p>
<p>https://pypi.org/project/gender-extractor/
https://www.anthropic.com/news/claude-3-family</p>
<p>The issue of gender bias represented in authorship in the fields of exercise and rehabilitation: A 5-year research in indexed journals. N Rinaldo, G Piva, S Ryder, A Crepaldi, A Pasini, L Caruso, R Manfredini, S Straudi, F Manfredini, N Lamberti, J. Funct. Morphol. Kinesiol. 818Jan. 2023</p>
<p>Gender differences in research performance and its impact on careers: a longitudinal case study. P Van Den Besselaar, U Sandström, Scientometrics. 106Nov. 2015</p>
<p>Gender stereotypes in science education resources: A visual content analysis. A H Kerkhoven, P Russo, A M Land-Zandstra, A Saxena, F J Rodenburg, PLoS One. 11e0165037Nov. 2016</p>
<p>What's in a Word? Qualitative and Quantitative Analysis of Leadership Language in Anesthesiology Resident Feedback. N Arkin, C Lai, L M Kiwakyou, G M Lochbaum, A Shafer, S K Howard, E R Mariano, M Fassiotto, Journal of Graduate Medical Education. 112019</p>
<p>Women's underrepresentation in science: sociocultural and biological considerations. S J Ceci, W M Williams, S M Barnett, Psychol. Bull. 135Mar. 2009</p>
<p>Narrative style influences citation frequency in climate change science. A Hillier, R P Kelly, T Klinger, PLoS One. 11e0167983Dec. 2016</p>
<p>Narrative stories as mediators for serial learning. G H Bower, M C Clark, Psychonomic Science. 14Apr. 1969</p>
<p>Investigating writing style as a contributor to gender gaps in science and technology. E Levitskaya, K Kedrick, R J Funk, 2022</p>
<p>Research: Gender bias in scholarly peer review. M Helmer, M Schottdorf, A Neef, D Battaglia, mar 20176e21718</p>
<p>Bibliometrics: Global gender disparities in science. V Larivière, C Ni, Y Gingras, B Cronin, C R Sugimoto, Nature. 504Dec. 2013</p>
<p>Gender differences in deceivers writing style. V Pérez-Rosas, R Mihalcea, Human-Inspired Computing and Its Applications. A Gelbukh, F C Espinoza, S N Galicia-Haro, Springer International Publishing2014</p>
<p>Linguistic features identify alzheimer's disease in narrative speech. K C Fraser, J A Meltzer, F Rudzicz, Journal of Alzheimer's Disease. 492016</p>
<p>The role of storylines in hate speech detection (short paper). K Englmeier, Machine Learning for Trend and Weak Signal Detection in Social Networks and Social Media. 2020</p>
<p>The psychological meaning of words: Liwc and computerized text analysis methods. Y R Tausczik, J W Pennebaker, Journal of Language and Social Psychology. 292010</p>
<p>Sentiment analysis and social cognition engine (SEANCE): An automatic tool for sentiment, social cognition, and social-order analysis. S A Crossley, K Kyle, D S Mcnamara, Behavior Research Methods. 49June 2017</p>
<p>Empath: Understanding topic signals in large-scale text. E Fast, B Chen, M S Bernstein, Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, CHI '16. the 2016 CHI Conference on Human Factors in Computing Systems, CHI '16New York, NY, USAAssociation for Computing Machinery2016</p>
<p>Social anhedonia and affiliation: examining behavior and subjective reactions within a social interaction. K Llerena, S G Park, S M Couture, J J Blanchard, Psychiatry Res. 200Aug. 2012</p>
<p>Testing associations between language use in descriptions of playfulness and age, gender, and self-reported playfulness in german-speaking adults. K Brauer, R Sendatzki, R T Proyer, Frontiers in Psychology. 132022</p>
<p>Male and female spoken language differences: Stereotypes and evidence. A Haas, Psychological bulletin. 8631979</p>
<p>Selected linguistic sex differences during initial social interactions of same-sex and mixed-sex student dyads. J N Martin, R T Craig, Western Journal of Speech Communication. 4711983</p>
<p>A gramulator analysis of gendered language in cable news reportage. X Wen, P M Mccarthy, A C Strain, The Florida AI Research Society. 2013</p>
<p>Does writing style affect gender differences in the research performance of articles?: An empirical study of BERT-based textual sentiment analysis. Y Ma, Y Teng, Z Deng, L Liu, Y Zhang, Scientometrics. 128Apr. 2023</p>
<p>Gender bias and stereotypes in large language models. H Kotek, R Dockum, D Sun, Proceedings of The ACM Collective Intelligence Conference, CI '23. The ACM Collective Intelligence Conference, CI '23New York, NY, USAAssociation for Computing Machinery2023</p>
<p>Editing personality for large language models. S Mao, X Wang, M Wang, Y Jiang, P Xie, F Huang, N Zhang, 2024</p>
<p>Core: A global aggregation service for open access papers. P Knoth, D Herrmannova, M Cancellieri, L Anastasiou, N Pontika, S Pearce, B Gyawali, D Pride, Nature Scientific Data. 10366June 2023</p>
<p>Mistral 7b. A Q Jiang, A Sablayrolles, A Mensch, C Bamford, D S Chaplot, D De Las Casas, F Bressand, G Lengyel, G Lample, L Saulnier, L R Lavaud, M.-A Lachaux, P Stock, T L Scao, T Lavril, T Wang, T Lacroix, W E Sayed, 2023</p>
<p>. G Team, P Georgiev, V I Lei, R Burnell, L Bai, A Gulati, G Tanzer, D Vincent, Z Pan, S Wang, S Mariooryad, Y Ding, X Geng, F Alcober, R Frostig, M Omernick, L Walker, C Paduraru, C Sorokin, A Tacchetti, C Gaffney, S Daruki, O Sercinoglu, Z J Love, P Voigtlaender, R Jain, G Surita, K Mohamed, R Blevins, J Ahn, T Zhu, K Kawintiranon, O Firat, Y Gu, Y Zhang, M Rahtz, M Faruqui, N Clay, J Gilmer, J Co-Reyes, I Penchev, R Zhu, N Morioka, K Hui, K Haridasan, V Campos, M Mahdieh, M Guo, S Hassan, K Kilgour, A Vezer, H.-T Cheng, R De Liedekerke, S Goyal, P Barham, D Strouse, S Noury, J Adler, M Sundararajan, S Vikram, D Lepikhin, M Paganini, X Garcia, F Yang, D Valter, M Trebacz, K Vodrahalli, C Asawaroengchai, R Ring, N Kalb, L B Soares, S Brahma, D Steiner, T Yu, F Mentzer, A He, L Gonzalez, B Xu, R L Kaufman, L E Shafey, J Oh, T Hennigan, G Van Den Driessche, S Odoom, M Lucic, B Roelofs, S Lall, A Marathe, B Chan, S Ontanon, L He, D Teplyashin, J Lai, P Crone, B Damoc, L Ho, S Riedel, K Lenc, C.-K Yeh, A Chowdhery, Y Xu, M Kazemi, E Amid, A Petrushkina, K Swersky, A Khodaei, G Chen, C Larkin, M Pinto, G Yan, A P Badia, P Patil, S Hansen, D Orr, S M R Arnold, J Grimstad, A Dai, S Douglas, R Sinha, V Yadav, X Chen, E Gribovskaya, J Austin, J Zhao, K Patel, P Komarek, S Austin, S Borgeaud, L Friso, A Goyal, B Caine, K Cao, D.-W Chung, M Lamm, G Barth-Maron, T Kagohara, K Olszewska, M Chen, K Shivakumar, R Agarwal, H Godhia, R Rajwar, J Snaider, X Dotiwalla, Y Liu, A Barua, V Ungureanu, Y Zhang, B.-O Batsaikhan, M Wirth, J Qin, I Danihelka, T Doshi, M Chadwick, J Chen, S Jain, Q Le, A Kar, M Gurumurthy, C Li, R Sang, F Liu, L Lamprou, R Munoz, N Lintz, H Mehta, H Howard, M Reynolds, L Aroyo, Q Wang, L Blanco, A Cassirer, J Griffith, D Das, S Lee, J Sygnowski, Z Fisher, J Besley, R Powell, Z Ahmed, D Paulus, D Reitter, Z Borsos, R Joshi, A Pope, S Hand, V Selo, V Jain, N Sethi, M Goel, T Makino, R May, Z Yang, J Schalkwyk, C Butterfield, A Hauth, A Goldin, W Hawkins, E Senter, S Brin, O Woodman, M Ritter, E Noland, M Giang, V Bolina, L Lee, T Blyth, I Mackinnon, M Reid, O Sarvana, D Silver, A Chen, L Wang, L Maggiore, O Chang, N Attaluri, G Thornton, C.-C Chiu, O Bunyan, N Levine, T Chung, E Eltyshev, X Si, T Lillicrap, D Brady, V Aggarwal, B Wu, Y Xu, R Mcilroy, K Badola, P Sandhu, E Moreira, W Stokowiec, R Hemsley, D Li, A Tudor, P Shyam, E Rahimtoroghi, S Haykal, P Sprechmann, X Zhou, D Mincu, Y Li, R Addanki, K Krishna, X Wu, A Frechette, M Eyal, A Dafoe, D Lacey, J Whang, T Avrahami, Y Zhang, E Taropa, H Lin, D Toyama, E Rutherford, M Sano, H Choe, A Tomala, C Safranek-Shrader, N Kassner, M Pajarskas, M Harvey, S Sechrist, M Fortunato, C Lyu, G Elsayed, C Kuang, J Lottes, E Chu, C Jia, C.-W Chen, P Humphreys, K Baumli, C Tao, R Samuel, C N Santos, A Andreassen, N Rakićević, D Grewe, A Kumar, S Winkler, J Caton, A Brock, S Dalmia, H Sheahan, I Barr, Y Miao, P Natsev, J Devlin, F Behbahani, F Prost, Y Sun, A Myaskovsky, T S Pillai, D Hurt, A Lazaridou, X Xiong, C Zheng, F Pardo, X Li, D Horgan, J Stanton, M Ambar, F Xia, A Lince, M Wang, B Mustafa, A Webson, H Lee, R Anil, M Wicke, T Dozat, A Sinha, E Piqueras, E Dabir, S Upadhyay, A Boral, L A Hendricks, C Fry, J Djolonga, Y Su, J Walker, J Labanowski, R Huang, V Misra, J Chen, R Skerry-Ryan, A Singh, S Rijhwani, D Yu, A Castro-Ros, B Changpinyo, R Datta, S Bagri, A M Hrafnkelsson, M Maggioni, D Zheng, Y Sulsky, S Hou, T L Paine, A Yang, J Riesa, D Rogozinska, D Marcus, D E Badawy, Q Zhang, L Wang, H Miller, J Greer, L L Sjos, A Nova, H Zen, R Chaabouni, M Rosca, J Jiang, C Chen, R Liu, T Sainath, M Krikun, A Polozov, J.-B Lespiau, J Newlan, Z Cankara, S Kwak, Y Xu, P Chen, A Coenen, C Meyer, K Tsihlas, A Ma, J Gottweis, J Xing, C Gu, J Miao, C Frank, Z Cankara, S Ganapathy, I Dasgupta, S Hughes-Fitt, H Chen, D Reid, K Rong, H Fan, J Van Amersfoort, V Zhuang, A Cohen, S S Gu, A Mohananey, A Ilic, T Tobin, J Wieting, A Bortsova, P Thacker, E Wang, E Caveness, J Chiu, E Sezener, A Kaskasoli, S Baker, K Millican, M Elhawaty, K Aisopos, C Lebsack, N Byrd, H Dai, W Jia, M Wiethoff, E Davoodi, A Weston, L Yagati, A Ahuja, I Gao, G Pundak, S Zhang, M Azzam, K C Sim, S Caelles, J Keeling, A Sharma, A Swing, Y Li, C Liu, C G Bostock, Y Bansal, Z Nado, A Anand, J Lipschultz, A Karmarkar, L Proleev, A Ittycheriah, S H Yeganeh, G Polovets, A Faust, J Sun, A Rrustemi, P Li, R Shivanna, J Liu, C Welty, F Lebron, A Baddepudi, S Krause, E Parisotto, R Soricut, Z Xu, D Bloxwich, M Johnson, B Neyshabur, J Mao-Jones, R Wang, V Ramasesh, Z Abbas, A Guez, C Segal, D D Nguyen, J Svensson, L Hou, S York, K Milan, S Bridgers, W Gworek, M Tagliasacchi, J Lee-Thorp, M Chang, A Guseynov, A J Hartman, M Kwong, R Zhao, S Kashem, E Cole, A Miech, R Tanburn, M Phuong, F Pavetic, S Cevey, R Comanescu, R Ives, S Yang, C Du, B Li, Z Zhang, M Iinuma, C H Hu, A Roy, S Bijwadia, Z Zhu, D Martins, R Saputro, A Gergely, S Zheng, D Jia, I Antonoglou, A Sadovsky, S Gu, Y Bi, A Andreev, S Samangooei, M Khan, T Kocisky, A Filos, C Kumar, C Bishop, A Yu, S Hodkinson, S Mittal, P Shah, A Moufarek, Y Cheng, A Bloniarz, J Lee, P Pejman, P Michel, S Spencer, V Feinberg, X Xiong, N Savinov, C Smith, S Shakeri, D Tran, M Chesus, B Bohnet, G Tucker, T Von Glehn, C Muir, Y Mao, H Kazawa, A Slone, K Soparkar, D Shrivastava, J Cobon-Kerr, M Sharman, J Pavagadhi, C Araya, K Misiunas, N Ghelani, M Laskin, D Barker, Q Li, A Briukhov, N Houlsby, M Glaese, B Lakshminarayanan, N Schucher, Y Tang, E Collins, H Lim, F Feng, A Recasens, G Lai, A Magni, N D Cao, A Siddhant, Z Ashwood, J Orbay, M Dehghani, J Brennan, Y He, K Xu, Y Gao, C Saroufim, J Molloy, X Wu, S Arnold, S Chang, J Schrittwieser, E Buchatskaya, S Radpour, M Polacek, S Giordano, A Bapna, S Tokumine, V Hellendoorn, T Sottiaux, S Cogan, A Severyn, M Saleh, S Thakoor, L Shefey, S Qiao, M Gaba, S Chang, C Swanson, B Zhang, B Lee, P K Rubenstein, G Song, T Kwiatkowski, A Koop, A Kannan, D Kao, P Schuh, A Stjerngren, G Ghiasi, G Gibson, L Vilnis, Y Yuan, F T Ferreira, A Kamath, T Klimenko, K Franko, K Xiao, I Bhattacharya, M Patel, R Wang, A Morris, R Strudel, V Sharma, P Choy, S H Hashemi, J Landon, M Finkelstein, P Jhakra, J Frye, M Barnes, M Mauger, D Daun, K Baatarsukh, M Tung, W Farhan, H Michalewski, F Viola, F De Chaumont Quitry, C L Lan, T Hudson, Q Wang, F Fischer, I Zheng, E White, A Dragan, J Baptiste Alayrac, E Ni, A Pritzel, A Iwanicki, M Isard, A Bulanova, L Zilka, E Dyer, D Sachan, S Srinivasan, H Muckenhirn, H Cai, A Mandhane, M Tariq, J W Rae, G Wang, K Ayoub, N Fitzgerald, Y Zhao, W Han, C Alberti, D Garrette, K Krishnakumar, M Gimenez, A Levskaya, D Sohn, J Matak, I Iturrate, M B Chang, J Xiang, Y Cao, N Ranka, G Brown, A Hutter, V Mirrokni, N Chen, K Yao, Z Egyed, F Galilee, T Liechty, P Kallakuri, E Palmer, S Ghemawat, J Liu, D Tao, C Thornton, T Green, M Jasarevic, S Lin, V Cotruta, Y.-X Tan, N Fiedel, H Yu, E Chi, A Neitz, J Heitkaemper, A Sinha, D Zhou, Y Sun, C Kaed, B Hulse, S Mishra, M Georgaki, S Kudugunta, C Farabet, I Shafran, D Vlasic, A Tsitsulin, R Ananthanarayanan, A Carin, G Su, P Sun, S V , G Carvajal, J Broder, I Comsa, A Repina, W Wong, W W Chen, P Hawkins, E Filonov, L Loher, C Hirnschall, W Wang, J Ye, A Burns, H Cate, D G Wright, F Piccinini, L Zhang, C.-C Lin, I Gog, Y Kulizhskaya, A Sreevatsa, S Song, L C Cobo, A Iyer, C Tekur, G Garrido, Z Xiao, R Kemp, H S Zheng, H Li, A Agarwal, C Ngani, K Goshvadi, R Santamaria-Fernandez, W Fica, X Chen, C Gorgolewski, S Sun, R Garg, X Ye, ; H Lu, Z Tung, N Gaur, A Walton, L Dixon, M Zhang, A Globerson, G Uy, A Bolt, O Wiles, M Nasr, I Shumailov, M Selvi, F Piccinno, R Aguilar, S Mccarthy, M Khalman, M Shukla, V Galic, J Carpenter, K Villela, H Zhang, H Richardson, J Martens, M Bosnjak, S R Belle, J Seibert, M Alnahlawi, B Mcwilliams, S Singh, A Louis, W Ding, D Popovici, L Simicich, L Knight, P Mehta, N Gupta, C Shi, S Fatehi, J Mitrovic, A Grills, J Pagadora, D Petrova, D Eisenbud, Z Zhang, D Yates, B Mittal, N Tripuraneni, Y Assael, T Brovelli, P Jain, M Velimirovic, C Akbulut, J Mu, W Macherey, R Kumar, J Xu, H Qureshi, G Comanici, J Wiesner, Z Gong, A Ruddock, M Bauer, N Felt, A Gp, A Arnab, D Zelle, J Rothfuss, B Rosgen, A Shenoy, B Seybold, X Li, J Mudigonda, G Erdogan, J Xia, J Simsa, A Michi, Y Yao, C Yew, S Kan, I Caswell, C Radebaugh, A Elisseeff, P Valenzuela, K Mckinney, K Paterson, A Cui, E Latorre-Chimoto, S Kim, W Zeng, K Durden, P Ponnapalli, T Sosea, C A Choquette-Choo, ; S M Carthy, J Hoover, L Kim, S Kumar, W Chen, C Biles, G Bingham, E Rosen, L Wang, Q Tan, D Engel, F Pongetti, D De Cesare, D Hwang, L Yu, J Pullman, S Narayanan, K Levin, S Gopal, M Li, A Aharoni, T Trinh, J Lo, N Casagrande, R Vij, L Matthey, B Ramadhana, A Matthews, C Carey, M Johnson, K Goranova, R Shah, S Ashraf, K Dasgupta, R Larsen, Y Wang, M R Vuyyuru, C Jiang, J Ijazi, K Osawa, C Smith, R S Boppana, T Bilal, Y Koizumi, Y Xu, Y Altun, N Shabat, B Bariach, A Korchemniy, K Choo, O Ronneberger, C Iwuanyanwu, S Zhao, D Soergel, C.-J Hsieh, I Cai, S Iqbal, M Sundermeyer, Z Chen, E Bursztein, C Malaviya, F Biadsy, P Shroff, I Dhillon, T Latkar, C Dyer, H Forbes, M Nicosia, V Nikolaev, S Greene, M Georgiev, P Wang, N Martin, H Sedghi, J Zhang, P Banzal, D Fritz, V Rao, X Wang, J Zhang, J. Manyika, B. Robenek, H. Vashisht, S. Pereira, H. Lam, M. Velic, D. Owusu-Afriyie, K. Lee, T. Bolukbasi, A. Parrish, S. Lu, J. Park, B. Venkatraman, A. Talbert, L. Rosique, Y. Cheng, A. Sozanschi, A. Paszke, P. Kumar, J. Austin, L. Li, K. Salama, W. Kim, N. Dukkipati, A. Baryshnikov, C. Kaplanis, X. Sheng, Y. Chervonyi, C. Unlu, D. de Las Casas, H. Askham, K. Tunyasuvunakool, F. Gimeno, S. Poder, C. Kwak, M. Miecnikowski, V. Mirrokni, A. Dimitriev, A. Parisi, D. Liu, T. Tsai, T. Shevlane, C. Kouridi, D. Garmon, A. Goedeckemeyer, A. R. Brown, A. Vijayakumar, A. Elqursh, S. Jazayeri, J. Huang,Patraucean, D. Du, I. Mordatch, I. Jurin, L. Liu, A. Dubey, A. Mohan, J. Nowakowski, V.-D. Ion, N. Wei, R. Tojo, M. A. Raad, D. A. Hudson, V. Keshava, S. Agrawal, K. Ramirez, Z. Wu, H. Nguyen, J. Liu, M. Sewak, B. Petrini, D. Choi, I. Philips, Z. Wang, I. Bica, A. Garg, J. Wilkiewicz, P. Agrawal, X. Li, D. Guo, E. Xue, N. Shaik, A. Leach, S. M. Khan, J. Wiesinger, S. Jerome, A. Chakladar, A. W. Wang, T. Ornduff, F. Abu, A. Ghaffarkhah, M. Wainwright, M. Cortes, F. Liu, J. Maynez, S. Petrov, Y. Wu, D. Hassabis, K. Kavukcuoglu, J. Dean, and O. Vinyals, "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context," 2024.</p>
<p>The development and psychometric properties of liwc-22. R Boyd, A Ashokkumar, S Seraj, J Pennebaker, 022022</p>            </div>
        </div>

    </div>
</body>
</html>