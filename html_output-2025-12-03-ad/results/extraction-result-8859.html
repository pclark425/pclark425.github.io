<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8859 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8859</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8859</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-154.html">extraction-schema-154</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-2163dbd2c06f0aa326995b59c226e40553c4c63b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2163dbd2c06f0aa326995b59c226e40553c4c63b" target="_blank">NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> A model combining neural networks with logic programming in a novel manner for solving multi-hop reasoning tasks over natural language by using an Prolog prover to utilize a similarity function over pretrained sentence encoders and fine-tune the representations for the similarity function via backpropagation.</p>
                <p><strong>Paper Abstract:</strong> Rule-based models are attractive for various tasks because they inherently lead to interpretable and explainable decisions and can easily incorporate prior knowledge. However, such systems are difficult to apply to problems involving natural language, due to its large linguistic variability. In contrast, neural models can cope very well with ambiguity by learning distributed representations of words and their composition from data, but lead to models that are difficult to interpret. In this paper, we describe a model combining neural networks with logic programming in a novel manner for solving multi-hop reasoning tasks over natural language. Specifically, we propose to use an Prolog prover which we extend to utilize a similarity function over pretrained sentence encoders. We fine-tune the representations for the similarity function via backpropagation. This leads to a system that can apply rule-based reasoning to natural language, and induce domain-specific natural language rules from training data. We evaluate the proposed system on two different question answering tasks, showing that it outperforms two baselines – BiDAF (Seo et al., 2016a) and FastQA( Weissenborn et al., 2017) on a subset of the WikiHop corpus and achieves competitive results on the MedHop data set (Welbl et al., 2017).</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8859.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8859.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLProlog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic QA system that combines a backward-chaining Prolog-style prover with differentiable weak unification over pretrained sentence embeddings (SENT2VEC + MLP). It learns rule predicate embeddings via template-based ILP and fine-tunes encoders end-to-end to perform multi-hop reasoning on natural language triples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NLProlog</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Neuro-symbolic system: a symbolic backward-chaining prover (Prolog-style) where exact unification is replaced by a differentiable similarity function between embeddings; sentence predicates encoded with SENT2VEC (frozen) plus an MLP; entity and rule predicate embeddings learned/finetuned; rule templates used for ILP-style rule induction; proof search pruned by similarity threshold λ and limited depth D.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>MEDHOP and WikiHop (selected single-predicate subsets: publisher, developer, country, record_label)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Multi-hop document-level question answering where the answer requires combining facts across multiple documents (e.g., transitive relations like born_in(X,Z) ← born_in(X,Y) ∧ located_in(Y,Z)). Tasks require multi-step logical combination of natural-language facts represented as triples.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Weak (similarity-based) unification within backward-chaining prover; use of pretrained sentence embeddings (SENT2VEC) + MLP to compute cosine-based similarity in [0,1]; rule templates for learning rules via gradient-based optimization (ILP-style); pruning of proof search by similarity threshold λ and limiting proof depth D; aggregation of proof scores via min or product and max over proofs to get p(c|R;θ).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Development-set accuracies (Table 1): MEDHOP 65.78%; publisher 83.33%; developer 68.97%; country 77.84%; record_label 79.51%. Hidden MEDHOP test accuracy reported: 29.3% (noted as 6.1 pp better than FastQA on that test but 18.5 pp worse than BiDAF on hidden test).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against BiDAF and FastQA baselines (and their Sent2Vec-augmented variants). On the reported development subsets NLProlog outperforms the tested BiDAF and FastQA models on all predicates except developer (where it matches the best baseline). Ablations shown: removing rule templates (- rules) yields small to moderate drops on three of five tasks; removing entity-MLP (- entity MLP) dramatically reduces accuracy (e.g., MEDHOP down to 37.13% from 65.78%), indicating heavy reliance on learned entity embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Scalability: proof search worst-case exponential in proof depth; requires pruning heuristics (similarity threshold λ) and depth limit (D=3) to be tractable. Error analysis: 49% of WikiHop errors due to wrong entity unification (over-reliance on heuristics/spurious alignment), 25% due to labeling/candidate definition issues, 22% due to predicate unification errors (sentence does not express target relation). On hidden MEDHOP test performance dropped substantially vs dev. Much reasoning sometimes happens via aligning entity embeddings rather than applying explicit multi-hop rules.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Combining symbolic backward-chaining with pretrained sentence embeddings and end-to-end fine-tuning enables interpretable, rule-based multi-hop reasoning on natural language and can outperform strong neural QA baselines on several multi-hop tasks. Rule templates are beneficial in many cases, and fine-tuning entity embeddings is critical; pruning and thresholds are essential to keep proof search tractable. The method exposes failure modes (entity/predicate unification errors and over-reliance on embedding alignment) that can be diagnosed via produced proof trees.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8859.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8859.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BiDAF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Attention Flow for Machine Comprehension</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extractive neural reading-comprehension model using bidirectional attention flow between context and query to produce span-based answers; commonly used as a strong baseline for QA tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bidirectional attention flow for machine comprehension</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BiDAF</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>End-to-end neural QA model employing bidirectional attention between context and question to model interactions; extractive (predicts answer spans) and typically trained on large reading-comprehension corpora. In this paper BiDAF is evaluated as a baseline and also in variants augmented with SENT2VEC to map predicted answer spans to candidate entities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>WikiHop subsets and MEDHOP (multi-hop QA)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Multi-hop document-level QA requiring integration of multiple supporting sentences across documents; tasks are not strict formal logic benchmarks but require multi-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>End-to-end differentiable neural comprehension with bidirectional attention; in this paper also evaluated with an augmentation where predicted answer span and candidate entities are represented with SENT2VEC embeddings and nearest candidate is chosen (+Sent2Vec).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported development-set accuracies (Table 1): MEDHOP 42.98%; publisher 66.67%; developer 65.52%; country 53.09%; record_label 68.90%. Augmented variant (+Sent2Vec) improved some predicates (e.g., publisher 75.93%; developer 68.97%; country 61.86%; record_label 75.62%). Also a BiDAF trained on whole WikiHop (+Sent2Vec + wikihop) reported (publisher 74.07; developer 62.07; country 66.49; record_label 78.09).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>NLProlog outperforms BiDAF on most evaluated development-set predicates; BiDAF+Sent2Vec narrows the gap. On the hidden MEDHOP test BiDAF reportedly outperformed NLProlog (BiDAF was 18.5 pp better on hidden MEDHOP test).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Extractive design means BiDAF cannot directly use candidate entity lists; needs augmentation (+Sent2Vec) to map spans to provided candidates. Neural models perform reasoning implicitly via opaque differentiable operations, making interpretation difficult; they often require large training data and have limited ways to incorporate explicit background knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Pretrained sentence embeddings can improve extractive models on candidate-ranking tasks; however, implicit neural multi-hop reasoning remains hard to interpret and incorporate explicit rule knowledge into.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8859.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8859.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FastQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FastQA: A Simple and Efficient Neural Architecture for Question Answering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A lightweight, efficient neural extractive QA model that emphasizes simplicity and speed while retaining competitive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fastqa: A simple and efficient neural architecture for question answering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FastQA</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Simple and efficient extractive QA neural architecture; evaluated here as a baseline on multi-hop QA datasets, and in variants augmented with SENT2VEC to map predictions to candidate entities.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>MEDHOP and WikiHop subsets (multi-hop QA)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same multi-hop document-level QA setting as for other baselines: requires combining facts across documents to identify correct candidate entity answers.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>End-to-end neural extractive QA; in this work tested both standard FastQA and a variant where predicted answer span and candidate entities are embedded with SENT2VEC (+Sent2Vec) to pick the nearest candidate.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported development-set accuracies (Table 1): MEDHOP 52.63%; publisher 62.96%; developer 62.07%; country 57.21%; record_label 70.32%. +Sent2Vec variant: publisher 75.93%; developer 58.62%; country 64.95%; record_label 78.09%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>NLProlog outperforms FastQA on the evaluated development subsets (NLProlog higher on all reported predicates). On the hidden MEDHOP test NLProlog was 6.1 pp better than FastQA (though both experienced reliability issues between dev and hidden test).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Same limitations as other extractive neural models: implicit reasoning, difficulty incorporating explicit rules and background knowledge, dependence on large labeled data; performance varies with augmentation and domain-specific embeddings (e.g., biomedical embeddings used for MEDHOP).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Augmenting extractive QA with pretrained sentence embeddings (+Sent2Vec) to map to candidate entities can significantly improve practical performance on candidate-selection QA, but does not address interpretability or explicit multi-hop rule application.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8859.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8859.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NTPs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Theorem Provers (NTPs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable theorem-proving approach that relaxes backward-chaining and unification to continuous similarity operations so that logical proofs and parameters can be trained end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>End-toend differentiable proving</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Neural Theorem Provers (NTPs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Continuous relaxation of Prolog backward-chaining: a differentiable unification operator computes soft matches between symbols using embeddings so that proof success scores are differentiable and can be optimized via gradient descent; used for learning rules and reasoning over KBs in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>General differentiable proving / logical inference (prior work), applied to KB reasoning and rule learning tasks (not directly evaluated here).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Learning and scoring logical proofs via end-to-end differentiable relaxation of symbolic theorem proving; appropriate for learning rules from data and performing logical inference in a differentiable manner.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Continuous relaxation of backward-chaining and unification with differentiable similarity/unification, enabling gradient-based learning of embeddings and rule parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>No quantitative performance numbers reported in this paper; prior-work limitations and scaling behavior are discussed instead of direct performance metrics here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Cited as closely related prior work; not used as an experimental baseline in this paper. The paper contrasts NTPs' fully differentiable internal prover with NLProlog's approach of using an external prover plus pretrained embeddings to enable scalability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Major limitation highlighted: scalability — the number of candidate proofs grows exponentially with proof depth; NTPs do not scale to moderately-sized KBs and hence are currently not applicable to natural-language scale problems. This motivated NLProlog's strategy of using an external prover and pretrained encoders to prune the search.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Differentiable proving is a promising direction for learning logical rules end-to-end, but practical application to natural-language scale datasets requires addressing exponential proof-search complexity, e.g., via pruning, pretrained encoders, or external provers as done in NLProlog.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8859.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8859.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GCN-QA (De Cao et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Question answering by reasoning across documents with graph convolutional networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-based neural approach that constructs an entity/mention graph across documents and applies Graph Convolutional Networks to perform multi-hop reasoning for QA (reported as strong results on WikiHop).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Question answering by reasoning across documents with graph convolutional networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Graph Convolutional Network for multi-document QA (De Cao et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Builds a graph connecting entities/mentions across supporting documents and applies GCN layers to propagate and integrate evidence for multi-hop question answering; represents an alternative neural approach to multi-hop reasoning across documents.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>WikiHop (multi-document multi-hop QA)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Multi-hop QA across documents where entity graphs link mentions enabling relational propagation of evidence across multiple facts.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Graph construction over entities/mentions + Graph Convolutional Networks to propagate information across the constructed graph to answer multi-hop queries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>The paper cites De Cao et al. (2018) as achieving strong results on WikiHop, but does not report specific numeric results within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mentioned as a strong neural approach for WikiHop and contrasted with NLProlog's explicit rule-based/prover-based method; not used as a direct experimental baseline in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not detailed in this paper; mentioned to illustrate other neural approaches that perform multi-hop reasoning implicitly and achieve strong empirical results but remain opaque in reasoning steps compared to symbolic provers.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Graph-based propagation across entity mention graphs is an effective neural strategy for multi-hop QA; however, it performs implicit reasoning without producing human-readable rule-based proofs like NLProlog.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>End-toend differentiable proving <em>(Rating: 2)</em></li>
                <li>Bidirectional attention flow for machine comprehension <em>(Rating: 2)</em></li>
                <li>Fastqa: A simple and efficient neural architecture for question answering <em>(Rating: 2)</em></li>
                <li>Question answering by reasoning across documents with graph convolutional networks <em>(Rating: 2)</em></li>
                <li>Constructing datasets for multi-hop reading comprehension across documents <em>(Rating: 2)</em></li>
                <li>End-to-end memory networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8859",
    "paper_id": "paper-2163dbd2c06f0aa326995b59c226e40553c4c63b",
    "extraction_schema_id": "extraction-schema-154",
    "extracted_data": [
        {
            "name_short": "NLProlog",
            "name_full": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
            "brief_description": "A neuro-symbolic QA system that combines a backward-chaining Prolog-style prover with differentiable weak unification over pretrained sentence embeddings (SENT2VEC + MLP). It learns rule predicate embeddings via template-based ILP and fine-tunes encoders end-to-end to perform multi-hop reasoning on natural language triples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NLProlog",
            "model_description": "Neuro-symbolic system: a symbolic backward-chaining prover (Prolog-style) where exact unification is replaced by a differentiable similarity function between embeddings; sentence predicates encoded with SENT2VEC (frozen) plus an MLP; entity and rule predicate embeddings learned/finetuned; rule templates used for ILP-style rule induction; proof search pruned by similarity threshold λ and limited depth D.",
            "model_size": null,
            "reasoning_task_name": "MEDHOP and WikiHop (selected single-predicate subsets: publisher, developer, country, record_label)",
            "reasoning_task_description": "Multi-hop document-level question answering where the answer requires combining facts across multiple documents (e.g., transitive relations like born_in(X,Z) ← born_in(X,Y) ∧ located_in(Y,Z)). Tasks require multi-step logical combination of natural-language facts represented as triples.",
            "method_or_approach": "Weak (similarity-based) unification within backward-chaining prover; use of pretrained sentence embeddings (SENT2VEC) + MLP to compute cosine-based similarity in [0,1]; rule templates for learning rules via gradient-based optimization (ILP-style); pruning of proof search by similarity threshold λ and limiting proof depth D; aggregation of proof scores via min or product and max over proofs to get p(c|R;θ).",
            "performance": "Development-set accuracies (Table 1): MEDHOP 65.78%; publisher 83.33%; developer 68.97%; country 77.84%; record_label 79.51%. Hidden MEDHOP test accuracy reported: 29.3% (noted as 6.1 pp better than FastQA on that test but 18.5 pp worse than BiDAF on hidden test).",
            "baseline_comparison": "Compared against BiDAF and FastQA baselines (and their Sent2Vec-augmented variants). On the reported development subsets NLProlog outperforms the tested BiDAF and FastQA models on all predicates except developer (where it matches the best baseline). Ablations shown: removing rule templates (- rules) yields small to moderate drops on three of five tasks; removing entity-MLP (- entity MLP) dramatically reduces accuracy (e.g., MEDHOP down to 37.13% from 65.78%), indicating heavy reliance on learned entity embeddings.",
            "limitations_or_failures": "Scalability: proof search worst-case exponential in proof depth; requires pruning heuristics (similarity threshold λ) and depth limit (D=3) to be tractable. Error analysis: 49% of WikiHop errors due to wrong entity unification (over-reliance on heuristics/spurious alignment), 25% due to labeling/candidate definition issues, 22% due to predicate unification errors (sentence does not express target relation). On hidden MEDHOP test performance dropped substantially vs dev. Much reasoning sometimes happens via aligning entity embeddings rather than applying explicit multi-hop rules.",
            "insights_or_conclusions": "Combining symbolic backward-chaining with pretrained sentence embeddings and end-to-end fine-tuning enables interpretable, rule-based multi-hop reasoning on natural language and can outperform strong neural QA baselines on several multi-hop tasks. Rule templates are beneficial in many cases, and fine-tuning entity embeddings is critical; pruning and thresholds are essential to keep proof search tractable. The method exposes failure modes (entity/predicate unification errors and over-reliance on embedding alignment) that can be diagnosed via produced proof trees.",
            "uuid": "e8859.0",
            "source_info": {
                "paper_title": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "BiDAF",
            "name_full": "Bidirectional Attention Flow for Machine Comprehension",
            "brief_description": "An extractive neural reading-comprehension model using bidirectional attention flow between context and query to produce span-based answers; commonly used as a strong baseline for QA tasks.",
            "citation_title": "Bidirectional attention flow for machine comprehension",
            "mention_or_use": "use",
            "model_name": "BiDAF",
            "model_description": "End-to-end neural QA model employing bidirectional attention between context and question to model interactions; extractive (predicts answer spans) and typically trained on large reading-comprehension corpora. In this paper BiDAF is evaluated as a baseline and also in variants augmented with SENT2VEC to map predicted answer spans to candidate entities.",
            "model_size": null,
            "reasoning_task_name": "WikiHop subsets and MEDHOP (multi-hop QA)",
            "reasoning_task_description": "Multi-hop document-level QA requiring integration of multiple supporting sentences across documents; tasks are not strict formal logic benchmarks but require multi-step reasoning.",
            "method_or_approach": "End-to-end differentiable neural comprehension with bidirectional attention; in this paper also evaluated with an augmentation where predicted answer span and candidate entities are represented with SENT2VEC embeddings and nearest candidate is chosen (+Sent2Vec).",
            "performance": "Reported development-set accuracies (Table 1): MEDHOP 42.98%; publisher 66.67%; developer 65.52%; country 53.09%; record_label 68.90%. Augmented variant (+Sent2Vec) improved some predicates (e.g., publisher 75.93%; developer 68.97%; country 61.86%; record_label 75.62%). Also a BiDAF trained on whole WikiHop (+Sent2Vec + wikihop) reported (publisher 74.07; developer 62.07; country 66.49; record_label 78.09).",
            "baseline_comparison": "NLProlog outperforms BiDAF on most evaluated development-set predicates; BiDAF+Sent2Vec narrows the gap. On the hidden MEDHOP test BiDAF reportedly outperformed NLProlog (BiDAF was 18.5 pp better on hidden MEDHOP test).",
            "limitations_or_failures": "Extractive design means BiDAF cannot directly use candidate entity lists; needs augmentation (+Sent2Vec) to map spans to provided candidates. Neural models perform reasoning implicitly via opaque differentiable operations, making interpretation difficult; they often require large training data and have limited ways to incorporate explicit background knowledge.",
            "insights_or_conclusions": "Pretrained sentence embeddings can improve extractive models on candidate-ranking tasks; however, implicit neural multi-hop reasoning remains hard to interpret and incorporate explicit rule knowledge into.",
            "uuid": "e8859.1",
            "source_info": {
                "paper_title": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "FastQA",
            "name_full": "FastQA: A Simple and Efficient Neural Architecture for Question Answering",
            "brief_description": "A lightweight, efficient neural extractive QA model that emphasizes simplicity and speed while retaining competitive performance.",
            "citation_title": "Fastqa: A simple and efficient neural architecture for question answering",
            "mention_or_use": "use",
            "model_name": "FastQA",
            "model_description": "Simple and efficient extractive QA neural architecture; evaluated here as a baseline on multi-hop QA datasets, and in variants augmented with SENT2VEC to map predictions to candidate entities.",
            "model_size": null,
            "reasoning_task_name": "MEDHOP and WikiHop subsets (multi-hop QA)",
            "reasoning_task_description": "Same multi-hop document-level QA setting as for other baselines: requires combining facts across documents to identify correct candidate entity answers.",
            "method_or_approach": "End-to-end neural extractive QA; in this work tested both standard FastQA and a variant where predicted answer span and candidate entities are embedded with SENT2VEC (+Sent2Vec) to pick the nearest candidate.",
            "performance": "Reported development-set accuracies (Table 1): MEDHOP 52.63%; publisher 62.96%; developer 62.07%; country 57.21%; record_label 70.32%. +Sent2Vec variant: publisher 75.93%; developer 58.62%; country 64.95%; record_label 78.09%.",
            "baseline_comparison": "NLProlog outperforms FastQA on the evaluated development subsets (NLProlog higher on all reported predicates). On the hidden MEDHOP test NLProlog was 6.1 pp better than FastQA (though both experienced reliability issues between dev and hidden test).",
            "limitations_or_failures": "Same limitations as other extractive neural models: implicit reasoning, difficulty incorporating explicit rules and background knowledge, dependence on large labeled data; performance varies with augmentation and domain-specific embeddings (e.g., biomedical embeddings used for MEDHOP).",
            "insights_or_conclusions": "Augmenting extractive QA with pretrained sentence embeddings (+Sent2Vec) to map to candidate entities can significantly improve practical performance on candidate-selection QA, but does not address interpretability or explicit multi-hop rule application.",
            "uuid": "e8859.2",
            "source_info": {
                "paper_title": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "NTPs",
            "name_full": "Neural Theorem Provers (NTPs)",
            "brief_description": "A differentiable theorem-proving approach that relaxes backward-chaining and unification to continuous similarity operations so that logical proofs and parameters can be trained end-to-end.",
            "citation_title": "End-toend differentiable proving",
            "mention_or_use": "mention",
            "model_name": "Neural Theorem Provers (NTPs)",
            "model_description": "Continuous relaxation of Prolog backward-chaining: a differentiable unification operator computes soft matches between symbols using embeddings so that proof success scores are differentiable and can be optimized via gradient descent; used for learning rules and reasoning over KBs in prior work.",
            "model_size": null,
            "reasoning_task_name": "General differentiable proving / logical inference (prior work), applied to KB reasoning and rule learning tasks (not directly evaluated here).",
            "reasoning_task_description": "Learning and scoring logical proofs via end-to-end differentiable relaxation of symbolic theorem proving; appropriate for learning rules from data and performing logical inference in a differentiable manner.",
            "method_or_approach": "Continuous relaxation of backward-chaining and unification with differentiable similarity/unification, enabling gradient-based learning of embeddings and rule parameters.",
            "performance": "No quantitative performance numbers reported in this paper; prior-work limitations and scaling behavior are discussed instead of direct performance metrics here.",
            "baseline_comparison": "Cited as closely related prior work; not used as an experimental baseline in this paper. The paper contrasts NTPs' fully differentiable internal prover with NLProlog's approach of using an external prover plus pretrained embeddings to enable scalability.",
            "limitations_or_failures": "Major limitation highlighted: scalability — the number of candidate proofs grows exponentially with proof depth; NTPs do not scale to moderately-sized KBs and hence are currently not applicable to natural-language scale problems. This motivated NLProlog's strategy of using an external prover and pretrained encoders to prune the search.",
            "insights_or_conclusions": "Differentiable proving is a promising direction for learning logical rules end-to-end, but practical application to natural-language scale datasets requires addressing exponential proof-search complexity, e.g., via pruning, pretrained encoders, or external provers as done in NLProlog.",
            "uuid": "e8859.3",
            "source_info": {
                "paper_title": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "GCN-QA (De Cao et al.)",
            "name_full": "Question answering by reasoning across documents with graph convolutional networks",
            "brief_description": "A graph-based neural approach that constructs an entity/mention graph across documents and applies Graph Convolutional Networks to perform multi-hop reasoning for QA (reported as strong results on WikiHop).",
            "citation_title": "Question answering by reasoning across documents with graph convolutional networks",
            "mention_or_use": "mention",
            "model_name": "Graph Convolutional Network for multi-document QA (De Cao et al.)",
            "model_description": "Builds a graph connecting entities/mentions across supporting documents and applies GCN layers to propagate and integrate evidence for multi-hop question answering; represents an alternative neural approach to multi-hop reasoning across documents.",
            "model_size": null,
            "reasoning_task_name": "WikiHop (multi-document multi-hop QA)",
            "reasoning_task_description": "Multi-hop QA across documents where entity graphs link mentions enabling relational propagation of evidence across multiple facts.",
            "method_or_approach": "Graph construction over entities/mentions + Graph Convolutional Networks to propagate information across the constructed graph to answer multi-hop queries.",
            "performance": "The paper cites De Cao et al. (2018) as achieving strong results on WikiHop, but does not report specific numeric results within this paper.",
            "baseline_comparison": "Mentioned as a strong neural approach for WikiHop and contrasted with NLProlog's explicit rule-based/prover-based method; not used as a direct experimental baseline in this work.",
            "limitations_or_failures": "Not detailed in this paper; mentioned to illustrate other neural approaches that perform multi-hop reasoning implicitly and achieve strong empirical results but remain opaque in reasoning steps compared to symbolic provers.",
            "insights_or_conclusions": "Graph-based propagation across entity mention graphs is an effective neural strategy for multi-hop QA; however, it performs implicit reasoning without producing human-readable rule-based proofs like NLProlog.",
            "uuid": "e8859.4",
            "source_info": {
                "paper_title": "NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language",
                "publication_date_yy_mm": "2019-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "End-toend differentiable proving",
            "rating": 2
        },
        {
            "paper_title": "Bidirectional attention flow for machine comprehension",
            "rating": 2
        },
        {
            "paper_title": "Fastqa: A simple and efficient neural architecture for question answering",
            "rating": 2
        },
        {
            "paper_title": "Question answering by reasoning across documents with graph convolutional networks",
            "rating": 2
        },
        {
            "paper_title": "Constructing datasets for multi-hop reading comprehension across documents",
            "rating": 2
        },
        {
            "paper_title": "End-to-end memory networks",
            "rating": 1
        }
    ],
    "cost": 0.0156695,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>NLProlog: Reasoning with Weak Unification for Question Answering in Natural Language</h1>
<p>Leon Weber<br>Humboldt-Universität zu Berlin<br>weberple@hu-berlin.de<br>Pasquale Minervini<br>Jannes Münchmeyer<br>University College London GFZ German Research Center<br>p.minervini@ucl.ac.uk for Geoscience Potsdam<br>munchmej@gfz-potsdam.de</p>
<h2>Ulf Leser</h2>
<p>Humboldt-Universität
zu Berlin
leser@informatik.hu-berlin.de</p>
<h2>Tim Rocktäschel</h2>
<p>University College London
t.rocktaschel@cs.ucl.ac.uk</p>
<h2>Abstract</h2>
<p>Rule-based models are attractive for various tasks because they inherently lead to interpretable and explainable decisions and can easily incorporate prior knowledge. However, such systems are difficult to apply to problems involving natural language, due to its linguistic variability. In contrast, neural models can cope very well with ambiguity by learning distributed representations of words and their composition from data, but lead to models that are difficult to interpret. In this paper, we describe a model combining neural networks with logic programming in a novel manner for solving multi-hop reasoning tasks over natural language. Specifically, we propose to use a Prolog prover which we extend to utilize a similarity function over pretrained sentence encoders. We fine-tune the representations for the similarity function via backpropagation. This leads to a system that can apply rulebased reasoning to natural language, and induce domain-specific rules from training data. We evaluate the proposed system on two different question answering tasks, showing that it outperforms two baselines - BiDAF (Seo et al., 2016a) and FASTQA (Weissenborn et al., 2017b) on a subset of the WikiHop corpus and achieves competitive results on the MEDHOP data set (Welbl et al., 2017).</p>
<h2>1 Introduction</h2>
<p>We consider the problem of multi-hop reasoning on natural language data. For instance, consider the statements "Socrates was born in Athens" and "Athens belongs to Greece", and the question "Where was Socrates born?". There are two possible answers following from the given statements, namely "Athens" and "Greece". While the answer "Athens" follows directly from "Socrates was born in Athens", the answer "Greece" requires the reader to combine both statements, using the knowledge
that a person born in a city $X$, located in a country $Y$, is also born in $Y$. This step of combining multiple pieces of information is referred to as multi-hop reasoning (Welbl et al., 2017). In the literature, such multi-hop reading comprehension tasks are frequently solved via end-to-end differentiable (deep learning) models (Sukhbaatar et al., 2015; Peng et al., 2015; Seo et al., 2016b; Raison et al., 2018; Henaff et al., 2016; Kumar et al., 2016; Graves et al., 2016; Dhingra et al., 2018). Such models are capable of dealing with the linguistic variability and ambiguity of natural language by learning word and sentence-level representations from data. However, in such models, explaining the reasoning steps leading to an answer and interpreting the model parameters to extrapolate new knowledge is a very challenging task (DoshiVelez and Kim, 2017; Lipton, 2018; Guidotti et al., 2019). Moreover, such models tend to require large amounts of training data to generalise correctly, and incorporating background knowledge is still an open problem (Rocktäschel et al., 2015; Weissenborn et al., 2017a; Rocktäschel and Riedel, 2017; Evans and Grefenstette, 2017).</p>
<p>In contrast, rule-based models are easily interpretable, naturally produce explanations for their decisions, and can generalise from smaller quantities of data. However, these methods are not robust to noise and can hardly be applied to domains where data is ambiguous, such as vision and language (Moldovan et al., 2003; Rocktäschel and Riedel, 2017; Evans and Grefenstette, 2017).</p>
<p>In this paper, we introduce NLProLOG, a system combining a symbolic reasoner and a rulelearning method with distributed sentence and entity representations to perform rule-based multihop reasoning on natural language input. ${ }^{1}$ NLProLOG generates partially interpretable and explain-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>able models, and allows for easy incorporation of prior knowledge. It can be applied to natural language without the need of converting it to an intermediate logic form. At the core of NLProlog is a backward-chaining theorem prover, analogous to the backward-chaining algorithm used by Prolog reasoners (Russell and Norvig, 2010b), where comparisons between symbols are replaced by differentiable similarity function between their distributed representations (Sessa, 2002). To this end, we use end-to-end differentiable sentence encoders, which are initialized with pretrained sentence embeddings (Pagliardini et al., 2017) and then finetuned on a downstream task. The differentiable fine-tuning objective enables us learning domainspecific logic rules - such as transitivity of the relation is in - from natural language data. We evaluate our approach on two challenging multi-hop Question Answering data sets, namely MEDHOP and WIKIHOP (Welbl et al., 2017).</p>
<p>Our main contributions are the following: $i$ ) We show how backward-chaining reasoning can be applied to natural language data by using a combination of pretrained sentence embeddings, a logic prover, and fine-tuning via backpropagation, ii) We describe how a Prolog reasoner can be enhanced with a differentiable unification function based on distributed representations (embeddings), iii) We evaluate the proposed system on two different Question Answering (QA) datasets, and demonstrate that it achieves competitive results in comparison with strong neural QA models while providing interpretable proofs using learned rules.</p>
<h2>2 Related Work</h2>
<p>Our work touches in general on weak-unification based fuzzy logic (Sessa, 2002) and focuses on multi-hop reasoning for QA, the combination of logic and distributed representations, and theorem proving for question answering.</p>
<p>Multi-hop Reasoning for QA. One prominent approach for enabling multi-hop reasoning in neural QA models is to iteratively update a query embedding by integrating information from embeddings of context sentences, usually using an attention mechanism and some form of recurrency (Sukhbaatar et al., 2015; Peng et al., 2015; Seo et al., 2016b; Raison et al., 2018). These models have achieved state-of-the-art results in a number of reasoning-focused QA tasks. Henaff et al. (2016) employ a differentiable memory structure
that is updated each time a new piece of information is processed. The memory slots can be used to track the state of various entities, which can be considered as a form of temporal reasoning. Similarly, the Neural Turing Machine (Graves et al., 2016) and the Dynamic Memory Network (Kumar et al., 2016), which are built on differentiable memory structures, have been used to solve synthetic QA problems requiring multi-hop reasoning. Dhingra et al. (2018) modify an existing neural QA model to additionally incorporate coreference information provided by a coreference resolution model. De Cao et al. (2018) build a graph connecting entities and apply Graph Convolutional Networks (Kipf and Welling, 2016) to perform multi-hop reasoning, which leads to strong results on WIKIHOP. Zhong et al. (2019) propose a new neural QA architecture that combines a combination of coarse-grained and fine-grained reasoning to achieve very strong results on WIKIHOP.</p>
<p>All of the methods above perform reasoning implicitly as a sequence of opaque differentiable operations, making the interpretation of the intermediate reasoning steps very challenging. Furthermore, it is not obvious how to leverage user-defined inference rules during the reasoning procedure.</p>
<p>Combining Rule-based and Neural Models. In Artificial Intelligence literature, integrating symbolic and sub-symbolic representations is a longstanding problem (Besold et al., 2017). Our work is very related to the integration of Markov Logic Networks (Richardson and Domingos, 2006) and Probabilistic Soft Logic (Bach et al., 2017) with word embeddings, which was applied to Recognizing Textual Entailment (RTE) and Semantic Textual Similarity (STS) tasks (Garrette et al., 2011, 2014; Beltagy et al., 2013, 2014), improving over purely rule-based and neural baselines.</p>
<p>An area in which neural multi-hop reasoning models have been investigated is Knowledge Base Completion (KBC) (Das et al., 2016; Cohen, 2016; Neelakantan et al., 2015; Rocktäschel and Riedel, 2017; Das et al., 2017; Evans and Grefenstette, 2018). While QA could be in principle modeled as a KBC task, the construction of a Knowledge Base $(\mathrm{KB})$ from text is a brittle and error prone process, due to the inherent ambiguity of natural language.</p>
<p>Very related to our approach are Neural Theorem Provers (NTPs) (Rocktäschel and Riedel, 2017): given a goal, its truth score is computed via a continuous relaxation of the backward-chaining rea-</p>
<p>soning algorithm, using a differentiable unification operator. Since the number of candidate proofs grows exponentially with the length of proofs, NTPs cannot scale even to moderately sized knowledge bases, and are thus not applicable to natural language problems in its current form. We solve this issue by using an external prover and pretrained sentence representations to efficiently discard all proof trees producing proof scores lower than a given threshold, significantly reducing the number of candidate proofs.</p>
<p>Theorem Proving for Question Answering. Our work is not the first to apply theorem proving to QA problems. Angeli et al. (2016) employ a system based on Natural Logic to search a large KB for a single statement that entails the candidate answer. This is different from our approach, as we aim to learn a set of rules that combine multiple statements to answer a question.</p>
<p>Systems like Watson (Ferrucci et al., 2010) and COGEX (Moldovan et al., 2003) utilize an integrated theorem prover, but require a transformation of the natural language sentences to logical atoms. In the case of COGEX, this improves the accuracy of the underlying system by $30 \%$, and increases its interpretability. While this work is similar in spirit, we greatly simplify the preprocessing step by replacing the transformation of natural language to logic with the simpler approach of transforming text to triples by using co-occurences of named entities.</p>
<p>Fader et al. (2014) propose OPENQA, a system that utilizes a mixture of handwritten and automatically obtained operators that are able to parse, paraphrase and rewrite queries, which allows them to perform large-scale QA on KBs that include Open IE triples. While this work shares the same goal - answering questions using facts represented by natural language triples - we choose to address the problem of linguistic variability by integrating neural components, and focus on the combination of multiple facts by learning logical rules.</p>
<h2>3 Background</h2>
<p>In the following, we briefly introduce the backward chaining algorithm and unification procedure (Russell and Norvig, 2016) used by Prolog reasoners, which lies at the core of NLProlog. We consider Prolog programs that consists of a set of rules in
the form of Horn clauses:</p>
<p>$$
\begin{aligned}
&amp; h\left(f_{1}^{h}, \ldots, f_{n}^{h}\right) \Leftarrow \
&amp; \quad p_{1}\left(f_{1}^{1}, \ldots, f_{m}^{1}\right) \wedge \ldots \wedge p_{B}\left(f_{1}^{B}, \ldots, f_{l}^{B}\right)
\end{aligned}
$$</p>
<p>where $h, p_{i}$ are predicate symbols, and $f_{j}^{i}$ are either function (denoted in lower case) or variable (upper case) symbols. The domain of function symbols is denoted by $\mathcal{F}$, and the domain of predicate symbols by $\mathcal{P} . h\left(f_{1}^{h}, \ldots, f_{n}^{h}\right)$ is called the head and $p_{1}\left(f_{1}^{1}, \ldots, f_{m}^{1}\right) \wedge \ldots \wedge p_{B}\left(f_{1}^{B}, \ldots, f_{l}^{B}\right)$ the body of the rule. We call $B$ the body size of the rule and rules with a body size of zero are named atoms (short for atomic formula). If an atom does not contain any variable symbols it is termed fact.</p>
<p>For simplicity, we only consider function-free Prolog in our experiments, i.e. Datalog (Gallaire and Minker, 1978) programs where all function symbols have arity zero and are called entities and, similarly to related work (Sessa, 2002; JuliánIranzo et al., 2009), we disregard negation and disjunction. However, in principle NLProlog also supports functions with higher arity.</p>
<p>A central component in a Prolog reasoner is the unification operator: given two atoms, it tries to find variable substitutions that make both atoms syntactically equal. For example, the atoms country(Greece, Socrates) and country $(X, Y)$ result in the following variable substitutions after unification: ${X /$ Greece, $Y /$ Socrates $}$.</p>
<p>Prolog uses backward chaining for proving assertions. Given a goal atom $g$, this procedure first checks whether $g$ is explicitly stated in the KB in this case, it can be proven. If it is not, the algorithm attempts to prove it by applying suitable rules, thereby generating subgoals that are proved next. To find applicable rules, it attempts to unify $g$ with the heads of all available rules. If this unification succeeds, the resulting variable substitutions are applied to the atoms in the rule body: each of those atoms becomes a subgoal, and each subgoal is recursively proven using the same strategy.</p>
<p>For instance, the application of the rule $\operatorname{country}(X, Y) \Leftarrow \operatorname{born} _$in $(Y, X)$ to the goal country(Greece, Socrates) would yield the subgoal born_in(Socrates, Greece). Then the process is repeated for all subgoals until no subgoal is left to be proven. The result of this procedure is a set of rule applications and variable substitutions referred to as proof. Note that the number of possible proofs grows exponentially with its depth, as every rule might be used in the proof of each subgoal.</p>
<p>Pseudo code for weak unification can be found in Appendix A - we refer the reader to (Russell and Norvig, 2010a) for an in-depth treatment of the unification procedure.</p>
<h2>4 NLProlog</h2>
<p>Applying a logic reasoner to QA requires transforming the natural language paragraphs to logical representations, which is a brittle and error-prone process.</p>
<p>Our aim is reasoning with natural language representations in the form of triples, where entities and relations may appear under different surface forms. For instance, the textual mentions is located in and lies in express the same concept. We propose replacing the exact matching between symbols in the Prolog unification operator with a weak unification operator (Sessa, 2002), which allows to unify two different symbols $s_{1}, s_{2}$, by comparing their representations using a differentiable similarity function $s_{1} \sim_{\theta} s_{2} \in[0,1]$ with parameters $\theta$.</p>
<p>With the weak unification operator, the comparison between two logical atoms results in an unification score resulting from the aggregation of each similarity score. Inspired by fuzzy logic tnorms (Gupta and Qi, 1991), aggregation operators are e.g. the minimum or the product of all scores. The result of backward-chaining with weak unification is a set of proofs, each associated with a proof score measuring the truth degree of the goal with respect to a given proof. Similarly to backward chaining, where only successful proofs are considered, in NLProLOG the final proof success score is obtained by taking the maximum over the success scores of all found proofs. NLProLOG combines inference based on the weak unification operator and distributed representations, to allow reasoning over sub-symbolic representations - such as embeddings - obtained from natural language statements.</p>
<p>Each natural language statement is first translated into a triple, where the first and third element denote the entities involved in the sentence, and the second element denotes the textual surface pattern connecting the entities. All elements in each triple - both the entities and the textual surface pattern - are then embedded into a vector space. These vector representations are used by the similarity function $\sim_{\theta}$ for computing similarities between two entities or two textual surface patterns and, in turn, by the backward chaining algorithm with
the weak unification operator for deriving a proof score for a given assertion. Note that the resulting proof score is fully end-to-end differentiable with respect to the model parameters $\theta$ : we can train NLProLOG using gradient-based optimisation by back-propagating the prediction error to $\theta$. Fig. 1 shows an outline of the model, its components and their interactions.</p>
<h3>4.1 Triple Extraction</h3>
<p>To transform the support documents to natural language triples, we first detect entities by performing entity recognition with SPACY (Honnibal and Montani, 2017). From these, we generate triples by extracting all entity pairs that co-occur in the same sentence and use the sentence as the predicate blinding the entities. For instance, the sentence "Socrates was born in Athens and his father was Sophronicus" is converted in the following triples: i) (Socrates, ENT1 was born in ENT2 and his father was Sophronicus, Athens), ii) (Socrates, ENT1 was born in Athens and his father was ENT2, Sophronicus), and iii) (Athens, Socrates was born in ENT1 and his father was ENT2, Sophronicus). We also experimented with various Open Information Extraction frameworks (Niklaus et al., 2018): in our experiments, such methods had very low recall, which led to significantly lower accuracy values.</p>
<h3>4.2 Similarity Computation</h3>
<p>Embedding representations of the symbols in a triple are computed using an encoder $\mathbf{e}<em _theta="\theta">{\theta}: \mathcal{F} \cup \mathcal{P} \mapsto$ $\mathbb{R}^{d}$ parameterized by $\theta$ - where $\mathcal{F}, \mathcal{P}$ denote the sets of entity and predicate symbols, and $d$ denotes the embedding size. The resulting embeddings are used to induce the similarity function $\sim</em> \mapsto[0,1]$, given by their cosine similarity scaled to $[0,1]$ :}:(\mathcal{F} \cup \mathcal{P})^{2</p>
<p>$$
s_{1} \sim_{\theta} s_{2}=\frac{1}{2}\left(1+\frac{\mathbf{e}<em 1="1">{\theta}\left(s</em>}\right)^{\top} \mathbf{e<em 2="2">{\theta}\left(s</em>}\right)}{\left|\mathbf{e<em 1="1">{\theta}\left(s</em>}\right)\right| \cdot\left|\mathbf{e<em 2="2">{\theta}\left(s</em>\right)
$$}\right)\right|</p>
<p>In our experiments, for using textual surface patterns, we use a sentence encoder composed of a static pre-trained component - namely, SENT2VEC (Pagliardini et al., 2017) - and a MultiLayer Perceptron (MLP) with one hidden layer and Rectified Linear Unit (ReLU) activations (Jarrett et al., 2009). For encoding predicate symbols and entities, we use a randomly initialised embedding matrix. During training, both the MLP and the embedding matrix are learned via backpropagation, while the sentence encoder is kept fixed.</p>
<p>Additionally, we introduce a third lookup table and MLP for the predicate symbols of rules and goals. The main reason of this choice is that semantics of goal and rule predicates may differ from the semantics of fact predicates, even if they share the same surface form. For instance, the query $(X$, parent, $Y$ ) can be interpreted either as $(X$, is the parent of, $Y)$ or as $(X$, has parent, $Y)$, which are semantically dissimilar.</p>
<h3>4.3 Training the Encoders</h3>
<p>We train the encoder parameters $\theta$ on a downstream task via gradient-based optimization. Specifically, we train NLProLOG with backpropagation using a learning from entailment setting (Muggleton and Raedt, 1994), in which the model is trained to decide whether a Prolog program $\mathcal{R}$ entails the truth of a candidate triple $c \in C$, where $C$ is the set of candidate triples. The objective is a model that assigns high probabilities $p(c \mid \mathcal{R} ; \theta)$ to true candidate triples, and low probabilities to false triples. During training, we minimize the following loss:</p>
<p>$$
\begin{aligned}
L(\theta)= &amp; -\log p(a \mid \mathcal{R} ; \theta) \
&amp; -\log \left(1-\max _{c \in C \backslash{a}} p(c \mid \mathcal{R} ; \theta)\right)
\end{aligned}
$$</p>
<p>where $a \in C$ is the correct answer. For simplicity, we assume that there is only one correct answer per example, but an adaptation to multiple correct answers would be straight-forward, e.g. by taking the minimum of all answer scores.</p>
<p>To estimate $p(c \mid \mathcal{R} ; \theta)$, we enumerate all proofs for the triple $c$ up to a given depth $D$, where $D$ is a user-defined hyperparameter. This search yields a number of proofs, each with a success score $S_{i}$. We set $p(c \mid \mathcal{R} ; \theta)$ to be the maximum of such proof scores:</p>
<p>$$
p(c \mid \mathcal{R} ; \theta)=S_{\max }=\max <em i="i">{i} S</em> \in[0,1]
$$</p>
<p>Note that the final proof score $p(c \mid \mathcal{R} ; \theta)$ only depends on the proof with maximum success score $S_{\text {max }}$. Thus, we propose to first conduct the proof search by using a prover utilizing the similarity function induced by the current parameters $\sim_{\theta_{\mathrm{t}}}$, which allows us to compute the maximum proof score $S_{\text {max }}$. The score for each proof is given by the aggregation - either using the minimum or the product functions - of the weak unification scores, which in turn are computed via the differentiable similarity function $\sim_{\theta}$. It follows that $p(c \mid \mathcal{R} ; \theta)$
is end-to-end differentiable, and can be used for updating the model parameters $\theta$ via Stochastic Gradient Descent.</p>
<h3>4.4 Runtime Complexity of Proof Search</h3>
<p>The worst case complexity vanilla logic programming is exponential in the depth of the proof (Russell and Norvig, 2010a). However, in our case, this is a particular problem because weak unification requires the prover to attempt unification between all entity and predicate symbols.</p>
<p>To keep things tractable, NLProLOG only attempts to unify symbols with a similarity greater than some user-defined threshold $\lambda$. Furthermore, in the search step for one statement $q$, for the rest of the search, $\lambda$ is set to $\max (\lambda, S)$ whenever a proof for $q$ with success score $S$ is found. Due to the monotonicity of the employed aggregation functions, this allows to prune the search tree without losing the guarantee to find the proof yielding the maximum success score $S_{\max }$, provided that $S_{\max } \geq \lambda$. We found this optimization to be crucial to make the proof search scale on the considered data sets.</p>
<h3>4.5 Rule Learning</h3>
<p>In NLProLOG, the reasoning process depends on rules that describe the relations between predicates. While it is possible to write down rules involving natural language patterns, this approach does not scale. Thus, we follow Rocktäschel and Riedel (2017) and use rule templates to perform Inductive Logic Programming (ILP) (Muggleton, 1991), which allows NLProLOG to learn rules from training data. In this setting, a user has to define a set of rules with a given structure as input. Then, NLProLOG can learn the rule predicate embeddings from data by minimizing the loss function in Eq. (2) using gradient-based optimization methods.</p>
<p>For instance, to induce a rule that can model transitivity, we can use a rule template of the form $p_{1}(X, Z) \Leftarrow p_{2}(X, Y) \wedge p_{3}(Y, Z)$, and NLProLOG will instantiate multiple rules with randomly initialized embeddings for $p_{1}, p_{2}$, and $p_{3}$, and finetune them on a downstream task. The exact number and structure of the rule templates is treated as a hyperparameter.</p>
<p>Unless explicitly stated otherwise, all experiments were performed with the same set of rule templates containing two rules for each of the forms $q(X, Y) \Leftarrow p_{2}(X, Y), p_{1}(X, Y) \Leftarrow$ $p_{2}(Y, X)$ and $p_{1}(X, Z) \Leftarrow p_{2}(X, Y) \wedge p_{3}(Y, Z)$,</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of NLPROLOG - all components are depicted as ellipses, while inputs and outputs are drawn as squares. Phrases with red background are entities and blue ones are predicates.
where $q$ is the query predicate. The number and structure of these rule templates can be easily modified, allowing the user to incorporate additional domain-specific background knowledge, such as born_in $(X, Z) \Leftarrow$ born_in $(X, Y) \wedge$ located_in $(Y, Z)$</p>
<h2>5 Evaluation</h2>
<p>We evaluate our method on two QA datasets, namely MEDHOP, and several subsets of WikiHOP (Welbl et al., 2017). These data sets are constructed in such a way that it is often necessary to combine information from multiple documents to derive the correct answer.</p>
<p>In both data sets, each data point consists of a query $p(e, X)$, where $e$ is an entity, $X$ is a variable - representing the entity that needs to be predicted, $C$ is a list of candidates entities, $a \in C$ is an answer entity and $p$ is the query predicate. Furthermore, every query is accompanied by a set of support documents which can be used to decide which of the candidate entities is the correct answer.</p>
<h3>5.1 MedHop</h3>
<p>MEDHOP is a challenging multi-hop QA data set, and contains only a single query predicate. The goal in MEDHOP is to predict whether two drugs interact with each other, by considering the interactions between proteins that are mentioned in the support documents. Entities in the support documents are mapped to data base identifiers. To compute better entity representations, we reverse this mapping and replace all mentions with the
drug and proteins names gathered from DrugBank (Wishart et al., 2006) and UniProt (Apweiler et al., 2004).</p>
<h3>5.2 Subsets of WikiHop</h3>
<p>To further validate the effectiveness of our method, we evaluate on different subsets of WiKiHOP (Welbl et al., 2017), each containing a single query predicate. We consider the predicates publisher, developer, country, and record_label, because their semantics ensure that the annotated answer is unique and they contain a relatively large amount of questions that are annotated as requiring multi-hop reasoning. For the predicate publisher, this yields 509 training and 54 validation questions, for developer 267 and 29, for country 742 and 194, and for record_label 2305 and 283. As the test set of WikiHop is not publicly available, we report scores for the validation set.</p>
<h3>5.3 Baselines</h3>
<p>Following Welbl et al. (2017), we use two neural QA models, namely BiDAF (Seo et al., 2016a) and FASTQA (Weissenborn et al., 2017b), as baselines for the considered WikiHop predicates. We use the implementation provided by the JACK ${ }^{2}$ QA framework (Weissenborn et al., 2018) with the same hyperparameters as used by Welbl et al. (2017), and train a separate model for each predicate. ${ }^{3}$ To ensure that the performance of the</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>baseline is not adversely affected by the relatively small number of training examples, we also evaluate the BiDAF model trained on the whole WiKiHOP corpus. In order to compensate for the fact that both models are extractive QA models which cannot make use of the candidate entities, we additionally evaluate modified versions which transform both the predicted answer and all candidates to vectors using the wiki-unigrams model of SENT2VEC (Pagliardini et al., 2017). Consequently, we return the candidate entity which has the highest cosine similarity to the predicted entity. We use the normalized version of MEDHOP for training and evaluating the baselines, since we observed that denormalizing it (as for NLProlog) severely harmed performance. Furthermore on MEDHOP, we equip the models with word embeddings that were pretrained on a large biomedical corpus (Pyysalo et al., 2013).</p>
<h3>5.4 Hyperparameter Configuration</h3>
<p>On MEDHOP we optimize the embeddings of predicate symbols of rules and query triples, as well as of entities. WikiHop has a large number of unique entity symbols and thus, learning their embeddings is prohibitive. Thus, we only train the predicate symbols of rules and query triples on this data set. For MedHop we use bigram SENT2VEC embeddings trained on a large biomedical corpus ${ }^{4}$, and for WikiHop the wikiunigrams model ${ }^{5}$ of SENT2VEC. All experiments were performed with the same set of rule templates containing two rules for each of the forms $p(X, Y) \Leftarrow q(X, Y), p(X, Y) \Leftarrow q(Y, X)$ and $p(X, Z) \Leftarrow q(X, Y) \wedge r(Y, Z)$ and set the similarity threshold $\lambda$ to 0.5 and maximum proof depth to 3. We use Adam (Kingma and Ba, 2014) with default parameters.</p>
<h3>5.5 Results</h3>
<p>The results for the development portions of WikiHop and MedHop are shown in Table 1. For all predicates but developer, NLProlog strongly outperforms all tested neural QA models, while achieving the same accuracy as the best performing QA model on developer. We evaluated NLPROLOG on the hidden test set of MedHop and obtained</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>an accuracy of $29.3 \%$, which is 6.1 pp better than FastQA and 18.5 pp worse than BiDAF. ${ }^{6}$. As the test set is hidden, we cannot diagnose the exact reason for the inconsistency with the results on the development set, but observe that FastQA suffers from a similar drop in performance.</p>
<h3>5.6 Importance of Rules</h3>
<p>Exemplary proofs generated by NLProlog for the predicates record_label and country can be found in Fig. 2.</p>
<p>To study the impact of the rule-based reasoning on the predictive performance, we perform an ablation experiment in which we train NLProlog without any rule templates. The results can be found in the bottom half of Table 1. On three of the five evaluated data sets, performance decreases markedly when no rules can be used and does not change on the remaining two data sets. This indicates that reasoning with logic rules is beneficial in some cases and does not hurt performance in the remaining ones.</p>
<h3>5.7 Impact of Entity Embeddings</h3>
<p>In a qualitative analysis, we observed that in many cases multi-hop reasoning was performed via aligning entities and not by applying a multi-hop rule. For instance, the proof of the statement country(Oktabrskiy Big Concert Hall, Russia) visualized in Figure 2, is performed by making the embeddings of the entities Oktabrskiy Big Concert Hall and Saint Petersburg sufficiently similar. To gauge the extent of this effect, we evaluate an ablation in which we remove the MLP on top of the entity embeddings. The results, which can be found in Table 1, show that fine-tuning entity embeddings plays an integral role, as the performance degrades drastically. Interestingly, the observed performance degradation is much worse than when training without rules, suggesting that much of the reasoning is actually performed by finding a suitable transformation of the entity embeddings.</p>
<h3>5.8 Error Analysis</h3>
<p>We performed an error analysis for each of the WikiHop predicates. To this end, we examined all instances in which one of the neural QA models (with SENT2VEC) produced a correct prediction</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">MedHop</th>
<th style="text-align: center;">publisher</th>
<th style="text-align: center;">developer</th>
<th style="text-align: center;">country</th>
<th style="text-align: center;">recordlabel</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BiDAF</td>
<td style="text-align: center;">42.98</td>
<td style="text-align: center;">66.67</td>
<td style="text-align: center;">65.52</td>
<td style="text-align: center;">53.09</td>
<td style="text-align: center;">68.90</td>
</tr>
<tr>
<td style="text-align: left;">+ Sent2Vec</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">75.93</td>
<td style="text-align: center;">$\mathbf{6 8 . 9 7}$</td>
<td style="text-align: center;">61.86</td>
<td style="text-align: center;">75.62</td>
</tr>
<tr>
<td style="text-align: left;">+ Sent2Vec + wikihop</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">74.07</td>
<td style="text-align: center;">62.07</td>
<td style="text-align: center;">66.49</td>
<td style="text-align: center;">78.09</td>
</tr>
<tr>
<td style="text-align: left;">FastQA</td>
<td style="text-align: center;">52.63</td>
<td style="text-align: center;">62.96</td>
<td style="text-align: center;">62.07</td>
<td style="text-align: center;">57.21</td>
<td style="text-align: center;">70.32</td>
</tr>
<tr>
<td style="text-align: left;">+ Sent2Vec</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">75.93</td>
<td style="text-align: center;">58.62</td>
<td style="text-align: center;">64.95</td>
<td style="text-align: center;">78.09</td>
</tr>
<tr>
<td style="text-align: left;">NLProlog</td>
<td style="text-align: center;">$\mathbf{6 5 . 7 8}$</td>
<td style="text-align: center;">$\mathbf{8 3 . 3 3}$</td>
<td style="text-align: center;">$\mathbf{6 8 . 9 7}$</td>
<td style="text-align: center;">$\mathbf{7 7 . 8 4}$</td>
<td style="text-align: center;">$\mathbf{7 9 . 5 1}$</td>
</tr>
<tr>
<td style="text-align: left;">- rules</td>
<td style="text-align: center;">64.33</td>
<td style="text-align: center;">$\mathbf{8 3 . 3 3}$</td>
<td style="text-align: center;">$\mathbf{6 8 . 9 7}$</td>
<td style="text-align: center;">74.23</td>
<td style="text-align: center;">74.91</td>
</tr>
<tr>
<td style="text-align: left;">- entity MLP</td>
<td style="text-align: center;">37.13</td>
<td style="text-align: center;">68.52</td>
<td style="text-align: center;">41.38</td>
<td style="text-align: center;">72.16</td>
<td style="text-align: center;">64.66</td>
</tr>
</tbody>
</table>
<p>Table 1: Accuracy scores in percent for different predicates on the development set of the respective predicates. +/denote independent modifications to the base algorithm.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Example proof trees generated by NLProlog, showing a combination of multiple rules. Entities are shown in red and predicates in blue. Note, that entities do not need to match exactly. The first and third proofs were obtained without the entity MLP (as described in Section 5.7), while the second one was obtained in the full configuration of NLProlog.
and NLProlog did not, and labeled them with predefined error categories. Of the 55 instances, $49 \%$ of the errors were due to NLProlog unifying the wrong entities, mainly because of an over-reliance on heuristics, such as predicting a record label if it is from the same country as the artist. In $25 \%$ of the cases, NLProlog produced a correct prediction, but another candidate was defined as the answer. In $22 \%$ the prediction was due to an error in predicate unification, i.e. NLProlog identified the correct entities, but the sentence did not express the target relation. Furthermore, we performed an evaluation on all problems of the studied WiKi-</p>
<p>Hop predicates that were unanimously labeled as containing the correct answer in the support texts by Welbl et al. (2017). On this subset, the microaveraged accuracy of NLProlog shows an absolute increase of 3.08 pp , while the accuracy of BiDAF (FASTQA) augmented with SENT2VEC decreases by $3.26(3.63) \mathrm{pp}$. We conjecture that this might be due to NLProlog's reliance on explicit reasoning, which could make it less susceptible to spurious correlations between the query and supporting text.</p>
<h2>6 Discussion and Future Work</h2>
<p>We proposed NLProlog, a system that is able to perform rule-based reasoning on natural language, and can learn domain-specific rules from data. To this end, we proposed to combine a symbolic prover with pretrained sentence embeddings, and to train the resulting system using backpropagation. We evaluated NLProlog on two different QA tasks, showing that it can learn domainspecific rules and produce predictions which outperform those of the two strong baselines BiDAF and FASTQA in most cases.</p>
<p>While we focused on a subset of First Order Logic in this work, the expressiveness of NLProlog could be extended by incorporating a different symbolic prover. For instance, a prover for temporal logic (Orgun and Ma, 1994) would allow to model temporal dynamics in natural language. We are also interested in incorporating future improvements of symbolic provers, triple extraction systems and pretrained sentence representations to further enhance the performance of NLProlog. Additionally, it would be interesting to study the behavior of NLProlog in the presence of multiple WikiHop query predicates.</p>
<h2>Acknowledgments</h2>
<p>Leon Weber and Jannes Münchmeyer acknowledge the support of the Helmholtz Einstein International Berlin Research School in Data Science (HEIBRiDS). We would like to thank the anonymous reviewers for the constructive feedback. We gratefully acknowledge the support of NVIDIA Corporation with the donation of a Titan X Pascal GPU used for this research.</p>
<h2>References</h2>
<p>Gabor Angeli, Neha Nayak, and Christopher D Manning. 2016. Combining natural logic and shallow reasoning for question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 442-452.</p>
<p>Rolf Apweiler, Amos Bairoch, Cathy H Wu, Winona C Barker, Brigitte Boeckmann, Serenella Ferro, Elisabeth Gasteiger, Hongzhan Huang, Rodrigo Lopez, Michele Magrane, et al. 2004. Uniprot: the universal protein knowledgebase. Nucleic acids research, 32(suppl_1):D115-D119.</p>
<p>Stephen H. Bach, Matthias Broecheler, Bert Huang, and Lise Getoor. 2017. Hinge-loss markov random fields and probabilistic soft logic. Journal of Machine Learning Research, 18:109:1-109:67.</p>
<p>Islam Beltagy, Cuong Chau, Gemma Boleda, Dan Garrette, Katrin Erk, and Raymond Mooney. 2013. Montague meets markov: Deep semantics with probabilistic logical form. In Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity, volume 1, pages 11-21.</p>
<p>Islam Beltagy, Katrin Erk, and Raymond Mooney. 2014. Probabilistic soft logic for semantic textual similarity. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 12101219 .</p>
<p>Tarek R Besold, Artur d’Avila Garcez, Sebastian Bader, Howard Bowman, Pedro Domingos, Pascal Hitzler, Kai-Uwe Kühnberger, Luis C Lamb, Daniel Lowd, Priscila Machado Vieira Lima, et al. 2017. Neuralsymbolic learning and reasoning: A survey and interpretation. arXiv preprint arXiv:1711.03902.</p>
<p>William W Cohen. 2016. Tensorlog: A differentiable deductive database. arXiv preprint arXiv:1605.06523.</p>
<p>Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Luke Vilnis, Ishan Durugkar, Akshay Krishnamurthy, Alex Smola, and Andrew McCallum. 2017. Go for a walk and arrive at the answer: Reasoning
over paths in knowledge bases using reinforcement learning. arXiv preprint arXiv:1711.05851.</p>
<p>Rajarshi Das, Arvind Neelakantan, David Belanger, and Andrew McCallum. 2016. Chains of reasoning over entities, relations, and text using recurrent neural networks. arXiv preprint arXiv:1607.01426.</p>
<p>Nicola De Cao, Wilker Aziz, and Ivan Titov. 2018. Question answering by reasoning across documents with graph convolutional networks. arXiv preprint arXiv:1808.09920.</p>
<p>Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2018. Neural models for reasoning over multiple mentions using coreference. arXiv preprint arXiv:1804.05922.</p>
<p>Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. arXiv.</p>
<p>Richard Evans and Edward Grefenstette. 2017. Learning explanatory rules from noisy data. CoRR, abs/1711.04574.</p>
<p>Richard Evans and Edward Grefenstette. 2018. Learning explanatory rules from noisy data. J. Artif. Intell. Res., 61:1-64.</p>
<p>Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2014. Open question answering over curated and extracted knowledge bases. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, pages 1156-1165, New York, NY, USA. ACM.</p>
<p>David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A Kalyanpur, Adam Lally, J William Murdock, Eric Nyberg, John Prager, and Others. 2010. Building watson: An overview of the DeepQA project. AI magazine, 31(3):59-79.</p>
<p>Hervé Gallaire and Jack Minker, editors. 1978. Logic and Data Bases, Symposium on Logic and Data Bases, Centre d'études et de recherches de Toulouse, 1977, Advances in Data Base Theory. Plemum Press, New York.</p>
<p>Dan Garrette, Katrin Erk, and Raymond Mooney. 2011. Integrating logical representations with probabilistic information using markov logic. In Proceedings of the Ninth International Conference on Computational Semantics, pages 105-114. Association for Computational Linguistics.</p>
<p>Dan Garrette, Katrin Erk, and Raymond Mooney. 2014. A formal approach to linking logical form and vector-space lexical semantics. In Computing meaning, pages 27-48. Springer.</p>
<p>Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka GrabskaBarwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, et al.</p>
<ol>
<li>Hybrid computing using a neural network with dynamic external memory. Nature, 538(7626):471.</li>
</ol>
<p>Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino Pedreschi. 2019. A survey of methods for explaining black box models. ACM Comput. Surv., 51(5):93:1-93:42.
M. M. Gupta and J. Qi. 1991. Theory of T-norms and Fuzzy Inference Methods. Fuzzy Sets and Systems, 40(3):431-450.</p>
<p>Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. 2016. Tracking the world state with recurrent entity networks. arXiv preprint arXiv:1612.03969.</p>
<p>Matthew Honnibal and Ines Montani. 2017. spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing. To appear.</p>
<p>Kevin Jarrett, Koray Kavukcuoglu, Marc'Aurelio Ranzato, and Yann LeCun. 2009. What is the best multistage architecture for object recognition? In ICCV, pages 2146-2153. IEEE Computer Society.</p>
<p>Pascual Julián-Iranzo, Clemente Rubio-Manzano, and Juan Gallardo-Casero. 2009. Bousi prolog: a prolog extension language for flexible query answering. Electron. Notes Theor. Comput. Sci., 248(Supplement C):131-147.</p>
<p>Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.</p>
<p>Thomas N Kipf and Max Welling. 2016. Semisupervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.</p>
<p>Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher. 2016. Ask me anything: Dynamic memory networks for natural language processing. In International Conference on Machine Learning, pages 1378-1387.</p>
<p>Zachary C. Lipton. 2018. The mythos of model interpretability. Commun. ACM, 61(10):36-43.</p>
<p>Dan Moldovan, Christine Clark, Sanda Harabagiu, and Steve Maiorano. 2003. COGEX: A logic prover for question answering. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL '03, pages 87-93, Stroudsburg, PA, USA. Association for Computational Linguistics.</p>
<p>Stephen Muggleton. 1991. Inductive logic programming. New generation computing, 8(4):295-318.</p>
<p>Stephen Muggleton and Luc De Raedt. 1994. Inductive logic programming: Theory and methods. J. Log. Program., 19/20:629-679.</p>
<p>Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base completion. arXiv preprint arXiv:1504.06662.</p>
<p>Christina Niklaus, Matthias Cetto, André Freitas, and Siegfried Handschuh. 2018. A survey on open information extraction. In COLING, pages 3866-3878. Association for Computational Linguistics.</p>
<p>Mehmet A Orgun and Wanli Ma. 1994. An overview of temporal and modal logic programming. In Temporal logic, pages 445-479. Springer.</p>
<p>Matteo Pagliardini, Prakhar Gupta, and Martin Jaggi. 2017. Unsupervised learning of sentence embeddings using compositional n-gram features. arXiv preprint arXiv:1703.02507.</p>
<p>Baolin Peng, Zhengdong Lu, Hang Li, and Kam-Fai Wong. 2015. Towards neural network-based reasoning. arXiv preprint arXiv:1508.05508.</p>
<p>Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio Salakoski, and Sophia Ananiadou. 2013. Distributional semantics resources for biomedical text processing.</p>
<p>Martin Raison, Pierre-Emmanuel Mazaré, Rajarshi Das, and Antoine Bordes. 2018. Weaver: Deep coencoding of questions and documents for machine reading. arXiv preprint arXiv:1804.10490.</p>
<p>Matthew Richardson and Pedro M. Domingos. 2006. Markov logic networks. Machine Learning, 62(12):107-136.</p>
<p>Tim Rocktäschel and Sebastian Riedel. 2017. End-toend differentiable proving. In Advances in Neural Information Processing Systems, pages 3788-3800.</p>
<p>Tim Rocktäschel, Sameer Singh, and Sebastian Riedel. 2015. Injecting logical background knowledge into embeddings for relation extraction. In NAACL HLT 2015, The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Colorado, USA, May 31 - June 5, 2015, pages 11191129 .</p>
<p>Stuart J. Russell and Peter Norvig. 2010a. Artificial Intelligence - A Modern Approach (3. internat. ed.). Pearson Education.</p>
<p>Stuart J Russell and Peter Norvig. 2010b. Artificial Intelligence: A Modern Approach.</p>
<p>Stuart J Russell and Peter Norvig. 2016. Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited,.</p>
<p>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2016a. Bidirectional attention flow for machine comprehension. arXiv preprint arXiv:1611.01603.</p>
<p>Minjoon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. 2016b. Query-reduction networks for question answering. arXiv preprint arXiv:1606.04582.</p>
<p>Maria I Sessa. 2002. Approximate reasoning by similarity-based sld resolution. Theoretical computer science, 275(1-2):389-426.</p>
<p>Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. 2015. End-to-end memory networks. In Advances in neural information processing systems, pages $2440-2448$.</p>
<p>Dirk Weissenborn, Tomas Kocisky, and Chris Dyer. 2017a. Dynamic integration of background knowledge in neural nlu systems. CoRR, abs/1706.02596.</p>
<p>Dirk Weissenborn, Pasquale Minervini, Isabelle Augenstein, Johannes Welbl, Tim Rocktäschel, Matko Bosnjak, Jeff Mitchell, Thomas Demeester, Tim Dettmers, Pontus Stenetorp, and Sebastian Riedel. 2018. Jack the reader - A machine reading framework. In Proceedings of ACL 2018, Melbourne, Australia, July 15-20, 2018, System Demonstrations, pages $25-30$.</p>
<p>Dirk Weissenborn, Georg Wiese, and Laura Seiffe. 2017b. Fastqa: A simple and efficient neural architecture for question answering. arxiv preprint. arXiv preprint arXiv:1703.04816.</p>
<p>Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2017. Constructing datasets for multi-hop reading comprehension across documents. arXiv preprint arXiv:1710.06481.</p>
<p>David S Wishart, Craig Knox, An Chi Guo, Savita Shrivastava, Murtaza Hassanali, Paul Stothard, Zhan Chang, and Jennifer Woolsey. 2006. Drugbank: a comprehensive resource for in silico drug discovery and exploration. Nucleic acids research, 34(suppl_1):D668-D672.</p>
<p>Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, and Richard Socher. 2019. Coarse-grain fine-grain coattention network for multi-evidence question answering. arXiv preprint arXiv:1901.00603.</p>
<h2>Appendices</h2>
<h2>A Algorithms</h2>
<div class="codehilite"><pre><span></span><code><span class="n">fun</span><span class="w"> </span><span class="n">unify</span><span class="w"> </span>\<span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">Input</span><span class="p">:</span>
<span class="w">    </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">function</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span><span class="p">(</span>\<span class="n">ldots</span><span class="p">)</span><span class="w"> </span>\<span class="n">mid</span>\<span class="p">)</span><span class="w"> </span><span class="n">atom</span><span class="w"> </span>\<span class="p">(</span><span class="n">p</span><span class="p">(</span>\<span class="n">ldots</span><span class="p">)</span><span class="w"> </span>\<span class="n">mid</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">variable</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">mid</span>\<span class="p">)</span><span class="w"> </span><span class="n">list</span><span class="w"> </span>\<span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="mi">2</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span>\<span class="p">(</span><span class="n">y</span>\<span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">function</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}(</span>\<span class="n">ldots</span><span class="p">)</span><span class="w"> </span>\<span class="n">mid</span>\<span class="p">)</span><span class="w"> </span><span class="n">atom</span><span class="w"> </span>\<span class="p">(</span><span class="n">p</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}(</span>\<span class="n">ldots</span><span class="p">)</span><span class="w"> </span>\<span class="n">mid</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">variable</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">mid</span>\<span class="p">)</span><span class="w"> </span><span class="n">list</span><span class="w"> </span>\<span class="p">(</span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="mi">2</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">m</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span>\<span class="p">(</span>\<span class="n">theta</span>\<span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="n">substitutions</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="w"> </span>\<span class="p">(</span><span class="o">=</span>\<span class="p">{</span><span class="w"> </span>\<span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span>\<span class="p">(</span><span class="n">S</span>\<span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="n">success</span><span class="w"> </span><span class="n">score</span><span class="p">,</span><span class="w"> </span><span class="n">default</span><span class="w"> </span>\<span class="p">(</span><span class="o">=</span><span class="mf">1.0</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">Output</span><span class="p">:</span><span class="w"> </span><span class="p">(</span><span class="n">Unifying</span><span class="w"> </span><span class="n">substitution</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">theta</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span><span class="w"> </span><span class="ow">or</span>
<span class="w">        </span><span class="n">failure</span><span class="p">,</span><span class="w"> </span><span class="n">Updated</span><span class="w"> </span><span class="n">success</span><span class="w"> </span><span class="n">score</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">theta</span><span class="o">=</span>\<span class="p">)</span><span class="w"> </span><span class="n">failure</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">failure</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">S</span><span class="o">&lt;</span>\<span class="n">lambda</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">failure</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">y</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span>\<span class="p">((</span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">Var</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span>
<span class="w">    </span><span class="n">unify_var</span><span class="w"> </span>\<span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">y</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">Var</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span>
<span class="w">    </span><span class="n">unify_var</span><span class="w"> </span>\<span class="p">((</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="n">right</span><span class="p">)</span>\<span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="k">is</span>
<span class="w">    </span>\<span class="p">(</span><span class="n">f</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="n">left</span><span class="p">(</span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="n">right</span><span class="p">)</span>\<span class="p">),</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span>\<span class="p">(</span><span class="n">f</span><span class="w"> </span>\<span class="n">sim</span><span class="w"> </span><span class="n">f</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span><span class="w"> </span>\<span class="n">geq</span><span class="w"> </span>\<span class="n">lambda</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}:</span><span class="o">=</span><span class="n">S</span><span class="w"> </span>\<span class="n">wedge</span><span class="w"> </span><span class="n">f</span><span class="w"> </span>\<span class="n">sim</span><span class="w"> </span><span class="n">f</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">unify</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span>\<span class="n">right</span><span class="o">.</span>\<span class="p">)</span>
<span class="w">        </span>\<span class="p">(</span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">end</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span>\<span class="p">(</span><span class="n">p</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="n">right</span><span class="p">)</span>\<span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="k">is</span>
<span class="w">    </span>\<span class="p">(</span><span class="n">p</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="n">left</span><span class="p">(</span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="n">right</span><span class="p">)</span>\<span class="p">),</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span>\<span class="p">(</span><span class="n">p</span><span class="w"> </span>\<span class="n">sim</span><span class="w"> </span><span class="n">p</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span><span class="w"> </span>\<span class="n">geq</span><span class="w"> </span>\<span class="n">lambda</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}:</span><span class="o">=</span><span class="n">S</span><span class="w"> </span>\<span class="n">wedge</span><span class="w"> </span><span class="n">f</span><span class="w"> </span>\<span class="n">sim</span><span class="w"> </span><span class="n">f</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">unify</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span>\<span class="n">right</span><span class="o">.</span>\<span class="p">)</span>
<span class="w">        </span>\<span class="p">(</span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">end</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span>\<span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span>\<span class="p">(</span><span class="n">y</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span>
<span class="w">        </span>\<span class="p">(</span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">}</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span>
<span class="w">            </span>\<span class="p">(</span>\<span class="n">left</span><span class="p">(</span>\<span class="n">theta</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">},</span><span class="w"> </span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="n">right</span><span class="p">):</span><span class="o">=</span>\<span class="n">operatorname</span><span class="p">{</span><span class="n">unify</span><span class="p">}</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span>\<span class="n">right</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">unify</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">left</span><span class="p">(</span><span class="n">x_</span><span class="p">{</span><span class="mi">2</span><span class="p">}::</span><span class="w"> </span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">x_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="mi">2</span><span class="p">}::</span>\<span class="n">right</span><span class="o">.</span>\<span class="p">)</span>
<span class="w">            </span>\<span class="p">(</span>\<span class="n">ldots</span><span class="p">::</span><span class="w"> </span><span class="n">y_</span><span class="p">{</span><span class="n">n</span><span class="p">},</span><span class="w"> </span>\<span class="n">theta</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">},</span><span class="w"> </span><span class="n">S</span><span class="o">^</span><span class="p">{</span>\<span class="n">prime</span><span class="p">}</span>\<span class="p">)</span>
<span class="w">    </span><span class="n">end</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span><span class="n">x</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span>\<span class="p">(</span><span class="n">y</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">empty</span><span class="w"> </span><span class="n">list</span>
<span class="w">        </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span>\<span class="p">((</span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">failure</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">)</span>
<span class="n">fun</span><span class="w"> </span><span class="n">unify_var</span><span class="w"> </span>\<span class="p">((</span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="n">o</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span>\<span class="p">{</span><span class="n">v</span><span class="w"> </span><span class="o">/</span><span class="w"> </span>\<span class="n">mathrm</span><span class="p">{</span><span class="n">val</span><span class="p">}</span>\<span class="p">}</span><span class="w"> </span>\<span class="ow">in</span><span class="w"> </span>\<span class="n">theta</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span>
<span class="w">        </span><span class="n">unify</span><span class="w"> </span>\<span class="p">((</span><span class="n">v</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="n">o</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>\<span class="p">(</span>\<span class="p">{</span><span class="n">o</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">l</span>\<span class="p">}</span><span class="w"> </span>\<span class="ow">in</span><span class="w"> </span>\<span class="n">theta</span>\<span class="p">)</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span>
<span class="w">        </span><span class="n">unify</span><span class="w"> </span>\<span class="p">((</span><span class="n">v</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">r</span><span class="p">,</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">l</span><span class="p">,</span><span class="w"> </span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">return</span><span class="w"> </span>\<span class="p">((</span>\<span class="p">{</span><span class="n">v</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">o</span>\<span class="p">}</span><span class="o">+</span>\<span class="n">theta</span><span class="p">,</span><span class="w"> </span><span class="n">S</span><span class="p">)</span>\<span class="p">)</span>
<span class="n">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">weak</span><span class="w"> </span><span class="n">unification</span><span class="w"> </span><span class="n">algorithm</span><span class="w"> </span><span class="ow">in</span>
<span class="n">NLProlog</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">occurs</span><span class="w"> </span><span class="n">check</span>
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ https://github.com/ncbi-nlp/
BioSentVec
${ }^{5}$ https://drive.google.com/open?id= 0B6VhzidiLvjSa19uYW1LUEkzX3c&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{6}$ Note, that these numbers are taken from Welbl et al. (2017) and were obtained with different implementations of BiDAF and FASTQA&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>