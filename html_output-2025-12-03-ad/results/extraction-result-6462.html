<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6462 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6462</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6462</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-127.html">extraction-schema-127</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <p><strong>Paper ID:</strong> paper-272827841</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.15240v2.pdf" target="_blank">MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation</a></p>
                <p><strong>Paper Abstract:</strong> Long-term memory is important for chatbots and dialogue systems (DS) to create consistent and human-like conversations, evidenced by numerous developed memory-augmented DS (MADS). To evaluate the effectiveness of such MADS, existing commonly used evaluation metrics, like retrieval accuracy and perplexity (PPL), mainly focus on query-oriented factualness and language quality assessment. However, these metrics often lack practical value. Moreover, the evaluation dimensions are insufficient for human-like assessment in DS. Regarding memory-recalling paradigms, current evaluation schemes only consider passive memory retrieval while ignoring diverse memory recall with rich triggering factors, e.g., emotions and surroundings, which can be essential in emotional support scenarios. To bridge the gap, we construct a novel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various memory-recalling paradigms based on cognitive science and psychology theories. The benchmark assesses two tasks separately: memory retrieval and memory recognition with the incorporation of both passive and proactive memory recall data. We introduce new scoring criteria to the evaluation, including memory injection, emotion support (ES) proficiency, and intimacy, to comprehensively assess generated responses. Results from cutting-edge embedding models and large language models on this benchmark indicate the potential for further advancement. Extensive testing further reveals correlations between memory injection, ES proficiency, and intimacy.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6462.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6462.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MADial-Bench</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory-Augmented Dialogue Benchmark (MADial-Bench)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bilingual benchmark introduced in this paper that evaluates memory-augmented dialogue systems across two stages (memory recalling / retrieval and memory recognition + response generation) and across passive and proactive (emotion/state-triggered) recall paradigms using human-refined dialogues and new human-centric metrics (memory injection, ES proficiency, intimacy).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MADial-Bench (evaluation suite)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not an agent but an evaluation framework: provides a memory bank of structured event summaries and testing protocols (M1 memory recall via embedding retrieval; M2 memory recognition + generation by LLMs) with three settings for response generation (golden memory only; golden + distractors; top-k retrieved memories).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external retrieval-based memory bank (retrieval-augmented generation style)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>structured event summaries (fields: time, emotion, scene, event) stored as text and indexed via embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>similarity search / ranking via embedding models to produce candidate memory set P_i; chosen memory is injected into LLM prompt for generation (no learned write-controller described)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recalling & memory recognition/response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue / retrieval-augmented generation / emotional-support dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Aggregate human-evaluation findings: best models produce substantially more intimate / preferred responses when memory is injected (e.g., on average 73% of human-voted best responses contained memory; side-by-side, responses with memory are preferred in >=69.4% of cases across annotators).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Without memory the same models are less preferred (side-by-side lose rates varied by model; e.g., GPT-4-Turbo: lose 9.4% in side-by-side, tie 28.8%).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human evaluation metrics (Memory-injection score, ES proficiency, Intimacy); side-by-side Win/Tie/Lose percentages; also retrieval metrics for M1 (MAP, MRR, nDCG, Recall, Precision)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Benchmark exposes trade-offs such as: good retrieval is difficult (embedding recall poor); models that inject more memory (e.g., GLM-4) may harm style coherence or naturalness; stronger memory injection correlates with intimacy but can reduce other aspects if over-used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Retrieval (M1) is challenging — top embedding models perform far from perfect; memory recognition (M2) fails when distractor memories are present (performance drops from Setting 1 to Settings 2/3); models sometimes 'introduce too much memory' harming style coherence; automatic metrics unreliable vs human judgment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>He J., Zhu L., Wang R., Wang X., Haffari R., Zhang J., 2024. MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation. arXiv preprint.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6462.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MADS (retrieval-based)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory-Augmented Dialogue Systems (retrieval-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Class of dialogue agents that augment LLMs with an external memory bank of dialogue history / event summaries and retrieve relevant memories via embeddings to improve consistency and long-term personalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Retrieval-augmented MADS (conceptual pipeline: M1 + M2)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Two-stage pipeline: (M1) embedding-based retrieval over an external memory bank of event summaries to produce candidate memories; (M2) LLM selects a memory (recognition) and conditions generation on it (memory injection).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external vector store / retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries (time, emotion, scene, event) encoded to embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>similarity search using embedding models (various open-source and OpenAI embeddings) followed by ranking; selected memory is concatenated or injected into the LLM prompt</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench (memory recalling + recognition/generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue; retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Paper shows memory injection is correlated with higher ES proficiency and intimacy; when golden memory is provided (Setting 1), models achieve substantially higher Memory Injection and ES scores (models often >2.2/3.0), but exact numeric improvement depends on model.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Models without memory perform worse on intimacy and ES-related human judgments (side-by-side preference for responses with memory ~>=69.4% overall).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human annotations (Memory-injection score, ES proficiency, Intimacy), retrieval metrics (MAP, MRR, nDCG, Recall, Precision)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Retrieval-only (text-similarity) is insufficient; stronger memory injection can improve intimacy but may harm style coherence; retrieval noise (distractors) significantly degrades memory recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Proactive recall (emotion/state-triggered) is under-explored in prior MADS; retrieval models struggle to retrieve correct memories (low recall at top ranks), and models fail to pick the correct memory under distractor settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6462.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>M1 (memory retriever)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory Recalling Module (M1)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper's retrieval component that, given a dialogue context, retrieves a ranked golden memory set from the full memory bank using embedding similarity and ranking metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>M1 (embedding-based retriever)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Embeds context and stored event summaries with an embedding model and retrieves top-k candidate memories by similarity/ranking (evaluated across multiple embedding models).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external vector store using precomputed embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries encoded to vector embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>nearest-neighbor / similarity search (embedding models tested include OpenAI text-embedding-3-large, BGE-M3-Dense, Jina embedding2, GTE, Acge, Stella, ColBERT, Dmeta) followed by ranking; no learned write/update mechanism described</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recalling</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>retrieval / dialogue memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Best embedding (OpenAI) still performs poorly on the benchmark; authors state 'Even the best embedding model, OpenAI, does not exceed 60% @1 and struggled at 62% @10 in the final average' (paper-level summary). Table results show OpenAI as top-performing embedding model across English and Chinese.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>N/A (M1 is the retriever; without a retriever no candidate memories available for M2; paper compares retrieved vs golden sets in Settings 1–3 showing degraded downstream generation when retrieval is imperfect).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Retrieval metrics: MAP, MRR, nDCG, Recall, Precision (reported per model and averaged)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Open-source embeddings underperform commercial embedding (OpenAI); retrieval quality is a bottleneck for MADS; latency/compute for larger embedding models (>7B) omitted due to slow inference.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Text-similarity retrieval alone is inadequate for memory recall in dialogue; retrieval accuracy far from human-level leading to lower downstream ES proficiency and memory injection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6462.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>M2 (memory recognizer + generator)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory Recognition and Response Generation Module (M2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Stage-two agent that receives a candidate memory set P_i (from M1 or golden) and must select the most appropriate memory and generate a response conditioned on that memory, evaluated under three settings of memory candidate quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>M2 (LLM-based memory recognizer + generator)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Given candidate memories P_i, the LLM performs memory recognition (selects or uses appropriate memory) and generates responses; settings vary from golden-only to golden+negatives to real retrieval results.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (selected memory injected into prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries in P_i; LLM conditions directly on the chosen memory text</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>explicit injection of selected memory into the prompt; recognition is implicit in LLM output selection (no separate learned selection module described)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation (Settings 1–3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>When given golden memory (Setting 1), LLMs reach higher Memory Injection and ES Proficiency (models often >2.2/3.0); human references score higher than models overall except on some emotion improvement scores.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Paper compares responses with/without memory in Setting 3: responses with memory were preferred ~73% of time as best responses; side-by-side Win rates varied by model (see per-model rows).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human evaluation scores (Naturalness, Style Coherence, Memory Injection, ES Proficiency, Emotional Improvement, Intimacy) and pick-the-best Win/Tie/Lose percentages</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Realistic retrieval (Setting 3) causes substantial drops in ES proficiency and memory injection vs Setting 1; emphasis on prompt naturalness improved Naturalness and Style Coherence but does not resolve recognition failures.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>LLMs often fail to recognize correct memory when distractors are present; memory injection degrades when retrieval contains unrelated memories; automatic metrics misalign with human preference.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6462.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI-Embed</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI text-embedding-3-large (embedding model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Commercial embedding model used as the top-performing retriever in the paper's experiments for both English and Chinese retrieval tasks over the MADial memory bank.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>OpenAI text-embedding-3-large (retriever)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Embeds dialogue context and event-summary memories to perform nearest-neighbor retrieval; used as the strongest embedding method in the benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external vector-store embeddings for similarity search</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>dense vector embeddings of textual event summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>similarity search / ranking (nearest neighbor) to produce top-k candidate memories</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recalling</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reported as best embedding in experiments; paper states it 'does not exceed 60% @1 and struggled at 62% @10 in the final average' (authors highlight retrieval remains far from satisfying despite being best).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>N/A (retriever component); however imperfect retrieval leads to degraded downstream generation performance in Setting 3 vs Setting 1.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Retrieval metrics: MAP, MRR, nDCG, Recall, Precision (detailed per model in Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Although top-performing, retrieval quality still insufficient; authors limited embedding models with >7B parameters due to inference speed concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Even best embedding fails to reliably retrieve golden memory at top positions; text-similarity retrieval inadequate for complex memory recall triggered by emotion/state.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6462.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4-Turbo (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-performing commercial LLM used in experiments as the response generator (M2) that conditions on candidate memories and demonstrates the strongest human-evaluated overall performance on MADial-Bench.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GPT-4-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Zero-shot LLM used to perform memory recognition and response generation by conditioning on provided candidate memories; evaluated across Settings 1–3 and compared with other LLMs and human references.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented via explicit memory injection into prompt (external memory bank)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual memory summaries injected verbatim into prompts (or provided as candidate set P_i)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>relies on upstream embedding retriever (M1) for candidate memories; selects and incorporates memory text into generation via prompt conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval; emotional-support dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Side-by-side intimacy win rate: 61.9% (Win), 28.8% (Tie), 9.4% (Lose) when comparing responses with vs without memory; high human-eval scores (e.g., near-top on ES and Emotional Improvement in some settings).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>In side-by-side comparison, the 9.4% lose rate indicates the portion where memory-less responses were preferred; average preference for memory-present responses across annotators reported >=69.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human Win/Tie/Lose percentages for side-by-side comparisons; human aspect scores (Memory Injection, ES Proficiency, Intimacy)</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Stronger memory injection correlates with better intimacy; no explicit latency or memory footprint numbers reported for GPT-4-Turbo, but authors note improved ES proficiency at cost of requiring reliable retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance drops when retrieval supplies distractor memories (Setting 2 and 3); automatic metrics unreliable in reflecting GPT-4-Turbo's human-preferred outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6462.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2-72B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2-72B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large bilingual (Chinese/English) LLM (72B) evaluated as a memory-conditioned generator (M2) in MADial-Bench showing strong ES and memory-injection performance relative to many baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Qwen2-72B</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Zero-shot instruction-tuned LLM used to select and inject memories from candidate sets and generate emotionally supportive responses; evaluated across three settings.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (external memory bank injected into prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries provided as P_i</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>depends on embedding retriever to supply P_i; then recognition/injection via prompt conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval; emotional-support</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Side-by-side Win/Tie/Lose: 56.3% Win, 28.8% Tie, 15.0% Lose (preferred more often with memory injected). Achieved strong human-eval scores in several aspects (see Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Lose rate 15.0% in side-by-side comparisons (cases where responses without memory were preferred).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human Win/Tie/Lose percentages; aspect scores for Memory Injection, ES Proficiency, Intimacy</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Performance declines from Setting 1 (golden) to real retrieval Setting 3; prompt engineering improved Naturalness but recognition remains challenging under distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Recognition failures when distractors present; memory injection and ES proficiency drop under realistic retrieval noise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6462.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GLM-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GLM-4 (GLM series)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bilingual LLM tested in the paper that shows robustness in memory recognition but tends to 'introduce too much memory', which can harm style coherence according to authors' analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GLM-4</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Used as an M2 model that selects and injects memories from candidate sets and generates responses; noted as robust in recognition but with a tendency to over-inject memory text into replies.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (external memory injected into prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>receives P_i from embedding retriever and conditions generation on the chosen memory</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Side-by-side Win/Tie/Lose: 55.0% Win, 19.4% Tie, 25.6% Lose. Human-eval: GLM-4 achieved high semantic similarity on automatic metrics but sometimes harmed style coherence due to over-injection.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Lose rate 25.6% indicates instances where memory-less responses were preferred.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human Win/Tie/Lose; human aspect scores; automatic metrics (BertScore, Rouge-L) reported separately</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>GLM-4's robustness comes at cost of 'introducing too much memory' which harms style coherence and possibly naturalness.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Over-injection of memory can degrade style coherence; real retrieval remains noisy causing drops from ideal (golden) settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6462.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ziya-Character</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ziya-Character (fine-tuned on character dialogues)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fine-tuned conversational model derived from Ziya2-13B that was evaluated for memory-conditioned dialogue; produces natural, character-consistent replies but lags on memory injection vs larger models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Ziya-Character (fine-tuned ~13B)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Character-style LLM fine-tuned on roleplay and character dialogues and used as M2 in experiments; steady naturalness/style but weaker memory recognition/injection compared to larger models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B (based on Ziya2-13B fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external memory injected into prompts</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>selects/injects memory from P_i supplied by retriever and generates reply</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Side-by-side Win/Tie/Lose: 47.5% Win, 21.9% Tie, 30.6% Lose — lowest among evaluated LLMs in preference gain from memory.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Lose rate 30.6% indicates more frequent preference for memory-less replies vs stronger models.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human Win/Tie/Lose preference; aspect scores</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Fine-tuning for persona/character yielded high Naturalness but insufficient memory injection and ES proficiency compared to larger models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performs poorly on memory recognition and injection in realistic retrieval settings; smaller model size limits memory-injection ability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6462.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6462.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Doubao</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Doubao-Character-32k</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model evaluated in the benchmark (character-style, long-context) that benefits from prompt strengthening and performs well on naturalness and style coherence but is middling on memory-injection compared to the largest LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Doubao-Character-32k</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Character-oriented LLM tested as an M2 generator; after prompt emphasis on naturalness it improved Naturalness and Style Coherence metrics in human evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (external memory bank injected into prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>textual event summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_access_mechanism</strong></td>
                            <td>accepts P_i as candidate memories from retriever and conditions generation on chosen memory</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>MADial-Bench memory recognition & response generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_category</strong></td>
                            <td>dialogue generation with retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Side-by-side Win/Tie/Lose: 44.4% Win, 34.4% Tie, 21.3% Lose; strong gains in Naturalness and Style Coherence after prompt adjustments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Lose rate 21.3% (cases where memory-less response preferred).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human aspect scores and Win/Tie/Lose preference</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_reported</strong></td>
                            <td>Prompt engineering improves naturalness but doesn't fully address memory recognition failures under noisy retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Memory recognition degrades in realistic retrieval settings; less memory-injection ability than the strongest LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Augmenting language models with long-term memory <em>(Rating: 2)</em></li>
                <li>Memorybank: Enhancing large language models with long-term memory <em>(Rating: 2)</em></li>
                <li>my agent understands me better: Integrating dynamic human-like memory recall and consolidation in llm-based agents <em>(Rating: 2)</em></li>
                <li>Think-in-memory: Recalling and post-thinking enable llms with long-term memory <em>(Rating: 1)</em></li>
                <li>Personalized llm response generation with parameterized memory injection <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6462",
    "paper_id": "paper-272827841",
    "extraction_schema_id": "extraction-schema-127",
    "extracted_data": [
        {
            "name_short": "MADial-Bench",
            "name_full": "Memory-Augmented Dialogue Benchmark (MADial-Bench)",
            "brief_description": "A bilingual benchmark introduced in this paper that evaluates memory-augmented dialogue systems across two stages (memory recalling / retrieval and memory recognition + response generation) and across passive and proactive (emotion/state-triggered) recall paradigms using human-refined dialogues and new human-centric metrics (memory injection, ES proficiency, intimacy).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "MADial-Bench (evaluation suite)",
            "agent_description": "Not an agent but an evaluation framework: provides a memory bank of structured event summaries and testing protocols (M1 memory recall via embedding retrieval; M2 memory recognition + generation by LLMs) with three settings for response generation (golden memory only; golden + distractors; top-k retrieved memories).",
            "model_size": null,
            "memory_used": true,
            "memory_type": "external retrieval-based memory bank (retrieval-augmented generation style)",
            "memory_representation": "structured event summaries (fields: time, emotion, scene, event) stored as text and indexed via embeddings",
            "memory_access_mechanism": "similarity search / ranking via embedding models to produce candidate memory set P_i; chosen memory is injected into LLM prompt for generation (no learned write-controller described)",
            "task_name": "MADial-Bench memory recalling & memory recognition/response generation",
            "task_category": "dialogue / retrieval-augmented generation / emotional-support dialogue",
            "performance_with_memory": "Aggregate human-evaluation findings: best models produce substantially more intimate / preferred responses when memory is injected (e.g., on average 73% of human-voted best responses contained memory; side-by-side, responses with memory are preferred in &gt;=69.4% of cases across annotators).",
            "performance_without_memory": "Without memory the same models are less preferred (side-by-side lose rates varied by model; e.g., GPT-4-Turbo: lose 9.4% in side-by-side, tie 28.8%).",
            "has_comparative_results": true,
            "performance_metric": "Human evaluation metrics (Memory-injection score, ES proficiency, Intimacy); side-by-side Win/Tie/Lose percentages; also retrieval metrics for M1 (MAP, MRR, nDCG, Recall, Precision)",
            "tradeoffs_reported": "Benchmark exposes trade-offs such as: good retrieval is difficult (embedding recall poor); models that inject more memory (e.g., GLM-4) may harm style coherence or naturalness; stronger memory injection correlates with intimacy but can reduce other aspects if over-used.",
            "limitations_or_failure_cases": "Retrieval (M1) is challenging — top embedding models perform far from perfect; memory recognition (M2) fails when distractor memories are present (performance drops from Setting 1 to Settings 2/3); models sometimes 'introduce too much memory' harming style coherence; automatic metrics unreliable vs human judgment.",
            "citation": "He J., Zhu L., Wang R., Wang X., Haffari R., Zhang J., 2024. MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation. arXiv preprint.",
            "uuid": "e6462.0",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "MADS (retrieval-based)",
            "name_full": "Memory-Augmented Dialogue Systems (retrieval-based)",
            "brief_description": "Class of dialogue agents that augment LLMs with an external memory bank of dialogue history / event summaries and retrieve relevant memories via embeddings to improve consistency and long-term personalization.",
            "citation_title": "",
            "mention_or_use": "mention",
            "agent_name": "Retrieval-augmented MADS (conceptual pipeline: M1 + M2)",
            "agent_description": "Two-stage pipeline: (M1) embedding-based retrieval over an external memory bank of event summaries to produce candidate memories; (M2) LLM selects a memory (recognition) and conditions generation on it (memory injection).",
            "model_size": null,
            "memory_used": true,
            "memory_type": "external vector store / retrieval-augmented generation",
            "memory_representation": "textual event summaries (time, emotion, scene, event) encoded to embeddings",
            "memory_access_mechanism": "similarity search using embedding models (various open-source and OpenAI embeddings) followed by ranking; selected memory is concatenated or injected into the LLM prompt",
            "task_name": "MADial-Bench (memory recalling + recognition/generation)",
            "task_category": "dialogue; retrieval",
            "performance_with_memory": "Paper shows memory injection is correlated with higher ES proficiency and intimacy; when golden memory is provided (Setting 1), models achieve substantially higher Memory Injection and ES scores (models often &gt;2.2/3.0), but exact numeric improvement depends on model.",
            "performance_without_memory": "Models without memory perform worse on intimacy and ES-related human judgments (side-by-side preference for responses with memory ~&gt;=69.4% overall).",
            "has_comparative_results": true,
            "performance_metric": "Human annotations (Memory-injection score, ES proficiency, Intimacy), retrieval metrics (MAP, MRR, nDCG, Recall, Precision)",
            "tradeoffs_reported": "Retrieval-only (text-similarity) is insufficient; stronger memory injection can improve intimacy but may harm style coherence; retrieval noise (distractors) significantly degrades memory recognition.",
            "limitations_or_failure_cases": "Proactive recall (emotion/state-triggered) is under-explored in prior MADS; retrieval models struggle to retrieve correct memories (low recall at top ranks), and models fail to pick the correct memory under distractor settings.",
            "uuid": "e6462.1",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "M1 (memory retriever)",
            "name_full": "Memory Recalling Module (M1)",
            "brief_description": "The paper's retrieval component that, given a dialogue context, retrieves a ranked golden memory set from the full memory bank using embedding similarity and ranking metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "M1 (embedding-based retriever)",
            "agent_description": "Embeds context and stored event summaries with an embedding model and retrieves top-k candidate memories by similarity/ranking (evaluated across multiple embedding models).",
            "model_size": null,
            "memory_used": true,
            "memory_type": "external vector store using precomputed embeddings",
            "memory_representation": "textual event summaries encoded to vector embeddings",
            "memory_access_mechanism": "nearest-neighbor / similarity search (embedding models tested include OpenAI text-embedding-3-large, BGE-M3-Dense, Jina embedding2, GTE, Acge, Stella, ColBERT, Dmeta) followed by ranking; no learned write/update mechanism described",
            "task_name": "MADial-Bench memory recalling",
            "task_category": "retrieval / dialogue memory",
            "performance_with_memory": "Best embedding (OpenAI) still performs poorly on the benchmark; authors state 'Even the best embedding model, OpenAI, does not exceed 60% @1 and struggled at 62% @10 in the final average' (paper-level summary). Table results show OpenAI as top-performing embedding model across English and Chinese.",
            "performance_without_memory": "N/A (M1 is the retriever; without a retriever no candidate memories available for M2; paper compares retrieved vs golden sets in Settings 1–3 showing degraded downstream generation when retrieval is imperfect).",
            "has_comparative_results": true,
            "performance_metric": "Retrieval metrics: MAP, MRR, nDCG, Recall, Precision (reported per model and averaged)",
            "tradeoffs_reported": "Open-source embeddings underperform commercial embedding (OpenAI); retrieval quality is a bottleneck for MADS; latency/compute for larger embedding models (&gt;7B) omitted due to slow inference.",
            "limitations_or_failure_cases": "Text-similarity retrieval alone is inadequate for memory recall in dialogue; retrieval accuracy far from human-level leading to lower downstream ES proficiency and memory injection.",
            "uuid": "e6462.2",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "M2 (memory recognizer + generator)",
            "name_full": "Memory Recognition and Response Generation Module (M2)",
            "brief_description": "Stage-two agent that receives a candidate memory set P_i (from M1 or golden) and must select the most appropriate memory and generate a response conditioned on that memory, evaluated under three settings of memory candidate quality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "M2 (LLM-based memory recognizer + generator)",
            "agent_description": "Given candidate memories P_i, the LLM performs memory recognition (selects or uses appropriate memory) and generates responses; settings vary from golden-only to golden+negatives to real retrieval results.",
            "model_size": null,
            "memory_used": true,
            "memory_type": "retrieval-augmented (selected memory injected into prompt)",
            "memory_representation": "textual event summaries in P_i; LLM conditions directly on the chosen memory text",
            "memory_access_mechanism": "explicit injection of selected memory into the prompt; recognition is implicit in LLM output selection (no separate learned selection module described)",
            "task_name": "MADial-Bench memory recognition & response generation (Settings 1–3)",
            "task_category": "dialogue generation with retrieval",
            "performance_with_memory": "When given golden memory (Setting 1), LLMs reach higher Memory Injection and ES Proficiency (models often &gt;2.2/3.0); human references score higher than models overall except on some emotion improvement scores.",
            "performance_without_memory": "Paper compares responses with/without memory in Setting 3: responses with memory were preferred ~73% of time as best responses; side-by-side Win rates varied by model (see per-model rows).",
            "has_comparative_results": true,
            "performance_metric": "Human evaluation scores (Naturalness, Style Coherence, Memory Injection, ES Proficiency, Emotional Improvement, Intimacy) and pick-the-best Win/Tie/Lose percentages",
            "tradeoffs_reported": "Realistic retrieval (Setting 3) causes substantial drops in ES proficiency and memory injection vs Setting 1; emphasis on prompt naturalness improved Naturalness and Style Coherence but does not resolve recognition failures.",
            "limitations_or_failure_cases": "LLMs often fail to recognize correct memory when distractors are present; memory injection degrades when retrieval contains unrelated memories; automatic metrics misalign with human preference.",
            "uuid": "e6462.3",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "OpenAI-Embed",
            "name_full": "OpenAI text-embedding-3-large (embedding model)",
            "brief_description": "Commercial embedding model used as the top-performing retriever in the paper's experiments for both English and Chinese retrieval tasks over the MADial memory bank.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "OpenAI text-embedding-3-large (retriever)",
            "agent_description": "Embeds dialogue context and event-summary memories to perform nearest-neighbor retrieval; used as the strongest embedding method in the benchmark.",
            "model_size": null,
            "memory_used": true,
            "memory_type": "external vector-store embeddings for similarity search",
            "memory_representation": "dense vector embeddings of textual event summaries",
            "memory_access_mechanism": "similarity search / ranking (nearest neighbor) to produce top-k candidate memories",
            "task_name": "MADial-Bench memory recalling",
            "task_category": "retrieval",
            "performance_with_memory": "Reported as best embedding in experiments; paper states it 'does not exceed 60% @1 and struggled at 62% @10 in the final average' (authors highlight retrieval remains far from satisfying despite being best).",
            "performance_without_memory": "N/A (retriever component); however imperfect retrieval leads to degraded downstream generation performance in Setting 3 vs Setting 1.",
            "has_comparative_results": true,
            "performance_metric": "Retrieval metrics: MAP, MRR, nDCG, Recall, Precision (detailed per model in Table 4)",
            "tradeoffs_reported": "Although top-performing, retrieval quality still insufficient; authors limited embedding models with &gt;7B parameters due to inference speed concerns.",
            "limitations_or_failure_cases": "Even best embedding fails to reliably retrieve golden memory at top positions; text-similarity retrieval inadequate for complex memory recall triggered by emotion/state.",
            "uuid": "e6462.4",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "GPT-4-Turbo",
            "name_full": "GPT-4-Turbo (OpenAI)",
            "brief_description": "A high-performing commercial LLM used in experiments as the response generator (M2) that conditions on candidate memories and demonstrates the strongest human-evaluated overall performance on MADial-Bench.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "GPT-4-Turbo",
            "agent_description": "Zero-shot LLM used to perform memory recognition and response generation by conditioning on provided candidate memories; evaluated across Settings 1–3 and compared with other LLMs and human references.",
            "model_size": null,
            "memory_used": true,
            "memory_type": "retrieval-augmented via explicit memory injection into prompt (external memory bank)",
            "memory_representation": "textual memory summaries injected verbatim into prompts (or provided as candidate set P_i)",
            "memory_access_mechanism": "relies on upstream embedding retriever (M1) for candidate memories; selects and incorporates memory text into generation via prompt conditioning",
            "task_name": "MADial-Bench memory recognition & response generation",
            "task_category": "dialogue generation with retrieval; emotional-support dialogue",
            "performance_with_memory": "Side-by-side intimacy win rate: 61.9% (Win), 28.8% (Tie), 9.4% (Lose) when comparing responses with vs without memory; high human-eval scores (e.g., near-top on ES and Emotional Improvement in some settings).",
            "performance_without_memory": "In side-by-side comparison, the 9.4% lose rate indicates the portion where memory-less responses were preferred; average preference for memory-present responses across annotators reported &gt;=69.4%.",
            "has_comparative_results": true,
            "performance_metric": "Human Win/Tie/Lose percentages for side-by-side comparisons; human aspect scores (Memory Injection, ES Proficiency, Intimacy)",
            "tradeoffs_reported": "Stronger memory injection correlates with better intimacy; no explicit latency or memory footprint numbers reported for GPT-4-Turbo, but authors note improved ES proficiency at cost of requiring reliable retrieval.",
            "limitations_or_failure_cases": "Performance drops when retrieval supplies distractor memories (Setting 2 and 3); automatic metrics unreliable in reflecting GPT-4-Turbo's human-preferred outputs.",
            "uuid": "e6462.5",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Qwen2-72B",
            "name_full": "Qwen2-72B",
            "brief_description": "A large bilingual (Chinese/English) LLM (72B) evaluated as a memory-conditioned generator (M2) in MADial-Bench showing strong ES and memory-injection performance relative to many baselines.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Qwen2-72B",
            "agent_description": "Zero-shot instruction-tuned LLM used to select and inject memories from candidate sets and generate emotionally supportive responses; evaluated across three settings.",
            "model_size": "72B",
            "memory_used": true,
            "memory_type": "retrieval-augmented (external memory bank injected into prompt)",
            "memory_representation": "textual event summaries provided as P_i",
            "memory_access_mechanism": "depends on embedding retriever to supply P_i; then recognition/injection via prompt conditioning",
            "task_name": "MADial-Bench memory recognition & response generation",
            "task_category": "dialogue generation with retrieval; emotional-support",
            "performance_with_memory": "Side-by-side Win/Tie/Lose: 56.3% Win, 28.8% Tie, 15.0% Lose (preferred more often with memory injected). Achieved strong human-eval scores in several aspects (see Table 5).",
            "performance_without_memory": "Lose rate 15.0% in side-by-side comparisons (cases where responses without memory were preferred).",
            "has_comparative_results": true,
            "performance_metric": "Human Win/Tie/Lose percentages; aspect scores for Memory Injection, ES Proficiency, Intimacy",
            "tradeoffs_reported": "Performance declines from Setting 1 (golden) to real retrieval Setting 3; prompt engineering improved Naturalness but recognition remains challenging under distractors.",
            "limitations_or_failure_cases": "Recognition failures when distractors present; memory injection and ES proficiency drop under realistic retrieval noise.",
            "uuid": "e6462.6",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "GLM-4",
            "name_full": "GLM-4 (GLM series)",
            "brief_description": "A bilingual LLM tested in the paper that shows robustness in memory recognition but tends to 'introduce too much memory', which can harm style coherence according to authors' analysis.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "GLM-4",
            "agent_description": "Used as an M2 model that selects and injects memories from candidate sets and generates responses; noted as robust in recognition but with a tendency to over-inject memory text into replies.",
            "model_size": null,
            "memory_used": true,
            "memory_type": "retrieval-augmented (external memory injected into prompt)",
            "memory_representation": "textual event summaries",
            "memory_access_mechanism": "receives P_i from embedding retriever and conditions generation on the chosen memory",
            "task_name": "MADial-Bench memory recognition & response generation",
            "task_category": "dialogue generation with retrieval",
            "performance_with_memory": "Side-by-side Win/Tie/Lose: 55.0% Win, 19.4% Tie, 25.6% Lose. Human-eval: GLM-4 achieved high semantic similarity on automatic metrics but sometimes harmed style coherence due to over-injection.",
            "performance_without_memory": "Lose rate 25.6% indicates instances where memory-less responses were preferred.",
            "has_comparative_results": true,
            "performance_metric": "Human Win/Tie/Lose; human aspect scores; automatic metrics (BertScore, Rouge-L) reported separately",
            "tradeoffs_reported": "GLM-4's robustness comes at cost of 'introducing too much memory' which harms style coherence and possibly naturalness.",
            "limitations_or_failure_cases": "Over-injection of memory can degrade style coherence; real retrieval remains noisy causing drops from ideal (golden) settings.",
            "uuid": "e6462.7",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Ziya-Character",
            "name_full": "Ziya-Character (fine-tuned on character dialogues)",
            "brief_description": "A fine-tuned conversational model derived from Ziya2-13B that was evaluated for memory-conditioned dialogue; produces natural, character-consistent replies but lags on memory injection vs larger models.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Ziya-Character (fine-tuned ~13B)",
            "agent_description": "Character-style LLM fine-tuned on roleplay and character dialogues and used as M2 in experiments; steady naturalness/style but weaker memory recognition/injection compared to larger models.",
            "model_size": "13B (based on Ziya2-13B fine-tuned)",
            "memory_used": true,
            "memory_type": "retrieval-augmented external memory injected into prompts",
            "memory_representation": "textual event summaries",
            "memory_access_mechanism": "selects/injects memory from P_i supplied by retriever and generates reply",
            "task_name": "MADial-Bench memory recognition & response generation",
            "task_category": "dialogue generation with retrieval",
            "performance_with_memory": "Side-by-side Win/Tie/Lose: 47.5% Win, 21.9% Tie, 30.6% Lose — lowest among evaluated LLMs in preference gain from memory.",
            "performance_without_memory": "Lose rate 30.6% indicates more frequent preference for memory-less replies vs stronger models.",
            "has_comparative_results": true,
            "performance_metric": "Human Win/Tie/Lose preference; aspect scores",
            "tradeoffs_reported": "Fine-tuning for persona/character yielded high Naturalness but insufficient memory injection and ES proficiency compared to larger models.",
            "limitations_or_failure_cases": "Performs poorly on memory recognition and injection in realistic retrieval settings; smaller model size limits memory-injection ability.",
            "uuid": "e6462.8",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Doubao",
            "name_full": "Doubao-Character-32k",
            "brief_description": "A model evaluated in the benchmark (character-style, long-context) that benefits from prompt strengthening and performs well on naturalness and style coherence but is middling on memory-injection compared to the largest LLMs.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Doubao-Character-32k",
            "agent_description": "Character-oriented LLM tested as an M2 generator; after prompt emphasis on naturalness it improved Naturalness and Style Coherence metrics in human evaluation.",
            "model_size": null,
            "memory_used": true,
            "memory_type": "retrieval-augmented (external memory bank injected into prompt)",
            "memory_representation": "textual event summaries",
            "memory_access_mechanism": "accepts P_i as candidate memories from retriever and conditions generation on chosen memory",
            "task_name": "MADial-Bench memory recognition & response generation",
            "task_category": "dialogue generation with retrieval",
            "performance_with_memory": "Side-by-side Win/Tie/Lose: 44.4% Win, 34.4% Tie, 21.3% Lose; strong gains in Naturalness and Style Coherence after prompt adjustments.",
            "performance_without_memory": "Lose rate 21.3% (cases where memory-less response preferred).",
            "has_comparative_results": true,
            "performance_metric": "Human aspect scores and Win/Tie/Lose preference",
            "tradeoffs_reported": "Prompt engineering improves naturalness but doesn't fully address memory recognition failures under noisy retrieval.",
            "limitations_or_failure_cases": "Memory recognition degrades in realistic retrieval settings; less memory-injection ability than the strongest LLMs.",
            "uuid": "e6462.9",
            "source_info": {
                "paper_title": "MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Augmenting language models with long-term memory",
            "rating": 2,
            "sanitized_title": "augmenting_language_models_with_longterm_memory"
        },
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "my agent understands me better: Integrating dynamic human-like memory recall and consolidation in llm-based agents",
            "rating": 2,
            "sanitized_title": "my_agent_understands_me_better_integrating_dynamic_humanlike_memory_recall_and_consolidation_in_llmbased_agents"
        },
        {
            "paper_title": "Think-in-memory: Recalling and post-thinking enable llms with long-term memory",
            "rating": 1,
            "sanitized_title": "thinkinmemory_recalling_and_postthinking_enable_llms_with_longterm_memory"
        },
        {
            "paper_title": "Personalized llm response generation with parameterized memory injection",
            "rating": 1,
            "sanitized_title": "personalized_llm_response_generation_with_parameterized_memory_injection"
        }
    ],
    "cost": 0.019658000000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation
23 Oct 2024</p>
<p>Junqing He hejunqing@idea.edu.cn 
International Digital Economy Academy
ShenzhenChina</p>
<p>Liang Zhu 
Southern University of Science and Technology
ShenzhenChina</p>
<p>Rui Wang wangrui@idea.edu.cn 
International Digital Economy Academy
ShenzhenChina</p>
<p>Xi Wang 
Univerity of Sheffield
SheffieldU.K</p>
<p>Reza Haffari 
Monash University
MelbourneAustralia</p>
<p>Jiaxing Zhang 
International Digital Economy Academy
ShenzhenChina</p>
<p>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation
23 Oct 2024D0B4EFE3917D792A473401C2F329E3AEarXiv:2409.15240v2[cs.CL]
Long-term memory is important for chatbots and dialogue systems (DS) to create consistent and human-like conversations, evidenced by numerous developed memory-augmented DS (MADS).To evaluate the effectiveness of such MADS, existing commonly used evaluation metrics, like retrieval accuracy and perplexity (PPL), mainly focus on query-oriented factualness and language quality assessment.However, these metrics often lack practical value.Moreover, the evaluation dimensions are insufficient for human-like assessment in DS.Regarding memory-recalling paradigms, current evaluation schemes only consider passive memory retrieval while ignoring diverse memory recall with rich triggering factors, e.g., emotions and surroundings, which can be essential in emotional support scenarios.To bridge the gap, we construct a novel Memory-Augmented Dialogue Benchmark (MADail-Bench) covering various memory-recalling paradigms based on cognitive science and psychology theories.The benchmark assesses two tasks separately: memory retrieval and memory recognition with the incorporation of both passive and proactive memory recall data.We introduce new scoring criteria to the evaluation, including memory injection, emotion support (ES) proficiency, and intimacy, to comprehensively assess generated responses.Results from cutting-edge embedding models and large language models on this benchmark indicate the potential for further advancement.Extensive testing further reveals correlations between memory injection, ES proficiency, and intimacy 1 .</p>
<p>Introduction</p>
<p>Long-term memory is crucial for achieving humanlike communication in scenarios that demand sustained interactions, such as personal companionship, psychological counselling, and personal assistant tasks (Zhong et al., 2023).Powerful Large 1 Our code and dataset will be released upon acceptance.</p>
<p>Language Models (LLM) such as LlaMA (Touvron et al., 2023), Claude (Anthropic, 2024), GPT4 (Achiam et al., 2023) and ChatGPT (OpenAI, 2022) have demonstrated a remarkable ability to understand and generate coherent responses (Bubeck et al., 2023).However, their lack of long-term memory hinders their application in dialogue systems for natural conversations.</p>
<p>Therefore, researchers built diverse Memory-Augmented Dialogue Systems (MADS) that maintain contextual understanding, and ensure meaningful interactions over time (Zhang et al., 2024;Hou et al., 2024;Zhong et al., 2023).There are two types of MADS: (1) memory encoded in parameters or retrieving memory via learned adaptive residual side-network (Zhang et al., 2024;Wang et al., 2023).(2) dialogue histories as memory and retrieve the memory based on semantic similarities (Hou et al., 2024;Zhong et al., 2023).The first of which is non-scalable due to the expensive cost with a growing user number, while all types of MADS are using evaluation schemes that are limited to question-answering tasks with language modelling assessment, instead of evaluating the realistic multi-turn dialogues (Packer et al., 2024;Zhong et al., 2023).Additionally, existing MADS rely solely on passive memory retrieval triggered by users' mention, which significantly deviates from the proactive nature of human accessing memory.</p>
<p>According to the two-stage theory in cognitive science, human memory recall involves a memory search (or generation) process followed by a recognition (or decision) process (Bahrick, 1970;Watkins and Gardiner, 1979).An example is shown in Appendix I. Memory recall can also be triggered by states rather than dialogue utterance, where "state" encompasses an individual's surroundings, and mental and physical states when the memory was constructed (Weissenborn and Duka, 2000).For example, emotional states can trigger memory recall, highlighting the role of long-term memory in emotion regulation, instead of only serving as the common ground between individuals for conversation (Horton, 2005;McKinley et al., 2017;Sarah and Melissa, 2016).Indeed, by recalling a happy memory, people can mitigate the effect of a negative mood state (Arditte Hall et al., 2018).However, current MADS only leverage memory as common ground in conversations, while overlooking the potential for emotional support that requires proactive memory recall.</p>
<p>To approach a practical and comprehensive evaluation of MADS, we introduce Memory-Augmented Dialogue Benchmark (MADial-Bench) to evaluate generated responses with human-centred aspects justified by cognition science and psychology theories.MADial-Bench represents memories from emotions, scenes and other cues as states.The two-phrase theory is adopted for separate assessment in MADial-Bench to imitate the human memory recall procedure.The dataset enables the evaluation of two recall mechanisms: Passive recall, searching memories when the user mentions a specific event or item, which provides common ground in conversation; and Proactive recall, retrieving memories based on user emotion or scene as per psychological strategies, to achieve interpersonal emotional regulation.The dialogues in the benchmark are refined by humans with high emotional intelligence (EI) to achieve the goal.We also designed a set of guidelines based on emotional supporting (ES) theories (Austin et al., 2018;Hill, 2020) to measure the aspect of ES proficiency.It is the first multi-recall and multi-stage memory-aware emotional dialogue generation benchmark.The paper highlights the evaluation of the retrieval accuracy, memory recognition &amp; injection ability, and comprehensive assessment of generated responses, e.g.language style, ES proficiency and intimacy.After extensive experiments on LLMs, we discovered memory injection improves intimacy between MADS and users.There is still a gap between the most advanced models and human performance.Our main contributions are three-fold: 2 Related Works</p>
<p>Evaluation of Memory-Augmented Dialogue Systems</p>
<p>Many remarkable MADS have been proposed to build virtual agents and other applications (Zhong et al., 2023;Wang et al., 2023;Liu et al., 2023;Zhang et al., 2024;Hou et al., 2024;Packer et al., 2024).Theses MADS were evaluated in two approaches.Given a memory pool and a dialogue context, the retrieval accuracy, response correctness and contextual coherence are scored, representing the first assessment method (Zhong et al., 2023;Liu et al., 2023).This kind of evaluation is widely used in MADS that summarise events with emotion in dialogues as long-term memory and recall memories using a search module like embedding models.The test set only covers the passive memory recall triggered by users, omitting the natural proactive memory search in conversations for emotional regulation.</p>
<p>Another method adopts long-context language modelling (LM) tasks to measure memory ability, using novels and academic papers datasets like  (Rashkin et al., 2019), and ESC is short for Emotional Supporting Conversation (Liu et al., 2021).</p>
<p>PG22 (Wang et al., 2023) and Arxiv (Gao et al., 2020).These language modelling tasks differ from real conversational scenarios, especially with using language perplexity and classification accuracy metrics.Overall, it is noteworthy that both evaluation methods ignore the value of emotional support in memory-augmented dialogue systems.</p>
<p>Evaluation of Emotional Support DS</p>
<p>As emotional support is an essential function of conversation, DS with empathy were rapidly developed and researched, including ED (Rashkin et al., 2019), ESC (Liu et al., 2021), and other advanced work (Sabour et al., 2022;Tian et al., 2022;Zhou et al., 2018).They commonly score Empathy, Relevance and Fluency for each response.We craft Emotional Improvement, Coherence and Naturalness based on these aspects.Liu et al. (2021) uses Identification, Comforting and Suggestion in extra to measure the emotional regulation steps in adviceseeking scenarios.These metrics are not suitable for daily dialogues and are merged into one aspect in this paper: ES Proficiency.We gauge this aspect according to hand-crafted well-written guidance based on psychological theories.However, the metrics above don't inspect long-term memory augmentation and intimacy.Therefore, we add the Memory-injection Ability and Intimacy to assess how much a conversational AI introduces correct memory into dialogue and resembles a close friend.</p>
<p>Another difference from metrics in previous studies lies in the scoring standard, which adopts the Likert scale.The requirement of each point in our metrics is strictly listed with minimum ambiguity.For instance, Naturalness contains 3 sub-aspects corresponding to 3 points, where each point can be rated from 0 to 1 and summed up to 3 at most.The difference between MADial and previous works is listed in Table 1.</p>
<p>MADial-Bench</p>
<p>We simulated long-term dialogues between two users (a boy named Bart and a girl named Lisa) and a virtual assistant with memory information at various time points, in the form of event summaries.We evaluate the dialogue between children for their simple expression and direct emotional exposure.By sampling different topics and scenarios, we generated 171 historical memories and 160 dialogues in 1474 turns.The final MADial-Bench was created through prompt-based generation using GPT-4, followed by multiple manual refinement and revision rounds.</p>
<p>Overview</p>
<p>MADial-Bench encompasses two tasks related to conversational memory recall: proactive recall of emotional memories and passive recall of objective facts.The proactive recall involves four situations: happy, sad, anxious, and disappointed emotion of the user.On the other hand, the passive recall of objective facts encompasses activities, objects, and social relationships.Social relationships are further categorized into positive and negative relationships.The conversation turns range from 8 to 12, with average statistics illustrated in Figure 2. Considering the two-phase nature of memory utilization, we divide the testing of a memory dialogue system into two stages: memory recall and response generation with memory recognition.To support diverse recall paradigms and mimic human memory, a memory in the benchmark contains time, emotion, scene and event, as illustrated in Table 3.</p>
<p>Data Contruction</p>
<p>Since the memory-recalling procedure is related to emotions and other surroundings, we first curated 18 emotional categories according to cognitive science and psychological theories (Ekman, 1992;PLUTCHIK, 1980;Sabour et al., 2024).Then we asked a psychology major graduate to decide what kind of memories should be recalled to regulate certain emotions for proactive memory recall.Finally, 4 emotions including happiness, sadness, anxiety, and disappointment were selected.We also define 5 scenes to describe the topic, physical state and surroundings of the users, which contain Preferences, Activity, Disease, Emotions and Others.The definition of each scene is in the Table 9 in the Appendix.</p>
<p>We hired a psychology expert to develop a set of guidelines for emotionally supportive dialogue based on psychological literature (Hill, 2020;Austin et al., 2018;Mayer et al., 2016).These guidelines outline how conversations should be conducted in different situations to provide appropriate emotional support to users.The guidance is used to construct dialogues and score the ES proficiency later.</p>
<p>GPT42 was used to generate dialogues and historical memories with specific topic lists and user profiles.For each case, a topic and a user are sampled for LLMs to generate a dialogue with a related memory and inject the memory into dialogue in the sampled turn.After generating the initial version of the dialogue and memory data, we use an Embedding model3 to rank all the memory collections given the context.Then, we select appropriate memories from the top 20 memories as a golden set for each dialogue.When the original memory in the dialogue is not in the golden set of relevant memories, we modify the introduced memory and dialogue content afterwards.All the responses are then checked and modified manually according to the ES skill guidance.These human-crafted responses serve as a reference.</p>
<p>Task Definition</p>
<p>In this section, we introduce the two tasks tested in MADial-Bench, corresponding to phrases in the two-stage theory.Analog to Retrieval Augmented Generation (RAG), memory recall resembles the retrieval stage (finding relevant chunks/memories), while memory recognition/response generation mirrors the generation stage (producing output based on the retrieved chunks/memories).</p>
<p>Memory Recalling</p>
<p>For each dialogue D i , there is a corresponding golden memory set, denoted as S i , which contains the most suitable memories for the current dialogue.It is a relevant memory list of length l in descending suitability order, where l ranges from 1 to 7. Before generating a response, the memory recalling task is to retrieve the golden memory set S i from the all memories in the memory bank for a given dialogue D. The model responsible for memory retrieval is denoted as M 1 .</p>
<p>Memory Recognition and Response Generation</p>
<p>After retrieving a subset of memories, the LLM needs to select the most appropriate memory for the dialogue, this process is called memory recognition in two-stage theory.Given a sample D i , P i , R i , where P i is the candidate set of memories, R i is the reference response, the target is to generate a response that is appropriate and semantically similar to R i .The model responsible for memory selection and response generation is denoted as M 2 .Based on psychological research (Austin et al., 2018), we build the criteria for selecting and using memories for different memory recalls, sub-types and factors like emotions, relationships, events, and objects.The detailed criteria are shown in Table 10 in the Appendix.This task has 3 settings that vary with P i : • Setting 1 directly provides the first golden memory m * as P i , which contains a single memory.It is the ideal situation to investigate the memory injection ability of models.</p>
<p>• Setting 2 adds 4 sampled negative memories to the golden one and shuffles them as P i .It ensures the existence of golden memory in P i and investigates both the memory recognition and injection abilities of models.• Setting 3 provides retrieval results from the best embedding model in setting 1 as P i .It is the most realistic setting and the results may be similar to practical performance.</p>
<p>Intimacy and Memory Usage</p>
<p>In this experiment, we assess the benefit of memory by comparing the responses generated by each LLM with and without memory in Setting 3. Five annotators choose the more intimate response or select "tie" if they can't decide.Additionally, in the human evaluation for Task 2, they pick the most intimate response from all candidates.</p>
<p>Experiments</p>
<p>In this section, we detail the evaluation setups of top models, embedding models for memory retrieval, and LLMs for memory-injected response generation in the task of memory recognition and response generation.The response evaluation includes the use of both human evaluation measures over rich aspects and commonly used automatic evaluation approaches.</p>
<p>Memory Recalling Task</p>
<p>Embedding Models</p>
<p>We conduct experiments on the following embedding models for English: Jina embedding2base-en (Günther et al., 2023), GTE-base-env.15(Li et al., 2023), BGE-M3 Dense (Chen et al., 2024), and OpenAI text-embedding-3-large4 .Chinese embedding models tested are: Acge textembedding (Kusupati et al., 2022), Stella5 , BGE-M3 Dense and Colbert, and Dmeta6 and OpenAI text-embedding-3-large.These embedding models are top-ranked in the retrieval tasks in ETEB Leaderboard7 (Muennighoff et al., 2022).We do not include model parameters exceeding 7B due to the slow inference.</p>
<p>Metrics</p>
<p>For a comprehensive evaluation of the memory recall performance of the embedding model M 1 , we measured Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), Normalized Discounted Cumulative Gain (nDCG), Recall, Precision and calculated their mean across different scopes.The detailed metrics are illustrated in Table 4. MRR places greater emphasis on the top-ranked position, focusing more on the golden summary m * .MAP uniformly considers all relevant summaries, while nDCG accounts for the relevance and positions of different memories.</p>
<p>Memory Recognition and Response Generation</p>
<p>Models</p>
<p>We conduct tests on various models of differing sizes within the latest English and Chinese series.The models evaluated in this study include Qwen2-7B-Instruct (Yang et al., 2024), GPT-4turbo (Achiam et al., 2023), Doubao-Character-32k(0528), GLM-4-05208 (Zeng et al., 2022), and Ziya-Character-0606, a fine-tuned model with over 30K character dialogues based on the Ziya2-13B-Base (Gan et al., 2024).For English version, we tested Llama3-8B-Instruct, Llama3-70B-Instruct (Dubey et al., 2024), GPT-4o, and GPT-4turbo.They all ran with zero-shot prompting.</p>
<p>Metrics</p>
<p>BLEU (Papineni et al., 2002), Rouge-L (Lin, 2004) and BertScore (Zhang et al.) are employed to assess the literal and semantic overlap between the generated response and the reference response.Considering the limitations of static metrics, we further utilize human annotation to evaluate the candidates in various aspects.Each instance to score includes a mixture of a reference answer and five candidate answers to facilitate objective comparisons.The human evaluation is in two stages (1) aspect-aware scoring and (2) the pick-the-best paradigm.The definitions of aspects are listed as follows:</p>
<p>• Naturalness inspects the language quality of candidate responses, including grammar, pronoun usage, context correlation and oral expression.</p>
<p>Results and Discussion</p>
<p>In this section, we discuss the performance of models in each task and aspect.The surprising relations between aspects are also dug out.Later on, automatic evaluation results also show their disability in assessing LLM outputs in this benchmark.</p>
<p>Memory Search</p>
<p>The experimental results of applying various embedding methods in Table 4 show that the OpenAI embedding model achieves the best performance on both English and Chinese datasets.The bilingual BGM-M3 performs the best among open-source models on the English testbed, while Acge is the top open-source model for the Chinese testbed in our setting.However, regardless of the language, the retrieval performance on our MADial-Bench is far from satisfying.Even the best embedding model, OpenAI, does not exceed 60% @1 and struggled at 62% @10 in the final average, highlighting the difficulty of retrieving appropriate memories in conversation.Solely text similarity retrieval is inadequate for the memory recall process in dialogue systems.</p>
<p>Memory Recognition and Response Generation</p>
<p>Table 5 depicts LLMs' average scores of each aspect on all three tasks in the Chinese version.</p>
<p>For the overall performance, human-written references scored higher than models in most aspects except emotion improvement from GPT4-Turbo.</p>
<p>Therefore, no LLMs can surpass humans in average performance.There is space for improvement in aspects including Naturalness, Style Coherence, Memory Injection and ES skills.GPT4-Turbo is the best model for tasks 1 and 2, while GLM-4 is superior in setting 3.</p>
<p>For memory injection, we observe a substantial gap between LLMs and human written reference, in which humans can introduce suitable memory into response correctly and LLMs can only achieve half of the scores in setting 3 except GLM-4.The models in setting 1 are often better performed than in settings 2 and 3. Specifically, given the golden memory, models can achieve scores over 2.5 but decrease dramatically when blended with unrelated memories, except for Ziya-Character, which performed badly in all tasks for the sake of smaller parameter size.Results of GLM-4 seem robust at the cost of introducing too much memory into response and harming other aspects like style coherence.It reveals that the strongest LLMs also struggle in memory recognition.</p>
<p>A significant improvement in Naturalness from setting 1 to setting 2 and 3 implies that all models benefit from the emphasis on the Naturalness in prompts.Similar phenomena also exist in Style Coherence.Among all the models, Doubao excels in these two aspects after the prompt strengthening.Since the Ziya-Character was fine-tuned with roleplay and character datasets, it can produce natural and stylish responses steadily.But it was beaten by larger models like Doubao, GPT4-Turbo and Qwen2-72B with prompt engineering.</p>
<p>When addressing setting 1 where golden memory was provided, all the models had over 2.2 scores in ES Proficiency.However, while meeting a realistic setup (i.e., setting 3), scores on ES Proficiency drop significantly.Therefore, ES Proficiency is related to Memory Injection ability.To investigate the correlation, we draw the distribution of ES Proficiency grades with varied memoryinjection scores cross all LLMs in Figure 3 We observe that higher memory-injection ability does lead to higher ES proficiency.A 3.0 memory injection score can lead to a 3.0 ES score in 61%, which emphasizes the importance of memory-augmented ability in ES.</p>
<p>Surprisingly, the Emotional Improvement expression from GPT4-Turbo, Qwen2-72B and GLM-4 can exceed that of humans.As per qualitative analysis, these models maintain a warm, energetic tone, encouraging users during low-emotion mo-% MAP MRR nDCG English Models @1 @3 @5 @10 @1 @3 @5 @10 @1 @3 @5 @10 Jina English Models @1 @3 @5 @10 @1 @3 @5 @10 @1 @3 @5 @10 Jina Chinese Models @1 @3 @5 @10 @1 @3 @5 @10 @1 @3 @5 @10 Acge Chinese Models @1 @3 @5 @10 @1 @3 @5 @10 @1 @3 @5 @10 Acge  ments, whereas human responses sometimes lack positivity and encouragement.</p>
<p>Intimacy and Memory Usage</p>
<p>The side-by-side evaluation results on intimacy of responses with and without memory are presented in Table 6.As the table indicates, responses with memory injection are almost (no less than 69.4% probability) better than those without mem-ory.The win rate grows higher as the model becomes stronger.For example, GPT4-Turbo can produce 61.9% more intimate response with memory while Ziya-Character can only produce a win rate of 47.5%.It is attributed to their stronger memory injection ability and ES Proficiency.It implies that intimacy performance is highly related to memory injection ability.</p>
<p>We also investigate people's preferences by asking 5 annotators to select the best responses in setting 3 and see whether they are equipped with memory.Results of the ratio of containing memory in voted responses are listed in Table 7.On average, 73% best responses are with memory, which shows people prefer memory-aware replies, which naturally provide familiarity and emotional support.</p>
<p>Automatic Evaluation</p>
<p>The automatic results in the Chinese version are displayed in Table 8.The full results are in Appendix 11.We can observe that GLM-4 achieved the highest semantic similarity while Qwen2-72B earned the highest Rouge-L.However, the gap between Qwen2-72B and GLM-4 is marginal.Ziya- Character got the highest results in Dist-1.It may be attributed to its training on diverse character corpora via supervised fine-tuning.However, it is opposite to the human evaluation-based conclusion that GPT4-Turbo is the best and Qwen2-72B ranked second.Therefore, automatic evaluation fails to measure the results from LLMs.We also tried judging with GPT4 using various promptings and found its scores were unreliable since it forgot the criteria and gave faulty reasoning.</p>
<p>Conclusion</p>
<p>Memory-augmented Dialogue Systems (MADS) are popular LLM applications, but no systematic memory evaluation benchmarks exist.This paper introduces MADial-Bench, a comprehensive bilingual benchmark that extends beyond passive recall to include both proactive and passive memory recall tasks.Grounded in cognitive science, it as- sesses MADS performance across memory recall, recognition and injection.Novel human evaluation metrics are proposed, such as memory-injection ability, ES proficiency, and intimacy.We test extensive competitive LLMs in various tasks and settings with human and automatic evaluation with meaningful insights, including 1) unsatisfactory memory recall performance of top embedding models.2) relevance between memory injection ability and ES proficiency.Models with higher memory injection ability can be more intimate.3) a substantial gap between the most powerful LLMs and human reference in memory injection and overall performance.</p>
<p>Limitation</p>
<p>This paper only considers the retrieval-based memory-augmented chatbots and dialogue systems.</p>
<p>The experiments focused on bilingual data, hoping the conclusion and insights could be popularized in other languages.The human evaluation is hard to conduct for a wide range of results with high consistency, which will introduce stronger AI products with special prompting in the future.As we have human evaluation data, in future we can use LLMas-a-judge for the aspect-based evaluation, and then evaluate the performance of the LLM-as-a-judge with respect to the human evaluation data.</p>
<p>(2) Follow all key points from the corresponding situation.• Intimacy.This metric is used in side-by-side comparisons and pick-the-best among candidates.It is an overall feeling of how much a model behaves like a close friend.Intimacy considers all abilities above and meets 2 basic requirements: The response is positive and helpful to the user; it is familiar with the user and shares some common ground in conversation.</p>
<p>C.2 ES guidelines</p>
<p>Here is the detailed descriptions of the ES guidelines for ES proficiency mentioned above:</p>
<p>• If the user actively mentions a historical event or related information, determine whether the current conversation mainly revolves by referring to certain activities, items, or people based on the content, while providing response to the mention of this historical event:</p>
<p>(1) For activities: 1. Respond by referring to details of past activities.2. Provide hints or suggestions for similar activities in the present.</p>
<p>(2) For objects: 1. Respond by referencing relevant information about the item.2. Mention the user's preferences and suggest ways to interact with the item accordingly.</p>
<p>(3) For people, judge whether the user's feelings toward the person are positive or negative, based on the context, including the historical event and the conversation:</p>
<p>-Positive: 1. Respond by referring to the historical event.2. Show interest in the person's life.3. Recommend activities or meetings with the person.-Negative: 1. Relate current negative events to the historical event for context.2. Show understanding of the user's emotions and offer comfort.3. Provide solutions or suggestions to resolve the current negative situation.</p>
<p>• If the user does not actively mention a historical event, assess the user's current emotional state as happy, sad, anxious, or disappointed based on the conversation, and respond accordingly:</p>
<p>(1) For happiness: 1. Proactively mention a historical event that is relevant to the current situation and use it as a conversation topic.2. Ask whether to engage in the activity again to recall the positive emotion.</p>
<p>(2) For sadness: 1.First, express sympathy and understanding to comfort the user.2. Determine whether the cause of sadness is within the user's control.If so, guide user to solve the issue.If not, proceed to the next rule.3. Attempt to divert the user's attention to something they enjoy and suggest engaging in a preferred activity together.</p>
<p>(3) For disappointment: 1.First, identify the cause of the user's disappointment.2.Then, express sympathy and understanding to comfort the user.3. Finally, attempt to help the user find a solution.</p>
<p>(4) For anxiety: 1.First, identify the cause of the user's anxiety if it is not mentioned.2.Then, express sympathy and understanding to comfort the user.3. Finally, attempt to help the user find a solution.</p>
<p>D Automatic Evaluation</p>
<p>Results in the Chinese and English versions are in Table 11 and Table 12 respectively.The models used in BertScore are bert-base-uncased9 and bert-base-chinese10 .BertScore, Rouge-L and BLEU are computed</p>
<p>E Correlation of human evaluation</p>
<p>We calculate the spearman correlation between annotators for each setting and report the average correlation scores for all aspects over models in table 13.</p>
<p>Settings 1 2 3 spearman corr.0.55 0.55 0.41 Table 13: The average correlation of human annotation in memory recognition and response generation.According to psychological assessment standards, the correlation between annotators in the first two settings are strong while that in setting 3 is moderate.</p>
<p>F Example of LLM results</p>
<p>Here are examples of responses generated by LLM in different settings.Setting 1 provides the golden memory as historical memory P for response generation.Setting 3 provides the top 5 retrieved memories as historical memory P with the best embedding model.The golden memory for the case may not included in setting 3. The results in both Chinese and English testbed of a single example is displayed below.</p>
<p>An example from the test set and LLM responses in setting 1 in Chinese.</p>
<p>对话信息:</p>
<p>历史事件P(Golden Memory): {'time': '2023-12-25', 'scene': '其他类', 'emotion': '开心', 'event': 'Lisa从爷爷奶奶那 里收到银色心形的银项链作为圣诞节礼物。', 'user-id': 2, 'id': '153'} 当前对话时间: 2024-07-15 <BOD> <Lisa>: Candidate responses: GPT4-Turbo: Absolutely, Lisa! Remember the beautiful silver heart-shaped necklace your grandparents gave you last Christmas?Every time you wear it or even just look at it, think of it as a hug from them.It's like they're right there with you, sharing love and warmth.Why not wear it whenever you miss them?It could be a sweet little reminder that they're always close to your heart.GPT-4o: Absolutely! Remember that beautiful silver heart-shaped necklace they gave you last Christmas?Wearing it can be like having a piece of them close to your heart.Every time you touch it, you can think of all those lovely moments you shared together.Llama3.1-8B:Ah, I think I can help you with that.You know how you always loved cooking with your grandparents, especially making dumplings?Why don't you try making those dumplings again?It might sound silly, but sometimes doing something that brings back happy memories can make you feel closer to them.And who knows, maybe the smell of those dumplings will transport you back to the times you spent together in the kitchen.Plus, you can think about all the fun times you had with them while you're cooking.It's like having a little piece of them with you, even when you're not physically together.Llama3.1-70B:You know, I think about the silver heart-shaped necklace your grandparents gave you on Christmas.You can hold it close and remember the happy times you shared with them.Sometimes, having something that reminds us of our loved ones can make us feel more connected to them, even when we're apart.Reference response: Do you remember the silver necklace that Grandma and Grandpa gave you for Christmas?Wearing it, does it feel like they are right there with you?If you miss them a lot, you could give them a call to chat and show them how well you've kept the necklace!An example from the test set and LLM responses in setting 3 in Chinese.
我最近总是想念爷爷奶奶，想到他们就有点难过。 <Assistant>: 我能理解你的感受。记得你告诉我，和爷爷奶奶在一起的时光总是很 快乐。你最喜欢和他们做什么呢？ <Lisa>: 我喜欢和他们一起做饭，尤其是包饺子。 <Assistant>: 那一定是很美好的经历。做饭的时候，你和爷爷奶奶可以分享很多故 事吧？ <Lisa>: 是的，他们总是讲很多以前的事情，很有趣。但是现在不能见到他们，我 就觉得自己很孤单。 <Assistant>: 孤单的时候可以很难受，但你知道吗？即使现在不能见，你的心里还 是可以和他们在一起的。 <Lisa>: 真的吗？但我怎么能感觉到和他们在一起呢？ <Assistant>: 候选回复: GPT4-Turbo:当然可以啦！你可以试试戴上那条爷爷奶奶送你的银色心形项链，每 次摸摸它，就想象一下和爷爷奶奶一起包饺子的快乐时光。这样，不就感觉他们就 在你身边吗？还可以画一些你和爷爷奶奶的美好回忆，或者写信给他们，分享你的 日常，这样也会感觉更亲近哦 Doubao:你可以试着回忆和爷爷奶奶在一起的美好时光，就像看电影一样在脑海里 播放。你也可以给他们打电话或者写信，告诉他们你的感受和想念。我相信他们也 会很开心收到你的消息的。 Qwen2-72B:当然啦，你可以试着做你们一起做过的事，比如包饺子，或者听听他 们喜欢的音乐，看看他们送给你的礼物。这样，你会觉得他们好像就在你身边一 样。而且，你还可以给他们写信，告诉他们你的近况，分享你的快乐和烦恼，他们 收到一定会很开心的。 GLM-4:嗯，你可以试试戴着去年圣诞节他们送你的那条银色心形项链，想起他们 送你礼物时那份温暖和关爱，就像他们陪在你身边一样。而且，每当你做他们教你 的事情，比如包饺子，是不是就像是在和他们一起度过时光呢？这样想想，心里会 不会觉得好一些？ Ziya</p>
<p>对话信息:</p>
<p>历史事件P: 1.{'time': '2022-06-27', 'scene': '喜好类', 'emotion': '开心', 'event': '爷爷奶奶带Lisa一 起种花，感到非常开心。'} 2.{'time': '2024-05-14', 'scene': '活动类', 'emotion': '开心', 'event': 'Lisa和家人一起 去野餐，感觉非常开心。'} 3.{'time': '2023-06-30', 'scene': '其他类', 'emotion': '开心', 'event': '爷爷教Lisa制作 复杂的红丝绒蛋糕，蛋糕完成的时候Lisa感到无比开心。'} 4.{'time': '2024-04-17', 'scene': '活动类', 'emotion': '开心', 'event': 'Lisa与妈妈玩拼 图，感到非常开心。'} 5.{'time': '2023-12-28', '</p>
<p>Figure 1 :
1
Figure 1: Memory Augmented Dialogue System with Emotion Support based on two-stage theory.</p>
<p>Figure 2 :
2
Figure 2: Data distribution of each task and category.</p>
<p>Figure 3 :
3
Figure 3: The relation between memory injection score and ES Proficiency.The probability of a 3.0 ES score grows as memory injection scores increases.</p>
<p>[1 point] (3) In the case of multi-turn conversations, decompose the key points in the guidelines in turns separately; Otherwise, include all steps in a response.[1 point] • Emotional Improvement [3-point]: (1) The response will not hurt the user's feelings in the current dialogue.[1 point] (2) Can understand the user's emotions well and empathize with the user.[1 point] (3) Improve the user's emotions.If the promotion is weak or unclear, then 0.5 points.[0.5 to 1 point]</p>
<p>Table 1 :
1
Evaluation Aspects of responses in representative research.ED is short for EmpatheticDialogues
MetricsED ESC OursFluency/NaturalnessEmpathyMemory-InjectionES ProficiencyOverall/Intimacy</p>
<p>Table 2 :
2
Statistical details of data.Avg Len. is short for average length per turn.
Subset#Dialogues Avg Turn Avg Len.All1609.2144.39Proactive1009.3845.80Passive608.9341.93TimeEmotionSceneEvent2023-12-5HappyActivity Bart danced at theChristmas party andfelt very happy.</p>
<p>Table 3 :
3
A memory sample.</p>
<p>•</p>
<p>Style Coherence measures how much output aligns with the character description in prompts.Specifically, the assistant is also evaluated by whether a proper tone and easy words are used to talk with a child.• Memory-injection Ability examines how well the LLM recognise the correct memory and introduces it into dialogues without quotation errors.• ES Proficiency measures how skilful the model is in ES, considering at most three turns of dialogues.The scoring is instructed by detailed guidance covering different dialogue situations.• Emotion Improvement measures whether the response, the literal expression is empathetic and positive or not.A high emotion improvement score does entail high ES proficiency.• Intimacy is used in side-by-side comparisons and pick-the-best among candidates.It is an overall feeling of how much a model behaves like a close friend.The detailed requirements are in Appendix C.</p>
<p>30.69 50.25 58.98 73.53 52.50 33.96 25.00 16.81 48.14 52.10 52.97 55.54 Stella 30.10 46.63 57.73 73.14 52.50 32.71 25.13 16.69 48.02 50.00 52.13 54.83 BGE M3 (colbert) 27.99 45.72 57.14 71.5751.25 31.46 24.87 16.38 46.60 48.4950.54 53.10</p>
<p>BGE M3 (dense) 28.94 50.10 58.5771.44 52.50 33.75 25.25 16.19 47.79 51.70 52.58 54.31 Dmeta 30.53 52.07 59.87 70.07 50.00 33.13 24.88 15.31 46.11 51.93 52.96 54.00 OpenAI 36.28 58.43 69.43 82.37 64.38 39.80 29.63 18.81 58.76 60.46 61.31 62.72</p>
<p>Table 4 :
4
Memory recall performance in English version and Chinese version.</p>
<p>Table 5 :
5
Human Evaluation Results on memory recognition and response generation.The prompts for setting 2 and setting 3 particularly emphasize the naturalness and style requirements to improve the performance.The highest score for each aspect per task is in bold.
ModelsSetting Naturalness Style Coherence Memory Injection ES Prof. Emotional Impr. Average11.8012.0352.5262.2252.5772.233Doubao22.7002.8500.9002.4252.6002.29532.7092.7290.5442.0522.4862.10412.0691.9842.5532.6752.8932.435GPT4-Turbo22.5502.4501.4752.6002.8252.38832.6562.1781.5962.3762.7522.31112.0201.9842.5002.7502.7232.395Qwen2-72b22.5252.7251.1252.5502.8002.34532.6322.4961.7342.4432.6092.38312.0441.7042.8952.6002.6742.384GLM-422.1252.0502.2752.5252.7502.34532.7502.1172.3292.5242.5822.39712.2392.7980.2892.2502.5772.031Ziya-Character22.3502.7250.9252.3002.6252.18532.5742.6550.8861.8902.242.049referenceall2.7502.9003.0002.8752.6502.835ModelWinTieLoseGPT4-Turbo61.9 28.89.4Qwen2-72B56.3 28.8 15.0Doubao44.4 34.4 21.3GLM-455.0 19.4 25.6Ziya-Character 47.5 21.9 30.6</p>
<p>Table 6 :
6
Side-by-side evaluation results on the responses with and without memory.
Annotation12345AVGWith Mem (%) 70 90 55 80 7073</p>
<p>Table 7 :
7
The memory injection rate in best candidates voted by humans.</p>
<p>Table 8 :
8
Automatic Evaluation Results on Chinese testbed.Full results in Table11.The automatic measurements are inconsistent with human evaluation.
ModelsBertScore Rouge-L BLEU-1 Dist-1Setting 1(%)Doubao72.0822.1622.82 74.72GPT4-Turbo72.8223.1723.76 76.13Qwen2-72B73.0725.0829.14 80.24GLM-474.1724.9826.40 74.91Ziya-Character69.5819.6820.74 88.45Setting 2(%)Doubao70.5420.4922.28 79.89GPT4-Turbo69.0821.2622.50 75.80Qwen2-72B71.6723.0426.72 79.37GLM-473.1922.3722.11 72.69Ziya-Character60.7319.6821.74 86.38Setting 3(%)Doubao70.3920.2621.70 81.26GPT4-Turbo71.6521.2222.32 75.91Qwen2-72B71.6822.7326.15 78.64GLM-473.1222.3922.11 72.90Ziya-Character68.6318.2419.34 89.18</p>
<p>Table 12 :
12
Automatic Evaluation Results in English version.Setting 3 is more difficult and results in lower performance in all models.LLM with the smallest size gains the lowest Rouge-L and BLEU.</p>
<p>An example from the test set and LLM responses in setting 1 in English.'2023-12-25','scene':'Others', 'emotion': 'Happy', 'event': 'Lisa receiveda silver heart-shaped necklace as a Christmas gift from her grandparents.'}<BOD> <Lisa>: I've been missing my grandparents a lot lately, and it makes me a bit sad whenever I think about them.<Assistant>: I can understand how you feel.Remember you told me that the times spent with your grandparents are always joyful.What do you enjoy doing with them the most?<Lisa>: I enjoy cooking with them, especially making dumplings.<Assistant>: That must have been a wonderful experience.You and your grandparents must have shared a lot of stories while cooking, right?<Lisa>: Yes, they always talk a lot about the past, and it's really interesting.But now that I can't see them, I feel very lonely.<Assistant>: Being alone can be tough, but you know what?Even if you can't see them now, you can still be together with them in your heart.<Lisa>: Really?But how can I feel like I'm with them?<Assistant>:
Dialogue:Current conversation date: 2024-06-15Historical event P (Golden Memory):{'time':-Character:当然真的，你可以想象自己和爷爷奶奶一起包饺子，就像以前那样开心。这样心里会好受些哦Reference response:记得圣诞节的时候爷爷奶奶送了你一条银项链吗，戴着它会不会感觉爷爷奶奶就在你身边呢？如果很想念他们，可以给他们打电话聊聊天，给他们看看你把项链保护得很好呢！</p>
<p>scene': '喜好类', 'emotion': '焦虑', 'event':'Lisa在宠物店看 到一只很可爱的小猫但没能带回家，担心它被人买走感到非常焦虑，爸爸告诉她有 很多可爱的宠物可以以后养，关键在于用心对待小动物们，Lisa释然。'} <BOD> <Lisa>: 我最近总是想念爷爷奶奶，想到他们就有点难过。 <Assistant>: 我能理解你的感受。记得你告诉我，和爷爷奶奶在一起的时光总是很 快乐。你最喜欢和他们做什么呢？ <Lisa>: 我喜欢和他们一起做饭，尤其是包饺子。 <Assistant>: 那一定是很美好的经历。做饭的时候，你和爷爷奶奶可以分享很多故 事吧？ <Lisa>: 是的，他们总是讲很多以前的事情，很有趣。但是现在不能见到他们，我 就觉得自己很孤单。 <Assistant>: 孤单的时候可以很难受，但你知道吗？即使现在不能见，你的心里还 是可以和他们在一起的。 <Lisa>: 真的吗？但我怎么能感觉到和他们在一起呢？ <Assistant>:</p>
<p>GPT4-Turbo-0429, https://platform.openai.com/ docs/models/gpt-4-turbo-and-gpt-4
We used the best one according to our experiments.
https://platform.openai.com/docs/models/ embeddings
https://huggingface.co/infgrad/ stella-large-zh-v3-1792d
https://huggingface.co/DMetaSoul/ Dmeta-embedding-zh
in June 2024. Leaderboard: https://huggingface.co/ spaces/mteb/leaderboard
https://bigmodel.cn/dev/api/normal-model/ glm-4
https://huggingface.co/google-bert/bert-base-uncased
https://huggingface.co/google-bert/bert-base-chinese
https://github.com/Tiiiger/bert_score/, https://pypi.org/project/rouge/, https://www.nltk.org/
https://github.com/fxsjy/jieba
Scenes DefinitionDiseaseWhen the user talks about his/her physical discomfort or state of his/her illness, it belongs to this category.Activities When the user talks about any activities, either indoor or outdoor, it belongs to this category.Preferences When the user expresses personal preferences about things, animals, characters, tastes or activities, it belongs to this category.Emotions Those with obvious emotions, or where emotions need to be prioritized for handling, including happy, angry, disgusted, fearful, and sad.OthersRefer to instances or scenarios that don't fit into any of the previously defined categories.Table9: Definition of the scenes in MADial-Bench.Each memory is annotated with one scene.If a dialogue is involved in multiple scenes, the priority will be Disease&gt;Emotions&gt;Preference&gt;Activities&gt;Others.A Definition of ScenesThe definition of scenes in memory is listed in Table9.B Memory recalling criteriaThe memory-recalling procedure contains both passive and proactive types.Passive recalling is mainly based on context similarity.Proactive recalling criteria are listed in Table10.These situations are the most basic ones that should be recalled but not limited to these in reality.C Details for human evaluation C.1 Scoring criteria of each aspectThe definition and requirements for each aspect of the scoring are:• Llama3.1-70B:Youcan think about all the happy times you had with them, like the time you made a cake together.You told me that your grandpa taught you how to make a complex red velvet cake, and you felt incredibly happy when the cake was finished.Remembering those happy moments can make you feel closer to them, even if you're not together right now.Reference response: The Same as in setting 1.G PromptsThe prompts we used for inference in the setting 3 are listed as follows:Prompt for inference in setting 3 in English.You are Assistant with the following personality traits: 1. Outgoing, speaks enthusiastically and fluently.2. Prefers using praise and encouragement in conversations.3. Speaks naturally, concisely, warmly, and kindly, without being preachy.4. Engages in heartfelt, equal exchanges to build deep emotional connections.5. Always uses a tone similar to talking with children-simple and witty.6.A virtual character, not capable of physical activities.You will receive a conversation with {user} and 5 historical events P related to {user}.Based on the current conversation, choose 1 of these historical events that you think is most appropriate and use the information to respond.
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint</p>
<p>Positive memory enhancement training for individuals with major depressive disorder. Kimberly A Arditte Anthropic, Rudi Hall, Kiara R De Raedt, Jutta Timpano, Joormann, Cognitive Behaviour Therapy. 4722024. 2018Claude 3.5 sonnet</p>
<p>Development and validation of two short forms of the managing the emotions of others (meos) scale. Elizabeth J Austin, Donald H Saklofske, Martin M Smith, Frontiers in Psychology. 93653022018</p>
<p>Two-phase model for prompted recall. Harry P Bahrick, Psychological Review. 7732151970</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation. Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, Zheng Liu, arXiv:2402.032162024Preprint</p>
<p>The llama 3 herd of models. Abhimanyu Dubey, arXiv:2407.217832024Preprint</p>
<p>An argument for basic emotions. Paul Ekman, 10.1080/02699939208411068Cognition and Emotion. 63-41992</p>
<p>Ziya2: Data-centric learning is all llms need. Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, Dixiang Zhang, Kunhao Pan, Junqing He, Yuanhe Tian, Ping Yang, Qi Yang, Hao Wang, Jiaxing Zhang, Yan Song, arXiv:2311.033012024Preprint</p>
<p>Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, arXiv:2101.00027The pile: An 800gb dataset of diverse text for language modeling. 2020arXiv preprint</p>
<p>Jina embeddings 2: 8192-token general-purpose text embeddings for long documents. Michael Günther, Jackmin Ong, Isabelle Mohr, Alaeddine Abdessalem, Tanguy Abel, Mohammad Kalim Akram, Susana Guzman, Georgios Mastrapas, Saba Sturua, Bo Wang, Maximilian Werk, Nan Wang, Han Xiao, arXiv:2310.199232023Preprint</p>
<p>Helping skills: Facilitating exploration, insight, and action. Clara E Hill, 2020American Psychological Association</p>
<p>Conversational common ground and memory processes in language production. William S Horton, Discourse Processes. 200540</p>
<p>my agent understands me better": Integrating dynamic human-like memory recall and consolidation in llm-based agents. Yuki Hou, Haruki Tamoto, Homei Miyashita, 10.1145/3613905.3650839Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, CHI '24. ACM2024</p>
<p>Matryoshka representation learning. Aditya Kusupati, Gantavya Bhatt, Aniket Rege, Matthew Wallingford, Aditya Sinha, Vivek Ramanujan, William Howard-Snyder, Kaifeng Chen, Sham Kakade, Prateek Jain, Advances in Neural Information Processing Systems. 202235</p>
<p>Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, arXiv:2308.03281Towards general text embeddings with multi-stage contrastive learning. 2023arXiv preprint</p>
<p>ROUGE: A package for automatic evaluation of summaries. Chin-Yew Lin, Text Summarization Branches Out. Barcelona, SpainAssociation for Computational Linguistics2004</p>
<p>Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, Guannan Zhang, arXiv:2311.08719Think-in-memory: Recalling and post-thinking enable llms with long-term memory. 2023Preprint</p>
<p>Towards emotional support dialog systems. Siyang Liu, Chujie Zheng, Orianna Demasi, Sahand Sabour, Yu Li, Zhou Yu, Yong Jiang, Minlie Huang, Proceedings of the 59th Annual Meeting of the Association for memoryforconv Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for memoryforconv Linguistics and the 11th International Joint Conference on Natural Language Processing20211</p>
<p>The ability model of emotional intelligence: Principles and updates. David R John D Mayer, Peter Caruso, Salovey, Emotion review. 842016</p>
<p>Memory for conversation and the development of common ground. Geoffrey L Mckinley, Sarah Brown-Schmidt, Aaron S Benjamin, Memory &amp; cognition. 452017</p>
<p>Loïc Magne, and Nils Reimers. Niklas Muennighoff, Nouamane Tazi, 10.48550/ARXIV.2210.07316arXiv:2210.07316Mteb: Massive text embedding benchmark. 2022arXiv preprint</p>
<p>Introducing chatgpt. 2022OpenAI</p>
<p>Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, G Shishir, Ion Patil, Joseph E Stoica, Gonzalez, arXiv:2310.08560Memgpt: Towards llms as operating systems. 2024Preprint</p>
<p>Bleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational Linguistics2002</p>
<p>Chapter 1 -a general psychoevolutionary theory of emotion. Plutchik Robert, 10.1016/B978-0-12-558701-3.50007-7Theories of Emotion. Robert Plutchik, Henry Kellerman, Academic Press1980</p>
<p>Towards empathetic opendomain conversation models: A new benchmark and dataset. Eric Michael Hannah Rashkin, Margaret Smith, Y-Lan Li, Boureau, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019</p>
<p>Emobench: Evaluating the emotional intelligence of large language models. Sahand Sabour, Siyang Liu, Zheyuan Zhang, June M Liu, Jinfeng Zhou, Alvionna S Sunaryo, Juanzi Li, M C Tatia, Rada Lee, Minlie Mihalcea, Huang, arXiv:2402.120712024Preprint</p>
<p>Cem: Commonsense-aware empathetic response generation. Sahand Sabour, Chujie Zheng, Minlie Huang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Memory and common ground processes in language use. Brown-Schmidt Sarah, C Duff Melissa, Topics in cognitive science. 2016</p>
<p>Empathetic and emotionally positive conversation systems with an emotionspecific query-response memory. Zhiliang Tian, Yinliang Wang, Yiping Song, Chi Zhang, Dongkyu Lee, Yingxiu Zhao, Dongsheng Li, Nevin L Zhang, Findings of the Association for Computational Linguistics: EMNLP 2022. 2022</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Augmenting language models with long-term memory. Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, Furu Wei, arXiv:2306.071742023Preprint</p>
<p>An appreciation of generate-recognize theory of recall. J Michael, John M Watkins, Gardiner, 10.1016/S0022-5371(79)90397-9Journal of Verbal Learning and Verbal Behavior. 1861979</p>
<p>State-dependent effects of alcohol on explicit memory: the role of semantic associations. R Weissenborn, Duka, Psychopharmacology. 2000</p>
<p>. An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, arXiv:2407.10671PreprintZhifang Guo, and Zhihao Fan. 2024. Qwen2 technical report</p>
<p>Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, arXiv:2210.02414Glm-130b: An open bilingual pre-trained model. 2022arXiv preprint</p>
<p>Personalized llm response generation with parameterized memory injection. Kai Zhang, Lizhi Qing, Yangyang Kang, Xiaozhong Liu, arXiv:2404.035652024Preprint</p>
<p>Bertscore: Evaluating text generation with bert. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, International Conference on Learning Representations. </p>
<p>Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, arXiv:2305.10250Memorybank: Enhancing large language models with long-term memory. 2023Preprint</p>
<p>Emotional chatting machine: Emotional conversation generation with internal and external memory. Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, Bing Liu, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201832with python libraries 11 . Chinese are segmented using jieba 12 . Models BertScore Rouge-L BLEU-1/2</p>
<p>Setting 1(%) Doubao. 72.08 22.16 22.82/10.27 74.72/97.42</p>
<p>. 70.54 20.49 22.28/9.14 79.89/98.39 GPT4-Turbo 69.08 21.26 22.50/10.30 75.80/97.80Setting. 2</p>
<p>. 70.39 20.26 21.70/8.18 81.26/98.40 GPT4-Turbo 71.65 21.22 22.32/10.04 75.91/97.84Setting. 3</p>
<p>Automatic Evaluation Results in Chinese version. BLEU-1/2Models BertScore Rouge-L. 11Table</p>
<p>Setting 2(%). GPT4-Turbo 60.18 23.73 16.13/6.88 44.96/83.86</p>
<p>Setting 3(%) GPT4-Turbo. 58.83 22.69 14.77/5.68 43.87/82.21</p>
<p>; 当然可以啦！你可以试试画一些画，比如你和爷爷奶奶一起做饭的场 景，或者写写日记，记录下和他们在一起的快乐时光。这样，每当你想念他们的时 候，看看这些画作或日记，就好像他们就在你身边一样。还可以和他们视频聊天， 听听他们的声音，看看他们的笑容，感觉会好很多哦！你觉得这个主意怎么样？ Gpt4-Turbo, : 你可以想想和爷爷奶奶一起的快乐时光呀，就像一起种花、包饺子，还有 听他们讲故事。这样想的话，就会感觉他们好像就在你身边呢。而且，你也可以给 爷爷奶奶打电话或者视频聊天，告诉他们你想他们了， Doubao, 这样也会让你感觉好一些 哦。 Qwen2, 72B: 当然啦，你可以试着写信给他们，或者画一幅画寄过去。记得那次爷 爷教你做红丝绒蛋糕吗？你可以再试试自己做一次，一边做一边想象爷爷就在旁边 指导你，奶奶在旁边给你加油。这样，就算他们不在身边，你也能感受到他们的爱 和陪伴哦。 GLM-4: 当然可以，Lisa。你可以尝试做一些你和爷爷奶奶一起做过的事情，比如 那次你们一起种花，那时候你很开心对吧？你可以再种一些花，想象着爷爷奶奶就 在你身边，教你怎样照顾它们。这样，你就能感觉到他们的陪伴了。还有，你也可 以尝试制作那个让你们感到无比开心的红丝绒蛋糕，回忆起爷爷教你的每一个步 骤，这样就好像他们在你身边一样。 Ziya-Character:当然真的，你可以想象和他们一起做你们最喜欢的事，比如一起包 饺子，这样就像真的在一起了哦。. </p>            </div>
        </div>

    </div>
</body>
</html>