<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2430 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2430</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2430</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-64.html">extraction-schema-64</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <p><strong>Paper ID:</strong> paper-5ddbc3904b3d21b3fc6218ba2358c7368491d1b6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/5ddbc3904b3d21b3fc6218ba2358c7368491d1b6" target="_blank">Toward an AI Physicist for Unsupervised Learning</a></p>
                <p><strong>Paper Venue:</strong> Physical Review E</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a paradigm centered around the learning and manipulation of theories, which parsimoniously predict both aspects of the future and the domain in which these predictions are accurate, and proposes a generalized mean loss to encourage each theory to specialize in its comparatively advantageous domain.</p>
                <p><strong>Paper Abstract:</strong> We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide and conquer, Occam's razor, unification, and lifelong learning. Instead of using one model to learn everything, we propose a paradigm centered around the learning and manipulation of theories, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. Specifically, we propose a generalized mean loss to encourage each theory to specialize in its comparatively advantageous domain, and a differentiable description length objective to downweight bad data and "snap" learned theories into simple symbolic formulas. Theories are stored in a "theory hub," which continuously unifies learned theories and can propose theories when encountering new environments. We test our implementation, the toy "artificial intelligence physicist" learning agent, on a suite of increasingly complex physics environments. From unsupervised observation of trajectories through worlds involving random combinations of gravity, electromagnetism, harmonic motion, and elastic bounces, our agent typically learns faster and produces mean-squared prediction errors about a billion times smaller than a standard feedforward neural net of comparable complexity, typically recovering integer and rational theory parameters exactly. Our agent successfully identifies domains with different laws of motion also for a nonlinear chaotic double pendulum in a piecewise constant force field.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2430.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2430.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI physicist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Artificial Intelligence Physicist (this paper's agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A composite unsupervised learning agent that discovers, represents, simplifies, unifies, and reuses small symbolic or neural 'theories' (rules/equations) for different domains by combining differentiable divide-and-conquer, a minimum-description-length Occam's-razor stage, unification, and lifelong learning (theory hub).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI physicist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The AI physicist automatically generates candidate scientific theories (hypotheses) by: (1) proposing initial theories from a stored theory hub (lifelong learning) and random initialization; (2) training multiple prediction modules jointly with a generalized-mean (harmonic, gamma=-1) loss to encourage each module to specialize on data subsets (differentiable divide-and-conquer, DDAC); (3) fine-tuning each module on its assigned domain; (4) applying an approximate MDL-based Occam's-razor pipeline that computes a description length L_d for model parameters and prediction errors, then performs transformations: collapsing linear layers, snapping parameters to integers and rationals (via continued fractions), and converting nets to symbolic expressions to reduce model-bit cost; (5) clustering symbolic theories by their description length and unifying similar formulas into parameterized master theories; (6) storing successful theories and their example data in a theory hub used to propose prior theories in new environments. The agent optimizes total description length L_d(T,D) = L_d(T) + sum_t L_d(u_t) (model bits + data/error bits), with numerical heuristics for integer/rational/real encoding and an annealed precision floor during training.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>general scientific discovery / physics (toy physics benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended unsupervised discovery of governing equations / incremental theory-building (specialization, simplification, unification)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Minimum Description Length (MDL) proxy: model description bits L_d(T) (sum of bits for numeric parameters using formulas: L_d(integer)=log2(1+|m|), L_d(rational)=log2[(1+|m|) n], L_d(real)=log_+(r/ε) with log_+(x)=0.5 log2(1+x^2)); novelty (preference for simpler/new hypotheses) operationalized as lower model-bit cost. Clustering for unification uses the description length dl^i of symbolic prediction functions as clustering feature.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Reported example model description lengths: baseline model L_d(f) ≈ 11338.7 bits; newborn and AI physicist after MDL snapping L_d(f) ≈ 198.9 bits (median over 40 mystery worlds). Specific snap example: replacing a fitted parameter by rational 53/17 reduced total (model+data) description length by ≈16 bits in Fig. 3. (No explicit 'novelty' scalar beyond these L_d values.)</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Fit/error description bits: sum_t L_d(u_t) (prediction-error bits) and conventional MSE (used both in training annealing and reporting). During training DDAC uses ℓ = sum L_d(u) in harmonic loss; feasibility also operationalized as ability to predict (MSE) and fraction of domains 'solved' under exactness criteria (rational coefficients exact, irrational <1e-4).</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td>Median predictive performance reported: log10(MSE) ≈ -13.88 for the AI physicist using full data (median over 40 worlds), i.e., MSE ≈ 1.3e-14. Corresponding median sum of data bits reported example: ∑_t L_d(u_t) values shown in example: 2519.6 (after snapping) for one domain; overall description-length sums reported per-domain in examples and tables.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Explicit formulation of the model: total DL = L_d(T) + ∑_t L_d(u_t) encodes the trade-off between model simplicity (model bits) and explanatory accuracy (data/error bits). The paper shows examples where snapping a parameter to a simple rational reduces model bits but increases data bits; Fig. 2 and Fig. 3 visualize and quantify these trade-offs (e.g., a successful rational snap reduced model+data bits by ≈16 bits). The text states that ∑_i L_d(u_i) decreases by 1 bit when a single prediction error is halved, quantifying sensitivity of the data-bit term.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Multi-term MDL minimization: a two-stage practical pipeline — (A) gradient-based DDAC minimizing harmonic mean loss with ℓ = ∑ L_d(u) (annealing precision floor from MSE-like to DL loss) to get specialized predictors and domain classifiers; (B) discrete/symbolic MDL optimization (collapse layers, integer/rational snapping via continued fractions, symbolic conversion) that accepts transformations only if total DL decreases; unification/clustering (by description length) to create parameterized master theories; lifelong hub proposes previously stored theories in new tasks. Add/delete theory heuristics based on domain coverage and loss thresholds are used to adapt model count.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>A single large feedforward neural network baseline (leakyReLU) and a 'newborn' AI physicist with no prior theory hub experience.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>AI physicist vs baseline (median over 40 mystery worlds): median log10 MSE baseline = -3.89 vs AI physicist = -13.88 (≈10^10 fold MSE reduction); baseline classification accuracy ≈ 67.6% vs AI physicist = 100%; fraction of worlds solved: baseline 0.0% vs AI physicist 92.5%; model description length L_d(f) median baseline ≈ 11338.7 bits vs AI physicist ≈ 198.9 bits. The lifelong-hub-enabled AI physicist learned faster (e.g., epochs to reach 1e-2 MSE: baseline 95, newborn 83, AI physicist 15 median).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>On the toy physics domains, MDL-simplified theories generalized and unified well; however, for highly nonlinear/chaotic domains (double pendulum) simplification and unification were harder, reducing benefits — illustrating that simpler theories are more likely to unify and transfer, while very complex fitted predictors resist simplification and hence generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2430.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MDL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Minimum Description Length (MDL) formalism</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formalization of Occam's razor that defines the best explanation as the one minimizing total description length (bits to encode model plus bits to encode residuals/data given the model); used here as the central metric to prefer simpler, generalizable theories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Minimum Description Length (MDL) approximation used in AI physicist</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper uses an approximate MDL encoding to score models: L_d(T,D)=L_d(T)+∑_t L_d(u_t), with pragmatic encoding rules for integers L_d(m)=log2(1+|m|), rationals L_d(m/n)=log2[(1+|m|) n], and reals L_d(r)=log_+(r/ε) where log_+(x)=0.5 log2(1+x^2). MDL is used both during training (as the per-example loss ℓ = ∑ L_d(u)) and as a post-training simplification criterion (snap to integer/rational/symbolic only if total DL decreases).</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>model selection / scientific discovery / machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>model selection and hypothesis simplification / parsimony-driven discovery</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Model-bit cost L_d(T) (lower bits → preferred/simpler hypotheses).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Data-bit cost ∑_t L_d(u_t) and conventional error metrics (MSE) — feasibility operationalized as predictive accuracy or low residual bits.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>MDL explicitly trades off model complexity (model bits) and fit (data bits) via additive total DL; paper provides numeric examples (see AI physicist entry) and visualizations (Figs. 2–3) illustrating trade-offs and identification of compressible rational approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Minimize total DL by alternating continuous optimization (gradient descent on harmonic DL loss with annealing) and discrete/symbolic moves (integer/rational snapping and symbolic conversion) accepted only when DL decreases.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2430.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DDAC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Divide-And-Conquer (DDAC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An algorithm that jointly trains multiple prediction modules and a domain classifier using a generalized-mean loss (harmonic loss with γ = -1) to encourage different modules to specialize on different data domains, thereby proposing specialized hypotheses automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Differentiable Divide-and-Conquer (DDAC)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DDAC initializes multiple theories (prediction functions and domain subclassifiers), then minimizes the generalized-mean loss L_γ (implemented with γ = -1 harmonic mean) using ℓ = ∑ L_d(u) as per-example loss. Theorem 1 shows that with γ<0, gradients are larger for better-performing modules, encouraging specialization. DDAC includes an annealed precision floor so training begins MSE-like and gradually tightens to DL-based loss; it has subroutines to add or delete theories based on coverage and residual thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>unsupervised learning / automated theory induction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended domain discovery and specialized-hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Model feasibility judged by predictive error (ℓ = ∑ L_d(u) / MSE) and domain coverage thresholds used in add/delete heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>DDAC uses the harmonic mean of per-theory losses which implicitly shifts emphasis to theories that already perform well on subsets of data, encouraging specialization which can reduce total DL when combined with MDL snapping; no explicit statistical correlation numbers reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Gradient-based joint training with generalized-mean loss (γ=-1) plus heuristic procedures to add/split/delete theories based on coverage and residual thresholds, followed by MDL-based snapping.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Compared experimentally to a single large feedforward neural net baseline and to a 'newborn' agent (same DDAC but without prior theory hub).</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>DDAC as part of the AI physicist pipeline produced orders-of-magnitude smaller MSE and enabled automated domain discovery where the baseline failed; specific performance appears in AI physicist comparative results (see that entry).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2430.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Unification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unification (clustering + parameterization of symbolic formulas)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A post-processing method that clusters discovered symbolic theories (using their description-lengths) and creates master parameterized theories by introducing parameters where coefficients vary across cluster members, thereby generating continuum hypotheses that generalize across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Unification (MDL-clustering and parameterization)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The algorithm computes a description length dl^(i) for each discovered symbolic prediction function, clusters functions by dl values (e.g., k-means), canonicalizes expression trees, identifies the dominant structural form in each cluster, and traverses corresponding trees to replace differing numeric coefficients with parameters p_j to produce a parameterized master theory f_p; identical master forms are merged. This yields new hypothesis families that explain multiple observed environments.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>automated theory formation / symbolic model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>synthesis and generalization of discovered local hypotheses into broader, parameterized master hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Uses per-theory description length dl^(i) as clustering and selection feature (preferring compact symbolic forms).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Feasibility implicitly measured by how well member theories fit their domain (their per-theory DL and data bits) and by whether a parameterized master can reproduce them; no explicit numeric feasibility metric reported beyond DL and fit.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td>Unification is used to consolidate many local hypotheses into simpler parameterized families, effectively reducing model-bit complexity when successful; the paper reports qualitative success (e.g., discovering a gravity master theory) but provides no numeric tradeoff statistics specific to unification.</td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Cluster by description length, canonicalize tree forms, and replace varying coefficients by parameters — accept master theories that compactly represent multiple discovered theories.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2430.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bacon</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BACON (Langley's system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early computational scientific discovery system (historically important) that induced physical laws from observations and used divide-and-conquer-like strategies; cited as related prior work on automated scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BACON (historical scientific-discovery system)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as prior work in computational scientific discovery that induced physical laws from observations and used divide-and-conquer strategies; cited to place the AI physicist in context of earlier automated hypothesis-discovery research.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>computational scientific discovery / automated hypothesis formation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>induction of scientific laws from data</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2430.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sir Isaac</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sir Isaac (automated adaptive inference agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously published automated adaptive inference system for discovering dynamical models from data (cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sir Isaac (automated adaptive inference agent)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as a prior automated inference agent that learns adaptive dynamical models; presented as complementary to AI physicist approaches that learn one big model, whereas the AI physicist emphasizes many small modular theories and intelligibility.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>dynamical-system inference / model discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>automated inference of dynamical equations</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2430.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2430.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression / automated equation discovery (e.g., Schmidt & Lipson)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of methods that search symbolic expression space (via evolutionary/genetic search, sparse regression, or other techniques) to find closed-form formulas that fit data; cited as complementary and relevant to the Occam's-razor and toSymbolic steps in AI physicist.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Symbolic regression (genetic/evolutionary / sparse methods)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Mentioned as related prior work on automatic program/formula induction and scientific-discovery tools (e.g., genetic programming, symbolic regression) that can discover differential equations or closed-form laws from data; authors note such techniques could be used to enhance the Occam's-razor/simplification toolkit.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>automated discovery of symbolic laws / scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>search for closed-form governing equations from time series or observational data</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward an AI Physicist for Unsupervised Learning', 'publication_date_yy_mm': '2018-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2430",
    "paper_id": "paper-5ddbc3904b3d21b3fc6218ba2358c7368491d1b6",
    "extraction_schema_id": "extraction-schema-64",
    "extracted_data": [
        {
            "name_short": "AI physicist",
            "name_full": "Artificial Intelligence Physicist (this paper's agent)",
            "brief_description": "A composite unsupervised learning agent that discovers, represents, simplifies, unifies, and reuses small symbolic or neural 'theories' (rules/equations) for different domains by combining differentiable divide-and-conquer, a minimum-description-length Occam's-razor stage, unification, and lifelong learning (theory hub).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AI physicist",
            "system_description": "The AI physicist automatically generates candidate scientific theories (hypotheses) by: (1) proposing initial theories from a stored theory hub (lifelong learning) and random initialization; (2) training multiple prediction modules jointly with a generalized-mean (harmonic, gamma=-1) loss to encourage each module to specialize on data subsets (differentiable divide-and-conquer, DDAC); (3) fine-tuning each module on its assigned domain; (4) applying an approximate MDL-based Occam's-razor pipeline that computes a description length L_d for model parameters and prediction errors, then performs transformations: collapsing linear layers, snapping parameters to integers and rationals (via continued fractions), and converting nets to symbolic expressions to reduce model-bit cost; (5) clustering symbolic theories by their description length and unifying similar formulas into parameterized master theories; (6) storing successful theories and their example data in a theory hub used to propose prior theories in new environments. The agent optimizes total description length L_d(T,D) = L_d(T) + sum_t L_d(u_t) (model bits + data/error bits), with numerical heuristics for integer/rational/real encoding and an annealed precision floor during training.",
            "research_domain": "general scientific discovery / physics (toy physics benchmarks)",
            "problem_type": "open-ended unsupervised discovery of governing equations / incremental theory-building (specialization, simplification, unification)",
            "novelty_metric": "Minimum Description Length (MDL) proxy: model description bits L_d(T) (sum of bits for numeric parameters using formulas: L_d(integer)=log2(1+|m|), L_d(rational)=log2[(1+|m|) n], L_d(real)=log_+(r/ε) with log_+(x)=0.5 log2(1+x^2)); novelty (preference for simpler/new hypotheses) operationalized as lower model-bit cost. Clustering for unification uses the description length dl^i of symbolic prediction functions as clustering feature.",
            "novelty_score": "Reported example model description lengths: baseline model L_d(f) ≈ 11338.7 bits; newborn and AI physicist after MDL snapping L_d(f) ≈ 198.9 bits (median over 40 mystery worlds). Specific snap example: replacing a fitted parameter by rational 53/17 reduced total (model+data) description length by ≈16 bits in Fig. 3. (No explicit 'novelty' scalar beyond these L_d values.)",
            "feasibility_metric": "Fit/error description bits: sum_t L_d(u_t) (prediction-error bits) and conventional MSE (used both in training annealing and reporting). During training DDAC uses ℓ = sum L_d(u) in harmonic loss; feasibility also operationalized as ability to predict (MSE) and fraction of domains 'solved' under exactness criteria (rational coefficients exact, irrational &lt;1e-4).",
            "feasibility_score": "Median predictive performance reported: log10(MSE) ≈ -13.88 for the AI physicist using full data (median over 40 worlds), i.e., MSE ≈ 1.3e-14. Corresponding median sum of data bits reported example: ∑_t L_d(u_t) values shown in example: 2519.6 (after snapping) for one domain; overall description-length sums reported per-domain in examples and tables.",
            "tradeoff_evidence": "Explicit formulation of the model: total DL = L_d(T) + ∑_t L_d(u_t) encodes the trade-off between model simplicity (model bits) and explanatory accuracy (data/error bits). The paper shows examples where snapping a parameter to a simple rational reduces model bits but increases data bits; Fig. 2 and Fig. 3 visualize and quantify these trade-offs (e.g., a successful rational snap reduced model+data bits by ≈16 bits). The text states that ∑_i L_d(u_i) decreases by 1 bit when a single prediction error is halved, quantifying sensitivity of the data-bit term.",
            "optimization_strategy": "Multi-term MDL minimization: a two-stage practical pipeline — (A) gradient-based DDAC minimizing harmonic mean loss with ℓ = ∑ L_d(u) (annealing precision floor from MSE-like to DL loss) to get specialized predictors and domain classifiers; (B) discrete/symbolic MDL optimization (collapse layers, integer/rational snapping via continued fractions, symbolic conversion) that accepts transformations only if total DL decreases; unification/clustering (by description length) to create parameterized master theories; lifelong hub proposes previously stored theories in new tasks. Add/delete theory heuristics based on domain coverage and loss thresholds are used to adapt model count.",
            "human_evaluation": false,
            "human_evaluation_results": null,
            "comparative_baseline": "A single large feedforward neural network baseline (leakyReLU) and a 'newborn' AI physicist with no prior theory hub experience.",
            "comparative_results": "AI physicist vs baseline (median over 40 mystery worlds): median log10 MSE baseline = -3.89 vs AI physicist = -13.88 (≈10^10 fold MSE reduction); baseline classification accuracy ≈ 67.6% vs AI physicist = 100%; fraction of worlds solved: baseline 0.0% vs AI physicist 92.5%; model description length L_d(f) median baseline ≈ 11338.7 bits vs AI physicist ≈ 198.9 bits. The lifelong-hub-enabled AI physicist learned faster (e.g., epochs to reach 1e-2 MSE: baseline 95, newborn 83, AI physicist 15 median).",
            "domain_specific_findings": "On the toy physics domains, MDL-simplified theories generalized and unified well; however, for highly nonlinear/chaotic domains (double pendulum) simplification and unification were harder, reducing benefits — illustrating that simpler theories are more likely to unify and transfer, while very complex fitted predictors resist simplification and hence generalization.",
            "uuid": "e2430.0",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "MDL",
            "name_full": "Minimum Description Length (MDL) formalism",
            "brief_description": "A formalization of Occam's razor that defines the best explanation as the one minimizing total description length (bits to encode model plus bits to encode residuals/data given the model); used here as the central metric to prefer simpler, generalizable theories.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Minimum Description Length (MDL) approximation used in AI physicist",
            "system_description": "The paper uses an approximate MDL encoding to score models: L_d(T,D)=L_d(T)+∑_t L_d(u_t), with pragmatic encoding rules for integers L_d(m)=log2(1+|m|), rationals L_d(m/n)=log2[(1+|m|) n], and reals L_d(r)=log_+(r/ε) where log_+(x)=0.5 log2(1+x^2). MDL is used both during training (as the per-example loss ℓ = ∑ L_d(u)) and as a post-training simplification criterion (snap to integer/rational/symbolic only if total DL decreases).",
            "research_domain": "model selection / scientific discovery / machine learning",
            "problem_type": "model selection and hypothesis simplification / parsimony-driven discovery",
            "novelty_metric": "Model-bit cost L_d(T) (lower bits → preferred/simpler hypotheses).",
            "novelty_score": null,
            "feasibility_metric": "Data-bit cost ∑_t L_d(u_t) and conventional error metrics (MSE) — feasibility operationalized as predictive accuracy or low residual bits.",
            "feasibility_score": null,
            "tradeoff_evidence": "MDL explicitly trades off model complexity (model bits) and fit (data bits) via additive total DL; paper provides numeric examples (see AI physicist entry) and visualizations (Figs. 2–3) illustrating trade-offs and identification of compressible rational approximations.",
            "optimization_strategy": "Minimize total DL by alternating continuous optimization (gradient descent on harmonic DL loss with annealing) and discrete/symbolic moves (integer/rational snapping and symbolic conversion) accepted only when DL decreases.",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2430.1",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "DDAC",
            "name_full": "Differentiable Divide-And-Conquer (DDAC)",
            "brief_description": "An algorithm that jointly trains multiple prediction modules and a domain classifier using a generalized-mean loss (harmonic loss with γ = -1) to encourage different modules to specialize on different data domains, thereby proposing specialized hypotheses automatically.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Differentiable Divide-and-Conquer (DDAC)",
            "system_description": "DDAC initializes multiple theories (prediction functions and domain subclassifiers), then minimizes the generalized-mean loss L_γ (implemented with γ = -1 harmonic mean) using ℓ = ∑ L_d(u) as per-example loss. Theorem 1 shows that with γ&lt;0, gradients are larger for better-performing modules, encouraging specialization. DDAC includes an annealed precision floor so training begins MSE-like and gradually tightens to DL-based loss; it has subroutines to add or delete theories based on coverage and residual thresholds.",
            "research_domain": "unsupervised learning / automated theory induction",
            "problem_type": "open-ended domain discovery and specialized-hypothesis generation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": "Model feasibility judged by predictive error (ℓ = ∑ L_d(u) / MSE) and domain coverage thresholds used in add/delete heuristics.",
            "feasibility_score": null,
            "tradeoff_evidence": "DDAC uses the harmonic mean of per-theory losses which implicitly shifts emphasis to theories that already perform well on subsets of data, encouraging specialization which can reduce total DL when combined with MDL snapping; no explicit statistical correlation numbers reported.",
            "optimization_strategy": "Gradient-based joint training with generalized-mean loss (γ=-1) plus heuristic procedures to add/split/delete theories based on coverage and residual thresholds, followed by MDL-based snapping.",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": "Compared experimentally to a single large feedforward neural net baseline and to a 'newborn' agent (same DDAC but without prior theory hub).",
            "comparative_results": "DDAC as part of the AI physicist pipeline produced orders-of-magnitude smaller MSE and enabled automated domain discovery where the baseline failed; specific performance appears in AI physicist comparative results (see that entry).",
            "domain_specific_findings": null,
            "uuid": "e2430.2",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "Unification",
            "name_full": "Unification (clustering + parameterization of symbolic formulas)",
            "brief_description": "A post-processing method that clusters discovered symbolic theories (using their description-lengths) and creates master parameterized theories by introducing parameters where coefficients vary across cluster members, thereby generating continuum hypotheses that generalize across environments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Unification (MDL-clustering and parameterization)",
            "system_description": "The algorithm computes a description length dl^(i) for each discovered symbolic prediction function, clusters functions by dl values (e.g., k-means), canonicalizes expression trees, identifies the dominant structural form in each cluster, and traverses corresponding trees to replace differing numeric coefficients with parameters p_j to produce a parameterized master theory f_p; identical master forms are merged. This yields new hypothesis families that explain multiple observed environments.",
            "research_domain": "automated theory formation / symbolic model discovery",
            "problem_type": "synthesis and generalization of discovered local hypotheses into broader, parameterized master hypotheses",
            "novelty_metric": "Uses per-theory description length dl^(i) as clustering and selection feature (preferring compact symbolic forms).",
            "novelty_score": null,
            "feasibility_metric": "Feasibility implicitly measured by how well member theories fit their domain (their per-theory DL and data bits) and by whether a parameterized master can reproduce them; no explicit numeric feasibility metric reported beyond DL and fit.",
            "feasibility_score": null,
            "tradeoff_evidence": "Unification is used to consolidate many local hypotheses into simpler parameterized families, effectively reducing model-bit complexity when successful; the paper reports qualitative success (e.g., discovering a gravity master theory) but provides no numeric tradeoff statistics specific to unification.",
            "optimization_strategy": "Cluster by description length, canonicalize tree forms, and replace varying coefficients by parameters — accept master theories that compactly represent multiple discovered theories.",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2430.3",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "Bacon",
            "name_full": "BACON (Langley's system)",
            "brief_description": "An early computational scientific discovery system (historically important) that induced physical laws from observations and used divide-and-conquer-like strategies; cited as related prior work on automated scientific discovery.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "BACON (historical scientific-discovery system)",
            "system_description": "Mentioned as prior work in computational scientific discovery that induced physical laws from observations and used divide-and-conquer strategies; cited to place the AI physicist in context of earlier automated hypothesis-discovery research.",
            "research_domain": "computational scientific discovery / automated hypothesis formation",
            "problem_type": "induction of scientific laws from data",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2430.4",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "Sir Isaac",
            "name_full": "Sir Isaac (automated adaptive inference agent)",
            "brief_description": "A previously published automated adaptive inference system for discovering dynamical models from data (cited as related work).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Sir Isaac (automated adaptive inference agent)",
            "system_description": "Cited as a prior automated inference agent that learns adaptive dynamical models; presented as complementary to AI physicist approaches that learn one big model, whereas the AI physicist emphasizes many small modular theories and intelligibility.",
            "research_domain": "dynamical-system inference / model discovery",
            "problem_type": "automated inference of dynamical equations",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2430.5",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        },
        {
            "name_short": "Symbolic regression",
            "name_full": "Symbolic regression / automated equation discovery (e.g., Schmidt & Lipson)",
            "brief_description": "A family of methods that search symbolic expression space (via evolutionary/genetic search, sparse regression, or other techniques) to find closed-form formulas that fit data; cited as complementary and relevant to the Occam's-razor and toSymbolic steps in AI physicist.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Symbolic regression (genetic/evolutionary / sparse methods)",
            "system_description": "Mentioned as related prior work on automatic program/formula induction and scientific-discovery tools (e.g., genetic programming, symbolic regression) that can discover differential equations or closed-form laws from data; authors note such techniques could be used to enhance the Occam's-razor/simplification toolkit.",
            "research_domain": "automated discovery of symbolic laws / scientific discovery",
            "problem_type": "search for closed-form governing equations from time series or observational data",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": null,
            "uuid": "e2430.6",
            "source_info": {
                "paper_title": "Toward an AI Physicist for Unsupervised Learning",
                "publication_date_yy_mm": "2018-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.021385750000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>MIT <br> Libraries</h1>
<h2>DSpace@MIT</h2>
<h2>MIT Open Access Articles</h2>
<h2>Toward an artificial intelligence physicist for unsupervised learning</h2>
<p>The MIT Faculty has made this article openly available. Please share how this access benefits you. Your story matters.</p>
<p>As Published: 10.1103/PHYSREVE.100.033311
Publisher: American Physical Society (APS)
Persistent URL: https://hdl.handle.net/1721.1/136247
Version: Final published version: final published article, as it appeared in a journal, conference proceedings, or other formally published context</p>
<p>Terms of Use: Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use.</p>
<h1>Toward an artificial intelligence physicist for unsupervised learning</h1>
<p>Tailin $\mathrm{Wu}^{*}$ and Max Tegmark<br>Department of Physics and Center for Brains, Minds, and Machines, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA<br>and Theiss Research, La Jolla, California 92037, USA</p>
<p>(Received 20 April 2019; published 19 September 2019)</p>
<h4>Abstract</h4>
<p>We investigate opportunities and challenges for improving unsupervised machine learning using four common strategies with a long history in physics: divide and conquer, Occam's razor, unification, and lifelong learning. Instead of using one model to learn everything, we propose a paradigm centered around the learning and manipulation of theories, which parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate. Specifically, we propose a generalized mean loss to encourage each theory to specialize in its comparatively advantageous domain, and a differentiable description length objective to downweight bad data and "snap" learned theories into simple symbolic formulas. Theories are stored in a "theory hub," which continuously unifies learned theories and can propose theories when encountering new environments. We test our implementation, the toy "artificial intelligence physicist" learning agent, on a suite of increasingly complex physics environments. From unsupervised observation of trajectories through worlds involving random combinations of gravity, electromagnetism, harmonic motion, and elastic bounces, our agent typically learns faster and produces mean-squared prediction errors about a billion times smaller than a standard feedforward neural net of comparable complexity, typically recovering integer and rational theory parameters exactly. Our agent successfully identifies domains with different laws of motion also for a nonlinear chaotic double pendulum in a piecewise constant force field.</p>
<p>DOI: 10.1103/PhysRevE.100.033311</p>
<h2>I. INTRODUCTION</h2>
<h2>A. Motivation</h2>
<p>The ability to predict, analyze, and parsimoniously model observations is not only central to physics, but also a goal of unsupervised machine learning, which is a key frontier in artificial intelligence (AI) research [1]. Despite impressive recent progress with artificial neural nets, they still get frequently outmatched by human researchers at such modeling, suffering from two drawbacks:
(1) Different parts of the data are often generated by different mechanisms in different contexts. A big model that tries to fit all the data in one environment may therefore underperform in a new environment where some mechanisms are replaced by new ones, being inflexible and inefficient at combinatorial generalization [2].
(2) Big models are generally hard to interpret, and may not reveal succinct and universal knowledge such as Newton's law of gravitation that explains only some aspects of the data. The pursuit of "intelligible intelligence" in place of inscrutable black-box neural nets is important and timely, given the growing interest in AI interpretability from AI users and policymakers, especially for AI components involved in decisions and infrastructure where trust is important [3-6].</p>
<p>To address these challenges, we will borrow from physics the core idea of a theory, which parsimoniously predicts both aspects of the future (from past observations) and also the domain in which these predictions are accurate. This suggests</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>an alternative to the standard machine-learning paradigm of fitting a single big model to all the data: instead, learning small theories one by one, and gradually accumulating and organizing them. This paradigm suggests the four specific approaches summarized in Table 1, which we combine into a toy "AI physicist" learning agent: To find individual theories from complex observations, we use the divide-and-conquer strategy with multiple theories and a generalized mean loss that encourages each theory to specialize in its own domain by giving larger gradients for better-performing theories. To find simple theories that avoid overfitting and generalize well, we use the strategy known as Occam's razor, favoring simple theories that explain a lot, using a computationally efficient approximation of the minimum-description-length (MDL) formalism. To unify similar theories found in different environments, we use the description length for clustering and then learn a "master theory" for each class of theories. To accelerate future learning, we use a lifelong learning strategy where learned theories are stored in a theory hub for future use.</p>
<h2>B. Goals and relation to prior work</h2>
<p>The goal of the AI physicist learning agent presented in this paper is quite limited, and does not even remotely approach the ambition level of problem solving by human physicists. The latter is likely to be almost as challenging as artificial general intelligence, which most AI researchers guess remains decades away $[7,8]$. Rather, the goal of this paper is to take a very modest but useful step in that direction, combining the four physics-inspired strategies above.</p>
<p>TABLE I. AI physicist strategies tested.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Strategy</th>
<th style="text-align: left;">Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Divide and <br> conquer</td>
<td style="text-align: left;">Learn multiple theories each of which specializes <br> to fit part of the data very well</td>
</tr>
<tr>
<td style="text-align: left;">Occam's <br> razor</td>
<td style="text-align: left;">Avoid overfitting by minimizing description <br> length, which can include replacing fitted <br> constants by simple integers or fractions</td>
</tr>
<tr>
<td style="text-align: left;">Unification</td>
<td style="text-align: left;">Try unifying learned theories by <br> introducing parameters</td>
</tr>
<tr>
<td style="text-align: left;">Lifelong <br> learning</td>
<td style="text-align: left;">Remember learned solutions and try <br> them on future problems</td>
</tr>
</tbody>
</table>
<p>Our approach complements other work on automatic program learning, such as neural program synthesis or induction [9-14] and symbolic program induction [15-19], and builds on prior machine-learning work on divide and conquer [20-22], network simplification [23-28], and continuous learning [29-32]. It is often said that babies are born scientists, and there is arguably evidence for use of all of these four strategies during childhood development as well [14].</p>
<p>There has been significant recent progress on AI approaches specifically linked to physics, including physical scene understanding [33], latent physical properties [34-36], learning physics simulators [37], physical concept discovery [38], an intuitive physics engine [39], and the "Sir Isaac" automated adaptive inference agent [40]. Our AI physicist is different and complementary in two fundamental ways that loosely correspond to the two motivations on the first page:
(1) All of these papers learn one big model to fit all the data. In contrast, the AI physicist learns many small models applicable in different domains, using the divide-and-conquer strategy.
(2) Our primary focus is not on making approximate predictions or discovering latent variables, but on near-exact predictions and complete intelligibility. From the former perspective, it is typically irrelevant if a model parameter changes by a tiny amount, but from a physics perspective, one is quite interested to learn that gravity weakens like distance to the power 2 rather than 1.99999314 .</p>
<p>We share this focus on intelligibility with a long tradition of research on computational scientific discovery [41], including the Bacon system [42] and its successors [43], which induced physical laws from observations and which also used a divide-and-conquer strategy. Other work has extended this paradigm to support discovery of differential equation models from multivariate time series [44-47].</p>
<p>The rest of this paper is organized as follows. In Sec. II, we introduce the architecture of our AI physicist learning agent, and the algorithms implementing the four strategies. We present the results of our numerical experiments using a suite of physics environment benchmarks in Sec. III, and discuss our conclusions in Sec. IV, delegating supplementary technical details to a series of Appendices.</p>
<h2>II. METHODS</h2>
<p>Unsupervised learning of regularities in time series can be viewed as a supervised learning problem of predicting the future from the past. This paper focuses on the task of</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>FIG. 1. AI physicist architecture.
predicting the next state vector $\mathbf{y}<em t="t">{t} \in \mathbb{R}^{d}$ in a sequence from the concatenation $\mathbf{x}</em>}=\left(\mathbf{y<em t-1="t-1">{t-T}, \ldots, \mathbf{y}</em>$ from examples. In the following we first define theory, then introduce a unified AI physicist architecture implementing the four aforementioned strategies.}\right)$ of the last $T$ vectors. However, our AI physicist formalism applies more generally to learning any function $\mathbb{R}^{M} \mapsto \mathbb{R}^{N</p>
<h2>A. Definition of theory</h2>
<p>A theory $\mathcal{T}$ is a 2-tuple $(\mathbf{f}, c)$, where $\mathbf{f}$ is a prediction function that predicts $\mathbf{y}<em t="t">{t}$ when $\mathbf{x}</em>}$ is within the theory's domain, and $c$ is a domain subclassifier which takes $\mathbf{x<em t="t">{t}$ as input and outputs a logit of whether $\mathbf{x}</em>$ and $c$ can be implemented by a neural net or symbolic formula, and can be set to learnable during training and fixed during prediction or validation.}$ is inside this domain. When multiple theories are present, the subclassifier $c$ 's outputs are concatenated and fed into a softmax function, producing probabilities for which theory is applicable. Both $\mathbf{f</p>
<p>This definition draws inspirations from physics theories (conditional statements), such as "a ball not touching anything (condition) with vertical velocity and height $\left(v_{0}, h_{0}\right)$ will a time $t$ later have $\mathbf{y} \equiv(v, h)=\left(v_{0}-g t, h_{0}+v_{0} t-g t^{2} / 2\right)$ (prediction function)." For our AI physicist, theories constitute its "atoms" of learning, as well as the building blocks for higher-level manipulations.</p>
<h2>B. AI physicist architecture overview</h2>
<p>Figure 1 illustrates the architecture of the AI physicist learning agent. At the center is a theory hub which stores the learned and organized theories. When encountering a new environment, the agent first inspects the hub and proposes old theories that help account for parts of the data as well as randomly initialized new theories for the rest of the data. All these theories are trained via our divide-and-conquer strategy, first jointly with our generalized mean loss then separately to fine-tune each theory in its domain (Sec. II C). Successful</p>
<p>theories along with the corresponding data are added to the theory hub.</p>
<p>The theory hub has two organizing strategies: (1) Applying Occam's razor, it snaps the learned theories, in the form of neural nets, into simpler symbolic formulas (Sec. II D). (2) Applying unification, it clusters and unifies the symbolic theories into master theories (Sec. II E). The symbolic and master theories can be added back into the theory hub, improving theory proposals for new environments. The detailed AI physicist algorithm is presented in a series of appendices. It has polynomial time complexity, as detailed in Appendix F.</p>
<h2>C. Divide and conquer</h2>
<p>Conventionally, a function $\mathbf{f}$ mapping $\mathbf{x}<em t="t">{t} \mapsto \mathbf{y}</em>$ that is adjusted to minimize a loss (empirical risk)}$ is learned by parametrizing $\mathbf{f}$ by some parameter vector $\boldsymbol{\theta</p>
<p>$$
\mathcal{L} \equiv \sum_{t} \ell\left[\mathbf{f}\left(\mathbf{x}<em t="t">{t}\right), \mathbf{y}</em>\right]
$$</p>
<p>where $\ell$ is some non-negative distance function quantifying how far each prediction is from the target, typically satisfying $\ell(\mathbf{y}, \mathbf{y})=0$. In contrast, a physicist observing an unfamiliar environment does typically not try to predict everything with one model, instead starting with an easier question: is there any part or aspect of the world that can be described? For example, when Galileo famously tried to model the motion of swinging lamps in the Pisa cathedral, he completely ignored everything else, and made no attempts to simultaneously predict the behavior of sound waves, light rays, weather, or subatomic particles. In this spirit, we allow multiple competing theories $\mathcal{T}=\left{\mathcal{T}<em i="i">{i}\right}=\left{\left(\mathbf{f}</em>\right)\right}, i=1,2, \ldots, M$, to specialize in different domains, with a generalized mean loss}, c_{i</p>
<p>$$
\mathcal{L}<em t="t">{\gamma} \equiv \sum</em>}\left{\frac{1}{M} \sum_{i=1}^{M} \ell\left[\mathbf{f<em t="t">{i}\left(\mathbf{x}</em>
$$}\right), \mathbf{y}_{t}\right]^{T}\right}^{1 / \gamma</p>
<p>When $\gamma&lt;0$, the loss $\mathcal{L}<em i="i">{\gamma}$ will be dominated by whichever prediction function $\mathbf{f}</em>}$ fits each data point best. This dominance is controlled by $\gamma$, with $\mathcal{L<em i="i">{\gamma} \rightarrow \min </em>} \ell\left[\mathbf{f<em t="t">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em _gamma="\gamma">{t}\right]$ in the limit where $\gamma \rightarrow-\infty$. This means that the best way to minimize $\mathcal{L}</em>}$ is for each $\mathbf{f<em t="t">{i}$ to specialize by further improving its accuracy for the data points where it already outperforms the other theories. The following Theorem 1 formalizes the above intuition, stating that under mild conditions for the loss function $\ell(\cdot, \cdot)$, the generalized mean loss gives larger gradient with respect to the error $\left|\hat{\mathbf{y}}</em>\right|$ for theories that perform better, so that a gradient-descent loss minimization encourages specialization.}-\mathbf{y}_{t</p>
<p>Theorem 1. Let $\hat{\mathbf{y}}<em i="i">{t}^{(i)} \equiv \mathbf{f}</em>}\left(\mathbf{x<em t="t">{t}\right)$ denote the prediction of the target $\mathbf{y}</em>}$ by the function $\mathbf{f<em t="t">{i}, i=1,2, \ldots, M$. Suppose that $\gamma&lt;$ 0 and $\ell\left(\hat{\mathbf{y}}</em>}, \mathbf{y<em t="t">{t}\right)=\ell\left(\left|\hat{\mathbf{y}}</em>}-\mathbf{y<em 0="0">{t}\right|\right)$ for a monotonically increasing function $\ell(u)$ that vanishes on $\left[0, u</em>}\right]$ for some $u_{0} \geqslant 0$, with $\ell(u)^{\gamma}$ differentiable and strictly convex for $u&gt;u_{0}$. Then if $0&lt;\ell\left(\hat{\mathbf{y}<em t="t">{t}^{(i)}, \mathbf{y}</em>}\right)&lt;\ell\left(\hat{\mathbf{y}<em t="t">{t}^{(j)}, \mathbf{y}</em>\right)$, we have</p>
<p>$$
\left|\frac{\partial \mathcal{L}<em t="t">{\gamma}}{\partial u</em>}^{(i)}}\right|&gt;\left|\frac{\partial \mathcal{L<em t="t">{\gamma}}{\partial u</em>\right|
$$}^{(j)}</p>
<p>where $u_{t}^{(i)} \equiv\left|\hat{\mathbf{y}}<em t="t">{t}^{(i)}-\mathbf{y}</em>\right|$.</p>
<p>Appendix G gives the proof, and also shows that this theorem applies to mean-squared-error (MSE) loss $\ell(u)=$ $u^{2}$, mean-absolute-error loss $\ell(u)=|u|$, Huber loss, and our description-length loss from the next section.</p>
<p>We find empirically that the simple choice $\gamma=-1$ works quite well, striking a good balance between encouraging specialization for the best theory and also giving some gradient for theories that currently perform slightly worse. We term this choice $\mathcal{L}<em i="i">{-1}$ the "harmonic loss," because it corresponds to the harmonic mean of the losses for the different theories. Based on the harmonic loss, we propose an unsupervised differentiable divide-and-conquer (DDAC) algorithm (Algorithm 2 in Appendix B) that simultaneously learns prediction functions $\left{\mathbf{f}</em>\right}$ from observations.}\right}$ and corresponding domain classifiers $\left{c_{i</p>
<p>Our DDAC method's combination of multiple prediction modules into a single prediction is reminiscent of AdaBoost [48]. While AdaBoost gradually upweights those modules that best predict all the data, DDAC instead identifies complementary modules that each predict some part of the data best, and encourages these modules to simplify and improve by specializing on these respective parts.</p>
<h2>D. Occam's razor</h2>
<p>The principle of Occam's razor, that simpler explanations are better, is quite popular among physicists. This preference for parsimony helped dispense with phlogiston, aether, and other superfluous concepts.</p>
<p>Our method therefore incorporates the minimum-description-length (MDL) formalism [23,26], which provides an elegant mathematical implementation of Occam's razor. It is rooted in Solomonoff's theory of inference [49] and is linked to Hutter's AIXI approach to artificial general intelligence [50]. The description length $\left(L_{d}\right)$ of a data set $D$ is defined as the number of bits required to describe it. For example, if regularities are discovered that enable data compression, then the corresponding description length is defined as the number of bits of the program that produces $D$ as its output (including both the code bits and the compressed data bits). In our context of predicting a time series, this means that the description length is the number of bits required to describe the theories used plus the number of bits required to store all prediction errors. Finding the optimal data compression and hence computing the MDL is a famous hard problem that involves searching an exponentially large space, but any discovery reducing the description length is a step in the right direction, and provably avoids the overfitting problem that plagues many alternative machine-learning strategies $[23,26]$.</p>
<p>The end goal of the AI physicist is to discover theories $\mathcal{T}$ minimizing the total description length, given by</p>
<p>$$
L_{d}(\mathcal{T}, D)=L_{d}(\mathcal{T})+\sum_{t} L_{d}\left(\mathbf{u}_{t}\right)
$$</p>
<p>where $\mathbf{u}<em t="t">{t}=\hat{\mathbf{y}}</em>}-\mathbf{y<em d="d">{t}$ is the prediction error at time step $t$. By discovering simple theories that can each account for parts of the data very well, the AI physicist strives to make both $L</em>\right)$ small.}(\mathcal{T})$ and $\sum_{t} L_{d}\left(\mathbf{u}_{t</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>FIG. 2. The description length <em>Ld</em> is shown for real numbers <em>p</em> with ε = 2<sup>−14</sup> (rising curve) and for rational numbers (dots). Occam's razor favors lower <em>Ld</em>, and our MDL rational approximation of a real parameter <em>p</em> is the lowest point after taking these "model bits" specifying the approximate parameter and adding the "data bits" L required to specify the prediction error made. The two symmetric curves illustrate the simple example where L = log<sub>+</sub> (x−x<sub>0</sub>) for x<sub>0</sub> = 1.4995, ε = 2<sup>−14</sup> and 0.02, respectively.</p>
<p>Physics has enjoyed great success in its pursuit of simpler theories using rather vague definitions of simplicity. In this spirit, we choose to compute the description length <em>Ld</em> not exactly, but using an approximate heuristic that is numerically efficient, and significantly simpler than more precise versions such as [51], paying special attention to rational numbers since they appear in many physics theories. We compute <em>Ld</em> for both theories T and prediction errors <strong>u</strong><sub><em>r</em></sub> as the sum of the description length of all numbers that specify them, using the following conventions for <em>Ld</em> for integers, rational numbers, and real numbers. Our MDL implementation differs from popular machine-learning approaches whose goal is efficiency and generalizability [27,52,53] rather than intelligibility.</p>
<p>The number of binary digits required to specify a natural number <em>n</em> = 1, 2, 3, ... is approximately log<sub>2</sub> <em>n</em>, so we define <em>Ld</em>(<em>n</em>) ≡ log<sub>2</sub> <em>n</em> for natural numbers. For an integer <em>m</em>, we define</p>
<p>$$L_d(m) \equiv \log_2(1 + |m|).\tag{5}$$</p>
<p>For a rational number <em>q</em> = <em>m</em>/<em>n</em>, the description length is the sum of that for its integer numerator and (natural number) denominator, as illustrated in Fig. 2:</p>
<p>$$L_d\left(\frac{m}{n}\right) = \log_2[(1 + |m|)n].\tag{6}$$</p>
<p>For a real number <em>r</em> and a numerical precision floor ε, we define</p>
<p>$$L_d(r) = \log_+ \left(\frac{r}{\epsilon}\right),\tag{7}$$</p>
<p>where the function</p>
<p>$$\log_{+}(x) \equiv \frac{1}{2} \log_2(1 + x^2) \tag{8}$$</p>
<p>is plotted in Fig. 2. Since log<sub>+</sub>(<em>x</em>) ≈ log<sub>2</sub> <em>x</em> for <em>x</em> ≫ 1, <em>Ld</em>(<em>r</em>) is approximately the description length of the integer closest to <em>r</em>/ε. Since log<sub>+</sub>(<em>x</em>) ≳ <em>x</em><sup>2</sup> for <em>x</em> ≪ 1, <em>Ld</em>(<em>r</em>) simplifies to a quadratic (mean-squared-error) loss function below the numerical precision, which will prove useful below.<sup>1</sup></p>
<p>Note that as long as all prediction absolute errors |<em>u</em><sub><em>i</em></sub>| ≫ ε for some data set, minimizing the total description length ∑<sub><em>i</em></sub> <em>Ld</em>(<em>u</em><sub><em>i</em></sub>) instead of the MSE ∑<sub><em>i</em></sub> <em>u</em><sub><em>i</em></sub><sup>2</sup> corresponds to minimizing the geometric mean instead of the arithmetic mean of the squared errors, which encourages focusing more on improving already well-fitted points. ∑<sub><em>i</em></sub> <em>Ld</em>(<em>u</em><sub><em>i</em></sub>) drops by 1 bit whenever one prediction error is halved, which is can typically be achieved by fine-tuning the fit for many valid data points that are already well predicted while increasing <em>Ld</em> for bad or extraneous points at most marginally.</p>
<p>For numerical efficiency, our AI physicist minimizes the description length of Eq. (4) in two steps: (1) All model parameters are set to trainable real numbers, and the DDAC algorithm is applied to minimize the harmonic loss L−<sub>1</sub> with ℓ(<strong>u</strong>) ≡ ∑<sub><em>i</em></sub> <em>Ld</em>(<em>u</em><sub><em>i</em></sub>) using Eq. (7) and the annealing procedure for the precision floor described in Appendix B. (2) Some model parameters are replaced by rational numbers as described below, followed by reoptimization of the other parameters. The idea behind the second step is that if a physics experiment or neural net training produces a parameter <em>p</em> = 1.4999917, it would be natural to interpret this as a hint, and to check if <em>p</em> = 3/2 gives an equally acceptable fit to the data, reducing total <em>Ld</em>. We implement step 2 using continued fraction expansion as described in Appendix C and illustrated in Fig. 3.</p>
<h3>E. Unification</h3>
<p>Physicists aspire not only to find simple theories that explain aspects of the world accurately, but also to discover underlying similarities between theories and <em>unify</em> them. For example, when James Clerk Maxwell corrected and unified four key formulas describing electricity and magnetism into his eponymous equations (<em>d</em><strong>F</strong> = 0, <em>d</em><strong>F</strong> = <strong>J</strong> in differential form notation), he revealed the nature of light and enabled the era of wireless communication.</p>
<p>Here we make a humble attempt to automate part of this process. The goal of the unification is to output a master theory T = {|<strong>f</strong><sub><strong>p</strong></sub>, ·} such that varying the parameter vector <strong>p</strong> ∈ ℝ<sup><em>n</em></sup> can generate a continuum of theories (<strong>f</strong><sub><strong>p</strong></sub>, ·) including previously discovered ones. For example, Newton's law of gravitation can be viewed as a master theory unifying the gravitational force formulas around different planets by introducing a parameter <em>p</em> corresponding to planet mass. Einstein's special relativity can be viewed as a master theory unifying the approximate formulas for <em>v</em> ≪ <em>c</em> and <em>v</em> ≈ <em>c</em> motion.</p>
<p>We perform unification by first computing the description length dl<sup>1</sup> of the prediction function <strong>f</strong><sub><em>i</em></sub> (in symbolic form) for each theory <em>i</em> and performing clustering on {dl<sup><em>i</em></sup>}. Unification is then achieved by discovering similarities and variations between the symbolic formulas in each cluster, retaining the similar patterns, and introducing parameters in place of the parameters that vary as detailed in Appendix D.</p>
<p><sup>1</sup>Natural alternative definitions of log<sub>+</sub>(<em>x</em>) include log<sub>2</sub>(1 + |<em>x</em>|), log<sub>2</sub> max(1, |<em>x</em>|), (ln 2)−<sup>1</sup> sinh<sup>−1</sup> |<em>x</em>|, and (2 ln 2)−<sup>1</sup> sinh<sup>−1</sup>(<em>x</em><sup>2</sup>). Unless otherwise specified, we choose ε = 2<sup>−32</sup> in our experiments.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIG. 3. Illustration of our minimum-description-length (MDL) analysis of the parameter vector <strong>p</strong> = {<em>π</em>, √2, 3.43180632382353}. We approximate each real number <em>r</em> as a fraction <em>a</em><sub>k</sub>/<em>b</em><sub>k</sub> using the first <em>k</em> terms of its continued fraction expansion, and for each integer <em>k</em> = 1, . . . , we plot the number of "data bits" required to encode the prediction error <em>r</em> − <em>a</em><sub>k</sub>/<em>b</em><sub>k</sub> to 14 decimal places versus the number of "model bits" required to encode the rational approximation <em>a</em><sub>k</sub>/<em>b</em><sub>k</sub>, as described in the text. We then select the point with smallest bit sum (farthest down and left from the diagonal) as our first approximation candidate to test. Generic irrational numbers are incompressible; the total description length (model bits + data bits) is roughly independent of <em>k</em> as is seen for <em>π</em> and √2, corresponding to a line of slope −1 around which there are small random fluctuations. In contrast, the green (light gray) curve (bottom) is for a parameter that is anomalously close to a rational number, and the curve reveals this by the approximation 53/17 reducing the total description length (model+data bits) by about 16 bits.</p>
<h3><strong>F. Lifelong learning</strong></h3>
<p>Isaac Newton once said, "If I have seen further it is by standing on the shoulders of giants," emphasizing the utility of building on past discoveries. At a more basic level, our past experiences enable us humans to model new environments much faster than if we had to reacquire all our knowledge from scratch. We therefore embed a lifelong learning strategy into the architecture of the AI physicist. As shown in Fig. 1 and Algorithm 1, the theory hub stores successfully learned theories, organizes them with our Occam's razor and unification algorithms (reminiscent of what humans do while dreaming and reflecting), and when encountering new environments, uses its accumulated knowledge to propose new theories that can explain parts of the data. This both ensures that past experiences are not forgotten and enables faster learning in novel environments. The detailed algorithms for proposing and adding theories are in Appendix E.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>FIG. 4. In this sample mystery world, a ball moves through a harmonic potential (upper left quadrant), a gravitational field (lower left), and an electromagnetic field (lower right quadrant) and bounces elastically from four walls. The only input to the AI physicist is the sequence of dots (ball positions); the challenge is to learn all boundaries and laws of motion (predicting each position from the previous two). The color of each dot represents the domain into which it is classified by <strong>c</strong>, and its area represents the description length of the error with which its position is predicted (ε = 10<sup>−6</sup>) after the DDAC (differentiable divide-and-conquer) algorithm; the AI physicist tries to minimize the total area of all dots.</p>
<h3><strong>III. RESULTS OF NUMERICAL EXPERIMENTS</strong></h3>
<h4><strong>A. Physics environments</strong></h4>
<p>We test our algorithms on two suites of benchmarks, each with increasing complexity. In all cases, the goal is to predict the two-dimensional motion as accurately as possible. One suite involves chaotic and highly nonlinear motion of a charged double pendulum in two adjacent electric fields. The other suite involves balls affected by gravity, electromagnetic fields, springs, and bounce boundaries, as exemplified in Fig. 4. Within each spatial region, the force corresponds to a potential energy function <em>V</em> ∝ (<em>ax</em> + <em>by</em> + <em>c</em>)<sup><em>n</em></sup> for some constants <em>a</em>, <em>b</em>, <em>c</em>, where <em>n</em> = 0 (no force), <em>n</em> = 1 (uniform electric or gravitational field), <em>n</em> = 2 (spring obeying Hooke's law) or <em>n</em> = ∞ (ideal elastic bounce), and optionally involves also a uniform magnetic field. The environments are summarized in Table IV.</p>
<h4><strong>B. Numerical results</strong></h4>
<p>In the mystery world example of Fig. 4, after the DDAC algorithm 2 taking the sequence of coordinates as the only input, we see that the AI physicist has learned to simultaneously predict the future position of the ball from the previous</p>
<p>two, and classify without external supervision the observed inputs into four big physics domains. The predictions are seen to be more accurate deep inside the domains (tiny dots) than near boundaries (larger dots) where transitions and bounces create small domains with laws of motion that are harder to infer because of complexity and limited data. Because these small domains can be automatically inferred and eliminated once the large ones are known as described in Appendix H, all accuracy benchmarks quoted below refer to points in the large domains only.</p>
<p>After DDAC, the AI physicist performs Occam's razor with MDL (Algorithm 3) on the learned theories. As an example, it discovers that the motion deep inside the lower left quadrant obeys the difference equation parametrized by a learned 3-layer neural net, which after the first collapseLayer transformation simplifies to</p>
<p>$$
\hat{\mathbf{y}}<em t="t">{t}=\left(\begin{array}{ccc}
-0.99999994 &amp; 0.00000006 &amp; 1.99999990 &amp; -0.00000012 \
-0.00000004 &amp; -1.0000000 &amp; 0.00000004 &amp; 2.00000000
\end{array}\right) \mathbf{x}</em>
$$}+\binom{0.01088213}{-0.00776199</p>
<p>with $L_{d}(\mathbf{f})=212.7$ and $\sum_{t} L_{d}\left(\mathbf{u}_{t}\right)=2524.1$. The snapping stage thereafter simplifies this to</p>
<p>$$
\hat{\mathbf{y}}<em t="t">{t}=\left(\begin{array}{ccc}
-1 &amp; 0 &amp; 2 &amp; 0 \
0 &amp; -1 &amp; 0 &amp; 2
\end{array}\right) \mathbf{x}</em>
$$}+\binom{0.010882}{-0.007762</p>
<p>which has lower description length in both model bits $\left[L_{d}(\mathbf{f})=55.6\right]$ and data bits $\left[\sum_{t} L_{d}\left(\mathbf{u}_{t}\right)=2519.6\right]$ and gets transformed to the symbolic expressions</p>
<p>$$
\begin{aligned}
&amp; \hat{x}<em t_1="t+1">{t+2}=2 x</em>+0.010882 \
&amp; \hat{y}}-x_{t<em t_1="t+1">{t+2}=2 y</em>-0.007762
\end{aligned}
$$}-y_{t</p>
<p>where we have written the 2 D position vector $\mathbf{y}=(x, y)$ for brevity. During unification (Appendix D), the AI physicist discovers multiple clusters of theories based on the description length of each theory, where one cluster has $L_{d}$ ranging between 48.86 and 55.63 , which it unifies into a master theory $\mathbf{f}_{\mathbf{p}}$ with</p>
<p>$$
\begin{aligned}
&amp; \hat{x}<em t_1="t+1">{t+2}=2 x</em> \
&amp; \hat{y}}-x_{t}+p_{1<em t_1="t+1">{t+2}=2 y</em>
\end{aligned}
$$}-y_{t}+p_{2</p>
<p>effectively discovering a "gravity" master theory out of the different types of environments it encounters. If so desired, the difference equations (12) can be automatically generalized to the more familiar-looking differential equations</p>
<p>$$
\begin{aligned}
&amp; \ddot{x}=g_{x} \
&amp; \ddot{y}=g_{y}
\end{aligned}
$$</p>
<p>where $g_{i} \equiv p_{i}(\Delta t)^{2}$, and both the harmonic oscillator equation and Lorentz force law of electromagnetism can be analogously autoinferred from other master theories learned.</p>
<p>Many mystery domains in our test suite involve laws of motion whose parameters include both rational and irrational numbers. To count a domain as "solved" below, we use the very stringent requirement that any rational numbers (including integers) must be discovered exactly, while irrational numbers must be recovered with accuracy $10^{-4}$.</p>
<p>We apply our AI physicist to 40 mystery worlds in sequence (Appendix I). After this training, we apply it to a suite of 40 additional worlds to test how it learns different numbers of examples. The results, which Table II summarizes using the median over worlds, are shown in Tables III and IV. For comparison, we also show results for two simpler agents with similar parameter count: a "baseline" agent consisting of a three-layer feedforward MSE-minimizing leakyReLU
network and a "newborn" AI physicist that has not seen any past examples and therefore cannot benefit from the lifelong learning strategy.</p>
<p>We see that the newborn agent outperforms baseline on all the tabulated measures, and that the AI physicist does still better. Using all data, the newborn agent and AI physicist are able to predict with mean-squared prediction error below $10^{-13}$, more than nine orders of magnitude below baseline. Moreover, the newborn and AI physicist agents are able to simultaneously learn the domain classifiers with essentially perfect accuracy, without external supervision. Both agents are able to solve above $90 \%$ of all the 40 mystery worlds according to our stringent criteria.</p>
<p>The main advantage of the AI physicist over the newborn agent is seen to be its learning speed, attaining given accuracy levels faster, especially during the early stage of learning. Remarkably, for the subsequent 40 worlds, the AI physicist</p>
<p>TABLE II. Summary of numerical results, taking the median over 40 mystery environments from Table III (top part) and on 40 novel environments with varying fraction of random examples (bottom parts), where each world is run with 10 random initializations and taking the best performance. Accuracies refer to big regions only.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Benchmark</th>
<th style="text-align: center;">Baseline</th>
<th style="text-align: center;">Newborn</th>
<th style="text-align: center;">AI physicist</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$\log _{10}$ mean-squared error</td>
<td style="text-align: center;">-3.89</td>
<td style="text-align: center;">-13.95</td>
<td style="text-align: center;">-13.88</td>
</tr>
<tr>
<td style="text-align: left;">Classification accuracy</td>
<td style="text-align: center;">$67.56 \%$</td>
<td style="text-align: center;">$100.00 \%$</td>
<td style="text-align: center;">$100.00 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Fraction of worlds solved</td>
<td style="text-align: center;">$0.00 \%$</td>
<td style="text-align: center;">$90.00 \%$</td>
<td style="text-align: center;">$92.50 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Description length for $\mathbf{f}$</td>
<td style="text-align: center;">11338.7</td>
<td style="text-align: center;">198.9</td>
<td style="text-align: center;">198.9</td>
</tr>
<tr>
<td style="text-align: left;">Epochs until $10^{-2}$ MSE</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: left;">Epochs until $10^{-4}$ MSE</td>
<td style="text-align: center;">6925</td>
<td style="text-align: center;">330</td>
<td style="text-align: center;">45</td>
</tr>
<tr>
<td style="text-align: left;">Epochs until $10^{-6}$ MSE</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5403</td>
<td style="text-align: center;">3895</td>
</tr>
<tr>
<td style="text-align: left;">Epochs until $10^{-8}$ MSE</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6590</td>
<td style="text-align: center;">5100</td>
</tr>
<tr>
<td style="text-align: left;">$\log _{10}$ MSE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">using $100 \%$ of data</td>
<td style="text-align: center;">-3.78</td>
<td style="text-align: center;">-13.89</td>
<td style="text-align: center;">-13.89</td>
</tr>
<tr>
<td style="text-align: left;">using $50 \%$ of data</td>
<td style="text-align: center;">-3.84</td>
<td style="text-align: center;">-13.76</td>
<td style="text-align: center;">-13.81</td>
</tr>
<tr>
<td style="text-align: left;">using $10 \%$ of data</td>
<td style="text-align: center;">-3.16</td>
<td style="text-align: center;">-7.38</td>
<td style="text-align: center;">-10.54</td>
</tr>
<tr>
<td style="text-align: left;">using $5 \%$ of data</td>
<td style="text-align: center;">-3.06</td>
<td style="text-align: center;">-6.06</td>
<td style="text-align: center;">-6.20</td>
</tr>
<tr>
<td style="text-align: left;">using $1 \%$ of data</td>
<td style="text-align: center;">-2.46</td>
<td style="text-align: center;">-3.69</td>
<td style="text-align: center;">-3.95</td>
</tr>
<tr>
<td style="text-align: left;">Epochs until $10^{-2}$ MSE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">using $100 \%$ of data</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: left;">using $50 \%$ of data</td>
<td style="text-align: center;">190</td>
<td style="text-align: center;">152.5</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td style="text-align: left;">using $10 \%$ of data</td>
<td style="text-align: center;">195</td>
<td style="text-align: center;">162.5</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td style="text-align: left;">using $5 \%$ of data</td>
<td style="text-align: center;">205</td>
<td style="text-align: center;">165</td>
<td style="text-align: center;">30</td>
</tr>
<tr>
<td style="text-align: left;">using $1 \%$ of data</td>
<td style="text-align: center;">397.5</td>
<td style="text-align: center;">235</td>
<td style="text-align: center;">35</td>
</tr>
</tbody>
</table>
<p>TABLE III. Results for each of our first 40 mystery world benchmarks, as described in Appendix 11. Each number is the best out of ten trials with random initializations (using seeds $0,30,60,90,120,150,180,210,240,270$ ), and refers to big domains only. Based on the "unsolved domains" column, we count out of 40 worlds the percentage that baseline, newborn, and AI physicist completely solve (has unsolved domain of 0 ), which goes to the "fraction of worlds solved" row in Table II.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Regions</th>
<th style="text-align: center;">$\log _{10}$ MSE</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Classification accuracy</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Unsolved domains</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Description length</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">New- <br> born</td>
<td style="text-align: center;">AI <br> phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI <br> phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI <br> phys.</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">$-4.12$</td>
<td style="text-align: center;">$-14.07$</td>
<td style="text-align: center;">$-14.08$</td>
<td style="text-align: center;">72.88\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11310.4</td>
<td style="text-align: center;">59.4</td>
<td style="text-align: center;">73.5</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">$-4.21$</td>
<td style="text-align: center;">$-14.02$</td>
<td style="text-align: center;">$-14.04$</td>
<td style="text-align: center;">88.59\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11271.5</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">60.3</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">$-3.69$</td>
<td style="text-align: center;">$-14.03$</td>
<td style="text-align: center;">$-14.03$</td>
<td style="text-align: center;">67.65\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11364.2</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">41.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">$-4.18$</td>
<td style="text-align: center;">$-13.98$</td>
<td style="text-align: center;">$-13.98$</td>
<td style="text-align: center;">80.98\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11341.7</td>
<td style="text-align: center;">60.6</td>
<td style="text-align: center;">57.6</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">$-4.51$</td>
<td style="text-align: center;">$-14.06$</td>
<td style="text-align: center;">$-14.07$</td>
<td style="text-align: center;">87.66\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11289.3</td>
<td style="text-align: center;">5.2</td>
<td style="text-align: center;">59.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">$-3.77$</td>
<td style="text-align: center;">$-13.99$</td>
<td style="text-align: center;">$-13.94$</td>
<td style="text-align: center;">73.54\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11333.8</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">139.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">$-3.60$</td>
<td style="text-align: center;">$-14.05$</td>
<td style="text-align: center;">$-13.89$</td>
<td style="text-align: center;">66.92\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11337.4</td>
<td style="text-align: center;">173.0</td>
<td style="text-align: center;">172.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">$-3.77$</td>
<td style="text-align: center;">$-14.04$</td>
<td style="text-align: center;">$-13.95$</td>
<td style="text-align: center;">59.46\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11317.5</td>
<td style="text-align: center;">156.0</td>
<td style="text-align: center;">173.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">$-5.32$</td>
<td style="text-align: center;">$-10.48$</td>
<td style="text-align: center;">$-13.14$</td>
<td style="text-align: center;">80.29\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11219.5</td>
<td style="text-align: center;">91.6</td>
<td style="text-align: center;">90.5</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">$-3.64$</td>
<td style="text-align: center;">$-14.00$</td>
<td style="text-align: center;">$-13.89$</td>
<td style="text-align: center;">71.70\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11369.6</td>
<td style="text-align: center;">143.7</td>
<td style="text-align: center;">136.6</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">$-3.62$</td>
<td style="text-align: center;">$-13.95$</td>
<td style="text-align: center;">$-13.96$</td>
<td style="text-align: center;">82.77\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11397.5</td>
<td style="text-align: center;">142.8</td>
<td style="text-align: center;">284.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">$-4.13$</td>
<td style="text-align: center;">$-13.82$</td>
<td style="text-align: center;">$-13.67$</td>
<td style="text-align: center;">76.55\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11283.0</td>
<td style="text-align: center;">306.2</td>
<td style="text-align: center;">306.2</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">$-4.03$</td>
<td style="text-align: center;">$-13.45$</td>
<td style="text-align: center;">$-13.47$</td>
<td style="text-align: center;">74.56\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11388.1</td>
<td style="text-align: center;">305.9</td>
<td style="text-align: center;">307.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">$-4.31$</td>
<td style="text-align: center;">$-13.77$</td>
<td style="text-align: center;">$-13.62$</td>
<td style="text-align: center;">86.68\%</td>
<td style="text-align: center;">99.91\%</td>
<td style="text-align: center;">99.91\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11257.7</td>
<td style="text-align: center;">152.0</td>
<td style="text-align: center;">133.5</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">$-4.32$</td>
<td style="text-align: center;">$-14.00$</td>
<td style="text-align: center;">$-14.05$</td>
<td style="text-align: center;">84.55\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11258.9</td>
<td style="text-align: center;">303.7</td>
<td style="text-align: center;">303.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">$-3.45$</td>
<td style="text-align: center;">$-13.96$</td>
<td style="text-align: center;">$-13.95$</td>
<td style="text-align: center;">77.88\%</td>
<td style="text-align: center;">99.96\%</td>
<td style="text-align: center;">99.93\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11414.9</td>
<td style="text-align: center;">194.2</td>
<td style="text-align: center;">195.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">$-3.90$</td>
<td style="text-align: center;">$-13.96$</td>
<td style="text-align: center;">$-13.91$</td>
<td style="text-align: center;">71.13\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11340.0</td>
<td style="text-align: center;">199.0</td>
<td style="text-align: center;">199.0</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">$-4.12$</td>
<td style="text-align: center;">$-13.97$</td>
<td style="text-align: center;">$-13.90$</td>
<td style="text-align: center;">72.78\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11330.7</td>
<td style="text-align: center;">198.8</td>
<td style="text-align: center;">198.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">$-4.02$</td>
<td style="text-align: center;">$-14.07$</td>
<td style="text-align: center;">$-14.00$</td>
<td style="text-align: center;">77.92\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11323.5</td>
<td style="text-align: center;">197.8</td>
<td style="text-align: center;">197.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">$-4.83$</td>
<td style="text-align: center;">$-13.87$</td>
<td style="text-align: center;">$-13.86$</td>
<td style="text-align: center;">91.14\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11247.1</td>
<td style="text-align: center;">10.3</td>
<td style="text-align: center;">13.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">$-4.08$</td>
<td style="text-align: center;">$-14.03$</td>
<td style="text-align: center;">$-13.95$</td>
<td style="text-align: center;">60.08\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11269.0</td>
<td style="text-align: center;">191.8</td>
<td style="text-align: center;">191.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">$-4.31$</td>
<td style="text-align: center;">$-14.02$</td>
<td style="text-align: center;">$-13.66$</td>
<td style="text-align: center;">63.01\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11334.2</td>
<td style="text-align: center;">170.4</td>
<td style="text-align: center;">83.1</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">$-4.01$</td>
<td style="text-align: center;">$-14.01$</td>
<td style="text-align: center;">$-13.99$</td>
<td style="text-align: center;">67.48\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11351.0</td>
<td style="text-align: center;">168.7</td>
<td style="text-align: center;">198.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">$-3.64$</td>
<td style="text-align: center;">$-13.97$</td>
<td style="text-align: center;">$-13.88$</td>
<td style="text-align: center;">60.02\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">99.93\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11374.6</td>
<td style="text-align: center;">225.7</td>
<td style="text-align: center;">225.7</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">$-4.11$</td>
<td style="text-align: center;">$-7.42$</td>
<td style="text-align: center;">$-7.43$</td>
<td style="text-align: center;">51.63\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">11313.7</td>
<td style="text-align: center;">193.5</td>
<td style="text-align: center;">179.2</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">$-3.79$</td>
<td style="text-align: center;">$-13.93$</td>
<td style="text-align: center;">$-13.47$</td>
<td style="text-align: center;">57.89\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11334.0</td>
<td style="text-align: center;">323.9</td>
<td style="text-align: center;">346.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">$-4.18$</td>
<td style="text-align: center;">$-14.00$</td>
<td style="text-align: center;">$-14.00$</td>
<td style="text-align: center;">77.16\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">11301.0</td>
<td style="text-align: center;">277.9</td>
<td style="text-align: center;">96.2</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">$-3.38$</td>
<td style="text-align: center;">$-13.58$</td>
<td style="text-align: center;">$-13.87$</td>
<td style="text-align: center;">53.33\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">99.96\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11381.4</td>
<td style="text-align: center;">360.4</td>
<td style="text-align: center;">364.0</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">$-3.46$</td>
<td style="text-align: center;">$-13.87$</td>
<td style="text-align: center;">$-13.89$</td>
<td style="text-align: center;">49.08\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11370.1</td>
<td style="text-align: center;">354.0</td>
<td style="text-align: center;">350.4</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">$-3.54$</td>
<td style="text-align: center;">$-13.69$</td>
<td style="text-align: center;">$-13.83$</td>
<td style="text-align: center;">51.28\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11370.3</td>
<td style="text-align: center;">331.1</td>
<td style="text-align: center;">320.7</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">$-3.87$</td>
<td style="text-align: center;">$-13.82$</td>
<td style="text-align: center;">$-13.55$</td>
<td style="text-align: center;">67.27\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11404.0</td>
<td style="text-align: center;">267.1</td>
<td style="text-align: center;">275.4</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">$-3.69$</td>
<td style="text-align: center;">$-13.87$</td>
<td style="text-align: center;">$-10.93$</td>
<td style="text-align: center;">56.02\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">99.94\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11413.4</td>
<td style="text-align: center;">468.5</td>
<td style="text-align: center;">464.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">$-4.06$</td>
<td style="text-align: center;">$-13.39$</td>
<td style="text-align: center;">$-13.56$</td>
<td style="text-align: center;">70.87\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11340.0</td>
<td style="text-align: center;">452.3</td>
<td style="text-align: center;">452.3</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">$-3.46$</td>
<td style="text-align: center;">$-13.94$</td>
<td style="text-align: center;">$-10.51$</td>
<td style="text-align: center;">59.02\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">99.93\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11416.0</td>
<td style="text-align: center;">475.5</td>
<td style="text-align: center;">471.9</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">$-3.70$</td>
<td style="text-align: center;">$-13.75$</td>
<td style="text-align: center;">$-13.82$</td>
<td style="text-align: center;">61.67\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11354.9</td>
<td style="text-align: center;">466.8</td>
<td style="text-align: center;">466.8</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">$-3.76$</td>
<td style="text-align: center;">$-13.82$</td>
<td style="text-align: center;">$-9.48$</td>
<td style="text-align: center;">27.93\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">99.94\%</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11358.8</td>
<td style="text-align: center;">526.9</td>
<td style="text-align: center;">530.4</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">$-3.74$</td>
<td style="text-align: center;">$-13.00$</td>
<td style="text-align: center;">$-13.18$</td>
<td style="text-align: center;">40.80\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">11284.8</td>
<td style="text-align: center;">418.5</td>
<td style="text-align: center;">389.1</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">$-4.09$</td>
<td style="text-align: center;">$-13.97$</td>
<td style="text-align: center;">$-13.75$</td>
<td style="text-align: center;">35.69\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11297.4</td>
<td style="text-align: center;">504.6</td>
<td style="text-align: center;">504.6</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">$-3.63$</td>
<td style="text-align: center;">$-13.80$</td>
<td style="text-align: center;">$-9.99$</td>
<td style="text-align: center;">31.61\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">99.97\%</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11407.4</td>
<td style="text-align: center;">526.3</td>
<td style="text-align: center;">526.2</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">$-3.51$</td>
<td style="text-align: center;">$-6.37$</td>
<td style="text-align: center;">$-13.52$</td>
<td style="text-align: center;">32.97\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">11445.8</td>
<td style="text-align: center;">527.4</td>
<td style="text-align: center;">527.5</td>
</tr>
<tr>
<td style="text-align: center;">Median</td>
<td style="text-align: center;">$-3.89$</td>
<td style="text-align: center;">$-13.95$</td>
<td style="text-align: center;">$-13.88$</td>
<td style="text-align: center;">67.56\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">100.00\%</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">11338.7</td>
<td style="text-align: center;">198.9</td>
<td style="text-align: center;">198.9</td>
</tr>
<tr>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">$-3.94$</td>
<td style="text-align: center;">$-13.44$</td>
<td style="text-align: center;">$-13.29$</td>
<td style="text-align: center;">65.51\%</td>
<td style="text-align: center;">99.99\%</td>
<td style="text-align: center;">99.99\%</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">11337.9</td>
<td style="text-align: center;">253.7</td>
<td style="text-align: center;">252.9</td>
</tr>
</tbody>
</table>
<p>reaches 0.01 MSE within 35 epochs using as little as $1 \%$ of the data, performing almost as well as with $50 \%$ of the data much better than the newborn agent. This illustrates that the lifelong learning strategy enables the AI physicist to learn much faster in novel environments with less data. This is much like an experienced scientist can solve new problems way faster than a beginner by building on prior knowledge about similar problems.</p>
<p>Our double-pendulum mysteries (Appendix 12) are more challenging for all the agents, because the motion is more nonlinear and indeed chaotic. Although none of our double-pendulum mysteries get exactly solved according to our very stringent above-mentioned criterion, Fig. 5 illustrates that the newborn agent does a good job: it discovers the two domains and classifies points into them with an accuracy of $96.5 \%$. Overall, the newborn agent has a median best accuracy</p>
<p>TABLE IV. Same as previous table, but showing number of training epochs required to reach various MSE prediction accuracies. We record the metrics every 5 epochs, so all the epochs are multiples of 5 . Note that the AI physicist has superseded $10^{-2}$ MSE already by 0 epochs for some environments, showing that thanks to the lifelong learning strategy which proposes previously learned theories in novel environments, reasonably good predictions can sometimes be achieved even without gradient descent training.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Regions</th>
<th style="text-align: center;">Epochs to $10^{-2}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Epochs to $10^{-4}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Epochs to $10^{-6}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Epochs to $10^{-8}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI <br> phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI phys.</td>
<td style="text-align: center;">Base- <br> line</td>
<td style="text-align: center;">Newborn</td>
<td style="text-align: center;">AI phys.</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">8440</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4175</td>
<td style="text-align: center;">3625</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6315</td>
<td style="text-align: center;">4890</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">4680</td>
<td style="text-align: center;">190</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2900</td>
<td style="text-align: center;">4650</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2995</td>
<td style="text-align: center;">6500</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8205</td>
<td style="text-align: center;">3815</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">9620</td>
<td style="text-align: center;">6455</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">7495</td>
<td style="text-align: center;">140</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6735</td>
<td style="text-align: center;">1785</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8040</td>
<td style="text-align: center;">2860</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1770</td>
<td style="text-align: center;">295</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3740</td>
<td style="text-align: center;">3240</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7030</td>
<td style="text-align: center;">3460</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">145</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2725</td>
<td style="text-align: center;">4050</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2830</td>
<td style="text-align: center;">6145</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7965</td>
<td style="text-align: center;">1690</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">3400</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1805</td>
<td style="text-align: center;">3895</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1855</td>
<td style="text-align: center;">3900</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1285</td>
<td style="text-align: center;">460</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5390</td>
<td style="text-align: center;">1060</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7225</td>
<td style="text-align: center;">6385</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4380</td>
<td style="text-align: center;">3300</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4800</td>
<td style="text-align: center;">4035</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1190</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6305</td>
<td style="text-align: center;">3380</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6590</td>
<td style="text-align: center;">3435</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">125</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">6240</td>
<td style="text-align: center;">885</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7310</td>
<td style="text-align: center;">1865</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7565</td>
<td style="text-align: center;">1865</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">15260</td>
<td style="text-align: center;">600</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2430</td>
<td style="text-align: center;">1225</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2845</td>
<td style="text-align: center;">4435</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">145</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">6650</td>
<td style="text-align: center;">140</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3000</td>
<td style="text-align: center;">5205</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4530</td>
<td style="text-align: center;">8735</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">965</td>
<td style="text-align: center;">200</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4635</td>
<td style="text-align: center;">1970</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4690</td>
<td style="text-align: center;">2870</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">580</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5415</td>
<td style="text-align: center;">4150</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5445</td>
<td style="text-align: center;">4175</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">460</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2560</td>
<td style="text-align: center;">965</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2575</td>
<td style="text-align: center;">5760</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">140</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">11050</td>
<td style="text-align: center;">455</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1960</td>
<td style="text-align: center;">1150</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6295</td>
<td style="text-align: center;">4005</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">13315</td>
<td style="text-align: center;">325</td>
<td style="text-align: center;">175</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3970</td>
<td style="text-align: center;">1290</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4335</td>
<td style="text-align: center;">3560</td>
</tr>
<tr>
<td style="text-align: center;">Free + EM rational</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">1155</td>
<td style="text-align: center;">335</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3245</td>
<td style="text-align: center;">2130</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5115</td>
<td style="text-align: center;">5610</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">150</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">9085</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3870</td>
<td style="text-align: center;">6145</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5555</td>
<td style="text-align: center;">6185</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">145</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6915</td>
<td style="text-align: center;">140</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4525</td>
<td style="text-align: center;">3720</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">10275</td>
<td style="text-align: center;">4430</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">6925</td>
<td style="text-align: center;">155</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6665</td>
<td style="text-align: center;">6560</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8915</td>
<td style="text-align: center;">6845</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5790</td>
<td style="text-align: center;">10915</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">18450</td>
<td style="text-align: center;">13125</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">7970</td>
<td style="text-align: center;">190</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">13125</td>
<td style="text-align: center;">7045</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">$\infty$</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">575</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3215</td>
<td style="text-align: center;">5095</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3215</td>
<td style="text-align: center;">5100</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">125</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">5650</td>
<td style="text-align: center;">160</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6085</td>
<td style="text-align: center;">4720</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8025</td>
<td style="text-align: center;">4980</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">630</td>
<td style="text-align: center;">120</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4100</td>
<td style="text-align: center;">6250</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4100</td>
<td style="text-align: center;">6570</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5910</td>
<td style="text-align: center;">5815</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7295</td>
<td style="text-align: center;">6090</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1380</td>
<td style="text-align: center;">465</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">2390</td>
<td style="text-align: center;">11425</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7450</td>
<td style="text-align: center;">11510</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">600</td>
<td style="text-align: center;">150</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">3775</td>
<td style="text-align: center;">4525</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">4675</td>
<td style="text-align: center;">5070</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1245</td>
<td style="text-align: center;">200</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6225</td>
<td style="text-align: center;">2340</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6390</td>
<td style="text-align: center;">3180</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">16600</td>
<td style="text-align: center;">190</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6035</td>
<td style="text-align: center;">1515</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">10065</td>
<td style="text-align: center;">2110</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">720</td>
<td style="text-align: center;">195</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6990</td>
<td style="text-align: center;">3895</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6995</td>
<td style="text-align: center;">6115</td>
</tr>
<tr>
<td style="text-align: center;">Free + harmonic + EM</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">985</td>
<td style="text-align: center;">165</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5660</td>
<td style="text-align: center;">1670</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5820</td>
<td style="text-align: center;">1820</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">540</td>
<td style="text-align: center;">255</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8320</td>
<td style="text-align: center;">7390</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">9770</td>
<td style="text-align: center;">7590</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">1265</td>
<td style="text-align: center;">635</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6520</td>
<td style="text-align: center;">6365</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">8475</td>
<td style="text-align: center;">6475</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">85</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">8620</td>
<td style="text-align: center;">575</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6320</td>
<td style="text-align: center;">4035</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">9705</td>
<td style="text-align: center;">7685</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">815</td>
<td style="text-align: center;">425</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">7575</td>
<td style="text-align: center;">8405</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">10440</td>
<td style="text-align: center;">8620</td>
</tr>
<tr>
<td style="text-align: center;">Free + gravity + harmonic + EM</td>
<td style="text-align: center;">80</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">735</td>
<td style="text-align: center;">280</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6715</td>
<td style="text-align: center;">4555</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">12495</td>
<td style="text-align: center;">8495</td>
</tr>
<tr>
<td style="text-align: center;">Median</td>
<td style="text-align: center;">95</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">330</td>
<td style="text-align: center;">45</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5403</td>
<td style="text-align: center;">3895</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6590</td>
<td style="text-align: center;">5100</td>
</tr>
<tr>
<td style="text-align: center;">Mean</td>
<td style="text-align: center;">98</td>
<td style="text-align: center;">82</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">455</td>
<td style="text-align: center;">109</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">5217</td>
<td style="text-align: center;">4171</td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;">6892</td>
<td style="text-align: center;">5499</td>
</tr>
</tbody>
</table>
<p>of $91.0 \%$ compared with the baseline of $76.9 \%$. The MSE prediction error is comparable to the baseline performance $\left(\sim 4 \times 10^{-4}\right)$ in the median, since both architectures have similar large capacity. We analyze this challenge and opportunities for improvement below.</p>
<h2>IV. CONCLUSIONS</h2>
<p>We have presented a toy "AI physicist" unsupervised learning agent centered around the learning and manipulation of
theories, which in polynomial time learns to parsimoniously predict both aspects of the future (from past observations) and the domain in which these predictions are accurate.</p>
<h2>A. Key findings</h2>
<p>Testing it on a suite of mystery worlds involving random combinations of gravity, electromagnetism, harmonic motion, and elastic bounces, we found that its divide-and-conquer and Occam's razor strategies effectively identified domains</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>FIG. 5. In this mystery, a charged double pendulum moves through two different electric fields <strong>E₁</strong> and <strong>E₂</strong>, with a domain boundary corresponding to cos θ₁ + cos θ₂ = 1.05 (the black curve above left, where the lower charge crosses the <strong>E</strong>-field boundary). The color of each dot represents the domain into which it is classified by a newborn agent, and its area represents the description length of the error with which its position is predicted, for a precision floor ε ≈ 0.006. In this world, the newborn agent has a domain prediction accuracy of 96.5%.</p>
<p>with different laws of motion and reduced the mean-squared prediction error billionfold, typically recovering integer and rational theory parameters exactly. These two strategies both encouraged prediction functions to specialize: the former on the domains they handled best, and the latter on the data points within their domain that they handled best. Adding the lifelong learning strategy greatly accelerated learning in novel environments.</p>
<h3>B. What has been learned?</h3>
<p>Returning to the broader context of unsupervised learning from Sec. I raises two important questions: what is the <em>difficulty</em> of the problems that our AI physicist solved, and what is the <em>generality</em> of our paradigm?</p>
<p>In terms of <em>difficulty</em>, our solved physics problems are clearly on the easier part of the spectrum, so if we were to have faced the <em>supervised</em> learning problem where the different domains were pre-labeled, the domain learning would have been a straightforward classification task and the forecasting task could have been easily solved by a standard feedforward neural network. Because the real world is generally unlabeled, we instead tackled the more difficult problem where boundaries of multiple domains had to be learned concurrently with the dynamical evolution rules in a fully unsupervised fashion. The dramatic performance improvement over a traditional neural network seen in Table III reflects the power of the divide-and-conquer and Occam's razor strategies, and their robustness is indicated by the fact that unsupervised domain discovery worked well even for the two-field nonlinear double-pendulum system whose dynamic is notoriously chaotic and whose domain boundary is the curved rhomboid cos θ₁ + cos θ₂ = 1.05.</p>
<p>In terms of <em>generality</em>, our core contribution lies in the AI physicist paradigm we propose (combining divide and conquer, Occam's razor, unification, and lifelong learning), not in the specific implementation details. Here we draw inspiration from the history of the Turing machine: Turing's initial implementation of a universal computer was very inefficient for all but toy problems, but his framework laid out the essential architectural components that subsequent researchers developed into today's powerful computers. What has been learned is that our AI physicist paradigm outperforms traditional deep learning on a test suite of problems even though it is a fully general paradigm that is not designed specifically for these problems. For example, it is defined to work for an arbitrary number of input spatial dimensions, spatial domains, past time steps used, boundaries of arbitrary shapes, and evolution laws of arbitrary complexity.</p>
<p>From the above-mentioned successes and failures of our paradigm, we have also learned about promising opportunities for improvement of the implementation which we will now discuss. First of all, the more modest success in the double-pendulum experiments illustrated the value of learned theories being <em>simple</em>: if they are highly complex, they are less likely to unify or generalize to future environments, and the correspondingly complex baseline model will have less incentive to specialize because it has enough expressive power to approximate the motion in all domains at once. It will therefore be valuable to improve techniques for simplifying complex learned neural nets. The specific implementation details for the Occam's razor toolkit would then change, but the principle and numerical objective would remain the same: reducing their total description length from Eq. (4). There are many promising opportunities for this using techniques from the Monte-Carlo-Markov-chain-based and genetic techniques [54], reinforcement learning [55,56], and symbolic regression [57,58] literature to simplify and shrink the model architecture. Also, it will be valuable and straightforward to generalize our implementation to simplify not only the prediction functions, but also the classifiers, for example to find sharp domain boundaries composed of hyperplanes or other simple surfaces.</p>
<p>Analogously, there are many ways in which the unification and lifelong learning toolkits can be improved while staying within our AI physicist paradigm. For example, unification can undoubtedly be improved by using more sophisticated clustering techniques for grouping the learned theories with similar ones. Lifelong learning can probably be made more efficient by using better methods for determining which previous theories to try when faced by new data, for example by training a separate neural network to perform this prediction task.</p>
<h3>C. Outlook</h3>
<p>In summary, these and other improvements to the algorithms that implement our AI physicist paradigm could enable future unsupervised learning agents to learn simpler and more accurate models faster from fewer examples, and also to discover accurate symbolic expressions for more complicated physical systems. More broadly, AI has recently been used with great success to tackle problems in diverse areas of physics, ranging from quantum state reconstruction [59] to phase transitions [60–62], planetary dynamics [63], and</p>
<p>TABLE V. Hyperparameter settings in the numerical experiments. For a fair comparison between baseline and the other agents that can have up to 4 theories, the number of neurons in each layer of baseline is larger so that the total number of parameters is roughly the same for all agents. The baseline agent in mystery worlds has leakyReLU activation to be able to account for different domains.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Hyperparameter</th>
<th style="text-align: center;">Environments</th>
<th style="text-align: center;">Baseline</th>
<th style="text-align: center;">Newborn</th>
<th style="text-align: center;">AI physicist</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\gamma$</td>
<td style="text-align: center;">Generalized-mean-loss exponent</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">$-1$</td>
<td style="text-align: center;">$-1$</td>
<td style="text-align: center;">$-1$</td>
</tr>
<tr>
<td style="text-align: center;">$\beta_{\mathbf{f}}$</td>
<td style="text-align: center;">Initial learning rate for $\mathbf{f}_{\theta}$</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.005</td>
<td style="text-align: center;">0.005</td>
</tr>
<tr>
<td style="text-align: center;">$\beta_{c}$</td>
<td style="text-align: center;">Initial learning rate for $\mathbf{c}_{\phi}$</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.001</td>
<td style="text-align: center;">0.001</td>
</tr>
<tr>
<td style="text-align: center;">K</td>
<td style="text-align: center;">Number of gradient iterations</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
<td style="text-align: center;">10000</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{c}$</td>
<td style="text-align: center;">Hidden layer activation function in $\mathbf{c}_{\phi}$</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">leakyReLU</td>
<td style="text-align: center;">leakyReLU</td>
</tr>
<tr>
<td style="text-align: center;">$N_{\text {lay }}^{c}$</td>
<td style="text-align: center;">Number of layers in $\mathbf{c}_{\phi}$</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">C</td>
<td style="text-align: center;">Initial number of clusters in theory unification</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: center;">$\epsilon_{\text {MSE }}$</td>
<td style="text-align: center;">MSE regularization strength</td>
<td style="text-align: center;">All</td>
<td style="text-align: center;">$10^{-7}$</td>
<td style="text-align: center;">$10^{-7}$</td>
<td style="text-align: center;">$10^{-7}$</td>
</tr>
<tr>
<td style="text-align: center;">$\epsilon_{L 1}$</td>
<td style="text-align: center;">Final $L_{1}$ regularization strength</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">$10^{-8}$</td>
<td style="text-align: center;">$10^{-8}$</td>
<td style="text-align: center;">$10^{-8}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">$10^{-7}$</td>
<td style="text-align: center;">$10^{-7}$</td>
<td style="text-align: center;">$10^{-7}$</td>
</tr>
<tr>
<td style="text-align: center;">$N_{\text {lay }}^{f}$</td>
<td style="text-align: center;">Number of layers in $\mathbf{f}_{\theta}$</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: center;">$N_{\text {heat }}^{f}$</td>
<td style="text-align: center;">Number of neurons in $\mathbf{f}_{\theta}$</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">320</td>
<td style="text-align: center;">160</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$N_{\text {heat }}^{c}$</td>
<td style="text-align: center;">Number of neurons in $\mathbf{c}_{\phi}$</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$T$</td>
<td style="text-align: center;">Maximum time horizon for input</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{f}$</td>
<td style="text-align: center;">Hidden layer activation function in $\mathbf{f}_{\theta}$</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">leakyReLU</td>
<td style="text-align: center;">linear</td>
<td style="text-align: center;">linear</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">$\tanh$</td>
<td style="text-align: center;">$\tanh$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$M_{0}$</td>
<td style="text-align: center;">Initial number of theories</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 and 3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$M$</td>
<td style="text-align: center;">Maximum number of theories</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 and 3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\epsilon_{\text {add }}$</td>
<td style="text-align: center;">MSE threshold for theory adding</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$2 \times 10^{-6}$</td>
<td style="text-align: center;">$2 \times 10^{-6}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\eta_{\text {inop }}$</td>
<td style="text-align: center;">Inspection threshold for theory adding</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$30 \%$</td>
<td style="text-align: center;">$30 \%$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\eta_{\text {split }}$</td>
<td style="text-align: center;">Splitting threshold for theory adding</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5 \%$</td>
<td style="text-align: center;">$5 \%$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\infty$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\eta_{\text {del }}$</td>
<td style="text-align: center;">Fraction threshold for theory deletion</td>
<td style="text-align: center;">Mystery worlds</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$0.5 \%$</td>
<td style="text-align: center;">$0.5 \%$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Double pendulum</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$100 \%$</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>particle physics [64]. We hope that building on the ideas of this paper may one day enable AI to help us discover entirely novel physical theories from data.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>This work was supported by the Casey and Family Foundation, the Ethics and Governance of AI Fund, the Foundational Questions Institute, the Rothberg Family Fund for Cognitive Science, and the Templeton World Charity Foundation, Inc. We thank Isaac Chuang, John Peurifoy, and Marin Soljačić for helpful discussions and suggestions, and the Center for Brains, Minds, and Machines (CBMM) for hospitality.</p>
<h2>APPENDIX A: AI PHYSICIST ALGORITHM</h2>
<p>The detailed AI physicist algorithm is presented in Algorithm 1, with links to each of the individual subalgorithms. Like most numerical methods, the algorithm contains a number of hyperparameters that can be tuned to optimize performance; Table V lists them and their settings for our numerical experiments.</p>
<h2>APPENDIX B: THE DIFFERENTIABLE DIVIDE-AND-CONQUER ALGORITHM</h2>
<p>Here we elaborate on our differentiable divide-andconquer (DDAC) algorithm with generalized mean loss $\mathcal{L}<em d="d">{\gamma}$ [Eq. (2)]. This loss with $\gamma&lt;0$ works with a broad range of distance functions $\ell$ satisfying Theorem 1. Since the goal of our AI physicist is to minimize the overall description length $L</em>$ loss function of}$ from Eq. (4), we choose $\ell$ to be the $L_{d</p>
<p>Algorithm 1. AI physicist: Overall algorithm.
Given observations $D=\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>\right)\right}$ from new environment:
1: $\mathcal{T}<em 0="0">{M</em> .5)$
2: $\mathcal{T} \leftarrow$ differentiable-divide-and-conquer $\left(D, \mathcal{T}}} \leftarrow$ Hub.propose-theories $\left(D, M_{0}\right)(\operatorname{Alg<em 0="0">{M</em>\right)($ Alg. 2)
3: Hub.add-theories $(\mathcal{T}, D)($ Alg. 6)
Organizing theory hub:
$\mathcal{T} \leftarrow$ Hub.Occam's-razor-with-MDL $(\mathcal{T}, D)($ Alg. 3)
$\mathcal{T} \leftarrow$ Hub.unify $(\mathcal{T})($ Alg. 4)}</p>
<p>Algorithm 2. AI physicist: Differentiable divide and conquer with harmonic loss.</p>
<p>Require Data set $D=\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>\right)\right}$
Require $M$ : number of initial total theories for training
Require $\mathcal{T}<em 0="0">{M</em>}}=\left{\left(\mathbf{f<em i="i">{i}, c</em> \leqslant M$ :
theories proposed from theory hub
Require $K$ : number of gradient iterations
Require $\beta_{k}, \beta_{k}$ : learning rates
Require $\epsilon_{0}$ : initial precision floor
1: Randomly initialize $M-M_{0}$ theories $\mathcal{T}}\right)\right}, i=1, \ldots, M_{0}, 0 \leqslant M_{0<em 0="0">{i}, i=M</em>+1, \ldots, M$.
Denote $\mathcal{T}=\left(\mathcal{T}<em M="M">{1}, \ldots, \mathcal{T}</em>}\right), \mathbf{f<em 1="1">{\boldsymbol{\theta}}=\left(\mathbf{f}</em>}, \ldots, \mathbf{f<em _boldsymbol_phi="\boldsymbol{\phi">{M}\right), \mathbf{c}</em>$.
// Harmonic training with $L_{d}$ loss:
$2: \epsilon \leftarrow \epsilon_{0}$
3: for $k$ in ${1,2,3,4,5}$ do:
$4: \quad \mathcal{T} \leftarrow$ IterativeTrain $\left(\mathcal{T}, D, \ell_{L_{d}, \epsilon}, \mathcal{L}}}=\left(c_{1}, \ldots, c_{M}\right)$ with learnable parameters $\boldsymbol{\theta}$ and $\boldsymbol{\phi<em -1="-1">{-1}\right)$, where
$\mathcal{L}</em>} \equiv \sum_{i}\left{\frac{1}{M} \sum_{i=1}^{M} \ell\left[\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em L__d="L_{d">{i}\right]^{-1}\right}^{-1}$ [Eq. (2)]
$5: \quad \epsilon \leftarrow \operatorname{set} \operatorname{epsilon}(\mathcal{T}, D) / /$ median prediction error
6: end for
// Fine-tune each theory and its domain:
7: for $k$ in ${1,2}$ do:
$8: \quad \mathcal{T} \leftarrow$ IterativeTrain $\left(\mathcal{T}, D, \ell</em>}, \epsilon}, \mathcal{L<em _dom="{dom" _text="\text">{\text {dom }}\right)$, where
$\mathcal{L}</em>}} \equiv \sum_{i} \ell\left[\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em i="i">{i}\right]$ with $i</em>=\arg \max <em i="i">{\ell} \mathbf{c}</em>}\left(\mathbf{x<em _boldsymbol_theta="\boldsymbol{\theta">{i}\right)$
$9: \quad \epsilon \leftarrow \operatorname{set} \operatorname{epsilon}(\mathcal{T}, D) / /$ median prediction error
10: end for
11: return $\mathcal{T}$
subroutine IterativeTrain $(\mathcal{T}, D, \ell, \mathcal{L})$ :
s1: for $k$ in ${1, \ldots, K}$ do:
// Gradient descent on $\boldsymbol{f}</em>$ :
s2: $\quad \mathbf{g}}}$ with loss $\mathcal{L<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{f}} \leftarrow \nabla</em>, D, \ell]$
s3: Update $\boldsymbol{\theta}$ using gradients $\mathbf{g}}} \mathcal{L}[\mathcal{T<em _boldsymbol_phi="\boldsymbol{\phi">{\boldsymbol{f}}$ (e.g., Adam [65] or SGD)
// Gradient descent on $\boldsymbol{c}</em>$ with the best-performing theory index as target:
s4: $\quad b_{i} \leftarrow \arg \min }<em i="i">{i}\left{\ell\left[\mathbf{f}</em>}\left(\mathbf{x<em i="i">{i}\right), \mathbf{y}</em>\right]\right}, \forall t$
s5: $\quad \mathbf{g}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\epsilon}} \leftarrow \nabla</em>}} \sum_{\left(\mathbf{x<em _boldsymbol_phi="\boldsymbol{\phi">{i}, \mid \in D\right.} \operatorname{CrossEntropy}\left[\operatorname{softmax}\left(\boldsymbol{c}</em>}}\left(\mathbf{x<em i="i">{i}\right)\right), b</em>\right]$
s6: Update $\boldsymbol{\phi}$ using gradients $\mathbf{g}_{\boldsymbol{\epsilon}}$ (e.g., Adam [65] or SGD)
s7: end for
s8: $\mathcal{T} \leftarrow \operatorname{AddTheories}(\mathcal{T}, D, \ell, \mathcal{L}) / /$ Optional
s9: $\mathcal{T} \leftarrow$ DeleteTheories $(\mathcal{T}, D, \ell) / /$ Optional
s10: return $\mathcal{T}$</p>
<p>Eq. (7) together with $\gamma=-1$ (harmonic loss), which works quite well in practice.</p>
<p>Algorithm 2 describes our differentiable divide-andconquer implementation, which consists of two stages. In the first stage (steps 2-6), it applies the subroutine IterativeTrain $\left(\mathcal{T}, D, \ell_{L_{d}, \epsilon}, \mathcal{L}<em -1="-1">{-1}\right)$ with harmonic loss $\mathcal{L}</em>$ a few times with the precision floor $\epsilon$ gradually lowered according to the following annealing schedule. We set the initial precision floor $\epsilon$ to be quite large so that $\ell$ initially approximates an MSE loss function. After each successive iteration, we reset $\epsilon$ to the median prediction error.}$ to train the theories $\mathcal{T</p>
<p>The $L_{d}$ loss function from Eq. (7) is theoretically desirable but tricky to train, both because it is nonconvex and because it is quite flat and uninformative far from its minimum. Our annealing schedule helps overcome both problems: initially when $\epsilon$ is large, it approximates MSE loss which is convex and guides the training to a good approximate minimum, which further training accurately pinpoints as $\epsilon$ is reduced.</p>
<p>The subroutine IterativeTrain forms the core of the algorithm. In the first stage (steps 2-6), it uses the harmonic mean of the $L_{d}$ loss of multiple prediction functions $\mathbf{f}<em 1="1">{\boldsymbol{\theta}}=$ $\left(\mathbf{f}</em>}, \ldots, \mathbf{f<em d="d">{M}\right)$ [i.e., Eq. (2) with $\gamma=-1$ and $\ell=L</em>}$ ] to simultaneously train these functions, encouraging them to each specialize in the domains where they predict best (as proven by Theorem 1), and simultaneously trains the domain classifier $\mathbf{c<em 1="1">{\boldsymbol{\phi}}=\left(c</em>\right)$ using each example's best-performing prediction function as target, with categorical cross-entropy loss. After several rounds of IterativeTrain with successively lower precision floors, each prediction function typically becomes good at predicting part of the data set, and the domain classifier becomes good at predicting for each example which prediction function will predict best.}, \ldots, c_{M</p>
<p>AddTheories $(\mathcal{T}, D, \ell, \mathcal{L})$ inspects each theory $\mathcal{T}<em _insp="{insp" _text="\text">{i}$ describing at least a large fraction $\eta</em>$ ) and thus warrant splitting off into a separate domain.}}$ (we use $30 \%$ ) of the examples to see if a non-negligible proportion $\eta_{\text {split }}$ of examples (we use a threshold of $5 \%$ ) of the examples inside its domain have MSE larger than a certain limit $\epsilon_{\text {add }}$ (we use $2 \times 10^{-6</p>
<p>If so, it uses those examples to initialize a new theory $\mathcal{T}<em M_1="M+1">{M+1}$, and performs tentative training together with other theories using IterativeTrain without steps s8 and s9 (it is also possible to allow steps s8 and s9 in this recursive calling of IterativeTrain, which will enable a recursive adding of theories for not-well-explained data, and may enable a more powerful DDAC algorithm). If the resulting loss $\mathcal{L}$ is smaller than before adding the new theory, $\mathcal{T}</em>=0.5 \%$ ).}$ is accepted and retained; otherwise it is rejected and training reverts to the checkpoint before adding the theory. DeleteTheories $(\mathcal{T}, D, \ell)$ deletes theories whose domain or best-predicted examples cover a negligible fraction of the examples (we use a delete threshold $\eta_{\text {del }</p>
<p>In the second stage (steps 7-10), the IterativeTrain is applied again, but the loss for each example $\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>}\right)$ is using only the theory that the domain classifier $\mathbf{c<em 1="1">{\boldsymbol{\phi}}=\left(c</em>}$ with respect to each of its domain, and fine-tune the domain to the best-performing theory at each point. The reason that we assign examples to domains using our domain classifier rather than prediction accuracy is that the trained domains are likely to be simpler and more contiguous, thus generalizing better to unseen examples than, e.g., the nearest neighbor algorithm.}, c_{2}, \ldots, c_{M}\right)$ predicts (having the largest logit). In this way, we iteratively fine-tune the prediction functions ${\mathbf{f}_{i</p>
<p>We now specify the default hyperparameters used for Algorithm 1 in our experiments (unless otherwise specified). We set the initial total number of theories $M=4$, from which $M_{0}=2$ theories are proposed from the theory hub. The initial precision floor $\epsilon_{0}=10$ and the number of gradient iterations $K=10000$. We use the Adam [65] optimizer with default parameters for the optimization of both the prediction function and the domain classifier. We randomly split each data set $D$ into $D_{\text {train }}$ and $D_{\text {test }}$ with $4: 1$ ratio. The $D_{\text {test }}$ is used only for</p>
<p>Algorithm 3. AI physicist: Occam's razor with MDL.</p>
<div class="codehilite"><pre><span></span><code>Require Data set \(D=\left\{\left(\mathbf{x}_{i}, \mathbf{y}_{i}\right)\right\}\)
Require \(\mathcal{T}=\left\{\left(\mathbf{f}_{i}, c_{i}\right)\right\}, i=1, \ldots, M\) : theories trained after Alg. 2
Require \(\epsilon\) : Precision floor for \(\ell_{L_{d} \cdot \epsilon}\).
for \(i\) in $\{1, \ldots, M\}\) do:
    \(D^{(i)} \leftarrow\left\{\left(\mathbf{x}_{i}, \mathbf{y}_{i}\right) \mid \arg \max <span class="ge">_{j}\left\{c_</span>{j}\left(\mathbf{x}_{i}\right)\right\}=i\right\}\)
    \(\mathbf{f}_{i} \leftarrow\) MinimizeDL(collapseLayers, \(\mathbf{f}_{i}, D^{(i)}, \epsilon\) )
    \(\mathbf{f}_{i} \leftarrow\) MinimizeDL(localSnap, \(\mathbf{f}_{i}, D^{(i)}, \epsilon\) )
    \(\mathbf{f}_{i} \leftarrow\) MinimizeDL(integerSnap, \(\mathbf{f}_{i}, D^{(i)}, \epsilon\) )
    \(\mathbf{f}_{i} \leftarrow\) MinimizeDL(rationalSnap, \(\mathbf{f}_{i}, D^{(i)}, \epsilon\) )
    \(\mathbf{f}_{i} \leftarrow\) MinimizeDL(toSymbolic, \(\mathbf{f}_{i}, D^{(i)}, \epsilon\) )
8: end for
9: return \(\mathcal{T}\)
</code></pre></div>

<p>subroutine MinimizeDL(transformation, $\left.\mathbf{f}<em i="i">{i}, D^{(i)}, \epsilon\right)$ :
s1: while transformation is_applicable $\left(\mathbf{f}</em>\right)$ do:
s2: $\quad \mathrm{dl}<em d="d">{0} \leftarrow L</em>}\left(\mathbf{f<em _left_mathbf_x="\left(\mathbf{x">{i}\right)+\sum</em><em i="i">{i}, \mathbf{y}</em>}\right) \in D^{(i)}} \ell_{L_{d}, \epsilon}\left[\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em _clone="{clone" _text="\text">{i}\right]$
s3: $\quad f</em>}} \leftarrow \mathbf{f<em i="i">{i} / /$ clone $\mathbf{f}</em>$ in case transformation fails
s4: $\quad \mathbf{f}<em i="i">{i} \leftarrow$ transformation $\left(\mathbf{f}</em>\right)$
s5: $\quad \mathbf{f}<em _mathbf_f="\mathbf{f">{i} \leftarrow \operatorname{Minimize}</em><em _left_mathbf_x="\left(\mathbf{x">{i}} \sum</em><em i="i">{i}, \mathbf{y}</em>}\right) \in D^{(i)}} \ell_{L_{d}, \epsilon}\left[\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em 1="1">{i}\right]$
s6: $\quad \mathrm{dl}</em>} \leftarrow L_{d}\left(\mathbf{f<em _left_mathbf_x="\left(\mathbf{x">{i}\right)+\sum</em><em i="i">{i}, \mathbf{y}</em>}\right) \in D^{(i)}} \ell_{L_{d}, \epsilon}\left[\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em 1="1">{i}\right]$
s7: $\quad$ if $\mathrm{dl}</em>}&gt;\mathrm{dl<em _clone="{clone" _text="\text">{0}$ return $f</em>$
s8: end while
s9: return $\mathbf{f}}<em _text="\text" _train="{train">{i}$
evaluation of performance. The batch size is set to $\min (2000$, $\left|D</em>}}\right|)$. We set the initial learning rate $\beta_{\mathbf{f}}=5 \times 10^{-3}$ for the prediction functions $\mathbf{f<em _mathbf_c="\mathbf{c">{\boldsymbol{\theta}}$ and $\beta</em>$.}}=10^{-3}$ for the domain classifier $\mathbf{c}_{\boldsymbol{\phi}}$. We also use a learning rate scheduler that monitors the validation loss every 10 epochs, and divides the learning rate by 10 if the validation loss has failed to decrease after 40 monitoring points and stops training early if there is no decrease after 200 epochs-or if the entire MSE loss for all the theories in their respective domains drops below $10^{-12</p>
<p>To the main harmonic loss $\mathcal{L}<em 1="1">{\gamma}$, we add two regularization terms. One is $L</em>$, to encourage the prediction functions to remain not too far away from the target outside their domain.}$ loss whose strength increases quadratically from 0 to $\epsilon_{\mathrm{LI}}$ during the first 5000 epochs and remains constant thereafter. The second regularization term is a very small MSE loss of strength $\epsilon_{\mathrm{MSE}</p>
<h2>APPENDIX C: OCCAM'S RAZOR WITH MDL ALGORITHM</h2>
<p>Pushing on after the DDAC algorithm with harmonic loss that minimizes the $\sum_{i} L_{d}\left(\mathbf{u}<em d="d">{i}\right)$ term in Eq. (4), the AI physicist then strives to minimize the $L</em>}(\mathcal{T})$ term, which can be decomposed as $L_{d}(\mathcal{T})=L_{d}\left(\mathbf{f<em d="d">{\boldsymbol{\theta}}\right)+L</em>}\left(\mathbf{c<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\phi}}\right)$, where $\mathbf{f}</em>}}=\left(\mathbf{f<em M="M">{1}, \ldots, \mathbf{f}</em>}\right)$ and $\mathbf{c<em 1="1">{\boldsymbol{\phi}}=\left(c</em>}, \ldots, c_{M}\right)$. We focus on minimizing $L_{d}\left(\mathbf{f<em i="i">{\boldsymbol{\theta}}\right)$, since in different environments the prediction functions $\mathbf{f}</em>}$ can often be reused, while the domains may differ. As mentioned, we define $L_{d}\left(\mathbf{f<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}\right)$ simply as the sum of the description lengths of the numbers parametrizing $\mathbf{f}</em>$ :}</p>
<p>$$
L_{d}\left(\mathbf{f}<em j="j">{\boldsymbol{\theta}}\right)=\sum</em>\right)
$$} L_{d}\left(\theta_{j</p>
<p>This means that $L_{d}\left(\mathbf{f}_{\boldsymbol{\theta}}\right)$ can be significantly reduced if an irrational parameter is replaced by a simpler rational number.</p>
<p>If a physics experiment or neural net training produces a parameter $p=1.999942$, it would be natural to interpret this as a hint, and to check if $p=2$ gives an equally acceptable fit to the data. We formalize this by replacing any real-valued parameter $p_{i}$ in our theory $\mathcal{T}$ by its nearest integer if this reduces the total description length in Eq. (4), as detailed below. We start this search for integer candidates with the parameter that is closest to an integer, refitting for the other parameters after each successful "integer snap."</p>
<p>What if we instead observe a parameter $p=1.5000017$ ? Whereas generic real numbers have a closest integer, they lack a closest rational number. Moreover, as illustrated in Fig. 2, we care not only about closeness [to avoid increasing the second term in Eq. (4)] but also about simplicity (to reduce the first term). To rapidly find the best "rational snap" candidates (dots in Fig. 2 that lie both near $p$ and far down), we perform a continued fraction expansion of $p$ and use each series truncation as a rational candidate. We repeat this for all parameters in the theory $\mathcal{T}$, again accepting only those snaps that reduce the total description length. We again wish to try the most promising snap candidates first; to rapidly identify promising candidates without having to recompute the second term in Eq. (4), we evaluate all truncations of all parameters as in Fig. 3, comparing the description length of the rational approximation $q=m / n$ with the description length of the approximation error $|p-q|$. The most promising candidate minimizes their sum, i.e., lies farthest down to the left of the diagonal in the figure. The figure illustrates how, given the parameter vector $\mathbf{p}=[\pi, \sqrt{2}, 3.43180632382353]$, the first snap to be attempted will replace the third parameter by $53 / 17$.</p>
<p>We propose Algorithm 3 to implement the above minimization of $L_{d}\left(\mathbf{f}<em d="d">{\boldsymbol{\theta}}\right)$ without increasing $L</em>}(\mathcal{T}, D)$ [Eq. (4)]. For each theory $\mathcal{T<em i="i">{i}=\left(\mathbf{f}</em>}, c_{i}\right)$, we first extract the examples $D^{(i)}$ inside its domain, then perform a series of tentative transformations (simplifications) of the prediction function $\mathbf{f<em i="i">{i}$ using the MinimizeDL subroutine. This subroutine takes $\mathbf{f}</em>}$, the transformation, and $D^{(i)}$ as inputs and repeatedly applies the transformation to $\mathbf{f<em i="i">{i}$. After each such transformation, it fine-tunes the fit of $\mathbf{f}</em>}$ to $D^{(i)}$ using gradient descent. For determining whether to accept the transformation, Algorithm 3 presents the simplest 0 -step patience implementation: if the description length $\mathrm{dl}=L_{d}\left(\mathbf{f<em _left_mathbf_x="\left(\mathbf{x">{i}\right)+\sum</em><em i="i">{i}, \mathbf{y}</em>}\right) \in D^{(i)}} \ell_{L_{d}, \epsilon}\left(\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em d="d">{i}\right)$ for theory $i$ decreases, then apply the transformation again if possible; otherwise exit the loop. In general, to allow for temporary increase of $L</em>$ does not decrease during $n$ consecutive transformations inside MinimizeDL, exit the loop. In our implementation, we use a 4 -step patience.}$ during the transformations, a nonzero patience can be adopted: at each step, save the best-performing model as the pivot model, and if $L_{d</p>
<p>We now detail the five transformations used in Algorithm 3. The collapseLayer transformation finds all successive layers of a neural net where the lower layer has linear activation, and combines them into one. The toSymbolic transformation transforms $\mathbf{f}<em i="i">{i}$ from the form of a neural net into a symbolic expression (in our implementation, from a PyTorch net to a SymPy symbolic lambda expression). These two transformations are one-time transformations (for example, once $\mathbf{f}</em>$ has been transformed to a symbolic expression, toSymbolic cannot be applied to it again). The</p>
<p>localSnap transformation successively sets the incoming weights in the first layer to 0 , thus favoring inputs that are closer to the current time step. The integerSnap transformation finds the (nonsnapped) parameter in $\mathbf{f}<em i="i">{i}$ that is closest to an integer, and snaps it to that integer. The rationalSnap transformation finds the (nonsnapped) parameter in $\mathbf{f}</em>}$ that has the lowest bit sum when replaced by a rational number, as described in Sec. II D, and snaps it to that rational number. The latter three transformations can be applied multiple times to $\mathbf{f<em i="i">{i}$, until there are no more parameters to snap in $\mathbf{f}</em>$, or the transformation followed by fine-tuning fails to reduce the description length.</p>
<p>In the bigger picture, Algorithm 3 is an implementation of minimizing the $\mathrm{DL}\left(\mathbf{f}<em _boldsymbol_theta="\boldsymbol{\theta">{\boldsymbol{\theta}}\right)$ without increasing the total $\mathrm{DL}(\mathcal{T}, D)$, if the description length of $\mathbf{f}</em>, D)$ with respect to whatever DL formula it is based on.}}$ is given by Eq. (C1). There can be other ways to encode $\mathcal{T}$ with a different formula for $\mathrm{DL}(\mathcal{T})$, in which case the transformations for decreasing $\mathrm{DL}(\mathcal{T})$ may be different. But the structure of Algorithm 3 remains the same, with the goal of minimizing $\mathrm{DL}\left(\mathbf{f}_{\boldsymbol{\theta}}\right)$ without increasing $\operatorname{DL}(\mathcal{T</p>
<p>In the still bigger picture, Algorithm 3 is a computationally efficient approximate implementation of the MDL formalism, involving the following two approximations:
(1) The description lengths $L_{d}(x)$ for various types of numbers are approximate, for convenience. For example, the length of the shortest self-terminating bit string encoding an arbitrary natural number $n$ grows slightly faster than our approximation $\log <em 2="2">{2} n$, because self-termination requires storing not only the binary digits of the integer, but also the length of said bit string, recursively, requiring $\log </em> n+\log <em 2="2">{2} \log </em> n+$ $\log <em 2="2">{2} \log </em> n+\cdots$, where only the positive terms are included [51]. Slight additional overhead is required to upgrade the encodings to actual programs in some suitable language, including encoding of whether bits encode integers, rational numbers, floating-point numbers, etc.
(2) If the above-mentioned $L_{d}(x)$ formulas were made exact, they would be mere upper bounds on the true minimum description length. For example, our algorithm gives a gigabyte description length for $\sqrt{2}$ with precision $\epsilon=256^{-10^{6}}$, even though it can be computed by a rather short program, and there is no simple algorithm for determining which numbers can be accurately approximated by algebraic numbers. Computing the true minimum description length is a famous numerically intractable problem.</p>
<h2>APPENDIX D: UNIFICATION ALGORITHM</h2>
<p>The unification process takes as input the symbolic prediction functions $\left{\left(\mathbf{f}<em _mathbf_p="\mathbf{p">{i}, \cdot\right)\right}$, and outputs master theories $\mathscr{T}=$ $\left{\left(\mathbf{f}</em>}}, \cdot\right)\right}$ such that by varying each $\mathbf{p}$ in $\mathbf{f<em i="i">{\mathbf{p}}$, we can generate a continuum of prediction functions $\mathbf{f}</em>}$ within a certain class of prediction functions. The symbolic expression consists of 3 building blocks: operators (e.g.,,$+,- \times, /$ ), input variables (e.g., $x_{1}, x_{2}$ ), and coefficients that can be either a rational number or irrational number. The unification algorithm first calculates the description length $\mathrm{dl}^{(i)}$ of each prediction function, then clusters them into $K$ clusters using, e.g., K-means clustering. Within each cluster $S_{k}$, it first canonicalizes each $\mathbf{f<em k="k">{i</em>}} \in S_{k}$ into a 2-tuple $\left(\mathbf{g<em k="k">{i</em>}}, \mathbf{h<em k="k">{i</em>}}\right)$, where $\mathbf{g<em k="k">{i</em>$ is a tree-form}</p>
<p>Algorithm 4. AI physicist: Theory unification.</p>
<div class="codehilite"><pre><span></span><code><span class="nx">Require</span><span class="w"> </span><span class="nx">Hub</span><span class="p">:</span><span class="w"> </span><span class="nx">theory</span><span class="w"> </span><span class="nx">hub</span>
<span class="nx">Require</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">C</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="nx">initial</span><span class="w"> </span><span class="nx">number</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">clusters</span>
<span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i</span><span class="p">},</span><span class="w"> </span><span class="nx">c_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">Hub</span><span class="p">.</span><span class="nx">all</span><span class="o">-</span><span class="nx">symbolic</span><span class="o">-</span><span class="nx">theories</span><span class="w"> </span><span class="nx">do</span><span class="p">:</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathrm</span><span class="p">{</span><span class="nx">dl</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">i</span><span class="p">)}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="nx">L_</span><span class="p">{</span><span class="nx">d</span><span class="p">}</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="nx">end</span><span class="w"> </span><span class="k">for</span>
<span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="nx">S_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">Cluster</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">into</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">C</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">clusters</span><span class="w"> </span><span class="nx">based</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="nx">dl</span><span class="w"> </span><span class="err">\</span><span class="p">({</span><span class="w"> </span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">i</span><span class="p">)}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">5</span><span class="p">:</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">S_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="nx">S_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">do</span><span class="p">:</span>
<span class="mi">6</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">g</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">h</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">Canonicalize</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="p">),</span><span class="w"> </span><span class="err">\</span><span class="k">forall</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="k">in</span><span class="w"> </span><span class="nx">S_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">7</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">quad</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">h</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="o">^</span><span class="p">{</span><span class="nx">s</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">Mode</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">h</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="nx">mid</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="k">in</span><span class="w"> </span><span class="nx">S_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">8</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">quad</span><span class="w"> </span><span class="nx">G_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">g</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="nx">mid</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">h</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}=</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">h</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="o">^</span><span class="p">{</span><span class="nx">s</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
<span class="mi">9</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">quad</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">g</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">p</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">Traverse</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">g</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">i_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="k">in</span><span class="w"> </span><span class="nx">G_</span><span class="p">{</span><span class="nx">k</span><span class="p">}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">synchronized</span><span class="w"> </span><span class="nx">steps</span><span class="p">,</span>
<span class="w">                </span><span class="nx">replacing</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">coefficient</span><span class="w"> </span><span class="nx">by</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">p</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">j_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">when</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">all</span>
<span class="w">                    </span><span class="nx">coefficients</span><span class="w"> </span><span class="nx">at</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">same</span><span class="w"> </span><span class="nx">position</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">identical</span><span class="p">.</span>
<span class="mi">10</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">quad</span><span class="w"> </span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">p</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">toPlainForm</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">g</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">p</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="mi">11</span><span class="p">:</span><span class="w"> </span><span class="nx">end</span><span class="w"> </span><span class="k">for</span>
<span class="mi">12</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathscr</span><span class="p">{</span><span class="nx">T</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="nx">left</span><span class="err">\</span><span class="p">{</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">f</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="err">\</span><span class="nx">mathbf</span><span class="p">{</span><span class="nx">p</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="nx">k</span><span class="p">}},</span><span class="w"> </span><span class="err">\</span><span class="nx">cdot</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="nx">right</span><span class="err">\</span><span class="p">},</span><span class="w"> </span><span class="nx">k</span><span class="p">=</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="nx">ldots</span><span class="p">,</span><span class="w"> </span><span class="nx">C</span><span class="err">\</span><span class="p">)</span>
<span class="mi">13</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathscr</span><span class="p">{</span><span class="nx">T</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">MergeSameForm</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">mathscr</span><span class="p">{</span><span class="nx">T</span><span class="p">}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="mi">14</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">mathscr</span><span class="p">{</span><span class="nx">T</span><span class="p">}</span><span class="err">\</span><span class="p">)</span>
</code></pre></div>

<p>subroutine Canonicalize $\left(\mathbf{f}<em i="i">{i}\right)$ :
s1: $\mathbf{g}</em>} \leftarrow$ ToTreeForm $\left(\mathbf{f<em i="i">{i}\right)$
s2: $\mathbf{h}</em>} \leftarrow$ Replace all non-input coefficients by a symbol $s$ return $\left(\mathbf{g<em i="i">{i}, \mathbf{h}</em>\right)$
expression of $\mathbf{f}<em k="k">{i</em>}}$ where each internal node is an operator, and each leaf is an input variable or a coefficient. When multiple orderings are equivalent (e.g., $x_{1}+x_{2}+x_{3}$ vs $x_{1}+x_{3}+x_{2}$ ), it always uses a predefined partial ordering. $\mathbf{h<em k="k">{i</em>}}$ is the structure of $\mathbf{g<em k="k">{i</em>}}$ where all coefficients are replaced by an $s$ symbol. Then the algorithm obtains a set of $\mathbf{g<em k="k">{i</em>}}$ that has the same structure $\mathbf{h<em k="k">{i</em>}}$ with the largest cardinality (steps 7-8). This will eliminate some expressions within the cluster that might interfere with the following unification process. Step 9 is the core part, where it traverses each $\mathbf{g<em k="k">{i</em>}} \in G_{k}$ with synchronized steps using, e.g., depth-first search or breath-first search. This is possible since each $\mathbf{g<em k="k">{i</em>}} \in G_{k}$ has the same tree structure $h_{k}^{s}$. During traversing, whenever encountering a coefficient and not all coefficients across $G_{k}$ at this position are the same, replace the coefficients by some symbol $\mathbf{p<em k="k">{j</em>}}$ that has not been used before. Essentially, we are turning all coefficients that vary across $G_{k}$ into a parameter, and the coefficients that do not vary stay as they are. In this way, we obtain a master prediction function $\mathbf{f<em k="k">{\mathbf{p}</em>}}$. Finally, at step 13, the algorithm merges the master prediction functions in $\mathscr{T}=\left{\left(\mathbf{f<em k="k">{\mathbf{p}</em>$. The domain classifier is neglected during the unification process, since at different environments, each prediction function can have vastly different spatial domains. It is the prediction function (which characterizes the equation of motion) that is important for generalization.}}, \cdot\right)\right}$ that have the exact same form, and return $\mathscr{T</p>
<h2>APPENDIX E: ADDING AND PROPOSING THEORIES</h2>
<p>Here we detail the algorithms adding theories to the hub and proposing them for use in new environments. Algorithm 5 provides a simplest version of the theory-proposing algorithm. Given a new data set $D$, the theory hub inspects all theories $i$,</p>
<p>Algorithm 5. AI physicist: Theory proposing from hub.
Require Hub: theory hub
Require Data set $D=\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>\right)\right}$
Require $M_{0}$ : number of theories to propose from the hub
1: $\left{\left(\mathbf{f}<em i="i">{i}, c</em>\right)\right} \leftarrow$ Hub.retrieve-all-theories()
2: $D_{\text {heat }}^{(i)} \leftarrow\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>}\right) \mid \operatorname{argmin<em L__d="L_{d">{j} \ell</em>}, \sigma}\left{\mathbf{f<em i="i">{j}\left(\mathbf{x}</em>}\right), \mathbf{y<em M__0="M_{0">{i}\right}=i\right}, \forall i$
3: $\mathcal{T}</em>}} \leftarrow\left{\left(\mathbf{f<em i="i">{i}, c</em>\right}\right}$
4: return $\mathcal{T}}\right) \mid D_{\text {heat }}^{(i)}\right.$ ranks among $M_{0}$ largest sets in $\left{D_{\text {heat }}^{(i)<em 0="0">{M</em>$
and for each one, counts the number $n_{i}$ of data points where it outperforms all other theories. The top $M_{0}$ theories with largest $n_{i}$ are then proposed.}</p>
<p>For theory adding after training with DDAC (Algorithm 2), each theory $i$ calculates its description length $\mathrm{d} l^{(i)}$ inside its domain. If its $\mathrm{d} l^{(i)}$ is smaller than a threshold $\eta$, then the theory $\left(\mathbf{f}<em i="i">{i}, c</em>}\right)$ with its corresponding examples $D^{(i)}$ are added to the theory hub. The reason why the data $D^{(i)}$ are also added to the hub is that $D^{(i)}$ gives a reference for how the theory $\left(\mathbf{f<em i="i">{i}, c</em>\right)$ was trained, and is also needed in the Occam's razor algorithm.</p>
<h2>APPENDIX F: TIME COMPLEXITY</h2>
<p>In this Appendix, we list crude estimates of the time complexity of our AI physicist algorithm, i.e., of how its runtime scales with key parameters.
$D D A C$, the differentiable divide-and-conquer algorithm (Algorithm 2), is run once for each of the $n_{\text {myst }}$ different mystery worlds, with a total runtime scaling roughly as</p>
<p>$$
O\left(n_{\text {myst }} n_{\text {par }} n_{\text {data }} n_{\text {dom }}^{2}\right)
$$</p>
<p>where $n_{\text {par }}$ is the average number of neural-network parameters in a theory, $n_{\text {data }}$ is the average number of data points (time steps) per mystery, and $n_{\text {dom }}$ is the number of discovered domains (in our case $\leqslant 4$ ). The power of two for $n_{\text {dom }}$ appears because the time to evaluate the loss function scales as $n_{\text {dom }}$, and we need to perform of order $n_{\text {dom }}$ training cycles to add the right number of theories. The $n_{\text {par }}$ scaling is due to that the forward and backward propagation of the neural net involves successive matrices multiplied by a vector, which scales as $O\left(n^{2}\right)$, where $n \simeq \sqrt{n_{\text {par }} / N_{\text {lay }}^{T}}$ is the matrix dimension for each</p>
<p>Algorithm 6. AI physicist: Adding theories to hub.
Require Hub: theory hub
Require $\mathcal{T}=\left{\left(\mathbf{f}<em i="i">{i}, c</em>\right)\right}$ : Trained theories from Alg. 2
Require Data set $D=\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>\right)\right}$
Require $\eta: L_{d}$ threshold for adding theories to hub
1: $D^{(i)} \leftarrow\left{\left(\mathbf{x}<em i="i">{i}, \mathbf{y}</em>\right) \mid \arg \max <em j="j">{j}\left{c</em>}\left(\mathbf{x<em _left_mathbf_x="\left(\mathbf{x">{i}\right)\right}=i\right}, \forall i$
2: $\mathrm{d} l^{(i)} \leftarrow \frac{1}{\left|D^{(i)}\right|} \sum</em><em i="i">{i}, \mathbf{y}</em>}\right) \in D^{(i)}} \ell_{L_{d}, \sigma}\left(\mathbf{f<em i="i">{i}\left(\mathbf{x}</em>}\right), \mathbf{y<em i="i">{i}\right), \forall i$
3: for $i$ in ${1,2, \ldots,|\mathcal{T}|}$ do:
4: if $\mathrm{d} l^{(i)}&lt;\eta$ do
5: Hub.addIndividualTheory $\left(\left(\mathbf{f}</em>\right)$
6: end if
7: end for
layer and $N_{\text {lay }}^{f}$ is the number of layers. Accumulating all layers we have $N_{\text {lay }}^{f} n^{2}=n_{\text {par }}$. We make no attempt to model how the number of training epochs needed to attain the desired accuracy depends on parameters.}, c_{i}\right), D^{(i)</p>
<p>Our lifelong learning algorithm is also run once per mystery, with a time cost dominated by that for proposing new theories (Algorithm 5), which scales as</p>
<p>$$
O\left(n_{\text {myst }} n_{\text {data }} n_{\text {theo }}\right)
$$</p>
<p>Here $n_{\text {theo }}$ is the number of theories in the theory hub.
In contrast, our Occam's razor algorithm (Algorithm 3) and unification algorithm (Algorithm 4) are run once per learned theory, not once per mystery. For Occam's razor, the total runtime is dominated by that for snapping to rational numbers, which scales as</p>
<p>$$
O\left(n_{\text {par }} n_{\text {data }} n_{\text {theo }}\right)
$$</p>
<p>For the unification, the total runtime scales as $O\left(n_{\text {par }} n_{\text {theo }}\right)$, which can be neglected relative to the cost of Occam's razor.</p>
<p>We note that all these algorithms have merely polynomial time complexity. The DDAC algorithm dominates the time cost; our mystery worlds were typically solved in about 1 hour each on a single CPU. If vast amounts of data are available, it may suffice to analyze a random subset of much smaller size.</p>
<h2>APPENDIX G: PROOF OF THEOREM 1 AND COROLLARY</h2>
<p>Here we give the proof for Theorem 1, restated here for convenience.</p>
<p>Theorem 1. Let $\hat{\mathbf{y}}<em i="i">{t}^{(i)} \equiv \mathbf{f}</em>}\left(\mathbf{x<em t="t">{t}\right)$ denote the prediction of the target $\mathbf{y}</em>}$ by the function $\mathbf{f<em t="t">{i}, i=1,2, \ldots, M$. Suppose that $\gamma&lt;$ 0 and $\ell\left(\hat{\mathbf{y}}</em>}, \mathbf{y<em t="t">{t}\right)=\ell\left(\left|\hat{\mathbf{y}}</em>}-\mathbf{y<em 0="0">{t}\right|\right)$ for a monotonically increasing function $\ell(u)$ that vanishes on $\left[0, u</em>}\right]$ for some $u_{0} \geqslant 0$, with $\ell(u)^{\gamma}$ differentiable and strictly convex for $u&gt;u_{0}$. Then if $0&lt;\ell\left(\hat{\mathbf{y}<em t="t">{t}^{(i)}, \mathbf{y}</em>}\right)&lt;\ell\left(\hat{\mathbf{y}<em t="t">{t}^{(j)}, \mathbf{y}</em>\right)$, we have</p>
<p>$$
\left|\frac{\partial \mathcal{L}<em t="t">{\gamma}}{\partial u</em>}^{(i)}}\right|&gt;\left|\frac{\partial \mathcal{L<em t="t">{\gamma}}{\partial u</em>\right|
$$}^{(j)}</p>
<p>where $u_{t}^{(i)} \equiv\left|\hat{\mathbf{y}}<em t="t">{t}^{(i)}-\mathbf{y}</em>\right|$.
Proof. Since $u_{t}^{(i)} \equiv\left|\hat{\mathbf{y}}<em t="t">{t}^{(i)}-\mathbf{y}</em>}\right|$ and $\ell\left(\hat{\mathbf{y}<em t="t">{t}, \mathbf{y}</em>}\right)=\ell\left(\left|\hat{\mathbf{y}<em t="t">{t}-\mathbf{y}</em>$ as defined in Eq. (3) can be rewritten as}\right|\right)$, the generalized mean loss $L_{\gamma</p>
<p>$$
\mathcal{L}<em t="t">{\gamma}=\sum</em>
$$}\left[\frac{1}{M} \sum_{k=1}^{M} \ell\left(u_{t}^{(k)}\right)^{\gamma}\right]^{\frac{1}{\gamma}</p>
<p>which implies that</p>
<p>$$
\begin{aligned}
\left|\frac{\partial \mathcal{L}<em t="t">{\gamma}}{\partial u</em>\right| \
&amp; =\frac{1}{|\gamma| M}\left[\frac{1}{M} \sum_{k=1}^{M} \ell\left(u_{t}^{(k)}\right)^{\gamma}\right]^{\frac{1}{\gamma}-1}\left|\frac{d \ell\left(u_{t}^{(i)}\right)^{\gamma}}{d u_{t}^{(i)}}\right|
\end{aligned}
$$}^{(i)}}\right| &amp; =\left|\frac{1}{\gamma M}\left[\frac{1}{M} \sum_{k=1}^{M} \ell\left(u_{t}^{(k)}\right)^{\gamma}\right]^{\frac{1}{\gamma}-1} \frac{d \ell\left(u_{t}^{(i)}\right)^{\gamma}}{d u_{t}^{(i)}</p>
<p>Since only the last factor depends on $i$, proving Eq. (G1) is equivalent to proving that</p>
<p>$$
\left|\frac{d \ell\left(u_{t}^{(i)}\right)^{\gamma}}{d u_{t}^{(i)}}\right|&gt;\left|\frac{d \ell\left(u_{t}^{(j)}\right)^{\gamma}}{d u_{t}^{(j)}}\right|
$$</p>
<p>Let us henceforth consider only the case $u&gt;u_{0}$, since the conditions $\ell\left(u_{t}^{(j)}\right)&gt;\ell\left(u_{t}^{(i)}\right)&gt;0$ imply $u_{t}^{(j)}&gt;u_{t}^{(i)}&gt;u_{0}$. Since $\gamma&lt;0, \ell(u)&gt;0$, and $\ell^{\prime}(u) \geqslant 0$, we have $\frac{d \ell(u)^{\gamma}}{d u}=$ $\gamma \ell(u)^{\gamma-1} \ell^{\prime}(u) \leqslant 0$, so that $\left|\frac{d \ell(u)^{\gamma}}{d u}\right|=-\frac{d \ell(u)^{\gamma}}{d u}$. Because $\ell(u)^{\gamma}$ is differentiable and strictly convex, its derivative $\frac{d \ell(u)^{\gamma}}{d u}$ is monotonically increasing, implying that $\left|\frac{d \ell(u)^{\gamma}}{d u}\right|=-\frac{d \ell(u)^{\gamma}}{d u}$ is monotonically decreasing. Thus $\left|\frac{d \ell\left(u_{1}\right)^{\gamma}}{d u_{1}}\right|&gt;\left|\frac{d \ell\left(u_{2}\right)^{\gamma}}{d u_{2}}\right|$ whenever $u_{1}&lt;u_{2}$. Setting $u_{1}=\left|\mathbf{y}<em t="t">{t}^{(i)}-\mathbf{y}</em>}\right|$ and $u_{2}=\left|\mathbf{y<em t="t">{t}^{(j)}-\mathbf{y}</em>\right|$ therefore implies Eq. (G3), which completes the proof.</p>
<p>The following Corollary 1 demonstrates that the theorem applies to several popular loss functions as well as our two description-length loss functions.</p>
<p>Corollary 1. Defining $u \equiv|\mathbf{y}-\mathbf{y}|$, the following loss functions which depend only on $u$ satisfy the conditions for Theorem 1:
(1) $\ell(u)=u^{r}$ for any $r&gt;0$, which includes MSE loss $(r=2)$ and mean-absolute-error loss $(r=1)$.
(2) Huber loss:</p>
<p>$$
\ell_{\delta}(u)= \begin{cases}\frac{1}{2} u^{2}, &amp; u \in[0, \delta] \ \delta\left(u-\frac{\delta}{2}\right), &amp; \text { otherwise }\end{cases}
$$</p>
<p>where $\delta&gt;0$.
(3) Description length loss</p>
<p>$$
\ell_{L_{d}, \epsilon}(u)=\frac{1}{2} \log _{2}\left[1+\left(\frac{u}{\epsilon}\right)^{2}\right]
$$</p>
<p>(4) Hard description length loss</p>
<p>$$
\ell_{\mathrm{DLhard}, \epsilon}(u)=\log _{2} \max \left(1, \frac{u}{\epsilon}\right)
$$</p>
<p>Proof. We have $u_{0}=0$ for (1), (2), (3), and $u_{0}=\epsilon$ for (4). All four functions $\ell$ are monotonically increasing, satisfy $\ell(0)=0$, and are differentiable for $u&gt;u_{0}$, so all that remains to be shown is that $\ell(u)^{\gamma}$ is strictly convex for $u&gt;u_{0}$, i.e., that $\frac{d^{2} \ell(u)^{\gamma}}{d u^{2}}&gt;0$ when $u&gt;u_{0}$.
(1) For $\ell(u)=u^{r}$ and $u&gt;0$, we have $\frac{d^{2} \ell(u)^{\gamma}}{d u^{2}}=\gamma r(\gamma r-$ $1) u^{\gamma r-2}&gt;0$, since $\gamma&lt;0$ and $r&gt;0$ implies that $\gamma r&lt;0$ and $\gamma r-1&lt;0$, so $\ell(u)^{\gamma}$ is strictly convex for $u&gt;0$.
(2) The Huber loss $\ell_{\delta}(u)$ is continuous with a continuous derivative. It satisfies $\frac{d^{2} \ell(u)^{\gamma}}{d u^{2}}&gt;0$ both for $0&lt;u&lt;\delta$ and for $\delta&lt;u$ according to the above proof of (1), since $\ell_{\delta}(u)$ is proportional to $\ell^{r}$ in these two intervals with $r=2$ and $r=1$, respectively. At the transition point $u=\delta$, this second derivative is discontinuous, but takes positive value approaching both from the left and from the right, so $\ell(u)^{\gamma}$ is strictly convex. More generally, any function $\ell(u)$ built by smoothly connecting functions $\ell_{i}(u)$ in different intervals will satisfy our theorem if the functions $\ell_{i}(u)$ do.
(3) Proving strict convexity of $\ell(u)^{\gamma}$ when $\ell$ is the description length loss $\ell_{L_{d}, \epsilon}(u)=\frac{1}{2} \log _{2}\left[1+\left(\frac{u}{\epsilon}\right)^{2}\right]$ is equivalent to
proving it when $\ell(u)=\rho(u) \equiv \ln \left(1+u^{2}\right)$, since convexity is invariant under horizontal and vertical scaling. We thus need to prove that</p>
<p>$$
\frac{d^{2} \rho(u)^{\gamma}}{d u^{2}}=-\frac{2 \gamma\left[\ln \left(1+u^{2}\right)\right]^{\gamma-2}}{\left(1+u^{2}\right)^{2}\left[2 u^{2}(1-\gamma)+\left(u^{2}-1\right) \ln \left(1+u^{2}\right)\right]}
$$</p>
<p>is positive when $u&gt;0$. The factor $\frac{-2 \gamma\left[\ln \left(1+u^{2}\right)\right]^{\gamma-2}}{\left(1+u^{2}\right)^{2}}$ is always positive. The other factor</p>
<p>$$
\begin{aligned}
&amp; 2 u^{2}(1-\gamma)+\left(u^{2}-1\right) \log \left(1+u^{2}\right)&gt;2 u^{2} \
&amp; \quad+\left(u^{2}-1\right) \log \left(1+u^{2}\right)
\end{aligned}
$$</p>
<p>since $\gamma&lt;0$. Now we only have to prove that the function</p>
<p>$$
\chi(u) \equiv 2 u^{2}+\left(u^{2}-1\right) \log \left(1+u^{2}\right)&gt;0
$$</p>
<p>when $u&gt;0$. We have $\chi(0)=0$ and</p>
<p>$$
\chi^{\prime}(u)=2 u\left[\frac{1+3 u^{2}}{1+u^{2}}+\log \left(1+u^{2}\right)\right]&gt;0
$$</p>
<p>when $u&gt;0$. Therefore $\chi(u)=\chi(0)+\int_{0}^{u} \chi^{\prime}\left(u^{\prime}\right) d u^{\prime}&gt;0$ when $u&gt;0$, which completes the proof that $\ell_{L_{d}, \epsilon}(u)^{\gamma}$ is strictly convex for $u&gt;0$.
(4) For the hard description length loss $\ell_{\mathrm{DLhard}, \epsilon}(u)=$ $\log <em 0="0">{2} \max \left(1, \frac{u}{\epsilon}\right)$, we have $u</em>&gt;0$ and}=\epsilon$. When $u&gt;\epsilon$, we have $\ell_{\mathrm{DLhard}, \epsilon}^{\gamma}(u)=\frac{1}{\sin 2</p>
<p>$$
\frac{d^{2} \ell_{\mathrm{DLhard}, \epsilon}^{\gamma}(u)}{d u^{2}}=\frac{\gamma}{\ln 2}\left(-1+\gamma-\ln \frac{u}{\epsilon}\right) \frac{\left(\ln \frac{u}{\epsilon}\right)^{\gamma-2}}{u^{2}}
$$</p>
<p>For $u&gt;\epsilon$, the factor $\frac{\left(\ln \frac{u}{\epsilon}\right)^{\gamma-2}}{u^{2}}$ is always positive, as is the factor $\gamma\left(-1+\gamma-\ln \frac{u}{\epsilon}\right)$, since $\gamma&lt;0 . \ell_{\mathrm{DLhard}, \epsilon}^{\gamma}(u)$ is therefore strictly convex for $u&gt;\epsilon$.</p>
<h2>APPENDIX H: ELIMINATING TRANSITION DOMAINS</h2>
<p>In this Appendix, we show how the only hard problem our AI physicist need solve is to determine the laws of motion far from domain boundaries, because once this is done, the exact boundaries and transition regions can be determined automatically.</p>
<p>Our AI physicist tries to predict the next position vector $\mathbf{y}<em t="t">{t} \in R^{d}$ from the concatenation $\mathbf{x}</em>}=\left(\mathbf{y<em t-1="t-1">{t-T}, \ldots, \mathbf{y}</em>}\right)$ of the last $T$ position vectors. Consider the example shown in Fig. 6, where motion is predicted from the last $T=3$ positions in a space with $d=2$ dimensions containing $n=2$ domains with different physics (an electromagnetic field in the upper left quadrant and free motion elsewhere), as well as perfectly reflective boundaries. Although there are only two physics domains in the 2-dimensional space, there are many more types of domains in the $T d=6$-dimensional space of $\mathbf{x<em t="t">{t}$ from which the AI physicist makes its predictions of $\mathbf{y}</em>}$. When a trajectory crosses the boundary between the two spatial regions, there can be instances where $\mathbf{x<em t="t">{t}$ contains $3,2,1$, or 0 points in the first domain and correspondingly $0,1,2$, or 3 points in the second domain. Similarly, when the ball bounces, there can be instances where $\mathbf{x}</em>}$ contains $3,2,1$, or 0 points before the bounce and correspondingly $0,1,2$, or 3 points after. Each of these situations involves a different function $\mathbf{x<em t="t">{t} \mapsto \mathbf{y}</em>$ and a corresponding 6 -dimensional domain of validity for the AI physicist to learn.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>FIG. 6. Points where forward and backward extrapolations agree (large black dots) are boundary points. The tangent vectors agree for region boundaries (upper example), but not for bounce boundaries (lower example).</p>
<p>Our numerical experiments showed that the AI physicist typically solves the big domains (where all vectors in <strong>x</strong><sub><em>i</em></sub> lie in the same spatial region), but occasionally fails to find an accurate solution in some of the many small transition domains involving boundary crossings or bounces, where data are insufficient. Fortunately, simple postprocessing can automatically eliminate these annoying transition domains with an algorithm that we will now describe.</p>
<p>The first step of the algorithm is illustrated in Fig. 6. For each big domain where our AI physicist has discovered the future-predicting function <strong>x</strong><sub><em>k</em></sub> ↦ <strong>y</strong><sub><em>i</em></sub>, we determine the corresponding function that predicts the <em>past</em> (<strong>x</strong><sub><em>i</em></sub> ↦ <strong>y</strong><sub><em>i</em></sub>, <em>t</em><sub><em>i</em></sub>, <em>t</em><sub><em>i</em></sub>) by fitting to forward trajectories generated with random initial conditions. Now whenever a trajectory passes from a big domain through a transition region into another big domain, two different extrapolations can be performed: forward in time from the first big domain or backward in time from the second big domain. Using cubic spline interpolation, we fit continuous functions <strong>y</strong><sub><em>f</em></sub>(<em>t</em>) and <strong>y</strong><sub><em>b</em></sub>(<em>t</em>) (smooth curves in Fig. 6) to these forward-extrapolated and backward-extrapolated trajectories, and numerically find the time</p>
<p>$$t_{\star} \equiv \arg\min \left| \mathbf{y}_f(t) - \mathbf{y}_b(t) \right| \tag{H1}$$</p>
<p>when the distance between the two predicted ball positions is minimized. If this minimum is numerically consistent with zero, so that <strong>y</strong><sub><em>f</em></sub>(<em>t</em><sub><em>a</em></sub>) ≈ <strong>y</strong><sub><em>b</em></sub>(<em>t</em><sub><em>a</em></sub>), then we record this as being a boundary point. If both extrapolations have the same derivative there, i.e., if <strong>y</strong><sub><em>f</em></sub>(<em>t</em><sub><em>a</em></sub>) ≈ <strong>y</strong><sub><em>b</em></sub>(<em>t</em><sub><em>a</em></sub>), then it is an interior boundary point between two different regions (Fig. 6, top); otherwise it is an external boundary point where the ball bounces (Fig. 6, bottom).</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>FIG. 7. Example of automatically determined boundary points, for region boundary points (green), bounce boundary points (black), and failed cases (red).</p>
<p>Figure 7 shows these two types of automatically computed boundary points in green and black, respectively. These can now be used to retrain the domain classifiers to extend the big domains to their full extent, eliminating the transition regions.</p>
<p>Occasionally the boundary point determinations will fail because of multiple transitions within <em>T</em> time steps; Fig. 7 illustrates that these failures (red dots) force us to discard merely a tiny fraction of all cases, thus having a negligible effect on the ability to fit for the domain boundaries.</p>
<h2>APPENDIX I: NUMERICAL EXPERIMENT DETAILS</h2>
<p>In this Appendix, we provide supplementary details on our benchmark problems.</p>
<h3>1. Mystery worlds</h3>
<p><em>World generation</em>. Our mystery worlds consist of a ball elastically bouncing against the square boundary of the two-dimensional spatial region where |<em>x</em>| ≤ 2 and |<em>y</em>| ≤ 2 (see Fig. 4). In each of the four quadrants, one of the following laws of physics is selected, together with the parameters sampled from distributions as follows:</p>
<ol>
<li>Free motion.</li>
<li>A uniform gravitational field <strong>g</strong> = (<em>g</em><sub><em>x</em></sub>, <em>g</em><sub><em>y</em></sub>, 0) with <em>g</em><sub><em>x</em></sub>, <em>g</em><sub><em>y</em></sub> drawn from a uniform distribution: <em>g</em><sub><em>x</em></sub>, <em>g</em><sub><em>y</em></sub> ∼ <em>U</em>[−5, 5].</li>
<li>Harmonic motion with frequency ω around a line a distance <em>a</em> from the origin, making an angle φ with the <em>x</em> axis; ω ∼ <em>U</em>[1, 4], <em>a</em> ∼ <em>U</em>[0.2, 0.5], φ ∼ <em>U</em>[0, 2π].</li>
<li>A uniform electric field <strong>E</strong> = (<em>E</em><sub><em>x</em></sub>, <em>E</em><sub><em>y</em></sub>, 0) and magnetic field <strong>B</strong> = (0, 0, <em>B</em><sub><em>z</em></sub>); <em>E</em><sub><em>x</em></sub>, <em>E</em><sub><em>y</em></sub> ∼ <em>U</em>[−5, 5], <em>B</em><sub><em>z</em></sub> ∼ <em>U</em>[0, 10].</li>
</ol>
<p>To control the difficulty of the tasks and avoid neardegenerate scenarios, we keep only mystery worlds satisfying the following two criteria: (1) At least 0.01 separation between all equations of motion (EOMs) in the same world, defined as the Euclidean distance between the vectors of coefficients specifying the EOM difference equations, and (2) at least 0.0015 of any noninteger parameter from its nearest integer.</p>
<p>Trajectory simulation. Within each world, we initialize the ball with a random position $(x, y) \sim U[-1,1]^{2}$ and velocity $\left(v_{0} \cos \theta_{0}, v_{0} \sin \theta_{0}, 0\right) ; v_{0} \sim U[0.1,0.5], \theta_{0} \sim U[0,2 \pi]$. We then compute its position for $N=4000$ times steps $t=$ $1,2, \ldots, N$ with time interval 0.05 .</p>
<p>Although the above-mentioned laws of physics are linear, the mapping from past points $\left(\mathbf{y}<em t-1="t-1">{t-T}, \ldots, \mathbf{y}</em>}\right)$ to the next points $\mathbf{y<em t-2="t-2">{t}$ is generally nonlinear because of region boundaries where the ball either bounces or transitions to a different physics region. An exception is when three successive points lie within the same region (with the same physics), which happens far from boundaries: in this case, the mapping from $\left(\mathbf{y}</em>}, \mathbf{y<em t="t">{t-1}\right) \mapsto \mathbf{y}</em>$ is deterministic and linear thanks to the differential equations of motion being second order and linear.</p>
<p>Architecture. For the newborn and AI physicist agents, each prediction function $\mathbf{f}<em _lay="{lay" _text="\text">{i}$ is implemented as an $N</em>=8$ neurons and leakyReLU activation. The last layer has linear activation. See Table V for a list of hyperparameters.}}^{f}$-layer neural network with linear activation, with $N_{\text {neur }}^{f}$-neuron hidden layers (we use $N_{\text {lay }}^{f}=3, N_{\text {neur }}^{f}=8$ for our main experiments; see Table V). Each domain subclassifier $c_{i}$ is implemented as an $N_{\text {lay }}^{c}$-layer neural net, with two hidden $N_{\text {neur }}^{c}$-neuron layers with leakyReLU activation $\sigma(x)=$ $\max {0.3 x, x}$, and the output layer having linear activation (we use $N_{\text {lay }}^{c}=3, N_{\text {neur }}^{c}=8$ for our main experiments). The baseline model is implemented as a single $N_{\text {lay }}^{f}$-layer neural net with two hidden 16 -neuron layers with leakyReLU activation followed by a linear output layer. Note that for a fair comparison, the baseline model has more hidden neurons, to roughly compensate for the newborn and AI physicist agents typically having multiple theories. The baseline network is nonlinear to boost its expressive power for modeling the nonlinear prediction function of each world as a whole. For the domain classifier $\mathbf{c}=\left(c_{1}, c_{2}, \ldots, c_{M}\right)$, it is an $N_{\text {lay }}^{c}$ layer neural net where each hidden layer has $N_{\text {neur }}^{c</p>
<p>Evaluation. The unsupervised classification accuracy is defined as the fraction of correctly classified points, using the permutation of the learned domain labels that best matches the hidden ground truth domain labels. It is "unsupervised" in the sense that there is no external supervision signal as to which domain label each point should be assigned to: the AI physicist has to figure out the number of domains and their boundaries and assign each point to a domain, which is a difficult task.</p>
<p>We define a domain as solved if the agent discovers its law of motion as a difference equation (prediction function) within the following stringent tolerance: all rational coefficients in the difference equation are exactly matched, and all irrational coefficients agree to an accuracy better than $10^{-4}$. Because of
the nature of the physics problems, some of these difference equation coefficients take on the values $0,-1$, or 2 , so solving a region requires successful integer snapping as described in Sec. II D. To make the problem even harder, we also fine-tune the magnetic field in five of the electromagnetic regions to make some of the coefficients simple fractions such as $1 / 3$ and $1 / 4$, thus making solving those regions contingent on successful rational snapping as described in Sec. II D. Domain solving can fail either by "undersnapping" (failing to approximate a floating-point number by a rational number) or "oversnapping" (mistakenly rounding to a rational number). All our mystery worlds are available for download [66].</p>
<p>As shown in Appendix H, the only hard problem our AI physicist or other algorithms need to solve is to determine the laws of motion away from domain boundaries. Therefore, we evaluate, tabulate, and compare the performance of the algorithms only on interior points, i.e., excluding data points $\left(\mathbf{x}<em t="t">{t}, \mathbf{y}</em>\right)$ straddling a boundary encounter.</p>
<h2>2. Double pendulum</h2>
<p>Our double pendulum is implemented as two connected pendulums with massless rods of length 1 and that each have a point charge of 1 at their end. As illustrated in Fig. 5, the system state is fully determined by the 4 -tuple $\mathbf{y}=\left(\theta_{1}, \dot{\theta}<em 2="2">{1}, \theta</em>}, \dot{\theta<em 1="1">{2}\right)$ and immersed in a piecewise constant electric field $\mathbf{E}: \mathbf{E}=$ $\left(0,-E</em>\right)$ in the lower half plane $y&lt;-1.05$, using coordinates where $y$ increases vertically and the origin is at the pivot point of the upper rod.}\right)$ in the upper half plane $y \geqslant-1.05$, and $\mathbf{E}=\left(0, E_{2</p>
<p>We generate 7 environments by setting $\left(E_{1}, E_{2}\right)$ equal to $\left(E_{0}, 2 E_{0}\right),\left(E_{0}, 1.5 E_{0}\right),\left(E_{0}, E_{0}\right),\left(E_{0}, 0.5 E_{0}\right),\left(2 E_{0}, E_{0}\right)$, $\left(1.5 E_{0}, E_{0}\right)$, and $\left(0.5 E_{0}, E_{0}\right)$, where $E_{0}=9.8$. We see that there are two different EOMs for the double-pendulum system depending on which of the two fields the lower charge is in (the upper charge is always in $E_{1}$ ). We use Runge-Kutta numerical integration to simulate $\mathbf{y}=\left(\theta_{1}, \dot{\theta}<em 2="2">{1}, \theta</em>}, \dot{\theta<em t_1="t+1">{2}\right)$ for 10000 time steps with interval of 0.05 , and the algorithms' task is to predict the future $\left(\mathbf{y}</em>}\right)$ based on the past $\left(\mathbf{x<em t="t">{t} \equiv \mathbf{y}</em>\right.$; history length $T=1$ ), and simultaneously discover the two domains and their different EOMs unsupervised.</p>
<p>In this experiment, we implement the prediction function of the baseline and newborn both as an $N_{\text {lay }}^{f}$-layer neural net (we use $N_{\text {lay }}^{f}=6$ ) during DDAC. For the newborn, each hidden layer has $N_{\text {neur }}^{f}=160$ neurons with hyperbolic tangent (tanh) activation, and for the baseline, each hidden layer has $N_{\text {neur }}^{f}=320$ neurons with tanh activation for a fair comparison. For the newborn, the optional AddTheories $(\mathcal{T}, D)$ (step s8 in Algorithm 2) is turned off to prevent unlimited adding of theories. The initial number $M$ of theories for the newborn is set to $M=2$ and $M=3$, each run with 10 instances with random initialization. Its domain classifier $\mathbf{c}=\left(c_{1}, c_{2}, \ldots, c_{M}\right)$ is an $N_{\text {lay }}^{c}$-layer neural net (we use $N_{\text {lay }}^{c}=3$ ) where each hidden layer has $N_{\text {neur }}^{c}=6$ neurons and leakyReLU activation. The last layer has linear activation.</p>
<p>[1] Y. LeCun, Y. Bengio, and G. Hinton, Nature (London) 521, 436 (2015).
[2] P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner et al., arXiv:1806.01261.
[3] S. Russell, D. Dewey, and M. Tegmark, AI Magazine 36, 105 (2015).
[4] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Mané, arXiv:1606.06565.
[5] M. Boden, J. Bryson, D. Caldwell, K. Dautenhahn, L. Edwards, S. Kember, P. Newman, V. Parry, G. Pegman, T. Rodden et al., Connection Sci. 29, 124 (2017).
[6] V. Krakovna and F. Doshi-Velez, arXiv:1606.05320.
[7] V. C. Müller and N. Bostrom, Fundamental Issues of Artificial Intelligence (Springer, Berlin, 2016), pp. 555-572.
[8] K. Grace, J. Salvatier, A. Dafoe, B. Zhang, and O. Evans, J. Artif. Intell. Res. 62, 729 (2018).
[9] A. Graves, G. Wayne, and I. Danihelka, arXiv:1410.5401.
[10] S. Sukhbaatar, A. Szlam, J. Weston, and R. Fergus, in Advances in Neural Information Processing Systems 28, edited by C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett (Curran Associates, Inc., 2015), pp. 24402448.
[11] S. Reed and N. De Freitas, arXiv:1511.06279.
[12] E. Parisotto, A.-R. Mohamed, R. Singh, L. Li, D. Zhou, and P. Kohli, arXiv:1611.01855.
[13] J. Devlin, J. Uesato, S. Bhupatiraju, R. Singh, A.-R. Mohamed, and P. Kohli, arXiv:1703.07469.
[14] N. Bramley, E. Schulz, F. Xu, and J. Tenenbaum (unpublished).
[15] S. Muggleton, New Generation Comp. 8, 295 (1991).
[16] N. Lavrac and S. Dzeroski, Workshop on Logic Programming (WLP) (Springer, Berlin, 1994), pp. 146-160.
[17] P. Liang, M. I. Jordan, and D. Klein, in Proceedings of the 27th International Conference on Machine Learning (ICML-10) (International Machine Learning Society, 2010), pp. 639-646.
[18] K. Ellis, A. Solar-Lezama, and J. Tenenbaum, in Advances in Neural Information Processing Systems 28 (Ref. [10]), pp. 973981.
[19] E. Dechter, J. Malmaud, R. P. Adams, and J. B. Tenenbaum, in Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI-13) (AAAI Press, 2013), pp. 1302-1309.
[20] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to Algorithms (MIT Press, 2009).
[21] J. Fürnkranz, Artif. Intell. Rev. 13, 3 (1999).
[22] D. Ghosh, A. Singh, A. Rajeswaran, V. Kumar, and S. Levine, arXiv:1711.09874.
[23] J. Rissanen, Automatica 14, 465 (1978).
[24] B. Hassibi and D. G. Stork, in Advances in Neural Information Processing Systems 5 (NIPS 1992), edited by S. J. Hanson, J. D. Cowan, and C. L. Giles (Morgan-Kaufmann, 1993), pp. 164171.
[25] K. Suzuki, I. Horiba, and N. Sugie, Neural Proc. Lett. 13, 43 (2001).
[26] P. D. Grünwald, I. J. Myung, and M. A. Pitt, Advances in Minimum Description Length: Theory and Applications (MIT Press, 2005).
[27] S. Han, H. Mao, and W. J. Dally, arXiv:1510.00149.
[28] S. Han, J. Pool, J. Tran, and W. Dally, Advances in Neural Information Processing Systems (NIPS 2015) (MIT Press, 2015), pp. 1135-1143.
[29] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska et al., Proc. Natl. Acad. Sci. USA 114, 3521 (2017).
[30] Z. Li and D. Hoiem, IEEE Trans. Pattern Anal. Mach. Int. 40, 2935 (2018).
[31] D. Lopez-Paz and M. A. Ranzato, in Advances in Neural Information Processing Systems 30 (NIPS 2017), edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Curran Associates, Inc., 2017), pp. 6467-6476.
[32] C. V. Nguyen, Y. Li, T. D. Bui, and R. E. Turner, arXiv:1710.10628.
[33] I. Yildirim, K. A. Smith, M. Belledonne, J. Wu, and J. B. Tenenbaum, in 2nd Conference on Cognitive Computational Neuroscience (CCN, 2018).
[34] D. Zheng, V. Luo, J. Wu, and J. B. Tenenbaum, arXiv:1807.09244.
[35] P. Battaglia, R. Pascanu, M. Lai, D. J. Rezende, and k. kavukcuoglu, in Advances in Neural Information Processing Systems 29 (NIPS 2016), edited by D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (Curran Associates, Inc., 2016), pp. 4502-4510.
[36] M. B. Chang, T. Ullman, A. Torralba, and J. B. Tenenbaum, arXiv:1612.00341.
[37] N. Watters, D. Zoran, T. Weber, P. Battaglia, R. Pascanu, and A. Tacchetti, in Advances in Neural Information Processing Systems 30 (NIPS 2017), edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Curran Associates, Inc., 2017), pp. 4539-4547.
[38] R. Iten, T. Mørger, H. Wilming, L. Del Rio, and R. Renner, arXiv:1807.10300.
[39] B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman, Behavioral Brain Sci. 40, e253 (2017).
[40] B. C. Daniels and I. Nemenman, Nat. Commun. 6, 8133 (2015).
[41] S. Džeroski, P. Langley, and L. Todorovski, in Computational Discovery of Scientific Knowledge: Introduction, Techniques, and Applications in Environmental and Life Sciences, edited by S. Džeroski and L. Todorovski (Springer, Berlin Heidelberg, 2007), pp. 1-14.
[42] P. Langley, Cognitive Science 5, 31 (1981).
[43] P. Langley and J. M. Zytkow, Artificial Intelligence 40, 283 (1989).
[44] S. Dzeroski and L. Todorovski, J. Intell. Inf. Syst. 4, 89 (1995).
[45] E. Bradley, M. Easley, and R. Stolle, Artificial Intelligence 133, 139 (2001).
[46] P. Langley, D. George, S. and Bay, and K. Saito, in Proceedings of the Twentieth International Conference on International Conference on Machine Learning (AAAI Press, Washington, DC, USA, 2003), pp. 432-439.
[47] P. Langley and A. Arvay, Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI Press, Washington, DC, USA, 2005).
[48] Y. Freund and R. E. Schapire, J. Comput. Syst. Sci. 55, 119 (1997).</p>
<p>[49] R. J. Solomonoff, Inf. Cont. 7, 1 (1964).
[50] M. Hutter, arXiv:cs/0004001.
[51] J. Rissanen, Annals Stat. 11, 416 (1983).
[52] G. E. Hinton and D. van Camp, in Proceedings of the Sixth Annual Conference on Computational Learning Theory (ACM, New York, 1993), pp. 5-13.
[53] L. Blier and Y. Ollivier (unpublished).
[54] E. Real, S. Moore, A. Selle, S. Saxena, Y. L. Suematsu, J. Tan, Q. Le, and A. Kurakin, arXiv:1703.01041.
[55] B. Zoph and Q. V. Le, arXiv:1611.01578.
[56] B. Baker, O. Gupta, N. Naik, and R. Raskar, arXiv:1611.02167.
[57] M. Schmidt and H. Lipson, Science 324, 81 (2009).
[58] S.-M. Udrescu and M. Tegmark, arXiv:1905.11481.
[59] J. Carrasquilla, G. Torlai, R. G. Melko, and L. Aolita, Nat. Mach. Intell. 1, 155 (2019).
[60] J. Carrasquilla and R. G. Melko, Nat. Phys. 13, 431 (2017).
[61] L. Wang, Phys. Rev. B 94, 195105 (2016).
[62] E. P. Van Nieuwenburg, Y.-H. Liu, and S. D. Huber, Nat. Phys. 13, 435 (2017).
[63] C. Lam and D. Kipping, Mon. Not. R. Astron. Soc. 476, 5692 (2018).
[64] P. Baldi, P. Sadowski, and D. Whiteson, Nat. Commun. 5, 4308 (2014).
[65] D. P. Kingma and J. Ba, arXiv:1412.6980.
[66] See http://space.mit.edu/home/tegmark/aiphysicist.html.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*tailin@mit.edu&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>