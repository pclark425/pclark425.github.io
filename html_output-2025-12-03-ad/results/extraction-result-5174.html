<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5174 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5174</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5174</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-214605613</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2003.08978v2.pdf" target="_blank">Generating new concepts with hybrid neuro-symbolic models</a></p>
                <p><strong>Paper Abstract:</strong> Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5174.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5174.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Full NS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Full Neuro-Symbolic model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid generative model that represents characters as symbolic, compositional programs (sequences of strokes) while using neural networks to model complex conditional distributions over stroke locations and trajectories; sampling proceeds one stroke at a time with a symbolic renderer updating an image 'canvas' memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Neuro-symbolic hybrid (program + distributed components)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented functionally as explicit compositional procedures (a program that sequences parts/strokes and relations) together with learned distributed conditional components that supply rich, nonparametric statistical detail for parts; a symbolic renderer enforces the causal mapping from motor/stroke program to visual outcome.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Hybrid: symbolic/procedural + distributed statistical components</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Compositional (parts/strokes as program steps), causal (explicit rendering step from stroke program to image), modular (separate location, stroke, termination modules), constrained inter-part information flow via image-canvas memory, probabilistic (GMM outputs for stochasticity).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>In this paper the Full NS model achieves the best log-likelihoods on held-out characters when test characters come from novel alphabets (alphabet-splits and held-out evaluation set), and its samples are qualitatively more structurally coherent and less frequently direct copies of training exemplars (fewer nearest-neighbor matches) than purely neural alternatives and BPL samples.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>The paper notes that the model does not allow arbitrary information flow between parts (a design tradeoff), and while it captures richer correlations than BPL it still imposes structural constraints that might limit capture of some patterns; computational/hyperparameter choices and reliance on spline preprocessing are additional practical limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Generative concept synthesis (new handwritten characters), few-shot generalization contexts (modeling human-like concept generation), qualitative sample generation and likelihood scoring on held-out concept classes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Outperforms purely neural H-LSTM and Baseline LSTM on generalization to novel alphabets; captures more correlated, complex visual detail than BPL while retaining compositional/causal structure that pure neural models lack; trades off expressive arbitrary connectivity for explicit causal compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Sequential program-like sampling of strokes: at each step a CNN-based location module predicts p(y|canvas), an LSTM stroke module with attention predicts auto-regressive stroke deltas p(x|y,canvas), a symbolic renderer draws the stroke to update the canvas, and a termination module decides when to stop; stochasticity realized via GMM outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How far this hybrid constraint (limited inter-part information flow) scales to more complex concepts; whether the design choices (renderer, spline preprocessing, GMM parametrization) bias or limit types of generalization; integration with richer symbolic priors or fully nonparametric part reuse remains to be explored.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5174.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>H-LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hierarchical LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical recurrent neural architecture that models characters as sequences of strokes where each stroke is encoded (bi-LSTM) and a higher-level character LSTM conditions the next-stroke location and stroke generator; no explicit renderer is used.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Hierarchical distributed sequence representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual structure is captured functionally by distributed hierarchical temporal representations: stroke-level encodings feed a character-level recurrent memory that generates subsequent strokes, so compositionality is implemented implicitly via learned hierarchical sequence encoding rather than explicit symbolic programs.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Distributed hierarchical recurrent representation</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Implicit compositionality via hierarchy (stroke encoder + character LSTM), flexible learned correlations across parts via recurrent connections and gating, end-to-end differentiable, no explicit causal renderer.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>In the paper H-LSTM can produce reasonably structured samples and sometimes performs competitively, but it generally underperforms the Full NS model on alphabet-splits and held-out novel alphabets.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Lacks explicit causal (motor-to-image) modeling—must learn transformations entirely from data; may require more data to capture structural constraints and can propagate arbitrary correlations that are not grounded in generative causality.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Generative stroke-wise sequence modeling of drawings/handwriting, intermediate between fully flat sequence models and neuro-symbolic program models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More structured than Baseline LSTM because of explicit stroke-level encoding, but less constrained and less causally grounded than Full NS; tends to capture correlations but not the explicit compositional causal knowledge of the neuro-symbolic model.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Stroke encoder (bi-LSTM) produces fixed vector per stroke; character LSTM integrates previous location and encoded stroke to predict next stroke location (GMM) and stroke generator (LSTM) outputs deltas sequentially (GMM), all learned end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to incorporate explicit causal rendering or symbolic constraints without losing the flexibility of learned distributed representations; sensitivity to hyperparameters and data regime for capturing compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5174.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baseline (unrolled) LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A single flat recurrent neural network (Sketch-RNN style) that models an entire character as one long sequence of pen actions (offsets and pen states) with GMM mixture outputs, without explicit stroke-level modularity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Flat sequential distributed representation (exemplar-like behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are functionally encoded as high-dimensional temporal trajectories in an RNN hidden state; generalization arises from sequence modeling of observed trajectories and is primarily exemplar- and pattern-based rather than compositional-programmatic.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Distributed sequential (instance/trajectory-based)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>No explicit compositional or causal structure beyond sequence order, learns statistical sequence regularities, can memorize exemplars, uses GMM outputs for stochastic generation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>In this paper Baseline LSTM performs best on the easier character-splits (new characters from familiar alphabets) in 2/3 splits and its generated samples often closely mirror nearest training examples, suggesting strong exemplar/instance-based generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Performs worse than Full NS on alphabet-splits and held-out novel alphabets; tends to produce samples that are near-memorized exemplars and generalizes poorly to systematic variations that require compositional knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Sequence generation of sketches/drawings when large within-class data exists; modeling of instance-based generation and trajectory prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Less structured than H-LSTM and Full NS; better at exemplar-style interpolation among familiar-styles but worse at compositional extrapolation to novel alphabets; easier to train but limited in creativity/generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Single LSTM unrolled over entire stroke-offset + pen-state sequence; outputs GMM for offsets and categorical for pen-state at each time step; stochastic sampling yields generated trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Extent to which memory-based/exemplar mechanisms in RNNs correspond to explicit exemplar models in cognition; how to endow such models with more compositional inductive biases without losing their ability to capture fine-grained correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5174.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BPL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Program Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic program induction framework that represents concepts as generative symbolic programs (composition of strokes/parts and motor primitives) and performs Bayesian inference over these program hypotheses to account for few-shot concept learning and generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Human-level concept learning through probabilistic program induction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Program-based symbolic representation / probabilistic language of thought</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented as symbolic generative programs that specify parts, causal/stochastic motor procedures, and composition rules; learning is Bayesian inference over program space guided by strong structured priors.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Symbolic programmatic representation (probabilistic)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Strong compositionality, explicit causal structure, part reuse, interpretable generative programs, strong inductive biases enabling powerful extrapolation from few examples.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Prior work (Lake et al., 2015) shows BPL accounts for human-level few-shot learning on Omniglot; in this paper BPL samples provide structured, interpretable character variants and were used as a qualitative baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>The paper highlights that BPL's parametric assumptions (e.g., approximate independence of strokes in the prior) can limit capturing the rich, nonparametric correlations and visual invariances present in real human drawings; computational cost and hand-designed primitives are additional limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Few-shot concept learning, generative modeling of handwritten characters, interpretable program induction for visual concepts and compositional generalization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides stronger compositional/causal inductive bias than purely statistical neural models but is less able to capture complex correlational structure in raw high-dimensional stimuli; Full NS aims to combine BPL's compositionality with neural networks' statistical power.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Represents concepts as stochastic programs that emit parts/strokes; Bayesian inference selects and composes program fragments to explain observed exemplars; can sample from program priors to generate novel concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Scalability to highly-detailed, high-dimensional concept spaces without strong parametric simplifications; how to integrate nonparametric correlation models while preserving programmatic compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5174.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory / Intuitive theories (structured knowledge)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cognitive account that concepts are embedded in domain-specific intuitive theories—structured, causal models that explain and organize conceptual knowledge (e.g., roles, causal relations, hierarchies).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The role of theories in conceptual coherence</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory-theory / intuitive theories</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, conceptual knowledge is organized as structured causal theories that specify relations among properties and categories; concepts gain meaning through their place in these explanatory frameworks rather than solely from statistical co-occurrence.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Theory-based symbolic/relational representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Causality, explanatory structure, role-based relations, hierarchical organization, supports strong inductive inferences and systematic generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Classic cognitive work (cited) shows humans use theory-like causal knowledge to make category judgments and inferences; program-based models (e.g., BPL) operationalize this approach and reproduce human-like few-shot learning behavior on Omniglot in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper notes that theory-like/symbolic models can be rigid and may make simplifying parametric assumptions that struggle to capture richly varying correlations in raw sensory data unless augmented with statistical components.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Concept learning, causal reasoning, category-based inference, explaining exceptions and substitutions (e.g., in recipe analogies), and few-shot generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasts with purely statistical/distributed views: theory-theory emphasizes explicit causal structure and compositional rules, trading off flexibility in capturing low-level statistical regularities unless combined with statistical modules.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Concept formation and use involve constructing/using causal models and symbolic rules to predict and explain observations; learning selects structured hypotheses (theories) that best explain data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to combine rich, low-level correlational learning with high-level theory structures; how much structure is innate vs. learned from limited data remains debated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5174.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Statistical / Distributed</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Statistical / distributed representations (neural-network emergent view)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A view that conceptual knowledge emerges from distributed, high-dimensional representations learned from statistical regularities in sensory/linguistic input (e.g., embeddings, latent codes), typically realized via neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergence in Cognitive Science</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Statistical/distributed (emergent) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are functionally encoded as patterns of activation across many units (distributed vectors), with meaning arising from co-occurrence statistics and learned mappings rather than explicit symbolic programs; composition and generalization emerge from interactions among units.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Distributed, emergent feature-based or latent-vector representations</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Captures complex correlations and invariances, scalable to high-dimensional raw inputs, flexible and data-driven, often lacks explicit compositional causal structure, supports interpolation and pattern completion.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Neural generative models (H-LSTM, Baseline LSTM, and other cited models like Sketch-RNN) capture rich correlational structure and produce visually complex samples; in the paper distributed models reproduce details of handwriting styles and can achieve high likelihoods within familiar domains.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper and cited critiques (Marcus 2003, Lake & Baroni 2018) note systematic generalization and compositionality failures—purely statistical models can struggle when tasks require strong causal/compositional inductive biases and extrapolation to novel structured variations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Representation learning, generative modeling (sketch/drawing generation), classification from high-dimensional inputs, capturing style and correlated structure in data-rich regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Stronger at modeling raw sensory correlations than symbolic/programmatic models, but weaker at systematic compositional extrapolation and causal interpretations; motivates hybrid neuro-symbolic approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Learning via gradient-based optimization of neural networks to map inputs to latent vectors and to learn conditional generation distributions (e.g., GMM outputs), with composition implemented implicitly through learned weights and recurrent dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to endow distributed models with systematic compositionality and causal interpretability without sacrificing their capacity to model rich statistical regularities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5174.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5174.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar / instance-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational hypothesis that concepts are functionally constituted by stored exemplars (individual instances), with categorization and generation arising through similarity-based retrieval and transformation of those exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>At the functional level, conceptual knowledge is a memory of individual exemplars; new instances are generated or classified by comparing to and interpolating among stored exemplars according to a perceptual similarity metric.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Instance-based (store & similarity-retrieve)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Memory-heavy, similarity-driven, good at within-domain interpolation, minimal compositional structure, straightforward explanation for nearest-neighbor-like generation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>In this paper the Baseline LSTM appears to behave exemplar-like: produced samples often match nearest training examples and the model performs well on character-splits (novel characters from familiar alphabets), consistent with exemplar interpolation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Exemplar-like behavior fails to account for compositional extrapolation to novel alphabets and systematic creative generation observed in human concept creation; does not naturally explain causal/part-based generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Within-class generalization, memory-based categorization, nearest-neighbor retrieval analyses, modeling exemplar effects in human judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Simpler and more data-intensive than program/symbolic models; complementary to distributed neural models that may implicitly memorize exemplars; contrasted with theory/program-based models that explain composition and causal substitution.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Storage of individual exemplars in a similarity space; retrieval and weighted combination based on distance metrics (here operationalized via nearest-neighbor in CNN embedding used for analyses).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exemplar storage scales and how exemplars can be recombined compositionally to produce genuinely novel structured concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Human-level concept learning through probabilistic program induction <em>(Rating: 2)</em></li>
                <li>The role of theories in conceptual coherence <em>(Rating: 2)</em></li>
                <li>How to grow a mind: Statistics, structure, and abstraction <em>(Rating: 2)</em></li>
                <li>Emergence in Cognitive Science <em>(Rating: 2)</em></li>
                <li>The Algebraic Mind: Integrating Connectionism and Cognitive Science <em>(Rating: 2)</em></li>
                <li>A neural representation of sketch drawings <em>(Rating: 1)</em></li>
                <li>Generating sequences with recurrent neural networks <em>(Rating: 1)</em></li>
                <li>Concepts in a probabilistic language of thought <em>(Rating: 2)</em></li>
                <li>Indexing by latent semantic analysis <em>(Rating: 1)</em></li>
                <li>The logical primitives of thought: Empirical foundations for compositional cognitive models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5174",
    "paper_id": "paper-214605613",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Full NS",
            "name_full": "Full Neuro-Symbolic model",
            "brief_description": "A hybrid generative model that represents characters as symbolic, compositional programs (sequences of strokes) while using neural networks to model complex conditional distributions over stroke locations and trajectories; sampling proceeds one stroke at a time with a symbolic renderer updating an image 'canvas' memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Neuro-symbolic hybrid (program + distributed components)",
            "theory_or_model_description": "Concepts are represented functionally as explicit compositional procedures (a program that sequences parts/strokes and relations) together with learned distributed conditional components that supply rich, nonparametric statistical detail for parts; a symbolic renderer enforces the causal mapping from motor/stroke program to visual outcome.",
            "representation_format_type": "Hybrid: symbolic/procedural + distributed statistical components",
            "key_properties": "Compositional (parts/strokes as program steps), causal (explicit rendering step from stroke program to image), modular (separate location, stroke, termination modules), constrained inter-part information flow via image-canvas memory, probabilistic (GMM outputs for stochasticity).",
            "empirical_support": "In this paper the Full NS model achieves the best log-likelihoods on held-out characters when test characters come from novel alphabets (alphabet-splits and held-out evaluation set), and its samples are qualitatively more structurally coherent and less frequently direct copies of training exemplars (fewer nearest-neighbor matches) than purely neural alternatives and BPL samples.",
            "empirical_challenges": "The paper notes that the model does not allow arbitrary information flow between parts (a design tradeoff), and while it captures richer correlations than BPL it still imposes structural constraints that might limit capture of some patterns; computational/hyperparameter choices and reliance on spline preprocessing are additional practical limitations.",
            "applied_domains_or_tasks": "Generative concept synthesis (new handwritten characters), few-shot generalization contexts (modeling human-like concept generation), qualitative sample generation and likelihood scoring on held-out concept classes.",
            "comparison_to_other_models": "Outperforms purely neural H-LSTM and Baseline LSTM on generalization to novel alphabets; captures more correlated, complex visual detail than BPL while retaining compositional/causal structure that pure neural models lack; trades off expressive arbitrary connectivity for explicit causal compositionality.",
            "functional_mechanisms": "Sequential program-like sampling of strokes: at each step a CNN-based location module predicts p(y|canvas), an LSTM stroke module with attention predicts auto-regressive stroke deltas p(x|y,canvas), a symbolic renderer draws the stroke to update the canvas, and a termination module decides when to stop; stochasticity realized via GMM outputs.",
            "limitations_or_open_questions": "How far this hybrid constraint (limited inter-part information flow) scales to more complex concepts; whether the design choices (renderer, spline preprocessing, GMM parametrization) bias or limit types of generalization; integration with richer symbolic priors or fully nonparametric part reuse remains to be explored.",
            "uuid": "e5174.0",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "H-LSTM",
            "name_full": "Hierarchical LSTM",
            "brief_description": "A hierarchical recurrent neural architecture that models characters as sequences of strokes where each stroke is encoded (bi-LSTM) and a higher-level character LSTM conditions the next-stroke location and stroke generator; no explicit renderer is used.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Hierarchical distributed sequence representation",
            "theory_or_model_description": "Conceptual structure is captured functionally by distributed hierarchical temporal representations: stroke-level encodings feed a character-level recurrent memory that generates subsequent strokes, so compositionality is implemented implicitly via learned hierarchical sequence encoding rather than explicit symbolic programs.",
            "representation_format_type": "Distributed hierarchical recurrent representation",
            "key_properties": "Implicit compositionality via hierarchy (stroke encoder + character LSTM), flexible learned correlations across parts via recurrent connections and gating, end-to-end differentiable, no explicit causal renderer.",
            "empirical_support": "In the paper H-LSTM can produce reasonably structured samples and sometimes performs competitively, but it generally underperforms the Full NS model on alphabet-splits and held-out novel alphabets.",
            "empirical_challenges": "Lacks explicit causal (motor-to-image) modeling—must learn transformations entirely from data; may require more data to capture structural constraints and can propagate arbitrary correlations that are not grounded in generative causality.",
            "applied_domains_or_tasks": "Generative stroke-wise sequence modeling of drawings/handwriting, intermediate between fully flat sequence models and neuro-symbolic program models.",
            "comparison_to_other_models": "More structured than Baseline LSTM because of explicit stroke-level encoding, but less constrained and less causally grounded than Full NS; tends to capture correlations but not the explicit compositional causal knowledge of the neuro-symbolic model.",
            "functional_mechanisms": "Stroke encoder (bi-LSTM) produces fixed vector per stroke; character LSTM integrates previous location and encoded stroke to predict next stroke location (GMM) and stroke generator (LSTM) outputs deltas sequentially (GMM), all learned end-to-end.",
            "limitations_or_open_questions": "How to incorporate explicit causal rendering or symbolic constraints without losing the flexibility of learned distributed representations; sensitivity to hyperparameters and data regime for capturing compositional generalization.",
            "uuid": "e5174.1",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Baseline LSTM",
            "name_full": "Baseline (unrolled) LSTM",
            "brief_description": "A single flat recurrent neural network (Sketch-RNN style) that models an entire character as one long sequence of pen actions (offsets and pen states) with GMM mixture outputs, without explicit stroke-level modularity.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Flat sequential distributed representation (exemplar-like behavior)",
            "theory_or_model_description": "Concepts are functionally encoded as high-dimensional temporal trajectories in an RNN hidden state; generalization arises from sequence modeling of observed trajectories and is primarily exemplar- and pattern-based rather than compositional-programmatic.",
            "representation_format_type": "Distributed sequential (instance/trajectory-based)",
            "key_properties": "No explicit compositional or causal structure beyond sequence order, learns statistical sequence regularities, can memorize exemplars, uses GMM outputs for stochastic generation.",
            "empirical_support": "In this paper Baseline LSTM performs best on the easier character-splits (new characters from familiar alphabets) in 2/3 splits and its generated samples often closely mirror nearest training examples, suggesting strong exemplar/instance-based generalization.",
            "empirical_challenges": "Performs worse than Full NS on alphabet-splits and held-out novel alphabets; tends to produce samples that are near-memorized exemplars and generalizes poorly to systematic variations that require compositional knowledge.",
            "applied_domains_or_tasks": "Sequence generation of sketches/drawings when large within-class data exists; modeling of instance-based generation and trajectory prediction.",
            "comparison_to_other_models": "Less structured than H-LSTM and Full NS; better at exemplar-style interpolation among familiar-styles but worse at compositional extrapolation to novel alphabets; easier to train but limited in creativity/generalization.",
            "functional_mechanisms": "Single LSTM unrolled over entire stroke-offset + pen-state sequence; outputs GMM for offsets and categorical for pen-state at each time step; stochastic sampling yields generated trajectories.",
            "limitations_or_open_questions": "Extent to which memory-based/exemplar mechanisms in RNNs correspond to explicit exemplar models in cognition; how to endow such models with more compositional inductive biases without losing their ability to capture fine-grained correlations.",
            "uuid": "e5174.2",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "BPL",
            "name_full": "Bayesian Program Learning",
            "brief_description": "A probabilistic program induction framework that represents concepts as generative symbolic programs (composition of strokes/parts and motor primitives) and performs Bayesian inference over these program hypotheses to account for few-shot concept learning and generation.",
            "citation_title": "Human-level concept learning through probabilistic program induction",
            "mention_or_use": "use",
            "theory_or_model_name": "Program-based symbolic representation / probabilistic language of thought",
            "theory_or_model_description": "Concepts are represented as symbolic generative programs that specify parts, causal/stochastic motor procedures, and composition rules; learning is Bayesian inference over program space guided by strong structured priors.",
            "representation_format_type": "Symbolic programmatic representation (probabilistic)",
            "key_properties": "Strong compositionality, explicit causal structure, part reuse, interpretable generative programs, strong inductive biases enabling powerful extrapolation from few examples.",
            "empirical_support": "Prior work (Lake et al., 2015) shows BPL accounts for human-level few-shot learning on Omniglot; in this paper BPL samples provide structured, interpretable character variants and were used as a qualitative baseline.",
            "empirical_challenges": "The paper highlights that BPL's parametric assumptions (e.g., approximate independence of strokes in the prior) can limit capturing the rich, nonparametric correlations and visual invariances present in real human drawings; computational cost and hand-designed primitives are additional limitations.",
            "applied_domains_or_tasks": "Few-shot concept learning, generative modeling of handwritten characters, interpretable program induction for visual concepts and compositional generalization tasks.",
            "comparison_to_other_models": "Provides stronger compositional/causal inductive bias than purely statistical neural models but is less able to capture complex correlational structure in raw high-dimensional stimuli; Full NS aims to combine BPL's compositionality with neural networks' statistical power.",
            "functional_mechanisms": "Represents concepts as stochastic programs that emit parts/strokes; Bayesian inference selects and composes program fragments to explain observed exemplars; can sample from program priors to generate novel concepts.",
            "limitations_or_open_questions": "Scalability to highly-detailed, high-dimensional concept spaces without strong parametric simplifications; how to integrate nonparametric correlation models while preserving programmatic compositionality.",
            "uuid": "e5174.3",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Theory-Theory",
            "name_full": "Theory-theory / Intuitive theories (structured knowledge)",
            "brief_description": "A cognitive account that concepts are embedded in domain-specific intuitive theories—structured, causal models that explain and organize conceptual knowledge (e.g., roles, causal relations, hierarchies).",
            "citation_title": "The role of theories in conceptual coherence",
            "mention_or_use": "mention",
            "theory_or_model_name": "Theory-theory / intuitive theories",
            "theory_or_model_description": "Functionally, conceptual knowledge is organized as structured causal theories that specify relations among properties and categories; concepts gain meaning through their place in these explanatory frameworks rather than solely from statistical co-occurrence.",
            "representation_format_type": "Theory-based symbolic/relational representations",
            "key_properties": "Causality, explanatory structure, role-based relations, hierarchical organization, supports strong inductive inferences and systematic generalization.",
            "empirical_support": "Classic cognitive work (cited) shows humans use theory-like causal knowledge to make category judgments and inferences; program-based models (e.g., BPL) operationalize this approach and reproduce human-like few-shot learning behavior on Omniglot in prior work.",
            "empirical_challenges": "Paper notes that theory-like/symbolic models can be rigid and may make simplifying parametric assumptions that struggle to capture richly varying correlations in raw sensory data unless augmented with statistical components.",
            "applied_domains_or_tasks": "Concept learning, causal reasoning, category-based inference, explaining exceptions and substitutions (e.g., in recipe analogies), and few-shot generalization.",
            "comparison_to_other_models": "Contrasts with purely statistical/distributed views: theory-theory emphasizes explicit causal structure and compositional rules, trading off flexibility in capturing low-level statistical regularities unless combined with statistical modules.",
            "functional_mechanisms": "Concept formation and use involve constructing/using causal models and symbolic rules to predict and explain observations; learning selects structured hypotheses (theories) that best explain data.",
            "limitations_or_open_questions": "How to combine rich, low-level correlational learning with high-level theory structures; how much structure is innate vs. learned from limited data remains debated.",
            "uuid": "e5174.4",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Statistical / Distributed",
            "name_full": "Statistical / distributed representations (neural-network emergent view)",
            "brief_description": "A view that conceptual knowledge emerges from distributed, high-dimensional representations learned from statistical regularities in sensory/linguistic input (e.g., embeddings, latent codes), typically realized via neural networks.",
            "citation_title": "Emergence in Cognitive Science",
            "mention_or_use": "mention",
            "theory_or_model_name": "Statistical/distributed (emergent) representation",
            "theory_or_model_description": "Concepts are functionally encoded as patterns of activation across many units (distributed vectors), with meaning arising from co-occurrence statistics and learned mappings rather than explicit symbolic programs; composition and generalization emerge from interactions among units.",
            "representation_format_type": "Distributed, emergent feature-based or latent-vector representations",
            "key_properties": "Captures complex correlations and invariances, scalable to high-dimensional raw inputs, flexible and data-driven, often lacks explicit compositional causal structure, supports interpolation and pattern completion.",
            "empirical_support": "Neural generative models (H-LSTM, Baseline LSTM, and other cited models like Sketch-RNN) capture rich correlational structure and produce visually complex samples; in the paper distributed models reproduce details of handwriting styles and can achieve high likelihoods within familiar domains.",
            "empirical_challenges": "Paper and cited critiques (Marcus 2003, Lake & Baroni 2018) note systematic generalization and compositionality failures—purely statistical models can struggle when tasks require strong causal/compositional inductive biases and extrapolation to novel structured variations.",
            "applied_domains_or_tasks": "Representation learning, generative modeling (sketch/drawing generation), classification from high-dimensional inputs, capturing style and correlated structure in data-rich regimes.",
            "comparison_to_other_models": "Stronger at modeling raw sensory correlations than symbolic/programmatic models, but weaker at systematic compositional extrapolation and causal interpretations; motivates hybrid neuro-symbolic approaches.",
            "functional_mechanisms": "Learning via gradient-based optimization of neural networks to map inputs to latent vectors and to learn conditional generation distributions (e.g., GMM outputs), with composition implemented implicitly through learned weights and recurrent dynamics.",
            "limitations_or_open_questions": "How to endow distributed models with systematic compositionality and causal interpretability without sacrificing their capacity to model rich statistical regularities.",
            "uuid": "e5174.5",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Exemplar model",
            "name_full": "Exemplar / instance-based representation",
            "brief_description": "A representational hypothesis that concepts are functionally constituted by stored exemplars (individual instances), with categorization and generation arising through similarity-based retrieval and transformation of those exemplars.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar-based representation",
            "theory_or_model_description": "At the functional level, conceptual knowledge is a memory of individual exemplars; new instances are generated or classified by comparing to and interpolating among stored exemplars according to a perceptual similarity metric.",
            "representation_format_type": "Instance-based (store & similarity-retrieve)",
            "key_properties": "Memory-heavy, similarity-driven, good at within-domain interpolation, minimal compositional structure, straightforward explanation for nearest-neighbor-like generation.",
            "empirical_support": "In this paper the Baseline LSTM appears to behave exemplar-like: produced samples often match nearest training examples and the model performs well on character-splits (novel characters from familiar alphabets), consistent with exemplar interpolation.",
            "empirical_challenges": "Exemplar-like behavior fails to account for compositional extrapolation to novel alphabets and systematic creative generation observed in human concept creation; does not naturally explain causal/part-based generalization.",
            "applied_domains_or_tasks": "Within-class generalization, memory-based categorization, nearest-neighbor retrieval analyses, modeling exemplar effects in human judgments.",
            "comparison_to_other_models": "Simpler and more data-intensive than program/symbolic models; complementary to distributed neural models that may implicitly memorize exemplars; contrasted with theory/program-based models that explain composition and causal substitution.",
            "functional_mechanisms": "Storage of individual exemplars in a similarity space; retrieval and weighted combination based on distance metrics (here operationalized via nearest-neighbor in CNN embedding used for analyses).",
            "limitations_or_open_questions": "How exemplar storage scales and how exemplars can be recombined compositionally to produce genuinely novel structured concepts.",
            "uuid": "e5174.6",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Human-level concept learning through probabilistic program induction",
            "rating": 2,
            "sanitized_title": "humanlevel_concept_learning_through_probabilistic_program_induction"
        },
        {
            "paper_title": "The role of theories in conceptual coherence",
            "rating": 2,
            "sanitized_title": "the_role_of_theories_in_conceptual_coherence"
        },
        {
            "paper_title": "How to grow a mind: Statistics, structure, and abstraction",
            "rating": 2,
            "sanitized_title": "how_to_grow_a_mind_statistics_structure_and_abstraction"
        },
        {
            "paper_title": "Emergence in Cognitive Science",
            "rating": 2,
            "sanitized_title": "emergence_in_cognitive_science"
        },
        {
            "paper_title": "The Algebraic Mind: Integrating Connectionism and Cognitive Science",
            "rating": 2,
            "sanitized_title": "the_algebraic_mind_integrating_connectionism_and_cognitive_science"
        },
        {
            "paper_title": "A neural representation of sketch drawings",
            "rating": 1,
            "sanitized_title": "a_neural_representation_of_sketch_drawings"
        },
        {
            "paper_title": "Generating sequences with recurrent neural networks",
            "rating": 1,
            "sanitized_title": "generating_sequences_with_recurrent_neural_networks"
        },
        {
            "paper_title": "Concepts in a probabilistic language of thought",
            "rating": 2,
            "sanitized_title": "concepts_in_a_probabilistic_language_of_thought"
        },
        {
            "paper_title": "Indexing by latent semantic analysis",
            "rating": 1,
            "sanitized_title": "indexing_by_latent_semantic_analysis"
        },
        {
            "paper_title": "The logical primitives of thought: Empirical foundations for compositional cognitive models",
            "rating": 2,
            "sanitized_title": "the_logical_primitives_of_thought_empirical_foundations_for_compositional_cognitive_models"
        }
    ],
    "cost": 0.015953000000000002,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Generating new concepts with hybrid neuro-symbolic models</p>
<p>Reuben Feinman reuben.feinman@nyu.edu 
Center for Neural Science
Department of Psychology and Center for Data Science
New York University
Brenden M. Lake</p>
<p>New York University</p>
<p>Generating new concepts with hybrid neuro-symbolic models
Neural networkscompositionalitycausalitygenerative models
Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
<p>Introduction</p>
<p>People can synthesize new concepts in imaginative ways; architects design new houses, chefs invent new recipes, and entrepreneurs create new business models. The resulting productions exhibit novel variations but maintain important structural consistencies with known entities. In contrast, state-of-the-art generative models from machine learning struggle with creative imagination, producing samples that either closely mimic the training data or that exhibit anomalous characteristics . How do people create novel yet coherent new concepts? How can we understand these abilities in computational terms?</p>
<p>Human conceptual knowledge plays a central role in creative generalization. A chef knows not only a repertoire of recipes, but also understands that recipes are built from reusable ingredients (e.g. carrots, flour, butter), and that these ingredients satisfy specific roles (thickening, seasoning, greasing). Furthermore, a chef understands which ingredients can substitute for others (e.g. butter for oil when greasing) and which should never be combined (e.g. ketchup and milk). In addition, they understand that recipes are composed of reusable causal procedures (cutting, whisking, browning), and they know how to compose these procedures in terms of order and substitutability. This causal and compositional knowledge is essential to understanding a culinary concept, as opposed to merely executing it, and is essential to a chef's ability to create new culinary concepts such as "carrots tartar" or "pea guacamole."</p>
<p>There have been two traditions of work on computational models of conceptual knowledge. The first tradition emphasizes "structured knowledge" for capturing relations between concepts and correlations between conceptual features, viewing concepts as embedded in intuitive theories (Murphy &amp; Medin, 1985) or capturing structured knowledge through symbolic representations such as hierarchies, trees, grammars and programs (Kemp &amp; Tenenbaum, 2008, 2009Tenenbaum et al., 2011). This tradition has prioritized the compositional and causal nature of conceptual knowledge, as emphasized through accounts of concept learning as program induction (Goodman et al., 2008;Stuhlmuller et al., 2010;Lake et al., 2015;Goodman et al., 2015;Ellis et al., 2018;Lake &amp; Piantadosi, 2019). The Bayesian Program Learning (BPL) framework (Lake et al., 2015), for example, demonstrates how to learn programs from images to express the causal and compositional nature of concepts and background knowledge. Although these models offer a convincing account for how strong inductive biases support flexible generalization, they often make simplifying and rigid parametric assumptions about the distributions of concepts in pursuit of a structured representation. As a result, they so far have been unsuccessful in characterizing the most complex correlations and invariances associated with human concepts in raw, highdimensional stimulus spaces.</p>
<p>The second tradition in models of conceptual knowledge emphasizes "statistical knowledge," a more amorphous form of background knowledge that is often not amenable to symbolic description. In the statistics view, conceptual knowledge manifests as complex systems of patterns and correlations recorded from observations. The meaning of a word, for example, can be derived from its patterns of co-occurrance with other words (Deerwester et al., 1990). Similarly, latent representations of objects and other sensory stimuli can be derived from "suspicious coincidences" noted in the data (Barlow, 1989). The statistics view emphasizes emergence, where conceptual knowledge emerges from the interaction of simpler processes, as operationalized through training neural network architectures (McClelland, 2010). Although a powerful modeling tool, standard neural networks do not explicitly model the compositional and causal structure of concepts. As result, they have difficulty generalizing to examples that vary systematically from training (Marcus, 2003;Lake &amp; Baroni, 2018), and to novel tasks, especially those that demand more generative and creative abilities (Lake et al., 2017.</p>
<p>Our goal in this paper is to explore generative models of concepts at the interface of these structured and statistical traditions, offering new ways of synthesizing key ideas from each. Previous efforts to integrate these traditions have demonstrated ways of performing statistical inference over structured representations . This includes models of concept learning as Bayesian inference over fully-symbolic expressions in formal logical (Goodman et al., 2008;Piantadosi et al., 2016), or models of inductive reasoning supported by structured intuitive theories (Kemp &amp; Tenenbaum, 2009). In accounts of this nature, statistics is primary in selecting between structured symbolic hypotheses (Kemp &amp; Tenenbaum, 2008;Perfors et al., 2011;Lake et al., 2015;Lake &amp; Piantadosi, 2019), while only secondary in selecting the constrained parametric distributions encapsulated in those hypotheses (Gaussians, multinomials, etc.).</p>
<p>Here we aim to more thoroughly integrate the structured and statistical traditions through hybrid neuro-symbolic generative models. Our goal is to devise a causal generative model with explicit compositional structure, and with complex correlations represented implicitly through neural networks rather than simple parametric distributions. We use simple visual concepts -handwritten characters from the world's languages -as a case study for exploring neurosymbolic models of concept generation. The Omniglot dataset (Lake et al., 2015) of handwritten characters provides an excellent preliminary modeling environment: it contains a large number of natural, simple concepts that people learn and use, and it has been explored extensively in prior work from both cognitive science and AI. Following the mixture density network framework for handwriting generation (Graves, 2013), we explore three distinct generative neural architectures, varying the strength and form of inductive bias imposed on the model, including their position on the neurosymbolic spectrum and the fidelity in which compositionality and causality are presented. We evaluate the generalization capacity of these models by comparing their log-likelihoods on a holdout set of characters. Furthermore, we analyze the samples produced by each model, looking for characters that are qualitatively consistent but sufficiently dissimilar from the training set. We find that a hybrid neuro-symbolic architecture with the strongest form of compositional structure exhibits the best generalization performance, and that it generates characters that are highly consistent with human drawings. In contrast, our generic neural models exhibit weaker performance on the holdout set, and they produce characters that more closely mimic the training examples.</p>
<p>Related Work</p>
<p>In the machine learning community, there have been a number of works studying generative neural network models for handwritten characters, including DRAW (Gregor et al., 2015), AIR (Eslami et al., 2016) and SPIRAL (Ganin et al., 2018). Although these models learn a procedure to generate new characters, they do not use the human drawing data from Omniglot, and therefore the generative process may not reflect the true causal processes of human character production. Our goal is different in that we aim to model the causal process of human handwriting directly from drawing data. Ha &amp; Eck (2018) introduced a neural network architecture called Sketch-RNN to model human drawing data for simple objects like cats, firetrucks, and windmills. Although their goal loosely resembles our own, the Sketch-RNN model is trained on just a single class of objects at one time (e.g. "cat"), and it receives 70,000 examples from the class. In contrast, our motivation is to model human conceptual knowledge of handwriting concepts in general. This background knowledge plays a central role in creative generalization, enabling people to synthesize new concepts that deviate from the observed entities. We train our models on many character classes at once, providing only 20 training examples of each class and asking them to generate new character concepts. The Sketch-RNN model has not been applied in this way.</p>
<p>Most related to our work is the Bayesian Program Learning (BPL) approach of Lake et al. (2015) that was also applied to the simple visual concepts in Omniglot. BPL is a parametric Bayesian model that captures causal, compositional structure in human background knowledge of handwriting, and shows that these ingredients are important for few-shot learning of new character concepts. Beyond supporting fewshot learning, the BPL character prior can also generate new character concepts by unconditional sampling. Although a powerful demonstration of compositional representation, the BPL parametric model makes many simplifying assumptions about characters. For example, it assumes that strokes in a character are generated largely independently from each other in the prior (although they are strongly correlated in the posterior). As result, new characters generated by the model often lack the rich correlation structure of human drawings. We build on this work and develop a new neuro-symbolic model that represents the compositional structure of characters while using neural networks to capture richer correlations.</p>
<p>Omniglot Case Study</p>
<p>We use simple visual concepts as a case study for modeling conceptual structure and developing generative models of concepts. The Omniglot dataset contains human drawings of characters from 50 unique alphabets, providing a large set of cognitively natural concepts that are simple enough for evaluating models (Lake et al., 2015. In our experiments, we use drawings from the Omniglot background set to train our models, which contains 30 alphabets and a total of 19,280 unique drawings. We also use 10 alphabets from the Omniglot evaluation set as a holdout set for quantitative evaluations, reserving the remaining 10 alphabets for future work on few-shot classification.</p>
<p>In the drawing data, a stroke is represented as a variablelength sequence of pen locations {z 1 , ..., z T }, with z i ∈ R 2 (Fig. 2, left). As a pre-processing step, we convert each stroke into a minimal spline representation using least-squares optimization ( Fig. 2, right), borrowing the B-spline tools from Lake et al. (2015). The number of spline control points depends on the stroke complexity and is determined by a resid-  GenerateCharacter consists of sequentially reading from and rendering to an image canvas, which is initialized to zero. At each time step, the current canvas I is fed to procedure GenerateStroke, which produces a stroke sample. The canvas is first processed by the location model, a CNN-MLP architecture that processes the image and returns a Gaussian mixture model (GMM) distribution for the starting location of the next stroke y. The location y is then sampled and passed along with I to the stroke model. The stroke model processes I with a CNN and feeds the embedding to an LSTM with attention. The LSTM samples a stroke trajectory x sequentially one offset at a time using GMM outputs. The sampled stroke is passed to a symbolic renderer, and the updated image canvas is then processed by a termination model that decides whether to continue the character sample.
GenerateStroke(I) location model p(y | I) stroke model p(x | y, I) CNN MLP CNN LSTM y I I I I, y attention p(Δ 1 ) p(Δ 2 | Δ 1 ) p(Δ T | Δ 1:T−1 ) … y ∼ p ( y | I ) I, y, x x ∼ p ( x | y , I ) procedure GENERATECHARACTER I 0 . Initialize
ual threshold. Furthermore, we removed small strokes from the data using a threshold on the trajectory length. These processing steps help suppress noise and emphasize signal in the character drawings. Our generative models are trained to produce character drawings, where each drawing is represented as an ordered set of splines (strokes). The number of strokes, and the number of spline coordinates per stroke, are allowed to vary. </p>
<p>Neuro-Symbolic Model</p>
<p>Our primary interest is to test whether a hybrid neurosymbolic model can capture the compositional, causal structure in a large corpus of simple character concepts. The architecture and sampling procedure of our hybrid model, which we call the "Full Neuro-Symbolic" (Full NS) model, is given in Fig. 1. Compared to generic neural networks, the Full NS model lies closer to structure on the structure-statistics spectrum, possessing a much stronger inductive bias. As in BPL (Lake et al., 2015), the generative model is a probabilistic program that captures real compositional and causal structure by sampling characters as a sequence of parts and locations/relations. Unlike BPL, the model has a symbolic engine that renders each part to an image canvas before producing the next one, and parts are generated using a powerful recurrent neural network that encodes and attends to the current canvas. Although correlations between parts can be captured through a process of rendering and then encoding, the model does not allow arbitrary information to flow between parts and variables as in monolithic neural networks. The Full NS model represents a character as a sequence of strokes, with each stroke decomposed into a starting location y t ∈ R 2 , conveying the first spline control point, and a stroke trajectory x t = {∆ 1 , ..., ∆ N }, conveying deltas between spline control points. It generates characters one stroke at a time, using a symbolic renderer as an intermediate processing step after forming each stroke. An image canvas I is used as a memory state to convey information about previous strokes. At each time step t, the next stroke's starting location and trajectory are sampled with procedure GenerateStroke. In this procedure, the current image canvas I is first read by the location model ( Fig. 1; bottom middle), a convolutional neural network (CNN) that processes the image and returns a probability distribution for starting location y t :
y t ∼ p(y t | I).
A visualization of the density p(y t | I) is given in Fig. 3, "Location Prediction." The starting location y t is then passed along with the image canvas I to the stroke model ( Fig. 1;  bottom right), a Long Short-Term Memory (LSTM) architecture with a CNN-based image attention mechanism inspired by Xu et al. (2016). The stroke model samples the next stroke trajectory x t sequentially one offset at a time, selectively attending to different parts of the image canvas at each sample step and combining this information with the context of y t :</p>
<p>x t ∼ p(x t | y t , I). After each stroke, the model receives the current image canvas ("Input Canvas") and makes a series of predictions. Termination Prediction. First, the model predicts a termination probability p (blue bar), i.e. a probability of terminating the drawing. Location Prediction. Next, the model predicts a probability density for the next stroke's starting location. The heatmap indicates the predicted density, and the hollow red dot indicates the ground-truth location. Stroke Prediction. Finally, the model predicts an auto-regressive probability density for the next stroke's trajectory (the "stroke"). Red dots indicate the previous control points, heatmaps indicate the predicted density for the next control point, and hollow red dot indicates the ground-truth next control point.</p>
<p>A visualization of the auto-regressive density p(x t | y t , I) is given in Fig. 3, "Stroke Prediction." Mixture Outputs. Both our location model and stroke model follow a technique from Graves (2013), who proposed to use neural networks with mixture outputs to model handwriting data. The parameters θ = {π 1:K , µ 1:K , σ 1:K , ρ 1:K } output by our network specify a Gaussian mixture model (GMM) with K components ( Fig. 1; colored ellipsoids), where π k ∈ (0, 1) is the mixture weight of the k th component, µ k ∈ R 2 its means, σ k ∈ R 2 + its standard deviations, and ρ k ∈ (−1, 1) its correlation. In our location model, a single GMM describes the distribution p(y t | I). In our stroke model, the LSTM outputs one GMM at each timestep, describing p(∆ t |∆ 1:t−1 , y t , I).</p>
<p>Training. Our Full NS model provides a density function which can be used to score the log-likelihood for any character drawing. We train the model to maximize the loglikelihood (minimize log-loss) of the training set drawings, using mini-batch gradient descent with a batch size of 200 and the Adam update rule.</p>
<p>Alternative Models</p>
<p>In addition to our Full NS model, we explored two alternative models with more generic neural network architectures. In each alternative, we lesioned key structural ingredients of the Full NS model, hoping to test the importance of these ingredients to model performance.</p>
<p>Hierarchical LSTM. As one alternative neural model, we explored a hierarchical recurrent architecture (Sordoni et al., 2015;Ling et al., 2016;Chung et al., 2017), which we denote "Hierarchical LSTM" (H-LSTM). Like our Full NS architecture, the H-LSTM model is trained on causal data demonstrating how people actually produce drawings of characters. In addition, it models the compositional structure of characters by separating them into explicit stroke parts, which defines the hierarchy in the hierarchical LSTM. Unlike our Full NS model, however, the H-LSTM has no renderer and thus lacks any explicit causal knowledge of how motor actions become raw images of inked characters. Instead, information about the previous strokes is written to memory via recurrent connections and gating mechanisms. These transformations can propagate arbitrary correlations, and they must be learned entirely from the data. Specifically, at each time step t, the previous stroke x t−1 is read by a stroke encoder f enc , a bi-directional LSTM that processes the stroke and returns a fixed-length vector (red box in Fig. 4). This vector is then passed as an input to the character LSTM along with previous location y t−1 and previous hidden state h t−1 :
h t = f LSTM (y t−1 , f enc (x t−1 ), h t−1 ).
The new hidden state h t is then fed to the location model p(y t | h t ), a multi-layer perceptron that outputs a GMM distribution for the next stroke's starting location y t (green box in Fig. 4). The location is sampled from this distribution and passed as an input along with h t to the stroke model p(x t | h t , y t ), an LSTM that samples a stroke trajectory one offset at a time with GMM outputs (yellow box in Fig. 4):
y t ∼ p(y t | h t ) x t ∼ p(x t | h t , y t ).
Baseline LSTM. A second alternative is even less structured and represents the most purely statistical architecture we examined. For this model, we explored a naive unrolled LSTM, denoted "Baseline." This model is a reproduction of the unconditional version of Sketch-RNN (Ha &amp; Eck, 2018, Sec 3.3). Similar to Full NS and H-LSTM, the Baseline LSTM is trained on causal data demonstrating the process of producing character; however, it does not explicitly take the compositional structure of characters into account in the architecture itself. Instead, it uses a single RNN to model a character as one long sequence of pen actions with stroke breaks.</p>
<p>Following Sketch-RNN, we expand the binary pen state variable v t ∈ {0, 1} from Graves (2013) to a ternary variable v t ∈ {0, 1, 2} to handle multi-stroke drawings. Value 0 indicates that we are continuing the current stroke, 1 that we are ending the current stroke and starting a new one, and 2 that we are ending the drawing. The initial hidden and cell states of the LSTM are set to zero, and at each time step t, the previous offset ∆ t−1 , previous pen state v t−1 , and previous hidden state h t−1 are fed as inputs to the LSTM, which outputs new hidden state h t :
h t = f LSTM (∆ t−1 , v t−1 , h t−1 ).
An output layer receives h t and returns a categorical distribution for next pen state v t , as well as a GMM distribution for next offset ∆ t :
θ v = f v (h t ), v t ∼ p(v t | θ v ) θ ∆ = f ∆ (h t ), ∆ t ∼ p(∆ t | θ ∆ ).</p>
<p>Experiments</p>
<p>We evaluated the creative generalizations of our 3 neural network models using both quantitative and qualitative analyses. Each of our models estimates a probability density function for characters from training examples. This density function can be used to compute likelihoods for held-out characters and to generate new character samples. A generative model for characters that exhibits creative generalization should produce high likelihood scores for novel character concepts from  Table 1: Test losses from our 3 models. Losses indicate the average negative log-likelihood per test character (lower is better). In our alphabet splits task, we divide the background set into train/test splits such that the model must generalize to new characters from novel alphabets. In our "character splits task, we divide the background set such that the model must generalize to new characters from familiar alphabets. In our "holdout task, we provide the entire background set for training and use the held-out evaluation setwhich contains new characters from novel alphabets-for testing.</p>
<p>held-out classes. In addition, the model should generate new characters that are sufficiently dissimilar from the training examples, but that are structurally consistent with ground truth. In our quantitative analysis, we tested our models for their likelihood performance on novel character classes using a rigorous set of experiments with different train/test splits. In our qualitative analysis, we inspected character samples produced by each model, comparing them to characters from both BPL and ground truth and looking at nearest neighbors from the training set.</p>
<p>Evaluation on Held-Out Concepts</p>
<p>Methods. In our quantitative analysis, we evaluated our models for two different forms of likelihood generalization, corresponding to different train/test splits. In the first generalization task, denoted "character splits," we asked whether our models could generalize to new character classes from familiar alphabets. We created 3 train/test splits from the Omniglot background set, sampling 80% of characters per alphabet for train and 20% for test. In our second task, denoted "alphabet splits," we asked whether our models could generalize to new character classes from novel alphabets. We again sampled 3 train/test splits of size 80-20, this time splitting by alphabet. In both the "character splits" and "alphabet splits" tasks, we explored multiple hyperparameter configurations for our models, varying parameters such as the number of hidden layers, number of units per layer, and dropout probability. 1 Average validation loss across splits was used to select the best configuration for each model in each task. We then took our best configurations in each task and reported their validation losses on all 3 splits. As a final quantitative analysis, we tested our models on one additional task that extends the "alphabet splits" task. Our motivation was to provide a more rigorous analysis using a completely withheld test set as per standard practice in machine learning evaluations. We re-trained our best configurations of each model on the entire background set, using the hyperparameters selected from our "alphabet splits" task. We then reported losses on the evaluation set, which contains character drawings from 10 novel alphabets. Results. Results from our CV-splits experiments are given in Table 1, "Alphabet Splits" and "Character Splits." In our alphabet splits experiment, the Full NS model consistently outperformed its alternatives, exhibiting the best generalization performance in each of the 3 splits with losses of 13.77, 14.18 and 17.53, respectively (per character average). Thus, our neuro-symbolic architecture appears best equipped to capture overarching principles in handwriting concepts that generalize far outside of the training examples. In our character splits task, the Baseline LSTM exhibited best performance in 2 out of 3 splits, and the Full NS model in 1 of 3. The character splits test present a much easier generalization task, where exemplar-based learning could offer a suitable alternative to learning general structural principals. Although our naive Baseline model performs well, its lack of consistency across splits suggests that this model may rely on more of an exemplar-based technique for learning, which we investigate further in our sample analyses. Interestingly, the selected hyperparameter configuration for our Full NS model remained constant across the "alphabet" and "character" split tasks, whereas the configuration changed for both the Baseline and H-LSTM models.</p>
<p>Results for each model on the held-out set of characters are shown in Table 1, "Holdout." Similarly to the "alphabets" task, our Full NS model outperforms both alternative models on the holdout set, providing further support that this architecture learns the best general model of these simple visual concepts.</p>
<p>Generating New Concepts</p>
<p>Methods. In our qualitative analysis, we analyzed the 3 neural network models on their ability to produce novel visual concepts. We took our trained models from the previous experiment and sampled 36 characters from each model, following the model's causal generative procedure. In addition, we sampled 36 characters from the BPL character prior, and we selected 36 "ground truth" characters from Omniglot at random. Samples were then compared visually side-by-side.</p>
<p>As an additional qualitative analysis, we compared character samples from each model for their similarity to the training examples. Although the complexity and structural coherency of generated characters are important criteria, these observations alone provide insufficient evidence for a human- like generative process; a model that memorizes the training examples might produce samples with structural coherence and rich variations, but such a model does not account for the flexible ways that humans generate new concepts. In our second analysis, we took the character samples from our models and found the 5 most-similar training characters for each, using cosine distance in the last hidden layer of a CNN classifier as a metric space for perceptual similarity. The CNN was trained to classify characters from the Omniglot background set, a 964-way classification task.</p>
<p>Results. Fig. 5 shows samples from each of our three models, as well as from the BPL forward model 2 and from the Omniglot data (ground truth). Compared to BPL, the neuralenhanced models capture more correlational structure and character complexity. For instance, the Full NS model propagates stylistic and structural consistency across three strokes to form a Braille-like character, as shown by the sample in column 1, row 2. Fig. 6 Figure 7: Topologically-Organized character samples and their nearest Omniglot neighbors. We drew 100 character samples from our Full NS model and organized them into a 10x10 grid such that neighboring characters have similar drawing styles (left). We then found the "nearest neighbor" of each sample from the Omniglot character dataset and organized the neighbors into a corresponding 10x10 grid (right).</p>
<p>acters that closely mimic the nearest training examples in the majority (7/9 by our eyes) of cases. In contrast, our Full NS model produces only a few (3/9) characters that directly mirror the nearest training examples, suggesting that it can generalize further from the training observations.</p>
<p>To get an idea of the different character styles produced by our Full NS model, we sampled 100 characters from the model and organized them into a 10x10 grid such that neighboring characters have high perceptual similarity (Fig. 7, left). Characters were sampled at a lower level of stochasticity, using the temperature parameter proposed by Ha &amp; Eck (2018) to modify the entropy of the mixture density outputs (we used T = 0.5). The model produces characters in multiple distinct styles, with some having more angular, linebased structure and others relying on complex curves. In Fig.  7, (right) we plotted the most-similar Omniglot character for each sample in a corresponding grid. In many cases, samples from the model have a distinct style and are visually dissimilar from their nearest Omniglot neighbor.</p>
<p>Conclusion</p>
<p>We presented a new neuro-symbolic generative model of simple visual concepts. Our model successfully captures compositional and causal structure in handwritten character concepts, forming a representation that generalizes to new concepts. We tested our model by comparing its likelihood scores on a holdout set of novel characters, finding that it consistently outperforms two generic neural network alternatives when the test characters deviate significantly from the training examples. Furthermore, our generative model produces new character concepts with richer variations than simple parametric models, yet that remain structurally coherent and visually consistent with human productions.</p>
<p>Neuro-symbolic models offer a promising set of tools to express the rich background knowledge that enables creative imagination. These models can explain the nonparametric correlation structure embodied in conceptual knowledge while maintaining important inductive biases to account for the structured ways that people generate new concepts. We believe that models of this kind will be useful to explain a variety of human imaginative behaviors, such as when a chef creates the new recipe "pea guacamole." In future work, we'd like to explore applications of neuro-symbolic models to other types of concepts with varying complexity.</p>
<p>Figure 1 :
1Full neuro-symbolic (Full NS) model. Our Full NS model produces character samples one stroke at a time. The procedure</p>
<p>Figure 2 :
2Spline representation. Raw strokes (left) are converted into minimal splines (right) using least-squares optimization. Crosses (left) indicate pen locations and red dots (right) indicate spline control points.</p>
<p>Figure 3 :
3Predictions of the Full NS model for a test character.</p>
<p>Figure 4 :
4Hierarchical LSTM model. The model samples characters one stroke at a time, using a character-level LSTM as a memory state. At each time, the model samples a starting location for the next stroke from a location predictor (MLP), and a stroke trajectory from the stroke predictor (LSTM). These samples are then fed to the model as inputs for the next time, with the location fed directly and the trajectory processed by a stroke encoder (bi-directional LSTM).</p>
<p>Figure 5 :
5Character sample comparison. Characters generated by our Full NS, H-LSTM and Baseline LSTM models are shown side-byside, along with samples from the BPL forward model 2 as well as ground truth characters from Omniglot.</p>
<p>Figure 6 :
6Novelty of character samples. Character drawings sampled from each model were compared to their 5 nearest neighbors from the training set. Each row corresponds to one character sample from the model. The red box indicates the model sample, and the 5 nearest neighbors are shown in the succeeding columns.</p>
<p>shows a handful of character samples produced by each neural model plotted alongside their five nearest neighbors from the Omniglot training set. Both the H-LSTM and the Baseline LSTM models produce char-samples from Full NS 
model (T=0.5) </p>
<p>corresponding 
Omniglot neighbors </p>
<p>stroke key: </p>
<p>For details about hyperparameters, see Appendix A.
BPL character samples have been centered for better visual appearance; the actual samples often protrude outside of the image window. A more complex non-parametric BPL model was used in the visual Turing tests inLake et al. (2015) that has explicit re-use of character parts. Those samples were also centered.
AcknowledgementsWe thank Maxwell Nye, Josh Tenenbaum, Tuan-Anh Le, and Jay McClelland for helpful discussions regarding this work.Appendix A. Model HyperparametersHere we review the hyperparameters (HPs) used for each of our models, indicating which HPs were fixed and which were tuned. All neural networks with GMM output layers use 20 mixture components.Full NS. The Full NS model has 3 submodules: a location model, a stroke model, and a termination model. Each submodule uses a distinct CNN, and each receives an image canvas of size (28,28). The location and termination modelswhich return outputs for a single time step-each use a feedforward CNN architecture inspired byVinyals et al. (2016). The CNNs consist of a stack of 4 blocks, with each block i including a 3x3 convolution with K i filters, batch normalization, nonlinear activation f , 2x2 max-pooling, and dropout with rate p. These blocks are followed by a single fully-connected layer with D units, activation f and dropout p. Hyperparameters {K i }, f , p and D were selected from tuning. The stroke model uses a modified CNN architecture without spatial pooling, designed to convey high-resolution spatial information for visual attention. The CNN returns a feature map of size(64,14,14), which is then passed to an LSTM. The LSTM predicts the spline trajectory of the next stroke one offset at a time, attending to different parts of the feature map at each step. The HPs of the CNN were fixed, but the HPs of the LSTM were tuned, including the number of LSTM layers and number of units per layer.Hierarchical LSTM. The Hierarchical LSTM model has a character-level LSTM backbone and 3 submodules: a stroke encoder (BiLSTM), a location model (MLP), and a stroke model (LSTM). The number of LSTM layers, number of units per layer and dropout rate in the character-level LSTM were selected from tuning, but HPs of all submodules were fixed. The stroke encoder is a bidirectional LSTM with a single layer of 256 units. It outputs a fixed-length vector representation of the previous stroke, which is fed to the character LSTM as input. The location model is a 2-layer MLP that receives the current hidden state of the character LSTM and outputs a GMM for the next stroke's starting location. The stroke model is an LSTM with a single layer of 256 units and outputs a GMM at each time step for the next spline offset.Baseline LSTM. The Baseline LSTM is a single module. It has L LSTM layers, each with K units and dropout rate p. The values of L, K and p were selected from tuning.B. Samples with stroke decompositionInFig. 8, we show a larger collection of characters from our Full NS model, using color coding to convey the stroke composition of each sample. We produced character samples at two different levels of stochasticity, using a temperature parameter to modify the entropy of the mixture density outputs(Ha &amp; Eck, 2018, Eq.8). Samples are shown for temperature settings T = 1.0 and T = 0.5.
Unsupervised learning. H B Barlow, Neural Computation. 13Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1(3), 295-311.</p>
<p>Hierarchical multiscale recurrent neural networks. J Chung, S Ahn, Y Bengio, In ICLRChung, J., Ahn, S., &amp; Bengio, Y. (2017). Hierarchical multiscale recurrent neural networks. In ICLR.</p>
<p>Indexing by latent semantic analysis. S Deerwester, S T Dumais, G W Furnas, T K Landauer, R Harshman, JASIS. 41Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. JASIS, 41, 391-407.</p>
<p>Learning to infer graphics programs from hand-drawn images. K Ellis, D Ritchie, A Solar-Lezama, J B Tenenbaum, NIPS. Ellis, K., Ritchie, D., Solar-lezama, A., &amp; Tenenbaum, J. B. (2018). Learning to infer graphics programs from hand-drawn images. In NIPS.</p>
<p>Attend, infer, repeat: Fast scene understanding with generative models. S M A Eslami, N Heess, T Weber, Y Tassa, D Szepesvari, K Kavukcuoglu, G E Hinton, NIPS. Eslami, S. M. A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Kavukcuoglu, K., &amp; Hinton, G. E. (2016). Attend, infer, repeat: Fast scene understanding with generative models. In NIPS.</p>
<p>Synthesizing programs for images using reinforced adversarial learning. Y Ganin, T Kulkarni, I Babuschkin, S M A Eslami, O Vinyals, ICML. Ganin, Y., Kulkarni, T., Babuschkin, I., Eslami, S. M. A., &amp; Vinyals, O. (2018). Syn- thesizing programs for images using reinforced adversarial learning. In ICML.</p>
<p>A rational analysis of rule-based concept learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, Cognitive Science. 32Goodman, N. D., Tenenbaum, J. B., Feldman, J., &amp; Griffiths, T. L. (2008). A rational analysis of rule-based concept learning. Cognitive Science, 32, 108-154.</p>
<p>Concepts in a probabilistic language of thought. N D Goodman, J B Tenenbaum, T Gerstenberg, The conceptual mind: New directions in the study of concepts. E. Margolis and S. LaurenceCambridge, MAMIT PressGoodman, N. D., Tenenbaum, J. B., &amp; Gerstenberg, T. (2015). Concepts in a proba- bilistic language of thought. In E. Margolis and S. Laurence (Ed.), The conceptual mind: New directions in the study of concepts (pp. 623-653). Cambridge, MA: MIT Press.</p>
<p>Generating sequences with recurrent neural networks. A Graves, arXiv:1308.0850arXiv preprintGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</p>
<p>DRAW: A recurrent neural network for image generation. K Gregor, I Danihelka, A Graves, D J Rezende, D Wierstra, ICML. Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., &amp; Wierstra, D. (2015). DRAW: A recurrent neural network for image generation. In ICML.</p>
<p>A neural representation of sketch drawings. D Ha, D Eck, ICLR. Ha, D., &amp; Eck, D. (2018). A neural representation of sketch drawings. In ICLR.</p>
<p>The discovery of structural form. C Kemp, J B Tenenbaum, PNASKemp, C., &amp; Tenenbaum, J. B. (2008). The discovery of structural form. PNAS, 105(31), 10687-92.</p>
<p>Structured statistical models of inductive reasoning. C Kemp, J B Tenenbaum, Psychological Review. 116Kemp, C., &amp; Tenenbaum, J. B. (2009). Structured statistical models of inductive rea- soning. Psychological Review, 116, 20-58.</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. B M Lake, M Baroni, ICML. Lake, B. M., &amp; Baroni, M. (2018). Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In ICML.</p>
<p>B M Lake, S T Piantadosi, People Infer Recursive Visual Concepts from Just a Few Examples. Lake, B. M., &amp; Piantadosi, S. T. (2019). People Infer Recursive Visual Concepts from Just a Few Examples. Computational Brain &amp; Behavior.</p>
<p>Human-level concept learning through probabilistic program induction. B M Lake, R Salakhutdinov, J B Tenenbaum, Science. 350Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350, 1332-1338.</p>
<p>The Omniglot challenge: A 3-year progress report. B M Lake, R Salakhutdinov, J B Tenenbaum, Behavioral Sciences. 29Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2019). The Omniglot challenge: A 3-year progress report. Behavioral Sciences, 29, 97-104.</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 40253Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). Building machines that learn and think like people. Behavioral and Brain Sciences, 40, E253.</p>
<p>Character-based neural machine translation. W Ling, I Trancoso, C Dyer, A Black, ICLR. Ling, W., Trancoso, I., Dyer, C., &amp; Black, A. (2016). Character-based neural machine translation. In ICLR.</p>
<p>The Algebraic Mind: Integrating Connectionism and Cognitive Science. G F Marcus, MIT PressCambridge, MAMarcus, G. F. (2003). The Algebraic Mind: Integrating Connectionism and Cognitive Science. Cambridge, MA: MIT Press.</p>
<p>Emergence in Cognitive Science. J L Mcclelland, Topics in Cognitive Science. 24McClelland, J. L. (2010). Emergence in Cognitive Science. Topics in Cognitive Science, 2(4), 751-770.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological Review. 923Murphy, G. L., &amp; Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological Review, 92(3), 289-316.</p>
<p>The learnability of abstract syntactic principles. A Perfors, J B Tenenbaum, T Regier, Cognition. 1183Perfors, A., Tenenbaum, J. B., &amp; Regier, T. (2011). The learnability of abstract syntactic principles. Cognition, 118(3), 306-338.</p>
<p>The logical primitives of thought: Empirical foundations for compositional cognitive models. S T Piantadosi, J B Tenenbaum, N D Goodman, Psych. Rev. Piantadosi, S. T., Tenenbaum, J. B., &amp; Goodman, N. D. (2016). The logical primitives of thought: Empirical foundations for compositional cognitive models. Psych. Rev..</p>
<p>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. A Sordoni, Y Bengio, H Vahabi, C Lioma, J G Simonsen, J Y Nie, CIKM. Sordoni, A., Bengio, Y., Vahabi, H., Lioma, C., Simonsen, J. G., &amp; Nie, J. Y. (2015). A hierarchical recurrent encoder-decoder for generative context-aware query sugges- tion. In CIKM.</p>
<p>Learning Structured Generative Concepts. A Stuhlmuller, J B Tenenbaum, N D Goodman, In CogSciStuhlmuller, A., Tenenbaum, J. B., &amp; Goodman, N. D. (2010). Learning Structured Generative Concepts. In CogSci.</p>
<p>How to grow a mind: Statistics, structure, and abstraction. J B Tenenbaum, C Kemp, T L Griffiths, N D Goodman, Science. 3316022Tenenbaum, J. B., Kemp, C., Griffiths, T. L., &amp; Goodman, N. D. (2011). How to grow a mind: Statistics, structure, and abstraction. Science, 331(6022), 1279-1285.</p>
<p>Matching networks for one shot learning. O Vinyals, C Blundell, T Lillicrap, D Wierstra, NIPS. Vinyals, O., Blundell, C., Lillicrap, T., &amp; Wierstra, D. (2016). Matching networks for one shot learning. In NIPS.</p>
<p>Show, attend and tell: Neural image caption generation with visual attention. K Xu, J L Ba, R Kiros, K Cho, A Courville, R Salakhutdinov, . . Bengio, Y , ICML. Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., . . . Bengio, Y. (2016). Show, attend and tell: Neural image caption generation with visual attention. In ICML.</p>            </div>
        </div>

    </div>
</body>
</html>