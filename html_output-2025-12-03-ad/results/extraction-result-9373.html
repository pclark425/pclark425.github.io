<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9373 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9373</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9373</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-f35e2b062aa13166aabdaed7ae56666bec51b3ca</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f35e2b062aa13166aabdaed7ae56666bec51b3ca" target="_blank">AER: Auto-Encoder with Regression for Time Series Anomaly Detection</a></p>
                <p><strong>Paper Venue:</strong> 2022 IEEE International Conference on Big Data (Big Data)</p>
                <p><strong>Paper TL;DR:</strong> AER (Auto-encoder with Regression), a joint model that combines a vanilla auto-encoding and an LSTM regressor to incorporate the successes and address the limitations of each method, is proposed.</p>
                <p><strong>Paper Abstract:</strong> Anomaly detection on time series data is increasingly common across various industrial domains that monitor metrics in order to prevent potential accidents and economic losses. However, a scarcity of labeled data and ambiguous definitions of anomalies can complicate these efforts. Recent unsupervised machine learning methods have made remarkable progress in tackling this problem using either single-timestamp predictions or time series reconstructions. While traditionally considered separately, these methods are not mutually exclusive and can offer complementary perspectives on anomaly detection. This paper first highlights the successes and limitations of prediction-based and reconstruction-based methods with visualized time series signals and anomaly scores. We then propose AER (Auto-encoder with Regression), a joint model that combines a vanilla auto-encoder and an LSTM regressor to incorporate the successes and address the limitations of each method. Our model can produce bi-directional predictions while simultaneously reconstructing the original time series by optimizing a joint objective function. Furthermore, we propose several ways of combining the prediction and reconstruction errors through a series of ablation studies. Finally, we compare the performance of the AER architecture against two prediction-based methods and three reconstruction-based methods on 12 well-known univariate time series datasets from NASA, Yahoo, Numenta, and UCR. The results show that AER has the highest averaged F1 score across all datasets (a 23.5% improvement compared to ARIMA) while retaining a runtime similar to its vanilla auto-encoder and regressor components. Our model is available in Orion1, an opensource benchmarking tool for time series anomaly detection.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9373",
    "paper_id": "paper-f35e2b062aa13166aabdaed7ae56666bec51b3ca",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00441725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<h1>AER: Auto-Encoder with Regression for Time Series Anomaly Detection</h1>
<p>Lawrence Wong, Dongyu Liu, Laure Berti-Equille, Sarah Alnegheimish, Kalyan Veeramachaneni</p>
<h2>To cite this version:</h2>
<p>Lawrence Wong, Dongyu Liu, Laure Berti-Equille, Sarah Alnegheimish, Kalyan Veeramachaneni. AER: Auto-Encoder with Regression for Time Series Anomaly Detection. 2022 IEEE International Conference on Big Data, Dec 2022, Osaka, Japan. pp.1152-1161, 10.1109/BigData55660.2022.10020857 . ird-04382119</p>
<h2>HAL Id: ird-04382119 <br> https://ird.hal.science/ird-04382119v1</h2>
<p>Submitted on 10 Jan 2024</p>
<p>HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers.</p>
<p>L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p>
<h1>AER: Auto-Encoder with Regression for Time Series Anomaly Detection</h1>
<p>Lawrence Wong<br>MIT<br>Cambridge, USA<br>lcwong@mit.edu</p>
<p>Dongyu Liu
MIT
Cambridge, USA
dongyu@mit.edu</p>
<p>Laure Berti-Equille IRD ESPACE-DEV
Montpellier, France
laure.berti@ird.fr</p>
<p>Sarah Alnegheimish MIT Cambridge, USA smish@mit.edu</p>
<p>Kalyan Veeramachaneni MIT
Cambridge, USA
kalyanv@mit.edu</p>
<p>Abstract-Anomaly detection on time series data is increasingly common across various industrial domains that monitor metrics in order to prevent potential accidents and economic losses. However, a scarcity of labeled data and ambiguous definitions of anomalies can complicate these efforts. Recent unsupervised machine learning methods have made remarkable progress in tackling this problem using either single-timestamp predictions or time series reconstructions. While traditionally considered separately, these methods are not mutually exclusive and can offer complementary perspectives on anomaly detection. This paper first highlights the successes and limitations of predictionbased and reconstruction-based methods with visualized time series signals and anomaly scores. We then propose AER (Autoencoder with Regression), a joint model that combines a vanilla auto-encoder and an LSTM regressor to incorporate the successes and address the limitations of each method. Our model can produce bi-directional predictions while simultaneously reconstructing the original time series by optimizing a joint objective function. Furthermore, we propose several ways of combining the prediction and reconstruction errors through a series of ablation studies. Finally, we compare the performance of the AER architecture against two prediction-based methods and three reconstruction-based methods on 12 well-known univariate time series datasets from NASA, Yahoo, Numenta, and UCR. The results show that AER has the highest averaged F1 score across all datasets (a $\mathbf{2 3 . 5 \%}$ improvement compared to ARIMA) while retaining a runtime similar to its vanilla auto-encoder and regressor components. Our model is available in Orion ${ }^{1}$, an opensource benchmarking tool for time series anomaly detection.</p>
<p>Index Terms-anomaly detection, time series data, autoencoder, regression, machine learning</p>
<h2>I. INTRODUCTION</h2>
<p>Time series data is consistently generated and collected across various industries - examples include stock prices in finance, vital signs in healthcare, and retail sales in business. Effective monitoring and use of time series data are essential for increasing efficiency and productivity. In addition, analysis of time series data can extrapolate recurring patterns to predict future occurrences. Anomaly detection, an important task within time series analysis, explicitly aims to identify unexpected events. This research is increasingly relevant due to its broad applications in detecting crucial issues, such as financial fraud in trading networks [8], medical problems in electrocardiograms [5], [16], and ecosystem disturbances in satellite signals [21].
${ }^{1}$ The AER model is available in Orion: https://github.com/sintel-dev/Orion
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Assumption: Anomalous values cannot be effectively reconstructed since information is lost in the mapping to the latent dimensions.</p>
<p>Fig. 1. A comparison between prediction-based and reconstruction-based methods for anomaly detection in time series data. Prediction-based methods learn a predictive model fitted to the given time series data. Reconstructionbased methods learn a model to capture the given time series data's latent structure and then reconstruct the data from their latent representations.</p>
<p>While the criteria differ across domains, anomalies in time series typically exhibit one of three identifiable patterns: point, contextual, or collective [4]. Point anomalies are singular data points that suddenly deviate from the normal range of the series. For example, a sensor malfunction is one common cause of point anomalies. Collective anomalies are a series of consecutive data points that are considered anomalous as a whole. Finally, contextual anomalies are groups of data points that fall within the series' normal range but do not follow expected temporal patterns.</p>
<p>Time series also exhibit unique properties that complicate anomaly detection. First, the temporality of time series implicates a correlation or dependence between each consecutive observation [11]. Second, the dimensionality of each observation influences the computational cost, imposing limitations on the modeling method. For example, modeling methods for multivariate datasets with more than one channel face the curse of dimensionality since they need to capture correlations between observations on top of temporal dependencies [3]. Third, noise due to minor sensor fluctuations during the process of capturing the signal can impact the performance [20]. The pre-processing stages must minimize noise to prevent models from confusing this noise with anomalies. Finally, time series are often non-stationary. They have statistical properties that change over time, like seasonality, concept drift, and change</p>
<p>points, that can easily be mistaken for anomalies.
Existing machine learning methods for anomaly detection on time series can be either prediction-based or reconstructionbased (Fig. 1). Prediction-based methods train a model to learn previous patterns in order to forecast future observations [6]. An observation is anomalous when the predicted value deviates significantly from the actual value. Prediction-based methods are good at revealing point anomalies but tend to produce more false detection [13]. On the other hand, reconstructionbased methods learn a latent low-dimensional representation to reconstruct the original input [6]. This method assumes that anomalies are rare events that are lost in the mapping to the latent space. Hence, regions that cannot be effectively reconstructed are considered anomalous. In our experiments, we observed that reconstruction-based methods tend to be more effective than prediction-based methods at identifying contextual and collective anomalies.</p>
<p>This paper proposes a new architecture - an auto-encoder with regression (AER) model - that leverages the successes and addresses the limitations faced by each method type. This architecture trains a reconstruction-based auto-encoder with a prediction-based regression component using a joint objective function. As a result, the model can produce both reconstruction-based and prediction-based anomaly scores (likelihood of an abnormal observation). This paper also explores several ways to calculate and combine scores to address several limitations of existing methods. Briefly, the contributions of this paper are as follows:</p>
<ul>
<li>We identified several successes and limitations of prediction-based and reconstruction-based methods using visualized examples.</li>
<li>We propose a novel architecture - auto-encoder with regression (AER) - that leverages the successes of prediction-based and reconstruction-based methods for anomaly detection on time series data.</li>
<li>We introduce the idea of masking anomaly scores created from the smoothing function to reduce start-of-sequence false-positive predictions. We applied masking to every baseline method and compared the method's performance to that of its unmasked counterpart.</li>
<li>We present bi-directional anomaly scores, which combine prediction-based anomaly scores in the forward and reverse directions. This method addresses the limitation of missing forecasts faced by prediction-based methods.</li>
<li>We demonstrated that AER outperformed five other baseline methods in anomaly detection on 12 time series datasets ${ }^{2}$. In addition, ablation studies show that the AER model achieved a $23.5 \%$ improvement in averaged F1 score compared to the baseline ARIMA model while retaining a runtime similar to its vanilla auto-encoder and LSTM regressor components.
The structure of the paper is as follows: Section II provides an overview of the existing pipeline and approaches for</li>
</ul>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>time series anomaly detection. Section III formally defines the problem, and Section IV documents the successes and limitations of existing methods. Section V introduces our solution, including the AER framework, smoothing function masking, and bi-directional scoring. Finally, Sections VI and VII evaluate the proposed framework, discuss the results, and summarize the key findings.</p>
<h2>II. Related Work</h2>
<h2>A. Anomaly Detection Pipelines</h2>
<p>Anomaly detection aims to find a set of anomalous intervals from either univariate or multivariate time series data. It is usually an unsupervised task due to the lack of labeled data. Recent work by Sintel [1] formalized this task as an end-toend pipeline consisting of pre-processing, modeling, and postprocessing stages. The pre-processing stage first transforms the raw data into suitable inputs for the models. The modeling stage then predicts or reconstructs the input to get the expected output. Finally, the post-processing stage finds discrepancies between the expected and real inputs. The methodology for finding these discrepancies significantly impacts the anomalies identified by this stage. Hence, our work focuses on the limitations in the post-processing stage for predictionbased and reconstruction-based methods. Understanding these limitations also enables us to make appropriate changes to the modeling stage.</p>
<h2>B. Machine Learning-Based Approaches</h2>
<p>Prediction-based approaches generally use the deviation between the predicted and actual values to identify anomalies. Autoregressive Integrated Moving Average (ARIMA) [15] and Long Short Term Memory Recurrent Neural Network with Non-parametric Dynamic Thresholding (LSTM-DT) [9] are well-known examples of prediction-based approaches. ARIMA uses lags and lagged forecast errors to predict future values. Statistical models like ARIMA require the user to have extensive domain knowledge about the time series data in order to adjust the parameters appropriately. Machine learningbased methods like LSTM-DT tend to require less domain knowledge. In the modeling stage, the method uses a separate LSTM neural network to model each channel in order to facilitate granular system control and mitigate errors from high-dimensionality outputs. In the post-processing stage, the method combines an exponentially-weighted average function with a non-parametric dynamic thresholding technique to detect anomalous intervals. Our work examines the limitations of the post-processing stage in LSTM-DT pipeline.</p>
<p>Reconstruction-based approaches learn a latent lowdimensional representation to reconstruct the original input. These methods assume that the latent space prioritizes capturing common patterns within the dataset. Rare events like anomalies are not captured in the latent representation and are less likely to be accurately reconstructed. Principal Component Analysis (PCA) [19], LSTM Auto-Encoders (LSTMAE) [7], and LSTM Variational Auto-Encoders (LSTM-VAE) [14] are examples of reconstruction-based approaches. PCA</p>
<p>is a dimensionality-reduction technique limited to linear reconstructions and fails to leverage spatial-temporal correlation in multivariate settings. LSTM-AE is an auto-encoder built from LSTM layers that learns a latent space representation for the input. The size of the latent space needs to be calibrated to capture generalizable patterns while avoiding noise and anomalies. LSTM-VAE introduces regularization in the latent space using a probabilistic encoder and decoder. However, these methods tend to overfit to the training data, which results in decreased performances [6].</p>
<p>Generative Adversarial Network (GAN) is another reconstruction-based approach to address the overfitting issue. This form of adversarial learning offers regularization to the reconstruction errors. An early example is MAD-GAN [12], which uses spatial-temporal correlation and other dependencies among multiple variables to capture non-linear latent interactions. TadGAN [6] is another GAN-based approach trained with cycle consistency loss to address model instability issues and allow for better reconstruction of time series data. It also proposes several methods in the post-processing stage to calculate reconstruction-based anomaly scores. Similar to prediction-based methods, our work examines post-processing steps presented by TadGAN for reconstruction-based approaches.</p>
<p>Zhao et al. propose MTAD-GAT, a multivariate anomaly detection model that optimizes a joint loss of forecasting- and reconstruction-based models [23]. The architecture of MTAD-GAT differs from AER (our work) where MTAD-GAT is a graph attention network in comparison to AER that includes a bidirectional LSTM network. Moreover, Zhao et al. apply additional preprocessing steps to clean the data. Specifically, they apply Spectral Residual (SR) anomaly detection method [17] to filter out anomalous regions. In this work, we limit preprocessing to data scaling, imputing, and detrending. Furthermore, our approach still operates in an unsupervised setting where there is no prior knowledge about the anomalies in the dataset and no hyperparameter tuning, preventing information leakage. Lastly, we provide analysis to understand why the combination of prediction-based and reconstruction-based anomaly scores can be beneficial in predicting point and collective anomalies.</p>
<h2>III. ML-BASED ANOMALY DETECTION PIPELINE</h2>
<p>Unsupervised time series anomaly detection aims to find a set of anomalous intervals given time series with one or more channels. Ideally, each interval captures an unexpected behavior that deviates from the expected patterns in the signal. This section first formulates the anomaly detection task into a sequence of steps (Fig. 2) similar to Alnegheimish et al.’s work [1] and then critically analyzes existing methods to learn their strengths and weaknesses.</p>
<h2>A. Pre-processing Stage</h2>
<p>The time series signal is pre-processed into inputs suitable for models similar to Geiger et al.’s work [6]. The time series $t$ with $d$ number of channels is divided into train and test splits. The train split is used to learn the parameters for subsequent
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 2. The pipeline for anomaly detection on time series data consists of pre-processing, modeling, and post-processing stages. Our work focuses on models, anomaly scores, and the smoothing function steps of the pipeline.
transformations. Both splits are detrended, as necessary, by fitting and subtracting a least-square fit. Then, the values of each split are min-max normalized to the range $[-1,1]$. Finally, any missing values are imputed with the mean. Let $T$ be the total number of observations in the split without loss of generality. A rolling window with window size $n$ and step size 1 creates $T-n$ number of inputs $\mathbf{x}<em i="i">{i}=\left{t</em>\right}$ such that $i$ represents the index of the first observation in the window. It is worth noting that pre-processing varies based on application scenarios, and the above summary only covers the most common steps.}, t_{i+1}, \ldots, t_{i+n-1</p>
<h2>B. Modeling Stage</h2>
<p>The input and output depend on the type of anomaly detection model. Each input $\mathbf{x}<em i="i">{i} \in \mathbb{R}^{n \times d}$ has $n$ observations based on the window size (default to $n=100$ for reconstructionbased models and $n=250$ for prediction-based models) with $d$ channels. In the case of multivariate inputs, separate models are trained for each channel to ensure traceability [9]. Usually, one channel is selected as the model's target channel. For example, many-to-one prediction-based models will produce single timestep predictions $f</em>$.} \in \mathbb{R}$ for index $i$ of the target channel. On the other hand, many-to-one reconstruction-based models reconstruct the entire target channel and produce a sequence $y_{i: i+n-1} \in \mathbb{R}^{n}$ with the same starting index $i$ as the input $\mathbf{x}_{i</p>
<h2>C. Post-processing Stage - Computing Anomaly Scores</h2>
<p>The computation of anomaly scores differs between prediction-based and reconstruction-based models since they produce different outputs.</p>
<p>Prediction-based models produce a one-step forecast in the forward direction $f_{i+n}$ at index $i+n$ given the input $\mathbf{x}<em i="i">{i}$ starting at index $i$. Only forecasts $f</em>$ for indices $i \in[n+1, T]$ can be computed since prediction-based models require at least</p>
<table>
<thead>
<tr>
<th>Anomaly Scores</th>
<th>Limitations (L)</th>
<th></th>
<th>Successes (S)</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Prediction-based (P)</td>
<td>PL1</td>
<td>High anomaly scores at the early indices often result in falsepositive predictions.</td>
<td>PS1</td>
<td>Prediction-based anomaly scores are better at capturing point anomalies than reconstruction-based anomaly scores.</td>
</tr>
<tr>
<td></td>
<td>PL2</td>
<td>Low prediction-based anomaly scores for contextual anomalies with simple patterns result in false-negative predictions.</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>PL3</td>
<td>Missing prediction-based anomaly scores at the early indices result in false-negative predictions.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reconstruction-based (R)</td>
<td>RL1</td>
<td>Reconstruction-based anomaly scores reducing peaks for point anomalies result in false-negative predictions.</td>
<td>RS1</td>
<td>Reconstruction-based anomaly scores are better at capturing contextual and collective anomalies.</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td>RS2</td>
<td>Reconstruction-based DTW anomaly scores are better at capturing anomalies than AD and PD anomaly scores.</td>
</tr>
</tbody>
</table>
<p>TABLE I: OVERVIEW OF SUCCESSSES (S) AND LIMITATIONS (L) FOR PREDICTION-BASED (P) AND RECONSTRUCTION-BASED (R) METHODS.</p>
<p>$n$ observations to forecast the first value at the index $n+1$. The absolute error between the sequence of forecasts in the forward direction $f$ and the time series $t$ creates the prediction-based anomaly score $\alpha_{p}$ as defined in Eq. (1).</p>
<p>$$
\alpha_{p}(t, f)= \begin{cases}0 &amp; i \in[1, n+1) \ \left|t_{i}-f_{i}\right| &amp; i \in[n+1, T]\end{cases}
$$</p>
<p>Reconstruction-based models reconstruct a sequence of values $y_{i: i+n-1}$ of one channel given the input $\mathbf{x}<em i:="i:" i_n-1="i+n-1">{i}$ starting at index $i$. Each index $i$ in the time series signal has multiple reconstructed values since that index occurs in multiple sequences of $y</em>$. The median of the collection of reconstructed values is used as the final value for index $i$ since using the median achieves better performance than using the mean [6]. Unlike prediction-based anomaly scores, reconstruction-based anomaly scores can be calculated for every index. The reconstruction-based anomaly scores can be calculated in three ways given sequences $t$ and $y$ : point-wise differencing, area differencing, or dynamic time warping.</p>
<p>Point-wise differencing (PD). The reconstruction-based PD anomaly score $\alpha_{r, p}$ defined in Eq. (2) takes the absolute error between the time series $t$ and the reconstructed value $y$ at every index $i$.</p>
<p>$$
\alpha_{r, p}(t, y)=\left|t_{i}-y_{i}\right| \quad i \in[1, T]
$$</p>
<p>Area differencing (AD). The reconstruction-based AD anomaly score $\alpha_{r, a}$ defined in Eq. (3) is created using a fixed length window size that measures the similarity between local regions.</p>
<p>$$
\alpha_{r, a}(t, y)=\frac{1}{2 l}\left|\int_{i-l}^{i+l} t_{i}-y_{i} d t\right| \quad i \in[1, T]
$$</p>
<p>The similarity is measured as the average difference between areas beneath two curves of length $2 l$ calculated using the trapezoidal rule ( $l=10$ by default).</p>
<p>Dynamic Time Warping (DTW). The reconstruction-based DTW anomaly score $\alpha_{r, d}$ defined in Eq. (4) created with dynamic time warping allows for many-to-many mapping between two sequences that are locally out of phase [2]. DTW creates a cost matrix $C \in \mathbb{R}^{2 l \times 2 l}$ such that each $(i, j)$ coordinate represents the distance $c_{q}$ between $t_{i}$ and $y_{j}$.</p>
<p>$$
\alpha_{r, d}(t, y)=\min <em q="1">{C}\left[\frac{1}{Q} \sqrt{\sum</em>\right]
$$}^{Q} c_{q}</p>
<p>Dynamic programming solves for the optimal warp path $C^{*}$ with the minimum warp distances between $t$ and $y$.</p>
<p>Exponentially weighted moving average (EWMA) [10] with a smoothing window of $0.1 T$ is applied to both prediction-based and reconstruction-based anomaly scores to reduce noise.</p>
<h2>D. Post-processing Stage - Identifying Anomalous Sequences</h2>
<p>Hundman et al. [9] used the locally adaptive thresholding function to identify anomalous intervals from the anomaly scores. This function uses a sliding window to compute local thresholds, merges continuous observations to create anomalous sequences, and mitigates false-positives by pruning anomalies.</p>
<p>Let $\alpha$ be the sequence of anomaly scores with a maximum size of length $T$ (one score for each observation). The window size defaults to $\frac{T}{3}$ with a step size of $\frac{T}{3 * 10}$ to optimally identify anomalies. The adaptive threshold for each sliding window is four standard deviations from the window's mean. Observations with scores that exceed that threshold are identified as anomalous. Consecutive anomalous time steps are joined together to create $K$ anomalous sequences. Hundman et al. [9] additionally employed a pruning method to reduce the number of false positives. Let $K_{\max }^{(i)}$ represent the maximum anomaly score in each anomalous sequence $K^{(i)}$. The maxima are sorted in descending order, and the decrease percentage change $p^{(i)}$ is calculated between $K_{\max }^{(i)}$ and $K_{\max }^{(i+1)}$. At the sequence $K^{(j)}$ whose percentage change $p^{(j)}$ does not exceed an empirically defined threshold $\theta$ (defaults to 0.13 ), that sequence and all subsequent sequences are reclassified as normal, i.e., all sequences between [j, K].</p>
<h2>IV. Critical Analysis of Existing Methods</h2>
<p>Despite some minor differences, most prediction-based (P) and reconstruction-based (R) methods follow the same course presented in Fig. 2. Both method types generally have their successes (S) and limitations (L), which are summarized in Table I. Fig. 3 and 4 illustrate the time series signal and the anomaly scores produced by each method in real-world datasets to understand each of their behavior better. In each figure, graph (a) shows the time series signal (blue) with the ground truth anomalous intervals (red). Graph (b) shows the prediction-based anomaly score $\alpha_{p}$ produced by ARIMA (orange) and LSTM-DT (sky blue) models. Graphs (c,d) correspond to the reconstruction-based PD $\alpha_{r, p}$ and DTW</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 3. Anomaly scores for the art_daily_flatmiddle signal from the artificialWithAnomaly dataset with one contextual anomaly. Prediction-based anomaly scores are high near the beginning (PL1) and low for contextual anomalies with simple patterns (PL2). On the other hand, all variations of reconstruction-based anomaly scores could capture the simple contextual anomaly (RS1).</p>
<p>α<sub>r,d</sub> anomaly scores for LSTM-AE (green) and LSTM-VAE (purple) models.</p>
<p><strong>PL1</strong>: High anomaly scores at the early indices often result in false-positive predictions. This error is likely the byproduct of using the exponential weighted moving average function to smooth the anomaly scores. The function requires at least the same number of observations as the size of the smoothing window before it can produce stable anomaly scores. While this limitation occurs in many signals, an example is seen in the prediction-based anomaly scores from the art_daily_flatmiddle signal (see PL1 in Fig. 3(b)).</p>
<p><strong>PL2</strong>: Low prediction-based anomaly scores for contextual anomalies with simple patterns result in false-negative predictions. The cyclic pattern in prediction-based anomaly scores suggests that the models could not fully capture the structure, especially at the change point in the time series. However, in this case, the contextual anomaly is a simple pattern. Therefore, the models can easily forecast the pattern, resulting in nearly zero anomaly scores at the interval. Hence, the adaptive threshold failed to find the contextual anomaly (see PL2 in Fig. 3(b)).</p>
<p><strong>PL3</strong>: Missing prediction-based anomaly scores at the early indices result in false-negative predictions (see PL3 in Fig. 4(b)). This limitation occurs only in prediction-based models since they require at least n observations to forecast the first value at index n+1. This behavior usually results in false-negative predictions for signals with anomalies occurring at the beginning, mainly from datasets like YAHOOA3 with a</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 4. Anomaly scores for the A3Benchmark-TS11 signal from the YAHOOA3 dataset with multiple point anomalies. Prediction-based anomaly scores are better at identifying point anomalies than reconstruction-based anomaly scores (PS1) but fail to find anomalies at the start of the signal (PL3). Of the variations in calculating reconstruction-based anomaly scores, DTW was the best at capturing the point anomalies (RS2).</p>
<p>decent number of point anomalies at the start of the time series.</p>
<p><strong>PS1</strong>: Prediction-based anomaly scores are better at capturing point anomalies than reconstruction-based anomaly scores. For example, prediction-based anomaly scores showed more prominent peaks at anomalies than reconstruction-based anomaly scores for the A3Benchmark-TS11 signal from the YAHOOA3 dataset. As a result, the locally adaptive thresholding function can quickly identify anomalies using prediction-based anomalies, resulting in higher F1 scores for datasets like YAHOOA3 with more point anomalies (see PS1 in Fig. 4(b)).</p>
<p><strong>RL1</strong>: Reconstruction-based anomaly scores reducing peaks for point anomalies result in false-negative predictions. The reconstruction-based anomaly scores are calculated from the median of all predicted values for index i. Since some reconstructed outputs are better at capturing the point anomalies than others, the median value is closer to the true value at index i. This calculation lowers the anomaly scores such that the window-based threshold no longer captures those point anomalies, since the scores are now closer to the window's mean (see RL1 in Fig. 4(c)).</p>
<p><strong>RS1</strong>: Reconstruction-based anomaly scores are better at capturing contextual and collective anomalies. For example, reconstruction-based anomaly scores from the art_daily_flatmiddle signal spiked while prediction-based anomaly scores remained close to zero at the contextual anomaly (see RS1 in Fig. 3(d)). This behavior occurs for prediction-based anomaly scores since the contextual anomaly pattern was easy to model. On the other hand, reconstruction-</p>
<p>based models struggled to recreate the entire interval, since the model tries to reconstruct values from simple anomalous intervals and complex non-anomalous intervals. The sudden shift from an intricate cyclic pattern to a simple pattern results in high reconstruction-based anomaly scores.</p>
<p>RS2: Reconstruction-based DTW anomaly scores are better at capturing anomalies than AD and PD anomaly scores. Reconstruction-based anomaly scores for the A3Benchmark-TS11 signal show that reconstruction-based DTW anomaly scores are less noisy than reconstruction-based PD anomaly scores (see RS2 in Fig. 4(d)). The success of DTW scores is attributed to the method's ability to handle shifts in the alignment of two series. The ablation study by Geiger et al. [6] also reports that DTW slightly outperforms the other two reconstruction error types.</p>
<p>Our observations show that prediction-based and reconstruction-based anomaly scores have successes and limitations that complement one another. For example, we observe from our experiments that prediction-based anomaly scores have an easier time identifying point anomalies but produce relatively more false positives. On the other hand, reconstruction-based anomaly scores have an easier time identifying contextual and collective anomalies but produce relatively more false negatives. Therefore, our method strives to address these limitations and leverage strengths from both types of models as an alternative solution for anomaly detection in time series.</p>
<h2>V. AER: AUTO-ENCODER WITH REGRESSION</h2>
<p>Our solution has three components targeting the models, anomaly scores, and smoothing function steps in the anomaly detection pipeline, as summarized in Fig. 5.</p>
<h3>A. Modeling Stage</h3>
<p>The AER model borrows ideas from LSTM-AE and LSTMDT to produce prediction-based and reconstruction-based anomaly scores simultaneously. The goal is to combine the strengths of both types of methods while overcoming some of their limitations.</p>
<p>The input to the model is $\mathbf{x}<em i-1="i-1">{i} \in \mathbb{R}^{n \times d}$ with $n$ observations and $d$ channels. Like other auto-encoder architectures, AER consists of an encoder and a decoder. While AER uses a regular encoder, the decoder reconstructs $n+2$ instead of $n$ observations by increasing the number of units of the repeated vector layer by two. This minor change allows the model to create an output consisting of three components: the one-step reverse prediction $r</em>$.} \in \mathbb{R}$, the reconstructed sequence $y_{i: i+n-1} \in \mathbb{R}^{n}$, and the one-step-ahead prediction $f_{i+n} \in \mathbb{R</p>
<p>The loss function (Eq. 5) is divided into prediction and reconstruction portions. The prediction loss $V_{\text {pred }}$ is the average of the mean squared error between the pairs of true and prediction values in the reverse $\left(t_{i-1}, r_{i-1}\right)$ and forward direction $\left(t_{i+n}, f_{i+n}\right)$. Likewise, the reconstruction loss $V_{r e c}$ is the mean squared error between the time series $t_{i: i+n-1}$ and the reconstructed sequence $y_{i: i+n-1}$. The contribution of the</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 5. Our solution targets three steps in the anomaly detection pipeline: models, anomaly scores, and smoothing function. AER is a joint model consisting of an LSTM auto-encoder and regressor capable of producing forecasts and reconstructing the input sequence. Second, bi-directional scoring combines prediction-based anomaly scores in the forward and reverse directions to address the issue of missing anomaly scores (PL3). Finally, masking in the smoothing step replaces the values of the anomaly scores at the first few indices to address start-of-sequence false-positive predictions (PL1).
prediction and reconstruction loss is determined by $\gamma \in[0,1]$. The full objective function is defined as follows:</p>
<p>$$
\begin{aligned}
\text { Loss }= &amp; \frac{\gamma}{2} V_{\text {pred }}\left(t_{i-1}, r_{i-1}\right)+\frac{\gamma}{2} V_{\text {pred }}\left(t_{i+n}, f_{i+n}\right) \
&amp; +(1-\gamma) V_{\text {rec }}\left(t_{i: i+n-1}, y_{i: i+n-1}\right)
\end{aligned}
$$</p>
<p>By default, the hyperparameters are $n=100$ observations per input and $\gamma=0.5$ to give equal importance to the prediction and reconstruction losses. One biLSTM layer with $b=30$ units is used for both the encoder and decoder. The latent space is the same dimension as the last hidden state of the bidirectional LSTM layer, which is $2 b$.</p>
<h2>B. Post-processing Stage: Masking</h2>
<p>To overcome the false-positive predictions created from the exponential weighted moving average smoothing function (PL1), we introduce masking. The proposed solution is to mask $m$ indices from the start of the sequence with some value. Our observations show that using the minimum anomaly scores as the masking value produced the best results. By default, $m$ is equal to $0.01 T$ (size of smoothing window) where $T$ is the time series length.</p>
<h2>C. Post-processing Stage: Bi-Directional Scoring</h2>
<p>Bi-directional anomaly scores target the missing start of sequence anomaly scores since prediction-based methods require at least $n$ observations to make the first forecast (PL3). A solution is to produce anomaly scores using the sequence of predictions in the forward direction $f$ and in the reverse direction $r$. The anomaly scores created using $r$ can fill in the missing prediction-based anomaly scores produced by $f$.</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Source</th>
<th>NASA</th>
<th></th>
<th>YAHOO</th>
<th></th>
<th></th>
<th></th>
<th>NAB</th>
<th></th>
<th></th>
<th></th>
<th>UCR</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Name</td>
<td>MSL</td>
<td>SMAP</td>
<td>A1</td>
<td>A2</td>
<td>A3</td>
<td>A4</td>
<td>Art</td>
<td>AdEx</td>
<td>AWS</td>
<td>Traffic</td>
<td>Tweets</td>
</tr>
<tr>
<td>Properties</td>
<td>Synthetic</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td></td>
<td># Signals</td>
<td>27</td>
<td>53</td>
<td>67</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>6</td>
<td>5</td>
<td>17</td>
<td>7</td>
<td>10</td>
</tr>
<tr>
<td># Anomalies</td>
<td>Point (len=1)</td>
<td>0</td>
<td>0</td>
<td>68</td>
<td>33</td>
<td>935</td>
<td>833</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td></td>
<td>Collective (len&gt;1)</td>
<td>36</td>
<td>67</td>
<td>110</td>
<td>167</td>
<td>4</td>
<td>2</td>
<td>6</td>
<td>11</td>
<td>30</td>
<td>14</td>
<td>33</td>
</tr>
<tr>
<td># Data Points</td>
<td>Anomalous Points</td>
<td>7766</td>
<td>54696</td>
<td>1669</td>
<td>466</td>
<td>943</td>
<td>837</td>
<td>2418</td>
<td>795</td>
<td>6312</td>
<td>1560</td>
<td>15651</td>
</tr>
<tr>
<td></td>
<td>Total Points</td>
<td>132046</td>
<td>562800</td>
<td>94866</td>
<td>142100</td>
<td>168000</td>
<td>168000</td>
<td>24192</td>
<td>7965</td>
<td>67644</td>
<td>15662</td>
<td>158511</td>
</tr>
</tbody>
</table>
<p>TABLE II
HIGH-LEVEL OVERVIEW OF ALL 12 BENCHMARK DATASETS.</p>
<p>Again, let $\alpha_{p}$ denote the function to calculate prediction-based anomaly scores. Prediction-based anomaly scores are calculated in the forward direction $\alpha_{p}(t, f)$ for indices $i \in[n+1, T]$ and in the reverse direction $\alpha_{p}(t, r)$ for indices $i \in[1, T-n]$. If masking is used, then the first $m$ values of $\alpha_{p}(t, f)$ are replaced with zeros, and the first $m$ values of $\alpha_{p}(t, r)$ are replaced with $\min \left(\alpha_{p}(t, r)\right)$. Then, the scores $\alpha_{p}(t, f)$ are padded with $n$ zeros in the beginning while $\alpha_{p}(t, r)$ are padded with $n$ zeros at the end to align the anomaly scores.</p>
<p>$$
\alpha_{b}(t, f, r)= \begin{cases}\alpha_{p}(t, r) &amp; i \in[1, n+m+1) \ \frac{1}{2} \alpha_{p}(t, r)+\frac{1}{2} \alpha_{p}(t, f) &amp; i \in[n+m+1, T-n+1) \ \alpha_{p}(t, f) &amp; i \in[T-n+1, T]\end{cases}
$$</p>
<p>The bi-directional anomaly scores $\alpha_{b}$ defined in Eq. (6) consist of averages of both scores in overlapping intervals and the max between both scores in non-overlapping intervals.</p>
<h2>D. Post-processing Stage: Combination Scores</h2>
<p>The bi-directional prediction-based anomaly scores $\alpha_{b}$ and reconstruction-based anomaly errors $\alpha_{r}$ can be used to create the combined anomaly scores $\alpha_{c}$.
1) Prediction-based Only (PRED): The combined anomaly scores $\alpha_{c}$ are calculated using only the bi-directional prediction-based anomaly scores.</p>
<p>$$
\alpha_{c}(t, r, y, f)=\alpha_{b}(t, f, r)
$$</p>
<p>2) Reconstruction-based Only (REC): The combined anomaly scores $\alpha_{c}$ are calculated using only the reconstruction-based anomaly scores. The calculation of reconstruction-based anomaly scores defaults to using DTW since it outperforms reconstruction-based PD and AD (RS2).</p>
<p>$$
\alpha_{c}(t, r, y, f)=\alpha_{r, d}(t, y)
$$</p>
<p>3) Convex (SUM): The combined anomaly scores $\alpha_{c}$ are calculated using a convex combination with parameter weight $\beta$ that controls the two errors' relative importance (by default $\beta=0.5$ ). Both prediction-based and reconstruction-based anomaly scores are min-max scaled to between [0, 1] before the combination.</p>
<p>$$
\alpha_{c}(t, r, y, f)=(1-\beta) \alpha_{r, d}(t, y)+\beta \alpha_{b}(t, f, r)
$$</p>
<p>4) Product (MULT): The combined anomaly scores $\alpha_{c}$ are calculated using a point-wise product between the two scores to emphasize both scores' high values. $\beta$ controls the relative importance of the two errors (by default $\beta=1$ ). Both prediction-based and reconstruction-based anomaly scores are
min-max scaled to between [1, 2] before the combination.</p>
<p>$$
\alpha_{c}(t, r, y, f)=\beta \alpha_{r, d}(t, y) \odot \alpha_{b}(t, f, r)
$$</p>
<h2>VI. EXPERIMENTAL RESULTS</h2>
<p>The three main points we seek to validate in our experimental study are as follows:</p>
<ul>
<li>RQ1: Does the AER framework enable us to discover anomalies more efficiently than we can through other approaches?</li>
<li>RQ2: What is the impact of smoothing function masking and bi-directional scoring on anomaly detection?</li>
<li>RQ3: Do mixture anomaly scores offer additional information compared to using either a prediction-based or reconstruction-based anomaly score on its own?</li>
</ul>
<h2>A. Data Sources</h2>
<p>We use 12 datasets ( 742 signals) spanning various domains to evaluate the models' generalizability and adaptability. The National Aeronautics and Space Administration (NASA) provided two spacecraft telemetry datasets ${ }^{3}$ : Soil Moisture Active Passage (SMAP) and Mars Science Laboratory (MSL) acquired from a satellite and a rover, respectively [9]. Each numeric measurement in the target channel is accompanied by one-hot encoded information about commands sent or received by specific spacecraft modules in a given time window. The Yahoo Webscope Program provided the S5 datasets ${ }^{4}$ consisting of one set of real production traffic to Yahoo properties (A1) and three synthetic datasets (A2, A3, A4) with varying trends, noise, and pre-specified or random seasonality. The A2 and A3 datasets only contain outliers inserted at random positions, while A4 has outliers and change points. The Numenta Anomaly Benchmark (NAB) provided several datasets ${ }^{5}$ from various domains: artificialWithAnomaly (Art), realAdExchange (AdEx), realAWSCloudwatch (AWS), realTraffic (Traffic), realTweets (Tweets). The UCR Time Series Anomaly Archive ${ }^{6}$ is a dataset created to address flaws like triviality, unrealistic anomaly density, mislabeled ground truth, and run-to-failure bias faced by popular datasets [22].</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Models</th>
<th>NASA</th>
<th></th>
<th>YAHOO</th>
<th></th>
<th></th>
<th></th>
<th>NAB</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>UCR</th>
<th>Avg. F1 ( $\mu \pm \sigma$ )</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>MNL</td>
<td>SMAP</td>
<td>A1</td>
<td>A2</td>
<td>A3</td>
<td>A4</td>
<td>Art</td>
<td>AdEx</td>
<td>AWS</td>
<td>Traffic</td>
<td>Tweets</td>
<td>UCR</td>
<td></td>
</tr>
<tr>
<td>ARIMA</td>
<td>0.442</td>
<td>0.333</td>
<td>0.733</td>
<td>0.807</td>
<td>0.818</td>
<td>0.700</td>
<td>0.353</td>
<td>0.518</td>
<td>0.741</td>
<td>0.500</td>
<td>0.567</td>
<td>0.124</td>
<td>$0.553 \pm 0.21$</td>
</tr>
<tr>
<td>LSTM-DT</td>
<td>0.515</td>
<td>0.707</td>
<td>0.721</td>
<td>0.980</td>
<td>0.744</td>
<td>0.638</td>
<td>0.400</td>
<td>0.513</td>
<td>0.741</td>
<td>0.667</td>
<td>0.580</td>
<td>0.391</td>
<td>$0.633 \pm 0.16$</td>
</tr>
<tr>
<td>LSTM-AE</td>
<td>0.500</td>
<td>0.705</td>
<td>0.610</td>
<td>0.866</td>
<td>0.420</td>
<td>0.253</td>
<td>0.545</td>
<td>0.750</td>
<td>0.692</td>
<td>0.457</td>
<td>0.483</td>
<td>0.314</td>
<td>$0.550 \pm 0.17$</td>
</tr>
<tr>
<td>LSTM-VAE</td>
<td>0.526</td>
<td>0.653</td>
<td>0.575</td>
<td>0.823</td>
<td>0.432</td>
<td>0.240</td>
<td>0.667</td>
<td>0.700</td>
<td>0.643</td>
<td>0.483</td>
<td>0.590</td>
<td>0.317</td>
<td>$0.554 \pm 0.16$</td>
</tr>
<tr>
<td>TadGAN</td>
<td>0.584</td>
<td>0.617</td>
<td>0.533</td>
<td>0.842</td>
<td>0.391</td>
<td>0.297</td>
<td>0.571</td>
<td>0.677</td>
<td>0.720</td>
<td>0.581</td>
<td>0.588</td>
<td>0.162</td>
<td>$0.547 \pm 0.18$</td>
</tr>
<tr>
<td>AER*</td>
<td>0.541</td>
<td>0.772</td>
<td>0.772</td>
<td>0.959</td>
<td>0.896</td>
<td>0.722</td>
<td>0.615</td>
<td>0.635</td>
<td>0.621</td>
<td>0.606</td>
<td>0.585</td>
<td>0.470</td>
<td>$0.683 \pm 0.14$</td>
</tr>
</tbody>
</table>
<p>TABLE III F1 SCORES FOR AER COMPARED TO PREDICTION-BASED AND RECONSTRUCTION-BASED BASELINE MODELS. THE HIGHEST SCORES ARE HIGHLIGHTED IN DARK GREEN, WHILE THE LOWEST SCORES ARE HIGHLIGHTED IN DARK RED PER DATASET.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 6. A comparison between the total execution time in seconds on signals from the UCR dataset with increasing sizes. The total execution time consists of the time to train the model pipeline (training time) and the time to convert an input into an output (pipeline latency).</p>
<p>Similar to Geiger et al. [6], Table II summarizes basic information about each dataset. It differentiates between real and synthetic datasets and provides the number of signals and anomalies for each dataset. Each anomaly is classified as either point or collective, depending on the length of the anomaly. Lastly, the total number of anomalous and overall data points are provided for each dataset.</p>
<h2>B. Evaluation Metrics</h2>
<p>Like Hundman et al. [9] and Geiger et al. [6], the metric used in this study is unweighted contextual F1 scores for each dataset. The motivation is that anomalies are rare and windowbased in many real-world application scenarios. The end user's goal is to detect timely true alarms without receiving many false positives. Hence, this evaluation metric is preferable since it prioritizes finding any part of the anomalies. Anomaly scoring is based on overlapping segments: a true positive (TP) if a known anomalous window overlaps any detected windows, a false negative (FN) if a known anomalous window does not overlap any detected windows, and a false positive (FP) if a detected window does not overlap any known anomalous region.</p>
<p>We performed all experiments in an instance of MIT Supercloud [18] with an Intel Xeon Gold 6249 processor, 10 CPU cores, 9 GB RAM per core, and 1 Nvidia Volta V100 GPU. The environment is created using the anaconda/2022a module, which includes TensorFlow 2.0. All models are implemented as primitives and benchmarked using Orion [6].</p>
<h2>C. Baseline Models</h2>
<p>We compare our solution against the following five state-of-the-art methods:</p>
<p><strong>ARIMA</strong> (Prediction-based): Autoregressive Integrated Moving Average [15] is implemented with the StatsModels library. The hyperparameters are empirically set to p=1, d=0, q=0.</p>
<p><strong>LSTM-DT</strong> (Prediction-based): LSTM non-parametric Dynamic Threshold [9] uses two LSTM layers with 80 units and a dropout rate of 0.3. The training hyperparameters were: 35 epochs, batch size of 64, and Adam optimizer.</p>
<p><strong>LSTM-AE</strong> (Reconstruction-based): LSTM auto-encoders [7] use one LSTM layer with 60 units for the encoder and generator. A time-distributed layer with a dense one-unit layer is used to create the output.</p>
<p><strong>LSTM-VAE</strong> (Reconstruction-based): LSTM variational auto-encoders [14] consist of an encoder and a decoder. The encoder uses one shared LSTM layer with 60 units and separate dense layers, each with 60 units, to create the mean and standard deviation vector. The decoder uses a repeat vector layer, an LSTM layer with 60 units, and a time-distributed layer with a dense one-unit layer.</p>
<p><strong>TadGAN</strong> (Reconstruction-based): TadGAN [6] consists of an encoder and generator that use bi-directional LSTM layers, and critics that use 1D convolution layers. The reconstruction-based anomaly scores can be used in combination with the critic scores to create the final anomaly scores. Geiger et al. [6] reported an ablation study merging these scores using summation, product, critic-only, and reconstruction-only combinations.</p>
<h2>D. Benchmarking Results</h2>
<p><strong>AER outperforms baseline models based on averaged F1 scores (RQ1).</strong> Table III shows that AER has an averaged F1 score of 0.683, which is 23.5% higher than the score of the standard ARIMA model. The flexibility of combining prediction-based and reconstruction-based anomaly scores leads to an improvement in F1 scores across the datasets. The graph in Fig. 6 shows the runtime of AER scales in the same order as LSTM-DT, LSTM-AE, and LSTM-VAE. While the runtime is slighter higher for AER than for those models, this is a very reasonable computation cost considering the performance increase.</p>
<p><strong>AER v.s. TadGAN (RQ1).</strong> Similarly, Table III shows that AER outperforms TadGAN by 24.9% in terms of averaged</p>
<p>A: Masking and Bi-Directional Scoring Comparison</p>
<table>
<thead>
<tr>
<th>Models</th>
<th>NASA</th>
<th></th>
<th>YAHOO</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>NAB</th>
<th></th>
<th></th>
<th></th>
<th>UCR</th>
<th>Avg. F1 $(\mu \pm \sigma)$</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>MSL</td>
<td>SMAP</td>
<td>A1</td>
<td>A2</td>
<td>A3</td>
<td>A4</td>
<td>Art</td>
<td>AdEx</td>
<td>AWS</td>
<td>Traffic</td>
<td>Tweets</td>
<td>UCR</td>
<td></td>
</tr>
<tr>
<td>ARIMA</td>
<td>0.442</td>
<td>0.333</td>
<td>0.733</td>
<td>0.807</td>
<td>0.818</td>
<td>0.700</td>
<td>0.353</td>
<td>0.518</td>
<td>0.741</td>
<td>0.500</td>
<td>0.567</td>
<td>0.124</td>
<td>$0.553 \pm 0.21$</td>
</tr>
<tr>
<td>ARIMA (M)*</td>
<td>0.457</td>
<td>0.359</td>
<td>0.752</td>
<td>0.809</td>
<td>0.807</td>
<td>0.690</td>
<td>0.500</td>
<td>0.518</td>
<td>0.769</td>
<td>0.500</td>
<td>0.576</td>
<td>0.148</td>
<td>$0.574 \pm 0.19$</td>
</tr>
<tr>
<td>LSTM-DT</td>
<td>0.515</td>
<td>0.707</td>
<td>0.721</td>
<td>0.980</td>
<td>0.744</td>
<td>0.638</td>
<td>0.400</td>
<td>0.513</td>
<td>0.741</td>
<td>0.667</td>
<td>0.580</td>
<td>0.391</td>
<td>$0.633 \pm 0.16$</td>
</tr>
<tr>
<td>LSTM-DT (M)*</td>
<td>0.521</td>
<td>0.754</td>
<td>0.729</td>
<td>0.987</td>
<td>0.734</td>
<td>0.638</td>
<td>0.600</td>
<td>0.513</td>
<td>0.769</td>
<td>0.686</td>
<td>0.588</td>
<td>0.446</td>
<td>$0.664 \pm 0.14$</td>
</tr>
<tr>
<td>LSTM-DT (M, Bi)*</td>
<td>0.505</td>
<td>0.662</td>
<td>0.755</td>
<td>0.949</td>
<td>0.895</td>
<td>0.792</td>
<td>0.545</td>
<td>0.488</td>
<td>0.786</td>
<td>0.684</td>
<td>0.587</td>
<td>0.432</td>
<td>$0.673 \pm 0.16$</td>
</tr>
<tr>
<td>LSTM-AE</td>
<td>0.500</td>
<td>0.705</td>
<td>0.610</td>
<td>0.866</td>
<td>0.420</td>
<td>0.253</td>
<td>0.545</td>
<td>0.750</td>
<td>0.692</td>
<td>0.457</td>
<td>0.483</td>
<td>0.314</td>
<td>$0.550 \pm 0.17$</td>
</tr>
<tr>
<td>LSTM-AE (M)*</td>
<td>0.522</td>
<td>0.701</td>
<td>0.644</td>
<td>0.882</td>
<td>0.442</td>
<td>0.236</td>
<td>0.667</td>
<td>0.750</td>
<td>0.609</td>
<td>0.533</td>
<td>0.542</td>
<td>0.334</td>
<td>$0.572 \pm 0.17$</td>
</tr>
<tr>
<td>LSTM-VAE</td>
<td>0.526</td>
<td>0.653</td>
<td>0.575</td>
<td>0.823</td>
<td>0.432</td>
<td>0.240</td>
<td>0.667</td>
<td>0.700</td>
<td>0.643</td>
<td>0.483</td>
<td>0.590</td>
<td>0.317</td>
<td>$0.554 \pm 0.16$</td>
</tr>
<tr>
<td>LSTM-VAE (M)*</td>
<td>0.521</td>
<td>0.710</td>
<td>0.628</td>
<td>0.901</td>
<td>0.460</td>
<td>0.246</td>
<td>0.545</td>
<td>0.764</td>
<td>0.615</td>
<td>0.519</td>
<td>0.590</td>
<td>0.333</td>
<td>$0.569 \pm 0.17$</td>
</tr>
<tr>
<td>TadGAN</td>
<td>0.584</td>
<td>0.617</td>
<td>0.533</td>
<td>0.842</td>
<td>0.391</td>
<td>0.297</td>
<td>0.571</td>
<td>0.677</td>
<td>0.720</td>
<td>0.581</td>
<td>0.588</td>
<td>0.162</td>
<td>$0.547 \pm 0.18$</td>
</tr>
<tr>
<td>TadGAN (M)*</td>
<td>0.584</td>
<td>0.630</td>
<td>0.534</td>
<td>0.846</td>
<td>0.395</td>
<td>0.291</td>
<td>0.615</td>
<td>0.677</td>
<td>0.720</td>
<td>0.581</td>
<td>0.588</td>
<td>0.164</td>
<td>$0.552 \pm 0.18$</td>
</tr>
</tbody>
</table>
<p>B: Ablation Study</p>
<table>
<thead>
<tr>
<th>Models</th>
<th>NASA</th>
<th></th>
<th>YAHOO</th>
<th></th>
<th></th>
<th></th>
<th>NAB</th>
<th></th>
<th></th>
<th></th>
<th>UCR</th>
<th>Avg. F1 $(\mu \pm \sigma)$</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>MSL</td>
<td>SMAP</td>
<td>A1</td>
<td>A2</td>
<td>A3</td>
<td>A4</td>
<td>Art</td>
<td>AdEx</td>
<td>AWS</td>
<td>Traffic</td>
<td>Tweets</td>
<td>UCR</td>
</tr>
<tr>
<td>AER (PRED)*</td>
<td>0.494</td>
<td>0.685</td>
<td>0.705</td>
<td>0.923</td>
<td>0.896</td>
<td>0.722</td>
<td>0.500</td>
<td>0.541</td>
<td>0.688</td>
<td>0.615</td>
<td>0.556</td>
<td>0.461</td>
</tr>
<tr>
<td>AER (SUM)*</td>
<td>0.488</td>
<td>0.680</td>
<td>0.714</td>
<td>0.936</td>
<td>0.719</td>
<td>0.553</td>
<td>0.500</td>
<td>0.702</td>
<td>0.733</td>
<td>0.606</td>
<td>0.559</td>
<td>0.428</td>
</tr>
<tr>
<td>AER (REC)*</td>
<td>0.500</td>
<td>0.683</td>
<td>0.707</td>
<td>0.985</td>
<td>0.620</td>
<td>0.416</td>
<td>0.444</td>
<td>0.644</td>
<td>0.692</td>
<td>0.571</td>
<td>0.519</td>
<td>0.363</td>
</tr>
<tr>
<td>AER (MULT)*</td>
<td>0.541</td>
<td>0.772</td>
<td>0.772</td>
<td>0.959</td>
<td>0.752</td>
<td>0.572</td>
<td>0.615</td>
<td>0.635</td>
<td>0.621</td>
<td>0.606</td>
<td>0.585</td>
<td>0.470</td>
</tr>
</tbody>
</table>
<p>TABLE IV F1 SCORES FOR MASKING, BI-DIRECTIONAL SCORING, AND ABLATION STUDY. ALL NEW METHODS ARE MARKED WITH *. THE VARIATION WITH THE HIGHEST SCORE IS IN BOLD FOR EACH MODEL TYPE. THE FINAL AER MODEL USES THE GREEN FILL SCORES.</p>
<p>F1 scores while requiring less execution time (see Fig. 6). This result suggests that combining prediction-based with reconstruction-based anomaly scores could lead to better F1 scores than combining critic-based with reconstruction-based anomaly scores.</p>
<p>Masking improves averaged F1 scores slightly (RQ2). Table IV-A shows that masking scores improved averaged F1 scores by $4.3 \%$, on average, for prediction-based methods and $2.6 \%$, on average, for reconstruction-based methods. Masking anomaly scores benefited prediction-based methods more than reconstruction-based methods since those methods tend to make more false-positive predictions. However, masking may remove anomalies at the start of the signal and hurt model performance on datasets like YAHOOA3 and YAHOOA4.</p>
<p>Bi-directional scoring greatly improves F1 scores on some datasets (RQ2). LSTM-DT (M, Bi) consists of two separate LSTM-DT models trained on the sequence in the forward and reversed direction respectively. Table III-A shows that using bi-directional scoring with LSTM-DT (M, Bi) improved F1 scores by $20.3 \%$ for the YAHOOA3 dataset and $24.1 \%$ for the YAHOOA4 dataset compared to LSTM-DT. These datasets have signals with point anomalies at the beginning that unidirectional prediction-based models cannot predict. However, bi-directional scoring may negatively impact the performance of models on other datasets. Since prediction-based methods tend to produce false-positive predictions, filling in anomaly scores missed by prediction-based anomaly scores allows for more opportunities to produce false positives.</p>
<h2>E. Ablation Study</h2>
<p>Product (MULT) combination of anomaly scores have the highest averaged F1 score across all combination methods (RQ3). The product (MULT) combination of predictionbased and reconstruction-based anomaly scores produced the highest F1 scores on 6 of 12 datasets (see Table IV-B). Most of these datasets were non-synthetic, including MSL, SMAP, YAHOOA1, and Tweets. This combination method outperformed the convex (SUM) combination by $3.7 \%$, the reconstruction-based only (REC) combination by $10.6 \%$, and the prediction-based only (PRED) combination by $1.5 \%$ in terms of averaged F1 scores. Additionally, excluding YAHOOA3 and YAHOOA4 synthetic datasets with many point anomalies result in an averaged F1 score of 0.658 for the product (MULT) combination, a $6.6 \%$ increase compared to 0.617 for prediction-based only (PRED) combination. These results support the idea that mixture anomaly scores offer more information than reconstruction-based anomaly scores in general and prediction-based anomaly scores in cases other than identifying point anomalies.</p>
<p>Prediction-based only (PRED) anomaly scores perform better on datasets with mostly point anomalies. Bidirectional scoring produced the highest F1 scores on datasets like YAHOOA3 and YAHOOA4 with mostly point anomalies (see Table IV-B). This finding is consistent with our findings in the LSTM-DT (M, Bi) model.</p>
<p>The selection of the combination method for each dataset is based on the use case. We recommend that users default to using product (MULT) anomaly scores and using predictionbased only (PRED) scores when users primarily want to</p>
<p>identify point anomalies. The AER model reports the F1 scores of AER (PRED) for the YAHOOA3 and YAHOOA4 datasets with mostly point anomalies and AER (MULT) for the other datasets, even though they might not be the best combination method according to the ablation study. In practice, datasets come without labels since anomaly detection is an unsupervised problem. Hence, it is impossible to retroactively tune the best method to calculate anomaly scores for each dataset.</p>
<h2>F. Limitations and Discussion</h2>
<p>While product mixture scores offer unique insights for anomaly detection, several ways exist to improve the AER framework. For example, the model architecture could be better since our study uses a vanilla auto-encoder architecture with one biLSTM layer for both the encoder and decoder. Our framework is designed to easily extend to any reconstructionbased method with minimum changes to the objective function. Another improvement involves experimenting with the $\gamma$ (defaults to 0.5 ), which controls the contribution of prediction and reconstruction loss to the objective function. An optimal $\gamma$ could lead to more accurate prediction-based and reconstruction-based anomaly scores that ultimately improve F1 scores. Lastly, the findings in our analysis of existing methods in section IV are for datasets we are currently investigating. The identified constraints may not always hold in other datasets.</p>
<p>Although researchers pay increasing attention to building more powerful models to improve the accuracy of predictionbased and reconstruction-based methods, we would like to call for more attention to the post-processing stage. Our study demonstrated that changes in the post-processing stage could significantly improve performances in addition to our proposed model. Future exploration directions could include additional methods to create mixture scores and better heuristics for the selection of such methods (e.g., between PRED and MULT) for each signal.</p>
<h2>VII. CONCLUSION</h2>
<p>This study analyzed the successes and limitations of existing reconstruction-based and prediction-based methods. We proposed a threefold solution to address existing limitations: (1) the AER framework that leverages the successes of prediction-based and reconstruction-based methods, (2) masking anomaly scores to reduce start-of-sequence falsepositive predictions, and (3) bi-directional scoring to address missing forecast issues. In addition, we conducted an ablation study to test several ways of combining prediction-based and reconstruction-based anomaly scores. Our results showed that (1) AER has the highest F1 score averaged across 12 datasets, (2) masking and bi-directional scoring improve F1 scores given the right conditions, (3) the product combination (MULT) of bi-directional and reconstruction-based anomaly scores produces better results, on average, for datasets with mostly collective anomalies. Finally, the code is available at https://github.com/sintel-dev/Orion.</p>
<h2>REFERENCES</h2>
<p>[1] S. Alnegheimish, D. Liu, C. Sala, L. Berti-Equille, and K. Veeramachaneni. Sintel: A machine learning framework to extract insights from signals. In SIGMOD'22. ACM, jun 2022.
[2] D. J. Berndt and J. Clifford. Using dynamic time warping to find patterns in time series. In KDD workshop, page 359-370, 1994.
[3] R. Chalapathy and S. Chawla. Deep learning for anomaly detection: A survey. CoRR, abs/1901.03407, 2019.
[4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. ACM Comput. Surv., 41(3), jul 2009.
[5] F. Cheng, D. Liu, F. Du, Y. Lin, A. Zytek, H. Li, H. Qu, and K. Veeramachaneni. Vbridge: Connecting the dots between features and data to explain healthcare models. IEEE Transactions on Visualization and Computer Graphics, 28(1):378-388, 2021.
[6] A. Geiger, D. Liu, S. Alnegheimish, A. Cuesta-Infante, and K. Veeramachaneni. Tadgan: Time series anomaly detection using generative adversarial networks. CoRR, abs/2009.07769, 2020.
[7] R.-J. Hsieh, J. Chou, and C.-H. Ho. Unsupervised online anomaly detection on multivariate sensing time series data for smart manufacturing. In IEEE SOCA'19, pages 90-97, Nov 2019.
[8] D. Huang, D. Mu, L. Yang, and X. Cai. Codetect: Financial fraud detection with anomaly feature detection. IEEE Access, 6:19161-19174, 2018.
[9] K. Hundman, V. Constantinou, C. Laporte, I. Colwell, and T. Soderstrom. Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. ACM SIGKDD'18, Jul 2018.
[10] J. S. Hunter. The exponentially weighted moving average. Journal of Quality Technology, 18(4):203-210, 1986.
[11] J. Kusuma, L. Doherty, and K. Ramchandran. Distributed compression for sensor networks. In Proceedings 2001 International Conference on Image Processing, volume 1, pages 82-85 vol.1, 2001.
[12] D. Li, D. Chen, L. Shi, B. Jin, J. Goh, and S. Ng. MAD-GAN: multivariate anomaly detection for time series data with generative adversarial networks. CoRR, abs/1901.04997, 2019.
[13] T. Li, M. L. Comer, E. J. Delp, S. R. Desai, J. L. Mathieson, R. H. Foster, and M. W. Chan. Anomaly scoring for prediction-based anomaly detection in time series. In 2020 IEEE Aerospace Conference, pages 17, 2020.
[14] D. Park, Y. Hoshi, and C. C. Kemp. A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder. CoRR, abs/1711.00614, 2017.
[15] E. H. M. Pena, M. V. O. de Assis, and M. L. Proença. Anomaly detection using forecasting methods arima and hwds. In Proceedings 2013 SCCC, pages 63-66, 2013.
[16] J. Pereira and M. Silveira. Learning representations from healthcare time series data for unsupervised anomaly detection. In IEEE BigComp'19, pages $1-7,2019$.
[17] H. Ren, B. Xu, Y. Wang, C. Yi, C. Huang, X. Kou, T. Xing, M. Yang, J. Tong, and Q. Zhang. Time-series anomaly detection service at microsoft. In ACM SIGKDD'19, pages 3009-3017, 2019.
[18] A. Reuther, J. Kepner, C. Byun, S. Samsi, W. Arcand, D. Bestor, B. Bergeron, V. Gadepally, M. Houle, M. Hubbell, M. Jones, A. Klein, L. Milechin, J. Mullen, A. Prout, A. Rosa, C. Yee, and P. Michaleas. Interactive supercomputing on 40,000 cores for machine learning and data analysis. In IEEE HPEC'18, pages 1-6. IEEE, 2018.
[19] H. Ringberg, A. Soule, J. Rexford, and C. Diot. Sensitivity of pca for traffic anomaly detection. SIGMETRICS Perform. Eval. Rev., 35(1):109-120, jun 2007.
[20] V. P. Tuzlukov and Cheng. Signal Processing Noise. CRC Press, Inc., USA, 2002.
[21] J. Verbesselt, A. Zeileis, and M. Herold. Near real-time disturbance detection using satellite image time series. Remote Sensing of Environment, 123:98-108, 2012.
[22] R. Wu and E. Keogh. Current time series anomaly detection benchmarks are flawed and are creating the illusion of progress. IEEE Transactions on Knowledge and Data Engineering, pages 1-1, 2021.
[23] H. Zhao, Y. Wang, J. Duan, C. Huang, D. Cao, Y. Tong, B. Xu, J. Bai, J. Tong, and Q. Zhang. Multivariate time-series anomaly detection via graph attention network. In ICDM'20, pages 841-850. IEEE, 2020.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ NASA data: https://github.com/khundman/telemanom/
${ }^{4}$ Yahoo data: https://webscope.sandbox.yahoo.com/catalog.php?datatype $=$ $\mathrm{s} \&amp; \mathrm{did}=70$
${ }^{5}$ NAB data: https://github.com/numenta/NAB
${ }^{6}$ UCR data: https://www.cs.ucr.edu/ eamonn/time_series_data_2018/UCR_ TimeSeriesAnomalyDatasets2021.zip&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>