<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9233 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9233</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9233</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-272424210</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.03046v1.pdf" target="_blank">Oddballness: universal anomaly detection with language models</a></p>
                <p><strong>Paper Abstract:</strong> We present a new method to detect anomalies in texts (in general: in sequences of any data), using language models, in a totally unsupervised manner. The method considers probabilities (likelihoods) generated by a language model, but instead of focusing on low-likelihood tokens, it considers a new metric introduced in this paper: oddballness. Oddballness measures how ``strange'' a given token is according to the language model. We demonstrate in grammatical error detection tasks (a specific case of text anomaly detection) that oddballness is better than just considering low-likelihood events, if a totally unsupervised setup is assumed.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9233.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9233.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Oddballness</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Oddballness (ξ_D)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distribution-relative anomaly score computed from a language model's token probability distribution: ξ_D(p_i)=sum_j (p_j - p_i)_+ (with g identity), giving values in [0,1] that indicate how 'strange' a token's probability is within the local distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (decoder-only for GPT2/Mistral/Yi; encoder-only masked LM for RoBERTa)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>GPT2-small (small), GPT2-XL (XL), Yi-6b (6B), Mistral 7b (7B), RoBERTa Base, RoBERTa Large</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text token sequences (per-token probability distributions produced by language models)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Learner writing / grammatical error detection datasets (FCE, MultiGED-2023 multilingual GED sets: Czech, German, English-FCE, English-REALEC, Italian, Swedish)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Grammatical errors / token-level anomalies (rare or contextually inconsistent tokens in text sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Obtain the LM's probability distribution over candidate tokens for each token position; compute oddballness ξ_D(p_actual) = sum_j (p_j - p_actual)_+ (with g(x)=x). Mark token as anomalous if ξ_D exceeds a tuned threshold (single hyperparameter). Optionally apply a short prompt to smooth distributions before scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Raw per-token probability thresholding (probability of actual token), top-K inclusion (whether actual token is among top-K predicted tokens), supervised error-detection models (BiLSTM, BERT-based, ELECTRA), and reference to log-anomaly methods (LogBERT/LogGPT top-K approach).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F0.5 score (development and test splits used; thresholds tuned on development set).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Across experiments, oddballness outperformed raw probability thresholding for all tested unsupervised LMs and languages. Representative results: on FCE dataset GPT2-XL: Probability Test F0.5 ≈ 38.86 vs Oddballness Test F0.5 ≈ 40.52; combined best (max of GPT2-XL, RoBERTa Large) Oddballness Test F0.5 ≈ 43.15. On MultiGED (Mistral 7b) examples: Czech Probability Test F0.5 41.90 vs Oddballness 46.61; German Probability 31.36 vs Oddballness 36.68; English-FCE Probability 34.42 vs Oddballness 35.86. With an added prompt, oddballness often improved further (e.g., Czech oddballness Test F0.5 47.75).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Oddballness consistently outperformed the unsupervised baseline of thresholding the raw token probability and also outperformed the top-K approach in multilingual GED tests. However, oddballness underperforms compared to supervised, task-specific state-of-the-art models fine-tuned for grammatical error detection (e.g., ELECTRA, specialized systems achieving much higher F0.5/F-scores).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not competitive with heavily fine-tuned supervised SOTA models; false positives possible because learner texts (CEFR B level) include non-fluent/creative usage that LMs may flag as anomalous; model size alone did not guarantee better performance (GPT2-small sometimes outperformed larger Mistral 7b), suggesting domain mismatch and sensitivity to pretraining/data mismatch; requires tuning a threshold on development data; method relies solely on LM token probabilities and ignores other features; evaluated only on token-level grammatical error detection in text — application to numeric lists/tables is proposed but not empirically validated here.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Oddballness is the complement of a 'probability-of-probability' notion and provides a distribution-relative measure of surprise that corrects for cases where low absolute probability is not anomalous (e.g., many low-probability names in a birthplace slot). Thresholds of oddballness are empirically more universal than raw probability thresholds across models and languages; short prompting to smooth distributions improves performance, and gains from prompting are larger for oddballness than for raw probability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Oddballness: universal anomaly detection with language models', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9233.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9233.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Probability baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Raw token probability thresholding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple unsupervised anomaly detector that flags tokens whose absolute probability (assigned by an LM) falls below a tuned threshold.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Same LMs as used with oddballness: GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (decoder-only and encoder-only masked LM variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text token sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Grammatical error detection datasets (FCE, MultiGED-2023 multilingual GED sets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Grammatical errors / low-likelihood token events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each token position, compute the probability assigned to the actual token by the LM; label token anomalous if probability < tuned threshold (threshold chosen to maximize F0.5 on dev set).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared primarily to oddballness and top-K approach; supervised GED models used as upper-bound baselines in tables (Bi-LSTM, BERT-base, MHMLA, ELECTRA).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F0.5 score (dev and test).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Consistently lower F0.5 than oddballness across experiments. Example figures: on FCE GPT2-XL Probability Test F0.5 ≈ 38.86 (vs oddballness ≈ 40.52); MultiGED Mistral 7b examples: Czech Probability Test 41.90 (oddballness 46.61), German Probability Test 31.36 (oddballness 36.68). Prompting also improved probability results but to a lesser extent than oddballness.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Serves as the primary unsupervised baseline in the paper; oddballness outperforms this baseline across models and languages tested.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fails to distinguish legitimately low-probability but non-anomalous events (e.g., many unique named entities in a position), making raw probability a brittle signal for anomaly in contexts with large domain-specific tails; probability thresholds are less universal across models/languages than oddballness thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates that absolute token probability is a weaker unsupervised anomaly signal than a distribution-relative metric; smoothing via a descriptive prompt helps but benefits oddballness more.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Oddballness: universal anomaly detection with language models', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9233.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9233.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TopK approach</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Top-K predicted-token inclusion (as used in LogBERT / LogGPT anomaly methods)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that treats a token as anomalous if the actual token is not among the top-K highest-likelihood tokens predicted by an LM, used previously in log anomaly detection systems like LogBERT and LogGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogBERT: Log anomaly detection via BERT</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Referenced approaches used encoder-only (LogBERT/BERT-style) and decoder-only (LogGPT/GPT-style) models in prior work; in this paper top-K was evaluated with Mistral 7b for MultiGED experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (encoder-only masked LM in LogBERT; decoder-only GPT-like in LogGPT; experiments here used decoder model Mistral 7b)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varies (LogBERT/LogGPT papers); Mistral 7b used in this paper's top-K evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequence token data (logs in prior work; text tokens in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Prior work: system logs; this paper: learner writing / GED datasets (multilingual MultiGED-2023)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Out-of-distribution / anomalous tokens (token not predicted among top-K)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mask tokens (or consider actual token) and compute LM's top-K predicted tokens; if the actual token is not in top-K, label it anomalous. K is a hyperparameter chosen per setup.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against probability thresholding and oddballness in this paper; originally compared to other anomaly-detection schemes in log-analysis literature.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F0.5 score (used in the paper for GED tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Top-K did not outperform the probability baseline on multilingual GED tasks in this paper. Example: across languages tested with Mistral 7b, top-K scores were generally lower than probability or oddballness methods (e.g., on German TopK Test F0.5 ≈ 28.56 vs Probability 31.36 and Oddballness 36.68 in Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Worse than raw probability thresholding and substantially worse than oddballness for the GED tasks in this study; in prior log-anomaly literature top-K variants were proposed successfully but typically with task-specific training/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Top-K depends on a discrete K hyperparameter that may not generalize across positions and datasets; it ignores the shape of the full distribution and can fail when the LM assigns a long tail of mass across many plausible tokens (where top-K may arbitrarily exclude the correct but plausible token). The paper also notes prior systems often fine-tune specifically for anomaly detection, whereas top-K here was applied in a mostly zero-shot fashion.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Shows that techniques successful in log anomaly detection (top-K inclusion) do not directly transfer better than simple probability thresholding to grammatical error detection on natural text without task-specific fine-tuning; highlights the advantage of distribution-relative signals like oddballness over discrete top-K checks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Oddballness: universal anomaly detection with language models', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogBERT: Log anomaly detection via BERT <em>(Rating: 2)</em></li>
                <li>LogGPT: Log anomaly detection via GPT <em>(Rating: 2)</em></li>
                <li>MultiGED-2023 shared task at NLP4CALL: Multilingual grammatical error detection <em>(Rating: 2)</em></li>
                <li>Compositional sequence labeling models for error detection in learner writing <em>(Rating: 1)</em></li>
                <li>Estimating the support of a high-dimensional distribution <em>(Rating: 1)</em></li>
                <li>Grammatical error correction: A survey of the state of the art <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9233",
    "paper_id": "paper-272424210",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "Oddballness",
            "name_full": "Oddballness (ξ_D)",
            "brief_description": "A distribution-relative anomaly score computed from a language model's token probability distribution: ξ_D(p_i)=sum_j (p_j - p_i)_+ (with g identity), giving values in [0,1] that indicate how 'strange' a token's probability is within the local distribution.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large",
            "model_type": "Transformer (decoder-only for GPT2/Mistral/Yi; encoder-only masked LM for RoBERTa)",
            "model_size": "GPT2-small (small), GPT2-XL (XL), Yi-6b (6B), Mistral 7b (7B), RoBERTa Base, RoBERTa Large",
            "data_type": "Text token sequences (per-token probability distributions produced by language models)",
            "data_domain": "Learner writing / grammatical error detection datasets (FCE, MultiGED-2023 multilingual GED sets: Czech, German, English-FCE, English-REALEC, Italian, Swedish)",
            "anomaly_type": "Grammatical errors / token-level anomalies (rare or contextually inconsistent tokens in text sequences)",
            "method_description": "Obtain the LM's probability distribution over candidate tokens for each token position; compute oddballness ξ_D(p_actual) = sum_j (p_j - p_actual)_+ (with g(x)=x). Mark token as anomalous if ξ_D exceeds a tuned threshold (single hyperparameter). Optionally apply a short prompt to smooth distributions before scoring.",
            "baseline_methods": "Raw per-token probability thresholding (probability of actual token), top-K inclusion (whether actual token is among top-K predicted tokens), supervised error-detection models (BiLSTM, BERT-based, ELECTRA), and reference to log-anomaly methods (LogBERT/LogGPT top-K approach).",
            "performance_metrics": "F0.5 score (development and test splits used; thresholds tuned on development set).",
            "performance_results": "Across experiments, oddballness outperformed raw probability thresholding for all tested unsupervised LMs and languages. Representative results: on FCE dataset GPT2-XL: Probability Test F0.5 ≈ 38.86 vs Oddballness Test F0.5 ≈ 40.52; combined best (max of GPT2-XL, RoBERTa Large) Oddballness Test F0.5 ≈ 43.15. On MultiGED (Mistral 7b) examples: Czech Probability Test F0.5 41.90 vs Oddballness 46.61; German Probability 31.36 vs Oddballness 36.68; English-FCE Probability 34.42 vs Oddballness 35.86. With an added prompt, oddballness often improved further (e.g., Czech oddballness Test F0.5 47.75).",
            "comparison_to_baseline": "Oddballness consistently outperformed the unsupervised baseline of thresholding the raw token probability and also outperformed the top-K approach in multilingual GED tests. However, oddballness underperforms compared to supervised, task-specific state-of-the-art models fine-tuned for grammatical error detection (e.g., ELECTRA, specialized systems achieving much higher F0.5/F-scores).",
            "limitations_or_failure_cases": "Not competitive with heavily fine-tuned supervised SOTA models; false positives possible because learner texts (CEFR B level) include non-fluent/creative usage that LMs may flag as anomalous; model size alone did not guarantee better performance (GPT2-small sometimes outperformed larger Mistral 7b), suggesting domain mismatch and sensitivity to pretraining/data mismatch; requires tuning a threshold on development data; method relies solely on LM token probabilities and ignores other features; evaluated only on token-level grammatical error detection in text — application to numeric lists/tables is proposed but not empirically validated here.",
            "unique_insights": "Oddballness is the complement of a 'probability-of-probability' notion and provides a distribution-relative measure of surprise that corrects for cases where low absolute probability is not anomalous (e.g., many low-probability names in a birthplace slot). Thresholds of oddballness are empirically more universal than raw probability thresholds across models and languages; short prompting to smooth distributions improves performance, and gains from prompting are larger for oddballness than for raw probability.",
            "uuid": "e9233.0",
            "source_info": {
                "paper_title": "Oddballness: universal anomaly detection with language models",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Probability baseline",
            "name_full": "Raw token probability thresholding",
            "brief_description": "A simple unsupervised anomaly detector that flags tokens whose absolute probability (assigned by an LM) falls below a tuned threshold.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Same LMs as used with oddballness: GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large",
            "model_type": "Transformer (decoder-only and encoder-only masked LM variants)",
            "model_size": "GPT2-small, GPT2-XL, Yi-6b, Mistral 7b, RoBERTa Base, RoBERTa Large",
            "data_type": "Text token sequences",
            "data_domain": "Grammatical error detection datasets (FCE, MultiGED-2023 multilingual GED sets)",
            "anomaly_type": "Grammatical errors / low-likelihood token events",
            "method_description": "For each token position, compute the probability assigned to the actual token by the LM; label token anomalous if probability &lt; tuned threshold (threshold chosen to maximize F0.5 on dev set).",
            "baseline_methods": "Compared primarily to oddballness and top-K approach; supervised GED models used as upper-bound baselines in tables (Bi-LSTM, BERT-base, MHMLA, ELECTRA).",
            "performance_metrics": "F0.5 score (dev and test).",
            "performance_results": "Consistently lower F0.5 than oddballness across experiments. Example figures: on FCE GPT2-XL Probability Test F0.5 ≈ 38.86 (vs oddballness ≈ 40.52); MultiGED Mistral 7b examples: Czech Probability Test 41.90 (oddballness 46.61), German Probability Test 31.36 (oddballness 36.68). Prompting also improved probability results but to a lesser extent than oddballness.",
            "comparison_to_baseline": "Serves as the primary unsupervised baseline in the paper; oddballness outperforms this baseline across models and languages tested.",
            "limitations_or_failure_cases": "Fails to distinguish legitimately low-probability but non-anomalous events (e.g., many unique named entities in a position), making raw probability a brittle signal for anomaly in contexts with large domain-specific tails; probability thresholds are less universal across models/languages than oddballness thresholds.",
            "unique_insights": "Demonstrates that absolute token probability is a weaker unsupervised anomaly signal than a distribution-relative metric; smoothing via a descriptive prompt helps but benefits oddballness more.",
            "uuid": "e9233.1",
            "source_info": {
                "paper_title": "Oddballness: universal anomaly detection with language models",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "TopK approach",
            "name_full": "Top-K predicted-token inclusion (as used in LogBERT / LogGPT anomaly methods)",
            "brief_description": "A method that treats a token as anomalous if the actual token is not among the top-K highest-likelihood tokens predicted by an LM, used previously in log anomaly detection systems like LogBERT and LogGPT.",
            "citation_title": "LogBERT: Log anomaly detection via BERT",
            "mention_or_use": "use",
            "model_name": "Referenced approaches used encoder-only (LogBERT/BERT-style) and decoder-only (LogGPT/GPT-style) models in prior work; in this paper top-K was evaluated with Mistral 7b for MultiGED experiments.",
            "model_type": "Transformer (encoder-only masked LM in LogBERT; decoder-only GPT-like in LogGPT; experiments here used decoder model Mistral 7b)",
            "model_size": "Varies (LogBERT/LogGPT papers); Mistral 7b used in this paper's top-K evaluation",
            "data_type": "Sequence token data (logs in prior work; text tokens in this paper)",
            "data_domain": "Prior work: system logs; this paper: learner writing / GED datasets (multilingual MultiGED-2023)",
            "anomaly_type": "Out-of-distribution / anomalous tokens (token not predicted among top-K)",
            "method_description": "Mask tokens (or consider actual token) and compute LM's top-K predicted tokens; if the actual token is not in top-K, label it anomalous. K is a hyperparameter chosen per setup.",
            "baseline_methods": "Compared against probability thresholding and oddballness in this paper; originally compared to other anomaly-detection schemes in log-analysis literature.",
            "performance_metrics": "F0.5 score (used in the paper for GED tasks).",
            "performance_results": "Top-K did not outperform the probability baseline on multilingual GED tasks in this paper. Example: across languages tested with Mistral 7b, top-K scores were generally lower than probability or oddballness methods (e.g., on German TopK Test F0.5 ≈ 28.56 vs Probability 31.36 and Oddballness 36.68 in Table 2).",
            "comparison_to_baseline": "Worse than raw probability thresholding and substantially worse than oddballness for the GED tasks in this study; in prior log-anomaly literature top-K variants were proposed successfully but typically with task-specific training/fine-tuning.",
            "limitations_or_failure_cases": "Top-K depends on a discrete K hyperparameter that may not generalize across positions and datasets; it ignores the shape of the full distribution and can fail when the LM assigns a long tail of mass across many plausible tokens (where top-K may arbitrarily exclude the correct but plausible token). The paper also notes prior systems often fine-tune specifically for anomaly detection, whereas top-K here was applied in a mostly zero-shot fashion.",
            "unique_insights": "Shows that techniques successful in log anomaly detection (top-K inclusion) do not directly transfer better than simple probability thresholding to grammatical error detection on natural text without task-specific fine-tuning; highlights the advantage of distribution-relative signals like oddballness over discrete top-K checks.",
            "uuid": "e9233.2",
            "source_info": {
                "paper_title": "Oddballness: universal anomaly detection with language models",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogBERT: Log anomaly detection via BERT",
            "rating": 2,
            "sanitized_title": "logbert_log_anomaly_detection_via_bert"
        },
        {
            "paper_title": "LogGPT: Log anomaly detection via GPT",
            "rating": 2,
            "sanitized_title": "loggpt_log_anomaly_detection_via_gpt"
        },
        {
            "paper_title": "MultiGED-2023 shared task at NLP4CALL: Multilingual grammatical error detection",
            "rating": 2,
            "sanitized_title": "multiged2023_shared_task_at_nlp4call_multilingual_grammatical_error_detection"
        },
        {
            "paper_title": "Compositional sequence labeling models for error detection in learner writing",
            "rating": 1,
            "sanitized_title": "compositional_sequence_labeling_models_for_error_detection_in_learner_writing"
        },
        {
            "paper_title": "Estimating the support of a high-dimensional distribution",
            "rating": 1,
            "sanitized_title": "estimating_the_support_of_a_highdimensional_distribution"
        },
        {
            "paper_title": "Grammatical error correction: A survey of the state of the art",
            "rating": 1,
            "sanitized_title": "grammatical_error_correction_a_survey_of_the_state_of_the_art"
        }
    ],
    "cost": 0.011227749999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Oddballness: universal anomaly detection with language models
September 6, 2024</p>
<p>Filip Graliński filipg@amu.edu.pl 
Ryszard Staruch ryszard.staruch@amu.edu.pl 
Krzysztof Jurkiewicz </p>
<p>Adam Mickiewicz University</p>
<p>Adam Mickiewicz University</p>
<p>Adam Mickiewicz University</p>
<p>Adam Mickiewicz University</p>
<p>Oddballness: universal anomaly detection with language models
September 6, 2024D91184CF586541C4C652F3A8FB0B4D23arXiv:2409.03046v1[cs.CL]
We present a new method to detect anomalies in texts (in general: in sequences of any data), using language models, in a totally unsupervised manner.The method considers probabilities (likelihoods) generated by a language model, but instead of focusing on low-likelihood tokens, it considers a new metric introduced in this paper: oddballness.Oddballness measures how "strange" a given token is according to the language model.We demonstrate in grammatical error detection tasks (a specific case of text anomaly detection) that oddballness is better than just considering low-likelihood events, if a totally unsupervised setup is assumed.</p>
<p>Introduction</p>
<p>Not all events with low probability are weird or oddball when they happen.For instance, the probability of a specific deal in the game of bridge is extremely low (p b = 1 5.36×10 28 for each deal).So every time you are dealt cards in bridge, something unfathomable happens?Of course not, actually an event of the very low probability p b must happen (with the probability 1!).</p>
<p>Another example, imagine two probability distributions:</p>
<ol>
<li>D 1 = {p 1 = 1 100 , p 2 = 99 100 }, 2. D 2 = {p 1 = 1 100 , p 2 = 1 100 , . . .p 100 = 1 100 }, Intuitively, p 1 is much more oddball in D 1 than p 1 in D 2 .So, how to measure oddballness?We already know that a low probability is not enough.Let us start with basic assumptions or axioms of oddballness.Then we will define oddballness and show their practical usage for anomaly detection when applied to probability distributions generated by language models.</li>
</ol>
<p>Let us assume a discrete probability distribution D = (Ω, Pr), where Ω could be finite or countably infinite.From now on, for simplicity, we define D just as a multiset of probabilities:
D = {p 1 , p 2 , p 3 , . . .} = {Pr(ω i ) : ω i ∈ Ω}.
We would like to define an oddballness measure1 for an outcome (elementary event) of a given probability p i within a distribution D:
ξ D (p i ), ξ D : D → [0, 1]
Let us define some common-sense axioms for oddballness:
(O0) ξ D (p i ) ∈ [0, 1] -let
us assume our measure is from 0 to 1, (O1) ξ D (0) = 1 -if an impossible event happens, that's pretty oddball!(O2) for any distribution ξ D (max{p i }) = 0 the most likely outcome is not oddball at all,
(O3) p i = p j → ξ D (p i ) = ξ D (p j ) -all
we know is a distribution, hence two outcomes of the same probability must have the same oddballness (within the same distribution),
(O4) p i &lt; p j → ξ D (p i ) ≥ ξ D (p j )
, if some outcome is less likely than another outcome, it cannot be less oddball,
(O5) (continuity) for any distribution D = {p 1 , p 2 , p 3 , . . .}, the function f (x) = ξ Dx (x), where D x = {x, p 2 × 1−x 1−p 1 , . . . , p i × 1−x 1−p 1 , .
. .}, is continuous -if we change the probabilities a little bit, the oddballness should not change much.</p>
<p>Note that (O2) implies the following two facts:
(F1) p i &gt; 0.5 → ξ D (p i ) = 0,
what is more likely than 50% is not oddball at all, (F2) for any distribution D = {p 1 = 1 N , . . ., p N = 1 N }, ξ D (p i ) = 0 -like in the bridge example.</p>
<p>Oddballness measure</p>
<p>Let us a define a measure that fulfils (O0)-(O5).First, let us define an auxiliary function:</p>
<p>x + = max(0, x) (In other words, this is the ReLU activation function.)Now let us assume a probability distribution D = {p 1 , p 2 , p 3 , . ..}.Let us define the following oddballness measure:
ξ D (p i ) = j g((p j − p i ) + ) j g(p j )
, where g is any monotonic and continuous function for which g(0) = 0 and g(1) = 1.This measure satisfies the axioms (O0)-(O5).</p>
<p>From now on, we assume the identity function g(x) = x (though, for instance x 2 or x 3 can be used as well); the oddballness measure simplifies to:
ξ D (p i ) = j (p j − p i ) + .
Let us check this measure for our distributions D 1 and D 2 given as examples:
ξ D (p 2 ) π D (p 2 ) p 1 = 0.05 p 2 = 0.25 p 3 = 0.7
Figure 1: Illustration of oddballness ξ D and "probability of probability" (π D ) for event ω 2 of probablity p 2 = 0.25 for D 3 = {p 1 = 0.7, p 2 = 0.25, p 3 = 0.05}
• ξ D 1 (p 1 ) = 0.98, • ξ D 1 (p 2 ) = 0, • ξ D 2 (p i ) = 0, Consider another example: D 3 = {p 1 = 0.7, p 2 = 0.25, p 3 = 0.05}, then: ξ D 3 (p 1 ) = 0, ξ D 3 (p 2 ) = (0.7 − 0.25) + + (0.25 − 0.25) + + (0.05 − 0.25) + = 0.45, ξ D 3 (p 3 ) = 0.85.</p>
<p>Oddballness as a complement of probability of probability</p>
<p>Interestingly, oddballness can be interpreted as the complement of the probability of a probability.By probability of a probability p i with respect to distribution D, or π D (p i ), we mean the probability that an event of probability p i (not necessarily ω i ) happens, with two extra assumptions:</p>
<p>• all probabilities smaller than p i are also summed up,</p>
<p>• for each event ω j with probability p j &gt; p i , we assume that it contains a "subevent" of probability p i , hence for each such event we sum p i in.</p>
<p>It can be shown that
π D (p i ) = 1 − ξ D (p i ).
Intuitively, it makes sense: An event is oddball if the probability of any event happening with similar probability is low.See Figure 1 for an illustration of the relation between oddballness and probability of probability.</p>
<p>What's the practical use?</p>
<p>The oddballness measure can be used to detect anomalies or errors, e.g. in a text, assuming that we have a good language model.The language model will give a probability distribution for any word in a text, some words will be given higher probability (likelihood), some lower.We could mark words with low probability as suspicious, but sometimes a low-probability event must occur.For instance, the distribution for the gap in the sentence:</p>
<p>I was born in . . ., a small village should be (for a good language model2 ) composed of a large number of names, each with a rather low probability.Hence, like in the bridge example, we should be not surprised to see a low-probability event.On the other hand, in the sentence: I was born in New . . .City any word other than York is pretty unlikely (and oddball).Therefore, rather than probability, the oddballness should be used -words with oddballness exceeded some threshold should be marked as suspicious, they are potential mistakes or anomalies to be checked by humans.This way, we could devise a grammar checking/proofreading system that is not trained or fine-tuned in a supervised manner for the specific task of error detection.</p>
<p>The notion of oddballness might not be that useful in the world before good language models, when usually only static discrete distributions were assumed.Language models, even for the same text, can generate vastly different types of probability distributions for each position:</p>
<p>• sometimes the model is almost certain and almost all probability will be assigned to one token,</p>
<p>• sometimes the model will predict a group of possible tokens plus a long tail of less likely tokens,</p>
<p>• and sometimes the model is uncertain and the entropy is high.</p>
<p>In this paper, we focus on applying oddballness to grammatical error detection (see Section 6).Some related (but not the same) ideas were, however, proposed in the field of log anomaly detection, as log sequences can be viewed as a modality similar to natural language.LogBERT by Guo et al. [2021] was trained on, in a semi-supervised way, on log sequences.During anomaly detection some tokens are masked and the probability distribution is obtained from LogBERT for each of them.If the probability of the actual token is not one of the K highest-likelihood tokens (K is a hyperparameter), the token is considered anomalous (we will refer to this method as topK later).LogGPT by Han et al. [2023] is a similar idea, but applied to an decoder-only GPT-like architecture, rather than an encoder-only Transformer, but still the same approach of considering topK prediction is taken for the anomaly detection itself, though the model is also fine-tuned specifically for anomaly detection.</p>
<p>In general, there is a vast body of literature on anomaly or outlier detection (see, for instance: Schölkopf et al. [2001], Breunig et al. [2000], Liu et al. [2008]).Oddballness is different, as it considers only probabilities from a language model (or any other statistical model) rather than any intrinsic feature of events in question.</p>
<p>Experiments with error detection</p>
<p>Table 1 presents the results on the FCE dataset Yannakoudakis et al. [2011].In each case, using the oddballness value as the threshold gives better results than using the probability value.All thresholds were adjusted to maximize the F0.5 score on the development set.The maximum oddballness value from the GPT2-XL and RoBERTa Large Liu [2019] models produced the best F0.5 score on the test set.The result is slightly better than the BiLSTM model by Rei and Yannakoudakis [2016], which was trained specifically to detect errors in texts, while GPT2-XL and RoBERTa Large are models which were trained, in a self-supervised manner, on the masked token prediction task.Although results based on the oddballness value are not competitive with state-of-the-art solutions, it should be noted that the oddballness technique does not involve any task-specific fine-tuning, except for single-hyperparameter tuning.Also, the texts were written by CEFR B level students, indicating that they may not be fully proficient in the language.This could cause the language model to flag not fluent words as incorrect and thus predict correct words as erroneous.This may also explain why the smaller GPT2-small model outperforms the much larger Mistral 7b model.This study demonstrates that the oddballness measure can yield superior results compared to using probability values for anomaly detection.We also tested the Mistral 7b model for multilingual GED datasets used in MultiGED-2023 Shared Task Volodina et al. [2023] using the same approach as in experiments for the FCE dataset.The results in Table 2 show that for all languages the oddballness method outperforms the probability method.We also tested adding the following prompt before each sentence: "An example of a grammatically correct text in any language that may be out of context: <example>" to make probability distribution more smooth.The results in Table 3 show that this trick helps in almost all experiments, but the improvements for the oddballness method are greater compared to the probability method.Looking at the thresholds we can also indicate that thresholds for the oddballness value are more universal compared to the probability thresholds.We also tested the top-K approach.For multilingual GED task it does not provide better results than probability method in any language.The best solutions for each dataset in the shared task are better compared to oddballness value results, but again those solutions are trained to predict incorrect tokens, whereas the oddballness method approach focus more on predicting spans in texts that are most likely errorneous without precisely labeling all incorrect tokens.</p>
<p>Conclusions</p>
<p>We have showed that using a new metric for anomalous events, oddballness, is better than just considering low-likelihood tokens, at least for grammatical error detection tasks.The method based on oddballness yields worse results than state-of-the-art models heavily fine-tuned for the task (Bryant et al. [2023]), but its great advantage is that it can be used for any language model, without any fine-tuning.This technique can be applied potentially to anomaly detection in sequences of any type of data, assuming that a "language" model was pre-trained.</p>
<p>Table 1 :
1
Results for the Grammatical Errror Detection FCE Dataset.Thresholds tuned with the development set.
ModelMethodThreshold Dev F0.5 Test F0.5 SubmissionUnsupervised methodsGPT2-smallProbability 0.000235.0037.74LinkGPT2-smallOddballness 0.8437.2739.19LinkGPT2-XLProbabilisty 0.000136.0038.86LinkGPT2-XLOddballness 0.8538.1740.52LinkYi-6bProbability 0.000534.3837.35LinkYi-6bOddballness 0.8536.7739.83LinkMistral 7bProbability 0.000333.6836.86LinkMistral 7bOddballness 0.8935.0438.00LinkRoBERTa BaseProbability 0.00532.6333.62LinkRoBERTa BaseOddballness 0.9133.0834.86LinkRoBERTa LargeProbability 0.01432.7433.39LinkRoBERTa LargeOddballness 0.8434.3335.78Linkmin(GPT2-XL, RoBERTa Large)Probability 0.000136.8839.31Linkmax(GPT2-XL, RoBERTa Large)Oddballness 0.8940.3243.15LinkSupervised methodsRei and Yannakoudakis [2016] Bi-LSTM-46.0041.10-Bell et al. [2019]BERT-base --57.28-Kaneko and Komachi [2019]MHMLA-61.65-Yuan et al. [2021]ELECTRA --72.93-</p>
<p>Table 2 :
2
Results for the Mistral 7b model on MultiGED-2023 shared task dataset
LanguageMethodThreshold Dev F0.5 Test F0.5CzechTopK3041.1938.55CzechProbability 0.00244.3441.90CzechOddballness 0.8449.1646.61GermanTopK8630.5528.56GermanProbability 0.00132.5331.36GermanOddballness 0.8937.6936.68English -FCETopK20029.1431.60English -FCEProbability 0.0000932.5134.42English -FCEOddballness 0.9035.0735.86English -REALEC TopK38027.6228.10English -REALEC Probability 0.0000631.0831.05English -REALEC Oddballness 0.9532.8932.09ItalianTopK1822.7624.55ItalianProbability 0.00323.6626.00ItalianOddballness 0.827.3129.75SwedishTopK3635.1433.93SwedishProbability 0.00337.3436.11SwedishOddballness 0.7940.2638.93</p>
<p>Table 3 :
3
Results for the Mistral 7b model on MultiGED-2023 shared task dataset with an additional prompt
LanguageMethodThreshold Dev F0.5 Test F0.5CzechTopK1841.2239.52CzechProbability 0.00244.2642.70CzechOddballness 0.8549.6847.75GermanTopK7231.7830.39GermanProbability 0.000834.4832.91GermanOddballness 0.8939.4439.26English -FCETopK14029.7631.72English -FCEProbability 0.000332.8734.91English -FCEOddballness 0.9035.9636.37English -REALEC TopK50027.7027.60English -REALEC Probability 0.0000830.4430.18English -REALEC Oddballness 0.9232.8132.35ItalianTopK7423.1724.55ItalianProbability 0.000825.2626.56ItalianOddballness 0.9231.6632.62SwedishTopK5036.9634.93SwedishProbability 0.00239.3438.26SwedishOddballness 0.8443.4541.99
Measure understood informally, not as defined in measure theory.
For this example, an encoder-only model trained on the masked language task should be assumed, for instance RoBERTaLiu [2019].</p>
<p>Context is key: Grammatical error detection with contextual word representations. S J Bell, H Yannakoudakis, M Rei, CoRR, abs/1906.065932019</p>
<p>LOF: identifying density-based local outliers. M M Breunig, H.-P Kriegel, R T Ng, J Sander, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of data2000</p>
<p>Grammatical error correction: A survey of the state of the art. C Bryant, Z Yuan, M R Qorib, H Cao, H T Ng, T Briscoe, 10.1162/coli_a_00478Computational Linguistics. 1530- 9312July 2023</p>
<p>LogBERT: Log anomaly detection via BERT. H Guo, S Yuan, X Wu, 2021 international joint conference on neural networks (IJCNN). IEEE2021</p>
<p>LogGPT: Log anomaly detection via GPT. X Han, S Yuan, M Trabelsi, 2023 IEEE International Conference on Big Data (BigData). IEEE2023</p>
<p>Multi-head multi-layer attention to deep language representations for grammatical error detection. M Kaneko, M Komachi, CoRR, abs/1904.073342019</p>
<p>Isolation forest. F T Liu, K M Ting, Z.-H Zhou, 2008 Eighth IEEE International Conference on Data Mining. IEEE2008</p>
<p>Y Liu, arXiv:1907.11692RoBERTa: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Compositional sequence labeling models for error detection in learner writing. M Rei, H Yannakoudakis, 10.18653/v1/P16-1112Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Long Papers. K Erk, N A Smith, the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational LinguisticsAug. 20161</p>
<p>Estimating the support of a high-dimensional distribution. B Schölkopf, J C Platt, J Shawe-Taylor, A J Smola, R C Williamson, 10.1162/089976601750264965Neural Computation. 1372001</p>
<p>MultiGED-2023 shared task at NLP4CALL: Multilingual grammatical error detection. E Volodina, C Bryant, A Caines, O De Clercq, J.-C Frey, E Ershova, A Rosen, O Vinogradova, Proceedings of the 12th Workshop on NLP for Computer Assisted Language Learning. D Alfter, E Volodina, T François, A Jönsson, E Rennes, the 12th Workshop on NLP for Computer Assisted Language LearningTórshavn, Faroe IslandsLiU Electronic PressMay 2023</p>
<p>A new dataset and method for automatically grading ESOL texts. H Yannakoudakis, T Briscoe, B Medlock, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. D Lin, Y Matsumoto, R Mihalcea, the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesPortland, Oregon, USAAssociation for Computational LinguisticsJune 2011</p>
<p>Multi-class grammatical error detection for correction: A tale of two systems. Z Yuan, S Taslimipoor, C Davis, C Bryant, 10.18653/v1/2021.emnlp-main.687Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. M.-F Moens, X Huang, L Specia, S W -T, Yih, the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNov. 2021Online and Punta Cana</p>            </div>
        </div>

    </div>
</body>
</html>