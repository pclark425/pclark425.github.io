<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9883 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9883</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9883</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-168.html">extraction-schema-168</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <p><strong>Paper ID:</strong> paper-e65b346d442e9962a4276dc1c1af2956d9d5f1eb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e65b346d442e9962a4276dc1c1af2956d9d5f1eb" target="_blank">Self-Instruct: Aligning Language Models with Self-Generated Instructions</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> Self-Instruct is introduced, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations by generating instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model.</p>
                <p><strong>Paper Abstract:</strong> Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9883.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9883.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SUPERNI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SUPERNATURALInStructions (SUPERNI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark of diverse NLP instruction-following tasks used to evaluate zero-shot generalization of instruction-tuned LMs; here used as an unseen-task testbed of 119 tasks (100 instances each) to measure ability to follow task definitions without in-context examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) and instruction-tuned variants (GPT3_SELF-INST, InstructGPT_001, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>GPT-3 davinci engine (175B parameters) is used as the vanilla LM for generation and finetuning; InstructGPT engines (text-davinci-001/002/003) used as comparison and for distillation in later experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / instruction-following evaluation (general NLP tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Zero-shot evaluation: models are prompted only with the task instruction (no in-context examples) and produce outputs; deterministic decoding with temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Aggregate task performance as reported on SUPERNI (task-dependent metrics aggregated into overall performance); reported as absolute improvement percentages over baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>SUPERNI evaluation set: 119 unseen tasks with 100 instances each, used for zero-shot assessment of instruction-following.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Finetuning GPT-3 on SELF-INSTRUCT data yields a +33.1% absolute improvement over vanilla GPT-3 on SUPERNI and nearly matches performance of InstructGPT_001; combining SELF-INSTRUCT with SUPERNI training yields additional gains. Models trained directly on SUPERNI training still perform best on the SUPERNI test set due to instruction-style match.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Generated SELF-INSTRUCT data deviates from typical SUPERNI/NLP tasks; performance gains plateau earlier on SUPERNI (after hundreds of instructions) likely because distributions differ; SUPERNI metrics aggregate heterogeneous task metrics so interpretation must consider task-specific measures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>SUPERNI is an automated benchmark (task-specific metrics) rather than human expert evaluation; authors compare model performance against InstructGPT (trained with private human data) to approximate human-supervised baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use deterministic decoding for evaluation (temperature=0); complement task-specific benchmark data (like SUPERNI) with diverse generated instruction data to improve generalization; combine datasets for best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9883.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UserExpertEval252</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Human expert evaluation on 252 user-oriented, expert-written instructions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-evaluation setup using 252 novel, user-oriented tasks written by the authors; two expert annotators rated model outputs on a 4-level scale (A-D) to evaluate practical instruction-following in diverse, real-world-like tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) variants including GPT3_SELF-INST and InstructGPT_001/002/003</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>Same as above: GPT-3 davinci as base; instruction-tuned variants via OpenAI endpoints (text-davinci-001/002/003) used for comparison and distillation experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing / human-oriented instruction-following evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Expert human rating: two authors (instruction writers) independently rated anonymized model outputs against the instruction, input, and target output, using a 4-level categorical scale; results reported from one evaluator with inter-rater agreement analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Four-level quality categories: A (valid & satisfying), B (acceptable with minor errors), C (relevant but significant errors), D (irrelevant/invalid). Acceptable outcomes often counted as A or B.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>252 user-oriented instructions curated by the authors (one instance per instruction); used as a testbed for diverse, unfamiliar instruction types.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT3_SELF-INST outperforms other publicly available instruction-trained variants (T0, SUPERNI-trained GPT3) on this set; when counting A or B as acceptable, GPT3_SELF-INST is ~5% behind InstructGPT_001. InstructGPT_002 and _003 score higher overall.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Many tasks require domain expertise and cannot be reliably judged by crowdworkers; evaluators were authors which may introduce bias; small evaluator pool (two experts).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>This evaluation uses expert human judgment rather than automated metrics, providing a more faithful assessment for complex or creative tasks that lack automatic metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use expert annotators for diverse, specialized instruction evaluation; anonymize model outputs and randomize order; report inter-rater agreement; treat A/B as acceptable when measuring practical usefulness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9883.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ROUGE-L Filtering</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ROUGE-L similarity threshold for instruction deduplication</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated diversity filter that computes ROUGE-L between a newly generated instruction and existing instructions; new instructions are added only if their highest ROUGE-L overlap is < 0.7 to encourage diversity and reduce redundancy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) (used to generate instructions that are then compared)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>GPT-3 davinci engine (175B) used to produce generated instructions; ROUGE-L applied as a postprocess filter.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / dataset curation and evaluation for instruction generation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Compute ROUGE-L between generated instruction and all existing instructions; accept if maximum overlap < 0.7.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>ROUGE-L similarity < 0.7 as pass criterion for adding to task pool (heuristic for novelty/diversity).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>Applied to the generated dataset (52K instructions) and seed pool (175 tasks) during SELF-INSTRUCT generation.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Using the ROUGE-L < 0.7 threshold helps produce a set of generated instructions with limited overlap to seeds and earlier generations, contributing to a diverse 52K-instruction dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>ROUGE-L is a surface-overlap measure and may not capture semantic novelty; fixed threshold is heuristic and may both miss semantically novel paraphrases or accept near-duplicates with low lexical overlap.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Automated lexical similarity filtering is faster than manual curation but less semantically precise than human judgment; recommended to combine with human review or learned semantic filters for higher fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use ROUGE-L thresholding as a coarse filter for diversity, supplemented with heuristic exclusions (multimodal keywords) and later human or learned filtering to improve quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9883.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DataQualityReview200</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expert annotation-based data quality review (200-sample)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Manual quality assessment where an expert annotator labeled whether generated instructions, inputs, and outputs were valid/correct for a random sample of 200 instructions (1 instance each) to estimate noise levels in the generated dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) (source of the generated instruction-instance data being reviewed)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>Generation from GPT-3 davinci; manual expert review used to assess resulting data quality.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / dataset validation and quality assessment</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Expert labels on 200 randomly sampled instruction-instance triples, marking validity of instruction, appropriateness of input, correctness of output, and whether all fields are valid.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Reported percentages: instruction valid 92%, input appropriate 79%, output correct 58%, all fields valid 54%.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>Random 200 instruction-instance pairs sampled from the SELF-INSTRUCT generated dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Most generated instructions are meaningful (92%), inputs are mostly appropriate (79%), but outputs are noisier (58% correct); overall only 54% of sampled triples had all fields valid, indicating useful but noisy supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Single expert annotator (author) performed labeling which may bias results; limited sample size; binary/ternary judgments may not capture degrees of utility.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Expert manual review provides a grounded estimate of noise compared to automated heuristics; shows that synthetic data may be imperfect but still useful for finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Expect and tolerate moderate noise; improve data quality via human postediting or distillation from stronger models; consider larger multi-annotator reviews for robust estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9883.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DataScalingDistill</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of data size and quality (scaling & distillation experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of ablations studying how the size and quality of SELF-INSTRUCT generated data affect downstream instruction-following: subsampling instruction counts and distilling outputs from a stronger model (InstructGPT_003) to improve supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) as the finetuned target; InstructGPT_003 used as a source of higher-quality outputs for distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>GPT-3 davinci (175B) finetuned on varying amounts of SELF-INSTRUCT data; InstructGPT_003 provides regenerated outputs to improve label quality.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / instruction-following model development and empirical analysis</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Subsample different numbers of instructions from generated data, finetune GPT-3, and human-evaluate on the 252 user-oriented tasks; also replace instance outputs by re-generating them with InstructGPT_003 (distillation) and measure improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Human-evaluated acceptable response rates (A/B ratings); performance as a function of training data size and output quality.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>SELF-INSTRUCT generated data subsets (ranging from 175 seeds up to 52K), evaluated on the 252 user-oriented instructions; SUPERNI also used to observe plateau behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Performance improves consistently with more generated instructions but plateaus around 16K instructions for the user-oriented set; on SUPERNI performance plateaus earlier (hundreds). Replacing outputs with those generated by InstructGPT_003 yields ~10% absolute improvement, showing quality gains matter.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Diminishing returns with larger quantities of noisy data; distillation requires a stronger model or human annotation which increases cost; plateau points depend on target evaluation distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Shows trade-off between quantity and quality: more synthetic data helps but high-quality labels (from humans or stronger models) provide substantial additional gains.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Scale generated data up to empirically-determined plateau (e.g., ~16K here) and prioritize improving label quality (distillation or human review) to get further gains; combine synthetic and curated datasets for broader generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9883.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InputFirstOutputFirst</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Input-first and Output-first instance generation approaches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two prompting strategies for generating instance input-output pairs from instructions: input-first (generate input then output) for non-classification tasks, and output-first (generate class labels then condition input on label) to avoid class-label imbalance in classification tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) as the generator for both approaches</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>GPT-3 davinci prompted with few-shot templates to produce inputs and outputs per instruction using the two strategies depending on task type.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / synthetic data generation for instruction tuning</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Apply input-first prompts for non-classification tasks and output-first prompts for classification tasks identified by a classification detector; inspect label balance and quality.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Preference is given to generation order that reduces label bias (output-first for classification) and produces valid input-output pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>Generated instances for the 52K instructions; classification detection used 12 classification and 19 non-classification seed examples.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Input-first sometimes biases inputs toward a single label (e.g., positive example bias in grammar tasks), while output-first for classification yields more balanced class-conditioned inputs and mitigates label imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Still produces noisy instances; only a small number of instances per task generated per round; relies on correct identification of classification tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Automated generation via these approaches is cheaper but noisier than human-created instances; output-first acts as a lightweight technique to emulate balanced annotation.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Use output-first for classification tasks to condition inputs on each label and avoid label collapse; use varied in-context templates and multiple rounds to increase instance diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9883.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FilteringHeuristics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automatic heuristics for filtering invalid or duplicate generations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of applied heuristics to filter out low-quality or inapplicable instructions/instances: exclude multimodal keywords (image/graph), remove exact duplicates or same-input/different-output conflicts, length-based filters, and outputs that merely repeat inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>GPT-3 (davinci) (used to generate candidate tasks/instances which are then filtered)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td>Generation followed by rule-based postprocessing to enforce usability of synthetic data for text-only LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / dataset curation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Apply deterministic heuristics to generated data to discard invalid or unsupported tasks/instances prior to inclusion in the training pool.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Heuristics: reject instructions containing excluded keywords (e.g., image, picture, graph), filter instances that are exact duplicates or conflicting, drop outputs that equal inputs or are too long/short.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>Applied during construction of the 52K instruction / 82K instance SELF-INSTRUCT dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>After heuristic filtering and deduplication, the pipeline produced ~52,445 instructions and ~82,439 instances; heuristics remove obviously invalid or multimodal tasks unsuitable for text-only finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Heuristics are brittle and may accidentally exclude valid tasks (e.g., legitimate references to images) or fail to catch subtle semantic errors; manual tuning of rules required.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Automated heuristics scale cheaply relative to manual filtering but are less precise; recommended to augment with human review or learned classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Combine simple heuristic filters with semantic similarity checks (ROUGE-L) and consider follow-up human or model-based quality improvement (distillation or reward-model selection).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9883.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9883.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, benchmarks, and results for evaluating LLM-generated scientific theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>InterRaterMetrics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Inter-rater agreement metrics used for human evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Quantitative measures computed to assess reliability of expert annotations: Cohen's kappa for categorical agreement (both 4-class and binary acceptable vs not) and Spearman correlation treating ratings as ordinal.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_name</strong></td>
                            <td>N/A (applies to human evaluation procedure for LLM outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Evaluation methodology / human annotation reliability</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Compute Cohen's kappa for 4-level categorical ratings and for binary acceptable classification (A/B vs C/D); compute Spearman rho for ordinal correlation of ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Reported values: Cohen's kappa = 0.58 for 4-class (moderate), kappa = 0.75 for binary acceptable (substantial), Spearman rho = 0.81 (high correlation).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_dataset</strong></td>
                            <td>Human ratings collected on model outputs for the 252 user-oriented instruction set (two expert evaluators).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Moderate agreement on the fine-grained 4-class scale and substantial agreement on binary acceptable judgments; high ordinal correlation indicates consistent ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Only two evaluators (both authors), which can limit generalizability of agreement statistics; potential shared biases among expert annotators.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_or_traditional</strong></td>
                            <td>Demonstrates that expert human evaluation can be made reliable with inter-rater metrics, and binary acceptability yields higher agreement than fine-grained quality grades.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Report both fine-grained and binary agreement metrics; use Spearman rho for ordinal consistency; when possible include more annotators and external experts to improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Instruct: Aligning Language Models with Self-Generated Instructions', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks. <em>(Rating: 2)</em></li>
                <li>Training Language Models to Follow Instructions with Human Feedback <em>(Rating: 2)</em></li>
                <li>Unnatural instructions: Tuning language models with (almost) no human labor. <em>(Rating: 2)</em></li>
                <li>PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts. <em>(Rating: 1)</em></li>
                <li>Finetuned Language Models are Zero-Shot Learners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9883",
    "paper_id": "paper-e65b346d442e9962a4276dc1c1af2956d9d5f1eb",
    "extraction_schema_id": "extraction-schema-168",
    "extracted_data": [
        {
            "name_short": "SUPERNI",
            "name_full": "SUPERNATURALInStructions (SUPERNI)",
            "brief_description": "A benchmark of diverse NLP instruction-following tasks used to evaluate zero-shot generalization of instruction-tuned LMs; here used as an unseen-task testbed of 119 tasks (100 instances each) to measure ability to follow task definitions without in-context examples.",
            "citation_title": "Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks.",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) and instruction-tuned variants (GPT3_SELF-INST, InstructGPT_001, etc.)",
            "llm_description": "GPT-3 davinci engine (175B parameters) is used as the vanilla LM for generation and finetuning; InstructGPT engines (text-davinci-001/002/003) used as comparison and for distillation in later experiments.",
            "scientific_domain": "Natural Language Processing / instruction-following evaluation (general NLP tasks)",
            "evaluation_method": "Zero-shot evaluation: models are prompted only with the task instruction (no in-context examples) and produce outputs; deterministic decoding with temperature=0.",
            "evaluation_criteria": "Aggregate task performance as reported on SUPERNI (task-dependent metrics aggregated into overall performance); reported as absolute improvement percentages over baseline.",
            "benchmark_or_dataset": "SUPERNI evaluation set: 119 unseen tasks with 100 instances each, used for zero-shot assessment of instruction-following.",
            "results_summary": "Finetuning GPT-3 on SELF-INSTRUCT data yields a +33.1% absolute improvement over vanilla GPT-3 on SUPERNI and nearly matches performance of InstructGPT_001; combining SELF-INSTRUCT with SUPERNI training yields additional gains. Models trained directly on SUPERNI training still perform best on the SUPERNI test set due to instruction-style match.",
            "limitations_or_challenges": "Generated SELF-INSTRUCT data deviates from typical SUPERNI/NLP tasks; performance gains plateau earlier on SUPERNI (after hundreds of instructions) likely because distributions differ; SUPERNI metrics aggregate heterogeneous task metrics so interpretation must consider task-specific measures.",
            "comparison_to_human_or_traditional": "SUPERNI is an automated benchmark (task-specific metrics) rather than human expert evaluation; authors compare model performance against InstructGPT (trained with private human data) to approximate human-supervised baselines.",
            "recommendations_or_best_practices": "Use deterministic decoding for evaluation (temperature=0); complement task-specific benchmark data (like SUPERNI) with diverse generated instruction data to improve generalization; combine datasets for best performance.",
            "uuid": "e9883.0",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "UserExpertEval252",
            "name_full": "Human expert evaluation on 252 user-oriented, expert-written instructions",
            "brief_description": "A human-evaluation setup using 252 novel, user-oriented tasks written by the authors; two expert annotators rated model outputs on a 4-level scale (A-D) to evaluate practical instruction-following in diverse, real-world-like tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) variants including GPT3_SELF-INST and InstructGPT_001/002/003",
            "llm_description": "Same as above: GPT-3 davinci as base; instruction-tuned variants via OpenAI endpoints (text-davinci-001/002/003) used for comparison and distillation experiments.",
            "scientific_domain": "Natural Language Processing / human-oriented instruction-following evaluation",
            "evaluation_method": "Expert human rating: two authors (instruction writers) independently rated anonymized model outputs against the instruction, input, and target output, using a 4-level categorical scale; results reported from one evaluator with inter-rater agreement analysis.",
            "evaluation_criteria": "Four-level quality categories: A (valid & satisfying), B (acceptable with minor errors), C (relevant but significant errors), D (irrelevant/invalid). Acceptable outcomes often counted as A or B.",
            "benchmark_or_dataset": "252 user-oriented instructions curated by the authors (one instance per instruction); used as a testbed for diverse, unfamiliar instruction types.",
            "results_summary": "GPT3_SELF-INST outperforms other publicly available instruction-trained variants (T0, SUPERNI-trained GPT3) on this set; when counting A or B as acceptable, GPT3_SELF-INST is ~5% behind InstructGPT_001. InstructGPT_002 and _003 score higher overall.",
            "limitations_or_challenges": "Many tasks require domain expertise and cannot be reliably judged by crowdworkers; evaluators were authors which may introduce bias; small evaluator pool (two experts).",
            "comparison_to_human_or_traditional": "This evaluation uses expert human judgment rather than automated metrics, providing a more faithful assessment for complex or creative tasks that lack automatic metrics.",
            "recommendations_or_best_practices": "Use expert annotators for diverse, specialized instruction evaluation; anonymize model outputs and randomize order; report inter-rater agreement; treat A/B as acceptable when measuring practical usefulness.",
            "uuid": "e9883.1",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "ROUGE-L Filtering",
            "name_full": "ROUGE-L similarity threshold for instruction deduplication",
            "brief_description": "An automated diversity filter that computes ROUGE-L between a newly generated instruction and existing instructions; new instructions are added only if their highest ROUGE-L overlap is &lt; 0.7 to encourage diversity and reduce redundancy.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) (used to generate instructions that are then compared)",
            "llm_description": "GPT-3 davinci engine (175B) used to produce generated instructions; ROUGE-L applied as a postprocess filter.",
            "scientific_domain": "NLP / dataset curation and evaluation for instruction generation",
            "evaluation_method": "Compute ROUGE-L between generated instruction and all existing instructions; accept if maximum overlap &lt; 0.7.",
            "evaluation_criteria": "ROUGE-L similarity &lt; 0.7 as pass criterion for adding to task pool (heuristic for novelty/diversity).",
            "benchmark_or_dataset": "Applied to the generated dataset (52K instructions) and seed pool (175 tasks) during SELF-INSTRUCT generation.",
            "results_summary": "Using the ROUGE-L &lt; 0.7 threshold helps produce a set of generated instructions with limited overlap to seeds and earlier generations, contributing to a diverse 52K-instruction dataset.",
            "limitations_or_challenges": "ROUGE-L is a surface-overlap measure and may not capture semantic novelty; fixed threshold is heuristic and may both miss semantically novel paraphrases or accept near-duplicates with low lexical overlap.",
            "comparison_to_human_or_traditional": "Automated lexical similarity filtering is faster than manual curation but less semantically precise than human judgment; recommended to combine with human review or learned semantic filters for higher fidelity.",
            "recommendations_or_best_practices": "Use ROUGE-L thresholding as a coarse filter for diversity, supplemented with heuristic exclusions (multimodal keywords) and later human or learned filtering to improve quality.",
            "uuid": "e9883.2",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "DataQualityReview200",
            "name_full": "Expert annotation-based data quality review (200-sample)",
            "brief_description": "Manual quality assessment where an expert annotator labeled whether generated instructions, inputs, and outputs were valid/correct for a random sample of 200 instructions (1 instance each) to estimate noise levels in the generated dataset.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) (source of the generated instruction-instance data being reviewed)",
            "llm_description": "Generation from GPT-3 davinci; manual expert review used to assess resulting data quality.",
            "scientific_domain": "NLP / dataset validation and quality assessment",
            "evaluation_method": "Expert labels on 200 randomly sampled instruction-instance triples, marking validity of instruction, appropriateness of input, correctness of output, and whether all fields are valid.",
            "evaluation_criteria": "Reported percentages: instruction valid 92%, input appropriate 79%, output correct 58%, all fields valid 54%.",
            "benchmark_or_dataset": "Random 200 instruction-instance pairs sampled from the SELF-INSTRUCT generated dataset.",
            "results_summary": "Most generated instructions are meaningful (92%), inputs are mostly appropriate (79%), but outputs are noisier (58% correct); overall only 54% of sampled triples had all fields valid, indicating useful but noisy supervision.",
            "limitations_or_challenges": "Single expert annotator (author) performed labeling which may bias results; limited sample size; binary/ternary judgments may not capture degrees of utility.",
            "comparison_to_human_or_traditional": "Expert manual review provides a grounded estimate of noise compared to automated heuristics; shows that synthetic data may be imperfect but still useful for finetuning.",
            "recommendations_or_best_practices": "Expect and tolerate moderate noise; improve data quality via human postediting or distillation from stronger models; consider larger multi-annotator reviews for robust estimates.",
            "uuid": "e9883.3",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "DataScalingDistill",
            "name_full": "Effect of data size and quality (scaling & distillation experiments)",
            "brief_description": "A set of ablations studying how the size and quality of SELF-INSTRUCT generated data affect downstream instruction-following: subsampling instruction counts and distilling outputs from a stronger model (InstructGPT_003) to improve supervision.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) as the finetuned target; InstructGPT_003 used as a source of higher-quality outputs for distillation.",
            "llm_description": "GPT-3 davinci (175B) finetuned on varying amounts of SELF-INSTRUCT data; InstructGPT_003 provides regenerated outputs to improve label quality.",
            "scientific_domain": "NLP / instruction-following model development and empirical analysis",
            "evaluation_method": "Subsample different numbers of instructions from generated data, finetune GPT-3, and human-evaluate on the 252 user-oriented tasks; also replace instance outputs by re-generating them with InstructGPT_003 (distillation) and measure improvement.",
            "evaluation_criteria": "Human-evaluated acceptable response rates (A/B ratings); performance as a function of training data size and output quality.",
            "benchmark_or_dataset": "SELF-INSTRUCT generated data subsets (ranging from 175 seeds up to 52K), evaluated on the 252 user-oriented instructions; SUPERNI also used to observe plateau behavior.",
            "results_summary": "Performance improves consistently with more generated instructions but plateaus around 16K instructions for the user-oriented set; on SUPERNI performance plateaus earlier (hundreds). Replacing outputs with those generated by InstructGPT_003 yields ~10% absolute improvement, showing quality gains matter.",
            "limitations_or_challenges": "Diminishing returns with larger quantities of noisy data; distillation requires a stronger model or human annotation which increases cost; plateau points depend on target evaluation distribution.",
            "comparison_to_human_or_traditional": "Shows trade-off between quantity and quality: more synthetic data helps but high-quality labels (from humans or stronger models) provide substantial additional gains.",
            "recommendations_or_best_practices": "Scale generated data up to empirically-determined plateau (e.g., ~16K here) and prioritize improving label quality (distillation or human review) to get further gains; combine synthetic and curated datasets for broader generalization.",
            "uuid": "e9883.4",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "InputFirstOutputFirst",
            "name_full": "Input-first and Output-first instance generation approaches",
            "brief_description": "Two prompting strategies for generating instance input-output pairs from instructions: input-first (generate input then output) for non-classification tasks, and output-first (generate class labels then condition input on label) to avoid class-label imbalance in classification tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) as the generator for both approaches",
            "llm_description": "GPT-3 davinci prompted with few-shot templates to produce inputs and outputs per instruction using the two strategies depending on task type.",
            "scientific_domain": "NLP / synthetic data generation for instruction tuning",
            "evaluation_method": "Apply input-first prompts for non-classification tasks and output-first prompts for classification tasks identified by a classification detector; inspect label balance and quality.",
            "evaluation_criteria": "Preference is given to generation order that reduces label bias (output-first for classification) and produces valid input-output pairs.",
            "benchmark_or_dataset": "Generated instances for the 52K instructions; classification detection used 12 classification and 19 non-classification seed examples.",
            "results_summary": "Input-first sometimes biases inputs toward a single label (e.g., positive example bias in grammar tasks), while output-first for classification yields more balanced class-conditioned inputs and mitigates label imbalance.",
            "limitations_or_challenges": "Still produces noisy instances; only a small number of instances per task generated per round; relies on correct identification of classification tasks.",
            "comparison_to_human_or_traditional": "Automated generation via these approaches is cheaper but noisier than human-created instances; output-first acts as a lightweight technique to emulate balanced annotation.",
            "recommendations_or_best_practices": "Use output-first for classification tasks to condition inputs on each label and avoid label collapse; use varied in-context templates and multiple rounds to increase instance diversity.",
            "uuid": "e9883.5",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "FilteringHeuristics",
            "name_full": "Automatic heuristics for filtering invalid or duplicate generations",
            "brief_description": "A set of applied heuristics to filter out low-quality or inapplicable instructions/instances: exclude multimodal keywords (image/graph), remove exact duplicates or same-input/different-output conflicts, length-based filters, and outputs that merely repeat inputs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "GPT-3 (davinci) (used to generate candidate tasks/instances which are then filtered)",
            "llm_description": "Generation followed by rule-based postprocessing to enforce usability of synthetic data for text-only LMs.",
            "scientific_domain": "NLP / dataset curation",
            "evaluation_method": "Apply deterministic heuristics to generated data to discard invalid or unsupported tasks/instances prior to inclusion in the training pool.",
            "evaluation_criteria": "Heuristics: reject instructions containing excluded keywords (e.g., image, picture, graph), filter instances that are exact duplicates or conflicting, drop outputs that equal inputs or are too long/short.",
            "benchmark_or_dataset": "Applied during construction of the 52K instruction / 82K instance SELF-INSTRUCT dataset.",
            "results_summary": "After heuristic filtering and deduplication, the pipeline produced ~52,445 instructions and ~82,439 instances; heuristics remove obviously invalid or multimodal tasks unsuitable for text-only finetuning.",
            "limitations_or_challenges": "Heuristics are brittle and may accidentally exclude valid tasks (e.g., legitimate references to images) or fail to catch subtle semantic errors; manual tuning of rules required.",
            "comparison_to_human_or_traditional": "Automated heuristics scale cheaply relative to manual filtering but are less precise; recommended to augment with human review or learned classifiers.",
            "recommendations_or_best_practices": "Combine simple heuristic filters with semantic similarity checks (ROUGE-L) and consider follow-up human or model-based quality improvement (distillation or reward-model selection).",
            "uuid": "e9883.6",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "InterRaterMetrics",
            "name_full": "Inter-rater agreement metrics used for human evaluation",
            "brief_description": "Quantitative measures computed to assess reliability of expert annotations: Cohen's kappa for categorical agreement (both 4-class and binary acceptable vs not) and Spearman correlation treating ratings as ordinal.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_name": "N/A (applies to human evaluation procedure for LLM outputs)",
            "llm_description": null,
            "scientific_domain": "Evaluation methodology / human annotation reliability",
            "evaluation_method": "Compute Cohen's kappa for 4-level categorical ratings and for binary acceptable classification (A/B vs C/D); compute Spearman rho for ordinal correlation of ratings.",
            "evaluation_criteria": "Reported values: Cohen's kappa = 0.58 for 4-class (moderate), kappa = 0.75 for binary acceptable (substantial), Spearman rho = 0.81 (high correlation).",
            "benchmark_or_dataset": "Human ratings collected on model outputs for the 252 user-oriented instruction set (two expert evaluators).",
            "results_summary": "Moderate agreement on the fine-grained 4-class scale and substantial agreement on binary acceptable judgments; high ordinal correlation indicates consistent ranking.",
            "limitations_or_challenges": "Only two evaluators (both authors), which can limit generalizability of agreement statistics; potential shared biases among expert annotators.",
            "comparison_to_human_or_traditional": "Demonstrates that expert human evaluation can be made reliable with inter-rater metrics, and binary acceptability yields higher agreement than fine-grained quality grades.",
            "recommendations_or_best_practices": "Report both fine-grained and binary agreement metrics; use Spearman rho for ordinal consistency; when possible include more annotators and external experts to improve robustness.",
            "uuid": "e9883.7",
            "source_info": {
                "paper_title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks.",
            "rating": 2
        },
        {
            "paper_title": "Training Language Models to Follow Instructions with Human Feedback",
            "rating": 2
        },
        {
            "paper_title": "Unnatural instructions: Tuning language models with (almost) no human labor.",
            "rating": 2
        },
        {
            "paper_title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.",
            "rating": 1
        },
        {
            "paper_title": "Finetuned Language Models are Zero-Shot Learners",
            "rating": 1
        }
    ],
    "cost": 0.0181775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Self-Instruct: Aligning Language Models with Self-Generated Instructions</h1>
<p>Yizhong Wang<em> Yeganeh Kordi</em> Swaroop Mishra<em> Alisa Liu</em><br>Noah A. Smith<strong> Daniel Khashabi* Hannaneh Hajishirzi</strong><br><em>University of Washington </em>Tehran Polytechnic <em>Arizona State University<br>${ }^{\text {</em> }}$ Johns Hopkins University ${ }^{+}$Allen Institute for AI<br>yizhongw@cs.washington.edu</p>
<h4>Abstract</h4>
<p>Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce SELFINSTRUCT, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a $33 \%$ absolute improvement over the original model on SUPERNATURALInStruCtions, on par with the performance of InstructGPT ${ }<em 001="001">{001}{ }^{1}$ which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin, leaving only a $5 \%$ absolute gap behind InstructGPT ${ }</em>$}$. SELF-INSTRUCT provides an almost annotation-free method for aligning pretrained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. ${ }^{2</p>
<h2>1 Introduction</h2>
<p>The recent NLP literature has witnessed a tremendous amount of activity in building models that can</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Selected tasks from the generated instruction data using vanilla GPT3. Some texts are reformatted for presentation. See Table 10 for more examples.
follow natural language instructions (Mishra et al., 2022; Wei et al., 2022; Sanh et al., 2022; Wang et al., 2022; Ouyang et al., 2022; Chung et al., 2022, i.a.). These developments are powered by two key components: large pretrained language models (LM) and human-written instruction data (e.g., PromptSource (Bach et al., 2022) and SUPERNATURALInStruCtions (Wang et al., 2022, SuPERNI for short)). However, collecting such instruction data is costly and often suffers limited diversity given that most human generations tend to be popular NLP tasks, falling short of covering a true variety of tasks and different ways to</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: A high-level overview of SELF-INSTRUCT. The process starts with a small seed set of tasks as the task pool. Random tasks are sampled from the task pool, and used to prompt an off-the-shelf LM to generate both new instructions and corresponding instances, followed by filtering low-quality or similar generations, and then added back to the initial repository of tasks. The resulting data can be used for the instruction tuning of the language model itself later to follow instructions better. Tasks shown in the figure are generated by GPT3.</p>
<p>describe them. Continuing to improve the quality and coverage of instruction-tuned models necessitates the development of alternative approaches for supervising the instruction tuning process.</p>
<p>In this work, we introduce SELF-INSTRUCT, a semi-automated process for instruction-tuning a pretrained LM using instructional signals from the model itself. The overall process is an iterative bootstrapping algorithm (see Figure 2), which starts off with a limited (e.g., 175 in our study) seed set of manually-written tasks that are used to guide the overall generation. In the first phase, the model is prompted to generate instructions for new tasks. This step leverages the existing collection of instructions to create more broad-coverage instructions that define (often new) tasks. Given the newly-generated set of instructions, the framework also creates input-output instances for them, which can be later used for supervising the instruction tuning. Finally, various heuristics are used to automatically filter low-quality or repeated instructions, before adding the remaining valid tasks to the task pool. This process can be repeated for many iterations until reaching a large number of tasks.</p>
<p>To evaluate SELF-INSTRUCT empirically, we run this framework on GPT3 (Brown et al., 2020), which is a vanilla LM (§3). The iterative SELF-INSTRUCT process on this model leads to about 52k instructions, paired with about 82K instance inputs and target outputs. We observe that the resulting data provides a diverse range of creative tasks, as is demonstrated by examples in Figure 1. These generated tasks deviate from the distribution of typical NLP tasks, and also have fairly small overlap with the seed tasks (§3.2). On this resulting data, we build GPT3<sub>SELF-INST</sub> by finetuning GPT3 (i.e., the same model used for generating the instruction data). We evaluate GPT3<sub>SELF-INST</sub> in comparison to various other models on both typical NLP tasks included in SUPERNI (Wang et al., 2022), and a set of new instructions that are created for novel usage of instruction-following models (§4). The results indicate that GPT3<sub>SELF-INST</sub> outperforms GPT3 (the original model) by a large margin (+33.1%) and nearly matches the performance of InstructGPT<sub>001</sub>. Moreover, our human evaluation on the newly-created instruction set shows that GPT3<sub>SELF-INST</sub> demonstrates a broad range of instruction following ability, outperforming models trained on other publicly available instruction datasets and leaving only a 5% gap behind InstructGPT<sub>001</sub>.</p>
<p>In summary, our contributions are: (1) we introduce SELF-INSTRUCT, a method for inducing instruction following capabilities with minimal human-labeled data; (2) we demonstrate its effectiveness via extensive instruction-tuning experiments; and (3) we release a large synthetic dataset of 52K instructions and a set of manually-written novel tasks for building and evaluating future instruction-following models.</p>
<h2>2 Method</h2>
<p>Annotating large-scale instruction data can be challenging for humans because it requires 1) creativity to come up with novel tasks and 2) expertise for writing the solutions to each task. Here, we detail our process for SELF-INSTRUCT, which refers to the pipeline of generating tasks with a vanilla pretrained language model itself, filtering the generated data, and then conducting instruction tuning with this generated data in order to align the LM to follow instructions better. This pipeline is depicted in Figure 2.</p>
<h3>2.1 Defining Instruction Data</h3>
<p>The instruction data we want to generate contains a set of instructions $\left{I_{t}\right}$, each of which defines a task $t$ in natural language. Task $t$ has $n_{t} \geq 1$ input-output instances $\left{\left(X_{t, i}, Y_{t, i}\right)\right}<em t="t">{i=1}^{n</em>\right}$. Note that the instruction and instance input does not have a strict boundary in many cases. For example, "write an essay about school safety" can be a valid instruction that we expect models to respond to directly, while it can also be formulated as "write an essay about the following topic" as the instruction, and "school safety" as an instance input. To encourage the diversity of the data format, we allow such instructions that do not require additional input (i.e., $X$ is empty).}}$. A model $M$ is expected to produce the output, given the task instruction and the corresponding input: $M\left(I_{t}, X_{t, i}\right)=Y_{t, i}$, for $i \in\left{1, \ldots, n_{t</p>
<h3>2.2 Automatic Instruction Data Generation</h3>
<p>Our pipeline for data generation consists of four steps: 1) generating task instructions, 2) determining if the instruction represents a classification task, 3) instance generation with either an input-first or output-first approach, and 4) filtering low-quality data.</p>
<p>Instruction Generation. At the first step, SELFINSTRUCT generates new instructions from a small set of seed human-written instructions in a bootstrapping fashion. We initiate the task pool with 175 tasks ( 1 instruction and 1 instance for each task). ${ }^{3}$ For every step, we sample 8 task instructions from this pool as in-context examples. Of</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>the 8 instructions, 6 are from the human-written tasks, and 2 are from the model-generated tasks in previous steps to promote diversity. The prompting template is shown in Table 5.</p>
<p>Classification Task Identification. Because we need two different approaches for classification and non-classification tasks, we next identify whether the generated instruction represents a classification task or not. ${ }^{4}$ We prompt the LM in a few-shot way to determine this, using 12 classification instructions and 19 non-classification instructions from the seed tasks. The prompting template is shown in Table 6.</p>
<p>Instance Generation. Given the instructions and their task type, we generate instances for each instruction independently. This is challenging because it requires the model to understand what the target task is, based on the instruction, figure out what additional input fields are needed and generate them, and finally complete the task by producing the output. We found that pretrained LMs can achieve this to a large extent when prompted with instruction-input-output in-context examples from other tasks. A natural way to do this is the Inputfirst Approach, where we can ask an LM to come up with the input fields first based on the instruction, and then produce the corresponding output. This generation order is similar to how models are used to respond to instruction and input, but here with in-context examples from other tasks. The prompting template is shown in Table 7.</p>
<p>However, we found that this approach can generate inputs biased toward one label, especially for classification tasks (e.g., for grammar error detection, it usually generates grammatical input). Therefore, we additionally propose an Output-first Approach for classification tasks, where we first generate the possible class labels, and then condition the input generation on each class label. The prompting template is shown in Table 8. ${ }^{5}$ We apply the output-first approach to the classification tasks identified in the former step, and the inputfirst approach to the remaining non-classification tasks.</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>Filtering and Postprocessing. To encourage diversity, a new instruction is added to the task pool only when its ROUGE-L similarity with any existing instruction is less than 0.7 . We also exclude instructions that contain some specific keywords (e.g., image, picture, graph) that usually can not be processed by LMs. When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs. Invalid generations are identified and filtered out based on heuristics (e.g., instruction is too long or too short, instance output is a repetition of the input).</p>
<h3>2.3 Finetuning the LM to Follow Instructions</h3>
<p>After creating large-scale instruction data, we use it to finetune the original LM (i.e., SELF-INSTRUCT). To do this, we concatenate the instruction and instance input as a prompt and train the model to generate the instance output in a standard supervised way. To make the model robust to different formats, we use multiple templates to encode the instruction and instance input together. For example, the instruction can be prefixed with "Task:" or not, the input can be prefixed with "Input:" or not, "Output:" can be appended at the end of the prompt or not, and different numbers of break lines can be put in the middle, etc.</p>
<h2>3 Self-Instruct Data from GPT3</h2>
<p>In this section, we apply our method for inducing instruction data to GPT3 as a case study. We use the largest GPT3 LM ("davinci" engine) accessed through the OpenAI API. ${ }^{6}$ The parameters for making queries are described in Appendix A.2. Here we present an overview of the generated data.</p>
<h3>3.1 Statistics</h3>
<p>Table 1 describes the basic statistics of the generated data. We generate a total of over 52 K instructions and more than 82 K instances corresponding to these instructions after filtering.</p>
<h3>3.2 Diversity</h3>
<p>To study what types of instructions are generated and how diverse they are, we identify the verb-noun structure in the generated instructions. We use the Berkeley Neural Parser ${ }^{7}$ (Kitaev and Klein, 2018; Kitaev et al., 2019) to parse the instructions and</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>```
statistic
    # of instructions 52,445
    - # of classification instructions 11,584
    - # of non-classification instructions 40,861
    # of instances 82,439
    - # of instances with empty input 35,878
    ave. instruction length (in words) 15.9
    ave. non-empty input length (in words) 12.7
    ave. output length (in words) 18.9</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Table</span> <span class="mi">1</span><span class="o">:</span> <span class="nv">Statistics</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">data</span> <span class="s s-Atom">by</span> <span class="s s-Atom">applying</span> <span class="nv">SELF</span><span class="o">-</span><span class="nv">INSTRUCT</span> <span class="s s-Atom">to</span> <span class="nv">GPT3</span><span class="p">.</span>
<span class="s s-Atom">then</span> <span class="s s-Atom">extract</span> <span class="s s-Atom">the</span> <span class="s s-Atom">verb</span> <span class="s s-Atom">that</span> <span class="o">is</span> <span class="s s-Atom">closest</span> <span class="s s-Atom">to</span> <span class="s s-Atom">the</span> <span class="s s-Atom">root</span> <span class="s s-Atom">as</span> <span class="s s-Atom">well</span> <span class="s s-Atom">as</span> <span class="s s-Atom">its</span> <span class="s s-Atom">first</span> <span class="s s-Atom">direct</span> <span class="s s-Atom">noun</span> <span class="s s-Atom">object</span><span class="p">.</span> <span class="mi">26</span><span class="p">,</span><span class="mi">559</span> <span class="s s-Atom">out</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="mi">52</span><span class="p">,</span><span class="mi">445</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">contain</span> <span class="s s-Atom">such</span> <span class="s s-Atom">structure</span><span class="p">;</span> <span class="s s-Atom">other</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">usually</span> <span class="s s-Atom">contain</span> <span class="s s-Atom">more</span> <span class="s s-Atom">complex</span> <span class="nf">clauses</span> <span class="p">(</span><span class="s s-Atom">e</span><span class="p">.</span><span class="s s-Atom">g</span><span class="p">.,</span> <span class="s2">&quot;Classify whether this tweet contains political content or not.&quot;</span><span class="p">)</span> <span class="s s-Atom">or</span> <span class="s s-Atom">are</span> <span class="s s-Atom">framed</span> <span class="s s-Atom">as</span> <span class="nf">questions</span> <span class="p">(</span><span class="s s-Atom">e</span><span class="p">.</span><span class="s s-Atom">g</span><span class="p">.,</span> <span class="s2">&quot;Which of these statements are true?&quot;</span><span class="p">).</span> <span class="nv">We</span> <span class="s s-Atom">plot</span> <span class="s s-Atom">the</span> <span class="s s-Atom">top</span> <span class="mi">20</span> <span class="s s-Atom">most</span> <span class="s s-Atom">common</span> <span class="s s-Atom">root</span> <span class="s s-Atom">verbs</span> <span class="s s-Atom">and</span> <span class="s s-Atom">their</span> <span class="s s-Atom">top</span> <span class="mi">4</span> <span class="s s-Atom">direct</span> <span class="s s-Atom">noun</span> <span class="s s-Atom">objects</span> <span class="s s-Atom">in</span> <span class="nv">Figure</span> <span class="mi">3</span><span class="p">,</span> <span class="s s-Atom">which</span> <span class="s s-Atom">account</span> <span class="s s-Atom">for</span> <span class="err">$</span><span class="mi">14</span> <span class="s s-Atom">\</span><span class="c1">%$ of the entire set. Overall, we see quite diverse intents and textual formats in these instructions.</span>

<span class="nv">We</span> <span class="s s-Atom">further</span> <span class="s s-Atom">study</span> <span class="s s-Atom">how</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">differ</span> <span class="s s-Atom">from</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">used</span> <span class="s s-Atom">to</span> <span class="s s-Atom">prompt</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generation</span><span class="p">.</span> <span class="nv">For</span> <span class="s s-Atom">each</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instruction</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">compute</span> <span class="s s-Atom">its</span> <span class="s s-Atom">highest</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">overlap</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="mi">175</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">plot</span> <span class="s s-Atom">the</span> <span class="s s-Atom">distribution</span> <span class="s s-Atom">of</span> <span class="s s-Atom">these</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">scores</span> <span class="s s-Atom">in</span> <span class="nv">Figure</span> <span class="mf">4.</span> <span class="nv">The</span> <span class="s s-Atom">results</span> <span class="s s-Atom">indicate</span> <span class="s s-Atom">a</span> <span class="s s-Atom">decent</span> <span class="s s-Atom">number</span> <span class="s s-Atom">of</span> <span class="s s-Atom">new</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">were</span> <span class="s s-Atom">generated</span><span class="p">,</span> <span class="s s-Atom">which</span> <span class="s s-Atom">do</span> <span class="o">not</span> <span class="s s-Atom">have</span> <span class="s s-Atom">much</span> <span class="s s-Atom">overlap</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seeds</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">also</span> <span class="s s-Atom">demonstrate</span> <span class="s s-Atom">diversity</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">length</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instructions</span><span class="p">,</span> <span class="s s-Atom">instance</span> <span class="s s-Atom">inputs</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">instance</span> <span class="s s-Atom">outputs</span> <span class="s s-Atom">in</span> <span class="nv">Figure</span> <span class="mf">5.</span>

<span class="s s-Atom">###</span> <span class="mf">3.3</span> <span class="nv">Quality</span>

<span class="nv">So</span> <span class="s s-Atom">far</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">have</span> <span class="s s-Atom">shown</span> <span class="s s-Atom">the</span> <span class="s s-Atom">quantity</span> <span class="s s-Atom">and</span> <span class="s s-Atom">diversity</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">data</span><span class="p">,</span> <span class="s s-Atom">but</span> <span class="s s-Atom">its</span> <span class="s s-Atom">quality</span> <span class="s s-Atom">remains</span> <span class="s s-Atom">uncertain</span><span class="p">.</span> <span class="nv">To</span> <span class="s s-Atom">investigate</span> <span class="s s-Atom">this</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">randomly</span> <span class="s s-Atom">sample</span> <span class="mi">200</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">and</span> <span class="s s-Atom">randomly</span> <span class="s s-Atom">select</span> <span class="mi">1</span> <span class="s s-Atom">instance</span> <span class="s s-Atom">per</span> <span class="s s-Atom">instruction</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">asked</span> <span class="s s-Atom">an</span> <span class="s s-Atom">expert</span> <span class="nf">annotator</span> <span class="p">(</span><span class="s s-Atom">author</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="s s-Atom">work</span><span class="p">)</span> <span class="s s-Atom">to</span> <span class="s s-Atom">label</span> <span class="s s-Atom">whether</span> <span class="s s-Atom">each</span> <span class="s s-Atom">instance</span> <span class="o">is</span> <span class="s s-Atom">correct</span> <span class="s s-Atom">or</span> <span class="o">not</span><span class="p">,</span> <span class="s s-Atom">in</span> <span class="s s-Atom">terms</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instance</span> <span class="s s-Atom">input</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instance</span> <span class="s s-Atom">output</span><span class="p">.</span> <span class="nv">Evaluation</span> <span class="s s-Atom">results</span> <span class="s s-Atom">in</span> <span class="nv">Table</span> <span class="mi">2</span> <span class="s s-Atom">show</span> <span class="s s-Atom">that</span> <span class="s s-Atom">most</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">are</span> <span class="s s-Atom">meaningful</span><span class="p">,</span> <span class="s s-Atom">while</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instances</span> <span class="s s-Atom">may</span> <span class="s s-Atom">contain</span> <span class="s s-Atom">more</span> <span class="nf">noise</span> <span class="p">(</span><span class="s s-Atom">to</span> <span class="s s-Atom">a</span> <span class="s s-Atom">reasonable</span> <span class="s s-Atom">extent</span><span class="p">).</span> <span class="nv">However</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">found</span> <span class="s s-Atom">that</span> <span class="s s-Atom">even</span> <span class="s s-Atom">though</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generations</span> <span class="s s-Atom">may</span> <span class="s s-Atom">contain</span> <span class="s s-Atom">errors</span><span class="p">,</span> <span class="s s-Atom">most</span> <span class="s s-Atom">of</span> <span class="s s-Atom">them</span> <span class="s s-Atom">are</span> <span class="s s-Atom">still</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">correct</span> <span class="s s-Atom">format</span> <span class="s s-Atom">or</span> <span class="s s-Atom">partially</span> <span class="s s-Atom">correct</span><span class="p">,</span> <span class="s s-Atom">which</span> <span class="s s-Atom">can</span> <span class="s s-Atom">provide</span> <span class="s s-Atom">useful</span> <span class="s s-Atom">guidance</span> <span class="s s-Atom">for</span> <span class="s s-Atom">training</span> <span class="s s-Atom">models</span> <span class="s s-Atom">to</span> <span class="s s-Atom">follow</span> <span class="s s-Atom">instructions</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">listed</span> <span class="s s-Atom">a</span> <span class="s s-Atom">number</span> <span class="s s-Atom">of</span> <span class="s s-Atom">good</span>


<span class="p">[</span><span class="s s-Atom">^</span><span class="mi">0</span><span class="p">]</span><span class="o">:</span>    <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="s s-Atom">^</span><span class="p">{</span><span class="mi">6</span><span class="p">}</span><span class="err">$</span> <span class="s s-Atom">https</span><span class="p">:</span><span class="o">//</span><span class="s s-Atom">openai</span><span class="p">.</span><span class="s s-Atom">com</span><span class="o">/</span><span class="s s-Atom">api</span><span class="o">/</span>
    <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="s s-Atom">^</span><span class="p">{</span><span class="mi">7</span><span class="p">}</span><span class="err">$</span> <span class="s s-Atom">https</span><span class="p">:</span><span class="o">//</span><span class="s s-Atom">parser</span><span class="p">.</span><span class="s s-Atom">kitaev</span><span class="p">.</span><span class="s s-Atom">io</span><span class="o">/</span>

<span class="p">![</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">2.</span><span class="s s-Atom">jpeg</span><span class="p">](</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">2.</span><span class="s s-Atom">jpeg</span><span class="p">)</span>

<span class="nv">Figure</span> <span class="mi">3</span><span class="o">:</span> <span class="nv">The</span> <span class="s s-Atom">top</span> <span class="mi">20</span> <span class="s s-Atom">most</span> <span class="s s-Atom">common</span> <span class="s s-Atom">root</span> <span class="nf">verbs</span> <span class="p">(</span><span class="s s-Atom">inner</span> <span class="s s-Atom">circle</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="s s-Atom">their</span> <span class="s s-Atom">top</span> <span class="mi">4</span> <span class="s s-Atom">direct</span> <span class="s s-Atom">noun</span> <span class="nf">objects</span> <span class="p">(</span><span class="s s-Atom">outer</span> <span class="s s-Atom">circle</span><span class="p">)</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instructions</span><span class="p">.</span> <span class="nv">Despite</span> <span class="s s-Atom">their</span> <span class="s s-Atom">diversity</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">shown</span> <span class="s s-Atom">here</span> <span class="s s-Atom">only</span> <span class="s s-Atom">account</span> <span class="s s-Atom">for</span> <span class="err">$</span><span class="mi">14</span> <span class="s s-Atom">\</span><span class="c1">%$ of all the generated instructions because many instructions (e.g., &quot;Classify whether the user is satisfied with the service.&quot;) do not contain such a verb-noun structure.</span>
<span class="p">![</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">3.</span><span class="s s-Atom">jpeg</span><span class="p">](</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">3.</span><span class="s s-Atom">jpeg</span><span class="p">)</span>

<span class="nv">Figure</span> <span class="mi">4</span><span class="o">:</span> <span class="nv">Distribution</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">scores</span> <span class="s s-Atom">between</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">and</span> <span class="s s-Atom">their</span> <span class="s s-Atom">most</span> <span class="s s-Atom">similar</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span><span class="p">.</span>
<span class="p">![</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">4.</span><span class="s s-Atom">jpeg</span><span class="p">](</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">4.</span><span class="s s-Atom">jpeg</span><span class="p">)</span>

<span class="nv">Figure</span> <span class="mi">5</span><span class="o">:</span> <span class="nv">Length</span> <span class="s s-Atom">distribution</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">instructions</span><span class="p">,</span> <span class="s s-Atom">non</span><span class="o">-</span><span class="s s-Atom">empty</span> <span class="s s-Atom">inputs</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">outputs</span><span class="p">.</span>
<span class="s s-Atom">examples</span> <span class="s s-Atom">and</span> <span class="s s-Atom">bad</span> <span class="s s-Atom">examples</span> <span class="s s-Atom">in</span> <span class="nv">Table</span> <span class="mi">10</span> <span class="s s-Atom">and</span> <span class="mi">11</span><span class="p">,</span> <span class="s s-Atom">respectively</span><span class="p">.</span>

<span class="p">|</span> <span class="nv">Quality</span> <span class="nv">Review</span> <span class="nv">Question</span> <span class="p">|</span> <span class="nv">Yes</span> <span class="s s-Atom">\</span><span class="c1">% |</span>
<span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span>
<span class="p">|</span> <span class="nv">Does</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span> <span class="o">&lt;</span><span class="s s-Atom">br</span><span class="o">&gt;</span> <span class="s s-Atom">describe</span> <span class="s s-Atom">a</span> <span class="nb">val</span><span class="s s-Atom">id</span> <span class="s s-Atom">task</span><span class="nb">?</span> <span class="p">|</span> <span class="err">$</span><span class="mi">92</span> <span class="s s-Atom">\</span><span class="c1">%$ |</span>
<span class="p">|</span> <span class="nv">Is</span> <span class="s s-Atom">the</span> <span class="s s-Atom">input</span> <span class="s s-Atom">appropriate</span> <span class="o">&lt;</span><span class="s s-Atom">br</span><span class="o">&gt;</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span><span class="nb">?</span> <span class="p">|</span> <span class="err">$</span><span class="mi">79</span> <span class="s s-Atom">\</span><span class="c1">%$ |</span>
<span class="p">|</span> <span class="nv">Is</span> <span class="s s-Atom">the</span> <span class="s s-Atom">output</span> <span class="s s-Atom">a</span> <span class="s s-Atom">correct</span> <span class="s s-Atom">and</span> <span class="s s-Atom">acceptable</span> <span class="o">&lt;</span><span class="s s-Atom">br</span><span class="o">&gt;</span> <span class="s s-Atom">response</span> <span class="s s-Atom">to</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">and</span> <span class="s s-Atom">input</span><span class="nb">?</span> <span class="p">|</span> <span class="err">$</span><span class="mi">58</span> <span class="s s-Atom">\</span><span class="c1">%$ |</span>
<span class="p">|</span> <span class="nv">All</span> <span class="s s-Atom">fields</span> <span class="s s-Atom">are</span> <span class="nb">val</span><span class="s s-Atom">id</span> <span class="p">|</span> <span class="err">$</span><span class="mi">54</span> <span class="s s-Atom">\</span><span class="c1">%$ |</span>

<span class="nv">Table</span> <span class="mi">2</span><span class="o">:</span> <span class="nv">Data</span> <span class="s s-Atom">quality</span> <span class="s s-Atom">review</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span><span class="p">,</span> <span class="s s-Atom">input</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">output</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">data</span><span class="p">.</span> <span class="nv">See</span> <span class="nv">Table</span> <span class="mi">10</span> <span class="s s-Atom">and</span> <span class="nv">Table</span> <span class="mi">11</span> <span class="s s-Atom">for</span> <span class="s s-Atom">representative</span> <span class="nb">val</span><span class="s s-Atom">id</span> <span class="s s-Atom">and</span> <span class="s s-Atom">invalid</span> <span class="s s-Atom">examples</span><span class="p">.</span>

<span class="s s-Atom">##</span> <span class="mi">4</span> <span class="nv">Experimental</span> <span class="nv">Results</span>

<span class="nv">We</span> <span class="s s-Atom">conduct</span> <span class="s s-Atom">experiments</span> <span class="s s-Atom">to</span> <span class="s s-Atom">measure</span> <span class="s s-Atom">and</span> <span class="s s-Atom">compare</span> <span class="s s-Atom">the</span> <span class="s s-Atom">performance</span> <span class="s s-Atom">of</span> <span class="s s-Atom">models</span> <span class="s s-Atom">under</span> <span class="s s-Atom">various</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">tuning</span> <span class="s s-Atom">setups</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">first</span> <span class="s s-Atom">describe</span> <span class="s s-Atom">our</span> <span class="s s-Atom">models</span> <span class="s s-Atom">and</span> <span class="s s-Atom">other</span> <span class="s s-Atom">baselines</span><span class="p">,</span> <span class="s s-Atom">followed</span> <span class="s s-Atom">by</span> <span class="s s-Atom">our</span> <span class="s s-Atom">experiments</span><span class="p">.</span>

<span class="s s-Atom">###</span> <span class="mf">4.1</span> <span class="nv">GPT3</span> <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="k">_</span><span class="p">{</span><span class="s s-Atom">\text</span> <span class="p">{</span><span class="nv">SELF</span><span class="o">-</span><span class="nv">INST</span> <span class="p">}}</span><span class="err">$</span> <span class="o">:</span> <span class="s s-Atom">finetuning</span> <span class="nv">GPT3</span> <span class="s s-Atom">on</span> <span class="s s-Atom">its</span> <span class="s s-Atom">own</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">data</span>

<span class="nv">Given</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">generated</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">data</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">conduct</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">tuning</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="nv">GPT3</span>
<span class="s s-Atom">model</span> <span class="nf">itself</span> <span class="p">(</span><span class="s2">&quot;davinci&quot;</span> <span class="s s-Atom">engine</span><span class="p">).</span> <span class="nv">As</span> <span class="s s-Atom">described</span> <span class="s s-Atom">in</span> <span class="err">$</span><span class="s s-Atom">\</span><span class="nv">S</span> <span class="mf">2.3</span><span class="err">$</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">use</span> <span class="s s-Atom">various</span> <span class="s s-Atom">templates</span> <span class="s s-Atom">to</span> <span class="s s-Atom">concatenate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">and</span> <span class="s s-Atom">input</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">train</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">to</span> <span class="s s-Atom">generate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">output</span><span class="p">.</span> <span class="nv">This</span> <span class="s s-Atom">finetuning</span> <span class="o">is</span> <span class="s s-Atom">done</span> <span class="s s-Atom">through</span> <span class="s s-Atom">the</span> <span class="nv">OpenAI</span> <span class="s s-Atom">finetuning</span> <span class="nv">API</span><span class="p">.</span> <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="s s-Atom">^</span><span class="p">{</span><span class="mi">8</span><span class="p">}</span><span class="err">$</span> <span class="nv">We</span> <span class="s s-Atom">use</span> <span class="s s-Atom">the</span> <span class="s s-Atom">default</span> <span class="s s-Atom">hyper</span><span class="o">-</span><span class="s s-Atom">parameters</span><span class="p">,</span> <span class="s s-Atom">except</span> <span class="s s-Atom">that</span> <span class="s s-Atom">we</span> <span class="s s-Atom">set</span> <span class="s s-Atom">the</span> <span class="s s-Atom">prompt</span> <span class="s s-Atom">loss</span> <span class="s s-Atom">weight</span> <span class="s s-Atom">to</span> <span class="mi">0</span> <span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">we</span> <span class="s s-Atom">train</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">for</span> <span class="mi">2</span> <span class="s s-Atom">epochs</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">refer</span> <span class="s s-Atom">the</span> <span class="s s-Atom">reader</span> <span class="s s-Atom">to</span> <span class="nv">Appendix</span> <span class="nv">A</span><span class="p">.</span> <span class="mi">3</span> <span class="s s-Atom">for</span> <span class="s s-Atom">additional</span> <span class="s s-Atom">finetuning</span> <span class="s s-Atom">details</span><span class="p">.</span> <span class="nv">The</span> <span class="s s-Atom">resulting</span> <span class="s s-Atom">model</span> <span class="o">is</span> <span class="s s-Atom">denoted</span> <span class="s s-Atom">by</span> <span class="nv">GPT3</span> <span class="err">$</span><span class="mi">3</span><span class="k">_</span><span class="p">{</span><span class="s s-Atom">\text</span> <span class="p">{</span><span class="nv">SELF</span><span class="o">-</span><span class="nv">INST</span> <span class="p">}}</span><span class="err">$</span><span class="p">.</span>

<span class="s s-Atom">###</span> <span class="mf">4.2</span> <span class="nv">Baselines</span>

<span class="nv">Off</span><span class="o">-</span><span class="s s-Atom">the</span><span class="o">-</span><span class="s s-Atom">shelf</span> <span class="nv">LMs</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">evaluate</span> <span class="nv">T5</span><span class="o">-</span><span class="nv">LM</span> <span class="p">(</span><span class="nv">Lester</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2021</span><span class="p">;</span> <span class="nv">Raffel</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2020</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="nv">GPT3</span> <span class="p">(</span><span class="nv">Brown</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2020</span><span class="p">)</span> <span class="s s-Atom">as</span> <span class="s s-Atom">the</span> <span class="s s-Atom">vanilla</span> <span class="nv">LM</span> <span class="nf">baselines</span> <span class="p">(</span><span class="s s-Atom">only</span> <span class="s s-Atom">pretraining</span><span class="p">,</span> <span class="s s-Atom">no</span> <span class="s s-Atom">additional</span> <span class="s s-Atom">finetuning</span><span class="p">).</span> <span class="nv">These</span> <span class="s s-Atom">baselines</span> <span class="s s-Atom">will</span> <span class="s s-Atom">indicate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">extent</span> <span class="s s-Atom">to</span> <span class="s s-Atom">which</span> <span class="s s-Atom">off</span><span class="o">-</span><span class="s s-Atom">the</span><span class="o">-</span><span class="s s-Atom">shelf</span> <span class="nv">LMs</span> <span class="s s-Atom">are</span> <span class="s s-Atom">capable</span> <span class="s s-Atom">of</span> <span class="s s-Atom">following</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">naturally</span> <span class="s s-Atom">immediately</span> <span class="s s-Atom">after</span> <span class="s s-Atom">pretraining</span><span class="p">.</span>

<span class="nv">Publicly</span> <span class="s s-Atom">available</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuned</span> <span class="s s-Atom">models</span><span class="p">.</span> <span class="nv">T0</span> <span class="s s-Atom">and</span> <span class="nv">T</span> <span class="err">$</span><span class="s s-Atom">k$</span><span class="o">-</span><span class="nv">InStrUCT</span> <span class="s s-Atom">are</span> <span class="s s-Atom">two</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuned</span> <span class="s s-Atom">models</span> <span class="s s-Atom">proposed</span> <span class="s s-Atom">in</span> <span class="nv">Sanh</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.</span> <span class="p">(</span><span class="mi">2022</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="nv">Wang</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.</span> <span class="p">(</span><span class="mi">2022</span><span class="p">),</span> <span class="s s-Atom">respectively</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">are</span> <span class="s s-Atom">demonstrated</span> <span class="s s-Atom">to</span> <span class="s s-Atom">be</span> <span class="s s-Atom">able</span> <span class="s s-Atom">to</span> <span class="s s-Atom">follow</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">for</span> <span class="s s-Atom">many</span> <span class="nv">NLP</span> <span class="s s-Atom">tasks</span><span class="p">.</span> <span class="nv">Both</span> <span class="s s-Atom">of</span> <span class="s s-Atom">these</span> <span class="s s-Atom">models</span> <span class="s s-Atom">are</span> <span class="s s-Atom">finetuned</span> <span class="s s-Atom">from</span> <span class="s s-Atom">the</span>

<span class="p">[</span><span class="s s-Atom">^</span><span class="mi">0</span><span class="p">]</span>
<span class="p">[</span><span class="s s-Atom">^</span><span class="mi">0</span><span class="p">]</span><span class="o">:</span>    <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="s s-Atom">^</span><span class="p">{</span><span class="mi">8</span><span class="p">}</span><span class="err">$</span> <span class="nv">See</span> <span class="nv">OpenAI</span><span class="s s-Atom">&#39;s documentation on finetuning.</span>

<span class="s s-Atom">T5 (Raffel et al., 2020) checkpoints and are publicly available. ${ }^{9}$ For both of these models, we use their largest version with 11B parameters.</span>

<span class="s s-Atom">Instruction-tuned GPT3 models. We evaluate InstructGPT (Ouyang et al., 2022), which is developed by OpenAI based on GPT3 to follow human instructions better and has been found by the community to have impressive zero-shot abilities. There are various generations of these models, where newer ones use more expansive data or algorithmic novelties. ${ }^{10}$ For our SUPERNI experiments in $\S 4.3$, we only compare with their text-davinci-001 engine, because their newer engines are trained with the latest user data and are likely to have already seen the SUPERNI test set. For our human evaluation on newly written instructions, we include their 001, 002 and 003 engines for completeness.</span>

<span class="s s-Atom">Additionally, to compare SELF-INSTRUCT training with other publicly available instruction tuning data, we further finetune GPT3 model with data from PromptSource and SUPERNI, which are used to train the T0 and T $k$-InStrUCT models. We call them T0 training and SUPERNI training for short, respectively. To save the training budget, we sampled 50 K instances (but covering all their instructions) for each dataset, which has a comparable size to the instruction data we generated. Based on the findings from Wang et al. (2022) and our early experiments, reducing the number of instances per task does not degrade the model&#39;s</span> <span class="s s-Atom">generalization</span> <span class="s s-Atom">performance</span> <span class="s s-Atom">to</span> <span class="s s-Atom">unseen</span> <span class="s s-Atom">tasks</span><span class="p">.</span>

<span class="s s-Atom">###</span> <span class="mf">4.3</span> <span class="nv">Experiment</span> <span class="mi">1</span><span class="o">:</span> <span class="nv">Zero</span><span class="o">-</span><span class="nv">Shot</span> <span class="nv">Generalization</span> <span class="s s-Atom">on</span> <span class="nv">SUPERNI</span> <span class="s s-Atom">benchmark</span>

<span class="nv">We</span> <span class="s s-Atom">first</span> <span class="s s-Atom">evaluate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">models&#39; ability to follow instructions on typical NLP tasks in a zero-shot fashion. We use the evaluation set of SUPERNI (Wang et al., 2022), which consists of 119 tasks with 100 instances in each task. In this work, we mainly focus on the zero-shot setup, i.e., the model is prompted with the definition of the tasks only, without in-context demonstration examples. For all our requests to the GPT3 variants, we use the deterministic generation mode (temperature as 0 and no nucleus sampling) without specific stop sequences.</span>

<span class="s s-Atom">Results. We make the following observations from the results in Table 3. Self-Instruct</span>

<span class="s s-Atom">[^0]Table 3: Evaluation results on unseen tasks from SuPERNI (§4.3). From the results, we see that (1) SelFInSTRUCT can boost GPT3 performance by a large margin $(+33.1 \%)$ and (2) nearly matches the performance of InstructGPT ${ }_{001}$. Additionally, (3) it can further improve the performance even when a large amount of labeled instruction data is present.</span>
<span class="s s-Atom">boosts the instruction-following ability of GPT3 by a large margin. The vanilla GPT3 model basically cannot follow human instructions at all. Upon manual analysis, we find that it usually generates irrelevant and repetitive text, and does not know when to stop generation. Compared with other models that are not specifically trained for SUPERNI, GPT3 $3_{\text {SELF-INST }}$ achieves better performance than T0 or the GPT3 finetuned on the T0 training set, which takes tremendous human labeling efforts. Notably, GPT3 $3_{\text {SELF-INST }}$ also nearly matches the performance of InstructGPT ${ }_{001}$, which is trained with private user data and human-annotated labels.</span>

<span class="s s-Atom">Models trained on the SUPERNI training set still achieve better performance on its evaluation set, which we attribute to the similar instruction style and formatting. However, we show that SELfInStrUCT still brings in additional gains when combined with the SUPERNI training set, proving its value as complementary data.</span>

<span class="s s-Atom">### 4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</span>

<span class="s s-Atom">Despite the comprehensiveness of SUPERNI in collecting existing NLP tasks, most of these NLP tasks were proposed for research purposes and skewed toward classification. To better access the practical value of instruction-following models, a subset of the authors curate a new set of instructions motivated by user-oriented applications. We first brainstorm various domains where large LMs may be useful (e.g., email writing, social media, productivity tools, entertainment, programming), then</span>


<span class="s s-Atom">[^0]:    ${ }^{9} \mathrm{~T} 0$ is available at here and $\mathrm{T} k$-InSTRUCT is here.</span>
<span class="s s-Atom">    ${ }^{10}$ See OpenAI&#39;s</span> <span class="s s-Atom">documentation</span> <span class="s s-Atom">on</span> <span class="s s-Atom">their</span> <span class="s s-Atom">models</span><span class="p">.</span>

<span class="p">![</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">5.</span><span class="s s-Atom">jpeg</span><span class="p">](</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">5.</span><span class="s s-Atom">jpeg</span><span class="p">)</span>

<span class="nv">Figure</span> <span class="mi">6</span><span class="o">:</span> <span class="nv">Performance</span> <span class="s s-Atom">of</span> <span class="nv">GPT3</span> <span class="s s-Atom">model</span> <span class="s s-Atom">and</span> <span class="s s-Atom">its</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuned</span> <span class="s s-Atom">variants</span><span class="p">,</span> <span class="s s-Atom">evaluated</span> <span class="s s-Atom">by</span> <span class="s s-Atom">human</span> <span class="s s-Atom">experts</span> <span class="s s-Atom">on</span> <span class="s s-Atom">our</span> <span class="mi">252</span> <span class="nb">user</span><span class="o">-</span><span class="s s-Atom">oriented</span> <span class="nf">instructions</span> <span class="p">(</span><span class="s s-Atom">§</span><span class="mf">4.4</span><span class="p">).</span> <span class="nv">Human</span> <span class="s s-Atom">evaluators</span> <span class="s s-Atom">are</span> <span class="s s-Atom">instructed</span> <span class="s s-Atom">to</span> <span class="s s-Atom">rate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">models&#39; responses into four levels. The results indicate that GPT3_Self-Inst outperforms all the other GPT3 variants trained on publicly available instruction datasets. Additionally, GPT3_Self-Inst scores nearly as good as InstructGPT_001 (cf. footnote 1).</span>

<span class="s s-Atom">craft instructions related to each domain along with an input-output instance (again, input is optional). We aim to diversify the styles and formats of these tasks (e.g., instructions may be long or short; input/output may take the form of bullet points, tables, codes, equations, etc.). In total, we create 252 instructions with 1 instance per instruction. We believe it can serve as a testbed for evaluating how instruction-based models handle diverse and unfamiliar instructions. Table 9 presents a small portion of them. The entire set is available in our GitHub repository. We analyze the overlap between this set set and the seed instructions in §A.1.</span>

<span class="s s-Atom">**Human evaluation setup.** Evaluating models&#39;</span> <span class="s s-Atom">performance</span> <span class="s s-Atom">on</span> <span class="s s-Atom">this</span> <span class="s s-Atom">evaluation</span> <span class="s s-Atom">set</span> <span class="s s-Atom">of</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">tasks</span> <span class="o">is</span> <span class="s s-Atom">extremely</span> <span class="s s-Atom">challenging</span> <span class="s s-Atom">because</span> <span class="s s-Atom">different</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">require</span> <span class="s s-Atom">different</span> <span class="s s-Atom">expertise</span><span class="p">.</span> <span class="nv">Indeed</span><span class="p">,</span> <span class="s s-Atom">many</span> <span class="s s-Atom">of</span> <span class="s s-Atom">these</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">cannot</span> <span class="s s-Atom">be</span> <span class="s s-Atom">measured</span> <span class="s s-Atom">by</span> <span class="s s-Atom">automatic</span> <span class="s s-Atom">metrics</span> <span class="s s-Atom">or</span> <span class="s s-Atom">even</span> <span class="s s-Atom">be</span> <span class="s s-Atom">judged</span> <span class="s s-Atom">by</span> <span class="s s-Atom">normal</span> <span class="nf">crowdworkers</span> <span class="p">(</span><span class="s s-Atom">e</span><span class="p">.</span><span class="s s-Atom">g</span><span class="p">.,</span> <span class="s s-Atom">writing</span> <span class="s s-Atom">a</span> <span class="s s-Atom">program</span> <span class="s s-Atom">or</span> <span class="s s-Atom">converting</span> <span class="s s-Atom">first</span><span class="o">-</span><span class="s s-Atom">order</span> <span class="s s-Atom">logic</span> <span class="s s-Atom">into</span> <span class="s s-Atom">natural</span> <span class="s s-Atom">language</span><span class="p">).</span> <span class="nv">To</span> <span class="s s-Atom">get</span> <span class="s s-Atom">a</span> <span class="s s-Atom">more</span> <span class="s s-Atom">faithful</span> <span class="s s-Atom">evaluation</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">asked</span> <span class="s s-Atom">the</span> <span class="s s-Atom">authors</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">to</span> <span class="s s-Atom">judge</span> <span class="s s-Atom">model</span> <span class="s s-Atom">predictions</span><span class="p">.</span> <span class="nv">Details</span> <span class="s s-Atom">on</span> <span class="s s-Atom">how</span> <span class="s s-Atom">we</span> <span class="s s-Atom">set</span> <span class="s s-Atom">up</span> <span class="s s-Atom">this</span> <span class="s s-Atom">human</span> <span class="s s-Atom">evaluation</span> <span class="s s-Atom">are</span> <span class="s s-Atom">described</span> <span class="s s-Atom">in</span> <span class="nv">Appendix</span> <span class="nv">B</span><span class="p">.</span> <span class="nv">The</span> <span class="s s-Atom">evaluators</span> <span class="s s-Atom">were</span> <span class="s s-Atom">asked</span> <span class="s s-Atom">to</span> <span class="s s-Atom">rate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">output</span> <span class="s s-Atom">based</span> <span class="s s-Atom">on</span> <span class="s s-Atom">whether</span> <span class="s s-Atom">it</span> <span class="s s-Atom">accurately</span> <span class="s s-Atom">and</span> <span class="s s-Atom">effectively</span> <span class="s s-Atom">completes</span> <span class="s s-Atom">the</span> <span class="s s-Atom">task</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">implemented</span> <span class="s s-Atom">a</span> <span class="s s-Atom">four</span><span class="o">-</span><span class="s s-Atom">level</span> <span class="s s-Atom">rating</span> <span class="s s-Atom">system</span> <span class="s s-Atom">for</span> <span class="s s-Atom">categorizing</span> <span class="s s-Atom">the</span> <span class="s s-Atom">quality</span> <span class="s s-Atom">of</span> <span class="s s-Atom">models&#39; outputs:</span>

<span class="s s-Atom">- **Rating-A**: The response is valid and satisfying.</span>
<span class="s s-Atom">- **Rating-B**: The response is acceptable but has minor errors or imperfections.</span>
<span class="s s-Atom">- **Rating-C**: The response is relevant and responds to the instruction, but it has significant errors in the content. For example, GPT3 might generate a valid output first, but continue to generate other irrelevant things.</span>
<span class="s s-Atom">- **Rating-D**: The response is irrelevant or completely invalid.</span>

<span class="s s-Atom">**Results.** Figure 6 shows the performance of GPT3 model and its instruction-tuned counterparts on this newly written instruction set (w. interrater agreement K = 0.57 on the 4-class categorical scale, see Appendix B for details). As anticipated, the vanilla GPT3 LM is largely unable to respond to instructions, and all instruction-tuned models demonstrate comparatively higher performance. Nonetheless, GPT3_Self-Inst (i.e., GPT3 model finetuned with Self-Instruct) outperforms those counterparts trained on T0 or SUPERNI data by a large margin, demonstrating the value of the generated data despite the noise. Compared with InstructGPT_001, GPT3_Self-Inst is quite close in performance—if we count acceptable response with minor imperfections (Rating-B) as valid, GPT3_Self-Inst is only 5% behind InstructGPT_001. Lastly, our evaluation confirms the impressive instruction-following ability of InstructGPT_002 and InstructGPT_003. Although there are many factors behind this success, we conjecture that future work can largely benefit from improving the quality of our generated data by using human annotators or training a reward model to select better generations, similar to the algorithm used by Ouyang et al. (2022).</span>

<span class="s s-Atom"># 4.5 Effect of Data Size and Quality </span>

<span class="s s-Atom">Data size. Self-InStruCt provides a way to grow instruction data at a low cost with almost no human labeling; could more of this generated data lead to better instruction-following ability? We analyze the size of generated data by subsampling different numbers of instructions from the generated dataset, finetuning GPT3 on the sampled subsets, and evaluating how the resulting models perform on the 252 user-oriented instruction set. We conduct the same human evaluation as in $\S 4.4$. Figure 7 presents the performance of GPT3 $3_{\text {SELF-INST }}$ models finetuned with different sizes of generated data. Overall, we see consistent improvement as we grow the data size. However, this improvement almost plateaus after 16 K . This is in-line with the data scaling experiments in Wang et al. (2022, Fig. 5). Interestingly, when evaluating on SUPERNI we found the model&#39;s</span> <span class="s s-Atom">performance</span> <span class="s s-Atom">gain</span> <span class="s s-Atom">plateaus</span> <span class="s s-Atom">earlier</span> <span class="s s-Atom">at</span> <span class="s s-Atom">around</span> <span class="s s-Atom">hundreds</span> <span class="s s-Atom">of</span> <span class="s s-Atom">instructions</span><span class="p">.</span> <span class="nv">This</span> <span class="s s-Atom">may</span> <span class="s s-Atom">be</span> <span class="s s-Atom">due</span> <span class="s s-Atom">to</span> <span class="s s-Atom">the</span> <span class="s s-Atom">fact</span> <span class="s s-Atom">that</span> <span class="s s-Atom">the</span> <span class="s s-Atom">new</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">data</span> <span class="o">is</span> <span class="s s-Atom">distinct</span> <span class="s s-Atom">from</span> <span class="s s-Atom">typical</span> <span class="nv">NLP</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">in</span> <span class="nv">SUPERNI</span><span class="p">,</span> <span class="s s-Atom">indicating</span> <span class="s s-Atom">that</span> <span class="s s-Atom">future</span> <span class="s s-Atom">research</span> <span class="s s-Atom">may</span> <span class="s s-Atom">benefit</span> <span class="s s-Atom">from</span> <span class="s s-Atom">using</span> <span class="s s-Atom">a</span> <span class="s s-Atom">combination</span> <span class="s s-Atom">of</span> <span class="s s-Atom">different</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">data</span> <span class="s s-Atom">for</span> <span class="s s-Atom">better</span> <span class="s s-Atom">performance</span> <span class="s s-Atom">on</span> <span class="s s-Atom">various</span> <span class="s s-Atom">types</span> <span class="s s-Atom">of</span> <span class="s s-Atom">tasks</span><span class="p">.</span>

<span class="nv">Data</span> <span class="s s-Atom">quality</span><span class="p">.</span> <span class="nv">Another</span> <span class="s s-Atom">direction</span> <span class="s s-Atom">to</span> <span class="s s-Atom">improve</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model&#39;s performance is to take our generated data and get better supervision (with less noise). We explore this idea by using InstructGPT ${ }_{003}$ (the best available general-purpose model) to regenerate the output field of all our instances given the instruction and input. We then use this improved version of our data to finetune GPT3. As is shown in Figure 7, the resulting model outperforms the counterpart trained with the original data by $10 \%$, which suggests big room for future work on using our generation pipeline to get initial data and then improving the data quality with human experts or distillation from better models.</span>

<span class="s s-Atom">## 5 Related Work</span>

<span class="s s-Atom">Instruction-following LMs. A series of works have found evidence that vanilla LMs can be effective at following general language instructions if tuned with annotated &quot;instructional&quot; data-datasets containing language instructional commands and their desired outcomes based on human annotation (Weller et al., 2020; Mishra et al., 2022; Wei et al., 2022; Sanh et al., 2022, i.a.). Additionally, they show a direct correlation between the size and</span>

<span class="s s-Atom">![img-6.jpeg](img-6.jpeg)</span>

<span class="s s-Atom">Figure 7: Human evaluation performance of GPT3 $3_{\text {SELF-INST }}$ models tuned with different sizes of instructions. $x$-axis is in log scale. The smallest size is 175 , where only the seed tasks are used for instruction tuning. We also evaluate whether improving the data quality further improves the performance by distilling the outputs from InstructGPT ${ }_{003}$. We see consistent improvement from using larger data with better quality.</span>
<span class="s s-Atom">diversity of the &quot;instructional&quot; data and the generalizability of resulting models to unseen tasks (Wang et al., 2022; Chung et al., 2022). However, since these developments largely focus on existing NLP tasks and depend on human-annotated instructions, this poses a bottleneck for progress toward more generalizable models (e.g., see Fig. 5a in Wang et al., 2022). Our work aims to move beyond classical NLP tasks and tackle the challenges of creating diverse instruction data by employing pretrained LMs. InstructGPT (Ouyang et al., 2022) shares a similar goal as ours in building more generalpurpose LMs, and has demonstrated remarkable performance in following diverse user instructions. However, as a commercial system, their construction process still remains quite opaque. In particular, the role of data has remained understudied due to limited transparency and the private user data they used in their study. Addressing such challenges necessitates the creation of a large-scale, public dataset covering a broad range of tasks.</span>

<span class="s s-Atom">Language models for data generation and augmentation. A variety of works have proposed using LMs for data generation (Schick and Schütze, 2021; Wang et al., 2021; Liu et al., 2022; Meng et al., 2023) or augmentation (Feng et al., 2021; Yang et al., 2020; Mekala et al., 2022). Our work differs from this line in that it is not specific to a particular task (say, QA or NLI). In contrast, a distinct</span>

<span class="s s-Atom">motivation for SELF-INSTRUCT is to bootstrap new task definitions that may not have been defined before by NLP practitioners (though potentially still important for real users). In parallel with our work, Honovich et al. (2022a) also propose to generate large-scale instruction data (so-called Unnatural Instructions) with GPT3 models. The major differences are that 1) they use tasks in SUPERNI (Wang et al., 2022) as their seed tasks, resulting in a different distribution of generated tasks; 2) they employ InstructGPT ${ }_{002}$ for generating the data, in which sense they are distilling knowledge from an already instruction-tuned model, while we solely rely on the vanilla LM; 3) the detailed generation pipeline and templates are different. Nevertheless, we believe that both efforts in expanding instruction data are complementary, and the community will benefit from these diverse datasets.</span>

<span class="s s-Atom">Instruction generation. A series of recent works (Zhou et al., 2022b; Ye et al., 2022; Singh et al., 2022; Honovich et al., 2022b) generate instructions of a task given a few examples. While SELF-INSTRUCT also involves instruction generation, a major difference in our case is it is taskagnostic; we generate new tasks (instructions along with instances) from scratch.</span>

<span class="s s-Atom">Model self-training. A typical self-training framework (He et al., 2019; Xie et al., 2020; Du et al., 2021; Amini et al., 2022; Huang et al., 2022) uses trained models to assign labels to unlabeled data and then leverages the pseudo-labeled data to improve the model. Zhou et al. (2022a) use multiple prompts to specify a single task and propose to regularize via prompt consistency, encouraging consistent predictions over the prompts. This allows either finetuning the model with extra unlabeled training data, or direct application at inference time. While SELF-INSTRUCT has similarities with the self-training literature, most self-training methods assume a specific target task as well as unlabeled examples under it; in contrast, SELFINSTRUCT produces a variety of tasks from scratch.</span>

<span class="s s-Atom">Knowledge distillation. Knowledge distillation (Hinton et al., 2015; Sanh et al., 2019; West et al., 2021; Magister et al., 2022) often involves the transfer of knowledge from larger models to smaller ones. SELF-INSTRUCT can also be viewed as a form of &quot;knowledge distillation&quot;, however, it differs from this line in the following ways: (1) the source and target of distillation are the same, i.e., a</span>
<span class="s s-Atom">model&#39;s</span> <span class="s s-Atom">knowledge</span> <span class="o">is</span> <span class="s s-Atom">distilled</span> <span class="s s-Atom">to</span> <span class="s s-Atom">itself</span><span class="p">;</span> <span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="s s-Atom">the</span> <span class="s s-Atom">content</span> <span class="s s-Atom">of</span> <span class="s s-Atom">distillation</span> <span class="o">is</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">form</span> <span class="s s-Atom">of</span> <span class="s s-Atom">an</span> <span class="s s-Atom">instruction</span> <span class="nf">task</span> <span class="p">(</span><span class="s s-Atom">i</span><span class="p">.</span><span class="s s-Atom">e</span><span class="p">.,</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">that</span> <span class="s s-Atom">define</span> <span class="s s-Atom">a</span> <span class="s s-Atom">task</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">a</span> <span class="s s-Atom">set</span> <span class="s s-Atom">of</span> <span class="s s-Atom">examples</span> <span class="s s-Atom">that</span> <span class="s s-Atom">instantiate</span> <span class="s s-Atom">it</span><span class="p">).</span>

<span class="nv">Bootstrapping</span> <span class="s s-Atom">with</span> <span class="s s-Atom">limited</span> <span class="s s-Atom">resources</span><span class="p">.</span> <span class="nv">A</span> <span class="s s-Atom">series</span> <span class="s s-Atom">of</span> <span class="s s-Atom">recent</span> <span class="s s-Atom">works</span> <span class="s s-Atom">use</span> <span class="s s-Atom">language</span> <span class="s s-Atom">models</span> <span class="s s-Atom">to</span> <span class="s s-Atom">bootstrap</span> <span class="s s-Atom">some</span> <span class="s s-Atom">inferences</span> <span class="s s-Atom">using</span> <span class="s s-Atom">specialized</span> <span class="s s-Atom">methods</span><span class="p">.</span> <span class="nv">NPPrompt</span> <span class="p">(</span><span class="nv">Zhao</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">)</span> <span class="s s-Atom">provides</span> <span class="s s-Atom">a</span> <span class="s s-Atom">method</span> <span class="s s-Atom">to</span> <span class="s s-Atom">generate</span> <span class="s s-Atom">predictions</span> <span class="s s-Atom">for</span> <span class="s s-Atom">semantic</span> <span class="s s-Atom">labels</span> <span class="s s-Atom">without</span> <span class="s s-Atom">any</span> <span class="s s-Atom">finetuning</span><span class="p">.</span> <span class="nv">It</span> <span class="s s-Atom">uses</span> <span class="s s-Atom">a</span> <span class="s s-Atom">model&#39;s own embeddings to automatically find words relevant to the label of the data sample and hence reduces the dependency on manual mapping from model prediction to label (verbalizers). STAR (Zelikman et al., 2022) iteratively leverages a small number of rationale examples and a large dataset without rationales, to bootstrap a model&#39;s</span> <span class="s s-Atom">ability</span> <span class="s s-Atom">to</span> <span class="s s-Atom">perform</span> <span class="s s-Atom">reasoning</span><span class="p">.</span> <span class="nv">Self</span><span class="o">-</span><span class="nv">Correction</span> <span class="p">(</span><span class="nv">Welleck</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2023</span><span class="p">)</span> <span class="s s-Atom">decouples</span> <span class="s s-Atom">an</span> <span class="s s-Atom">imperfect</span> <span class="s s-Atom">base</span> <span class="nf">generator</span> <span class="p">(</span><span class="s s-Atom">model</span><span class="p">)</span> <span class="s s-Atom">from</span> <span class="s s-Atom">a</span> <span class="s s-Atom">separate</span> <span class="s s-Atom">corrector</span> <span class="s s-Atom">that</span> <span class="s s-Atom">learns</span> <span class="s s-Atom">to</span> <span class="s s-Atom">iteratively</span> <span class="s s-Atom">correct</span> <span class="s s-Atom">imperfect</span> <span class="s s-Atom">generations</span> <span class="s s-Atom">and</span> <span class="s s-Atom">demonstrates</span> <span class="s s-Atom">improvement</span> <span class="s s-Atom">over</span> <span class="s s-Atom">the</span> <span class="s s-Atom">base</span> <span class="s s-Atom">generator</span><span class="p">.</span> <span class="nv">Our</span> <span class="s s-Atom">work</span> <span class="s s-Atom">instead</span> <span class="s s-Atom">focuses</span> <span class="s s-Atom">on</span> <span class="s s-Atom">bootstrapping</span> <span class="s s-Atom">new</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">paradigm</span><span class="p">.</span>

<span class="nv">Multi</span><span class="o">-</span><span class="s s-Atom">modal</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">following</span><span class="p">.</span> <span class="nv">Instructionfollowing</span> <span class="s s-Atom">models</span> <span class="s s-Atom">have</span> <span class="s s-Atom">also</span> <span class="s s-Atom">been</span> <span class="s s-Atom">of</span> <span class="s s-Atom">interest</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">multi</span><span class="o">-</span><span class="s s-Atom">modal</span> <span class="s s-Atom">learning</span> <span class="nf">literature</span> <span class="p">(</span><span class="nv">Fried</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2018</span><span class="p">;</span> <span class="nv">Shridhar</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2020</span><span class="p">;</span> <span class="nv">Min</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">;</span> <span class="nv">Weir</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">).</span> <span class="nv">Self</span><span class="o">-</span><span class="nv">InSTRUCT</span><span class="p">,</span> <span class="s s-Atom">as</span> <span class="s s-Atom">a</span> <span class="s s-Atom">general</span> <span class="s s-Atom">approach</span> <span class="s s-Atom">to</span> <span class="s s-Atom">expanding</span> <span class="s s-Atom">data</span><span class="p">,</span> <span class="s s-Atom">can</span> <span class="s s-Atom">potentially</span> <span class="s s-Atom">also</span> <span class="s s-Atom">be</span> <span class="s s-Atom">helpful</span> <span class="s s-Atom">in</span> <span class="s s-Atom">those</span> <span class="s s-Atom">settings</span><span class="p">,</span> <span class="s s-Atom">which</span> <span class="s s-Atom">we</span> <span class="s s-Atom">leave</span> <span class="s s-Atom">to</span> <span class="s s-Atom">future</span> <span class="s s-Atom">work</span><span class="p">.</span>

<span class="s s-Atom">##</span> <span class="mi">6</span> <span class="nv">Conclusion</span>

<span class="nv">We</span> <span class="s s-Atom">introduce</span> <span class="nv">SELF</span><span class="o">-</span><span class="nv">INSTRUCT</span><span class="p">,</span> <span class="s s-Atom">a</span> <span class="s s-Atom">method</span> <span class="s s-Atom">to</span> <span class="s s-Atom">improve</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">following</span> <span class="s s-Atom">ability</span> <span class="s s-Atom">of</span> <span class="nv">LMs</span> <span class="s s-Atom">via</span> <span class="s s-Atom">their</span> <span class="s s-Atom">own</span> <span class="s s-Atom">generation</span> <span class="s s-Atom">of</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">data</span><span class="p">.</span> <span class="nv">On</span> <span class="s s-Atom">experimenting</span> <span class="s s-Atom">with</span> <span class="s s-Atom">vanilla</span> <span class="nv">GPT3</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">automatically</span> <span class="s s-Atom">construct</span> <span class="s s-Atom">a</span> <span class="s s-Atom">large</span><span class="o">-</span><span class="s s-Atom">scale</span> <span class="s s-Atom">dataset</span> <span class="s s-Atom">of</span> <span class="mi">52</span> <span class="nv">K</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">for</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">tasks</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">finetuning</span> <span class="nv">GPT3</span> <span class="s s-Atom">on</span> <span class="s s-Atom">this</span> <span class="s s-Atom">data</span> <span class="s s-Atom">leads</span> <span class="s s-Atom">to</span> <span class="s s-Atom">a</span> <span class="err">$</span><span class="mi">33</span> <span class="s s-Atom">\</span><span class="c1">%$ absolute improvement on SUPERNI over the original GPT3. Furthermore, we curate a set of expert-written instructions for novel tasks. Human evaluation on this set shows that tuning GPT3 with SELF-INSTRUCT outperforms using existing public instruction datasets by a large margin and performs closely to InstructGPT ${ }_{001}$. We hope SELF-INSTRUCT can serve as the first step to align pretrained LMs to follow human instructions, and future work can build on top of this data to improve instruction-following models.</span>

<span class="s s-Atom">##</span> <span class="mi">7</span> <span class="nv">Broader</span> <span class="nv">Impact</span>

<span class="nv">Beyond</span> <span class="s s-Atom">the</span> <span class="s s-Atom">immediate</span> <span class="s s-Atom">focus</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="s s-Atom">paper</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">believe</span> <span class="s s-Atom">that</span> <span class="nv">Self</span><span class="o">-</span><span class="nv">InSTruct</span> <span class="s s-Atom">may</span> <span class="s s-Atom">help</span> <span class="s s-Atom">bring</span> <span class="s s-Atom">more</span> <span class="s s-Atom">transparency</span> <span class="s s-Atom">to</span> <span class="s s-Atom">what</span> <span class="s s-Atom">happens</span> <span class="s2">&quot;behind the scenes&quot;</span> <span class="s s-Atom">of</span> <span class="s s-Atom">widely</span><span class="o">-</span><span class="s s-Atom">used</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuned</span> <span class="s s-Atom">models</span> <span class="s s-Atom">like</span> <span class="nv">InstructGPT</span> <span class="s s-Atom">or</span> <span class="nv">ChatGPT</span><span class="p">.</span> <span class="nv">Unfortunately</span><span class="p">,</span> <span class="s s-Atom">such</span> <span class="s s-Atom">industrial</span> <span class="s s-Atom">models</span> <span class="s s-Atom">remain</span> <span class="s s-Atom">behind</span> <span class="nv">API</span> <span class="s s-Atom">walls</span> <span class="s s-Atom">as</span> <span class="s s-Atom">their</span> <span class="s s-Atom">datasets</span> <span class="s s-Atom">are</span> <span class="o">not</span> <span class="s s-Atom">released</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">hence</span> <span class="s s-Atom">there</span> <span class="o">is</span> <span class="s s-Atom">little</span> <span class="s s-Atom">understanding</span> <span class="s s-Atom">of</span> <span class="s s-Atom">their</span> <span class="s s-Atom">construction</span> <span class="s s-Atom">and</span> <span class="s s-Atom">why</span> <span class="s s-Atom">they</span> <span class="s s-Atom">demonstrate</span> <span class="s s-Atom">impressive</span> <span class="s s-Atom">capabilities</span><span class="p">.</span> <span class="nv">The</span> <span class="s s-Atom">burden</span> <span class="s s-Atom">now</span> <span class="s s-Atom">falls</span> <span class="s s-Atom">on</span> <span class="s s-Atom">academia</span> <span class="s s-Atom">to</span> <span class="s s-Atom">better</span> <span class="s s-Atom">understand</span> <span class="s s-Atom">the</span> <span class="s s-Atom">source</span> <span class="s s-Atom">of</span> <span class="s s-Atom">success</span> <span class="s s-Atom">in</span> <span class="s s-Atom">these</span> <span class="s s-Atom">models</span> <span class="s s-Atom">and</span> <span class="s s-Atom">strive</span> <span class="s s-Atom">for</span> <span class="s s-Atom">better</span><span class="o">-</span><span class="s s-Atom">and</span> <span class="s s-Atom">more</span> <span class="s s-Atom">open</span><span class="o">-</span><span class="s s-Atom">models</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">believe</span> <span class="s s-Atom">our</span> <span class="s s-Atom">findings</span> <span class="s s-Atom">in</span> <span class="s s-Atom">this</span> <span class="s s-Atom">paper</span> <span class="s s-Atom">demonstrate</span> <span class="s s-Atom">the</span> <span class="s s-Atom">importance</span> <span class="s s-Atom">of</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">data</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">our</span> <span class="s s-Atom">large</span> <span class="s s-Atom">synthetic</span> <span class="s s-Atom">dataset</span> <span class="s s-Atom">can</span> <span class="s s-Atom">be</span> <span class="s s-Atom">the</span> <span class="s s-Atom">first</span> <span class="s s-Atom">step</span> <span class="s s-Atom">toward</span> <span class="s s-Atom">higher</span><span class="o">-</span><span class="s s-Atom">quality</span> <span class="s s-Atom">data</span> <span class="s s-Atom">for</span> <span class="s s-Atom">building</span> <span class="s s-Atom">better</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">following</span> <span class="s s-Atom">models</span><span class="p">.</span> <span class="nv">At</span> <span class="s s-Atom">this</span> <span class="s s-Atom">writing</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">central</span> <span class="s s-Atom">idea</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="s s-Atom">paper</span> <span class="s s-Atom">has</span> <span class="s s-Atom">been</span> <span class="s s-Atom">adopted</span> <span class="s s-Atom">in</span> <span class="s s-Atom">several</span> <span class="s s-Atom">follow</span><span class="o">-</span><span class="s s-Atom">up</span> <span class="s s-Atom">works</span> <span class="s s-Atom">for</span> <span class="s s-Atom">such</span> <span class="nf">endeavors</span> <span class="p">(</span><span class="nv">Taori</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2023</span><span class="p">;</span> <span class="nv">Xu</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2023</span><span class="p">;</span> <span class="nv">Sun</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2023</span><span class="p">,</span> <span class="s s-Atom">i</span><span class="p">.</span><span class="s s-Atom">a</span><span class="p">.).</span>

<span class="s s-Atom">##</span> <span class="mi">8</span> <span class="nv">Limitations</span>

<span class="nv">Here</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">discuss</span> <span class="s s-Atom">some</span> <span class="s s-Atom">limitations</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="s s-Atom">work</span> <span class="s s-Atom">to</span> <span class="s s-Atom">inspire</span> <span class="s s-Atom">future</span> <span class="s s-Atom">research</span> <span class="s s-Atom">in</span> <span class="s s-Atom">this</span> <span class="s s-Atom">direction</span><span class="p">.</span>

<span class="nv">Tail</span> <span class="s s-Atom">phenomena</span><span class="p">.</span> <span class="nv">Self</span><span class="o">-</span><span class="nv">InSTRUCT</span> <span class="s s-Atom">depends</span> <span class="s s-Atom">on</span> <span class="nv">LMs</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">it</span> <span class="s s-Atom">will</span> <span class="s s-Atom">inherit</span> <span class="s s-Atom">all</span> <span class="s s-Atom">the</span> <span class="s s-Atom">limitations</span> <span class="s s-Atom">that</span> <span class="s s-Atom">carry</span> <span class="s s-Atom">over</span> <span class="s s-Atom">with</span> <span class="nv">LMs</span><span class="p">.</span> <span class="nv">As</span> <span class="s s-Atom">recent</span> <span class="s s-Atom">studies</span> <span class="s s-Atom">have</span> <span class="nf">shown</span> <span class="p">(</span><span class="nv">Razeghi</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">;</span> <span class="nv">Kandpal</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">),</span> <span class="s s-Atom">tail</span> <span class="s s-Atom">phenomena</span> <span class="s s-Atom">pose</span> <span class="s s-Atom">a</span> <span class="s s-Atom">serious</span> <span class="s s-Atom">challenge</span> <span class="s s-Atom">to</span> <span class="s s-Atom">the</span> <span class="s s-Atom">success</span> <span class="s s-Atom">of</span> <span class="nv">LMs</span><span class="p">.</span> <span class="nv">In</span> <span class="s s-Atom">other</span> <span class="s s-Atom">words</span><span class="p">,</span> <span class="nv">LMs</span><span class="s s-Atom">&#39; largest gains correspond to the frequent uses of languages (head of the language use distribution), and there might be minimal gains in the low-frequency contexts. Similarly, in the context of this work, it would not be surprising if the majority of the gains by SelFInSTRUCT are skewed toward tasks or instructions that present more frequently in the pretraining corpus. As a consequence, the approach might show brittleness with respect to uncommon and creative instructions.</span>

<span class="s s-Atom">Dependence on large models. Because of SELFInSTRUCT&#39;s</span> <span class="s s-Atom">dependence</span> <span class="s s-Atom">on</span> <span class="s s-Atom">the</span> <span class="s s-Atom">inductive</span> <span class="s s-Atom">biases</span> <span class="s s-Atom">extracted</span> <span class="s s-Atom">from</span> <span class="nv">LMs</span><span class="p">,</span> <span class="s s-Atom">it</span> <span class="s s-Atom">might</span> <span class="s s-Atom">work</span> <span class="s s-Atom">best</span> <span class="s s-Atom">for</span> <span class="s s-Atom">larger</span> <span class="s s-Atom">models</span><span class="p">.</span> <span class="nv">If</span> <span class="s s-Atom">true</span><span class="p">,</span> <span class="s s-Atom">this</span> <span class="s s-Atom">may</span> <span class="s s-Atom">create</span> <span class="s s-Atom">barriers</span> <span class="s s-Atom">to</span> <span class="s s-Atom">access</span> <span class="s s-Atom">for</span> <span class="s s-Atom">those</span> <span class="s s-Atom">who</span> <span class="s s-Atom">may</span> <span class="o">not</span> <span class="s s-Atom">have</span> <span class="s s-Atom">large</span> <span class="s s-Atom">computing</span> <span class="s s-Atom">resources</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">hope</span> <span class="s s-Atom">future</span> <span class="s s-Atom">studies</span> <span class="s s-Atom">will</span> <span class="s s-Atom">carefully</span> <span class="s s-Atom">study</span> <span class="s s-Atom">the</span> <span class="s s-Atom">gains</span> <span class="s s-Atom">as</span> <span class="s s-Atom">a</span> <span class="s s-Atom">function</span> <span class="s s-Atom">of</span> <span class="s s-Atom">model</span> <span class="s s-Atom">size</span> <span class="s s-Atom">or</span> <span class="s s-Atom">various</span> <span class="s s-Atom">other</span> <span class="s s-Atom">parameters</span><span class="p">.</span> <span class="nv">It</span> <span class="o">is</span> <span class="s s-Atom">worthwhile</span> <span class="s s-Atom">to</span>
<span class="s s-Atom">note</span> <span class="s s-Atom">that</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuning</span> <span class="s s-Atom">with</span> <span class="s s-Atom">human</span> <span class="s s-Atom">annotation</span> <span class="s s-Atom">also</span> <span class="s s-Atom">suffers</span> <span class="s s-Atom">from</span> <span class="s s-Atom">a</span> <span class="s s-Atom">similar</span> <span class="s s-Atom">limitation</span><span class="p">:</span> <span class="s s-Atom">gains</span> <span class="s s-Atom">of</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">tuning</span> <span class="s s-Atom">are</span> <span class="s s-Atom">higher</span> <span class="s s-Atom">for</span> <span class="s s-Atom">larger</span> <span class="nf">models</span> <span class="p">(</span><span class="nv">Wei</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.,</span> <span class="mi">2022</span><span class="p">).</span>

<span class="nv">Reinforcing</span> <span class="nv">LM</span> <span class="s s-Atom">biases</span><span class="p">.</span> <span class="nv">A</span> <span class="s s-Atom">point</span> <span class="s s-Atom">of</span> <span class="s s-Atom">concern</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="s s-Atom">authors</span> <span class="o">is</span> <span class="s s-Atom">the</span> <span class="s s-Atom">unintended</span> <span class="s s-Atom">consequences</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="s s-Atom">iterative</span> <span class="s s-Atom">algorithm</span><span class="p">,</span> <span class="s s-Atom">such</span> <span class="s s-Atom">as</span> <span class="s s-Atom">the</span> <span class="s s-Atom">amplification</span> <span class="s s-Atom">of</span> <span class="s s-Atom">problematic</span> <span class="s s-Atom">social</span> <span class="nf">biases</span> <span class="p">(</span><span class="s s-Atom">stereotypes</span> <span class="s s-Atom">or</span> <span class="s s-Atom">slurs</span> <span class="s s-Atom">about</span> <span class="s s-Atom">gender</span><span class="p">,</span> <span class="s s-Atom">race</span><span class="p">,</span> <span class="s s-Atom">etc</span><span class="p">.).</span> <span class="nv">Relatedly</span><span class="p">,</span> <span class="s s-Atom">one</span> <span class="s s-Atom">observed</span> <span class="s s-Atom">challenge</span> <span class="s s-Atom">in</span> <span class="s s-Atom">this</span> <span class="s s-Atom">process</span> <span class="o">is</span> <span class="s s-Atom">the</span> <span class="s s-Atom">algorithm&#39;s difficulty in producing balanced labels, which reflected models&#39;</span> <span class="s s-Atom">prior</span> <span class="s s-Atom">biases</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">hope</span> <span class="s s-Atom">future</span> <span class="s s-Atom">work</span> <span class="s s-Atom">will</span> <span class="s s-Atom">lead</span> <span class="s s-Atom">to</span> <span class="s s-Atom">better</span> <span class="s s-Atom">understanding</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">pros</span> <span class="s s-Atom">and</span> <span class="s s-Atom">cons</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="s s-Atom">approach</span><span class="p">.</span>

<span class="s s-Atom">##</span> <span class="nv">Acknowledgements</span>

<span class="nv">The</span> <span class="s s-Atom">authors</span> <span class="s s-Atom">would</span> <span class="s s-Atom">like</span> <span class="s s-Atom">to</span> <span class="s s-Atom">thank</span> <span class="s s-Atom">the</span> <span class="s s-Atom">anonymous</span> <span class="s s-Atom">reviewers</span> <span class="s s-Atom">for</span> <span class="s s-Atom">their</span> <span class="s s-Atom">constructive</span> <span class="s s-Atom">feedback</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">especially</span> <span class="s s-Atom">thank</span> <span class="nv">Sewon</span> <span class="nv">Min</span><span class="p">,</span> <span class="nv">Eric</span> <span class="nv">Wallace</span><span class="p">,</span> <span class="nv">Ofir</span> <span class="nv">Press</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">other</span> <span class="s s-Atom">members</span> <span class="s s-Atom">of</span> <span class="nv">UWNLP</span> <span class="s s-Atom">and</span> <span class="nv">AllenNLP</span> <span class="s s-Atom">for</span> <span class="s s-Atom">their</span> <span class="s s-Atom">encouraging</span> <span class="s s-Atom">feedback</span> <span class="s s-Atom">and</span> <span class="s s-Atom">intellectual</span> <span class="s s-Atom">support</span><span class="p">.</span> <span class="nv">This</span> <span class="s s-Atom">work</span> <span class="s s-Atom">was</span> <span class="s s-Atom">supported</span> <span class="s s-Atom">in</span> <span class="s s-Atom">part</span> <span class="s s-Atom">by</span> <span class="nv">DARPA</span> <span class="nv">MCS</span> <span class="s s-Atom">program</span> <span class="s s-Atom">through</span> <span class="nv">NIWC</span> <span class="nv">Pacific</span> <span class="p">(</span><span class="nv">N66001</span><span class="o">-</span><span class="mi">19</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="mi">4031</span><span class="p">),</span> <span class="nv">ONR</span> <span class="nv">N00014</span><span class="o">-</span><span class="mi">18</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">2826</span><span class="p">,</span> <span class="nv">ONR</span> <span class="nv">MURI</span> <span class="nv">N00014</span><span class="o">-</span><span class="mi">18</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="mi">2670</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">gifts</span> <span class="s s-Atom">from</span> <span class="nv">AI2</span> <span class="s s-Atom">and</span> <span class="s s-Atom">an</span> <span class="nv">Allen</span> <span class="nv">Investigator</span> <span class="s s-Atom">award</span><span class="p">.</span>

<span class="s s-Atom">##</span> <span class="nv">References</span>

<span class="nv">Massih</span><span class="o">-</span><span class="nv">Reza</span> <span class="nv">Amini</span><span class="p">,</span> <span class="nv">Vasilii</span> <span class="nv">Feofanov</span><span class="p">,</span> <span class="nv">Loic</span> <span class="nv">Pauletto</span><span class="p">,</span> <span class="nv">Emilie</span> <span class="nv">Devijver</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="nv">Yury</span> <span class="nv">Maximov</span><span class="p">.</span> <span class="mf">2022.</span> <span class="nv">Self</span><span class="o">-</span><span class="s s-Atom">training</span><span class="p">:</span> <span class="nv">A</span> <span class="s s-Atom">survey</span><span class="p">.</span> <span class="s s-Atom">arXiv</span> <span class="s s-Atom">preprint</span> <span class="s s-Atom">arXiv</span><span class="o">:</span><span class="mf">2202.12040</span><span class="p">.</span>

<span class="nv">Stephen</span> <span class="nv">H</span> <span class="nv">Bach</span><span class="p">,</span> <span class="nv">Victor</span> <span class="nv">Sanh</span><span class="p">,</span> <span class="nv">Zheng</span><span class="o">-</span><span class="nv">Xin</span> <span class="nv">Yong</span><span class="p">,</span> <span class="nv">Albert</span> <span class="nv">Webson</span><span class="p">,</span> <span class="nv">Colin</span> <span class="nv">Raffel</span><span class="p">,</span> <span class="nv">Nihal</span> <span class="nv">V</span> <span class="nv">Nayak</span><span class="p">,</span> <span class="nv">Abheesht</span> <span class="nv">Sharma</span><span class="p">,</span> <span class="nv">Taewoon</span> <span class="nv">Kim</span><span class="p">,</span> <span class="nv">M</span> <span class="nv">Saiful</span> <span class="nv">Bari</span><span class="p">,</span> <span class="nv">Thibault</span> <span class="nv">Fevry</span><span class="p">,</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.</span> <span class="mf">2022.</span> <span class="nv">PromptSource</span><span class="o">:</span> <span class="nv">An</span> <span class="nv">Integrated</span> <span class="nv">Development</span> <span class="nv">Environment</span> <span class="s s-Atom">and</span> <span class="nv">Repository</span> <span class="s s-Atom">for</span> <span class="nv">Natural</span> <span class="nv">Language</span> <span class="nv">Prompts</span><span class="p">.</span> <span class="nv">In</span> <span class="nv">Annual</span> <span class="nv">Meeting</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">Association</span> <span class="s s-Atom">for</span> <span class="nv">Computational</span> <span class="nv">Linguistics</span> <span class="p">(</span><span class="nv">ACL</span><span class="p">)</span> <span class="nv">System</span> <span class="nv">Demonstrations</span><span class="p">.</span>

<span class="nv">Tom</span> <span class="nv">B</span><span class="p">.</span> <span class="nv">Brown</span><span class="p">,</span> <span class="nv">Benjamin</span> <span class="nv">Mann</span><span class="p">,</span> <span class="nv">Nick</span> <span class="nv">Ryder</span><span class="p">,</span> <span class="nv">Melanie</span> <span class="nv">Subbiah</span><span class="p">,</span> <span class="nv">Jared</span> <span class="nv">Kaplan</span><span class="p">,</span> <span class="nv">Prafulla</span> <span class="nv">Dhariwal</span><span class="p">,</span> <span class="nv">Arvind</span> <span class="nv">Neelakantan</span><span class="p">,</span> <span class="nv">Pranav</span> <span class="nv">Shyam</span><span class="p">,</span> <span class="nv">Girish</span> <span class="nv">Sastry</span><span class="p">,</span> <span class="nv">Amanda</span> <span class="nv">Askell</span><span class="p">,</span> <span class="nv">Sandhini</span> <span class="nv">Agarwal</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.</span> <span class="mf">2020.</span> <span class="nv">Language</span> <span class="s s-Atom">models</span> <span class="s s-Atom">are</span> <span class="s s-Atom">few</span><span class="o">-</span><span class="s s-Atom">shot</span> <span class="s s-Atom">learners</span><span class="p">.</span> <span class="nv">In</span> <span class="nv">Advances</span> <span class="s s-Atom">in</span> <span class="nv">Neural</span> <span class="nv">Information</span> <span class="nv">Processing</span> <span class="nv">Systems</span> <span class="p">(</span><span class="nv">NeurIPS</span><span class="p">).</span>

<span class="nv">Hyung</span> <span class="nv">Won</span> <span class="nv">Chung</span><span class="p">,</span> <span class="nv">Le</span> <span class="nv">Hou</span><span class="p">,</span> <span class="nv">Shayne</span> <span class="nv">Longpre</span><span class="p">,</span> <span class="nv">Barret</span> <span class="nv">Zoph</span><span class="p">,</span> <span class="nv">Yi</span> <span class="nv">Tay</span><span class="p">,</span> <span class="nv">William</span> <span class="nv">Fedus</span><span class="p">,</span> <span class="nv">Eric</span> <span class="nv">Li</span><span class="p">,</span> <span class="nv">Xuezhi</span> <span class="nv">Wang</span><span class="p">,</span> <span class="nv">Mostafa</span> <span class="nv">Dehghani</span><span class="p">,</span> <span class="nv">Siddhartha</span> <span class="nv">Brahma</span><span class="p">,</span> <span class="s s-Atom">et</span> <span class="s s-Atom">al</span><span class="p">.</span> <span class="mf">2022.</span> <span class="nv">Scaling</span> <span class="s s-Atom">instruction</span><span class="o">-</span><span class="s s-Atom">finetuned</span> <span class="s s-Atom">language</span> <span class="s s-Atom">models</span><span class="p">.</span> <span class="s s-Atom">arXiv</span> <span class="s s-Atom">preprint</span> <span class="s s-Atom">arXiv</span><span class="o">:</span><span class="mf">2210.11416</span><span class="p">.</span>

<span class="nv">Jingfei</span> <span class="nv">Du</span><span class="p">,</span> <span class="s s-Atom">Édouard</span> <span class="nv">Grave</span><span class="p">,</span> <span class="nv">Beliz</span> <span class="nv">Gunel</span><span class="p">,</span> <span class="nv">Vishrav</span> <span class="nv">Chaudhary</span><span class="p">,</span> <span class="nv">Onur</span> <span class="nv">Celebi</span><span class="p">,</span> <span class="nv">Michael</span> <span class="nv">Auli</span><span class="p">,</span> <span class="nv">Veselin</span> <span class="nv">Stoyanov</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="nv">Alexis</span> <span class="nv">Conneau</span><span class="p">.</span> <span class="mf">2021.</span> <span class="nv">Self</span><span class="o">-</span><span class="s s-Atom">training</span> <span class="s s-Atom">improves</span> <span class="s s-Atom">pre</span><span class="o">-</span><span class="s s-Atom">training</span> <span class="s s-Atom">for</span> <span class="s s-Atom">natural</span> <span class="s s-Atom">language</span> <span class="s s-Atom">understanding</span><span class="p">.</span> <span class="nv">In</span> <span class="nv">Conference</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">North</span> <span class="nv">American</span> <span class="nv">Chapter</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">Association</span> <span class="s s-Atom">for</span> <span class="nv">Computational</span> <span class="nv">Linguistics</span> <span class="p">(</span><span class="nv">NAACL</span><span class="p">)</span><span class="o">:</span> <span class="nv">Human</span> <span class="nv">Language</span> <span class="nv">Technologies</span><span class="p">,</span> <span class="s s-Atom">pages</span> <span class="mi">5408</span><span class="o">-</span><span class="mf">5418.</span>

<span class="nv">Steven</span> <span class="nv">Y</span> <span class="nv">Feng</span><span class="p">,</span> <span class="nv">Varun</span> <span class="nv">Gangal</span><span class="p">,</span> <span class="nv">Jason</span> <span class="nv">Wei</span><span class="p">,</span> <span class="nv">Sarath</span> <span class="nv">Chandar</span><span class="p">,</span> <span class="nv">Soroush</span> <span class="nv">Vosoughi</span><span class="p">,</span> <span class="nv">Teruko</span> <span class="nv">Mitamura</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="nv">Eduard</span> <span class="nv">Hovy</span><span class="p">.</span> <span class="mf">2021.</span> <span class="nv">A</span> <span class="s s-Atom">survey</span> <span class="s s-Atom">of</span> <span class="s s-Atom">data</span> <span class="s s-Atom">augmentation</span> <span class="s s-Atom">approaches</span> <span class="s s-Atom">for</span> <span class="s s-Atom">nlp</span><span class="p">.</span> <span class="nv">In</span> <span class="nv">Annual</span> <span class="nv">Meeting</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">Association</span> <span class="s s-Atom">for</span> <span class="nv">Computational</span> <span class="nv">Linguistics</span> <span class="p">(</span><span class="nv">ACL</span><span class="p">)</span> <span class="nv">ACLIJCNLP</span> <span class="o">-</span> <span class="nv">Findings</span><span class="p">,</span> <span class="s s-Atom">pages</span> <span class="mi">968</span><span class="o">-</span><span class="mf">988.</span>

<span class="nv">Daniel</span> <span class="nv">Fried</span><span class="p">,</span> <span class="nv">Ronghang</span> <span class="nv">Hu</span><span class="p">,</span> <span class="nv">Volkan</span> <span class="nv">Cirik</span><span class="p">,</span> <span class="nv">Anna</span> <span class="nv">Rohrbach</span><span class="p">,</span> <span class="nv">Jacob</span> <span class="nv">Andreas</span><span class="p">,</span> <span class="nv">Louis</span><span class="o">-</span><span class="nv">Philippe</span> <span class="nv">Morency</span><span class="p">,</span> <span class="nv">Taylor</span> <span class="nv">Berg</span><span class="o">-</span><span class="nv">Kirkpatrick</span><span class="p">,</span> <span class="nv">Kate</span> <span class="nv">Saenko</span><span class="p">,</span> <span class="nv">Dan</span> <span class="nv">Klein</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="nv">Trevor</span> <span class="nv">Darrell</span><span class="p">.</span> <span class="mf">2018.</span> <span class="nv">Speaker</span><span class="o">-</span><span class="s s-Atom">follower</span> <span class="s s-Atom">models</span> <span class="s s-Atom">for</span> <span class="s s-Atom">vision</span><span class="o">-</span><span class="s s-Atom">and</span><span class="o">-</span><span class="s s-Atom">language</span> <span class="s s-Atom">navigation</span><span class="p">.</span> <span class="nv">In</span> <span class="nv">Advances</span> <span class="s s-Atom">in</span> <span class="nv">Neural</span> <span class="nv">Information</span> <span class="nv">Processing</span> <span class="nv">Systems</span> <span class="p">(</span><span class="nv">NeurIPS</span><span class="p">).</span>

<span class="nv">Junxian</span> <span class="nv">He</span><span class="p">,</span> <span class="nv">Jiatao</span> <span class="nv">Gu</span><span class="p">,</span> <span class="nv">Jiajun</span> <span class="nv">Shen</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="nv">Marc</span><span class="s s-Atom">&#39;Aurelio Ranzato. 2019. Revisiting self-training for neural sequence generation. In International Conference on Learning Representations (ICLR).</span>

<span class="s s-Atom">Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. 2015. Distilling the knowledge in a neural network. In Advances in Neural Information Processing Systems (NeurIPS) Workshop on Deep Learning.</span>

<span class="s s-Atom">Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022a. Unnatural instructions: Tuning language models with (almost) no human labor. arXiv preprint arXiv:2212.09689.</span>

<span class="s s-Atom">Or Honovich, Uri Shaham, Samuel R Bowman, and Omer Levy. 2022b. Instruction induction: From few examples to natural language task descriptions. arXiv preprint arXiv:2205.10782.</span>

<span class="s s-Atom">Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022. Large language models can self-improve. arXiv preprint arXiv:2210.11610.</span>

<span class="s s-Atom">Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2022. Large language models struggle to learn long-tail knowledge. arXiv preprint arXiv:2211.08411.</span>

<span class="s s-Atom">Nikita Kitaev, Steven Cao, and Dan Klein. 2019. Multilingual constituency parsing with self-attention and pre-training. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 34993505 .</span>

<span class="s s-Atom">Nikita Kitaev and Dan Klein. 2018. Constituency parsing with a self-attentive encoder. In Annual Meeting of the Association for Computational Linguistics (ACL), pages 2676-2686.</span>

<span class="s s-Atom">Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</span>

<span class="s s-Atom">Alisa Liu, Swabha Swayamdipta, Noah A. Smith, and Yejin Choi. 2022. WANLI: Worker and ai collaboration for natural language inference dataset creation. In Conference on Empirical Methods in Natural Language Processing (EMNLP) - Findings.</span>

<span class="s s-Atom">Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and Aliaksei Severyn. 2022. Teaching small language models to reason. arXiv preprint arXiv:2212.08410.</span>

<span class="s s-Atom">Dheeraj Mekala, Tu Vu, Timo Schick, and Jingbo Shang. 2022. Leveraging qa datasets to improve generative data augmentation. arXiv preprint arXiv:2205.12604.</span>

<span class="s s-Atom">Yu Meng, Martin Michalski, Jiaxin Huang, Yu Zhang, Tarek Abdelzaher, and Jiawei Han. 2023. Tuning language models as training data generators for augmentation-enhanced few-shot learning. In International Conference on Machine Learning (ICML).</span>

<span class="s s-Atom">So Yeon Min, Devendra Singh Chaplot, Pradeep Ravikumar, Yonatan Bisk, and Ruslan Salakhutdinov. 2022. FILM: Following Instructions in Language with Modular Methods. In International Conference on Learning Representations (ICLR).</span>

<span class="s s-Atom">Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. In Annual Meeting of the Association for Computational Linguistics (ACL).</span>

<span class="s s-Atom">Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training Language Models to Follow Instructions with Human Feedback. In Advances in Neural Information Processing Systems (NeurIPS).</span>

<span class="s s-Atom">Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research (JMLR).</span>

<span class="s s-Atom">Yasaman Razeghi, Robert L Logan IV, Matt Gardner, and Sameer Singh. 2022. Impact of pretraining term frequencies on few-shot reasoning. arXiv preprint arXiv:2202.07206.</span>

<span class="s s-Atom">Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. In Advances in Neural Information Processing Systems (NeurIPS) Workshop on Energy Efficient Machine Learning and Cognitive Computing.</span>

<span class="s s-Atom">Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti</span>

<span class="s s-Atom">Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. 2022. Multitask Prompted Training Enables Zero-Shot Task Generalization. In International Conference on Learning Representations (ICLR).</span>

<span class="s s-Atom">Timo Schick and Hinrich Schütze. 2021. Generating datasets with pretrained language models. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</span>

<span class="s s-Atom">Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020. ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</span>

<span class="s s-Atom">Chandan Singh, John X Morris, Jyoti Aneja, Alexander M Rush, and Jianfeng Gao. 2022. Explaining patterns in data with language models via interpretable autoprompting. arXiv preprint arXiv:2210.01848.</span>

<span class="s s-Atom">Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2023. Principle-driven selfalignment of language models from scratch with minimal human supervision. arXiv preprint arXiv:2305.03047.</span>

<span class="s s-Atom">Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.</span>

<span class="s s-Atom">Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi. 2022. Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</span>

<span class="s s-Atom">Zirui Wang, Adams Wei Yu, Orhan Firat, and Yuan Cao. 2021. Towards zero-label language learning. arXiv preprint arXiv:2109.09193.</span>

<span class="s s-Atom">Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M.</span>

<span class="s s-Atom">Dai, and Quoc V Le. 2022. Finetuned Language Models are Zero-Shot Learners. In International Conference on Learning Representations (ICLR).</span>

<span class="s s-Atom">Nathaniel Weir, Xingdi Yuan, Marc-Alexandre Côté, Matthew Hausknecht, Romain Laroche, Ida Momennejad, Harm Van Seijen, and Benjamin Van Durme. 2022. One-Shot Learning from a Demonstration with Hierarchical Latent Language. arXiv preprint arXiv:2203.04806.</span>

<span class="s s-Atom">Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel Khashabi, and Yejin Choi. 2023. Generating sequences by learning to selfcorrect. In International Conference on Learning Representations (ICLR).</span>

<span class="s s-Atom">Orion Weller, Nicholas Lourie, Matt Gardner, and Matthew Peters. 2020. Learning from Task Descriptions. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</span>

<span class="s s-Atom">Peter West, Chandra Bhagavatula, Jack Hessel, Jena D Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. 2021. Symbolic knowledge distillation: from general language models to commonsense models. In Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</span>

<span class="s s-Atom">Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. 2020. Self-training with noisy student improves imagenet classification. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 10687-10698.</span>

<span class="s s-Atom">Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. 2023. Baize: An open-source chat model with parameter-efficient tuning on self-chat data. arXiv preprint arXiv:2304.01196.</span>

<span class="s s-Atom">Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang, Chandra Bhagavatula, Yejin Choi, and Doug Downey. 2020. Generative data augmentation for commonsense reasoning. In Conference on Empirical Methods in Natural Language Processing (EMNLP) Findings.</span>

<span class="s s-Atom">Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, and Minjoon Seo. 2022. Guess the instruction! making language models stronger zero-shot learners. arXiv preprint arXiv:2210.02969.</span>

<span class="s s-Atom">Eric Zelikman, Jesse Mu, Noah D Goodman, and Yuhuai Tony Wu. 2022. STar: Self-taught reasoner bootstrapping reasoning with reasoning. In Advances in Neural Information Processing Systems (NeurIPS).</span>

<span class="s s-Atom">Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu, and Lei Li. 2022. Pre-trained language models can be fully zero-shot learners. arXiv preprint arXiv:2212.06950.</span>

<span class="s s-Atom">Chunting Zhou, Junxian He, Xuezhe Ma, Taylor BergKirkpatrick, and Graham Neubig. 2022a. Prompt Consistency for Zero-Shot Task Generalization. In Conference on Empirical Methods in Natural Language Processing (EMNLP) - Findings.</span>

<span class="s s-Atom">Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022b. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910.</span>

<span class="s s-Atom"># Supplemental Material </span>

<span class="s s-Atom">## A Implementation Details</span>

<span class="s s-Atom">## A. 1 Writing the Seed Tasks</span>

<span class="s s-Atom">Our method relies on a set of seed tasks to bootstrap the generation. The seed tasks are important for both encouraging the task diversity and demonstrating correct ways for solving the diverse tasks. For example, with coding tasks to prompt the model, it has a larger chance to generate coding-related tasks; it&#39;s</span> <span class="s s-Atom">also</span> <span class="s s-Atom">better</span> <span class="s s-Atom">to</span> <span class="s s-Atom">have</span> <span class="s s-Atom">coding</span> <span class="s s-Atom">output</span> <span class="s s-Atom">to</span> <span class="s s-Atom">guide</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">in</span> <span class="s s-Atom">writing</span> <span class="s s-Atom">code</span> <span class="s s-Atom">for</span> <span class="s s-Atom">new</span> <span class="s s-Atom">tasks</span><span class="p">.</span> <span class="nv">So</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">more</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">are</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">more</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">and</span> <span class="s s-Atom">better</span> <span class="s s-Atom">quality</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">will</span> <span class="s s-Atom">be</span><span class="p">.</span>

<span class="nv">Our</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">were</span> <span class="s s-Atom">written</span> <span class="s s-Atom">when</span> <span class="s s-Atom">we</span> <span class="s s-Atom">initiated</span> <span class="s s-Atom">this</span> <span class="s s-Atom">project</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">targeted</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="s s-Atom">diverse</span> <span class="s s-Atom">and</span> <span class="s s-Atom">interesting</span> <span class="s s-Atom">usages</span> <span class="s s-Atom">of</span> <span class="nv">LLMs</span><span class="p">.</span> <span class="nv">The</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">were</span> <span class="s s-Atom">written</span> <span class="s s-Atom">by</span> <span class="s s-Atom">the</span> <span class="s s-Atom">authors</span> <span class="s s-Atom">and</span> <span class="s s-Atom">our</span> <span class="s s-Atom">labmates</span> <span class="s s-Atom">at</span> <span class="nv">UWNLP</span><span class="p">,</span> <span class="s s-Atom">without</span> <span class="s s-Atom">explicit</span> <span class="s s-Atom">reference</span> <span class="s s-Atom">to</span> <span class="s s-Atom">existing</span> <span class="s s-Atom">datasets</span> <span class="s s-Atom">or</span> <span class="s s-Atom">specific</span> <span class="s s-Atom">testing</span> <span class="s s-Atom">tasks</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">further</span> <span class="s s-Atom">categorized</span> <span class="s s-Atom">the</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">into</span> <span class="s s-Atom">classification</span> <span class="s s-Atom">and</span> <span class="s s-Atom">non</span><span class="o">-</span><span class="s s-Atom">classification</span> <span class="s s-Atom">tasks</span><span class="p">,</span> <span class="s s-Atom">based</span> <span class="s s-Atom">on</span> <span class="s s-Atom">whether</span> <span class="s s-Atom">the</span> <span class="s s-Atom">task</span> <span class="s s-Atom">has</span> <span class="s s-Atom">a</span> <span class="s s-Atom">limited</span> <span class="s s-Atom">output</span> <span class="s s-Atom">label</span> <span class="s s-Atom">space</span><span class="p">.</span> <span class="nv">In</span> <span class="s s-Atom">total</span><span class="p">,</span> <span class="s s-Atom">there</span> <span class="s s-Atom">are</span> <span class="mi">25</span> <span class="s s-Atom">classification</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">and</span> <span class="mi">150</span> <span class="s s-Atom">non</span><span class="o">-</span><span class="s s-Atom">classification</span> <span class="s s-Atom">tasks</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">release</span> <span class="s s-Atom">this</span> <span class="s s-Atom">data</span> <span class="s s-Atom">in</span> <span class="s s-Atom">our</span> <span class="nv">GitHub</span> <span class="s s-Atom">repository</span><span class="p">.</span> <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="s s-Atom">^</span><span class="p">{</span><span class="mi">11</span><span class="p">}</span><span class="err">$</span>

<span class="nv">To</span> <span class="s s-Atom">provide</span> <span class="s s-Atom">a</span> <span class="s s-Atom">sense</span> <span class="s s-Atom">of</span> <span class="s s-Atom">how</span> <span class="s s-Atom">much</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="o">is</span> <span class="s s-Atom">generalizing</span> <span class="s s-Atom">beyond</span> <span class="s s-Atom">these</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">tasks</span><span class="p">,</span> <span class="s s-Atom">we</span> <span class="s s-Atom">further</span> <span class="s s-Atom">quantify</span> <span class="s s-Atom">the</span> <span class="s s-Atom">overlap</span> <span class="s s-Atom">between</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">of</span> <span class="s s-Atom">these</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">of</span> <span class="s s-Atom">our</span> <span class="s s-Atom">test</span> <span class="s s-Atom">sets</span><span class="p">,</span> <span class="s s-Atom">including</span> <span class="s s-Atom">both</span> <span class="nv">SUPERNI</span> <span class="s s-Atom">task</span> <span class="nf">instructions</span> <span class="p">(</span><span class="s s-Atom">\</span><span class="err">$</span><span class="mf">4.3</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="nb">user</span><span class="o">-</span><span class="s s-Atom">oriented</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">in</span> <span class="s s-Atom">our</span> <span class="s s-Atom">human</span> <span class="nf">evaluation</span><span class="p">(</span><span class="s s-Atom">\</span><span class="err">$</span><span class="mf">4.4</span><span class="p">).</span> <span class="nv">We</span> <span class="s s-Atom">compute</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">similarities</span> <span class="s s-Atom">between</span> <span class="s s-Atom">each</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">and</span> <span class="s s-Atom">its</span> <span class="s s-Atom">most</span> <span class="s s-Atom">similar</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">test</span> <span class="s s-Atom">set</span><span class="p">.</span> <span class="nv">The</span> <span class="s s-Atom">distribution</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">scores</span> <span class="s s-Atom">are</span> <span class="s s-Atom">plotted</span> <span class="s s-Atom">in</span> <span class="nv">Figure</span> <span class="mi">8</span><span class="p">,</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="s s-Atom">average</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">similarity</span> <span class="s s-Atom">between</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">and</span> <span class="nv">SUPERNI</span> <span class="s s-Atom">as</span> <span class="mf">0.21</span> <span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="s s-Atom">average</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">similarity</span> <span class="s s-Atom">between</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">and</span> <span class="nb">user</span><span class="o">-</span><span class="s s-Atom">oriented</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">as</span> <span class="mf">0.34</span> <span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">see</span> <span class="s s-Atom">a</span> <span class="s s-Atom">decent</span> <span class="s s-Atom">difference</span> <span class="s s-Atom">between</span> <span class="s s-Atom">the</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">tasks</span> <span class="s s-Atom">and</span> <span class="s s-Atom">both</span> <span class="s s-Atom">test</span> <span class="s s-Atom">sets</span><span class="p">.</span> <span class="nv">There</span> <span class="o">is</span> <span class="s s-Atom">exactly</span> <span class="s s-Atom">one</span> <span class="s s-Atom">identical</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">occurring</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="nb">user</span><span class="o">-</span><span class="s s-Atom">oriented</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">test</span> <span class="s s-Atom">set</span><span class="p">,</span> <span class="s s-Atom">which</span> <span class="o">is</span> <span class="s2">&quot;answer the following question&quot;</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="s s-Atom">following</span> <span class="s s-Atom">questions</span> <span class="s s-Atom">are</span> <span class="s s-Atom">actually</span> <span class="s s-Atom">very</span> <span class="s s-Atom">different</span><span class="p">.</span>
<span class="p">![</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">7.</span><span class="s s-Atom">jpeg</span><span class="p">](</span><span class="s s-Atom">img</span><span class="o">-</span><span class="mf">7.</span><span class="s s-Atom">jpeg</span><span class="p">)</span>

<span class="nv">Figure</span> <span class="mi">8</span><span class="o">:</span> <span class="nv">Distribution</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="nv">ROUGE</span><span class="o">-</span><span class="nv">L</span> <span class="s s-Atom">scores</span> <span class="s s-Atom">between</span> <span class="s s-Atom">seed</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">and</span> <span class="s s-Atom">their</span> <span class="s s-Atom">most</span> <span class="s s-Atom">similar</span> <span class="s s-Atom">instructions</span> <span class="s s-Atom">in</span> <span class="nv">SUPERNI</span> <span class="p">(</span><span class="s s-Atom">left</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="mi">252</span> <span class="nb">user</span><span class="o">-</span><span class="s s-Atom">oriented</span> <span class="nf">instructions</span> <span class="p">(</span><span class="s s-Atom">right</span><span class="p">).</span>

<span class="s s-Atom">##</span> <span class="nv">A</span><span class="p">.</span> <span class="mi">2</span> <span class="nv">Querying</span> <span class="s s-Atom">the</span> <span class="nv">GPT3</span> <span class="nv">API</span>

<span class="nv">We</span> <span class="s s-Atom">use</span> <span class="s s-Atom">different</span> <span class="s s-Atom">sets</span> <span class="s s-Atom">of</span> <span class="s s-Atom">hyperparameters</span> <span class="s s-Atom">when</span> <span class="s s-Atom">querying</span> <span class="nv">GPT3</span> <span class="nv">API</span> <span class="s s-Atom">for</span> <span class="s s-Atom">different</span> <span class="s s-Atom">purposes</span><span class="p">.</span> <span class="nv">These</span> <span class="s s-Atom">hyperparameters</span> <span class="s s-Atom">are</span> <span class="s s-Atom">found</span> <span class="s s-Atom">to</span> <span class="s s-Atom">work</span> <span class="s s-Atom">well</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="nv">GPT3</span> <span class="nf">model</span> <span class="p">(</span><span class="s2">&quot;davinci&quot;</span> <span class="s s-Atom">engine</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="s s-Atom">the</span> <span class="s s-Atom">other</span> <span class="s s-Atom">instructiontuned</span> <span class="nv">GPT3</span> <span class="s s-Atom">variants</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">listed</span> <span class="s s-Atom">them</span> <span class="s s-Atom">in</span> <span class="nv">Table</span> <span class="mf">4.</span> <span class="nv">OpenAI</span> <span class="s s-Atom">charges</span> <span class="err">$</span><span class="s s-Atom">\</span><span class="err">$</span> <span class="mf">0.02</span><span class="err">$</span> <span class="s s-Atom">per</span> <span class="mi">1000</span> <span class="s s-Atom">tokens</span> <span class="s s-Atom">for</span> <span class="s s-Atom">making</span> <span class="s s-Atom">completion</span> <span class="s s-Atom">request</span> <span class="s s-Atom">to</span> <span class="s s-Atom">the</span> <span class="s2">&quot;davinci&quot;</span> <span class="s s-Atom">engine</span> <span class="s s-Atom">as</span> <span class="s s-Atom">of</span> <span class="nv">December</span><span class="p">,</span> <span class="mf">2022.</span> <span class="nv">The</span> <span class="s s-Atom">generation</span> <span class="s s-Atom">of</span> <span class="s s-Atom">our</span> <span class="s s-Atom">entire</span> <span class="s s-Atom">dataset</span> <span class="s s-Atom">cost</span> <span class="s s-Atom">around</span> <span class="err">$</span><span class="s s-Atom">\</span><span class="err">$</span> <span class="mi">600</span><span class="err">$</span><span class="p">.</span>

<span class="s s-Atom">##</span> <span class="nv">A</span><span class="p">.</span> <span class="mi">3</span> <span class="nv">Finetuning</span> <span class="nv">GPT3</span>

<span class="err">$</span><span class="s s-Atom">\mathrm</span><span class="p">{</span><span class="nv">GPT3</span><span class="p">}</span><span class="k">_</span><span class="p">{</span><span class="s s-Atom">\text</span> <span class="p">{</span><span class="nv">SELF</span><span class="o">-</span><span class="nv">INST</span> <span class="p">}}</span><span class="err">$</span> <span class="s s-Atom">and</span> <span class="s s-Atom">some</span> <span class="s s-Atom">of</span> <span class="s s-Atom">our</span> <span class="s s-Atom">baselines</span> <span class="s s-Atom">are</span> <span class="s s-Atom">finetuned</span> <span class="s s-Atom">from</span> <span class="nv">GPT3</span> <span class="nf">model</span> <span class="p">(</span><span class="s2">&quot;davinci&quot;</span> <span class="s s-Atom">engine</span> <span class="s s-Atom">with</span> <span class="mi">175</span><span class="nv">B</span> <span class="s s-Atom">parameters</span><span class="p">).</span> <span class="nv">We</span> <span class="s s-Atom">conduct</span> <span class="s s-Atom">this</span> <span class="s s-Atom">finetuning</span> <span class="s s-Atom">via</span> <span class="nv">OpenAI</span><span class="s s-Atom">&#39;s finetuning API. ${ }^{12}$ While the details of how the model is finetuned with this API are not currently available (e.g., which parameters are updated, or what</span>

<span class="s s-Atom">[^0]</span>
<span class="s s-Atom">[^0]:    ${ }^{11}$ https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions. jsonl</span>
<span class="s s-Atom">    ${ }^{12}$ See the the details on OpenAI&#39;s</span> <span class="nv">API</span><span class="p">.</span>

<span class="p">|</span> <span class="nv">Experiments</span> <span class="err">$</span><span class="s s-Atom">\downarrow$</span> <span class="p">|</span> <span class="nv">Temp</span><span class="p">.</span> <span class="p">|</span> <span class="nv">Top_P</span> <span class="p">|</span> <span class="nv">Freq</span><span class="p">.</span> <span class="nv">Penalty</span> <span class="p">|</span> <span class="nv">Presence</span> <span class="nv">Penalty</span> <span class="p">|</span> <span class="nv">Beam</span> <span class="nv">Size</span> <span class="p">|</span> <span class="nv">Max</span> <span class="nv">Length</span> <span class="p">|</span> <span class="nv">Stop</span> <span class="nv">Sequences</span> <span class="p">|</span>
<span class="p">|</span> <span class="o">:--</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span> <span class="o">:-</span><span class="s s-Atom">-:</span> <span class="p">|</span>
<span class="p">|</span> <span class="nv">Generating</span> <span class="s s-Atom">instructions</span> <span class="p">|</span> <span class="mf">0.7</span> <span class="p">|</span> <span class="mf">0.5</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">2</span> <span class="p">|</span> <span class="mi">1</span> <span class="p">|</span> <span class="mi">1024</span> <span class="p">|</span> <span class="s2">&quot;in\n&quot;</span><span class="p">,</span> <span class="s2">&quot;in16&quot;</span><span class="p">,</span> <span class="s2">&quot;16.&quot;</span><span class="p">,</span> <span class="s2">&quot;16 .&quot;</span> <span class="p">|</span>
<span class="p">|</span> <span class="nv">Identifying</span> <span class="s s-Atom">clf</span><span class="p">.</span> <span class="s s-Atom">tasks</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">1</span> <span class="p">|</span> <span class="mi">3</span> <span class="p">|</span> <span class="s2">&quot;in&quot;</span><span class="p">,</span> <span class="s2">&quot;Task:&quot;</span> <span class="p">|</span>
<span class="p">|</span> <span class="nv">Generating</span> <span class="s s-Atom">instances</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mf">1.5</span> <span class="p">|</span> <span class="mi">1</span> <span class="p">|</span> <span class="mi">300</span> <span class="p">|</span> <span class="s2">&quot;Task:&quot;</span> <span class="p">|</span>
<span class="p">|</span> <span class="nv">Evaluating</span> <span class="s s-Atom">models</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">0</span> <span class="p">|</span> <span class="mi">1024</span> <span class="p">|</span> <span class="nv">None</span> <span class="p">(</span><span class="s s-Atom">default</span><span class="p">)</span> <span class="p">|</span>

<span class="nv">Table</span> <span class="mi">4</span><span class="o">:</span> <span class="nv">Hyper</span><span class="o">-</span><span class="s s-Atom">parameters</span> <span class="s s-Atom">for</span> <span class="s s-Atom">querying</span> <span class="nv">OpenAI</span> <span class="nv">API</span> <span class="s s-Atom">in</span> <span class="s s-Atom">different</span> <span class="s s-Atom">experiments</span><span class="p">.</span>
<span class="s s-Atom">the</span> <span class="s s-Atom">optimizer</span> <span class="o">is</span><span class="p">),</span> <span class="s s-Atom">we</span> <span class="s s-Atom">tune</span> <span class="s s-Atom">all</span> <span class="s s-Atom">our</span> <span class="s s-Atom">models</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="s s-Atom">default</span> <span class="s s-Atom">hyperparameters</span> <span class="s s-Atom">of</span> <span class="s s-Atom">this</span> <span class="nv">API</span> <span class="s s-Atom">so</span> <span class="s s-Atom">that</span> <span class="s s-Atom">the</span> <span class="s s-Atom">results</span> <span class="s s-Atom">are</span> <span class="s s-Atom">comparable</span><span class="p">.</span> <span class="nv">We</span> <span class="s s-Atom">only</span> <span class="s s-Atom">set</span> <span class="s s-Atom">the</span> <span class="s2">&quot;prompt_loss_weight&quot;</span> <span class="s s-Atom">to</span> <span class="mi">0</span> <span class="s s-Atom">since</span> <span class="s s-Atom">we</span> <span class="s s-Atom">find</span> <span class="s s-Atom">this</span> <span class="s s-Atom">works</span> <span class="s s-Atom">better</span> <span class="s s-Atom">in</span> <span class="s s-Atom">our</span> <span class="s s-Atom">case</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">every</span> <span class="s s-Atom">finetuning</span> <span class="s s-Atom">experiment</span> <span class="o">is</span> <span class="s s-Atom">trained</span> <span class="s s-Atom">for</span> <span class="s s-Atom">two</span> <span class="s s-Atom">epochs</span> <span class="s s-Atom">to</span> <span class="s s-Atom">avoid</span> <span class="s s-Atom">overfitting</span> <span class="s s-Atom">the</span> <span class="s s-Atom">training</span> <span class="s s-Atom">tasks</span><span class="p">.</span> <span class="nv">Finetuning</span> <span class="o">is</span> <span class="s s-Atom">charged</span> <span class="s s-Atom">based</span> <span class="s s-Atom">on</span> <span class="s s-Atom">the</span> <span class="s s-Atom">number</span> <span class="s s-Atom">of</span> <span class="s s-Atom">tokens</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">training</span> <span class="s s-Atom">file</span><span class="p">.</span> <span class="nv">In</span> <span class="s s-Atom">our</span> <span class="s s-Atom">case</span><span class="p">,</span> <span class="s s-Atom">finetuning</span> <span class="nv">GPT3</span> <span class="err">$</span><span class="p">{</span> <span class="p">}</span><span class="k">_</span><span class="p">{</span><span class="s s-Atom">\text</span> <span class="p">{</span><span class="nv">SELF</span><span class="o">-</span><span class="nv">INST</span> <span class="p">}}</span><span class="err">$</span> <span class="s s-Atom">from</span> <span class="s s-Atom">the</span> <span class="nv">GPT3</span> <span class="s s-Atom">model</span> <span class="s s-Atom">on</span> <span class="s s-Atom">the</span> <span class="s s-Atom">entire</span> <span class="s s-Atom">generated</span> <span class="s s-Atom">data</span> <span class="s s-Atom">cost</span> <span class="err">$</span><span class="s s-Atom">\</span><span class="err">$</span> <span class="mi">338</span><span class="err">$</span><span class="p">.</span>

<span class="s s-Atom">#</span> <span class="nv">A</span><span class="p">.</span> <span class="mi">4</span> <span class="nv">Prompting</span> <span class="nv">Templates</span> <span class="s s-Atom">for</span> <span class="nv">Data</span> <span class="nv">Generation</span> 

<span class="nv">SELF</span><span class="o">-</span><span class="nv">INSTRUCT</span> <span class="s s-Atom">relies</span> <span class="s s-Atom">on</span> <span class="s s-Atom">a</span> <span class="s s-Atom">number</span> <span class="s s-Atom">of</span> <span class="s s-Atom">prompting</span> <span class="s s-Atom">templates</span> <span class="s s-Atom">in</span> <span class="s s-Atom">order</span> <span class="s s-Atom">to</span> <span class="s s-Atom">elicit</span> <span class="s s-Atom">the</span> <span class="s s-Atom">generation</span> <span class="s s-Atom">from</span> <span class="s s-Atom">language</span> <span class="s s-Atom">models</span><span class="p">.</span> <span class="nv">Here</span> <span class="s s-Atom">we</span> <span class="s s-Atom">provide</span> <span class="s s-Atom">our</span> <span class="s s-Atom">four</span> <span class="s s-Atom">templates</span> <span class="s s-Atom">for</span> <span class="s s-Atom">generating</span> <span class="s s-Atom">the</span> <span class="nf">instruction</span> <span class="p">(</span><span class="nv">Table</span> <span class="mi">5</span><span class="p">),</span> <span class="s s-Atom">classifying</span> <span class="s s-Atom">whether</span> <span class="s s-Atom">an</span> <span class="s s-Atom">instruction</span> <span class="s s-Atom">represents</span> <span class="s s-Atom">a</span> <span class="s s-Atom">classification</span> <span class="s s-Atom">task</span> <span class="s s-Atom">or</span> <span class="o">not</span> <span class="p">(</span><span class="nv">Table</span> <span class="mi">6</span><span class="p">),</span> <span class="s s-Atom">generating</span> <span class="s s-Atom">non</span><span class="o">-</span><span class="s s-Atom">classification</span> <span class="s s-Atom">instances</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="s s-Atom">input</span><span class="o">-</span><span class="s s-Atom">first</span> <span class="nf">approach</span> <span class="p">(</span><span class="nv">Table</span> <span class="mi">7</span><span class="p">),</span> <span class="s s-Atom">and</span> <span class="s s-Atom">generating</span> <span class="s s-Atom">classification</span> <span class="s s-Atom">instances</span> <span class="s s-Atom">with</span> <span class="s s-Atom">the</span> <span class="s s-Atom">output</span><span class="o">-</span><span class="s s-Atom">first</span> <span class="nf">approach</span> <span class="p">(</span><span class="nv">Table</span> <span class="mi">8</span><span class="p">).</span>
</code></pre></div>

<p>Come up with a series of tasks:
Task 1: {instruction for existing task 1}
Task 2: {instruction for existing task 2}
Task 3: {instruction for existing task 3}
Task 4: {instruction for existing task 4}
Task 5: {instruction for existing task 5}
Task 6: {instruction for existing task 6}
Task 7: {instruction for existing task 7}
Task 8: {instruction for existing task 8}
Task 9:</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Table</span><span class="w"> </span><span class="mi">5</span>:<span class="w"> </span><span class="nv">Prompt</span><span class="w"> </span><span class="nv">used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">generating</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">instructions</span>.<span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="nv">existing</span><span class="w"> </span><span class="nv">instructions</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">randomly</span><span class="w"> </span><span class="nv">sampled</span><span class="w"> </span><span class="nv">from</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">task</span><span class="w"> </span><span class="nv">pool</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">in</span><span class="o">-</span><span class="nv">context</span><span class="w"> </span><span class="nv">demonstration</span>.<span class="w"> </span><span class="nv">The</span><span class="w"> </span><span class="nv">model</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">allowed</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">generate</span><span class="w"> </span><span class="nv">instructions</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">tasks</span>,<span class="w"> </span><span class="k">until</span><span class="w"> </span><span class="nv">it</span><span class="w"> </span><span class="nv">stops</span><span class="w"> </span><span class="nv">its</span><span class="w"> </span><span class="nv">generation</span>,<span class="w"> </span><span class="nv">reaches</span><span class="w"> </span><span class="nv">its</span><span class="w"> </span><span class="nv">length</span><span class="w"> </span><span class="nv">limit</span><span class="w"> </span><span class="nv">or</span><span class="w"> </span><span class="nv">generates</span><span class="w"> </span><span class="s2">&quot;Task 16&quot;</span><span class="w"> </span><span class="nv">tokens</span>.
</code></pre></div>

<p>Can the following task be regarded as a classification task with finite output labels?
Task: Given my personality and the job, tell me if I would be suitable.
Is it classification? Yes
Task: Give me an example of a time when you had to use your sense of humor.
Is it classification? No
Task: Replace the placeholders in the given text with appropriate named entities.
Is it classification? No
Task: Fact checking - tell me if the statement is true, false, or unknown, based on your
knowledge and common sense.
Is it classification? Yes
Task: Return the SSN number for the person.
Is it classification? No
Task: Detect if the Reddit thread contains hate speech.
Is it classification? Yes
Task: Analyze the sentences below to identify biases.
Is it classification? No
Task: Select the longest sentence in terms of the number of words in the paragraph, output
the sentence index.
Is it classification? Yes
Task: Find out the toxic word or phrase in the sentence.
Is it classification? No
Task: Rank these countries by their population.
Is it classification? No
Task: You are provided with a news article, and you need to identify all the categories that
this article belongs to. Possible categories include: Music, Sports, Politics, Tech, Finance,
Basketball, Soccer, Tennis, Entertainment, Digital Game, World News. Output its categories one
by one, seperated by comma.
Is it classification? Yes
Task: Given the name of an exercise, explain how to do it.
Is it classification? No
Task: Select the oldest person from the list.
Is it classification? Yes
Task: Find the four smallest perfect numbers.
Is it classification? No
Task: Does the information in the document supports the claim? You can answer "Support" or
"Unsupport".
Is it classification? Yes
Task: Create a detailed budget for the given hypothetical trip.
Is it classification? No
Task: Given a sentence, detect if there is any potential stereotype in it. If so, you should
explain the stereotype. Else, output no.
Is it classification? No</p>
<div class="codehilite"><pre><span></span><code><span class="n">Task</span><span class="o">:</span><span class="w"> </span><span class="n">To</span><span class="w"> </span><span class="n">make</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">pairs</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">same</span><span class="w"> </span><span class="n">analogy</span><span class="o">,</span><span class="w"> </span><span class="n">write</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">fourth</span><span class="w"> </span><span class="n">word</span><span class="o">.</span>
<span class="n">Is</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">classification</span><span class="o">?</span><span class="w"> </span><span class="n">No</span>
<span class="n">Task</span><span class="o">:</span><span class="w"> </span><span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="kd">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">numbers</span><span class="o">,</span><span class="w"> </span><span class="n">find</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">possible</span><span class="w"> </span><span class="n">subsets</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">number</span><span class="o">.</span>
<span class="n">Is</span><span class="w"> </span><span class="n">it</span><span class="w"> </span><span class="n">classification</span><span class="o">?</span><span class="w"> </span><span class="n">No</span>
<span class="n">Task</span><span class="o">:</span><span class="w"> </span><span class="o">\{</span><span class="n">instruction</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="n">task</span><span class="o">\}</span>
<span class="n">Table</span><span class="w"> </span><span class="mi">6</span><span class="o">:</span><span class="w"> </span><span class="n">Prompt</span><span class="w"> </span><span class="n">used</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">classifying</span><span class="w"> </span><span class="n">whether</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="n">instruction</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">classification</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">not</span><span class="o">.</span>
</code></pre></div>

<p>Come up with examples for the following tasks. Try to generate multiple examples when possible.
If the task doesn't require additional input, you can generate the output directly.
Task: Which exercises are best for reducing belly fat at home?
Output:
- Lying Leg Raises
- Leg In And Out
- Plank
- Side Plank
- Sit-ups
```</p>
<p>Task: Extract all the country names in the paragraph, list them separated by commas. Example 1
Paragraph: Dr. No is the sixth novel by the English author Ian Fleming to feature his British Secret Service agent James Bond. Written at Fleming's Goldeneye estate in Jamaica, it was first published in the United Kingdom by Jonathan Cape in 1958. In the novel Bond looks into the disappearance in Jamaica of two fellow MI6 operatives who had been investigating Doctor No. Bond travels to No's Caribbean island and meets Honeychile Rider, who is there to collect shells. They are captured and taken to a luxurious facility carved into a mountain. The character of Doctor No, the son of a German missionary and a Chinese woman, was influenced by Gaz Rohmer's Fu Manchu stories. Dr. No was the first of Fleming's novels to face widespread negative reviews in Britain, but it was received more favourably in the United States. Output: English, British, Jamaica, the United Kingdom, German, Chinese, Britain, the United States.</p>
<p>Task: Converting 85 F to Celsius.
Output: $85^{\circ} \mathrm{F}=29.44^{\circ} \mathrm{C}$
Task: Sort the given list ascendingly.
Example 1
List: $[10,92,2,5,-4,92,5,101]$
Output: $[-4,2,5,5,10,92,92,101]$
Example 2
Input 2 - List: $[9.99,10,-5,-1000,5 \mathrm{e} 6,999]$
Output: $[-1000,-5,9.99,10,999,5 \mathrm{e} 6]$
Task: Suggest a better and more professional rephrasing of the following sentence. Example 1
Sentence: This house is surprisingly not constructed very well, and you probably need more money to fix it after you buy it. If you ask me, I would suggest you to consider other candidates.
Output: This house does not seem to be constructed well, so you may need to spend more money to fix it after you purchase it. I would suggest that you look at other properties. Example 2
Sentence: Just so you know, we did an experiment last week and found really surprising results - language model can improve itself!
Output: Our experiments last week demonstrated surprising results, proving that the language model can improve itself.</p>
<p>Task: Turn down a job offer by sending an email to a recruiter explaining the reason. Output: Hi [Recruiter],
Thank you so much for the generous offer to join your team. As we discussed, I've admired the company for a number of years, and am a proud endorser of its products. However, after further consideration of where I currently am in my career, I've decided to accept an offer at another company.
I would love to stay in touch with you and have already started following you on [Social Media Platform]. Again, thank you so much for your time and consideration.
Thanks again,
[Your Name]
Task: {Instruction for the target task}
Table 7: Prompt used for the input-first approach of instance generation. The model is prompted to generate the instance first, and then generate the corresponding output. For instructions that don't require additional input, the output is allowed to be generated directly.</p>
<p>Given the classification task definition and the class labels, generate an input that corresponds to each of the class labels. If the task doesn't require input, just generate the correct class label.</p>
<p>Task: Classify the sentiment of the sentence into positive, negative, or mixed.
Class label: mixed
Sentence: I enjoy the flavor of the restaurant but their service is too slow.
Class label: Positive
Sentence: I had a great day today. The weather was beautiful and I spent time with friends.
Class label: Negative
Sentence: I was really disappointed by the latest superhero movie. I would not recommend it.
Task: Given a dialogue, classify whether the user is satisfied with the service. You should respond with "Satisfied" or "Unsatisfied".
Class label: Satisfied
Dialogue:</p>
<ul>
<li>Agent: Thank you for your feedback. We will work to improve our service in the future.</li>
<li>Customer: I am happy with the service you provided. Thank you for your help.</li>
</ul>
<p>Class label: Unsatisfied
Dialogue:</p>
<ul>
<li>Agent: Sorry that we will cancel your order. You will get a refund within 7 business days.</li>
<li>Customer: oh that takes too long. I want you to take quicker action on this.</li>
</ul>
<p>Task: Given a political opinion, classify whether the speaker is a Democrat or Republican. Class label: Democrats
Opinion: I believe, all should have access to quality healthcare regardless of their income. Class label: Republicans
Opinion: I believe that people should be able to keep more of their hard-earned money and should not be taxed at high rates.</p>
<p>Task: Tell me if the following email is a promotion email or not.
Class label: Promotion
Email: Check out our amazing new sale! We've got discounts on all of your favorite products. Class label: Not Promotion
Email: We hope you are doing well. Let us know if you need any help.
Task: Detect if the Reddit thread contains hate speech.
Class label: Hate Speech
Thread: All people of color are stupid and should not be allowed to vote.
Class label: Not Hate Speech
Thread: The best way to cook a steak on the grill.
Task: Does the document supports the claim? Answer with "Support" or "Unsupport".
Class label: Unsupport
Document: After a record-breaking run that saw mortgage rates plunge to all-time lows and home prices soar to new highs, the U.S. housing market finally is slowing. While demand and price gains are cooling, any correction is likely to be a modest one, housing economists and analysts say. No one expects price drops on the scale of the declines experienced during the Great Recession.
Claim: The US housing market is going to crash soon.
Class label: Support
Document: The U.S. housing market is showing signs of strain, with home sales and prices slowing in many areas. Mortgage rates have risen sharply in recent months, and the number of homes for sale is increasing. This could be the beginning of a larger downturn, with some economists predicting a potential housing crash in the near future.
Claim: The US housing market is going to crash soon.</p>
<p>Task: Which of the following is not an input type? (a) number (b) date (c) phone number (d) email address (e) all of these are valid inputs.
Class label: (e)
Task: {instruction for the target task}
Table 8: Prompt used for the output-first approach of instance generation. The model is prompted to generate the class label first, and then generate the corresponding input. This prompt is used for generating the instances for classification tasks.</p>
<h1>B Human Evaluation Details for Following the User-oriented Instructions</h1>
<h2>B. 1 Human Evaluation Setup</h2>
<p>Here we provide more details for the human evaluation described in $\S 4.4$ for rating the models' responses to the 252 user-oriented instructions. To ensure faithful and reliable evaluation, we asked two authors of these instructions (and of this paper) to judge model predictions. These two evaluators coordinated the standards for the 4-level rating system before starting annotation and then each of them rated all the instances independently. They were presented with the instruction, instance input, target output (as a reference), and model responses. Model responses are listed in random order, with all the model information anonymized. Figure 9 provides a screenshot of the annotation interface. The reported performance in this paper is based on the results from one of the evaluators, and the trends from the other evaluator's results are the same.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Human evaluation in done using a Google sheet, with predictions from different models present in random order and the model information being anonymized. Our expert evaluators are required to read the instruction and input, refer to the target, and then select the rating for the model's response from $\mathrm{A} / \mathrm{B} / \mathrm{C} / \mathrm{D}$, corresponding to the 4 levels described in $\S 4.4$.</p>
<h2>B. 2 Human Evaluation Agreement</h2>
<p>To measure how reliable our human evaluation is, we calculate the inner-rater agreement between our two evaluators.</p>
<p>We first report Cohen's $\kappa$, which is commonly used to measure inter-rater agreement for categorical items. When calculating this, we treat the 4-level rating (A-D) as a categorical variable, leading to a $\kappa$ of 0.58 , which is a moderate agreement according to common practice. ${ }^{13}$ Furthermore, we also calculate the agreement of our evaluators on classifying acceptable responses ((A or B) vs. (C or D)), with a final $\kappa$ of 0.75 , indicating substantial agreement.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>We also compute the Spearman correlation coefficient $\rho$ between the ratings of our two evaluators by treating the rating as an ordinal variable $(\mathrm{A}&gt;\mathrm{B}&gt;\mathrm{C}&gt;\mathrm{D})$. The final coefficient is $\rho=0.81$, indicating a high correlation between the two evaluators.</p>
<h1>B. 3 Example Predictions from GPT3 $3_{\text {SELF-INST }}$</h1>
<p>We present a selection of user-oriented tasks, the corresponding GPT3 $3_{\text {SELF-INST }}$-produced responses and annotator ratings in Table 9. We see that even for responses rated as level C, the model demonstrates extensive steps in solving the task, even though its final output is incorrect.</p>
<table>
<thead>
<tr>
<th>Instruction + Instance Input</th>
<th>Target Response</th>
<th>GPT3-5ssz-Insr Response</th>
<th>Rating</th>
</tr>
</thead>
<tbody>
<tr>
<td>Instruction: Give students tips on how to keep their nerves under control during class presentations.</td>
<td>Everyone gets a little nervous when speaking in front of a group. That's normal. But the more preparation you've done—meaning plenty of researching, organizing, and rehearsing—the more confident you'll be. Preparation is the key. And if you make a mistake or stumble over your words, just regroup and keep going. Nobody's perfect, and nobody expects you to be.</td>
<td>- Practice your presentation in front of friends and family. - Don't drink too much caffeine before the presentation. - Take deep breaths before you start speaking. - If you feel nervous, smile. - Remember that everyone in the audience is rooting for you.</td>
<td>A</td>
</tr>
<tr>
<td>Instruction: Make a list of the pros and cons of the given decision. Input: Implementing a Remote Working Policy</td>
<td>Pros: - Allowing employees to work from home can reduce their stressful commutes and increase their productivity. - Remote working provides greater flexibility, particularly for working parents and caregivers who have other responsibilities. - ...(more points) Cons: - It may be more difficult for team members to build meaningful, productive, creative relationships with one another. - ...(more points)</td>
<td>Pros: - Employees can work from home and save on commuting costs. - Employees can spend more time with their families. Cons: - Employees may not be as productive as they would be in the office. - Employees may not be as motivated to work.</td>
<td>A</td>
</tr>
<tr>
<td>Instruction: A user story is an informal, general explanation of a software feature written from the perspective of the end-user or customer. Write a user story for a given software. Input: Small</td>
<td>As a user, I want to be able to recover the password to my account, so that I will be able to access my account in case I forgot the password.</td>
<td>As a user, I want to be able to send emails to my friends and family. I want to be able to attach files to my emails. I want to be able to search for emails in my inbox.</td>
<td>A</td>
</tr>
<tr>
<td>Instruction: A color description has been provided. Find the CSS code associated with that color. Input: A light red color with a medium light shade of pink</td>
<td>#DB7093 ()</td>
<td>#ff66cc ()</td>
<td>B</td>
</tr>
<tr>
<td>Instruction: Someone gives you some information about where they want to go and what they enjoy seeing and doing. Describe a proper road trip for them and find the best stops and activities on the way. Input: I'm looking for a west coast road trip. My goal is to start near San Diego and travel to Los Angeles.</td>
<td>Begin near the city of San Diego and make the first stop in coastal La Jolla. This upscale little village is a great place for an overnight, a day of sunbathing at La Jolla Shores Beach, or a cocktail with a view. Just 20 minutes north, stop into beachy Encinitas to window shop the boutiques or sample fish tacos. Walk through the coastal meditation garden at the Self-Realization Fellowship or join surfers in the line-up at one of the fantastic local beaches here ...(more ideas)</td>
<td>You should start your trip in San Diego, California. You can visit the San Diego Zoo, which is one of the best zoos in the world. Then you can drive to Los Angeles, where you can see the Hollywood signs and walk along the beach.</td>
<td>B</td>
</tr>
<tr>
<td>Instruction: Give some examples of what people usually say in the given social situation. Input: when someone arrives safely</td>
<td>- "Glad you made it safe and sound." - "Good to see you got here unscathed." - "So, bulletproof vests actually work!"</td>
<td>Thank God, I made it.</td>
<td>B</td>
</tr>
<tr>
<td>Instruction: You are given a sentence in first-order logic. Translate it into natural language. Input: 7z7Q[addier(z) $\rightarrow$ general(z, g)]</td>
<td>There is someone (z) such that if he is a soldier, then he is general of everyone.</td>
<td>There exists a soldier such that for every general, he is a general.</td>
<td>C</td>
</tr>
<tr>
<td>Instruction: Make a questionnaire to help hotel guests write hotel reviews.</td>
<td>- Your overall rating of this hotel: - Summarize your visit or highlight an interesting detail: - ...(more questions)</td>
<td>Question: How would you rate the service at the front desk? Answer: Excellent, Good, Average, Poor</td>
<td>C</td>
</tr>
<tr>
<td>Instruction: Design an outline for a blog post based on the given information and list the sections accordingly. Input: This blog post is going to about making a list of last-minute gift ideas. Also, the tone of the post is going to be relaxed and casual.</td>
<td>- Section: Movie tickets - Section: A fun game console - Section: Personalized items with photos/artwork - ...(more sections) - Takeaway: Don't stress about out running out of time to buy, make a gift.</td>
<td>- Introduction - List of Gift Ideas - Conclusion</td>
<td>C</td>
</tr>
<tr>
<td>Instruction: Write a Jira ticket for the given task. Input: New Employee onboarding</td>
<td>Title: Please help our new employee get settled. Prepare a desk, chair, and computer for them to use. Create their company account, email, and temporary password. Grant access to company documents.</td>
<td>Hi [Manager], I'm writing to you because I have a question about the new employee onboarding process. I've been working here for a few months now, and I'm still not sure how it works. Could you please explain it to me?</td>
<td>D</td>
</tr>
<tr>
<td>Instruction: Create alliterations by finding synonyms for words in the given sentence. Input: David wears a hat everyday.</td>
<td>David does a derby daily.</td>
<td>David wears a hat every day.</td>
<td>D</td>
</tr>
</tbody>
</table>
<p>Table 9: Examples in the user-oriented instructions dataset (§4.4) and predictions from GPT3-5ssz-Insr. The right column indicates one of the four quality ratings assigned to the model's response, with "A" indicating "valid and satisfying" responses (highest) and "D" indicating "improved or invalid response" (lowest).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{13}$ https://en.wikipedia.org/wiki/Cohen\%27s_kappa&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ More concretely, we regard tasks that have a small limited output label space as classification tasks.
${ }^{5}$ In this work, we use a fixed set of seed tasks for prompting the instance generation, and thus only generate a small number of instances per task in one round. Future work can use randomly sampled tasks to prompt the model to generate a larger number of instances in multiple rounds.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>