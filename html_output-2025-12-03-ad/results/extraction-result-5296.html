<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5296 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5296</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5296</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-108.html">extraction-schema-108</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-f9d2434d6290d8800e4af08352fc88fac40a5e04</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f9d2434d6290d8800e4af08352fc88fac40a5e04" target="_blank">MatChat: A large language model and application service platform for materials science</a></p>
                <p><strong>Paper Venue:</strong> Chinese Physics B</p>
                <p><strong>Paper TL;DR:</strong> This study establishes a robust foundation for collaborative innovation in the integration of generative AI in materials science by harnessing the power of the LLaMA2-7B model and enhancing it through a learning process that incorporates 13878 pieces of structured material knowledge data.</p>
                <p><strong>Paper Abstract:</strong> The prediction of chemical synthesis pathways plays a pivotal role in materials science research. Challenges, such as the complexity of synthesis pathways and the lack of comprehensive datasets, currently hinder our ability to predict these chemical processes accurately. However, recent advancements in generative artificial intelligence (GAI), including automated text generation and question–answering systems, coupled with fine-tuning techniques, have facilitated the deployment of large-scale AI models tailored to specific domains. In this study, we harness the power of the LLaMA2-7B model and enhance it through a learning process that incorporates 13878 pieces of structured material knowledge data. This specialized AI model, named MatChat, focuses on predicting inorganic material synthesis pathways. MatChat exhibits remarkable proficiency in generating and reasoning with knowledge in materials science. Although MatChat requires further refinement to meet the diverse material design needs, this research undeniably highlights its impressive reasoning capabilities and innovative potential in materials science. MatChat is now accessible online and open for use, with both the model and its application framework available as open source. This study establishes a robust foundation for collaborative innovation in the integration of generative AI in materials science.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5296.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5296.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MatChat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MatChat (fine-tuned LLaMA2-7B for materials synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specialized large language model created by fine-tuning LLaMA2-7B on a curated dataset of inorganic material synthesis procedures to generate synthesis pathways, reaction equations, and conditions (temperature, time, environment).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA2-7B (fine-tuned as MatChat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (decoder-only / autoregressive) fine-tuned for instruction following</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on 13,878 high-confidence inorganic solid-phase synthesis pathway descriptions (extracted from an initial pool of 35,675 extracted synthesis procedures from scientific literature). Instruction-format Q&A pairs mapping synthesis queries (chemical formulas) to detailed textual answers including precursors, reaction equations, temperatures, times, and environment.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science — inorganic material synthesis pathway prediction and recipe generation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Supervised fine-tuning of LLaMA2-7B on curated instruction-response pairs plus reinforcement learning with human feedback mentioned; parameter-efficient fine-tuning techniques (LoRA, adapters, prefix-tuning) and optionally full/partial fine-tuning/FSDP for multi-GPU were employed in development/deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Human-readable textual synthesis instructions containing chemical formulas, stoichiometric precursor lists, reaction equations, processing steps, temperatures, times, and environment/device suggestions (not SMILES/SELFIES or graph representations).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative and domain-focused metrics grouped under 'SAU' (Safety, Accuracy, Usability); also discussion of BLEU/ROUGE as common NLP metrics but primary evaluation was domain-specific qualitative comparison of raw-material correctness and usability against literature examples.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td>Training data derived from 'Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature' (Wang et al., Sci Data 2022) — 13,878 curated entries used for fine-tuning; evaluation used literature test examples (e.g., compounds from refs. [28],[29]).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>MatChat produced detailed, literature-aligned synthesis recipes (precursors, reaction equations, temperatures, times) and outperformed general-purpose LLM baselines in accuracy and usability for the tested inorganic compounds; it demonstrated generative inference for formulas both present and absent in the training set, but the authors note inconsistencies and the need for further refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared against general-purpose LLMs (ChatGPT, Ernie Bot, Spark Desk, ChatGLM) as baselines: MatChat gave more accurate and actionable precursor lists and synthesis conditions for the evaluated inorganic compounds; no direct comparison to traditional cheminformatics generative models (e.g., SMILES-based generators) was reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Limited to inorganic synthesis Q&A format and English-only outputs; accuracy still imperfect and requires refinement; training data size modest (13,878 entries) and limited coverage; outputs are textual instructions (no structured molecular representations like SMILES), one-epoch fine-tuning reported, potential inconsistencies with training-set specifics noted, and safety/usability require further validation and integration with databases (Atomly, OQMD) before adoption in lab settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MatChat: A large language model and application service platform for materials science', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5296.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5296.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo used as baseline in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used general-purpose autoregressive large language model used here as a baseline to answer inorganic synthesis queries and compared against MatChat.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (autoregressive / decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Reported in paper: 175B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as a baseline for inorganic materials synthesis question-answering (materials science) in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting a general-purpose LLM (zero-shot or few-shot prompting) to produce synthesis instructions</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Textual synthesis instructions (precursor lists, high-level steps); in experiments produced some incorrect or vague precursor information for tested compounds.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Evaluated qualitatively via SAU (Safety, Accuracy, Usability) comparisons against literature and MatChat outputs; no formal numerical benchmark reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Provided answers for tested compounds but in at least one evaluated case included incorrect precursor materials compared to the literature and was less usable/actionable than MatChat for inorganic synthesis queries.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Served as a general LLM baseline; underperformed the domain-fine-tuned MatChat in accuracy and usability for the specific inorganic synthesis queries tested.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>As a general model it sometimes produced incorrect or vague raw-material suggestions for specialized inorganic synthesis tasks; model training specifics not disclosed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MatChat: A large language model and application service platform for materials science', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5296.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5296.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ernie Bot (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ernie Bot (Ernie 3.0 Titan, baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large Chinese pre-trained language model cited and used as a baseline in experiments; in the reported comparisons it often failed to provide usable synthesis answers for the tested queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Ernie 3.0 Titan (Ernie Bot)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (pretrained large language model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Reported in paper: 260B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as a baseline for inorganic materials synthesis question-answering in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting / using model as-is (no domain fine-tuning reported in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Textual synthesis responses (for some queries no relevant answer was provided)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative SAU assessment against literature examples</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Failed to furnish relevant answers for some evaluated inorganic compounds and was less useful than MatChat on the tested examples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared as a general LLM baseline; performed worse than MatChat on domain-specific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Did not provide relevant answers for certain specialized inorganic synthesis queries in the experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MatChat: A large language model and application service platform for materials science', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5296.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5296.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spark Desk (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spark Desk (unnamed internal/closed model used as a baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose conversational AI model used as an experimental baseline; model details were not disclosed in the paper but it produced some plausible answers for certain tested compounds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Spark Desk</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as a baseline for inorganic materials synthesis question-answering in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting the service to answer synthesis queries (no fine-tuning reported)</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Textual synthesis instructions (in some cases suggested oxides for element sources; for one tested compound suggested oxides but literature used H3BO3 for B)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative SAU assessment versus literature examples</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Provided answers but with some mismatches to literature (e.g., suggested oxides when literature used other precursors); overall less accurate/actionable than MatChat for the evaluated cases.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Performed better than some baselines on certain superficial aspects but still inferior to MatChat in closeness to literature precursors and usability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Model provenance and details not disclosed; produced partially incorrect precursor suggestions for specialized inorganic synthesis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MatChat: A large language model and application service platform for materials science', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5296.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5296.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate, design, or synthesize novel chemical compounds for specific applications, including details on the model, application, generation method, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGLM (GLM-based conversational model used as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A smaller GLM-based conversational model used as a baseline; in the reported comparisons it produced vague or incomplete raw-material information for the tested inorganic synthesis queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (GLM family, autoregressive/seq2seq hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Reported in paper: 6B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as a baseline for inorganic materials synthesis question-answering</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompting the model (no domain fine-tuning reported in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>output_representation</strong></td>
                            <td>Textual responses (vague element/compound suggestions; lacked practical guidance in some cases)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Qualitative SAU assessment</td>
                        </tr>
                        <tr>
                            <td><strong>benchmarks_or_datasets</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Provided answers but lacked specificity and practical guidance for some evaluated inorganic compounds compared to MatChat.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Underperformed the domain-fine-tuned MatChat in accuracy and usability for the tested synthesis queries.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Produced vague raw-material information and insufficiently actionable instructions for specialized inorganic synthesis queries in the evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'MatChat: A large language model and application service platform for materials science', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature <em>(Rating: 2)</em></li>
                <li>Matscibert: A materials domain language model for text mining and information extraction <em>(Rating: 1)</em></li>
                <li>Huatuogpt, towards taming language model to be a doctor <em>(Rating: 1)</em></li>
                <li>Llama 2: Open foundation and fine-tuned chat models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5296",
    "paper_id": "paper-f9d2434d6290d8800e4af08352fc88fac40a5e04",
    "extraction_schema_id": "extraction-schema-108",
    "extracted_data": [
        {
            "name_short": "MatChat",
            "name_full": "MatChat (fine-tuned LLaMA2-7B for materials synthesis)",
            "brief_description": "A domain-specialized large language model created by fine-tuning LLaMA2-7B on a curated dataset of inorganic material synthesis procedures to generate synthesis pathways, reaction equations, and conditions (temperature, time, environment).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA2-7B (fine-tuned as MatChat)",
            "model_type": "Transformer (decoder-only / autoregressive) fine-tuned for instruction following",
            "model_size": "7B parameters",
            "training_data": "Fine-tuned on 13,878 high-confidence inorganic solid-phase synthesis pathway descriptions (extracted from an initial pool of 35,675 extracted synthesis procedures from scientific literature). Instruction-format Q&A pairs mapping synthesis queries (chemical formulas) to detailed textual answers including precursors, reaction equations, temperatures, times, and environment.",
            "application_domain": "Materials science — inorganic material synthesis pathway prediction and recipe generation",
            "generation_method": "Supervised fine-tuning of LLaMA2-7B on curated instruction-response pairs plus reinforcement learning with human feedback mentioned; parameter-efficient fine-tuning techniques (LoRA, adapters, prefix-tuning) and optionally full/partial fine-tuning/FSDP for multi-GPU were employed in development/deployment.",
            "output_representation": "Human-readable textual synthesis instructions containing chemical formulas, stoichiometric precursor lists, reaction equations, processing steps, temperatures, times, and environment/device suggestions (not SMILES/SELFIES or graph representations).",
            "evaluation_metrics": "Qualitative and domain-focused metrics grouped under 'SAU' (Safety, Accuracy, Usability); also discussion of BLEU/ROUGE as common NLP metrics but primary evaluation was domain-specific qualitative comparison of raw-material correctness and usability against literature examples.",
            "benchmarks_or_datasets": "Training data derived from 'Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature' (Wang et al., Sci Data 2022) — 13,878 curated entries used for fine-tuning; evaluation used literature test examples (e.g., compounds from refs. [28],[29]).",
            "results_summary": "MatChat produced detailed, literature-aligned synthesis recipes (precursors, reaction equations, temperatures, times) and outperformed general-purpose LLM baselines in accuracy and usability for the tested inorganic compounds; it demonstrated generative inference for formulas both present and absent in the training set, but the authors note inconsistencies and the need for further refinement.",
            "comparison_to_other_methods": "Compared against general-purpose LLMs (ChatGPT, Ernie Bot, Spark Desk, ChatGLM) as baselines: MatChat gave more accurate and actionable precursor lists and synthesis conditions for the evaluated inorganic compounds; no direct comparison to traditional cheminformatics generative models (e.g., SMILES-based generators) was reported.",
            "limitations_or_challenges": "Limited to inorganic synthesis Q&A format and English-only outputs; accuracy still imperfect and requires refinement; training data size modest (13,878 entries) and limited coverage; outputs are textual instructions (no structured molecular representations like SMILES), one-epoch fine-tuning reported, potential inconsistencies with training-set specifics noted, and safety/usability require further validation and integration with databases (Atomly, OQMD) before adoption in lab settings.",
            "uuid": "e5296.0",
            "source_info": {
                "paper_title": "MatChat: A large language model and application service platform for materials science",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "ChatGPT (baseline)",
            "name_full": "ChatGPT (gpt-3.5-turbo used as baseline in experiments)",
            "brief_description": "A widely used general-purpose autoregressive large language model used here as a baseline to answer inorganic synthesis queries and compared against MatChat.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGPT (gpt-3.5-turbo)",
            "model_type": "Transformer (autoregressive / decoder-only)",
            "model_size": "Reported in paper: 175B parameters",
            "training_data": null,
            "application_domain": "Used as a baseline for inorganic materials synthesis question-answering (materials science) in this paper",
            "generation_method": "Prompting a general-purpose LLM (zero-shot or few-shot prompting) to produce synthesis instructions",
            "output_representation": "Textual synthesis instructions (precursor lists, high-level steps); in experiments produced some incorrect or vague precursor information for tested compounds.",
            "evaluation_metrics": "Evaluated qualitatively via SAU (Safety, Accuracy, Usability) comparisons against literature and MatChat outputs; no formal numerical benchmark reported.",
            "benchmarks_or_datasets": null,
            "results_summary": "Provided answers for tested compounds but in at least one evaluated case included incorrect precursor materials compared to the literature and was less usable/actionable than MatChat for inorganic synthesis queries.",
            "comparison_to_other_methods": "Served as a general LLM baseline; underperformed the domain-fine-tuned MatChat in accuracy and usability for the specific inorganic synthesis queries tested.",
            "limitations_or_challenges": "As a general model it sometimes produced incorrect or vague raw-material suggestions for specialized inorganic synthesis tasks; model training specifics not disclosed in this paper.",
            "uuid": "e5296.1",
            "source_info": {
                "paper_title": "MatChat: A large language model and application service platform for materials science",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Ernie Bot (baseline)",
            "name_full": "Ernie Bot (Ernie 3.0 Titan, baseline)",
            "brief_description": "A large Chinese pre-trained language model cited and used as a baseline in experiments; in the reported comparisons it often failed to provide usable synthesis answers for the tested queries.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Ernie 3.0 Titan (Ernie Bot)",
            "model_type": "Transformer (pretrained large language model)",
            "model_size": "Reported in paper: 260B parameters",
            "training_data": null,
            "application_domain": "Used as a baseline for inorganic materials synthesis question-answering in experiments",
            "generation_method": "Prompting / using model as-is (no domain fine-tuning reported in this paper)",
            "output_representation": "Textual synthesis responses (for some queries no relevant answer was provided)",
            "evaluation_metrics": "Qualitative SAU assessment against literature examples",
            "benchmarks_or_datasets": null,
            "results_summary": "Failed to furnish relevant answers for some evaluated inorganic compounds and was less useful than MatChat on the tested examples.",
            "comparison_to_other_methods": "Compared as a general LLM baseline; performed worse than MatChat on domain-specific tasks.",
            "limitations_or_challenges": "Did not provide relevant answers for certain specialized inorganic synthesis queries in the experiments reported.",
            "uuid": "e5296.2",
            "source_info": {
                "paper_title": "MatChat: A large language model and application service platform for materials science",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Spark Desk (baseline)",
            "name_full": "Spark Desk (unnamed internal/closed model used as a baseline)",
            "brief_description": "A general-purpose conversational AI model used as an experimental baseline; model details were not disclosed in the paper but it produced some plausible answers for certain tested compounds.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Spark Desk",
            "model_type": null,
            "model_size": null,
            "training_data": null,
            "application_domain": "Used as a baseline for inorganic materials synthesis question-answering in experiments",
            "generation_method": "Prompting the service to answer synthesis queries (no fine-tuning reported)",
            "output_representation": "Textual synthesis instructions (in some cases suggested oxides for element sources; for one tested compound suggested oxides but literature used H3BO3 for B)",
            "evaluation_metrics": "Qualitative SAU assessment versus literature examples",
            "benchmarks_or_datasets": null,
            "results_summary": "Provided answers but with some mismatches to literature (e.g., suggested oxides when literature used other precursors); overall less accurate/actionable than MatChat for the evaluated cases.",
            "comparison_to_other_methods": "Performed better than some baselines on certain superficial aspects but still inferior to MatChat in closeness to literature precursors and usability.",
            "limitations_or_challenges": "Model provenance and details not disclosed; produced partially incorrect precursor suggestions for specialized inorganic synthesis tasks.",
            "uuid": "e5296.3",
            "source_info": {
                "paper_title": "MatChat: A large language model and application service platform for materials science",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "ChatGLM (baseline)",
            "name_full": "ChatGLM (GLM-based conversational model used as baseline)",
            "brief_description": "A smaller GLM-based conversational model used as a baseline; in the reported comparisons it produced vague or incomplete raw-material information for the tested inorganic synthesis queries.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGLM",
            "model_type": "Transformer (GLM family, autoregressive/seq2seq hybrid)",
            "model_size": "Reported in paper: 6B parameters",
            "training_data": null,
            "application_domain": "Used as a baseline for inorganic materials synthesis question-answering",
            "generation_method": "Prompting the model (no domain fine-tuning reported in this paper)",
            "output_representation": "Textual responses (vague element/compound suggestions; lacked practical guidance in some cases)",
            "evaluation_metrics": "Qualitative SAU assessment",
            "benchmarks_or_datasets": null,
            "results_summary": "Provided answers but lacked specificity and practical guidance for some evaluated inorganic compounds compared to MatChat.",
            "comparison_to_other_methods": "Underperformed the domain-fine-tuned MatChat in accuracy and usability for the tested synthesis queries.",
            "limitations_or_challenges": "Produced vague raw-material information and insufficiently actionable instructions for specialized inorganic synthesis queries in the evaluation.",
            "uuid": "e5296.4",
            "source_info": {
                "paper_title": "MatChat: A large language model and application service platform for materials science",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature",
            "rating": 2
        },
        {
            "paper_title": "Matscibert: A materials domain language model for text mining and information extraction",
            "rating": 1
        },
        {
            "paper_title": "Huatuogpt, towards taming language model to be a doctor",
            "rating": 1
        },
        {
            "paper_title": "Llama 2: Open foundation and fine-tuned chat models",
            "rating": 1
        }
    ],
    "cost": 0.0111075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>MatChat: A Large Language Model and Application Service</h1>
<h2>Platform for Materials Science</h2>
<p>Ziyi Chen ${ }^{1,2, \dagger}$, Fankai Xie ${ }^{3,4,+}$, Meng Wan ${ }^{1, \dagger}$,Yang Yuan ${ }^{1,2}$, Miao Liu ${ }^{3,5,6, <em>}$, Zongguo Wang ${ }^{1,2, </em>}$, Sheng Meng ${ }^{3,5}$, Yangang Wang ${ }^{1,2}$<br>${ }^{1}$ Computer Network Information Center, Chinese Academy of Sciences, Beijing, 100083, China<br>${ }^{2}$ University of Chinese Academy of Sciences, Beijing, 100049, China<br>${ }^{3}$ Institute of Physics, Chinese Academy of Sciences, Beijing 100190, China<br>${ }^{4}$ School of Physical Sciences, University of Chinese Academy of Sciences, Beijing, 100190, China<br>${ }^{5}$ Songshan Lake Materials Laboratory, Dongguan, Guangdong, 523808, China<br>${ }^{6}$ Center of Materials Science and Optoelectronics Engineering, University of Chinese Academy of Sciences, Beijing, 100049, China<br>*Corresponding authors: Miao Liu(mliu@iphy.ac.cn),<br>Zongguo Wang(wangzg@cnic.cn)<br>${ }^{\dagger}$ These authors contributed equally to this work</p>
<h4>Abstract</h4>
<p>The prediction of chemical synthesis pathways plays a pivotal role in materials science research. Challenges, such as the complexity of synthesis pathways and the lack of comprehensive datasets, currently hinder our ability to predict these chemical processes accurately. However, recent advancements in generative artificial intelligence (GAI), including automated text generation and question-answering systems, coupled with fine-tuning techniques, have facilitated the deployment of largescale AI models tailored to specific domains. In this study, we harness the power of the LLaMA2-7B model and enhance it through a learning process that incorporates 13,878 pieces of structured material knowledge data. This specialized AI model, named MatChat, focuses on predicting inorganic material synthesis pathways. MatChat exhibits remarkable proficiency in generating and reasoning with knowledge in materials science. Although MatChat requires further refinement to meet the diverse material design needs, this research undeniably highlights its impressive reasoning capabilities and innovative potential in the field of materials science. MatChat is now accessible online and open for use, with both the model and its application framework available as open source. This study establishes a robust foundation for collaborative innovation in the integration of generative AI in materials science.</p>
<h1>1. Introduction</h1>
<p>At present, Large Language Models (LLMs) have established a robust foundation for various applications. OpenAI's ChatGPT and GPT-4.0 ${ }^{[1]}$, with 175 billion and 18 trillion parameters respectively, clearly represent a new era in the development of artificial intelligence (AI). However, OpenAI has not disclosed the specific details of the training methods and parameters of the model. Tsinghua's GLM base model ${ }^{[2-3]}$ provides a compelling option for natural language processing. It supports both English and Chinese, offering high accuracy, cross-platform compatibility, reproducibility, and fast inference. Baidu's Ernie 3.0 Titan, an evolution of the Ernie series models ${ }^{[4-6]}$ with an impressive 260 billion parameters, stands as the largest Chinese dense pre-training model to date, with great potential for deep language understanding and applications. The LLaMA and LLaMA2 models ${ }^{[7-8]}$, ranging from 7 billion to 70 billion parameters, contribute to the diversity of open-source large language models, catering to various applications. The Ziya-LLaMA-13B pre-training model ${ }^{[9]}$ exhibits robust capabilities across domains such as translation, programming, text classification, information extraction, summarization, copywriting, common sense question answering, and mathematical computation. The outstanding performance of these models offers strong support for various tasks and holds the promise of unlocking potential in other domains.</p>
<p>Fine-tuning open-source large models has emerged as an effective method for tailoring AI capabilities to meet the specific demands of various domains. Currently, fine-tuning techniques have demonstrated considerable success in vertical fields, including healthcare, education, and finance. In the field of healthcare, models like HuatuoGPT ${ }^{[10]}$ and DoctorGLM ${ }^{[11]}$ have been developed to address medical challenges, these models exhibit a high degree of professionalism and offer invaluable insights within the healthcare domain. In the finance sector, notable strides have been made with the XuanYuan ${ }^{[12]}$ model, its application has brought substantial benefits and advancements to financial operations. Similarly, in the education sector, the EduChat ${ }^{[13]}$ model has demonstrated its worth by delivering valuable capabilities tailored to educational contexts. Additionally, the Fengshenbang ${ }^{[14]}$ large model system, a product of the Cognitive Computing and Natural Language Research Center at IDEA Institute, has gained widespread recognition. The Fengshenbang large model system is a Chinese language-centric ecosystem that includes pre-training of large models and fine-tuned applications tailored for specific tasks, benchmarks, and datasets. Its overarching objective is to create a comprehensive, standardized, and user-centric ecosystem.</p>
<p>In recent years, researchers have achieved significant and innovation results in the discovery of new materials ${ }^{[15]}$ and their theoretical interpretation ${ }^{[16]}$ by leveraging the existing database such as Atomly ${ }^{[17-18]}$, OQMD ${ }^{[19]}$, MaterialsProject ${ }^{[20]}$, and others. They have successfully explored the intricate relationships between material structure and properties ${ }^{[21]}$, addressing the challenges posed by the scarcity of materials data through the development of more accuracy artificial intelligence optimization ${ }^{[22]}$ and training methods ${ }^{[23]}$. With the application of large models, researchers in materials science have explored the use of these models to tackle challenges such as the intricate nature of chemical reactions and structures. One notable example is the MatSciBERT ${ }^{[24]}$</p>
<p>model which is derived from BERT ${ }^{[25]}$. MatSciBERT exhibits the capability to automatically extract information from literature, conduct data mining, and construct knowledge graphs, thereby ushering in new possibilities for the application of language models in the field of materials science. To the best of our knowledge, there has been no reported utilization of large language models in material science until now.</p>
<p>To advance the innovative application of large language models in the field of materials science, this study employs a carefully constructed knowledge questionanswering database to explore their potential in materials science. We propose a viable solution for predicting inorganic material chemical synthesis pathways and provide a preliminary demonstration of the feasibility of this approach. To optimize the performance of the large model in answering questions related to material synthesis knowledge, our research adopts the LLaMA2-7B model as a pre-training model. This approach involves a combination of supervised fine-tuning and reinforcement learning, incorporating valuable human feedback to enhance model optimization. The dataset selected for this purpose comprises 35,675 solution-based synthesis processes ${ }^{[26]}$ extracted from scientific papers. Following thorough processing, we obtained a dataset consisting of 13,878 high-confidence synthesis pathway descriptions.</p>
<p>Although the relatively modest model parameters used in this study, result in costeffective training, the model has showcased impressive comprehensive reasoning abilities.</p>
<p>The highlights of this study include two primary aspects. (1). Fine-tuning the LLaMA2-7B pre-training model using the preprocessed dataset of inorganic material synthesis program instruction. (2). Development of a question-answering platform for the materials synthesis large language model, aimed at facilitating work within the field of materials science and providing an accessible and user-friendly dialogue platform. This paper's basic structure comprises the following sections. Section 2 focuses on the details of the model fine-tuning process. In section 3, we explore the construction of the question-answering platform, covering aspects such as architecture design, parallel processing, resource management, and other technologies. Section 4 presents the experimental findings, and section 5 serves as the conclusion of this study.</p>
<h1>2. Fine-tune MatChat Model Methods</h1>
<h3>2.1 Base Model</h3>
<p>LLaMA2, an updated iteration of LLaMA1, has been trained by Hugo's team ${ }^{[8]}$ on a revised combination of publicly available datasets. The pretraining corpus size has been increased by $40 \%$, the model's context length has been doubled, and a groupedquery attention mechanism has been adopted. Variants of LLaMA2 with 7B, 13B, and 70B parameters are being released to the public. Based on the results of the paper, both LLaMA2 7B and 30B models outperform MPT models of equivalent sizes in all categories ${ }^{[8]}$.</p>
<p>The model in our work is fine-tuned based on the open-source large language model, LLaMA2-7B, which has 7 billion parameters, a content length of 4 k , and supports up to 2.0 trillion tokens.</p>
<h1>2.2 Materials Knowledge Data</h1>
<p>The dataset used for fine-tuning the model in this paper is derived from 35,675 solid-phase synthesis processes of inorganic materials extracted from over four million papers. After rigorous screening, deduplication, and cleaning, we obtained a training set consisting of 13,878 highly reliable synthesis pathway descriptions. This dataset was further preprocessed and integrated into an instruction question-answering format, as shown in Figure 1. The prompts involve specific material synthesis method inquiries, and the responses provide the corresponding chemical reactions and synthesis conditions.</p>
<div class="codehilite"><pre><span></span><code>{
    &quot;instruction&quot;: &quot;How to synthesize Li4Ti5O12&quot;,
    &quot;input&quot;: &quot;How to synthesize Li4Ti5O12&quot;,
    &quot;output&quot;: &quot;Li4Ti5O12 can be made from TiO2, and Li2CO3 via solid state
        reaction. The chemical reaction equation is (2 Li2CO3 + 5 TiO2
            == 1 Li4Ti5O12 + 2 CO2). The detailed recipe can be found in
        literature [10.1149/1.1383553].&quot;
}
</code></pre></div>

<p>Figure. 1 The instruction format for the question-answering scenario</p>
<h3>2.3 Training Process</h3>
<p>The model fine-tuning process utilized the following parameters, a learning rate of $10^{-4}$, a batch size of 8 , and one epoch for fine-tuning. All fine-tuning operations were executed on NVIDIA A100 GPUs.</p>
<p>While fine-tuning the LLaMA2 model, we used two methods and respective resource management strategies. Firstly, the "Parameter Efficient Model Fine-Tuning" approach aimed to make fine-tuning economically feasible on a single consumer-grade GPU. This method involved freezing the entire model and adding small learnable parameters or layers, training only a fraction of the model's parameters. Methods like LORA, LLaMA Adapter, and Prefix-tuning were employed, addressing cost, deployment, and avoiding catastrophic forgetting.</p>
<p>Alternatively, the "Full/Partial Parameter Fine-Tuning" method offered flexibility. We could freeze most pre-trained model layers and fine-tune only the task-specific head, add extra fully connected layers, or fine-tune all layers. For larger models, multiple GPUs might be required, especially when a single GPU couldn't accommodate the model.</p>
<p>To tackle multi-GPU training challenges, we used the "Fully Sharded Data Parallel" (FSDP) technique as noted on the GitHub Repository ${ }^{[27]}$. FSDP shards data, model parameters, gradients, and optimizer states across GPUs, saving memory and enabling larger models on the same number of GPUs.</p>
<h1>3. MatChat Platform</h1>
<p>To support researchers in obtaining fast and accurate model inference results, we have developed a set of web-based dialogue service interfaces based on LLaMA2. This section focuses on explaining how to construct these service interfaces, including the associated technical details and implementation methods.</p>
<h3>3.1 Architecture and Method Design</h3>
<p>In the development of the MatChat platform, we employed PyTorch as the core computing framework to handle tasks such as loading, running, and reasoning with large models. For the web service interface, we chose Python Flask to manage both HTTP and WebSocket requests, facilitating seamless integration with PyTorch. SocketIO was implemented for efficient, event-based two-way communication. When users request model reasoning, SocketIO delivers the model's output in real-time, eliminating traditional polling delays. Flask is responsible for handling user HTTP requests, parsing input parameters, and scheduling background model runs.</p>
<p>To ensure rapid user authentication and system stability, we implemented lightweight data storage in Redis for token verification and resource isolation during concurrent usage. Redis, as an in-memory data structure storage, offers fast read and write capabilities, making it suitable for high-concurrency scenarios. Furthermore, Redis-based token verification enhances system security. When a user submits a request, the system queries Redis to validate tokens, thereby enhancing security against potential malicious activity.</p>
<h3>3.2 Concurrency Processing and Resource Management Technologies</h3>
<p>In scenarios with concurrent access from multiple users, efficient resource management becomes crucial. To address resource contention, we implemented a waiting queue based on condition variables. This design offers several advantages as follows:
(1) Automatic entry into waiting state: In situations where resources are occupied, new requests seamlessly transition into the waiting state.
(2) Sequential awakening of queued requests: Upon resource release, requests within the waiting queue are sequentially awakened, allowing them to acquire the resources.
(3) Thread locks for exclusive access: Thread locks guarantee exclusive resource access for a single request at any given time, mitigating potential data competition issues.</p>
<p>This mechanism ensures the system's functions to consistently provide services to each user, even in a high-concurrency environment, maintaining stability throughout.</p>
<h3>3.3 Deployment and optimization of LLaMA2 model</h3>
<p>As a deep learning model, the deployment of the LLaMA2 model presents a myriad of challenges, including high computing resource requirements, a complex model structure, a substantial number of parameters, and extensive demands on memory and processing power. To meet the need for real-time user responses, the model must exhibit swift inference capabilities.</p>
<p>We devised a mode employing half-precision floating-point numbers (float16) for loading the model. This approach significantly reduced both memory usage and computation time. Additionally, we leveraged PyTorch's compile function to further optimize the model's runtime efficiency. Furthermore, we implemented a streaming output feature for the model, allowing users to observe results in real time during the model's execution, thereby enhancing the user experience.</p>
<p>Considering the intricacy and computational demands of the LLaMA2 model, we introduced a resource scheduling mechanism to ensure seamless responses for concurrent users. When a user requests model resources, the system assesses resource availability by competing for locks. If GPU resources are occupied and in the inference state, the user's request is placed in a waiting queue, persisting until the resources become available. Through this mechanism, the system guarantees that only one request accesses the model at any given time, mitigating potential resource contention issues. Conversely, when a user obtains the lock resource and initiates inference, the streaming output doesn't wait for the entire sequence to complete. Instead, it continues to generate and dispatch results in real time.</p>
<h1>4. Experiment</h1>
<h3>4.1 Baseline</h3>
<p>In the experimental stage, given the lack of large models specifically tailored for inorganic material synthesis knowledge question-answering, we opted for the widelyused general large models-ChatGPT, Ernie Bot, Spark Desk, ChatGLM-for a comparative experiment on the performance of inorganic materials synthesis questionanswering. Details can be found in Table 1 for information. Among them, the information on the Spark Desk model is not disclosed.</p>
<p>Table. 1 Model information for experimental comparison]</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Parameters</th>
<th style="text-align: center;">Base Model</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">175B</td>
<td style="text-align: center;">gpt-3.5-turbo</td>
</tr>
<tr>
<td style="text-align: center;">Ernie Bot</td>
<td style="text-align: center;">260B</td>
<td style="text-align: center;">Ernie 3.0 Titan</td>
</tr>
<tr>
<td style="text-align: center;">Spark Desk</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">ChatGLM</td>
<td style="text-align: center;">6B</td>
<td style="text-align: center;">GLM-130B</td>
</tr>
</tbody>
</table>
<h1>4.2 Metrics</h1>
<p>When evaluating natural language processing models, a comprehensive assessment often involves a combination of BLEU and ROUGE metrics. BLEU primarily measures the accuracy and exact matching of translation, with an emphasis on Precision, while ROUGE evaluates information completeness and coverage in summaries, emphasizing Recall.</p>
<p>However, when dealing with extensive language models in the domain of inorganic material synthesis question answering, our primary focus is on observing the safety, accuracy, and usability of the generated answers-a metric we refer to as SAU. Safety involves ensuring that the resulting material synthesis process does not pose potential dangers or can highlight possible hazards. Accuracy requires that the generated answers be as precise as possible, factoring in crucial elements such as required raw materials, time, and temperature. Usability emphasizes that the model's answers should be highly specific, encompassing operational details like the synthesis environment and utilized devices.</p>
<p>Furthermore, we demonstrated the generative inference capability of our model, showcasing its proficiency in providing synthesis processes for structures not present in the training set.</p>
<h3>4.3 Results</h3>
<p>We conducted a comprehensive performance evaluation, comparing our model against several baseline models. The questions posed were primarily skewed towards probing the knowledge of inorganic material synthesis processes, with an emphasis on extracting synthesis methods mentioned in the literature ${ }^{[28-29]}$. To enhance clarity, we extracted key synthetic raw material contents from model answers, as illustrated in Table 2. Identical questions were input to both our model and the baseline models during the experiment, and the corresponding output responses were observed. To maintain brevity, we condensed lengthy model answers by extracting essential synthetic raw material details. Furthermore, our input questions were rooted in relevant synthesis literature, utilizing chemical formulas such as $\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>}{ }^{[28]}$ and $\mathrm{Nd<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>$.} \mathrm{O}_{161}{ }^{[29]</p>
<p>We first delve into the analysis of the answer regarding $\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>$. In terms of safety, all models perform similarly. Concerning accuracy, both ChatGPT and Spark Desk provide answers, but the raw materials mentioned in their responses are found to be incorrect based on relevant literature. Ernie Bot and ChatGLM models fail to furnish answers. Notably, our MatChat model not only provides an answer but also presents synthetic raw materials that closely aligned with those detailed in the literature. Moreover, our model outshines others in terms of usability by offering the most informative responses.</p>
<p>Then, turning our attention to the answers concerning $\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>$, the models demonstrate comparable performance in terms of safety. However, in terms of accuracy, ChatGPT and ChatGLM models provide vague raw material information for} \mathrm{O}_{161</p>
<p>various elements, lacking practical guidance. The Spark Desk model offers guidance in the form of oxides for each element, but the literature indicates that the source of the B element is H3BO3. Ernie Bot fails to provide a relevant answer. On the other hand, our MatChat model delivers raw material information closest to the literature, showcasing the highest guiding value.</p>
<p>In summary, MatChat proves to be highly valuable in predicting material synthesis processes, particularly for its accuracy and usability.</p>
<p>Table. 2 Experiments of model comparison</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">How to make $\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>$ ?</th>
<th style="text-align: center;">How to make $\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>$ ?} \mathrm{O}_{161</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">Materials Needed: <br> 1. Potassium carbonate (K2CO3) <br> 2. Calcium oxide (CaO) <br> 3.Ammonium molybdate $\left(\left(\mathrm{NH}<em 6="6">{4}\right)</em>} \mathrm{Mo<em 24="24">{7} \mathrm{O}</em>} \cdot 4 \mathrm{H<em 3="3">{2} \mathrm{O}\right)$ <br> 4. Boric acid $\left(\mathrm{H}</em>} \mathrm{BO<em 3="3">{3}\right)$ <br> 5. Phosphoric acid $\left(\mathrm{H}</em>\right)$ <br> 6. Deionized water <br> 7. Glassware (flasks, beakers, etc.) <br> 8. Heating equipment (hot plates, ovens, etc.) <br> 9. Laboratory equipment (stirrers, pipettes, etc.) <br> 10. Protective gear (lab coat, gloves, safety goggles, etc.)} \mathrm{PO}_{4</td>
<td style="text-align: center;">Gather the Starting Materials: <br> You'll need the following starting materials, which are the elements and compounds that make up the compound you want to synthesize: <br> 1. Neodymium (Nd) compounds <br> 2. Zinc (Zn) compounds <br> 3. Boron (B) compounds <br> 4. Silicon ( Si$)$ compounds <br> 5. Oxygen (O) sources (e.g., oxygen gas, oxides)</td>
</tr>
<tr>
<td style="text-align: center;">Ernie Bot</td>
<td style="text-align: center;">As an artificial intelligence language model, I cannot provide information about the production of chemical substances.</td>
<td style="text-align: center;">$\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>$ is a complex oxide ceramic material with a formula derived from the formula of the lanthanide series. It is a composite oxide ceramic material that has not been widely commercialized and is difficult to produce. The production process is complex and requires high technology. In this case, the best advice is to seek help from professionals.} \mathrm{O}_{161</td>
</tr>
<tr>
<td style="text-align: center;">Spark <br> Desk</td>
<td style="text-align: center;">$\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>}$ is a chemical compound with the formula $\mathrm{K<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>$. It is a type of potassium phosphate, commonly known as plaster of Paris. Making</td>
<td style="text-align: center;">To make $\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>} \mathrm{O<em 2="2">{161}$, one would need to start with the raw materials: $\mathrm{Nd}</em>} \mathrm{O<em 2="2">{3}, \mathrm{ZnO}, \mathrm{B}</em>} \mathrm{O<em 2="2">{3}, \mathrm{SiO}</em>$. The specific ratios of these components would need to be}$, and $\mathrm{H}_{2} \mathrm{O</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">plaster of Paris involves a process of mixing water and calcium hydroxide $(\mathrm{Ca}(\mathrm{OH})_{2}$ ) until it forms a thick paste.</th>
<th style="text-align: center;">carefully controlled during the synthesis process to achieve the desired composition.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ChatGLM</td>
<td style="text-align: center;">I'm sorry, but I cannot provide a specific method for creating the chemical compound $\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>$, as it is not a commonly known or widely used compound.</td>
<td style="text-align: center;">$\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>$ is a chemical formula for a specific alloy, which is a combination of neodymium ( Nd ), zinc ( Zn ), boron (B), silicon ( Si ), and oxygen (O). To make this alloy, you would typically start with the appropriate elements in their elemental forms and then mix them in the correct stoichiometric ratio.} \mathrm{O}_{161</td>
</tr>
<tr>
<td style="text-align: center;">MatChat</td>
<td style="text-align: center;">$\mathrm{K}<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>}$ can be made from $\mathrm{K<em 3="3">{2} \mathrm{CO}</em>}, \quad\left(\mathrm{NH<em 2="2">{4}\right)</em>} \mathrm{HPO<em 3="3">{4}, \quad \mathrm{CaCO}</em>}$, $\mathrm{H<em 3="3">{3} \mathrm{BO}</em>}$, and $\mathrm{MoO<em 4="4">{3}$ via solid state reaction. The chemical reaction equation is $\left(2\left(\mathrm{NH}</em>\right)<em 4="4">{2} \mathrm{HPO}</em>}+\right.$ $1 \mathrm{CaCO<em 3="3">{3}+1 \mathrm{H}</em>} \mathrm{BO<em 2="2">{3}+1 \mathrm{~K}</em>} \mathrm{CO<em 3="3">{3}+$ $0.5 \mathrm{MoO}</em>}=1 \mathrm{~K<em 2="2">{2} \mathrm{CaMoB}</em>} \mathrm{P<em 13="13">{2} \mathrm{O}</em>}+$ $2 \mathrm{CO<em 2="2">{2}+3 \mathrm{H}</em>$ for 24.0 h , cooled. The detailed recipe can be found in literature [10.1016/s0167-2738(03)00122-0].} \mathrm{O}+4 \mathrm{NH}_{3}$ ). The precursors are ground in agate, heated under $600.0^{\circ} \mathrm{C</td>
<td style="text-align: center;">$\mathrm{Nd}<em 60="60">{2} \mathrm{Zn}</em>} \mathrm{~B<em 19="19">{40} \mathrm{Si}</em>} \mathrm{O<em 2="2">{161}$ can be made from $\mathrm{SiO}</em>}, \mathrm{Nd<em 3="3">{2} \mathrm{O}</em>}, \mathrm{ZnO}$, and $\mathrm{H<em 3="3">{3} \mathrm{BO}</em>}$ via solid state reaction. The chemical reaction equation is $\left(40 \mathrm{H<em 3="3">{3} \mathrm{BO}</em>}+\right.$ $19 \mathrm{SiO<em 2="2">{2}+1 \mathrm{Nd}</em>} \mathrm{O<em 2="2">{3}+60 \mathrm{ZnO}==$ $1 \mathrm{Nd}</em>} \mathrm{Zn<em 40="40">{60} \mathrm{~B}</em>} \mathrm{Si<em 161="161">{19} \mathrm{O}</em>$ in air for 24.0 h , cooled. The detailed recipe can be found in literature [10.1016/j.jssc.2005.06.002].}+60 \mathrm{H}_{2} \mathrm{O}$ ). The precursors are mixed in agate, heated under $1000.0^{\circ} \mathrm{C</td>
</tr>
<tr>
<td style="text-align: center;">Litera ture</td>
<td style="text-align: center;">The studied glasses have the composition expressed by the formula $\mathrm{xMoO}<em 2="2">{3} \cdot(1-\mathrm{x})$ $\left[48 \mathrm{P}</em>} \mathrm{O<em 2="2">{5} \cdot 45 \mathrm{CaO} \cdot 2 \mathrm{~B}</em>} \mathrm{O<em 2="2">{3} \cdot 5 \mathrm{~K}</em>} \mathrm{O}\right]$ with $\mathrm{x}=0,1,3,5$ and $7 \mathrm{~mol} \%$. They were prepared using the conventional melt quenching method. Appropriate quantities of reagent grade $\mathrm{MoO<em 4="4">{3}, \mathrm{NH}</em>} \cdot \mathrm{H<em 4="4">{2} \mathrm{PO}</em>}, \mathrm{CaCO<em 3="3">{3}$, $\mathrm{H}</em>} \mathrm{BO<em 2="2">{3}$ and $\mathrm{K}</em>$ for 25 min . The melts were quickly cooled at room temperature} \mathrm{CO}_{3}$ were mixed in an agate mortar. The batches were melted in air, in sintered corundum crucibles, in an electric furnace at $1100^{\circ} \mathrm{C</td>
<td style="text-align: center;">Zinc-borosilicate glasses in the chemical composition of 60ZnO$20 \mathrm{~B}<em 3="3">{2} \mathrm{O}</em>}-19 \mathrm{SiO<em 2="2">{2}-1 \mathrm{Nd}</em>} \mathrm{O<em 2="2">{3}(\mathrm{~mol} \%)$ have been prepared by employing a conventional quenching method from the spectral pure grade raw chemicals such as $\mathrm{ZnO}, \mathrm{SiO}</em>}, \mathrm{H<em 3="3">{3} \mathrm{BO}</em>}$ and $\mathrm{Nd<em 3="3">{2} \mathrm{O}</em>$ for about 3 h in computer-controlled electrical furnace. The melts were poured onto a smooth surfaced stainless steel plate and pressed with another similar plate in order to obtain a few circular glass}$. The batches of chemical mix weighing about 50 g were melted in a platinum crucible at $1300^{\circ} \mathrm{C</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">by pouring and stamping between <br> two copper plates previously cooled <br> with liquid nitrogen. The glass <br> samples were ground to powder in a <br> Retsch Planetary ball mills, type PM <br> 100. The average size of the <br> obtained grains was about $30 \mu \mathrm{~m}$ <br> ${ }^{[28]}$.</th>
<th style="text-align: left;">discs of $2-3 \mathrm{~cm}$ in diameter with a <br> thickness of 0.3 cm each. These <br> samples were annealed at $550^{\circ} \mathrm{C}$ for 1 <br> h and cooled down slowly to the room <br> temperature to remove internal <br> stresses present in the glass samples <br> ${ }^{[29]}$</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Furthermore, we showcase the dual capabilities of our model, encompassing both generative and inferential aspects. Our training set comprises a total of 13,878 diverse chemical formula synthesis data. When we query the model using chemical formulas present in the dataset, the output exhibits a degree of inconsistency with the training set data, highlighting the model's generalization capabilities. Moreover, when posing questions with chemical formulas absent from the dataset, the output format and content align in structure with the dataset, offering valuable insights for the synthesis process.</p>
<h1>5. Conclusion</h1>
<p>Based on the LLaMA2-7B pre-training model, we have developed MatChat, a groundbreaking large language model explicitly designed for materials science. This model primarily focuses on synthesizing knowledge related to the inorganic materials synthesis process. It can engage in logical reasoning based on the queried materials formula and provides answers in the format of the training set, including formulas, temperature, time, environment conditions, and other relevant information. To facilitate the usage of MatChat, we have further developed a dialogue platform for users based on this model. This platform is currently accessible online at http://chat.aicnic.cn/onchat and is open to researchers in the materials field. This work is poised to inspire and bring new innovative ideas in the field of materials science.</p>
<p>MatChat represents a pioneering effort in the applications of large models within the field of materials science. It currently only supports English languages due to the lack of text data in other languages within the training set. The accuracy of its responses is an area we aim to further refine. The material large language model presented in this study focuses on inorganic chemical synthesis. We aspire for this work to be the 'The Wright brothers' one-minute flight' in the field of inorganic material synthesis pathway prediction. In the future, the research team intends to enhance the model's usability and accuracy by incorporating literature data and information from existing material databases such as Atomly.net, OQMD, etc. Additionally, we plan to optimize the training methodology to enable the large aircraft of inorganic materials synthesis pathway prediction to fly higher and farther.</p>
<h1>Code availability</h1>
<p>The relevant code of this article has been published on the GitHub website, and the link is https://github.com/materialsCnicCas/CASMatChat.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by the Informatization Plan of the Chinese Academy of Sciences, Grant No.CAS-WX2023SF-0101 and XDB33020000, the Key Research Program of Frontier Sciences, CAS, Grant No. ZDBS-LY-7025, and the Youth Innovation Promotion Association CAS (2021167).</p>
<h2>References</h2>
<ol>
<li>OpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).</li>
<li>Du, Z. et al. Glm: General language model pretraining with autoregressive blank infilling. In Proceedings of the $60^{\text {th }}$ Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 320-335 (2022).</li>
<li>Zeng, A. et al. GLM-130b: An open bilingual pre-trained model. In The Eleventh International Conference on Learning Representations (2023).</li>
<li>Sun, Y. et al. Ernie: Enhanced representation through knowledge integration. arXiv preprint arXiv:1904.09223 (2019).</li>
<li>Sun, Y. et al. Ernie 2.0: A continual pre-training framework for language understanding. In Proceedings of the AAAI conference on artificial intelligence, vol. 34, 8968-8975 (2020).</li>
<li>Sun, Y. et al. Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation. arXiv preprint arXiv:2107.02137 (2021).</li>
<li>Touvron, H. et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).</li>
<li>Touvron, H. et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).</li>
<li>Yang, P. et al. Zero-shot learners for natural language understanding via a unified multiple choice perspective. arXiv preprint arXiv:2210.08590 (2022).</li>
<li>Zhang, H. et al. Huatuogpt, towards taming language model to be a doctor. arXiv preprint arXiv:2305.15075 (2023).</li>
<li>Xiong, H. et al. Doctorglm: Fine-tuning your chinese doctor is not a herculean task. arXiv preprint arXiv:2304.01097(2023).</li>
<li>Zhang, X., Yang, Q. \&amp; Xu, D. Xuanyuan 2.0: A large chinese financial chat model with hundreds of billions parameters. arXiv preprint arXiv:2305.12002 (2023).</li>
<li>Dan, Y. et al. Educhat: A large-scale language model-based chatbot system for intelligent education. arXiv preprint arXiv:2308.02773 (2023).</li>
<li>IDEA-CCNL. Fengshenbang-lm. https://github.com/IDEA-CCNL/FengshenbangLM (2021).</li>
<li>Xie, F. et al. Lu-H-N Phase Diagram from First-Principles Calculations. Chin. Phys. Lett. 40, 1-5 (2023).</li>
<li>
<p>Jia, H. et al. Persona of transition metal ions in solids: A statistical learning on local structures of transition metal oxides. Adv. Sci. 9, 2202756 (2022).</p>
</li>
<li>
<p>https://atomly.net.</p>
</li>
<li>Miao Liu, S. M. Atomly.net materials database and its application in inorganic chemistry. SCIENTIA SINICA Chimica 53,19-25 (2023).</li>
<li>Saal, J., Kirklin, S., Aykol, M., Meredig, B. \&amp; Wolverton, C. Materials design and discovery with high-throughput density functional theory: The open quantum materials database (oqmd). JOM 65, 1501-1509 (2013).</li>
<li>Jain, A. et al. Commentary: The materials project: A materials genome approach to accelerating materials innovation. APL Mater. 1 (2013).</li>
<li>Liang, Y. et al. A universal model for accurately predicting the formation energy of inorganic compounds. Sci. China Mater. 66, 343-351 (2023).</li>
<li>Liu, Z. et al. Swarm intelligence for new materials. Comput. Mater. Sci. 214, 111699 (2022).</li>
<li>Guo, J. et al. Neural network training method for materials science based on multisource databases. Sci. reports 12, 15326(2022).</li>
<li>Gupta, T., Zaki, M., Krishnan, N. A. \&amp; Mausam. Matscibert: A materials domain language model for text mining and information extraction. npj Comput. Mater. 8, 102 (2022).</li>
<li>Devlin, J., Chang, M.-W., Lee, K. \&amp; Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171-4186 (Association for Computational Linguistics, Minneapolis, Minnesota, 2019).</li>
<li>Wang, Z. et al. Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature.Sci. Data 9, 231 (2022).</li>
<li>MetaResearch. Llama 2 fine-tuning / inference recipes and examples. https://github.com/facebookresearch/llama-recipes#install-with-optionaldependencies (2022).</li>
<li>Lucacel, R. C., Ponta, O., Licarete, E., Radu, T. \&amp; Simon, V. Synthesis, structure, bioactivity and biocompatibility of melt-derived p2o5-cao-b2o3-k2o-moo3 glasses. J. Non-Crystalline Solids 439, 67-73 (2016).</li>
<li>Annapurna, K., Dwivedi, R., Kundu, P. \&amp; Buddhudu, S. Nir emission and upconversion luminescence spectra of nd3+:zno-sio2-b2o3 glass. Mater. Lett. 57, 2095-2098 (2003).</li>
</ol>            </div>
        </div>

    </div>
</body>
</html>