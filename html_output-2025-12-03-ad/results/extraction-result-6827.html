<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6827 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6827</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6827</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-131.html">extraction-schema-131</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <p><strong>Paper ID:</strong> paper-277786851</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.11354v1.pdf" target="_blank">Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning</a></p>
                <p><strong>Paper Abstract:</strong> We introduce Kimina-Prover Preview, a large language model that pioneers a novel reasoning-driven exploration paradigm for formal theorem proving, as showcased in this preview release. Trained with a large-scale reinforcement learning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong performance in Lean 4 proof generation by employing a structured reasoning pattern we term \textit{formal reasoning pattern}. This approach allows the model to emulate human problem-solving strategies in Lean, iteratively generating and refining proof steps. Kimina-Prover sets a new state-of-the-art on the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved benchmark performance, our work yields several key insights: (1) Kimina-Prover exhibits high sample efficiency, delivering strong results even with minimal sampling (pass@1) and scaling effectively with computational budget, stemming from its unique reasoning pattern and RL training; (2) we demonstrate clear performance scaling with model size, a trend previously unobserved for neural theorem provers in formal mathematics; (3) the learned reasoning style, distinct from traditional search algorithms, shows potential to bridge the gap between formal verification and informal mathematical intuition. We open source distilled versions with 1.5B and 7B parameters of Kimina-Prover</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6827.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6827.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kimina-Prover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kimina-Prover Preview</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Lean 4-focused large language model trained via a large-scale reinforcement learning pipeline to generate whole formal proofs using a structured 'formal reasoning pattern' that interleaves informal thoughts and Lean code in <think> blocks; emphasizes reasoning-driven exploration instead of external tree search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Kimina-Prover (72B variant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based LLM initialized from Qwen2.5-72B and further trained with reinforcement learning and supervised fine-tuning using a formal reasoning pattern that outputs internal thinking blocks (<think> ... </think>) interleaving informal reasoning and Lean 4 code snippets.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>decoder-only transformer (fine-tuned) with RL objective and KL constraint; reasoning encouraged by token-level structured thinking pattern</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Mixed: autoformalized Lean 4 problems, human-annotated Lean 4 proofs (~10k), informal mathematical chain-of-thought data from Kimi k1.5, and distilled rollouts from the 72B checkpoint for smaller models</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Reinforcement learning eliciting long chain-of-thought-like internal reasoning (formal reasoning pattern: <think> blocks interleaving informal reasoning and Lean snippets), whole-proof generation (flattened step-wise search) with binary reward from Lean compiler verification</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Lean 4 compiler used as a binary verifier during RL rollouts (correct proof => reward 1). Integrated with a Numina Lean Server for high-throughput verification during training and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F (Lean 4)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>A cross-system benchmark of olympiad-style formal mathematics problems formalized for proof assistants (here evaluated in Lean 4); used to measure end-to-end formally verifiable proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Formal theorem proving / proof generation in Lean 4</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>pass@k (percent of problems whose generated final Lean code verifies)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>pass@8192 = 80.74% (miniF2F-test); pass@32 = 68.85%; pass@1 = 52.94%</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Outperforms prior SOTA BFS-Prover (72.95% reported) by ~+7.8% at large sample budgets; outperforms general-purpose LLMs (Gemini, o3) by large margins (e.g., pass@32 68.85% vs Gemini 37.70% / o3 24.59%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>RL with a formal reasoning pattern yields sample-efficient, human-like whole-proof generation that scales with model size and context length; achieves SOTA on miniF2F and demonstrates emergent decomposition, reflection, and longer-token outputs correlated with higher accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Training is sensitive to format collapse (model output dropping required tactic structure) requiring format filters and sample discarding; RL in non-verifiable subtasks (autoformalization) relies on LLM judges and can suffer false positives; occasional low-quality reflections (repetition/meaningless text); some volatile mid-training behavior; does not fully address overuse of high-level tactics or integrate library search.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6827.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kimina-Autoformalizer-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kimina-Autoformalizer-7B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dedicated model to translate natural language math problems into syntactically valid Lean 4 problem statements, used to construct a large diverse problem set for RL training (autoformalization).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Kimina-Autoformalizer-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>7B transformer model fine-tuned for autoformalization from natural language to Lean 4 syntax; trained with supervised fine-tuning and expert iteration, filtered by compilation and an LLM judge.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>decoder-only transformer (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Curated SFT pairs from PutnamBench, miniF2F, ProofNet, Compfiles; iterative additions from model-generated formalizations that compiled and passed LLM judging.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Sequence-to-sequence generation of formal statements with iterative expert iteration (generate -> compile filter -> LLM judge -> augment training set)</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Lean 4 compiler for syntactic/compilation filtering; QwQ-32B LLM used as semantic judge during expert iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Autoformalization human-curated test set</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>A held-out human-curated set (~1,000 problems) used to evaluate compilation rate and judged semantic correctness of autoformalized Lean 4 statements.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Autoformalization (natural language -> Lean 4 statement)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>one-shot Lean 4 compilation rate; judged autoformalization accuracy (%)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>one-shot compilation rate ≈ 90%; judged accuracy ≈ 66% (on curated test set)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Most external models failed to consistently produce Lean 4 (often produced Lean 3); Kimina-Autoformalizer outperforms them on Lean 4 compilation and judged correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Expert iteration with compilation + LLM judging yields high compilation rates and acceptable semantic accuracy, enabling large-scale generation of training problems for RL; human oversight remains necessary to catch judge false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>LLM judges can miss semantic mistakes as long as output compiles; requires significant expert monitoring; difficulty ensuring semantic equivalence between informal statement and formalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6827.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2.5-72B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2.5-72B (initial backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A foundation LLM used as the initialization point for Kimina-Prover's RL training; provided the transformer backbone and initial policy behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-72B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large decoder-only transformer family of foundation models from the Qwen team; used here as initialization for RL fine-tuning toward formal proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>72B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>General pretraining corpora (Qwen team resources); later fine-tuned with math-inclined SFT and RL datasets in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Pretrained transformer; reasoning capabilities further elicited via supervised fine-tuning and RL in the Kimina pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F (after RL fine-tuning as Kimina-Prover)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>See Kimina-Prover entry; Qwen2.5-72B served as base pretraining model before formal RL adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Foundation model initialization for formal theorem proving</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>N/A (serves as base model prior to RL)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Used as backbone; RL fine-tuning (Kimina-Prover) significantly changes task performance compared to vanilla Qwen2.5 behavior (paper reports gains after RL).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A large pre-trained foundation model can be adapted via RL + structured reasoning pattern to achieve strong formal proving; model scaling benefits become visible after RL.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Pretrained Qwen-variants without domain-specific SFT/RL struggle with formal Lean syntax and proof generation out-of-the-box.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6827.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2.5-Math-(1.5B/7B)-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2.5-Math-1.5B-Instruct and Qwen2.5-Math-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Smaller Qwen variants used as initialization points for distilled Kimina-Prover models (1.5B and 7B distilled variants), trained by SFT on rollouts from Kimina-Prover-72B.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-Math-1.5B-Instruct; Qwen2.5-Math-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Smaller instruction-tuned variants of the Qwen family specialized with math-oriented SFT; used as initialization for distilled Kimina-Prover 1.5B and 7B models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.5B and 7B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>decoder-only transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Math-focused SFT data and distilled rollouts from Kimina-Prover-72B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Supervised fine-tuning on rollouts distilled from a larger RL-trained model to transfer formal proof capability into smaller checkpoints</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F (evaluated after distillation)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Same miniF2F formal theorem proving benchmark used to measure distilled model performance relative to the 72B variant.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Formal theorem proving (distilled, smaller models)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>pass@k</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>1.5B and 7B distilled models achieve lower pass rates than 72B but show consistent scaling across sizes (exact numbers reported in paper figures/tables for different budgets)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Distilled models underperform the 72B but still gain from Kimina rollouts; demonstrates that RL rollouts can be distilled to smaller models with retained capability.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Distillation from a 72B RL-trained prover produces smaller models (1.5B, 7B) that retain meaningful formal proving ability and follow the observed scaling trend.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Smaller models have lower absolute performance and are more sensitive to sample budget; distillation cannot fully close the gap to the 72B model.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6827.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kimi k1.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kimi k1.5 (RL pipeline / model family)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior Kimi-Team reinforcement learning pipeline and model family that demonstrated elicitation of long chain-of-thought reasoning for complex informal math and coding tasks; used as the methodological foundation for Kimina-Prover's RL approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Kimi k1.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RL-trained LLM pipeline emphasizing long-form chain-of-thought via carefully designed reward signals and training recipes; used as conceptual and technical groundwork for Kimina-Prover.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer + RL fine-tuning pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Large-scale informal math and coding chain-of-thought data curated by Kimi-Team</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>RL to elicit long chain-of-thought style outputs and reflection; used as inspiration for formal RL in Kimina-Prover</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Informal math and coding benchmarks (referenced generally)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Prior Kimi work evaluated on informal math/coding tasks and competitions (AIME, Codeforces), showing emergent long-form reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Informal long-chain-of-thought reasoning, precursor to formal reasoning work</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Reported improvements on complex informal tasks and competitions (paper references Kimi-Team 2025)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Kimi k1.5 established that RL can induce long-form reflection and chains-of-thought, which Kimina-Prover adapts into formal theorem proving.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>RL can be engineered to elicit structured long thinking patterns that aid complex problem solving; adapting these methods to formal domains requires further constraints and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Informal reasoning successes do not trivially translate to formal proof generation without specialized SFT, pattern enforcement, and verifiable rewards.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6827.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude 3.7 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Claude 3.7 Sonnet (Anthropic)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose LLM used here to synthesize auxiliary thinking-block SFT examples combining informal reasoning and formal Lean 4 solutions to bootstrap Kimina-Prover's formal reasoning pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Claude 3.7 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>High-capacity general-purpose LLM (Anthropic) used to generate synthetic paired informal/formal thinking-block outputs for supervised initialization.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer-based LLM</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Anthropic's proprietary pretraining corpora; used here only as a synthesis tool</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Chain-of-thought style synthesis to create <think> blocks combining informal and formal proofs for SFT</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>SFT synthesis quality (internal validation)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Claude outputs were judged qualitatively; paper reports Claude 3.7 Sonnet produced satisfying synthetic thinking-block examples used to create ~20K mini-SFT dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Synthetic generation of informal-formal aligned training samples</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Qualitative suitability for SFT; number of examples synthesized (~20k)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>~20K examples synthesized; Claude judged as the only LLM producing sufficiently satisfying outputs among those attempted</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Other LLMs attempted produced lower-quality thinking blocks; only Claude's output was judged satisfactory for bootstrapping the formal reasoning pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using a strong general-purpose LLM to synthesize aligned informal-formal thinking blocks can jumpstart RL for formal reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Synthetic outputs may have limited reflection patterns and require mixing with informal math data to avoid low-quality repeated reflections at RL time.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6827.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QwQ-32B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>QwQ-32B (LLM judge / difficulty rater)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 32B model used as an automated judge to evaluate semantic correctness of autoformalizations and to assign difficulty ratings to problems for dataset balancing in the RL pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>QwQ-32B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large LLM used in a judge role with a handcrafted prompt and unanimous voting across multiple samples to reduce false positives when evaluating autoformalizations and difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>32B</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer-based LLM (judge role)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified; used as an evaluation/judging tool in expert iteration</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>LLM-based semantic evaluation via prompt engineering and multiple-sample unanimous voting</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Autoformalizer human-curated validation set</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>A human-curated test set (~1,000 examples) used to optimize and validate the QwQ-32B judge prompt and measure judge reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Semantic judging of formalizations and difficulty rating</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Judge-validated autoformalization accuracy; compilation+judged correctness rate</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Used in expert iteration that achieved up to 90% compilation and 66% judged accuracy on the autoformalizer test set</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Multiple-sample unanimous voting using QwQ-32B reduced false positives compared to naive single-sample judging.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-based judges can efficiently scale expert iteration, but require careful prompt engineering and human monitoring to limit false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>LLM judges can be fooled by compilable-but-incorrect formalizations; blind reliance on judge signals is risky for RL in non-verifiable domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6827.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini-2.5-pro</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini 2.5 Pro (general-purpose LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose reasoning model compared against Kimina-Prover; while it can solve AIME problems informally, it struggles to produce formally verifiable Lean proofs and often hallucinates invalid proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini 2.5 Pro</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large general-purpose transformer-based reasoning LLM (Google's Gemini family) evaluated in its default reasoning mode; not specialized for formal proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>2.5 (family name; internal size unspecified here)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer-based LLM (general-purpose)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Proprietary general web and reasoning corpora (not specified)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Informal chain-of-thought reasoning; not optimized for formal proof generation or Lean verification</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F (informal vs formal subsets: IMO/AIME)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Evaluation on miniF2F benchmark subsets (IMO and AIME) comparing informal solving capacity vs formalized Lean proving.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Informal mathematics reasoning and attempted formalization</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>pass@32 (formal), informal problem solving success (informal)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>pass@32 = 37.70% (miniF2F formal); IMO subset 5.00%; AIME subset 13.33% (formal). Informally, Gemini solves all 15 AIME problems but struggles to formalize them.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Underperforms Kimina-Prover substantially on formal tasks (e.g., 68.85% vs 37.70% at pass@32); outperforms some models on informal tasks but fails to formalize reliably.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>General-purpose LLMs can solve many informal math problems but exhibit a large gap when asked to produce machine-checkable formal proofs; they are prone to hallucination in formalization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Hallucination and inability to produce verifiable Lean proofs; limited formalization capability despite informal success.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6827.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI o3 (o3-mini)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI o3 (o3-mini variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose OpenAI model evaluated as a baseline; capable of solving informal math in some cases but shows very low formal proof pass rates and fails to formalize many solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI o3 (o3-mini)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's strong general-purpose reasoning LLM family; evaluated on informal vs formal miniF2F subsets in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>model family (size unspecified for o3-mini)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer-based LLM</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Proprietary large corpora (not specified)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Informal chain-of-thought; no specialized Lean integration reported</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F (formal evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>As above: olympiad-style formal problems in Lean 4; o3 evaluated for formal proof generation success.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Informal reasoning and attempted formalization; formal proof generation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>pass@32 (formal)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>pass@32 = 24.59% (miniF2F formal); IMO subset 0.00%; AIME subset 6.67% (formal). Informally, o3-mini solves all 15 AIME problems but cannot formalize them.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Performs substantially worse than Kimina-Prover on formal tasks; shows the informal-to-formal gap in current general-purpose systems.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Strong informal reasoning ability does not guarantee the capacity to produce verifiable formal proofs; specialized training and RL matter.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Poor formalization, high rate of unverifiable/hallucinated proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6827.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BFS-Prover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BFS-Prover (Best-First Search based prover)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior neural theorem prover that couples an LLM policy with a Best-First Search (BFS) tree search to generate stepwise tactic sequences; used as a key baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BFS-Prover</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>System combining an LLM for tactic prediction with a Best-First Search algorithm to explore proof trees step-by-step; representative of search-based provers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>various (previous SOTA reported at specific sizes; exact size not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>LLM + Best-First Search (tree search hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Supervised data for tactic prediction and training corpora used in cited works (Polu et al., R. Xin et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Step-by-step tactic generation guided by BFS search heuristics</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Search algorithm (BFS) used to explore tactic trees; leverages proof assistant environment for verification during search.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>miniF2F</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Same formal olympiad benchmark; BFS-Prover reported previous SOTA values on miniF2F.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Stepwise formal theorem proving (tactic-level search)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>pass@k (verification success rate)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported prior SOTA on miniF2F: 72.95% (paper reports Kimina-Prover surpasses this)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Kimina-Prover surpasses BFS-Prover at large sample budgets (80.74% vs 72.95% at pass@8192) and requires fewer samples for comparable performance due to whole-proof generation and internal exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Search-based approaches are effective but more computationally expensive; they historically did not show clear model-size scaling in formal mathematics, a gap Kimina-Prover addresses.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High computational overhead from explicit search; scalability limits; less explainable internal reasoning compared to Kimina's thinking-blocks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6827.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6827.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepSeek-R1</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent RL-based reasoning model referenced as prior work demonstrating that large-scale RL with engineered rewards can induce long chain-of-thought behaviors in LLMs for complex tasks; cited as conceptual precedent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepSeek-R1</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RL-trained LLM approach from DeepSeek-AI applying reward engineering to incentivize long-form reasoning and reflection.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>transformer + RL fine-tuning pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Task-specific data and RL rollouts; details in cited DeepSeek work</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Reinforcement learning with reward shaping to promote long chain-of-thought reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Informal and formal reasoning benchmarks (cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>DeepSeek-R1 reported improvements on reasoning tasks through RL; in this paper cited as precedent for RL eliciting long reasoning chains.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Long-form reasoning (informal tasks) and inspiration for formal RL</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Reported emergent reasoning improvements on complex math/coding tasks in cited work</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Cited as an example where RL with tailored rewards yields reasoning improvements; Kimina adapts similar principles to verifiable formal proof setting.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Large-scale RL can produce emergent long reasoning patterns that benefit complex tasks; adaptation to formal domains requires verifiable rewards and format controls.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Prior RL work focused on informal tasks; direct transfer to formal provers was previously unexplored and presents unique verification constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics <em>(Rating: 2)</em></li>
                <li>BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving <em>(Rating: 2)</em></li>
                <li>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning <em>(Rating: 2)</em></li>
                <li>HyperTree Proof Search for Neural Theorem Proving <em>(Rating: 2)</em></li>
                <li>AI achieves silver-medal standard solving International Mathematical Olympiad problems <em>(Rating: 2)</em></li>
                <li>Kimi k1.5: Scaling reinforcement learning with llms <em>(Rating: 2)</em></li>
                <li>Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs <em>(Rating: 1)</em></li>
                <li>Lean-STaR: Learning to Interleave Thinking and Proving <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6827",
    "paper_id": "paper-277786851",
    "extraction_schema_id": "extraction-schema-131",
    "extracted_data": [
        {
            "name_short": "Kimina-Prover",
            "name_full": "Kimina-Prover Preview",
            "brief_description": "A Lean 4-focused large language model trained via a large-scale reinforcement learning pipeline to generate whole formal proofs using a structured 'formal reasoning pattern' that interleaves informal thoughts and Lean code in &lt;think&gt; blocks; emphasizes reasoning-driven exploration instead of external tree search.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Kimina-Prover (72B variant)",
            "model_description": "Transformer-based LLM initialized from Qwen2.5-72B and further trained with reinforcement learning and supervised fine-tuning using a formal reasoning pattern that outputs internal thinking blocks (&lt;think&gt; ... &lt;/think&gt;) interleaving informal reasoning and Lean 4 code snippets.",
            "model_size": "72B",
            "architecture_type": "decoder-only transformer (fine-tuned) with RL objective and KL constraint; reasoning encouraged by token-level structured thinking pattern",
            "training_data": "Mixed: autoformalized Lean 4 problems, human-annotated Lean 4 proofs (~10k), informal mathematical chain-of-thought data from Kimi k1.5, and distilled rollouts from the 72B checkpoint for smaller models",
            "reasoning_method": "Reinforcement learning eliciting long chain-of-thought-like internal reasoning (formal reasoning pattern: &lt;think&gt; blocks interleaving informal reasoning and Lean snippets), whole-proof generation (flattened step-wise search) with binary reward from Lean compiler verification",
            "external_tool_used": true,
            "external_tool_description": "Lean 4 compiler used as a binary verifier during RL rollouts (correct proof =&gt; reward 1). Integrated with a Numina Lean Server for high-throughput verification during training and evaluation.",
            "benchmark_name": "miniF2F (Lean 4)",
            "benchmark_description": "A cross-system benchmark of olympiad-style formal mathematics problems formalized for proof assistants (here evaluated in Lean 4); used to measure end-to-end formally verifiable proof generation.",
            "task_type": "Formal theorem proving / proof generation in Lean 4",
            "performance_metric": "pass@k (percent of problems whose generated final Lean code verifies)",
            "performance_value": "pass@8192 = 80.74% (miniF2F-test); pass@32 = 68.85%; pass@1 = 52.94%",
            "comparison_with_baseline": "Outperforms prior SOTA BFS-Prover (72.95% reported) by ~+7.8% at large sample budgets; outperforms general-purpose LLMs (Gemini, o3) by large margins (e.g., pass@32 68.85% vs Gemini 37.70% / o3 24.59%).",
            "key_findings": "RL with a formal reasoning pattern yields sample-efficient, human-like whole-proof generation that scales with model size and context length; achieves SOTA on miniF2F and demonstrates emergent decomposition, reflection, and longer-token outputs correlated with higher accuracy.",
            "limitations": "Training is sensitive to format collapse (model output dropping required tactic structure) requiring format filters and sample discarding; RL in non-verifiable subtasks (autoformalization) relies on LLM judges and can suffer false positives; occasional low-quality reflections (repetition/meaningless text); some volatile mid-training behavior; does not fully address overuse of high-level tactics or integrate library search.",
            "uuid": "e6827.0",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Kimina-Autoformalizer-7B",
            "name_full": "Kimina-Autoformalizer-7B",
            "brief_description": "A dedicated model to translate natural language math problems into syntactically valid Lean 4 problem statements, used to construct a large diverse problem set for RL training (autoformalization).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Kimina-Autoformalizer-7B",
            "model_description": "7B transformer model fine-tuned for autoformalization from natural language to Lean 4 syntax; trained with supervised fine-tuning and expert iteration, filtered by compilation and an LLM judge.",
            "model_size": "7B",
            "architecture_type": "decoder-only transformer (fine-tuned)",
            "training_data": "Curated SFT pairs from PutnamBench, miniF2F, ProofNet, Compfiles; iterative additions from model-generated formalizations that compiled and passed LLM judging.",
            "reasoning_method": "Sequence-to-sequence generation of formal statements with iterative expert iteration (generate -&gt; compile filter -&gt; LLM judge -&gt; augment training set)",
            "external_tool_used": true,
            "external_tool_description": "Lean 4 compiler for syntactic/compilation filtering; QwQ-32B LLM used as semantic judge during expert iteration.",
            "benchmark_name": "Autoformalization human-curated test set",
            "benchmark_description": "A held-out human-curated set (~1,000 problems) used to evaluate compilation rate and judged semantic correctness of autoformalized Lean 4 statements.",
            "task_type": "Autoformalization (natural language -&gt; Lean 4 statement)",
            "performance_metric": "one-shot Lean 4 compilation rate; judged autoformalization accuracy (%)",
            "performance_value": "one-shot compilation rate ≈ 90%; judged accuracy ≈ 66% (on curated test set)",
            "comparison_with_baseline": "Most external models failed to consistently produce Lean 4 (often produced Lean 3); Kimina-Autoformalizer outperforms them on Lean 4 compilation and judged correctness.",
            "key_findings": "Expert iteration with compilation + LLM judging yields high compilation rates and acceptable semantic accuracy, enabling large-scale generation of training problems for RL; human oversight remains necessary to catch judge false positives.",
            "limitations": "LLM judges can miss semantic mistakes as long as output compiles; requires significant expert monitoring; difficulty ensuring semantic equivalence between informal statement and formalization.",
            "uuid": "e6827.1",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Qwen2.5-72B",
            "name_full": "Qwen2.5-72B (initial backbone)",
            "brief_description": "A foundation LLM used as the initialization point for Kimina-Prover's RL training; provided the transformer backbone and initial policy behavior.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-72B",
            "model_description": "Large decoder-only transformer family of foundation models from the Qwen team; used here as initialization for RL fine-tuning toward formal proof generation.",
            "model_size": "72B",
            "architecture_type": "decoder-only transformer",
            "training_data": "General pretraining corpora (Qwen team resources); later fine-tuned with math-inclined SFT and RL datasets in this paper",
            "reasoning_method": "Pretrained transformer; reasoning capabilities further elicited via supervised fine-tuning and RL in the Kimina pipeline",
            "external_tool_used": null,
            "external_tool_description": "",
            "benchmark_name": "miniF2F (after RL fine-tuning as Kimina-Prover)",
            "benchmark_description": "See Kimina-Prover entry; Qwen2.5-72B served as base pretraining model before formal RL adaptation",
            "task_type": "Foundation model initialization for formal theorem proving",
            "performance_metric": "N/A (serves as base model prior to RL)",
            "performance_value": "",
            "comparison_with_baseline": "Used as backbone; RL fine-tuning (Kimina-Prover) significantly changes task performance compared to vanilla Qwen2.5 behavior (paper reports gains after RL).",
            "key_findings": "A large pre-trained foundation model can be adapted via RL + structured reasoning pattern to achieve strong formal proving; model scaling benefits become visible after RL.",
            "limitations": "Pretrained Qwen-variants without domain-specific SFT/RL struggle with formal Lean syntax and proof generation out-of-the-box.",
            "uuid": "e6827.2",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Qwen2.5-Math-(1.5B/7B)-Instruct",
            "name_full": "Qwen2.5-Math-1.5B-Instruct and Qwen2.5-Math-7B-Instruct",
            "brief_description": "Smaller Qwen variants used as initialization points for distilled Kimina-Prover models (1.5B and 7B distilled variants), trained by SFT on rollouts from Kimina-Prover-72B.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-Math-1.5B-Instruct; Qwen2.5-Math-7B-Instruct",
            "model_description": "Smaller instruction-tuned variants of the Qwen family specialized with math-oriented SFT; used as initialization for distilled Kimina-Prover 1.5B and 7B models.",
            "model_size": "1.5B and 7B",
            "architecture_type": "decoder-only transformer",
            "training_data": "Math-focused SFT data and distilled rollouts from Kimina-Prover-72B",
            "reasoning_method": "Supervised fine-tuning on rollouts distilled from a larger RL-trained model to transfer formal proof capability into smaller checkpoints",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "miniF2F (evaluated after distillation)",
            "benchmark_description": "Same miniF2F formal theorem proving benchmark used to measure distilled model performance relative to the 72B variant.",
            "task_type": "Formal theorem proving (distilled, smaller models)",
            "performance_metric": "pass@k",
            "performance_value": "1.5B and 7B distilled models achieve lower pass rates than 72B but show consistent scaling across sizes (exact numbers reported in paper figures/tables for different budgets)",
            "comparison_with_baseline": "Distilled models underperform the 72B but still gain from Kimina rollouts; demonstrates that RL rollouts can be distilled to smaller models with retained capability.",
            "key_findings": "Distillation from a 72B RL-trained prover produces smaller models (1.5B, 7B) that retain meaningful formal proving ability and follow the observed scaling trend.",
            "limitations": "Smaller models have lower absolute performance and are more sensitive to sample budget; distillation cannot fully close the gap to the 72B model.",
            "uuid": "e6827.3",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Kimi k1.5",
            "name_full": "Kimi k1.5 (RL pipeline / model family)",
            "brief_description": "A prior Kimi-Team reinforcement learning pipeline and model family that demonstrated elicitation of long chain-of-thought reasoning for complex informal math and coding tasks; used as the methodological foundation for Kimina-Prover's RL approach.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Kimi k1.5",
            "model_description": "RL-trained LLM pipeline emphasizing long-form chain-of-thought via carefully designed reward signals and training recipes; used as conceptual and technical groundwork for Kimina-Prover.",
            "model_size": "not specified in this paper",
            "architecture_type": "transformer + RL fine-tuning pipeline",
            "training_data": "Large-scale informal math and coding chain-of-thought data curated by Kimi-Team",
            "reasoning_method": "RL to elicit long chain-of-thought style outputs and reflection; used as inspiration for formal RL in Kimina-Prover",
            "external_tool_used": null,
            "external_tool_description": "",
            "benchmark_name": "Informal math and coding benchmarks (referenced generally)",
            "benchmark_description": "Prior Kimi work evaluated on informal math/coding tasks and competitions (AIME, Codeforces), showing emergent long-form reasoning.",
            "task_type": "Informal long-chain-of-thought reasoning, precursor to formal reasoning work",
            "performance_metric": "Reported improvements on complex informal tasks and competitions (paper references Kimi-Team 2025)",
            "performance_value": "",
            "comparison_with_baseline": "Kimi k1.5 established that RL can induce long-form reflection and chains-of-thought, which Kimina-Prover adapts into formal theorem proving.",
            "key_findings": "RL can be engineered to elicit structured long thinking patterns that aid complex problem solving; adapting these methods to formal domains requires further constraints and verification.",
            "limitations": "Informal reasoning successes do not trivially translate to formal proof generation without specialized SFT, pattern enforcement, and verifiable rewards.",
            "uuid": "e6827.4",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Claude 3.7 Sonnet",
            "name_full": "Claude 3.7 Sonnet (Anthropic)",
            "brief_description": "A general-purpose LLM used here to synthesize auxiliary thinking-block SFT examples combining informal reasoning and formal Lean 4 solutions to bootstrap Kimina-Prover's formal reasoning pattern.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Claude 3.7 Sonnet",
            "model_description": "High-capacity general-purpose LLM (Anthropic) used to generate synthetic paired informal/formal thinking-block outputs for supervised initialization.",
            "model_size": "not specified",
            "architecture_type": "transformer-based LLM",
            "training_data": "Anthropic's proprietary pretraining corpora; used here only as a synthesis tool",
            "reasoning_method": "Chain-of-thought style synthesis to create &lt;think&gt; blocks combining informal and formal proofs for SFT",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "SFT synthesis quality (internal validation)",
            "benchmark_description": "Claude outputs were judged qualitatively; paper reports Claude 3.7 Sonnet produced satisfying synthetic thinking-block examples used to create ~20K mini-SFT dataset.",
            "task_type": "Synthetic generation of informal-formal aligned training samples",
            "performance_metric": "Qualitative suitability for SFT; number of examples synthesized (~20k)",
            "performance_value": "~20K examples synthesized; Claude judged as the only LLM producing sufficiently satisfying outputs among those attempted",
            "comparison_with_baseline": "Other LLMs attempted produced lower-quality thinking blocks; only Claude's output was judged satisfactory for bootstrapping the formal reasoning pattern.",
            "key_findings": "Using a strong general-purpose LLM to synthesize aligned informal-formal thinking blocks can jumpstart RL for formal reasoning.",
            "limitations": "Synthetic outputs may have limited reflection patterns and require mixing with informal math data to avoid low-quality repeated reflections at RL time.",
            "uuid": "e6827.5",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "QwQ-32B",
            "name_full": "QwQ-32B (LLM judge / difficulty rater)",
            "brief_description": "A 32B model used as an automated judge to evaluate semantic correctness of autoformalizations and to assign difficulty ratings to problems for dataset balancing in the RL pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "QwQ-32B",
            "model_description": "Large LLM used in a judge role with a handcrafted prompt and unanimous voting across multiple samples to reduce false positives when evaluating autoformalizations and difficulty.",
            "model_size": "32B",
            "architecture_type": "transformer-based LLM (judge role)",
            "training_data": "Not specified; used as an evaluation/judging tool in expert iteration",
            "reasoning_method": "LLM-based semantic evaluation via prompt engineering and multiple-sample unanimous voting",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "Autoformalizer human-curated validation set",
            "benchmark_description": "A human-curated test set (~1,000 examples) used to optimize and validate the QwQ-32B judge prompt and measure judge reliability.",
            "task_type": "Semantic judging of formalizations and difficulty rating",
            "performance_metric": "Judge-validated autoformalization accuracy; compilation+judged correctness rate",
            "performance_value": "Used in expert iteration that achieved up to 90% compilation and 66% judged accuracy on the autoformalizer test set",
            "comparison_with_baseline": "Multiple-sample unanimous voting using QwQ-32B reduced false positives compared to naive single-sample judging.",
            "key_findings": "LLM-based judges can efficiently scale expert iteration, but require careful prompt engineering and human monitoring to limit false positives.",
            "limitations": "LLM judges can be fooled by compilable-but-incorrect formalizations; blind reliance on judge signals is risky for RL in non-verifiable domains.",
            "uuid": "e6827.6",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Gemini-2.5-pro",
            "name_full": "Gemini 2.5 Pro (general-purpose LLM)",
            "brief_description": "A general-purpose reasoning model compared against Kimina-Prover; while it can solve AIME problems informally, it struggles to produce formally verifiable Lean proofs and often hallucinates invalid proofs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Gemini 2.5 Pro",
            "model_description": "Large general-purpose transformer-based reasoning LLM (Google's Gemini family) evaluated in its default reasoning mode; not specialized for formal proof generation.",
            "model_size": "2.5 (family name; internal size unspecified here)",
            "architecture_type": "transformer-based LLM (general-purpose)",
            "training_data": "Proprietary general web and reasoning corpora (not specified)",
            "reasoning_method": "Informal chain-of-thought reasoning; not optimized for formal proof generation or Lean verification",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "miniF2F (informal vs formal subsets: IMO/AIME)",
            "benchmark_description": "Evaluation on miniF2F benchmark subsets (IMO and AIME) comparing informal solving capacity vs formalized Lean proving.",
            "task_type": "Informal mathematics reasoning and attempted formalization",
            "performance_metric": "pass@32 (formal), informal problem solving success (informal)",
            "performance_value": "pass@32 = 37.70% (miniF2F formal); IMO subset 5.00%; AIME subset 13.33% (formal). Informally, Gemini solves all 15 AIME problems but struggles to formalize them.",
            "comparison_with_baseline": "Underperforms Kimina-Prover substantially on formal tasks (e.g., 68.85% vs 37.70% at pass@32); outperforms some models on informal tasks but fails to formalize reliably.",
            "key_findings": "General-purpose LLMs can solve many informal math problems but exhibit a large gap when asked to produce machine-checkable formal proofs; they are prone to hallucination in formalization.",
            "limitations": "Hallucination and inability to produce verifiable Lean proofs; limited formalization capability despite informal success.",
            "uuid": "e6827.7",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "OpenAI o3 (o3-mini)",
            "name_full": "OpenAI o3 (o3-mini variant)",
            "brief_description": "A general-purpose OpenAI model evaluated as a baseline; capable of solving informal math in some cases but shows very low formal proof pass rates and fails to formalize many solutions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "OpenAI o3 (o3-mini)",
            "model_description": "OpenAI's strong general-purpose reasoning LLM family; evaluated on informal vs formal miniF2F subsets in the paper.",
            "model_size": "model family (size unspecified for o3-mini)",
            "architecture_type": "transformer-based LLM",
            "training_data": "Proprietary large corpora (not specified)",
            "reasoning_method": "Informal chain-of-thought; no specialized Lean integration reported",
            "external_tool_used": false,
            "external_tool_description": "",
            "benchmark_name": "miniF2F (formal evaluation)",
            "benchmark_description": "As above: olympiad-style formal problems in Lean 4; o3 evaluated for formal proof generation success.",
            "task_type": "Informal reasoning and attempted formalization; formal proof generation",
            "performance_metric": "pass@32 (formal)",
            "performance_value": "pass@32 = 24.59% (miniF2F formal); IMO subset 0.00%; AIME subset 6.67% (formal). Informally, o3-mini solves all 15 AIME problems but cannot formalize them.",
            "comparison_with_baseline": "Performs substantially worse than Kimina-Prover on formal tasks; shows the informal-to-formal gap in current general-purpose systems.",
            "key_findings": "Strong informal reasoning ability does not guarantee the capacity to produce verifiable formal proofs; specialized training and RL matter.",
            "limitations": "Poor formalization, high rate of unverifiable/hallucinated proofs.",
            "uuid": "e6827.8",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "BFS-Prover",
            "name_full": "BFS-Prover (Best-First Search based prover)",
            "brief_description": "A prior neural theorem prover that couples an LLM policy with a Best-First Search (BFS) tree search to generate stepwise tactic sequences; used as a key baseline in comparisons.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "BFS-Prover",
            "model_description": "System combining an LLM for tactic prediction with a Best-First Search algorithm to explore proof trees step-by-step; representative of search-based provers.",
            "model_size": "various (previous SOTA reported at specific sizes; exact size not specified here)",
            "architecture_type": "LLM + Best-First Search (tree search hybrid)",
            "training_data": "Supervised data for tactic prediction and training corpora used in cited works (Polu et al., R. Xin et al.)",
            "reasoning_method": "Step-by-step tactic generation guided by BFS search heuristics",
            "external_tool_used": true,
            "external_tool_description": "Search algorithm (BFS) used to explore tactic trees; leverages proof assistant environment for verification during search.",
            "benchmark_name": "miniF2F",
            "benchmark_description": "Same formal olympiad benchmark; BFS-Prover reported previous SOTA values on miniF2F.",
            "task_type": "Stepwise formal theorem proving (tactic-level search)",
            "performance_metric": "pass@k (verification success rate)",
            "performance_value": "Reported prior SOTA on miniF2F: 72.95% (paper reports Kimina-Prover surpasses this)",
            "comparison_with_baseline": "Kimina-Prover surpasses BFS-Prover at large sample budgets (80.74% vs 72.95% at pass@8192) and requires fewer samples for comparable performance due to whole-proof generation and internal exploration.",
            "key_findings": "Search-based approaches are effective but more computationally expensive; they historically did not show clear model-size scaling in formal mathematics, a gap Kimina-Prover addresses.",
            "limitations": "High computational overhead from explicit search; scalability limits; less explainable internal reasoning compared to Kimina's thinking-blocks.",
            "uuid": "e6827.9",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "DeepSeek-R1",
            "name_full": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
            "brief_description": "A recent RL-based reasoning model referenced as prior work demonstrating that large-scale RL with engineered rewards can induce long chain-of-thought behaviors in LLMs for complex tasks; cited as conceptual precedent.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "DeepSeek-R1",
            "model_description": "RL-trained LLM approach from DeepSeek-AI applying reward engineering to incentivize long-form reasoning and reflection.",
            "model_size": "not specified in this paper",
            "architecture_type": "transformer + RL fine-tuning pipeline",
            "training_data": "Task-specific data and RL rollouts; details in cited DeepSeek work",
            "reasoning_method": "Reinforcement learning with reward shaping to promote long chain-of-thought reasoning",
            "external_tool_used": null,
            "external_tool_description": "",
            "benchmark_name": "Informal and formal reasoning benchmarks (cited work)",
            "benchmark_description": "DeepSeek-R1 reported improvements on reasoning tasks through RL; in this paper cited as precedent for RL eliciting long reasoning chains.",
            "task_type": "Long-form reasoning (informal tasks) and inspiration for formal RL",
            "performance_metric": "Reported emergent reasoning improvements on complex math/coding tasks in cited work",
            "performance_value": "",
            "comparison_with_baseline": "Cited as an example where RL with tailored rewards yields reasoning improvements; Kimina adapts similar principles to verifiable formal proof setting.",
            "key_findings": "Large-scale RL can produce emergent long reasoning patterns that benefit complex tasks; adaptation to formal domains requires verifiable rewards and format controls.",
            "limitations": "Prior RL work focused on informal tasks; direct transfer to formal provers was previously unexplored and presents unique verification constraints.",
            "uuid": "e6827.10",
            "source_info": {
                "paper_title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics",
            "rating": 2,
            "sanitized_title": "minif2f_a_crosssystem_benchmark_for_formal_olympiadlevel_mathematics"
        },
        {
            "paper_title": "BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving",
            "rating": 2,
            "sanitized_title": "bfsprover_scalable_bestfirst_tree_search_for_llmbased_automatic_theorem_proving"
        },
        {
            "paper_title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
            "rating": 2,
            "sanitized_title": "deepseekr1_incentivizing_reasoning_capability_in_llms_via_reinforcement_learning"
        },
        {
            "paper_title": "HyperTree Proof Search for Neural Theorem Proving",
            "rating": 2,
            "sanitized_title": "hypertree_proof_search_for_neural_theorem_proving"
        },
        {
            "paper_title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
            "rating": 2,
            "sanitized_title": "ai_achieves_silvermedal_standard_solving_international_mathematical_olympiad_problems"
        },
        {
            "paper_title": "Kimi k1.5: Scaling reinforcement learning with llms",
            "rating": 2,
            "sanitized_title": "kimi_k15_scaling_reinforcement_learning_with_llms"
        },
        {
            "paper_title": "Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs",
            "rating": 1,
            "sanitized_title": "draft_sketch_and_prove_guiding_formal_theorem_provers_with_informal_proofs"
        },
        {
            "paper_title": "Lean-STaR: Learning to Interleave Thinking and Proving",
            "rating": 1,
            "sanitized_title": "leanstar_learning_to_interleave_thinking_and_proving"
        }
    ],
    "cost": 0.02053825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>KIMINA-PROVER PREVIEW : TOWARDS LARGE FORMAL REASONING MODELS WITH REINFORCEMENT LEARNING TECHNICAL REPORT OF KIMINA-PROVER PREVIEW
15 Apr 2025</p>
<p>Kimi Team 
KIMINA-PROVER PREVIEW : TOWARDS LARGE FORMAL REASONING MODELS WITH REINFORCEMENT LEARNING TECHNICAL REPORT OF KIMINA-PROVER PREVIEW
15 Apr 20259C05CF5C92458E9BB40CB82C392D16B8arXiv:2504.11354v1[cs.AI]
We introduce Kimina-Prover Preview, a large language model that pioneers a novel reasoning-driven exploration paradigm for formal theorem proving, as showcased in this preview release.Trained with a large-scale reinforcement learning pipeline from Qwen2.5-72B,Kimina-Prover demonstrates strong performance in Lean 4 proof generation by employing a structured reasoning pattern we term formal reasoning pattern.This approach allows the model to emulate human problem-solving strategies in Lean, iteratively generating and refining proof steps.Kimina-Prover sets a new state-of-the-art on the miniF2F benchmark, reaching 80.7% with pass@8192.Beyond improved benchmark performance, our work yields several key insights: (1) Kimina-Prover exhibits high sample efficiency, delivering strong results even with minimal sampling (pass@1) and scaling effectively with computational budget, stemming from its unique reasoning pattern and RL training; (2) we demonstrate clear performance scaling with model size, a trend previously unobserved for neural theorem provers in formal mathematics; (3) the learned reasoning style, distinct from traditional search algorithms, shows potential to bridge the gap between formal verification and informal mathematical intuition.We open source distilled versions with 1.5B and 7B parameters of Kimina-Prover 1 .</p>
<p>Figure 1: Performance comparison of different theorem proving methods on miniF2F-test dataset.The x-axis shows the sample budget (number of language model queries), and the y-axis shows the pass rate.Methods are divided into two categories: whole-proof generation and tree search approaches.Results demonstrate that Kimina-Prover Preview achieves the highest pass rate with fewer samples, while tree search methods generally require more samples to achieve comparable performance.</p>
<p>Introduction</p>
<p>Recent advances in neural theorem proving have focused on leveraging large language models (LLMs) to tackle the inherent challenges of formal reasoning in proof assistants like Lean 4 (Moura et al. 2021) or Isabelle (Nipkow et al. 2002).Initial approaches focused on training LLMs to generate individual proof steps or tactics within interactive proof assistants (Polu et al. 2022;Wu et al. 2024;H. Wang et al. 2023;Deepmind 2024), often coupling the LLM's predictive capabilities with classical search algorithms like Best-First Search (BFS) (Polu et al. 2022;Wu et al. 2024;R. Xin et al. 2025) or Monte Carlo Tree Search (MCTS) (Lample et al. 2022;H. Wang et al. 2023;Deepmind 2024) to explore the proof space.Other strategies involved training models to generate entire proof structures from a given state (H.Xin et al. 2024;Y. Lin et al. 2025;First et al. 2023).Despite notable progress, these existing methods face significant challenges.The reliance on explicit search algorithms (BFS, MCTS) introduces substantial computational overhead and complexity, limiting scalability.Furthermore, while LLMs excel at pattern matching and sequence generation, effectively capturing the deep, structured, and often non-linear reasoning required for complex formal proofs remains difficult.Standard supervised fine-tuning or basic chain-of-thought prompting may not sufficiently elicit the sophisticated reasoning necessary.Critically, previous neural theorem provers tailored for formal mathematics have generally not demonstrated clear improvements in performance corresponding to increases in model size, suggesting limitations in their ability to leverage larger model capacity for enhanced reasoning.While some works (H.Lin et al. 2025; R. Wang et al. 2025) attempted to integrate informal reasoning hints, they typically relied on shorter chain-of-thought patterns or models not specifically optimized for long-form reasoning via reinforcement learning.</p>
<p>In this work, we introduce Kimina-Prover Preview, representing an early attempt to bridge this gap by pioneering a novel reasoning-driven exploration paradigm for formal theorem proving.Built upon the Kimi k1.5 reinforcement learning (RL) pipeline, which has demonstrated success in eliciting long chain-of-thought reasoning for complex informal math and coding tasks (Kimi-Team et al. 2025), Kimina-Prover is specifically adapted for formal reasoning within the Lean 4 proof assistant.Instead of relying on external search algorithms, our approach leverages the LLM's own internal reasoning capabilities, enhanced through large-scale RL with carefully designed reward signals and structured reasoning patterns.This allows the model to emulate human problem-solving strategies, implicitly exploring the proof space and iteratively generating and refining proof steps through a process guided by its internal reasoning tokens.Our contributions include:</p>
<p>• Pioneering Reasoning-Driven Exploration.We pioneer the application of large-scale reinforcement learning to elicit long chain-of-thought reasoning in theorem proving.</p>
<p>• Effective Model Scaling for Formal Mathematics.We show clear improvements in neural theorem proving performance as LLM size increases, a scaling effect not observed in previous systems.</p>
<p>• State-of-the-Art Performance.Illustrated in Figure 1, Kimina-Prover achieves state-of-the-art performance by reaching 80.7% with pass@8192 on the miniF2F benchmark, significantly surpassing prior SotA achieved by BFS Prover (R. Xin et al. 2025) (72.95%).</p>
<p>Methodology 2.1 Autoformalization for Constructing a Diverse Base Problem Set</p>
<p>To enable online reinforcement learning for formal theorem proving, we require a large, diverse set of formal problems in Lean 4. Manual construction of such a dataset is costly and time-intensive.To address this, we train models to automatically translate natural language problem statements into syntactically valid Lean 4 code ending with a placeholder proof.However, this task presents a fundamental challenge: the lack of a concrete, automatic reward signal.Unlike proof search, where success is easily defined by whether a theorem is proven, there is no straightforward way to verify the correctness of a generated formal problem statement with respect to the natural language input.Our solution combines careful initialization, supervised fine-tuning, and a structured expert iteration process with LLM-based judging to progressively improve quality.We open source our model Kimina-Autoformalizer-7B for the community and detail our training recipe in Appendix C.2.</p>
<p>Formal Reasoning Pattern</p>
<p>One of the critical challenges for reasoning LLMs to excel at formal theorem proving is the lack of alignment between informal mathematical reasoning data and its translation to formal proofs.To tackle this, we design a novel formal reasoning pattern to enable Kimina-Prover to think in an environment that aligns the informal and formal mathematical reasoning.During training, we filter for responses that format their thinking in between <think> ... </think> tokens and output the final proof between chosen special tokens.Within the thinking block, we seek informal-formal alignment by interspersing informal reasoning with relevant Lean 4 code snippets, also marked by special tokens.To enforce thinking block alignment with the final proof, we ensure that the majority of the Lean 4 code snippets appear in the final proof.With this reasoning pattern (see Figure 2 on the left), we observe scaling of output token length, which correlates with passing proof-complexity from our evaluations.</p>
<p>Additionally, this pattern also offers great improvement in terms of reasoning explainability compared to search-based provers.The thinking block allows users to inspect the models' internal process during proof generation.This provides tangible insights about the nature of the failure modes of the model and serves as an educational tool for end-users.</p>
<p>Cold start.To kickstart the models' ability to output formal proofs following our formal reasoning pattern, we perform a minimal supervised fine-tuning run before starting our reinforcement learning training loop.In particular, we collect a dataset of olympiad-style mathematics problems with statements and solutions both in natural language format and formalized in Lean 4. We then ask Claude 3.7 Sonnet (Anthropic 2025) to synthesize a thinking block output combining the the informal and formal proofs to synthesize a mini-SFT dataset of around 20K examples (we have tried several LLMs and only Claude's performance is satisfying).This significantly boosts the models' ability to align the informal and formal reasoning steps and enhances downstream performance during the RL phase.</p>
<p>Informal math mix-training.To further bolster the initial informal mathematical capabilities of our model, we incorporate informal mathematical thinking data from Kimi k1.5 into the SFT training.The synthetic data generated by Claude exhibited a limited range of reflection patterns.While we observed the emergence of test-time scaling and reflection during subsequent RL training, these reflections were often of low quality, characterized by repetition and meaningless phrases.Integrating informal thinking data aims to provide a better starting point for generating more meaningful reflections.Indeed, our experiments during the RL phase demonstrate that checkpoints trained with this mixed data significantly outperform those trained solely on formal reasoning data.</p>
<p>Reinforcement Learning</p>
<p>Following the supervised fine-tuning (SFT) phase, we employ reinforcement learning (RL) to further enhance our model's formal theorem-proving capabilities, as illustrated in the pipeline schematic (Figure 2).The RL process iteratively refines the model's policy.Each iteration begins by sampling a batch of N = 1000 problems from our established problem set.For each problem, the current policy generates k = 8 candidate solutions (rollouts).The final Lean 4 code of each candidate is then rigorously verified using the Lean compiler to determine correctness.A binary reward signal is assigned: 1 for a completely correct proof and 0 otherwise.In line with the methodology of Kimi k1.5 (Kimi-Team et al. 2025), we employ the following loss to optimize the language model:
L(θ) = E (x,y * )∼D E (y,z)∼πold r(x, y, y * ) − τ log Z − τ log π θ (y, z|x) π old (y, z|x) ,(1)
where π old is the previous policy model and the normalization constant log Z is approximated using the empirical mean of the rewards in practice.During RL training, we see strong scaling of formal reasoning at test time.However, limited SFT data and formal structure cause early RL format collapse from negative gradients.To prevent this, we apply format filtering with two key constraints: (1) each generated sample must contain at least one tactic block; and (2) tactic blocks must collectively cover at least 60% of the Lean code included in the final Lean 4 solution.Moreover, To counter format collapse from negative gradients, we randomly discard samples with negative gradients (probability ω = 0.5).</p>
<p>Combined with mixed training on informal math data, this stabilizes training and promotes more sophisticated formal reasoning.</p>
<p>In practice, our RL training is conducted starting from Qwen2.5-72B (Qwen-Team 2024).We maintain a constant learning rate of (2 × 10 −6 ) and a fixed KL divergence coefficient τ = 0.4 (Equation 1).This KL constraint ensures stability by controlling the policy's deviation from the initial supervised policy throughout the RL process.</p>
<p>3 Results</p>
<p>Inference Setup</p>
<p>Benchmark.We evaluate our models on the miniF2F benchmark (K.Zheng et al. 2022), using the Lean 4 version from DeepSeek-ProverV1.5.To prevent data contamination, we perform 13-gram decontamination and explicitly remove all AMC12, AIME, and IMO problems from the Numina Math 1.5 training set if their sources overlap with problems in the miniF2F test set.We also identify and correct eight unsolvable problems in the benchmark (mathd_numbertheory_618, aime_1994_p3, amc12a_2021_p9, mathd_algebra_342, mathd_numbertheory_343, mathd_algebra_158, induction_pord1p1on2powklt5on2, induction_prod1p1onk3le3m1onn), releasing the corrected versions via the Numina HuggingFace repository.Evaluations utilize a 32K token context length and sampling budgets up to 8192 attempts, with each attempt sampled independently.</p>
<p>Distillation.We train our 1.5B and 7B models by rolling out data from the Kimina-Prover-Preview model with 72B parameters and performing SFT, initializing from Qwen2.5-Math-1.5B-Instructand Qwen2.5-Math-7B-Instruct,respectively.We use packing and cosine learning rate scheduling with lr = 2 × 10 −5 for 3 epochs.</p>
<p>Lean Server.In our reinforcement learning and evaluation pipelines, we integrate the Numina Lean Server (Numina 2025) as the verification backend to provide real-time feedback for generated proof attempts.Built upon Lean FRO's LeanREPL (Lean FRO 2023), the Numina Lean Server employs an LRU-based caching mechanism that reuses preloaded environments based on import headers, significantly reducing initialization overhead.Furthermore, it supports extensive parallelization across multiple CPUs by managing multiple Lean REPL processes concurrently.These innovations result in a 10× speedup in verification throughput, achieving up to 100 iterations per second on machines equipped with 64 CPU cores and 512 GB RAM.During RL training, this verification system operates efficiently in the rollout phase, evaluating proofs in real time as they are generated.Due to the relatively slow proofgeneration process, verification does not become a bottleneck, requiring only 640 CPU cores for training.This efficiency contrasts with previous language model-based theorem proving approaches, which typically require thousands of CPU cores to sustain real-time verification at scale (Lample et al. 2022;H. Xin et al. 2024).</p>
<p>Performance Analysis</p>
<p>Comparison with State-of-the-Art Methods</p>
<p>On the miniF2F benchmark, Kimina-Prover Preview achieves a state-of-the-art result among all evaluated systems-including both whole-proof generation and tree search methods-reaching 80.74% miniF2F-test accuracy (see Table 1).Importantly, Kimina-Prover demonstrates strong performance even in low-pass settings and scales effectively with higher sampling budgets.With just pass@1, the model already achieves 52.94%, and with pass@32, it reaches 68.85%, already competitive with or surpassing many larger-sample baselines, showcasing exceptional sample efficiency.This efficiency can be attributed to Kimina-Prover's novel reasoning process.Rather than relying on explicit step-based searches, Kimina-Prover implicitly flattens the step-wise search, allowing the model to decide both how and what to search.This architectural flexibility enables more targeted and dynamic reasoning, leading to higher performance with fewer samples.</p>
<p>Another key observation (see Figure 3) is that our models present a clear upward trend in performance as model size increases -from 1.5B, to 7B, and finally 72B.Especially with larger sampling budgets, the 72B variant shows significant gains (the 72B model outperforms the 7B version by +0.44%, +5.75%, and +7.87% at those respective sampling budgets.).To our knowledge, this is the first formal reasoning system that consistently scales in performance with model size, suggesting that Kimina-Prover not only scales computationally but also in its reasoning capabilities.</p>
<p>Comparison with General Purpose LLMs</p>
<p>In Table 2. we compare Kimina-Prover with leading general-purpose reasoning models-OpenAI's o3 and Gemini 2.5 Pro-on the miniF2F benchmark and its IMO and AIME subsets.Despite these subsets containing relatively easier, older problems, Kimina-Prover significantly outperforms both models across the board.At pass@32, Kimina-Prover achieves 68.85% on miniF2F, versus 37.70% for Gemini and 24.59% for o3.On the IMO and AIME subsets, Kimina-Prover scores 20.00% and 46.67%, respectively-well above Gemini (5%, 13.33%) and o3 (0%, 6.67%).At pass@8192, Kimina-Prover further improves to 80.74%, 40.00% (IMO), and 86.67% (AIME).These results highlight a core limitation of general-purpose models.o3 and similar systems fail at formal reasoning, defaulting to informal, unverifiable answers.Gemini shows formal reasoning capabilities but often suffers from hallucination and generates invalid proofs.In contrast, Kimina-Prover consistently generates formally verifiable, Lean-checkable proofs, demonstrating both accuracy and reasoning ability.Gemini 2.5 and Openai o3-mini can solve all 15 AIME problems in miniF2F using informal reasoning, both models struggle to formalize these solutions.This highlights a significant gap between informal reasoning capacity and formal reasoning capabilities in current state-of-the-art models.</p>
<p>Gap between Informal Mathematics and Formal Mathematics</p>
<p>One particularly interesting finding is that our formal reasoning model shows strong potential to bridge the gap between formal and informal mathematics.As shown in Table 2, while general-purpose reasoning models such as Gemini-2.5-proand o3-mini are capable of solving all AIME problems in miniF2F under informal settings, they exhibit substantially lower performance in formal mathematics.This discrepancy suggests that transferring domain knowledge from general mathematical problem solving to formal mathematical reasoning remains a challenging task.In contrast, Kimina-Prover's formal reasoning capabilities demonstrate that formal mathematics can complement and enhance informal reasoning, rather than exist in isolation.By learning to reason within a formal system, the model appears to gain deeper structural understanding, which could in turn benefit informal mathematical problem solving.This opens exciting future directions, where formal mathematics may not only be useful for verification, but also for boosting model performance on informal math reasoning tasks.</p>
<p>Test Time Scaling in Formal Reasoning</p>
<p>A key capability of reasoning models is their ability to improve with increased test-time budget.Figure 4 shows how Kimina-Prover's miniF2F pass@32 accuracy (blue) correlates with the average token length of its outputs (orange) over training.As the model learns to generate longer proofs-from 2,500 to over 10,000 tokens-its accuracy rises from 61.8% to nearly 69%.Unlike informal math models, which often scale smoothly, formal reasoning shows a much more volatile pattern.Accuracy jumps are frequent and sometimes regress, especially in the mid-phase between 50-150 iterations, likely due to the model adjusting to complex, structured reasoning with limited formal training data.This turbulent but ultimately successful trend highlights how formal reasoning can still scale effectively, even without vast pretraining corpora.This success suggests that similar reasoning approaches may be transferable to other domains that are also limited in domain knowledge during pre-training.</p>
<p>3.2.5 Emergent human-like proof style.</p>
<p>Given the described formal reasoning pattern, we observe that after initialization and RL training, our model demonstrates the ability to produce complex reasoning patterns.These include exploring multiple reasoning paths, reflecting on and refining its thinking process, and analyzing small-scale cases to uncover general patterns (see Appendix F).</p>
<p>Additionally, the proofs generated by Kimina-Prover are more decomposed and structured compared to those of previous step-based provers.This is exhibited by the abundance of have statements within the proofs, which is a common pattern observed in human-written proofs optimized for clarity (see Appendix E).These emergent behaviors of reflection, decomposition, and refinement scale effectively with increasing problem difficulty, giving our approach a distinct advantage over models that extensively rely on existing Lean 4 automation tools.</p>
<p>Conclusion</p>
<p>In conclusion, we present Kimina-Prover, a large reasoning model for Lean 4 theorem proving developed through a training recipe combining autoformalization, SFT, and RL with a specific formal reasoning pattern.Our key findings demonstrate that performance scales significantly with both context length and model size-a trend not typically observed in tree-search provers-leading to state-of-the-art results (80.74% on miniF2F pass@8192) with modest compute.This underscores the potential of reasoning-enabled neural provers.Promising future directions include enhancing proof quality by filtering outputs that overuse high-level tactics, enabling iterative refinement using Lean compiler feedback to fix errors efficiently, and integrating external tools like library search and computation engines to alleviate generation challenges.</p>
<p>A Contributions Large-scale reinforcement learning has recently been applied to improve the reasoning abilities of language models, exemplified by models such as OpenAI's o1 (OpenAI et al. 2024), DeepSeek's R1 (DeepSeek-AI 2025), and Kimi's k1.5 (Kimi-Team et al. 2025).These models, trained with extensive RL on carefully engineered reward signals, exhibit emergent long chain-of-thought reasoning behavior, enabling them to achieve impressive results in complex mathematical and coding tasks, including competitions like AIME and Codeforces.These achievements underscore the potential for long, structured reasoning in overcoming challenging reasoning problems.</p>
<p>A few recent works have attempted to integrate informal reasoning with formal theorem proving.For instance, H. Lin et al. 2025 proposed generating informal thoughts prior to predicting individual tactics, and R. Wang et al. 2025 employs a structured interaction between informal natural language reasoning and formal verification in Lean 4.However, these previous attempts either relied on conventional short-form chain-of-thought reasoning or relied on reasoning models trained via transfer learning from general reasoning tasks and supervised fine-tuning rather than reinforcement learning.Prior to our work, the feasibility and effectiveness of applying RL-driven long-form reasoning directly within formal theorem proving remained unexplored.</p>
<p>C Training Details of Kimina-Prover</p>
<p>C.1 Informal Dataset</p>
<p>The informal dataset serves as the foundational layer of our pipeline, feeding directly into supervised fine-tuning (SFT) and reinforcement learning (RL) for the large formal reasoning model.Below, we outline the data processing steps that convert the raw informal mathematical dataset into a curated prompt set for training our models.</p>
<p>Our informal data pipeline consists of the following steps:</p>
<ol>
<li>Initial Dataset Acquisition: We begin with the Numina 1.5 dataset (J.Li et al. 2024), a comprehensive collection of mathematical problems.2. Filtering and Preprocessing: We filter this dataset based on specific criteria, retaining only problems clearly classified as either proofs or problems with explicit numeric or symbolic outputs.Problems involving geometry and combinatorics are excluded to form a dataset more suitable for autoformalization.This filtered dataset is denoted by auto-statement-candidates.</li>
</ol>
<p>Autoformalization:</p>
<p>The auto-statement-candidates dataset undergoes an automatic formalization process, resulting in the auto-statements dataset.This step converts natural language mathematical problems into formal statements compatible with the Lean 4 proof assistant.4. Human Annotation and Refinement: To ensure the quality and precision of formalizations, we established a dedicated annotation team tasked with reviewing and refining the outputs from the autoformalization process.Annotated outputs are categorized as follows:</p>
<p>• Human Statements: Statements refined by human annotators.</p>
<p>• Human Proofs: Select, challenging statements are further annotated with formal proofs by domain experts.These proofs constitute a significant portion of our supervised fine-tuning (SFT) dataset. 5. Prompt Set Creation: The refined formalized statements from the auto-statements and human statements datasets are combined to form our final prompt set.The validated and proven formal statements subsequently enrich the SFT dataset, creating a dynamic cycle of continuous improvement for subsequent iterations of reinforcement learning.</p>
<p>This structured and iterative approach ensures robust data quality, facilitating effective model training and iterative refinement in subsequent phases.</p>
<p>C.2 Training Details of Kimina-Autoformalizer</p>
<p>C.2.1 Model Initialization</p>
<p>We begin by creating a supervised fine-tuning dataset for autoformalization, to teach the model the structure and style of competition-level Lean 4 problems.This dataset aggregates formal problem pairs from multiple sources: PutnamBench, miniF2F, ProofNet, and Compfiles (Renshaw 2024) (K.Zheng et al. 2022) (Tsoukalas et al. 2024) (Azerbayev et al. 2023).We ablate the contribution of each source and find that all positively contribute to downstream performance.In particular, including Mathlib data, such as the MMA dataset (Jiang et al. 2023b) -an LLM-generated informalization of Mathlib -degrades performance.We hypothesize two key reasons: (1) the mathematical content in Mathlib is substantially different in nature and tone from competition problems, and (2) Mathlib statements often involve auxiliary variables and rely on external definitions, which may confuse the model during generation.Our initialization is a fine-tuned version of Qwen2.5-Coder-7B-Instruct on the curated dataset, capable of producing syntactically valid Lean 4 problem statements from informal descriptions.</p>
<p>C.2.2 Expert Iteration with LLM Judge</p>
<p>After supervised initialization, we employ a structured expert iteration loop to improve the quality and coverage of the autoformalization model.This loop uses a challenging subset of competition-style problems from the NuminaMath 1.5 dataset.For each iteration, we begin by sampling a minibatch of informal problems.For each problem, the model generates a number of candidate formalizations.These are filtered to retain only those that compile successfully in Lean 4. We then employ a QwQ-32B as a judge to evaluate the semantic correctness of each remaining formalization, using a handcrafted prompt to guide its assessment.We observe that using multiple samples from the judge model and unanimous voting structure significantly reduces the amount of false positives with little impact on true positives.Formalizations that pass both the compilation and judging stages are added to the training dataset, and a training step is performed.</p>
<p>Since the reward signal in this task is inherently fuzzy, and LLM-based feedback is susceptible to false positives, we monitor model outputs throughout training with Lean 4 experts and gradually improve the judge prompt over iterations.This allows us to maintain fine-grained control over the data quality.As our proving infrastructure improves, we also introduce automated filters to discard problematic formalizations.These include detecting logical contradictions, proving the negation of the formalized statement, or identifying that the problem is trivial via a short LLM-generated proof.These safeguards help ensure the training set remains both challenging and correct, guiding the model toward meaningful improvements in future iterations.To evaluate our autoformalizer, we use a human-curated test set of size approximately 1,000 and optimize an LLM judge prompt on this set for reliable results.After each iteration, we generate one autoformalization per problem using greedy decoding.We track two metrics: (1) Lean 4 compilation rate and (2) autoformalization accuracy, defined as the percentage of samples that both compile and are judged correct by the LLM.We observe steady and reliable improvement over iteration as can be seen in the plots, reaching 90% one-shot compilation rate and 66% accuracy.</p>
<p>C.2.3 Kimina-Autoformalizer Performance</p>
<p>We evaluate several existing models for autoformalization tasks, but found that most struggled to generate valid Lean 4 code consistently.Instead, these models predominantly produced Lean 3 syntax, a limitation we attribute to the composition of their pretraining data.Prior to these LLMs' knowledge cutoff dates, Lean 3 dominated online repositories and documentation, while Lean 4-with its substantial syntax differences-remained relatively new and underrepresented.This training data imbalance caused models without specific Lean 4 fine-tuning to default to the more familiar Lean 3 patterns.The inability of comparison models to produce compilable Lean 4 code at meaningful rates ultimately prevented us from establishing fair benchmarks against existing approaches, highlighting the challenges of working with emerging formal languages.</p>
<p>We note that this method required careful expert monitoring as we observe that the model would repeatedly make mistakes that the LLM judge model cannot catch, as long as it passed compilation.We believe this presents a significant challenge in applying reinforcement learning in non-verifiable domains.</p>
<p>C.3 Problem Set</p>
<p>In this section, we detail the creation of our problem set, which serves as a foundational component of our reinforcement learning pipeline.The prompt set consists of two distinct subsets: one derived from the autoformalization model and another consisting of human-annotated statements.To ensure balanced difficulty across the problem set, we utilize the QwQ-32B preview model to assign a difficulty rating to each problem and subsequently construct a dataset with an evenly distributed difficulty spectrum.</p>
<p>Given that our annotated statements are limited in number-approximately 10k-compared to the 100k generated by autoformalization, we prioritize high-quality data in training.Therefore, we resample our annotated set to achieve a 1:1 ratio with the autoformalized subset, yielding a balanced and high-quality problem set of 200k total problems.</p>
<p>To further improve the efficiency and effectiveness of the reinforcement learning pipeline, we iteratively refine the prompt set using the following strategies:</p>
<p>Error Filtering via Negation Proving.We employ DeepSeek-Prover's negation-proving to identify and remove potentially erroneous formalizations from our problem set.</p>
<p>Adaptive Problem Pruning.After specific iterations of reinforcement learning, we prune problems where the model consistently demonstrates high proficiency.This adaptive pruning allows the model to concentrate computational resources on increasingly challenging and informative problems, promoting continuous improvement in formal reasoning capabilities.</p>
<p>Annotation Pipeline for Difficult Problems.For wrongly formalized statements or very difficult problems, we send them to the annotation pipeline for additional statement and proof annotation by human annotators.This ensures that challenging problems are not discarded but receive appropriate human oversight.</p>
<p>Post-RL Validation.After reinforcement learning training, we use a judge model to assess whether the proofs generated by the model are correct or if the model has merely leveraged a mistake in the formalization.This step ensures the integrity and reliability of the generated proofs.</p>
<p>D Illustrative Proof Examples found by Kimina-Prover</p>
<p>D.1 Newly Proved IMO problem from the miniF2F Benchmark Kimina-Prover successfully proves an IMO problem (imo_1968_p5_1) that no previous publicly released model has ever solved.We present the proof generated by Kimina-Prover below.This proof shows an excellent ability of the model to plan its proof sketch.Such emergent behavior in the output shows a clear improvement in reasoning ability compared to previous models.For example, in this proof, the model begins by first stating a key auxiliary lemma h2 and continues to prove it across multiple lines.This is followed by guessing the correct answer via the (use 2 * a) tactic.The proof is completed via a complex reasoning chain, where the previously proved lemma h2 is key and necessary to complete the proof.Listing 1: Lean 4 proof of IMO 1968 P5 (1 st part) found by Kimina-Prover.</p>
<p>D.2 Example Proofs of AIME Problems</p>
<p>Kimina-Prover excels at solving complex trigonometric equations in the formal theorem proving domain.This is shown in its proof of aime_1991_p9 presented below.Given the initial hypothesis h0 stated as: h0 : 1 / Real.cos x + Real.tan x = 22 / 7, the model is able to use the trigonometric identity have h3 : Real.sin x ^2 + Real.cos x ^2 = 1 := Real.sin_sq_add_cos_sq x to derive the values for the sine and cosine functions.Kimina-Prover also excels at carrying out long calculations using the Lean 4 tactic calc.This is shown in the proof of aime_1997_p9 presented below.We would especially like to draw attention to the calc blocks required to prove statements h32, h33, . .., h34. in this proof.These calculation steps require careful and precise consideration of the current proof context and cannot rely solely on Lean 4's automation tactics, which shows deep understanding of the formal theorem proving domain.</p>
<p>D.3 Example of Formal Reasoning Pattern</p>
<p>The following list demonstrates the formal reasoning pattern of Kimina-Prover.Upon receiving the problem, the model first uses natural language reasoning to get a general proof idea.Then, it proceeds to formalize its thoughts to Lean 4 code step by step.In this process, the model further ensures the rigor of the reasoning and deliberates on how to effectively utilize appropriate tactics to formalize the proof.Upon completion of the proof, the model assembles all Lean code snippets to form a coherent and complete Lean proof.</p>
<p>Input:</p>
<p>--In an arithmetic sequence, the 7th term is 30, and the 11th term is 60.Determine the 21st I'm given that in an arithmetic sequence, the 7th term is 30, and the 11th term is 60.I need to find the 21st term.</p>
<p>First, let's think about the structure of an arithmetic sequence.The general term of an arithmetic sequence is given by a n = a + (n − 1)d, where a is the first term and d is the common difference.</p>
<p>Given:</p>
<h2>-The 7th term a 7 = a + 6d = 30 We need to find a + 20d.</h2>
<p>From the two equations, we can eliminate a to solve for d.Subtracting h 0 from h 1 :</p>
<p>E Proof Comparison against BFS-Prover</p>
<p>The performance of all previous provers on the miniF2F benchmark shows that BFS-Prover solved the most IMO problems -five in total: imo_1959_p1, imo_1960_p2, imo_1962_p2, imo_1964_p2, and imo1983_p6.Kimina-Prover was able to correctly prove all five of these problems.Below, we select one example imo_1962_p2 to compare the proofs generated by BFS-Prover and Kimina-Prover.</p>
<p>We observe that Kimina-Prover generates proofs by decomposing the argument into a sequence of 'have' statements, resulting in a clear and highly readable logical structure.In contrast, the proof produced by BFS-Prover-which relies on step-by-step tactic search-makes it difficult to discern the purpose of each step directly from the code.This comparison highlights the strong proof sketch planning capabilities of Kimina-Prover.First, let's think about the structure of the problem.We're given that a, b, and c are positive real numbers satisfying the triangle inequality, and we need to prove that a certain expression is non-negative.</p>
<p>......One possible approach is to consider symmetry or substitution.However, this expression isn't symmetric -it's cyclic.So we need to find a way to handle the cyclic structure.Another approach is to use the substitution for triangular inequalities.Since a, b, and c form a triangle, we can set:
-a = x + y -b = y + z -c = z + x ......
Alternatively, we can try to rewrite the inequality in a different form.Let's expand the expression:
a 2 b(a − b) + b 2 c(b − c) + c 2 a(c − a) = a 3 b − a 2 b 2 + b 3 c − b 2 c 2 + c 3 a − c 2 a 2 ......
Another approach: Use the identity that for any real numbers x, y, z: After numerous unsuccessful attempts, the model backtracks to its initial approach and conducts in-depth analysis.In this way, it identifies a crucial simplification of the original equality, which ultimately leads to the successful resolution of the problem.
x 3 + y 3 + z 3 − 3xyz = (x + y + z)(x 2 + y 2 + z 2 − xy − yz − zx) ......
Alternatively, we can use the substitution a = x + y, b = y + z, c = z + x as before, and try to prove the resulting expression is non-negative.</p>
<p>After expanding, we had the expression in terms of x, y, z:
(y + z) 2 (z + x)(y − x) + (z + x) 2 (x + y)(z − y) + (x + y) 2 (y + z)(x − z) ≥ 0
Let's try to expand this.</p>
<p>First term:
(y + z) 2 (z + x)(y − x) = (y 2 + 2yz + z 2 )(z + x)(y − x) = (y 2 + 2yz + z 2 )(yz + xy − xz − x 2 )
This expands to:
= y 3 z + xy 3 − xy 2 z − x 2 y 2 + 2y 2 z 2 + 2xy 2 z − 2xyz 2 − 2x 2 yz + yz 3 + xyz 2 − xz 3 − x 2 z 2
This is complex, but after expanding all terms and simplifying, it can be rewritten as a sum of squares:
(y − z) 2 (y + z)(x + y + z) + (z − x) 2 (z + x)(x + y + z) + (x − y) 2 (x + y)(x + y + z)
This sum is clearly non-negative because it's a sum of squares multiplied by positive terms.</p>
<p>Therefore, in Lean, after substitution and expansion, we can prove the resulting expression is non-negative.</p>
<p>The complete Lean proof would be:</p>
<ol>
<li>Introduce x, y, z as above In addressing this problem, the model initially struggles with the complexity of the expanded expression but revisits its earlier approaches with a deeper analysis.This reflects a "human-like" problem-solving process -trying, failing, and refining.One possible method is to fix some of the variables and solve for the others.For example, if we fix a = 3, then we need 3 • b + c • d = n, with b, c, d odd and &gt; 1.</li>
</ol>
<p>......But let's think differently.Since n is even, we can write it as n=2m, and m can be either even or odd.</p>
<p>Alternatively, think of n as being in different congruence classes mod 6 or mod 12 to find a suitable decomposition.</p>
<p>Alternatively, think of n as either 4 mod 6 or 2 mod 6 (since even numbers can be 0 mod2, and further classified as 0,2,4 mod6) But this might complicate things.</p>
<p>Alternatively, use a more direct approach: construct the numbers.</p>
<p>For example, for n=40 (which is 4 mod 6), we found 3<em>5 +5</em>5</p>
<p>For n=42 (0 mod6), we found 3<em>3 +3</em>11 To formalize a proof, we can separate into cases based on n mod6:</p>
<p>Case 1: n ≡ 0 mod6.Then n=6k.If k is odd or even, we can use similar approaches as above.For n=6k, we can write n=3<em>3 +3</em>(2k-3).For example, n=42=6<em>7: 3</em>3 +3<em>11.Here 2k-3=2</em>7-3=11.</p>
<p>Case 2: n ≡ 2 mod6.Then n=6k+2.For example, n=44=6*7+2.We need to express 6k+2 as a sum of two products.</p>
<p>...... Now, to complete the proof in Lean, we need to combine these three cases: The model successfully solved the problem, demonstrating notable constructive reasoning ability.The approach begins by strategically assuming 3 as one of the odd numbers, achieving significant simplification.Then by observing small-scale cases, it identified distinct patterns for each residue class of n modulo 3. Finally, the model systematically verified each case through rigorous reasoning.This "observation of small cases → conjecture formulation → rigorous proof" approach represents a highly successful pattern in mathematical proof.Wait, the Lean proof is trying to prove x 2 ≤ 4 directly.Let's see why that's true:</p>
<p>From y 2 + 3x 2 y 2 = 30x 2 + 517</p>
<p>Rearranged: y 2 (3x 2 + 1) = 30x 2 + 517</p>
<p>Figure 2 :
2
Figure 2: Left.Formal Reasoning Pattern.Right.Formal RL pipeline.</p>
<p>Figure 3 :
3
Figure 3: Performance scaling of Kimina-Prover models across different sizes.</p>
<p>Figure 4 :
4
Figure 4: miniF2F accuracy (pass@32) and average output token length of Kimina-Prover during training.</p>
<p>Figure 5 :
5
Figure 5: Performance of Autoformalizer Across Iterations.</p>
<p>theorem imo_1968_p5_1 (a : R) (f : R → R) (h0 : 0 &lt; a) (h1 : ∀ x, f (x + a) = 1 / 2 + Real.sqrt (f x -f x ^2)) : ∃ b &gt; 0, ∀ x, f (x + b) = f x := by have h2 : ∀ x, 0 ≤ f x ∧ f x ≤ 1 := by intro x have h1 := h1 (x -a) rw [show x -a + a = x by ring] at h1 have h3 : 0 ≤ Real.sqrt (f (x -a) -f (x -a) ^2) := Real.sqrt_nonneg (f (x -a) -f (xa) ^2) have h4 : f x = 1 / 2 + Real.sqrt (f (x -a) -f (x -a) ^2) := by linarith have h5 : f x ≤ 1 := by have h6 : Real.sqrt (f (x -a) -f (x -a) ^2) ≤ 1 / 2 := by have h7 : f (x -a) -f (x -a) ^2 ≤ 1 / 4 := by nlinarith [sq_nonneg (f (x -a) -1 / 2)] have h8 : 0 ≤ Real.sqrt (f (x -a) -f (x -a) ^2) := Real.sqrt_nonneg (f (x -a) -f (x -a) ^2) have h9 : Real.sqrt (f (x -a) -f (x -a) ^2) ≤ Real.sqrt (1 / 4 : R) := Real.sqrt_le_sqrt (by linarith) have h10 : Real.sqrt (1 / 4 : R) = 1 / 2 := by rw [Real.sqrt_eq_iff_sq_eq]&lt;;&gt; norm_num linarith linarith [h4, h6] have h11 : 0 ≤ f x := by nlinarith [Real.sqrt_nonneg(f (x -a) -f (x -a) ^2), h4] exact ⟨h11, h5⟩ use 2 * a constructor • linarith [h0] • intro x have h3 := h1 (x + a) have h4 := h1 x rw [show x + a + a = x + 2 * a by ring] at h3 have h5 : f (x + 2 * a) = 1 / 2 + Real.sqrt (f (x + a) -f (x + a) ^2) := by linarith have h6 : f (x + a) -f (x + a) ^2 = (f x -1 / 2) ^2 := by have h7 : f (x + a) = 1 / 2 + Real.sqrt (f x -f x ^2) := by linarith rw [h7] ring_nf rw [Real.sq_sqrt(by nlinarith [h2 x])] ring rw [h6] at h5 have h7 : Real.sqrt ((f x -1 / 2) ^2) = abs (f x -1 / 2) := by rw [Real.sqrt_sq_eq_abs]have h8 : abs (f x -1 / 2) = f x -1 / 2 := by have h9 : f x ≥ 1 / 2 := by have h10 := h1 (x -a) rw [show x -a + a = x by ring] at h10 have h11 : Real.sqrt (f (x -a) -f (x -a) ^2) ≥ 0 := Real.sqrt_nonneg (f (x -a) -f (x -a) ^2) linarith [h10, h11] apply abs_of_nonneg linarith rw [h7, h8] at h5 linarith [h5]</p>
<p>have h_cos : Real.cos x = 308 / 533 := by nlinarith [h_cos_sq] have h_sin' : Real.sin x = 435 / 533 := by have h9 : Real.sin x = (22 * Real.cos x -7) / 7 := h_sin rw [h9, h_cos] norm_numFrom here, the model substitutes these derived values into h1: h1 : 1 / Real.sin x + 1 / Real.tan x = mAfter this step, it successfully closes out the proof showing great mastery of algebraic techniques.theorem aime_1991_p9 (x : R) (m : Q) (h0 : 1 / Real.cos x + Real.tan x = 22 / 7) (h1 : 1 / Real.sin x + 1 / Real.tan x = m) : ↑m.den + m.num = 44 := by have h2 : Real.cos x ̸ = 0 := by by_contra h have h3 : 1 / Real.cos x = 0 := by field_simp [h] have h4 : Real.tan x = 0 := by rw [Real.tan_eq_sin_div_cos]simp [h] have h5 : (22 : R) / 7 = 0 := by linarith [h0, h3, h4] norm_num at h5 have h_tan : Real.tan x = Real.sinx / Real.cos x := by rw [Real.tan_eq_sin_div_cos]have h3 : Real.sin x ^2 + Real.cos x ^2 = 1 := Real.sin_sq_add_cos_sq x have h4 : 1 / Real.cos x + Real.tan x = 22 / 7 := h0 rw [h_tan] at h4 have h5 : 1 / Real.cos x + Real.sin x / Real.cos x = 22 / 7 := h4 have h6 : (1 + Real.sin x) / Real.cos x = 22 / 7 := by have h7 : Real.cos x ̸ = 0 := h2 field_simp [h7] at h5 ⊢ nlinarith have h7 : 7 * (1 + Real.sin x) = 22 * Real.cos x := by have h8 : Real.cos x ̸ = 0 := h2 field_simp at h6 nlinarith have h_sin : Real.sin x = (22 * Real.cos x -7) / 7 := by linarith have h8 : Real.sin x ^2 + Real.cos x ^2 = 1 := Real.sin_sq_add_cos_sq x have h9 : Real.sin x = (22 * Real.cos x -7) / 7 := h_sin have h_cos_sq : Real.cos x ^2 = (308 / 533) ^2 := by have h10 : Real.cos x ̸ = 0 := h2 have h11 : Real.sin x = (22 * Real.cos x -7) / 7 := h_sin rw [h11] at h3 have h12 : ((22 * Real.cos x -7) / 7) ^2 + Real.cos x ^2 = 1 := by linarith have h13 : (22 * Real.cos x -7) ^2 + (7 * Real.cos x) ^2 = 49 := by nlinarith have h14 : (Real.cosx) * (533 * Real.cos x -308) = 0 := by ring_nf at h13 ⊢ linarith cases' (mul_eq_zero.mph14) with h_cos h15 • --Real.cosx = 0 exfalso exact h10 (by linarith) • --533 * Real.cos x -308 = 0 have h_cos : Real.cos x = 308 / 533 := by linarith nlinarith [h_cos] have h_cos : Real.cos x = 308 / 533 := by nlinarith [h_cos_sq] have h_sin' : Real.sin x = 435 / 533 := by have h9 : Real.sin x = (22 * Real.cos x -7) / 7 := h_sin rw [h9, h_cos] norm_num have h_csc_cot : (1 / Real.sin x : R) + (1 / Real.tan x : R) = (29 / 15 : R) := by have h10 : Real.sin x ̸ = 0 := by by_contra h have h11 : Real.sin x = 0 := by linarith rw [h11] at h3 have h12 : Real.cos x ^2 = 1 := by nlinarith have h13 : Real.cos x = 1 ∨ Real.cos x = -1 := by have h14 : Real.cos x ^2 -1 = 0 := by linarith have h15 : (Real.cosx -1) * (Real.cosx + 1) = 0 := by ring_nf at h14 ⊢ linarith cases (mul_eq_zero.mph15) with | inl h16 =&gt; left; linarith | inr h17 =&gt; right; linarith cases h13 with | inl h14 =&gt; have h15 : Real.cos x = 308 / 533 := h_cos linarith | inr h14 =&gt; have h15 : Real.cos x = 308 / 533 := h_cos linarith have h11 : Real.tan x ̸ = 0 := by by_contra h have h12 : Real.sin x = 0 := by rw [Real.tan_eq_sin_div_cos]at h have h13 : Real.cos x ̸ = 0 := h2 field_simp [h13] at h linarith contradiction have h12 : (1 / Real.sin x : R) + (1 / Real.tan x : R) = (29 / 15 : R) := by have h13 : Real.tan x = Real.sinx / Real.cos x := Real.tan_eq_sin_div_cos x rw [h13] have h14 : Real.sin x ̸ = 0 := h10 have h15 : Real.cos x ̸ = 0 := h2 field_simp [h14, h15, h_sin', h_cos] norm_num exact h12 have h_m : (m : R) = (29 / 15 : R) := by have h12 : (1 / Real.sin x : R) + (1 / Real.tan x : R) = (29 / 15 : R) := h_csc_cot have h13 : (1 / Real.sin x : R) + (1 / Real.tan x : R) = (m : R) := by exact_mod_cast h1 rw [h13] at h12 linarith have h14 : m = (29 / 15 : Q) := by have h15 : (m : R) = (29 / 15 : R) := h_m have h16 : (m : R) = (29 / 15 : Q) := by norm_num at h15 ⊢ exact_mod_cast h15 exact_mod_cast h16 rw [h14] norm_num Listing 2: Lean 4 proof of AIME 1991 Problem 9 found by Kimina-Prover.</p>
<p>term.theorem mathd_algebra_354 (a d : R) (h0 : a + 6 * d = 30) (h1 : a + 10 * d = 60) : a + 20 * d = 135 := by Output: <think> # Solving for the 21st Term of an Arithmetic Sequence</p>
<p>The 11th term a 11 = a + 10d = 60 -We need to find the 21st term a 21 = a + 20d Let's solve for a and d to find a 21 .Subtracting the first equation from the second gives: d = 7.5 back into the first equation: a + 6(7.5) = 30 a + 45 = 30 a = 30 − 45 = −15 So, the 21st term is a 21 = a + 20d = −15 + 20(7.5)= −15 + 150 = 135 Let's formalize this in Lean 4: Nat Topology Rat theorem mathd_algebra_354 (a d : R) (h0 : a + 6 * d = 30) (h1 : a + 10 * d = 60) : a + 20 * d = 135 := by We have two equations: 1. a + 6d = 30 (h 0 ) 2. a + 10d = 60 (h 1 )</p>
<p>compute this in Lean: have hd : d = 15 / 2 := by linarith Now we have d = 15 2 .Let's verify this calculation: From a + 10d = 60 and a + 6d = 30, subtracting gives 4d = 30, so d = 30 4 = 15 2 .This is correct.Next, we'll substitute d = 15 2 back into one of the equations to solve for a. Let's use h 0 : a + 6d = 30 a + 6( 15 2 ) = 30 a + 45 = 30 a = 30 − 45 = −15 In Lean, once we have d, we can determine a: have ha : a = -15 := by linarith [h0, hd] Now we need to compute a + 20d: a + 20d = −15 + 20( 15 2 ) = −15 + 150 = 135 In Lean, we can directly compute a + 20d using the values of a and d: linarith [ha, hd] The Lean proof is concise because once we have d = 15 2 and a = −15, it can directly compute that a + 20d = −15 + 20 • 15 2 = −15 + 30 • 15 1 = −15 + 150 = 135 using linear arithmetic.So, the 21st term of the sequence is 135.a d : R) (h0 : a + 6 * d = 30) (h1 : a + 10 * d = 60) : a + 20 * d = 135 := by have hd : d = 15 / 2 := by linarith have ha : a = -15 := by linarith [h0, hd] linarith[ha, hd]</p>
<p>theorem imo_1962_p2 (x : R) (h0 : 0 ≤ 3 -x) (h1 : 0 ≤ x + 1) (h2 : 1 / 2 &lt; Real.sqrt (3 -x) -Real.sqrt(x + 1)) : -1 ≤ x ∧ x &lt; 1 -Real.sqrt31 / 8 := by have h3 : -1 ≤ x := by nlinarith have h4 : Real.sqrt (3 -x) -Real.sqrt(x + 1) &gt; 1 / 2 := by linarith have h5 : Real.sqrt (x + 1) ≥ 0 := Real.sqrt_nonneg (x + 1) have h6 : (7 / 4 -2 * x) &gt; Real.sqrt (x + 1) := by nlinarith [Real.sq_sqrt(show (0 : R) ≤ 3 -x by linarith), Real.sq_sqrt (show (0 : R) ≤ x + 1 by linarith), Real.sqrt_nonneg (3 -x), Real.sqrt_nonneg (x + 1)] have h7 : (7 / 4 -2 * x) ^2 &gt; (Real.sqrt(x + 1)) ^2 := by nlinarith [h6, Real.sqrt_nonneg (x + 1)] have h8 : (7 / 4 -2 * x) ^2 &gt; x + 1 := by have h10 : (Real.sqrt(x + 1)) ^2 = x + 1 := by rw [Real.sq_sqrt]linarith nlinarith [h7, h10] have h9 : 64 * x ^2 -128 * x + 33 &gt; 0 := by nlinarith [h8] have h10 : x &lt; 1 -Real.sqrt31 / 8 := by by_contra hx push_neg at hx have h12 : Real.sqrt 31 &gt; 0 := by apply Real.sqrt_pos.mprnorm_num nlinarith [sq_nonneg (x -(1 -Real.sqrt31 / 8)), sq_nonneg (Real.sqrt31), Real.sq_sqrt (show (0 : R) ≤ 31 by norm_num), h12] exact ⟨h3, h10⟩ Listing 3: Lean 4 proof of IMO-1962-P2 found by Kimina-Prover.lt_sub_iff_add_lt] ring_nf rw [← lt_sub_iff_add_lt] linarith [Real.sq_sqrt(by linarith : 0 &lt;= 1 + x)] rw [Real.sqrt_lt(by norm_num)] rw [Real.sqrt_lt]&lt;;&gt; nlinarith norm_num at this } Listing 4: Lean 4 proof of IMO-1962-P2 found by BFS-Prover.F Examples of Thinking Output &amp; Analysis F.1 Success Modes F.1.1 Success Case: Exploration of Multiple Informal Reasoning paths Formal statement of Problem IMO-1983-P6: theorem imo_1983_p6 (a b c : R) (h0 : 0 &lt; a ∧ 0 &lt; b ∧ 0 &lt; c) (h1 : c &lt; a + b) (h2 : b &lt; a + c) (h3 : a &lt; b + c) : 0 ≤ a ^2 * b * (a -b) + b ^2 * c * (b -c) + c ^2 * a * (c -a) := by In addressing IMO 1983 P6, a challenging inequality problem, Kimina-Prover starts its analysis by exploring multiple variable substitution methodologies.<think> I'll tackle the problem of proving that for the sides a, b, and c of a triangle, the inequality a 2 b(a − b) + b 2 c(b − c) + c 2 a(c − a) ≥ 0 holds, and determine when equality occurs.</p>
<p>Alternatively, consider using the substitution a = x+y 2 , b = y+z 2 , c = z+x 2 , but I'm not sure.......Alternatively, use the substitution a = y + z, b = z + x, c = x + y, with x, y, z &gt; 0 (the Ravi substitution).Let's try that again more carefully....... Alteratively, use the substitution a = 1 x , b = 1 y , c = 1 z , but I don't think this helps....... Let's try another approach.The expression can be rewritten using the identity: a 2 b(a−b)+b 2 c(b−c)+c 2 a(c−a) = (a − b)(b − c)(c − a)(a + b + c) ......</p>
<p>2.</p>
<p>Prove x, y, z &gt; 0 using the triangle inequalities 3. Substitute a = x + y, b = y + z, c = z + x into the goal 4. Expand the expression 5. Show it's equal to the sum of squares 6. Conclude non-negativity The Lean code to perform this substitution would look like: have ha : a = x + y := by dsimp [x, y, z] linarith ......The entire Lean proof leveraging the Ravi substitution and expansion would look something like: theorem imo_1983_p6 (a b c : R) (h0 : 0 &lt; a ∧ 0 &lt; b ∧ 0 &lt; c) (h1 : c &lt; a + b) (h2 : b &lt; a + c) (h3 : a &lt; b + c) : 0 ≤ a ^2 * b * (a -b) + b ^2 * c * (b -c) + c ^2 * a * (c -a) := by let x := (a + c -b) / 2 let y := (a + b -c) / 2 let z := (b + c -a) / 2 have hx : 0 &lt; x := by dsimp [x] nlinarith [h0.left, h0.right.left,h1] have hy : 0 &lt; y := by dsimp [y] nlinarith [h0.left, h0.right.right,h2] have hz : 0 &lt; z := by dsimp [z] nlinarith [h0.right.left,h0.right.right,h3] have ha : a = x + y := by dsimp [x, y, z] nlinarith have hb : b = y + z := by dsimp [x, y, z] nlinarith have hc : c = z + x := by dsimp [x, y, z] nlinarith rw [ha, hb, hc] nlinarith [sq_nonneg (x -y), sq_nonneg (y -z), sq_nonneg (z -x), mul_pos hx hy, mul_pos hy hz, mul_pos hz hx, sq_nonneg (x + y + z), sq_nonneg (x -y), sq_nonneg (y -z), sq_nonneg (z -x), sq_nonneg (x + y + z), sq_nonneg (x -y), sq_nonneg (y -z), sq_nonneg (z -x), sq_nonneg (x + y + z), sq_nonneg (z -x), sq_nonneg (x + y + z), sq_nonneg (x -y), sq_nonneg (y + z + x), sq_nonneg (y -z), sq_nonneg (z + x + x), sq_nonneg (z -x), sq_nonneg (x + y + y)]</p>
<p>F. 1
1
.2 Success Case: Reflection and Refinement Formal statement of Problem number_theory_72826: theorem number_theory_72826 {n : N} (hn : Even n) (h : n &gt; 38) : ∃ a b c d : N, Odd a ∧ Odd b ∧ Odd c ∧ Odd d ∧ a &gt; 1 ∧ b &gt; 1 ∧ c &gt; 1 ∧ d &gt; 1 ∧ n = a * b + c * d := by Another example is a number theory problem that involves proving the decomposition of large odd numbers.This problem requires creative constructions and a detailed analysis of different cases.The thinking and analysis process of Kimina-Prover for this problem is shown in the list below.<think> If we can write n = a • b + c • d, where all variables are odd and greater than 1, then we can try to find such a decomposition for any n &gt; 38.</p>
<ol>
<li>n ≡ 0 mod6: n=6k, use a=3, b=3, c=3, d=2k-3 2. n ≡ 2 mod6: n=6k+2, use a=3, b=2k-11, c=5, d=7 3. n ≡ 4 mod6: n=6k+4, use a=3, b=2k-7, c=5, d=5 ......</think>theorem number_theory_72826 {n : N} (hn : Even n) (h : n &gt; 38) : ∃ a b c d : N, Odd a ∧ Odd b ∧ Odd c ∧ Odd d ∧ a &gt; 1 ∧ b &gt; 1 ∧ c &gt; 1 ∧ d &gt; 1 ∧ n =a * b + c * d := by have h1 : n % 2 = 0 := by exact Nat.even_iff.1 hn have h2 : n &gt; 38 := h have h3 : n % 6 = 0 ∨ n % 6 = 2 ∨ n % 6 = 4 := by have h1 : n % 2 = 0 := by exact Nat.even_iff.1 hn have : n % 6 = 0 ∨ n % 6 = 2 ∨ n % 6 = 4 := by omega assumption rcases h3 with (h3 | h3 | h3) • --Case n % 6 = 0 have h4 : n % 6 = 0 := h3 have h5 : ∃ k, n = 6 * k := by refine ⟨n / 6, by omega⟩ rcases h5 with ⟨k, hk⟩ have hk1 : k ≥ 7 exact h_odd, by exact h_odd, by exact h_odd, by exact h_odd2, by norm_num, by norm_num, by norm_num, by omega, by omega⟩ • --Case n % 6 = 2 have h4 : n % 6 = 2 := h3 have h5 : ∃ k, n = 6 * k + 2 := by refine ⟨(n -2) / 6, by omega⟩ rcases h5 with ⟨k, hk⟩ have hk1 : k ≥ 7 exact h_odd1, by exact h_odd2, by exact h_odd3, by exact h_odd4, by norm_num, by omega, by norm_num, by norm_num, by omega⟩ • --Case n % 6 = 4 have h4 : n % 6 = 4 := h3 have h5 : ∃ k, n = 6 * k + 4 := by refine ⟨(n -4) / 6, by omega⟩ rcases h5 with ⟨k, hk⟩ have hk1 : k ≥ 6 := by omega use 3, 2 * k -7, 5exact h_odd1, by exact h_odd2, by exact h_odd3, by exact h_odd3, by norm_num, by omega, by norm_num, by norm_num, by omega⟩</li>
</ol>
<p>F</p>
<p>Table 1 :
1
Performance of various prover systems in terms of model size, sample budget, and miniF2F-test results.Bold indicates SotA performance in model size and compute budget.</p>
<p>Table 2 :
2
Performance Comparison of SOTA Large Reasoning Models on the IMO and AIME Subset of miniF2F.While
BenchmarkSample budget miniF2F miniF2F/IMO miniF2F/AIMEOpenAI o3-mini3224.59%0%6.67%gemini-2.5-pro-preview-03-253237.70%5%13.33%Kimina-Prover-Preview32 819268.85% 80.74%20.00% 40.00%46.67% 86.67%</p>
<p>(Lample et al. 2022; et al. 2024;earch, tDeepmind 2024-model-based approaches are frequently integrated with classical tree search algorithms, such as Best-First Search(Polu et al. 2022;Wu et al. 2024; R. Xin et al. 2025) and Monte Carlo Tree Search(Lample et al. 2022; H. Wang et al. 2023;Deepmind 2024).The search component plays a central role in these systems, as it guides the exploration and selection of promising proof paths based on heuristic evaluations.Such hybrid methods significantly benefit from heuristic-driven exploration but incur substantial computational overhead.
NuminaKimi TeamJia Li<em>Haiming Wang</em>Mert Unsal<em>Zhengying Liu</em>Mantas Baksys<em>Xiaohan Lin</em>Marco Dos Santos<em>Junqi Liu</em>Marina Vinyes<em>Flood Sung</em>Zhenzhe Ying<em>Chendong SongZekai Zhu</em>Chenjun XiaoJianqiao Lu<em>Dehao ZhangHugues de Saxcé</em>Han ZhuBolton BaileyLonghui YuEbony ZhangYangyang HuFrederick PuZhilin YangJiawei LiuZihan WangJonas BayerJulien MichelLéo Dreyfus-SchmidtLewis TunstallLuigi PaganiMoreira MachadoPauline BourigaultRan WangStanislas PoluThibaut BarroyerWen-Ding LiYazhe NiuYann FleureauZhouliang YuNames marked with an asterisk (*) indicate core contributors. Other authors are listed in alphabetical order based ontheir first names.
Xin et al. 2024;022;Polu et al. 2022First et al. 2023;Huang et al. 2024;Wu et al. 2024;ge models with formal proof assistants such as Lean 4. These systems typically employ a language model trained to either generate individual proof steps(Lample et al. 2022;Polu et al. 2022;Deepmind 2024; H. Wang et al. 2023;Wu et al. 2024; R. Xin et al. 2025; Y. Lin  et al. 2025; H. Wang, H. Xin, Liu, et al. 2024)or produce entire proof completions from a given proof state (H.Xin et al. 2024; Y. Lin et al. 2025;First et al. 2023;Huang et al. 2024; H. Wang, H. Xin, C. Zheng, et al. 2023; Jiang et al. 2023a).</p>
<p>https://github.com/MoonshotAI/Kimina-Prover-Preview
If x 2 &gt; 4, then 3x 2 + 1 &gt; 13, let's see if that's possible: If x 2 = 9 (i.e., x = ±3), then 3x 2 + 1 = 28 The reasoning contains a logical gap when trying to prove x 2 ≤ 4.Although correctly showing that x = ±3 and x = ±4 lead to non-integer values for y, it fails to address whether larger values of x could satisfy the equation.The model mistakenly assumed that solving the cases for n = 3 and n = 4 would resolve all cases for n &gt; 2. This incomplete case analysis pattern hinders the model from solving problems correctly.
. System Sonnet, Card, </p>
<p>ProofNet: Autoformalizing and Formally Proving Undergraduate-Level Mathematics. Zhangir Azerbayev, arXiv:2302.12433[cs.CL2023</p>
<p>AI achieves silver-medal standard solving International Mathematical Olympiad problems. Deepmind, 2024</p>
<p>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. Deepseek-Ai , arXiv:2501.12948[cs.CL2025</p>
<p>Baldur: Whole-Proof Generation and Repair with Large Language Models. Emily First, arXiv:2303.04910[cs.LG2023</p>
<p>MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data. Yinya Huang, arXiv:2402.08957[cs.AI2024</p>
<p>Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs. Albert Q Jiang, arXiv:2210.12283[cs.AI2023</p>
<p>Multilingual Mathematical Autoformalization. Albert Q Jiang, Wenda Li, Mateja Jamnik, arXiv:2311.03755[cs.CL2023</p>
<p>Kimi k1.5: Scaling reinforcement learning with llms. Kimi-Team , arXiv:2501.125992025arXiv preprint</p>
<p>HyperTree Proof Search for Neural Theorem Proving. Guillaume Lample, Advances in Neural Information Processing Systems. Curran Associates, Inc202235</p>
<p>Fro Lean, A read-eval-print-loop for Lean. </p>
<p>. Jia Li, </p>
<p>HunyuanProver: A Scalable Data Synthesis Framework and Guided Tree Search for Automated Theorem Proving. Yang Li, arXiv:2412.20735[cs.AI2025</p>
<p>Lean-STaR: Learning to Interleave Thinking and Proving. Haohan Lin, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving. Yong Lin, arXiv:2502.07640[cs.LG2025</p>
<p>The Lean 4 Theorem Prover and Programming Language. Leonardo Moura, Sebastian De, Ullrich, 10.1007/978-3-030-79876-5_37Automated Deduction -CADE 28: 28th International Conference on Automated Deduction, Virtual Event. Berlin, HeidelbergSpringer-VerlagJuly 12-15, 2021. 2021</p>
<p>Isabelle/HOL: a proof assistant for higher-order logic. Tobias Nipkow, Lawrence C Paulson, Markus Wenzel, 2002Springer Science &amp; Business Media2283</p>
<p>OpenAI et al. OpenAI o1 System Card. Numina, Lean Numina, Server, arXiv:2412.16720[cs.AI2025. 2024arXiv preprint forthcoming</p>
<p>Formal Mathematics Statement Curriculum Learning. Stanislas Polu, arXiv:2202.01344[cs.LG2022</p>
<p>Qwen-Team, Qwen2.5: A Party of Foundation Models. Sept. 2024</p>
<p>David Renshaw, Compfiles: Catalog Of Math Problems Formalized In Lean. </p>
<p>George Tsoukalas, arXiv:2407.11214[cs.AIEvaluating Neural Theorem-Provers on the Putnam Mathematical Competition. 2024</p>
<p>Dt-solver: Automated theorem proving with dynamic-tree sampling guided by proof-level value function. Haiming Wang, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational Linguistics20231</p>
<p>. Haiming Wang, Huajian Xin, Zhengying Liu, arXiv:2405.14414[cs.AIProving Theorems Recursively. 2024.</p>
<p>LEGO-Prover: Neural Theorem Proving with Growing Libraries. Haiming Wang, Huajian Xin, Chuanyang Zheng, arXiv:2310.00656[cs.AI2023</p>
<p>MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving. Ruida Wang, arXiv:2503.03205[cs.CL2025</p>
<p>5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems. Zijian Wu, arXiv:2410.15700[cs.AI2024</p>
<p>DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search. Huajian Xin, arXiv:2408.08152[cs.CL2024</p>
<p>BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving. Ran Xin, arXiv:2502.03438[cs.AI2025</p>
<p>Leanabell-Prover: Posttraining Scaling in Formal Reasoning. Jingyuan Zhang, arXiv:2504.06122[cs.AI2025</p>
<p>MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics. Kunhao Zheng, Jesse Michael Han, Stanislas Polu, arXiv:2109.00110[cs.AI2022</p>            </div>
        </div>

    </div>
</body>
</html>