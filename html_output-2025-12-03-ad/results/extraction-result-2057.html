<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2057 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2057</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2057</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-53.html">extraction-schema-53</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <p><strong>Paper ID:</strong> paper-277452187</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.23170v1.pdf" target="_blank">AstroAgents: A Multi-Agent AI for Hypothesis Generation from Mass Spectrometry Data</a></p>
                <p><strong>Paper Abstract:</strong> With upcoming sample return missions across the solar system and the increasing availability of mass spectrometry data, there is an urgent need for methods that analyze such data within the context of existing astrobiology literature and generate plausible hypotheses regarding the emergence of life on Earth. Hypothesis generation from mass spectrometry data is challenging due to factors such as environmental contaminants, the complexity of spectral peaks, and difficulties in cross-matching these peaks with prior studies. To address these challenges, we introduce AstroAgents, a large language model-based, multi-agent AI system for hypothesis generation from mass spectrometry data. AstroAgents is structured around eight collaborative agents: a data analyst, a planner, three domain scientists, an accumulator, a literature reviewer, and a critic. The system processes mass spectrometry data alongside user-provided research papers. The data analyst interprets the data, and the planner delegates specific segments to the scientist agents for in-depth exploration. The accumulator then collects and deduplicates the generated hypotheses, and the literature reviewer identifies relevant literature using Semantic Scholar. The critic evaluates the hypotheses, offering rigorous suggestions for improvement. To assess AstroAgents, an astrobiology expert evaluated the novelty and plausibility of more than a hundred hypotheses generated from data obtained from eight meteorites and ten soil samples. Of these hypotheses, 36% were identified as plausible, and among those, 66% were novel. Project website: https://astroagents.github.io/</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2057.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2057.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AstroAgents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AstroAgents: A multi-agent AI system for hypothesis generation from mass spectrometry data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent LLM-based system composed of eight collaborative agents (data analyst, planner, three scientist agents, accumulator, literature reviewer, critic) designed to generate, consolidate, and critique scientific hypotheses from GC×GC-HRTOF-MS mass spectrometry data with integrated literature search (Semantic Scholar) and iterative feedback to the data analyst.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AstroAgents</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>multi-agent LLM orchestration (multiple specialized LLM agents coordinated by planner/accumulator/critic)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>astrobiology / analytical chemistry (mass spectrometry, prebiotic chemistry)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses (structured JSON hypothesis statements with supporting key datapoints)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel (paper reports the system produced novel hypotheses especially when using larger-context LLM; novelty depends on LLM configuration)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>orchestrated LLM generation: planner assigns data segments to specialized scientist agents which generate structured hypotheses (statement + key_datapoints); accumulator deduplicates; literature-review agent retrieves relevant papers; critic evaluates and provides feedback for iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>expert human evaluation (single astrobiology expert) using six criteria (novelty, consistency with literature, clarity/precision, empirical support, scope/generalizability, predictive power) scored 0–10; automated literature retrieval (Semantic Scholar) and an internal critic agent also provide machine critique and literature-consistency checks but final validation reported is human expert scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Experimental generation counts: two experiments produced 48 hypotheses (Claude 3.5 Sonnet) and 101 hypotheses (Gemini 2.0 Flash), total 149 hypotheses across experiments. Per-experiment average overall expert score: Claude 3.5 Sonnet = 6.58 ± 1.7 (n=48); Gemini 2.0 Flash = 5.67 ± 0.64 (n=101).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation is via human expert scoring. Plausibility as defined by paper: hypothesis considered 'plausible' if average of non-novelty criteria >= 8. Claude: 24/48 hypotheses (50.0%) met plausibility criterion. Gemini: 36/101 hypotheses (~35.6%) met plausibility criterion. Aggregate expert-scored per-criterion means available (see paper Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Paper reports a trade-off: Gemini (larger context) produced more novel hypotheses (higher novelty means) but lower average validation scores and more logical errors; Claude (better agentic cooperation) produced fewer novel hypotheses but higher consistency/clarity/empirical support scores. The authors interpret validation performance as decreasing for more novel outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Yes — the paper compares generation vs validation across two LLM configurations: Gemini generated more hypotheses and more novel ideas but had lower validation (expert scores and more logical errors). Claude generated fewer, less-novel hypotheses but higher validation scores, indicating an asymmetry where generation (novelty/diversity) can exceed reliable validation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not reported — the system/agents do not provide calibrated uncertainty scores for generated hypotheses in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported — no calibration metrics or confidence-vs-accuracy analyses provided.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not explicitly reported; authors claim Gemini's larger context enabled more creative/novel (potentially out-of-distribution) hypotheses but with reduced consistency; no quantitative OOD metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — the system uses proxy metrics for plausibility: human-judged criteria (plausibility via averaged scores across consistency, clarity, empirical support, scope, predictive power). The internal critic also assesses consistency with the literature retrieved by Semantic Scholar (coherence and alignment) as a proxy validation step.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Per-hypothesis (an astrobiology expert evaluated each generated hypothesis across six criteria). The paper explicitly relies on this expert evaluation for reported validation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (mass spectrometry / astrobiology) — domain requires experimental/observational validation rather than formal proofs; this empirical nature increases the generation-validation gap for novel claims.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>System design strategies: multi-agent decomposition (specialist scientist agents), accumulator deduplication, automated literature retrieval (Semantic Scholar) and summarization, an internal critic agent to flag weaknesses and provide iteration to the data analyst; also comparison of different LLMs to balance cooperation vs context window. Effectiveness: partial — reduces some logical errors and improves literature consistency (Claude), but does not eliminate need for human expert validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Empirical evidence: Gemini 2.0 Flash produced more hypotheses (101) and higher novelty mean (novelty 4.26 ± 1.87) but had lower overall expert scores (5.67 ± 0.64) and more logical errors; Claude 3.5 Sonnet produced fewer hypotheses (48), lower novelty (2.75 ± 0.75), but higher expert scores (6.58 ± 1.7). The paper reports that among Gemini's 36 plausible hypotheses, 24 were novel (66% of plausible), whereas Claude had 24 plausible but none flagged novel — demonstrating generation (novelty) exceeding reliable validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Counter-evidence is limited: Claude Sonnet 3.5 achieved relatively high expert scores and a high plausibility fraction (50%), indicating that strong agentic cooperation can produce outputs that validate well and partially close the gap; however, human expert validation was still required.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2057.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2057.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Claude 3.5 Sonnet (Anthropic)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A commercial large language model used as the LLM backend for AstroAgents in one experiment; selected for its strong agentic/collaborative abilities and used to power all internal agent outputs in the Claude-configured experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language model</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific reasoning applied to astrochemistry / hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses (textual statements with supporting key datapoints)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>mostly in-distribution / incremental to moderately novel (paper reports low novelty mean: 2.75 ± 0.75 on 0–10 scale)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>prompted LLM generation within a multi-agent orchestration; agents implemented via LLM instances executing specialized prompts (data analyst, planner, scientist agents, critic, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Downstream validation relied on automatic literature retrieval and internal critic checks plus human expert scoring across six criteria; no intrinsic formal validation in Claude itself.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Produced 48 hypotheses over 10 iterations (as reported), with per-hypothesis generation speed not quantified. Per-hypothesis expert average overall score (across six criteria) = 6.58 ± 1.7.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>24/48 hypotheses (50%) met the paper's plausibility threshold (average of non-novelty criteria >= 8). Per-criterion means (Claude): Novelty 2.75 ± 0.75; Consistency 7.60 ± 1.91; Clarity 7.20 ± 2.30; Empirical Support 6.75 ± 2.63; Scope 7.60 ± 1.91; Predictive Power 7.60 ± 1.91.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Lower novelty outputs from Claude aligned with higher validation scores; the paper reports Claude-generated hypotheses had fewer logical errors and stronger literature consistency, indicating validation is better for lower-novelty outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper compares Claude to Gemini: Claude's generation quality (fewer, less-novel hypotheses) aligned with higher validation (expert scores) than Gemini, indicating different generation/validation trade-offs across LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not reported for Claude outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported; novelty low so limited OOD claims.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Relies on human-judged criteria and internal critic literature-consistency checks rather than model-internal confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Per-hypothesis (expert evaluated each of the 48 hypotheses).</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (mass spectrometry / astrobiology)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Using an LLM with stronger cooperative ability (Claude) within multi-agent setup to improve consistency and reduce logical errors; iterative critic feedback loop.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Low novelty but higher validation indicates that generating novel outputs while maintaining validation quality is challenging; Claude favored validation over novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Claude's high validation scores show that careful agent design can yield valid hypotheses without extreme novelty, partially mitigating the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2057.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2057.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini 2.0 Flash (Google DeepMind / Google)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-context LLM used as the backend for AstroAgents in a second experiment; selected for its extended context window (up to ~1M tokens) enabling inclusion of a large book plus research papers as context, producing more hypotheses and higher novelty but more logical errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language model with extended context window</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific reasoning applied to astrochemistry / hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific hypotheses (textual statements with supporting key datapoints)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel (paper reports higher novelty mean: 4.26 ± 1.87 on 0–10 scale)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>prompted LLM generation within the AstroAgents multi-agent orchestration, leveraging a much larger contextual input (10 papers + 400-page book) to enable broader associations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Same external validation pipeline: automated literature retrieval, critic agent checks, and human expert evaluation across six criteria (no automated ground-truth verification).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Produced 101 hypotheses over 10 iterations. Generated more hypotheses and more novel ideas compared to Claude, but produced more logical errors and lower average expert scores. Per-hypothesis overall expert score = 5.67 ± 0.64.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>36/101 hypotheses (~35.6%) met the paper's plausibility threshold (average of non-novelty criteria >= 8). Among those 36 plausible, 24 were considered novel (24/36 = 66.7% of plausible hypotheses flagged as novel). Per-criterion means (Gemini): Novelty 4.26 ± 1.87; Consistency 6.19 ± 2.88; Clarity 5.92 ± 2.86; Empirical Support 5.79 ± 2.86; Scope 6.01 ± 2.80; Predictive Power 5.86 ± 2.68.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Reported inverse relationship: higher novelty (Gemini) coincided with decreased validation metrics (lower consistency/clarity/empirical support and more logical errors), suggesting validation reliability decreases as novelty increases.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Direct comparison in paper shows Gemini generated more and more-novel hypotheses but validated worse by human expert metrics compared to Claude, indicating a generation > validation gap for this model/configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not quantitatively reported; authors qualitatively note Gemini produced more novel/out-of-context combinations but with higher logical error rates.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Relies on human expert scoring and critic/literature-consistency checks as proxies for validity.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Per-hypothesis (expert evaluated each of the 101 hypotheses).</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (mass spectrometry / astrobiology)</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>The multi-agent critic + literature review + iterative feedback loop are intended to catch logical errors from novel hypotheses; paper reports partial success but not elimination of validation failures.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Gemini's higher novelty yet lower expert validation scores and higher logical error incidence provide direct evidence of generation outpacing robust validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>None direct; some plausible & novel hypotheses were produced and validated (24 novel plausible hypotheses), indicating validation can succeed for certain novel outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2057.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2057.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic Scholar (literature review agent)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantic Scholar (automated literature retrieval used by AstroAgents literature-review agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated literature search/data source used by AstroAgents' literature-review agent to retrieve up to five pertinent paper snippets per hypothesis query; results are synthesized to assess alignment with existing research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Semantic Scholar (API / search)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>automated literature retrieval/search platform (external tool)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>bibliographic / literature mining to support scientific hypothesis validation</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>paper snippets and summaries used as evidence for literature-consistency checks</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>not an output-generator of hypotheses itself (retrieval system)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>retrieval of relevant literature snippets given hypothesis queries</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>used as part of validation pipeline to check hypothesis consistency with prior literature and to feed the critic agent; final validation still human-expert scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Provides literature evidence to the critic; no quantitative validation metrics reported for the retrieval performance within the study.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not analyzed; retrieval quality not reported as function of hypothesis novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Not applicable (retrieval only supports validation, does not generate hypotheses).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Used to produce proxy checks of literature consistency (presence/absence of corroborating snippets) rather than direct experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Used per hypothesis as intermediate step; human expert still required for final evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical / bibliographic</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Automated retrieval to ground hypotheses in existing literature, thereby reducing unsupported fabrications; effectiveness not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>No direct metrics; paper notes literature review plus critic helps identify conflicts and weaknesses, but human review remains necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2057.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2057.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciAgents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited prior multi-agent AI system that combines LLMs, ontological knowledge graphs, and in-situ learning to automate aspects of scientific discovery; mentioned in related work as precedent.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SciAgents</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>multi-agent system combining LLMs and knowledge graphs</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>automated scientific discovery (general)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scientific findings / hypotheses (in prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>not assessed in this paper (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>multi-agent reasoning plus ontological graphs (per citation)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>not detailed in this paper (citation only)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2057.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2057.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HypoRefine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypoRefine (iterative hypothesis refinement system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited iterative multi-agent approach to hypothesis refinement that synthesizes insights from literature and empirical data; referenced as related work demonstrating iterative refinement approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>HypoRefine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HypoRefine</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>iterative multi-agent/LLM-based hypothesis refinement system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>automated hypothesis generation/refinement</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>refined hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>not assessed in this paper (related work mention)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>iterative synthesis of literature and data (per citation)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>not detailed in this paper (citation only)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning <em>(Rating: 2)</em></li>
                <li>Hypothesis generation with large language models <em>(Rating: 2)</em></li>
                <li>A comprehensive survey of scientific large language models and their applications in scientific discovery <em>(Rating: 2)</em></li>
                <li>Large language models should be used as scientific reasoning engines, not knowledge databases <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2057",
    "paper_id": "paper-277452187",
    "extraction_schema_id": "extraction-schema-53",
    "extracted_data": [
        {
            "name_short": "AstroAgents",
            "name_full": "AstroAgents: A multi-agent AI system for hypothesis generation from mass spectrometry data",
            "brief_description": "A multi-agent LLM-based system composed of eight collaborative agents (data analyst, planner, three scientist agents, accumulator, literature reviewer, critic) designed to generate, consolidate, and critique scientific hypotheses from GC×GC-HRTOF-MS mass spectrometry data with integrated literature search (Semantic Scholar) and iterative feedback to the data analyst.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AstroAgents",
            "system_type": "multi-agent LLM orchestration (multiple specialized LLM agents coordinated by planner/accumulator/critic)",
            "scientific_domain": "astrobiology / analytical chemistry (mass spectrometry, prebiotic chemistry)",
            "output_type": "scientific hypotheses (structured JSON hypothesis statements with supporting key datapoints)",
            "novelty_level": "moderately novel (paper reports the system produced novel hypotheses especially when using larger-context LLM; novelty depends on LLM configuration)",
            "generation_method": "orchestrated LLM generation: planner assigns data segments to specialized scientist agents which generate structured hypotheses (statement + key_datapoints); accumulator deduplicates; literature-review agent retrieves relevant papers; critic evaluates and provides feedback for iterative refinement.",
            "validation_method": "expert human evaluation (single astrobiology expert) using six criteria (novelty, consistency with literature, clarity/precision, empirical support, scope/generalizability, predictive power) scored 0–10; automated literature retrieval (Semantic Scholar) and an internal critic agent also provide machine critique and literature-consistency checks but final validation reported is human expert scoring.",
            "generation_performance": "Experimental generation counts: two experiments produced 48 hypotheses (Claude 3.5 Sonnet) and 101 hypotheses (Gemini 2.0 Flash), total 149 hypotheses across experiments. Per-experiment average overall expert score: Claude 3.5 Sonnet = 6.58 ± 1.7 (n=48); Gemini 2.0 Flash = 5.67 ± 0.64 (n=101).",
            "validation_performance": "Validation is via human expert scoring. Plausibility as defined by paper: hypothesis considered 'plausible' if average of non-novelty criteria &gt;= 8. Claude: 24/48 hypotheses (50.0%) met plausibility criterion. Gemini: 36/101 hypotheses (~35.6%) met plausibility criterion. Aggregate expert-scored per-criterion means available (see paper Table 1).",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Paper reports a trade-off: Gemini (larger context) produced more novel hypotheses (higher novelty means) but lower average validation scores and more logical errors; Claude (better agentic cooperation) produced fewer novel hypotheses but higher consistency/clarity/empirical support scores. The authors interpret validation performance as decreasing for more novel outputs.",
            "generation_validation_comparison": "Yes — the paper compares generation vs validation across two LLM configurations: Gemini generated more hypotheses and more novel ideas but had lower validation (expert scores and more logical errors). Claude generated fewer, less-novel hypotheses but higher validation scores, indicating an asymmetry where generation (novelty/diversity) can exceed reliable validation quality.",
            "uncertainty_quantification": "Not reported — the system/agents do not provide calibrated uncertainty scores for generated hypotheses in the paper.",
            "calibration_quality": "Not reported — no calibration metrics or confidence-vs-accuracy analyses provided.",
            "out_of_distribution_performance": "Not explicitly reported; authors claim Gemini's larger context enabled more creative/novel (potentially out-of-distribution) hypotheses but with reduced consistency; no quantitative OOD metrics provided.",
            "validation_proxy_metrics": "Yes — the system uses proxy metrics for plausibility: human-judged criteria (plausibility via averaged scores across consistency, clarity, empirical support, scope, predictive power). The internal critic also assesses consistency with the literature retrieved by Semantic Scholar (coherence and alignment) as a proxy validation step.",
            "human_validation_required": true,
            "human_validation_frequency": "Per-hypothesis (an astrobiology expert evaluated each generated hypothesis across six criteria). The paper explicitly relies on this expert evaluation for reported validation metrics.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (mass spectrometry / astrobiology) — domain requires experimental/observational validation rather than formal proofs; this empirical nature increases the generation-validation gap for novel claims.",
            "gap_mitigation_strategies": "System design strategies: multi-agent decomposition (specialist scientist agents), accumulator deduplication, automated literature retrieval (Semantic Scholar) and summarization, an internal critic agent to flag weaknesses and provide iteration to the data analyst; also comparison of different LLMs to balance cooperation vs context window. Effectiveness: partial — reduces some logical errors and improves literature consistency (Claude), but does not eliminate need for human expert validation.",
            "evidence_supporting_gap": "Empirical evidence: Gemini 2.0 Flash produced more hypotheses (101) and higher novelty mean (novelty 4.26 ± 1.87) but had lower overall expert scores (5.67 ± 0.64) and more logical errors; Claude 3.5 Sonnet produced fewer hypotheses (48), lower novelty (2.75 ± 0.75), but higher expert scores (6.58 ± 1.7). The paper reports that among Gemini's 36 plausible hypotheses, 24 were novel (66% of plausible), whereas Claude had 24 plausible but none flagged novel — demonstrating generation (novelty) exceeding reliable validation.",
            "evidence_contradicting_gap": "Counter-evidence is limited: Claude Sonnet 3.5 achieved relatively high expert scores and a high plausibility fraction (50%), indicating that strong agentic cooperation can produce outputs that validate well and partially close the gap; however, human expert validation was still required.",
            "computational_cost_ratio": null,
            "uuid": "e2057.0"
        },
        {
            "name_short": "Claude 3.5 Sonnet",
            "name_full": "Claude 3.5 Sonnet (Anthropic)",
            "brief_description": "A commercial large language model used as the LLM backend for AstroAgents in one experiment; selected for its strong agentic/collaborative abilities and used to power all internal agent outputs in the Claude-configured experiment.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Claude 3.5 Sonnet",
            "system_type": "large language model",
            "scientific_domain": "general scientific reasoning applied to astrochemistry / hypothesis generation",
            "output_type": "scientific hypotheses (textual statements with supporting key datapoints)",
            "novelty_level": "mostly in-distribution / incremental to moderately novel (paper reports low novelty mean: 2.75 ± 0.75 on 0–10 scale)",
            "generation_method": "prompted LLM generation within a multi-agent orchestration; agents implemented via LLM instances executing specialized prompts (data analyst, planner, scientist agents, critic, etc.).",
            "validation_method": "Downstream validation relied on automatic literature retrieval and internal critic checks plus human expert scoring across six criteria; no intrinsic formal validation in Claude itself.",
            "generation_performance": "Produced 48 hypotheses over 10 iterations (as reported), with per-hypothesis generation speed not quantified. Per-hypothesis expert average overall score (across six criteria) = 6.58 ± 1.7.",
            "validation_performance": "24/48 hypotheses (50%) met the paper's plausibility threshold (average of non-novelty criteria &gt;= 8). Per-criterion means (Claude): Novelty 2.75 ± 0.75; Consistency 7.60 ± 1.91; Clarity 7.20 ± 2.30; Empirical Support 6.75 ± 2.63; Scope 7.60 ± 1.91; Predictive Power 7.60 ± 1.91.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Lower novelty outputs from Claude aligned with higher validation scores; the paper reports Claude-generated hypotheses had fewer logical errors and stronger literature consistency, indicating validation is better for lower-novelty outputs.",
            "generation_validation_comparison": "Paper compares Claude to Gemini: Claude's generation quality (fewer, less-novel hypotheses) aligned with higher validation (expert scores) than Gemini, indicating different generation/validation trade-offs across LLMs.",
            "uncertainty_quantification": "Not reported for Claude outputs.",
            "calibration_quality": "Not reported.",
            "out_of_distribution_performance": "Not reported; novelty low so limited OOD claims.",
            "validation_proxy_metrics": "Relies on human-judged criteria and internal critic literature-consistency checks rather than model-internal confidence.",
            "human_validation_required": true,
            "human_validation_frequency": "Per-hypothesis (expert evaluated each of the 48 hypotheses).",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (mass spectrometry / astrobiology)",
            "gap_mitigation_strategies": "Using an LLM with stronger cooperative ability (Claude) within multi-agent setup to improve consistency and reduce logical errors; iterative critic feedback loop.",
            "evidence_supporting_gap": "Low novelty but higher validation indicates that generating novel outputs while maintaining validation quality is challenging; Claude favored validation over novelty.",
            "evidence_contradicting_gap": "Claude's high validation scores show that careful agent design can yield valid hypotheses without extreme novelty, partially mitigating the gap.",
            "computational_cost_ratio": null,
            "uuid": "e2057.1"
        },
        {
            "name_short": "Gemini 2.0 Flash",
            "name_full": "Gemini 2.0 Flash (Google DeepMind / Google)",
            "brief_description": "A large-context LLM used as the backend for AstroAgents in a second experiment; selected for its extended context window (up to ~1M tokens) enabling inclusion of a large book plus research papers as context, producing more hypotheses and higher novelty but more logical errors.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Gemini 2.0 Flash",
            "system_type": "large language model with extended context window",
            "scientific_domain": "general scientific reasoning applied to astrochemistry / hypothesis generation",
            "output_type": "scientific hypotheses (textual statements with supporting key datapoints)",
            "novelty_level": "moderately novel (paper reports higher novelty mean: 4.26 ± 1.87 on 0–10 scale)",
            "generation_method": "prompted LLM generation within the AstroAgents multi-agent orchestration, leveraging a much larger contextual input (10 papers + 400-page book) to enable broader associations.",
            "validation_method": "Same external validation pipeline: automated literature retrieval, critic agent checks, and human expert evaluation across six criteria (no automated ground-truth verification).",
            "generation_performance": "Produced 101 hypotheses over 10 iterations. Generated more hypotheses and more novel ideas compared to Claude, but produced more logical errors and lower average expert scores. Per-hypothesis overall expert score = 5.67 ± 0.64.",
            "validation_performance": "36/101 hypotheses (~35.6%) met the paper's plausibility threshold (average of non-novelty criteria &gt;= 8). Among those 36 plausible, 24 were considered novel (24/36 = 66.7% of plausible hypotheses flagged as novel). Per-criterion means (Gemini): Novelty 4.26 ± 1.87; Consistency 6.19 ± 2.88; Clarity 5.92 ± 2.86; Empirical Support 5.79 ± 2.86; Scope 6.01 ± 2.80; Predictive Power 5.86 ± 2.68.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Reported inverse relationship: higher novelty (Gemini) coincided with decreased validation metrics (lower consistency/clarity/empirical support and more logical errors), suggesting validation reliability decreases as novelty increases.",
            "generation_validation_comparison": "Direct comparison in paper shows Gemini generated more and more-novel hypotheses but validated worse by human expert metrics compared to Claude, indicating a generation &gt; validation gap for this model/configuration.",
            "uncertainty_quantification": "Not reported.",
            "calibration_quality": "Not reported.",
            "out_of_distribution_performance": "Not quantitatively reported; authors qualitatively note Gemini produced more novel/out-of-context combinations but with higher logical error rates.",
            "validation_proxy_metrics": "Relies on human expert scoring and critic/literature-consistency checks as proxies for validity.",
            "human_validation_required": true,
            "human_validation_frequency": "Per-hypothesis (expert evaluated each of the 101 hypotheses).",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (mass spectrometry / astrobiology)",
            "gap_mitigation_strategies": "The multi-agent critic + literature review + iterative feedback loop are intended to catch logical errors from novel hypotheses; paper reports partial success but not elimination of validation failures.",
            "evidence_supporting_gap": "Gemini's higher novelty yet lower expert validation scores and higher logical error incidence provide direct evidence of generation outpacing robust validation.",
            "evidence_contradicting_gap": "None direct; some plausible & novel hypotheses were produced and validated (24 novel plausible hypotheses), indicating validation can succeed for certain novel outputs.",
            "computational_cost_ratio": null,
            "uuid": "e2057.2"
        },
        {
            "name_short": "Semantic Scholar (literature review agent)",
            "name_full": "Semantic Scholar (automated literature retrieval used by AstroAgents literature-review agent)",
            "brief_description": "An automated literature search/data source used by AstroAgents' literature-review agent to retrieve up to five pertinent paper snippets per hypothesis query; results are synthesized to assess alignment with existing research.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Semantic Scholar (API / search)",
            "system_type": "automated literature retrieval/search platform (external tool)",
            "scientific_domain": "bibliographic / literature mining to support scientific hypothesis validation",
            "output_type": "paper snippets and summaries used as evidence for literature-consistency checks",
            "novelty_level": "not an output-generator of hypotheses itself (retrieval system)",
            "generation_method": "retrieval of relevant literature snippets given hypothesis queries",
            "validation_method": "used as part of validation pipeline to check hypothesis consistency with prior literature and to feed the critic agent; final validation still human-expert scoring.",
            "generation_performance": null,
            "validation_performance": "Provides literature evidence to the critic; no quantitative validation metrics reported for the retrieval performance within the study.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not analyzed; retrieval quality not reported as function of hypothesis novelty.",
            "generation_validation_comparison": "Not applicable (retrieval only supports validation, does not generate hypotheses).",
            "uncertainty_quantification": null,
            "calibration_quality": null,
            "out_of_distribution_performance": null,
            "validation_proxy_metrics": "Used to produce proxy checks of literature consistency (presence/absence of corroborating snippets) rather than direct experimental validation.",
            "human_validation_required": true,
            "human_validation_frequency": "Used per hypothesis as intermediate step; human expert still required for final evaluation.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical / bibliographic",
            "gap_mitigation_strategies": "Automated retrieval to ground hypotheses in existing literature, thereby reducing unsupported fabrications; effectiveness not quantified.",
            "evidence_supporting_gap": "No direct metrics; paper notes literature review plus critic helps identify conflicts and weaknesses, but human review remains necessary.",
            "evidence_contradicting_gap": null,
            "computational_cost_ratio": null,
            "uuid": "e2057.3"
        },
        {
            "name_short": "SciAgents",
            "name_full": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning",
            "brief_description": "A cited prior multi-agent AI system that combines LLMs, ontological knowledge graphs, and in-situ learning to automate aspects of scientific discovery; mentioned in related work as precedent.",
            "citation_title": "Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning",
            "mention_or_use": "mention",
            "system_name": "SciAgents",
            "system_type": "multi-agent system combining LLMs and knowledge graphs",
            "scientific_domain": "automated scientific discovery (general)",
            "output_type": "scientific findings / hypotheses (in prior work)",
            "novelty_level": "not assessed in this paper (related work mention)",
            "generation_method": "multi-agent reasoning plus ontological graphs (per citation)",
            "validation_method": "not detailed in this paper (citation only)",
            "generation_performance": null,
            "validation_performance": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": null,
            "generation_validation_comparison": null,
            "uncertainty_quantification": null,
            "calibration_quality": null,
            "out_of_distribution_performance": null,
            "validation_proxy_metrics": null,
            "human_validation_required": null,
            "human_validation_frequency": null,
            "formal_verification_used": null,
            "domain_formalization_level": null,
            "gap_mitigation_strategies": null,
            "evidence_supporting_gap": null,
            "evidence_contradicting_gap": null,
            "computational_cost_ratio": null,
            "uuid": "e2057.4"
        },
        {
            "name_short": "HypoRefine",
            "name_full": "HypoRefine (iterative hypothesis refinement system)",
            "brief_description": "A cited iterative multi-agent approach to hypothesis refinement that synthesizes insights from literature and empirical data; referenced as related work demonstrating iterative refinement approaches.",
            "citation_title": "HypoRefine",
            "mention_or_use": "mention",
            "system_name": "HypoRefine",
            "system_type": "iterative multi-agent/LLM-based hypothesis refinement system",
            "scientific_domain": "automated hypothesis generation/refinement",
            "output_type": "refined hypotheses",
            "novelty_level": "not assessed in this paper (related work mention)",
            "generation_method": "iterative synthesis of literature and data (per citation)",
            "validation_method": "not detailed in this paper (citation only)",
            "generation_performance": null,
            "validation_performance": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": null,
            "generation_validation_comparison": null,
            "uncertainty_quantification": null,
            "calibration_quality": null,
            "out_of_distribution_performance": null,
            "validation_proxy_metrics": null,
            "human_validation_required": null,
            "human_validation_frequency": null,
            "formal_verification_used": null,
            "domain_formalization_level": null,
            "gap_mitigation_strategies": null,
            "evidence_supporting_gap": null,
            "evidence_contradicting_gap": null,
            "computational_cost_ratio": null,
            "uuid": "e2057.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning",
            "rating": 2
        },
        {
            "paper_title": "Hypothesis generation with large language models",
            "rating": 2
        },
        {
            "paper_title": "A comprehensive survey of scientific large language models and their applications in scientific discovery",
            "rating": 2
        },
        {
            "paper_title": "Large language models should be used as scientific reasoning engines, not knowledge databases",
            "rating": 1
        }
    ],
    "cost": 0.017386,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ASTROAGENTS: A MULTI-AGENT AI FOR HYPOTHESIS GENERATION FROM MASS SPECTROMETRY DATA
29 Mar 2025</p>
<p>Daniel Saeedi dsaeedi3@gatech.edu 
Department of Electrical and Computer Engineering
Georgia Institute of Technology Atlanta
GAUSA</p>
<p>Denise Buckner denise.k.buckner@nasa.gov 
NASA Goddard Space Flight Center Greenbelt
MDUSA</p>
<p>José C Aponte jose.c.aponte@nasa.gov 
NASA Goddard Space Flight Center Greenbelt
MDUSA</p>
<p>Amirali Aghazadeh amiralia@gatech.edu 
Department of Electrical and Computer Engineering
Georgia Institute of Technology Atlanta
GAUSA</p>
<p>ASTROAGENTS: A MULTI-AGENT AI FOR HYPOTHESIS GENERATION FROM MASS SPECTROMETRY DATA
29 Mar 20256558E117610728B23EA21CF6500ABCBDarXiv:2503.23170v1[cs.AI]
With upcoming sample return missions across the solar system and the increasing availability of mass spectrometry data, there is an urgent need for methods that analyze such data within the context of existing astrobiology literature and generate plausible hypotheses regarding the emergence of life on Earth.Hypothesis generation from mass spectrometry data is challenging due to factors such as environmental contaminants, the complexity of spectral peaks, and difficulties in cross-matching these peaks with prior studies.To address these challenges, we introduce AstroAgents, a large language model-based, multi-agent AI system for hypothesis generation from mass spectrometry data.AstroAgents is structured around eight collaborative agents: a data analyst, a planner, three domain scientists, an accumulator, a literature reviewer, and a critic.The system processes mass spectrometry data alongside user-provided research papers.The data analyst interprets the data, and the planner delegates specific segments to the scientist agents for in-depth exploration.The accumulator then collects and deduplicates the generated hypotheses, and the literature reviewer identifies relevant literature using Semantic Scholar.The critic evaluates the hypotheses, offering rigorous suggestions for improvement.To assess AstroAgents, an astrobiology expert evaluated the novelty and plausibility of more than a hundred hypotheses generated from data obtained from eight meteorites and ten soil samples.Of these hypotheses, 36% were identified as plausible, and among those, 66% were novel 12 .</p>
<p>Introduction</p>
<p>The rapid growth of spectrometry data from sample return missions to the solar system, where traces of past, extinct, or present life can be found, necessitates methods to analyze this massive, high-dimensional data and generate plausible hypotheses on one of the most fundamental questions in astrobiology: How did life emerge on Earth?[1,2] Analyzing mass spectrometry data in astrobiology is challenged by the presence of terrestrial contaminants [3], the complexity of spectral peaks, and the lack of a systematic approach for hypothesis generation by comparing and contrasting to existing mass spectrometry data [4].Hypothesis generation by human experts is often biased, time-consuming, and limited to the literature that the individual has expertise in [5].Computational methods, on the other hand, are challenged by the sparsity of peaks relevant to the dimension of the mass spectrometry data, which makes identifying patterns extremely difficult [6].</p>
<p>Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in scientific reasoning [7] and hypothesis generation [8,9].However, these models face inherent limitations when deployed individually: They struggle with consistent reasoning over complex datasets, lack specialized domain expertise, and cannot independently validate their outputs against scientific literature [10].These limitations become particularly apparent in origins of life Evaluates the generated hypotheses and suggests improvements.</p>
<p>Figure 1: AstroAgents is a multi-agent system designed to generate and evaluate hypotheses about the molecular distribution of meteoritic and terrestrial samples based on mass spectrometry data.a, The input interface allows users to upload mass spectrometry data (in this case, coupled with gas chromatography (GC)), relevant research papers, and specific instructions to follow.b, The data processing agent analyzes mass spectrometry data, identifies significant patterns, detects unexpected findings, and recognizes potential environmental contamination.c, The planner agent delegates specific segments of the input data to a team of three scientist agents for in-depth analysis.d, The scientist agents generate hypotheses based on distinct aspects of the data, as assigned by the planner agent.In this illustration, the first scientist focuses on unsubstituted polycyclic aromatic hydrocarbons (PAHs), the second examines sulfur and oxygen-containing compounds, and the third investigates alkylated PAHs.e, The accumulator agent consolidates hypotheses generated by the scientist agents, eliminating duplicates.f, The literature review agent searches Semantic Scholar for relevant papers corresponding to each hypothesis and provides summarized findings.g, The critic agent evaluates the generated hypotheses alongside their corresponding literature reviews, offering rigorous critique and suggestions for improvement.The critic agent's feedback is then sent to the data analyst, facilitating an iterative refinement process to enhance subsequent analyses and hypothesis generation.</p>
<p>research, where hypotheses must bridge multiple disciplines and incorporate complex molecular evidence from mass spectrometry data.</p>
<p>Multi-agent architectures have emerged as a promising approach to overcoming the limitations of LLMs.Recent work has shown how multiple AI agents, each with specialized roles, can collaborate to enhance scientific discovery.</p>
<p>SciAgents [11] is a multi-agent AI system that combines LLMs, ontological knowledge graphs, and in-situ learning capabilities to automate scientific discovery.Similarly, HypoRefine [12] offers an iterative approach to hypothesis refinement by synthesizing insights from scientific literature and empirical data.However, existing multi-agent systems often lack the specialized knowledge and structured workflows needed for analyzing complex mass spectrometry data in astrobiology.</p>
<p>Herein, we develop AstroAgents (Fig. 1), a multi-agent system developed to assist astrobiologists in generating hypotheses and uncovering subtle patterns within large-scale mass spectrometry datasets.AstroAgents comprises eight specialized agents working collaboratively: a data analyst, responsible for processing mass spectrometry data, identifying significant patterns, detecting unexpected findings, and recognizing potential environmental contamination; a planner, who delegates specific segments of the input data to a team of three Scientist Agents for in-depth exploration; an accumulator agent, which consolidates hypotheses generated by the scientist agents and eliminates duplicates; a literature review agent searches Semantic Scholar [13] for relevant papers corresponding to each hypothesis and provides summarized findings; and a critic agent, which evaluates the generated hypotheses alongside their corresponding literature reviews, offering rigorous critique and suggestions for improvement.The critic agent's feedback is then sent to the data analyst, enabling an iterative refinement process to enhance the next analyses and hypothesis generation.</p>
<p>We conducted two experiments using AstroAgents powered by different large language models that varied in agentic collaboration ability [14] and context length.In the first experiment, we used Claude Sonnet 3.5, which was supplied with 10 carefully selected research papers for astrobiological context.This configuration generated 48 hypotheses and achieved an average expert evaluation score of 6.58 ± 1.7 (out of 10) while exhibiting fewer logical errors and demonstrating stronger consistency with the literature.In the second experiment, we employed Gemini 2.0 Flash, which was provided with an expanded astrobiological context comprising the same 10 research papers plus an entire book.This model produced 101 hypotheses, achieved an average score of 5.67 ± 0.64, and displayed a higher rate of logical errors, although it tended to generate more novel ideas.Notably, 36 of Gemini 2.0 Flash's hypotheses met the plausibility criteria, with 24 considered novel, whereas none of the hypotheses generated by Claude Sonnet 3.5 were flagged as novel.Overall, AstroAgents is a promising step in facilitating the interpretation of mass spectrometry data and hypotheses generation.</p>
<p>Methods</p>
<p>In this section, we begin by outlining the user input format, then detail the responsibilities of each agent within AstroAgents, and finally describe our approach to evaluating the quality of the generated hypotheses.For every agent, we present both the system prompt and its initial output from the first iteration.Note that these outputs were generated using Claude 3.5 Sonnet.For the complete system prompts, see the Appendix.</p>
<p>User Input</p>
<p>AstroAgents begins by prompting the user to select research papers and books that are closely related to the hypotheses the domain expert aims to generate (Fig. 1a).In the absence of these targeted references, the system tends to generate hypotheses that, while data-supported, are overly general.For example:</p>
<p>"The presence of diverse organic compounds in meteorite samples indicates that these materials could have played a significant role in prebiotic chemistry on early Earth."</p>
<p>Although such a hypothesis is supported by literature, its lack of specificity diminishes its novelty.To mitigate this issue, we require users to provide relevant research papers (see Table S1).Each paper is then converted into the Markdown format using the pymupdf4llm Python package, and the resulting text is used as background knowledge for the data analyst and scientist agents.Following this, users input their mass spectrometry data, which details the identified compounds and the corresponding samples in which they are found, in a LaTeX-formatted table.Finally, users provide additional instructions and detailed descriptions of the data to guide the subsequent analysis.</p>
<p>Data Analyst Agent</p>
<p>The data analyst agent examines mass spectrometry data to uncover key patterns, highlight anomalies, and identify potential environmental contamination (Fig. 1b).It employs a structured prompt template that provides access to mass spectrometry data, astrobiological context extracted from academic papers, and user instructions.After the initial analysis, the agent refines its findings based on feedback from the critic agent.</p>
<p>Following the hypotheses generation phase, an accumulator agent processes the combined output from all three scientist agents (Fig. 1e).This agent performs hypothesis deduplication by identifying and consolidating substantially similar hypotheses, ensuring a streamlined and non-redundant set of hypotheses for further investigation.</p>
<p>Planner Agent</p>
<p>The planner agent, based on data analysis from the data analyst agent, delegates specific segments of the input data to a team of three scientist agents for in-depth exploration (Fig. 1c).This agent is responsible for generating instructions for each of the three scientist agents in JSON format.</p>
<p>Hypothesis Generation Agents</p>
<p>The expanding volume of data increasingly complicates the identification of significant patterns and relationships by individual scientists.To overcome this limitation, we developed a system that enables multiple artificial researchers to concurrently analyze different segments of data.The workflow initiates with a planner agent, which generates detailed instructions for multiple scientist agents.Each scientist agent is assigned a distinct research area and focuses on specific compound IDs for hypothesis generation.Although the number of scientist agents can exceed three, our primary objective was to demonstrate the advantage over using a single scientist agent.A single-agent approach typically concentrates exclusively on one specific research area, such as PAH molecules, thereby neglecting other molecular groups in the dataset.</p>
<p>Each scientist agent, operating within its assigned domain, generates hypotheses in a structured JSON format (Fig. 1d).Each hypothesis entry contains two key components: a statement describing the proposed hypothesis and supporting evidence in the form of key data points that substantiate the hypothesis.</p>
<p>Literature Review and Critic Agent</p>
<p>AstroAgents features an integrated literature review and critique process (Fig. 1f,g).It utilizes the Semantic Scholar [13] to locate relevant research papers for each hypothesis, retrieving and analyzing up to five pertinent paper snippets per query.The literature review agent then processes the search results by extracting key insights, synthesizing information, and presenting a clear, concise summary while highlighting significant findings and potential conflicts.</p>
<p>The critic agent evaluates each hypothesis based on its consistency with experimental data, scientific rigor, theoretical basis from the selected papers, and integration with external literature gathered by literature review agents.The critic particularly focuses on assessing the novelty and specificity of the claims, providing structured feedback to guide the next round of hypothesis refinement.Finally, the critic's response is passed to the Data Analyst agent for further iterative improvements.[ { " i d " : " H_one " , " s t a t e m e n t " : " The p r e s e n c e o f m e t h y l a t e d n a p h t h a l e n e s (2 − m e t h y l n a p h t h a l e n e , 1− m e t h y l n a p h t h a l e n e , t r i m e t h y l n a p h t h a l e n e ) e x c l u s i v e l y i n m e t e o r i t e s a m p l e s b u t n o t i n s o i l s a m p l e s s u g g e s t s t h a t a l k y l a t i o n o f PAHs o c c u r s t h r o u g h a b i o t i c p r o c e s s e s i n s p a c e r a t h e r t h a n t h r o u g h b i o l o g i c a l a c t i v i t y ." , " k e y _ d a t a p o i n t s " : " IDs 2 , 8 , 15 f o u n d i n m e t e o r i t e s ( O r g u e i l , ALH 8 3 1 0 0 , LON 9 4 1 0 1 , Murchison , J b i l e t Winselwan , LEW 8 5 3 1 1 ) b u t a b s e n t i n a l l s o i l s a m p l e s " } , { " i d " : " H_two " , " s t a t e m e n t " : " The co − o c c u r r e n c e o f f l u o r a n t h e n e and p y r e n e ( IDs 1 2 , 1 3 ) s p e c i f i c a l l y i n A n t a r c t i c m e t e o r i t e s s u g g e s t s t h e s e . .</p>
<p>. " } ]</p>
<p>Literature Review Prompt You are a specialized literature review agent analyzing scientific literature search results.Your tasks include:</p>
<ol>
<li>
<p>Analyzing the search results provided below.</p>
</li>
<li>
<p>Extracting and synthesizing key insights.</p>
</li>
</ol>
<p>Critic Prompt</p>
<p>You are an expert scientist in astrobiology and prebiotic chemistry, with deep expertise in PAH analysis and meteoritic organic chemistry.Background Context:
[SELECTED PAPERS]
Your task is to provide a detailed, scientifically rigorous critique of the proposed hypothesis and the associated data analysis...Your critique must include:</p>
<ol>
<li>Alignment with the data... Input Data:
[INPUT DATA]
Literature Review:</li>
</ol>
<p>[LITERATURE REVIEW GOES HERE]</p>
<p>Hypothesis:</p>
<p>[ACCUMULATED HYPOTHESES GOES HERE]</p>
<p>Critic Output</p>
<p>Thank you for providing the detailed hypotheses and data.I'll provide a structured critique of each hypothesis:</p>
<p>H_final_one -Methylated Naphthalenes: Strengths:</p>
<p>-Clear correlation between methylated naphthalenes and meteoritic samples... Critical Weaknesses:</p>
<ol>
<li>Oversimplified causation -The exclusive presence in meteorites doesn't necessarily prove abiotic formation 2. Ignores potential preservation bias -Methylated naphthalenes may form biologically but preserve better in meteoritic matrices ...</li>
</ol>
<p>H_final_two</p>
<p>Experimental Setup</p>
<p>In this section, we describe in detail the experimental setup used to evaluate our AstroAgents, including the acquisition and utilization of mass spectrometry data, the design of our hypothesis-generation experiments, and the configuration of the employed Large Language Model (LLM) agents.Notably, the total cost of all experiments was less than $100.</p>
<p>Mass Spectrometry Data</p>
<p>The data were obtained from eight meteoric and ten terrestrial samples, which were systematically analyzed to assess differences in the molecular distributions of their organic compounds.We employed state-of-the-art mass spectrometric techniques called two-dimensional gas chromatography coupled with high-resolution mass spectrometry (GC×GC-HRTOF-MS).This analysis produced a list of 48 compounds along with their peak information, including retention times (RTs), mass-to-charge ratios (M/Z), and the samples in which they were detected.</p>
<p>Domain Expert Evaluation</p>
<p>To assess the quality of hypotheses generated by AstroAgents, an astrobiology expert performed a systematic evaluation using six criteria: novelty, consistency with existing knowledge, clarity and precision, empirical support, scope and generalizability, and predictive power.Each criterion was rated on a scale from 0 to 10, where 0 signifies a complete lack of the quality (e.g., a novelty score of 0 indicates no originality) and 10 represents the highest possible level.The criteria were defined as follows:</p>
<p>• Novelty: How original is the hypothesis compared to existing literature?</p>
<p>• Consistency with the literature: Does the hypothesis align with established astrobiology research?</p>
<p>• Clarity and precision: Is the hypothesis clearly stated, specific, and unambiguous?</p>
<p>• Empirical Support: To what extent do the mass spectrometry data support the hypothesis?</p>
<p>• Scope &amp; Generalizability: Can the hypothesis explain broader phenomena or be applied to wider contexts?</p>
<p>• Predictive Power: Does the hypothesis make clear, testable predictions?</p>
<p>LLM Agents and Configuration</p>
<p>We conducted two sets of experiments, each comprising 10 iterations.In each experiment, AstroAgents utilizes multiple LLM agents powered by either Claude 3.5 Sonnet or Gemini 2.0 Flash.The choice of models is motivated by distinct capabilities.Claude 3.5 Sonnet was selected for its proven cooperation ability, which is critical for effective multi-agent collaboration [14].In contrast, Gemini 2.0 Flash was chosen for its extended context window (up to 1M tokens), which enables the inclusion of a more comprehensive astrobiological context derived from a wide array of scientific literature.The primary objective of comparing these two models is to investigate how the balance between cooperative ability and the capacity for extended contextual input affects the quality and coherence of generated hypotheses.</p>
<p>Astrobiological Context Integration</p>
<p>To enrich the hypothesis-generation process, both Claude Sonnet 3.5 and Gemini 2.0 Flash were provided with astrobiological context extracted from a curated collection of research papers.Additionally, Gemini 2.0 Flash received a 400-page book [15].For a complete list of referenced sources, please refer to Table S1.This contextual information is intended to ground the agents in relevant domain knowledge and is crucial for interpreting the mass spectrometry data and generating hypotheses in the field of astrobiology.</p>
<p>Results</p>
<p>We selected 10 research papers closely related to the hypotheses that the domain expert aimed to generate.These papers were used as astrobiological knowledge input for Claude Sonnet 3.5.For the Gemini model, we included not only the 10 related papers but also a complete book, taking advantage of Gemini's large 1M input token capacity.We conducted two separate experiments with AstroAgents over 10 iterations: one powered by Claude 3.5 Sonnet, which generated 48 hypotheses, and another powered by Gemini 2.0 Flash, which generated 101 hypotheses (Table 2).Subsequently, an astrobiology expert evaluated each hypothesis on six distinct criteria: novelty, consistency with the literature, clarity and precision, empirical support, scope &amp; generalizability, and predictive power, with scores ranging from 0-10.AstroAgents although the Gemini 2.0 Flash model tended to generate more novel ideas on average.We considered a hypothesis to be novel if its novelty score was greater than or equal to 5, and plausible if the average scores of other criteria were greater than or equal to 8.Among the 101 hypotheses generated by Gemini 2.0 Flash, 36 were determined to be plausible by the expert, and of these, 24 were flagged as novel.Among the 48 hypotheses generated by Claude Sonnet 3.5, 24 were determined to be plausible by the expert, with none flagged as novel.See Table 1 for detailed scores across all criteria per model.</p>
<p>Summary and Discussion</p>
<p>Traditional approaches to analyzing large datasets often fail to uncover nuanced patterns and generate sophisticated hypotheses, typically identifying only basic correlations and trends while missing deeper insights.To address these limitations, we developed a multi-agent framework that employs specialized AI agents, each bringing distinct expertise to the analysis.By carefully crafting prompts, providing relevant research context, and assigning focused analytical objectives to each agent, our system generates novel hypotheses that might be overlooked using conventional methods, as demonstrated in our analysis of mass spectrometry data using AstroAgents.</p>
<p>AstroAgents introduces a novel paradigm that leverages the capabilities of large language models (LLMs) to analyze mass spectrometry data for origin-of-life research.Although this paper primarily focuses on a gas chromatography dataset, our methodology is versatile and can be applied to a wide range of datasets.The comparative performance of Claude 3.5 Sonnet and Gemini 2.0 Flash reveals important insights about the trade-offs between contextual capacity and collaborative ability in multi-agent systems.Claude 3.5 Sonnet's superior performance in consistency and clarity suggests that stronger agent collaboration capabilities may be more valuable than expanded context windows for generating reliable scientific hypotheses.However, Gemini 2.0 Flash's higher novelty scores indicate that larger context windows might facilitate more creative connections across broader knowledge bases.</p>
<p>Despite these promising results, several limitations remain.The system's reliance on human expert evaluation to determine the novelty of hypotheses introduces subjectivity; future research should explore more objective criteria for hypothesis assessment.Furthermore, the system currently depends on pre-selected research papers for context, making its performance heavily reliant on the quality and relevance of the provided literature.Enhancements could include developing dynamic literature-selection capabilities, allowing the system to autonomously identify and incorporate relevant research based on emerging data patterns.AstroAgents demonstrates considerable potential for broader applications across diverse domains requiring the interpretation of complex, high-dimensional data.</p>
<p>A Appendix</p>
<p>We organize the appendix section as follows:</p>
<ol>
<li>System Prompts: Tables displaying the hypotheses generated by AstroAgents during each iteration.2. Tables: Generated hypotheses during each iteration.</li>
</ol>
<p>The outputs from each agent for 10 iterations are available in our GitHub repository here
A</p>
<p>Accumulator Agent</p>
<p>You are an expert astrobiologist and scientific reviewer tasked with evaluating multiple hypotheses generated by different astrobiology scientists.Your job is to combine concatenate the hypotheses and conclusions from the three scientists and discard any repetitive hypotheses.You have received the following hypotheses from three separate scientists: A JSON LISTING ALL HYPOTHESES GENERATED GOES HERE.</p>
<p>Your task is to: 1. Review each hypothesis critically 2. Concatenate the hypotheses and conclusions from the three scientists 3. Discard repetitive hypotheses 4. Make sure to include more than one hypothesis in the final hypothesis list 5. DO NOT include GC or environmental contamination in your hypothesis, the user already knows about it.6. DO NOT recommend any hypothesis about making the data better.Provide your response ONLY as a valid JSON object in the following format, with no additional text before or after: { " hypothesis ": [ { " id ": " Use a format like H_final_one , H_final_two , etc .", " statement ": " Don ' t change the hypothesis statement " , " key_datapoints ": " Don ' t change the key datapoints " , } ] } Ensure the JSON is properly formatted.</p>
<p>Planner Agent</p>
<p>You are an experienced scientific planner and coordinator.Based on the data analysis provided below, your task is to delegate specific areas within the input data across a team of three scientists for in-depth exploration and investigation.Input Data: INPUT DATA GOES HERE <strong>Data Analysis:</strong> DATA ANALYST OUTPUT GOES HERE IMPORTANT: 1.Just focus on the data analysis and divide the among three agents.2. The agents are not able to run tools, they only generate hypotheses based on the area that you delegate to them.3. Make sure to include the ID of the compounds in the task split.4. DO NOT include GC or environmental contamination in your task split, the user already knows about it.5. DO NOT assign any tasks about making the data better and doing further analysis.Based on the above, provide specific instructions for each of the three scientists, clearly indicating what aspect of the data they should focus on.• Assess the theoretical foundations and empirical basis of each hypothesis.</p>
<p>• Evaluate temperature constraints implied by PAH distributions.</p>
<p>• Consider parent body processes like aqueous alteration.</p>
<p>• Identify any assumptions that may not be well supported by the data.</p>
<p>• Point out specific weaknesses in the data analysis or experimental design.</p>
<p>Integration with Literature:</p>
<p>• Critically compare the hypothesis against current research findings.</p>
<p>• Evaluate consistency with known PAH formation mechanisms.</p>
<p>• Consider implications of PAH distributions for formation conditions.</p>
<p>• Identify gaps in the existing literature that the hypothesis addresses or ignores.A.2 Tables Table S1: The list of research papers provided as astrobiological context to Claude Sonnet 3.</p>
<p>A.3 Generated Hypotheses</p>
<p>Table S2: Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 1.</p>
<h1>Statement Key Datapoints</h1>
<p>1 The presence of methylated naphthalenes (2-methyl naphthalene, 1-methyl naphthalene, trimethyl naphthalene) exclusively in meteorite samples but not in soil samples suggests that alkylation of PAHs occurs through abiotic processes in space rather than through biological activity.</p>
<p>IDs</p>
<p>an experiment using GCxGC to analyze biotic (terrestrial) and abiotic (meteorite) samples.I want you to analyze the table and come up with interesting conclusions and hypotheses.Note that your hypotheses should be novel and specific.Delegates specific areas within the input data across a team of three scientists for in-depth exploration and investigation Planner Analyze PAH distribution patterns in meteorites, focus on IDs 1, 2 ... Investigate sulfur-containing and oxygen-containing compounds (IDs 14, 27, 30, 44)... Study the distribution patterns of complex alkylated aromatics and their derivatives (IDs 15, 23) ...Next iteration of hypothesis generation based on critics' feedback</p>
<p>3 .
3
Formatting your summary clearly and concisely.4. Highlighting significant findings and noting any conflicting evidence.Query: [THE LIST OF HYPOTHESES GOES HERE] Search Results: [SEARCH RESULTS GOES HERE] Literature Review Output Hypothesis H_final_one: Here's my analysis of the search results regarding methylated naphthalenes in meteorites versus soil samples: Key Findings: 1. Origin and Formation:PAHs are generally not produced by living organisms and are "essentially in... === Hypothesis H_final_two: Here's my synthesized analysis of the search results regarding the co-occurrence of fluoranthene and pyrene in Antarctic meteorites: Key Findings: 1. Formation Mechanisms &amp; Conditions -Recent isotopic analysis of asteroid Ryugu suggests that two-and four-ring PAHs (including fluoranthene and pyrene) likely formed in low-temperature interstellar environments...</p>
<p>7 2 9 3 8 4 7 7 16 8 6 9 21 11
798716621
5 and Gemini 2.0 Flash models.The checkmarks indicate which papers were included in each model's context, with paper #4 (Strategies of Life Detection) being excluded from Claude Sonnet 3.5's context due to length constraints.an Antarctic carbonaceous chondrite for two reaction pathways of extraterrestrial PAH formation [16] Alkylation of polycyclic aromatic hydrocarbons in carbonaceous chondrites [17] Ultraviolet irradiation of the polycyclic aromatic hydrocarbon (PAH) naphthalene in H2O.Implications for meteorites and biogenesis [18] Strategies of Life Detection [15] 373 5 A combined crossed molecular beam and theoretical investigation of the reaction of the meta-tolyl radical with vinylacetylene -toward the formation of methylnaphthalenes [19] 12 6 A robust, agnostic molecular biosignature based on machine learning [20] Polycyclic aromatic hydrocarbons and amino acids in meteorites and ice samples from LaPaz Icefield, Antarctica [21] Low temperature formation of naphthalene and its role in the synthesis of PAHs (Polycyclic Aromatic Hydrocarbons) in the interstellar medium [22] PAHs, hydrocarbons, and dimethylsulfides in Asteroid Ryugu samples A0106 and C0107 and the Orgueil (CI1) meteorite [23] 14 10 Link between Polycyclic Aromatic Hydrocarbon Size and Aqueous Alteration in Carbonaceous Chondrites Revealed by Laser Mass Spectrometry [24] Molecular indicators (biomarkers) of past life [25] 10</p>
<p>Table 1 :
1
Human Expert Evaluation.This table presents the average scores and their corresponding standard deviation assigned by astrobiology experts to hypotheses generated by two models: Claude Sonnet 3.5 and Gemini 2.0 Flash.Over 10 iterations of AstroAgents, Claude Sonnet 3.5 produced 48 hypotheses while Gemini 2.0 Flash produced 101.Each hypothesis was evaluated on a 0-10 scale across six distinct criteria.Claude Sonnet 3.5 achieved an average score of 6.58 ± 1.7, outperforming Gemini 2.0 Flash's average score of 5.67 ± 0.64.Claude Sonnet 3.5 demonstrated fewer logical errors and greater consistency with the literature,
CriteriaClaude Sonnet 3.5 Gemini 2.0 FlashNovelty2.75 ± 0.754.26 ± 1.87Consistency with the literature7.60 ± 1.916.19 ± 2.88Clarity and precision7.20 ± 2.305.92 ± 2.86Empirical Support6.75 ± 2.635.79 ± 2.86Scope &amp; Generalizability7.60 ± 1.916.01 ± 2.80Predictive Power7.60 ± 1.915.86 ± 2.68Overall Average6.58 ± 1.745.67 ± 0.64powered by</p>
<p>Table 2 :
2
Selected High-Scoring Hypotheses.This table presents four hypotheses generated by AstroAgents that received high ratings from astrobiology experts.Each hypothesis is accompanied by the key data points that AstroAgents identified as supporting evidence.</p>
<h1>StatementKey DatapointsEvaluation Score1 Gemini 2.0 Flash: The presence of 1H-1H-Phenalen-1-oneNovelty: 7/10Phenalen-1-one or 9H-Fluoren-9-one (ID 44,or 9H-Fluoren-9-oneLiterature: 9/10MW 180) exclusively in Orgueil and LEW 85311, and the presence of Biphenyl (ID 43,(ID 44, MW 180): Orgueil, LEW 85311;Clarity/Precision: 9/10MW 154) also in the same meteorites, suggestsBiphenyl (ID 43,Empirical Support: 9/10a unique chemical environment or alteration history shared by these samples, potentially in-MW 154): Orgueil, LEW 85311.Generalizability: 9/10dicating a similar formation region within thePredictive Power: 8/10early solar system. Given their related struc-tures, this may indicate a similar source.2 Gemini 2.0 Flash: The co-occurrence of mul-An unknown com-Novelty: 7/10tiple unknown compounds in Iceland Soil, Ata-pound with m/z 154.0Literature: 10/10cama, and GSFC soil suggests that these soils share similar depositional environments and/oris present in both Green River ShaleClarity/Precision: 10/10source material. This is based on the fact thatsoil and Lignite Soil.Empirical Support: 8/10they all contain ID 4, 5, and 10, which are un-characterized species.Generalizability: 8/10Predictive Power: 8/103 Gemini 2.0 Flash: The detection of toluene,Toluene,Methyl-Novelty: 7/10methylnaphthalenes, acenaphthene, dibenzoth-naphthalenes, Ace-Literature: 10/10iophene, and trimethylnaphthalene in Orgueil and LEW 85311 suggests a common originnaphthene, Dibenzo thiophene, TrimethylClarity/Precision: 10/10or similar formation pathways for these PAHsnaphthalene, Orgueil,Empirical Support: 8/10in both samples. The presence of these com-pounds suggests that these PAHs are relativelyLEW 85311Generalizability: 8/10stable and can be preserved under different en-Predictive Power: 8/10vironmental conditions.4 Claude 3.5 Sonnet: The exclusive detectionID36(1,2,3,4-Novelty: 4/10of 1,2,3,4-tetrahydro phenanthrene (ID 36)tetrahydro phenan-Literature: 8/10in Orgueil and Jbilet Winselwan, along with phenanthrene/anthracene (ID 42), suggests athrene) in Orgueil and Jbilet Winselwan;Clarity/Precision: 8/10specific hydrogenation pathway in certain me-ID 42 (phenan-Empirical Support: 7/10teorite parent bodies that resulted in partial re-duction of aromatic systems. This indicates dis-threne/anthracene) in Orgueil, LEW 85311Generalizability: 8/10tinct redox conditions in different parent bodiesPredictive Power: 8/10during organic synthesis.5 Claude 3.5 Sonnet: The detection of possibleIDs 4, 17, and 18Novelty: 3/10terpenes exclusively in soil samples indicates(possible terpenes)Literature: 10/10that complex branched isoprenoid structures re-quire enzymatic biosynthesis and are not read-were found only in soil samples (IcelandClarity/Precision: 10/10ily formed through abiotic processes in space,Soil, Atacama, UtahEmpirical Support: 10/10making them reliable biomarkers.soil, GSFC soil)Generalizability: 10/10Predictive Power: 10/10</h1>
<p>.1 System Prompts analysis based on the above, with special emphasis on addressing critic feedback.Pay particular attention to rewarded aspects and avoid patterns similar to criticized aspects.
INPUT DATA GOES HERE }Critic Feedback: ]CRITIC FEEDBACK GOES HERE }Provide a refined Literature Review Agent Ensure the JSON is properly formatted.You are a specialized literature review agent analyzing scientific literature searchresults.Your tasks include:1. Analyzing the search results provided below.2. Extracting and synthesizing key insights.3. Formatting your summary clearly and concisely.4. Highlighting significant findings and noting any conflicting evidence.Query:THE LIST OF HYPOTHESIS STATEMENTS GOES HERE.Search Results:SEARCH RESULTS GOES HERE.Provide a well-organized summary addressing the query, key discoveries, research gaps,and include any relevant citations.Astrobiology Scientist AgentYou are a sophisticated astrobiologist and prebiotic chemist specializing in meteoriticorganic compounds.You are Scientist AGENT_ID.Instructions: AGENT_INSTRUCTION.IMPORTANT: Only focus on the data that is assigned to you.Your job is to:1. Generate all hypotheses and conclusions from the <strong>Input Data</strong>.2. You must be original and novel, while considering established formation mechanisms.3. Make conclusions ONLY based on the <strong>Input Data</strong> and the <strong>Instructions</strong>.4. DO NOT include GC or environmental contamination in your hypothesis, the userData Analyst Agent already knows about it.You are a sophisticated analytical scientist specializing in astrobiological data 5. DO NOT recommend any hypothesis about making the data better.analysis, with deep expertise in meteorites. Your knowledge is based on but not Background Context: limited to the following: SELECTED PAPERS FOR BACKGROUND CONTEXT GOES HERE Background Context: <strong>Input Data</strong>: SELECTED PAPERS FOR BACKGROUND CONTEXT GOES HERE INPUT DATA GOES HERE Your tasks include: Based on the above, generate new hypotheses and conclusions as necessary. You must1. Identifying significant patterns and trends in the dataset, especially PAH respond ONLY with a valid JSON object in the following format, with no additional textdistributions and alkylation patterns. before or after:2. Identifying possible environmental contamination in the samples, considering { terrestrial vs. extraterrestrial signatures. " hypothesis ": [3. Highlighting unexpected or unusual findings, particularly regarding temperature {indicators." id ": " Format it like H_one , H_two , etc ." ," statement ": " Explain the hypothesis fully and 4. Comparing data subsets where relevant, especially between different meteorite in detail here ." , classes. " key_datapoints ": " List of compounds and samples that5. MOST IMPORTANTLY: Incorporating critic feedback to guide your analysis. support the hypothesis , directly point to ID orInput Data:compound / sample name ." ,</p>
<p>Your response must be ONLY a valid JSON object with the following format, with no additional text before or after: Your task is to provide a detailed, scientifically rigorous critique of the proposed hypothesis and the associated data analysis.Note that if the <strong>hypotheses</strong> are not exactly aligned with the data, you should discard the hypothesis and generate a new one.Your critique must include:1.Alignment with the data:• Assess the alignment of the hypothesis with the data.• Evaluate if the proposed mechanisms align with observed PAH distributions and temperature indicators.• Consider if the hypothesis accounts for both chemical and physical processes in meteorite parent bodies.• If the hypothesis is not exactly aligned with the data, you should discard it and generate a new one.2. Scientific Evaluation:
{" A g en t 1_ i n st r uc t io n s ": " Detailed instructions forwhat Scientist 1 should focus on ." ," A g en t 2_ i n st r uc t io n s ": " Detailed instructions forwhat Scientist 2 should focus on ." ," A g en t 3_ i n st r uc t io n s ": " Detailed instructions forwhat Scientist 3 should focus on ."}Ensure the JSON is properly formatted.Critic AgentYou are an expert scientist in astrobiology and prebiotic chemistry, with deepexpertise in PAH analysis and meteoritic organic chemistry.Background Context:SELECTED PAPERS FOR BACKGROUND CONTEXT GOES HERE</p>
<p>•</p>
<p>Propose additional sources or studies that could reinforce or challenge the claims.4.IMPORTANT: Novelty and originality are highly rewarded based on literature review.Punish <strong>hypotheses</strong> that are not novel or original.5. Punish hypothesis statements that are vague and too general.Reward specific and detailed <strong>hypotheses</strong> based on the data and analysis.6. Avoid suggesting any improvements to the input data.Only critique the <strong>hypotheses</strong>.
Input Data:INPUT DATALiterature Review:LITERATURE REVIEW GOES HERE<strong>Hypothesis</strong>:ACCUMULATED HYPOTHESES GOES HEREProvide your critique in a clear and structured format, ensuring that your comments areactionable and aimed at improving the hypothesis and data analysis.Your scientific critique:</p>
<p>Table S3 :
S3
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 2.
2, 8, 15 found inmeteorites (Orgueil, ALH83100, LON 94101, Murchi-son, Jbilet Winselwan, LEW85311) but absent in all soilsamples2 The co-occurrence of fluoranthene and pyrene (IDs 12,13)IDs 12,13 found togetherspecifically in Antarctic meteorites suggests these PAHs formin Antarctic meteorites ALHthrough similar abiotic mechanisms under cold conditions,83100, LON 94101, LEWpossibly through ion-molecule reactions in interstellar ice # Statement85311 Key Datapointsanalogs. 3 The presence of organosulfur compounds (dibenzo thiophene, 1,2,4-trithiolane) exclusively in meteorites indicates that sul-fur incorporation into organic compounds occurs through unique abiotic pathways in space, possibly catalyzed by min-1 The presence of methylated PAHs (e.g., methylnaphthalenes) predominantly in meteorite samples but not in soil samples suggests that abiotic methylation of PAHs occurs through distinct chemical pathways in space that are not common in terrestrial environments. eral surfaces.ID 2 (2-methylnaphthalene), IDs 14,27 found only in ID 8 (1-methylnaphthalene), meteorite samples Orgueil, ID 15 (trimethylnaphthalene) ALH 83100, LEW 85311, found mainly in meteorites Aguas Zarcas Orgueil, ALH 83100, Murchison, and LEW 85311,4 The detection of terpene-like compounds exclusively inIDs 4,17,18 found only in but absent in soil samplessoil samples but not in meteorites suggests these complex branched molecules require biological processes for their syn-2 The co-occurrence of organosulfur compounds (dibenzoth-iophene, trithiolane) specifically in meteorites suggests that thesis and are reliable biomarkers for distinguishing biotic sulfur incorporation into aromatic structures was an important from abiotic samples. abiotic process in the early solar system, possibly catalyzedsoil samples (Iceland, Ata-ID 14 (dibenzothiophene) in cama, Utah, GSFC soils) Orgueil/ALH 83100/LEW 85311, ID 27 (1,2,4-trithiolane) in Aguas5 The presence of oxidized PAHs (1H-Phenalen-1-one/9H-by mineral surfaces under reducing conditions.ID 44 found only in Orgueil Zarcas/LEW 85311Fluoren-9-one) specifically in Orgueil and LEW 85311 mete-3 The exclusive presence of high molecular weight PAHs (fluo-orites suggests these compounds form through unique parent ranthene, pyrene, dimethylpyrene) in meteorites but not soils body aqueous alteration processes rather than biological ac-indicates that extended PAH structures preferentially formed tivity. and survived in space environments, possibly through step-and LEW 85311 meteorites ID 12 (fluoranthene), ID 13 (pyrene), ID 45 (dimethylpyrene) found only in meteorites like Orgueil,wise molecular growth via acetylene additions under cosmicALH 83100, LON 94101,ray exposure.LEW 853114 The exclusive presence of certain cyclic compounds (indane,ID 11 (indane), ID 23methylindan, tetrahydrophenanthrene) in meteorites suggests(methylindan),ID 36a specific abiotic synthetic pathway involving sequential ring(tetrahydrophenanthrene)formation and reduction that is unique to space chemistry andfound only in meteoritedistinct from biological aromatic synthesis.samples5 The detection of ergostene exclusively in soil samples sug-ID 28 (ergost-14-ene) foundgests it serves as a reliable biomarker for distinguishing bioticonly in Lignite Soil andfrom abiotic organic matter, as its complex structure likelyMurchison Soil samplesrequires enzymatic biosynthesis rather than abiotic processes.</p>
<p>Table S4 :
S4
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 3.</p>
<h1>StatementKey Datapoints1 The presence of methylated naphthalenes (IDs 2, 8, 15) inID 2 (2-Methyl naphthalene),meteorites but not in terrestrial soils suggests that abioticID 8 (1-Methyl naphthalene),methylation of PAHs occurs through distinct chemical path-ID 15 (Trimethyl naphtha-ways in space that are not prevalent in Earth's biosphere. Thislene) found in Orgueil, ALHindicates a potential chemical marker for distinguishing abi-83100, Murchison, LEWotic from biotic organic matter.85311 meteorites but absentin all soil samples2 The co-occurrence of sulfur-containing aromatics (dibenzoth-ID 14 (Dibenzothiophene)iophene, trithiolane) exclusively in meteorite samples sug-in Orgueil, ALH 83100,gests that sulfur incorporation into PAHs was a significantLEW 85311; ID 27 (1,2,4-abiotic process in the early solar system, possibly catalyzedTrithiolane) in Aguas Zarcas,by mineral surfaces under reducing conditions.LEW 853113 The presence of fluoranthene and pyrene (IDs 12, 13) exclu-ID 12 (Fluoranthene) in ALHsively in meteorites, coupled with their absence in terrestrial83100, LON 94101, LEWsamples, suggests these 4-ring PAHs formed through spe-85311; ID 13 (Pyrene) incific high-temperature gas-phase reactions in the solar nebulaOrgueil, LON 94101, LEWrather than through biological processes.85311; absent in all soil sam-ples4 The exclusive presence of ergost-14-ene (ID 28) in soil sam-ID 28 found only in Ligniteples suggests it serves as a reliable biomarker for distinguish-Soil and Murchison Soil, ab-ing between biotic and abiotic organic matter sources, as it issent in all meteorite sampleslikely derived from biological steroid synthesis pathways.5 The presence of terpene-like compounds exclusively in soilID 4, ID 17, ID 18 (possi-samples suggests these complex branched molecules requireble terpenes) found only inbiological synthesis pathways and cannot form through abioticIceland Soil, Atacama, Utahprocesses in meteoritic parent bodies.soil, GSFC soil</h1>
<p>Table S5 :
S5
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 4.</p>
<h1>StatementKey Datapoints1 The presence of methylated PAHs (e.g., methylnaphthalenes,IDs2,8(methylnaph-trimethylnaphthalenes) predominantly in meteorite samplesthalenes) found in meteoritesbut not in soil samples suggests that alkylation of PAHs oc-Orgueil,ALH 83100,curs through abiotic processes in space rather than throughMurchison; ID 15 (trimethyl-biological activity.naphthalene) in Orgueil,Jbilet Winselwan, LEW85311; notably absent in soilsamples2 The presence of both fluoranthene (ID 12) and pyrene (ID 13)ID12(fluoranthene)exclusively in meteorite samples, coupled with their dimethy-in ALH 83100, LONlated derivative (ID 45), indicates a high-temperature PAH94101, LEW 85311; ID 13formation pathway specific to extraterrestrial environments.(pyrene) in Orgueil, LONThe absence of these compounds in soil samples suggests94101, LEW 85311; ID 45they are not products of biological processes or terrestrial(dimethylpyrene) in Orgueil,contamination.LEW 853113 The exclusive detection of 1,2,3,4-tetrahydro phenanthreneID 36 (1,2,3,4-tetrahydro(ID 36) in Orgueil and Jbilet Winselwan, along with phenan-phenanthrene) in Orgueil andthrene/anthracene (ID 42), suggests a specific hydrogenationJbilet Winselwan; ID 42pathway in certain meteorite parent bodies that resulted in(phenanthrene/anthracene) inpartial reduction of aromatic systems. This indicates distinctOrgueil, LEW 85311redox conditions in different parent bodies during organicsynthesis.4 The exclusive presence of certain terpenes and sesquiterpenesIDs 4, 17, 18 (terpenes/s-in extreme environment soils (Iceland, Atacama) but not inesquiterpenes) found only inmeteorites indicates these compounds are reliable biomarkersIceland Soil, Atacama, andfor extremophilic life, even in harsh conditions that mightRio Tinto Soil samplesresemble early Mars.5 The detection of ergost-14-ene exclusively in soil samplesID 28 (ergost-14-ene) foundindicates it is a reliable biomarker for eukaryotic life, as it isonly in Lignite Soil anda degradation product of ergosterol found in fungi and someMurchison Soilprotists.</h1>
<p>Table S6 :
S6
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 5.</p>
<h1>StatementKey Datapoints1 The presence of methylated PAHs (e.g., methylnaphthalenes,ID 2 (2-methylnaphthalene),trimethylnaphthalenes) predominantly in meteorite samplesID 8 (1-methylnaphthalene),but not in soil samples suggests that alkylation of PAHs oc-ID 15 (trimethylnaphthalene)curs through abiotic processes in space rather than throughfound mainly in meteoritesbiological activity.Orgueil,ALH 83100,Murchison, LEW 853112 The co-occurrence of organosulfur compounds (dibenzothio-ID 14 (dibenzothiophene)phene, trithiolane) exclusively in meteorite samples suggestsin Orgueil, ALH 83100,that sulfur incorporation into organic compounds was an im-LEW 85311; ID 27 (1,2,4-portant abiotic process in the early solar system, possiblytrithiolane) in Aguas Zarcas,catalyzed by metal sulfides present in the meteorite parentLEW 85311bodies.3 The presence of high molecular weight PAHs (fluoranthene,ID 12 (fluoranthene) and IDpyrene) exclusively in meteorites suggests that these com-13 (pyrene) found only in me-pounds form through high-temperature gas-phase reactions inteorites ALH 83100, LONspace rather than biological processes, as evidenced by their94101, Orgueil, LEW 85311absence in biologically active soil samples.4 The presence of both ketone-containing PAHs (1H-Phenalen-ID 44 (1H-Phenalen-1-1-one) and reduced PAHs in meteorites indicates alternatingone) and ID 36 (1,2,3,4-oxidizing and reducing conditions during PAH formation intetrahydrophenanthrene) inthe solar nebula or on parent bodies.Orgueil and other meteorites5 The presence of partially hydrogenated PAHs (like 1,2,3,4-ID36(1,2,3,4-tetrahydrophenanthrene) alongside their fully aromatic coun-tetrahydrophenanthrene) andterparts (phenanthrene) in meteorites suggests a low-ID 42 (phenanthrene) intemperature formation pathway for PAHs in the early so-Orgueil and other meteoriteslar system, rather than high-temperature combustion whichwould favor fully aromatic species.</h1>
<p>Table S7 :
S7
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 6.</p>
<h1>StatementKey Datapoints1 The presence of methylated naphthalenes (IDs 2, 8, 15) inIDs 2 (2-Methyl naph-meteorites but not in soil samples suggests that abiotic methy-thalene),8 (1-Methyllation of PAHs occurs through distinct chemical pathways innaphthalene),and15space that are not prevalent in Earth's biotic systems. This in-(Trimethylnaphthalene)dicates a potential chemical marker for distinguishing abioticfound in Orgueil, ALHfrom biotic origins of PAHs.83100, Murchison, and othermeteorites but absent in soilsamples2 The co-occurrence of dibenzothiophene with fluoranthene andID 14 (dibenzothiophene),pyrene specifically in meteorite samples suggests that sulfurID 12 (fluoranthene), ID 13incorporation into PAHs in space requires high-energy condi-(pyrene) found together intions that also favor the formation of 4-ring PAHs, potentiallyOrgueil, ALH 83100, LONthrough radical mechanisms in cold environments.94101, LEW 853113 The presence of phenanthrene/anthracene (ID 42) and 1H-IDs 42 and 44 found onlyPhenalen-1-one/9H-Fluoren-9-one (ID 44) exclusively inin Orgueil and LEW 85311;Orgueil and LEW 85311 suggests a unique oxidative pathwayrelated to oxidation of PAHin these meteorites that converts PAHs to their oxygenatedstructuresderivatives, potentially indicating distinct parent body pro-cessing conditions.4 The detection of possible terpenes exclusively in soil samplesIDs 4, 17, 18 (possible ter-indicates that complex branched isoprenoid structures requirepenes) found only in soilenzymatic biosynthesis and are not readily formed throughsamples (Iceland Soil, Ata-abiotic processes in space, making them reliable biomarkers.cama, Utah soil, GSFC soil)</h1>
<p>Table S8 :
S8
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 7.</p>
<h1>StatementKey Datapoints1 The presence of methylated PAHs (e.g., methylnaphthalenes,ID 2 (2-methylnaphthalene),trimethylnaphthalenes) predominantly in meteorite samplesID 8 (1-methylnaphthalene),but not in soil samples suggests that alkylation of PAHs oc-ID 15 (trimethylnaphthalene)curs through abiotic processes in space rather than throughfound mainly in meteoritesbiological activity.Orgueil,ALH 83100,Murchison, LEW 853112 The co-occurrence of organosulfur compounds (dibenzothio-ID 14 (dibenzothiophene)phene, trithiolane) specifically in meteorite samples suggestsin Orgueil, ALH 83100,that sulfur incorporation into organic compounds was an im-LEW 85311; ID 27 (1,2,4-portant abiotic process in the early solar system, possiblytrithiolane) in Aguas Zarcas,catalyzed by metal sulfides present in the meteorite parentLEW 85311bodies.3 The presence of 1,2,3,4-tetrahydro phenanthrene (ID 36) ex-ID 36 (1,2,3,4-tetrahydroclusively in Orgueil and Jbilet Winselwan, along with theirphenanthrene) and ID 45unique dimethylpyrene content (ID 45), suggests these mete-(dimethylpyrene) in Orgueilorites experienced similar parent body processing conditionsand Jbilet Winselwan; Distri-that were distinct from other carbonaceous chondrites.bution pattern distinct fromother meteorites4 The co-occurrence of phenanthrene/anthracene with their oxy-ID 42 (phenanthrene/an-genated derivatives (1H-Phenalen-1-one/9H-Fluoren-9-one)thracene) and ID 44specifically in meteorites suggests an abiotic oxidation path-(1H-Phenalen-1-one/9H-way that operates in space but not in terrestrial environments.Fluoren-9-one)foundtogether in Orgueil and LEW85311</h1>
<p>Table S9 :
S9
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 8.The presence of terpene-like compounds exclusively in soil samples (particularly from extreme environments like Iceland and Atacama) suggests these molecules are reliable biosignatures even in harsh conditions that might be analogous to other planetary environments.</p>
<h1>StatementKey Datapoints1 The presence of methylated PAHs (e.g., methylnaphthalenes,ID 2 (2-methylnaphthalene),trimethylnaphthalene) predominantly in meteorite samplesID 8 (1-methylnaphthalene),but not in soil samples suggests that alkylation of PAHs oc-ID 15 (trimethylnaphthalene)curs through abiotic processes in space rather than throughfound mainly in meteoritesbiological activity.Orgueil,ALH 83100,Murchison, LEW 853112 The co-occurrence of organosulfur compounds (dibenzothio-ID 14 (dibenzothiophene)phene, trithiolane) specifically in meteorite samples suggestsin Orgueil, ALH 83100,that sulfur incorporation into organic compounds was an im-LEW 85311; ID 27 (1,2,4-portant abiotic process in the early solar system, possiblytrithiolane) in Aguas Zarcas,catalyzed by metal sulfides present in the meteorite parentLEW 85311; notably absentbodies.in all soil samples3 The presence of high molecular weight PAHs (fluoranthene,ID 12 (fluoranthene) and IDpyrene) exclusively in meteorites but not in soil samples indi-13 (pyrene) found only in me-cates that these compounds form through high-temperatureteorites ALH 83100, LONgas-phase reactions in space rather than through biological94101, Orgueil, LEW 85311processes.4 The presence of partially hydrogenated aromatic compoundsID 11 (indane) in ALH(indane, acenaphthene, tetrahydrophenanthrene) specifically83100, LON 94101, LEWin meteorites suggests a stepwise PAH formation process85311; ID 33 (acenaphthene)in space involving both aromatic ring formation and partialin ALH 83100, LEW 85311;hydrogenation steps.ID 36 (tetrahydrophenan-threne) in Orgueil, JbiletWinselwan5 ID 4, ID 17, ID 18 (possi-ble terpenes/sesquiterpenes)found only in soil sam-ples from Iceland, Atacama,Utah, and GSFC</h1>
<p>Table S10 :
S10
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 9.The presence of methylated PAHs (e.g., methylnaphthalenes, trimethylnaphthalenes) predominantly in meteorite samples but not in soil samples suggests that alkylation of PAHs occurs through abiotic processes in the early solar system rather than through biological activity.The co-occurrence of fluoranthene and pyrene (IDs 12,13) exclusively in meteorites, combined with their absence in all soil samples, indicates these 4-ring PAHs are formed through specific high-temperature abiotic processes in space rather than biological processes on Earth.The presence of partially hydrogenated PAHs (like indane and acenaphthene) specifically in meteorites suggests a stepwise PAH formation process in space involving hydrogenation steps, rather than direct synthesis of fully aromatic systems.</p>
<h1>StatementKey Datapoints1 ID 2,8 (methylnaphthalenes)in Orgueil, ALH 83100,Murchison; ID 15 (trimethyl-naphthalene) in Orgueil,Jbilet Winselwan, LEW85311; Notably absent insoil samples2 ID 12 (fluoranthene) in ALH83100, LON 94101, LEW85311; ID 13 (pyrene) inOrgueil, LON 94101, LEW853113 The presence of organosulfur compounds (1,2,4-trithiolaneID 14 (dibenzothiophene) inand dibenzothiophene) exclusively in meteoritic samples sug-Orgueil, ALH 83100, LEWgests that sulfur incorporation into organic compounds oc-85311; ID 27 (trithiolane) incurred through unique chemical pathways in the early solarAguas Zarcas, LEW 85311system, possibly catalyzed by mineral surfaces under reduc-ing conditions.4 The exclusive detection of terpene-like compounds in soilID 4,17,18 (possible ter-samples but not in meteorites indicates these compounds arepenes) found only in Icelandreliable biomarkers for distinguishing biological from abioticSoil, Atacama, Utah soil,organic matter sources.GSFC soil5 ID 11 (indane) in ALH83100, LON 94101, LEW85311; ID 33 (acenaphthene)in ALH 83100, LEW 85311;ID 36 (tetrahydrophenan-threne) in Orgueil, JbiletWinselwan</h1>
<p>Table S11 :
S11
Generated hypotheses by AstroAgents powered by Claude Sonnet 3.5 -Iteration 10.The presence of methylated PAHs (e.g., methylnaphthalenes, trimethylnaphthalenes) predominantly in meteorite samples but not in soil samples suggests that abiotic methylation of PAHs occurs through unique chemical pathways in space that are distinct from biological methylation processes on Earth.The co-occurrence of dibenzothiophene (C12H8S) and 1,2,4trithiolane (C2H4S3) exclusively in meteorite samples suggests a distinct sulfur incorporation pathway in abiotic PAH formation, possibly linked to cosmic ray or UV-induced sulfurization of organic matter in space.The presence of high molecular weight PAHs (fluoranthene and pyrene) exclusively in meteorites suggests that abiotic PAH formation in space favors condensation reactions leading to larger ring systems, while biological PAH production on Earth tends toward smaller aromatic compounds.The co-occurrence of phenanthrene/anthracene with their oxygenated derivatives (1H-Phenalen-1-one/9H-Fluoren-9-one) specifically in meteorites suggests an abiotic oxidation pathway that operates in space but not in terrestrial environments.</p>
<h1>StatementKey Datapoints1 ID 2,8 (methylnaphthalenes)found in meteorites Orgueil,ALH 83100, Murchison; ID15 (trimethylnaphthalene) inOrgueil, Jbilet Winselwan,LEW 85311; Notably absentin most soil samples2 ID 14 (dibenzothiophene)in Orgueil, ALH 83100,LEW 85311; ID 27 (1,2,4-trithiolane) in Aguas Zarcas,LEW 853113 ID 12 (fluoranthene) andID 13 (pyrene) found onlyin meteorites ALH 83100,LON 94101, LEW 85311,Orgueil; Smaller PAHs likeID 7 (toluene) more commonin soil samples4 The exclusive presence of terpene-like compounds in soilID 4, 17, 18 (possible ter-samples but not in meteorites indicates these compounds arepenes) found only in biologi-reliable biomarkers for distinguishing biological from abioticcal samples like Iceland Soil,organic matter sources.Atacama, Utah soil; absentin all meteorite samples5 ID 42 (phenanthrene/an-thracene) and ID 44(1H-Phenalen-1-one/9H-Fluoren-9-one)foundtogether in Orgueil and LEW85311 meteorites</h1>
<p>Project website: https://astroagents.github.io/
Code is available at: https://github.com/amirgroup-codes/AstroAgents
AcknowledgmentsThis research was supported by the Parker H. Petit Institute for Bioengineering and Biosciences (IBB) interdisciplinary seed grant, the Institute of Matter and Systems (IMS) Exponential Electronics seed grant, and the Georgia Institute of Technology start-up funds.
The emergence of life on earth. Noam Lahav, Shlomo Nir, Avshalom C Elitzur, Progress in Biophysics and Molecular Biology. 7512001</p>
<p>The origin of life: what we know, what we can know and what we will never know. Addy Pross, Robert Pascal, Open Biology. 331201902013</p>
<p>Abundant ammonia and nitrogen-rich soluble organic matter in samples from asteroid (101955) bennu. P Daniel, Jason P Glavin, Dworkin, M Conel, O'd. Alexander, Nature Astronomy. 2025</p>
<p>Nobel turing challenge: creating the engine for scientific discovery. Hiroaki Kitano, Systems Biology and Applications. 7292021</p>
<p>Publication bias and the canonization of false facts. eLife. S B Nissen, T Magidson, K Gross, C T Bergstrom, 20165e21451</p>
<p>Addressing big data challenges in mass spectrometry-based metabolomics. J Guo, H Yu, S Xing, T Huan, Chemical Communications. August 16 2022</p>
<p>Large language models should be used as scientific reasoning engines, not knowledge databases. Daniel Truhn, S José, Jakob N Reis-Filho, Kather, Nature Medicine. 292023</p>
<p>Hypothesis generation with large language models. Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, Chenhao Tan, Proceedings of the 1st Workshop on NLP for Science (NLP4Science). Lotem Peled-Cohen, Nitay Calderon, Shir Lissak, Roi Reichart, the 1st Workshop on NLP for Science (NLP4Science)Miami, FL, USAAssociation for Computational LinguisticsNovember 2024</p>
<p>A comprehensive survey of scientific large language models and their applications in scientific discovery. Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, Jiawei Han, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Yaser Al-Onaizan, Mohit Bansal, Yun-Nung Chen, the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational LinguisticsNovember 2024</p>
<p>Challenges and applications of large language models. Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, Robert Mchardy, 2023</p>
<p>Sciagents: Automating scientific discovery through multi-agent intelligent graph reasoning. Alireza Ghafarollahi, Markus J Buehler, 2024</p>
<p>Literature meets data: A synergistic approach to hypothesis generation. Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan, 2025</p>
<p>The semantic scholar open data platform. Rodney Michael Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczynski, Isabel Cachola, Stefan Candra, Yoganand Chandrasekhar, Arman Cohan, Miles Crawford, Doug Downey, Jason Dunkelberger, Oren Etzioni, Rob Evans, Sergey Feldman, Joseph Gorney, David W Graham, F Q Hu, Regan Huff, Daniel King, Sebastian Kohlmeier, Bailey Kuehl, Michael Langan, Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey Macmillan, Tyler C Murray, Christopher Newell, Shaurya Smita R Rao, Paul Rohatgi, Zejiang Sayre, Amanpreet Shen, Luca Singh, Shivashankar Soldaini, A Subramanian, Alex D Tanaka, Linda M Wade, Lucy Lu Wagner, Christopher Wang, Caroline Wilhelm, Jiangjiang Wu, Angele Yang, Madeleine Zamarron, Daniel S Van Zuylen, Weld, ArXiv, abs/2301.101402023</p>
<p>Cultural evolution of cooperation among llm agents. Aron Vallinder, Edward Hughes, 2024</p>
<p>Franck Selsis, and Robert Summons. Strategies of Life Detection. Oliver Botta, Jeffrey Bada, Javier Gómez Elvira, Emmanuelle Javaux, 2008</p>
<p>Isotopic evidence from an antarctic carbonaceous chondrite for two reaction pathways of extraterrestrial pah formation. Hiroshi Naraoka, Akira Shimoyama, Kaoru Harada, Earth and Planetary Science Letters. 18412000</p>
<p>Alkylation of polycyclic aromatic hydrocarbons in carbonaceous chondrites. Jamie E Elsila, Nathalie P De Leon, Peter R Buseck, Richard N Zare, Geochimica et Cosmochimica Acta. 6952005</p>
<p>Ultraviolet irradiation of the polycyclic aromatic hydrocarbon (pah) naphthalene in h2o. implications for meteorites and biogenesis. M P Bernstein, J P Dworkin, S A Sandford, L J Allamandola, Advances in Space Research. 3062002</p>
<p>A combined crossed molecular beam and theoretical investigation of the reaction of the meta-tolyl radical with vinylacetylene -toward the formation of methylnaphthalenes. Tao Yang, Lloyd Muzangwa, Ralf I Kaiser, Adeel Jamal, Keiji Morokuma, Phys. Chem. Chem. Phys. 172015</p>
<p>A robust, agnostic molecular biosignature based on machine learning. H James Cleaves, Grethe Hystad, Anirudh Prabhu, Michael L Wong, George D Cody, Sophia Economon, Robert M Hazen, Proceedings of the National Academy of Sciences. 12041e23071491202023</p>
<p>Polycyclic aromatic hydrocarbons and amino acids in meteorites and ice samples from lapaz icefield, antarctica. Botta Oliver, Zita Martins Christian, Emmenegger , Jason P Dworkin, Daniel P Glavin, Ralph P Harvey, Renato Zenobi , Jeffrey L Bada, Pascale Ehrenfreund, Meteoritics &amp; Planetary Science. 4392008</p>
<p>Low temperature formation of naphthalene and its role in the synthesis of pahs (polycyclic aromatic hydrocarbons) in the interstellar medium. Dorian S N Parker, Fangtong Zhang, Y Seol Kim, Ralf I Kaiser, Alexander Landera, V Vadim, Alexander M Kislov, A G G M Mebel, Tielens, Proceedings of the National Academy of Sciences. 10912012</p>
<p>C José, Jason P Aponte, Daniel P Dworkin, Jamie E Glavin, Eric T Elsila, Hannah L Parker, Hiroshi Mclain, Ryuji Naraoka, Yoshinori Okazaki, Shogo Takano, Guannan Tachibana, Sarah S Dong, John M Zeichner, Hisayoshi Eiler, Tomoki Yurimoto, Hikaru Nakamura, Fuyuto Yabuta, Takaaki Terui, Kanako Noguchi, Toru Sakamoto, Masahiro Yada, Aiko Nishimura, Akiko Nakato, Kasumi Miyazaki, Masanao Yogata, Tatsuaki Abe, Tomohiro Okada, Makoto Usui, Takanao Yoshikawa, Satoshi Saiki, Satoru Tanaka, Yuichi Nakazawa, Tsuda, The Hayabusa2 initial-analysis SOM team, and The Hayabusa2 initial-analysis core team. Pahs, hydrocarbons, and dimethylsulfides in asteroid ryugu samples a0106 and c0107 and the orgueil (ci1) meteorite. Earth, Planets and Space. Sei ichiro Watanabe20237528</p>
<p>Link between polycyclic aromatic hydrocarbon size and aqueous alteration in carbonaceous chondrites revealed by laser mass spectrometry. Katerina Slavicinska, Dumitru Duca, Dmitrii Egorov, Tirthankar Mitra, Yvain Carpentier, Cristian Focsa, Christopher J Bennett, Claire Pirim, ACS Earth and Space Chemistry. 662022</p>
<p>Molecular indicators (biomarkers) of past life. B R Simoneit, Anatomical Record. 2683November 2002</p>            </div>
        </div>

    </div>
</body>
</html>