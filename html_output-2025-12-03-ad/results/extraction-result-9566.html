<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9566 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9566</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9566</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-279320573</p>
                <p><strong>Paper Title:</strong> Primer on large language models: an educational overview for intensivists</p>
                <p><strong>Paper Abstract:</strong> The integration of artificial intelligence (AI) and machine learning-enabled medical technologies into clinical practice is expanding at an unprecedented pace. Among these, large language models (LLMs) represent a subset of machine learning designed to comprehend linguistic patterns, semantics, and contextual meaning by processing vast amounts of textual data. This educational primer aims to inform intensivists on the foundational concepts of LLMs and how to approach emerging literature in this area. In critical care, LLMs have the potential to enhance various aspects of patient management, from triage and clinical documentation to diagnostic support and prognostic assessment of patient deterioration. They have also demonstrated high appropriateness in addressing critical care-related clinical inquiries and are increasingly recognized for their role in post-ICU rehabilitation and as educational resources for patients’ families and caregivers. Despite these promising applications, LLMs still have significant limitations, and integrating LLMs into clinical workflows presents inherent challenges, particularly concerning bias, reliability, and transparency. Given their emerging role as decision-support tools and potential collaborative partners in medicine, LLMs must adhere to rigorous validation and quality assurance standards. As the trajectory toward AI-driven healthcare continues, responsible and evidence-based integration of LLMs into critical care practice is imperative to optimize patient outcomes while ensuring ethical and equitable deployment. Supplementary Information The online version contains supplementary material available at 10.1186/s13054-025-05479-4.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9566",
    "paper_id": "paper-279320573",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.004158,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Primer on large language models: an educational overview for intensivists</p>
<p>Daphna Idan daphnaid@post.bgu.ac.il 
Ben-Gurion Faculty of Health Sciences
Beer-ShevaIsrael</p>
<p>Sharon Einav 
Faculty of Medicine and Regional Medical Director at Maccabi Healthcare and Chief Scientist
Medint Medical Intelligence
Hebrew University</p>
<p>Hebrew University
JerusalemIsrael</p>
<p>Primer on large language models: an educational overview for intensivists
383E6EFF6E2428A8A3A75AEA868C357C10.1186/s13054-025-05479-4Received: 2 March 2025 / Accepted: 30 May 2025Large language modelsCritical careArtificial intelligence
Artificial intelligence (AI) is broadly defined as the seeming ability of a device to perform tasks that typically require human cognitive skills, such as reasoning, learning, and decision-making.At its core, AI is intended to embody the capacity to "do the right thing" in a given context by employing logic-based methods efficiently and safely.Early AI systems were designed to achieve specific outcomes for well-defined tasks and are therefore often referred to as task-specific AIs.Typical examples are the early customer service chatbots, which relied on rigid rules to recognize specific keywords and generate preprogrammed responses to these words.These simple systems relied on algorithms -mathematical constructs first formalized in the ninth century by the Persian mathematician Muhammad ibn Musa al-Khwarizmi.Algorithms</p>
<p>Introduction</p>
<p>In 2022, the US Food and Drug Administration (FDA) approved 139 medical devices incorporating artificial intelligence (AI) [1].By August 2024, this number had surged to 950 AI or machine learning-enabled medical devices [2], highlighting the exponential growth of AI integration into medicine in general and clinical practice in particular [3].define specific rules for specific outcomes and have been the foundation of decision-making models for centuries [4].</p>
<p>More recently, AI has gained an additional layer of sophistication -the ability to learn from vast datasets (i.e., big data).This progress has given rise to neural networks, which mimic the interconnected pathways of the brain to model complex relationships.Neural networks evaluate multiple possible pathways and select the most probable outcome (probabilistic reasoning).Bayesian statistics comprise a critical component of this process.Bayesian methods may be applied to all types of data, and they are typically used to calculate outcome likelihoods based on prior probabilities and new evidence.The resultant outputs of these methods are ranges of confidence related to the likelihood of the outcome (i.e., confidence intervals) rather than a definitive answer (i.e., cutoff levels).While highly effective, Bayesian approaches to data highlight a fundamental AI challenge -the need to balance statistical precision with uncertainty.Or, in other words, creative problem-solving.</p>
<p>Here enters generative AI, whose emergence marked another milestone in AI development.Generative AI models differ from earlier models in the production of outputs for new inputs, based on learned patterns rather than solely following predefined pathways.Generative AI models introduce an element of creativity, as they generate predictions (often also called insights) by synthesizing prior information that is frequently not overt.For example, AI systems trained on extensive imaging datasets can identify new patterns and diagnose novel cases [5].Such advancements fuel ongoing debates regarding the limits of AI and the delicate balance between creativity, transparency, and replicability.</p>
<p>Of particular relevance to critical care is the AI field of machine learning (ML) that leverages vast datasets to train algorithms that infer logic and adapt to new scenarios.Using electronic health records (EHRs) as the data source, granular and diverse clinical data are aggregated to enable predictive modeling using ML.As discussed below, these datasets can be leveraged to empower AI systems to anticipate clinical decisions, optimize patient care pathways, and improve medical decision-making.This educational primer aims to teach intensivists the foundational concepts of large language models and how to approach emerging literature in this area.</p>
<p>The building blocks of large language models</p>
<p>Large language models (LLMs) are a type of machine learning specifically designed to understand the relationships between words and phrases [6].LLMs learn the grammar, semantics, and contextual use of human language by processing vast amounts of data from diverse sources.A key component of this learning involves creating embeddings, mathematical representations of words.These allow the model to group words with similar meaning close together in a kind of language map [7].For example, the words "heart rate", "blood pressure", "temperature", and "respiratory rate" would be grouped in the map as "vital signs".These relationships help the model understand how words are used in different contexts.</p>
<p>These models originate from natural language processing (NLP), a field that employs computational techniques to represent text using algorithmic structures based on word co-occurrence frequencies within a given dataset [8].Unlike traditional NLP models, which rely strictly on the data provided within a specific dataset, LLMs can incorporate contextual information and generate responses based on learned patterns.Table 1 presents key terms related to augmented intelligence and large language models.</p>
<p>A key distinction for understanding how LLM algorithms function is the model distinction between words and tokens.Words are linguistic units that convey meaning, while tokens are discrete symbols that comprise or represent these units (e.g., sub-words or even punctuation marks).For instance, a simple word like "note" may be represented by a single token, while a longer or compound word such as "hospitalization" might be broken into two tokens (e.g., "hospital", "ization").Each token is assigned a probability of appearing next in a sequence based on the tokens that preceded it.The model employs a mechanism called self-attention to evaluate all parts of the input simultaneously, allowing it to determine contextual relationships and generate coherent output.In other words, this mechanism is designed to evaluate the relevance of different parts of the input when generating a response.For example, when a physician prompts an LLM to generate an admission or discharge summary, the model may refer to the patient using both "the patient" and the pronoun "his/her." In the sentence, "The patient was given his medications, " the model is able to associate "his" with "the patient" because it considers the entire sentence holistically, not just word by word.This process ultimately results in an output reflecting the most likely and contextually appropriate sequence of tokens [9] -a "predictive language assembly" that enables the model to form medically coherent and grammatically accurate responses (Fig. 1).</p>
<p>Translating words into tokens is called encoding, and translating these tokens back into text is called decoding.Embeddings are a critical component of LLM formulation of the context, nuance, and subtle meanings of words and phrases that undergo decoding and encoding.These embeddings represent each token's place in the map of language space.LLM inputs are first transformed into tokens and embeddings, and after being processed as a series of layers in the model architecture, the output is created using the reverse process.This multi-layer architecture, known as a transformer encoder-decoder, allows the representations of tokens to be progressively refined.Each successive layer helps the model learn increasingly complex patterns, from basic grammar to more abstract semantic relationships.Statistical strategies are applied in the decoding process when the model selects one token over another based on learned probabilities -the likelihood of each token appearing in a given context based on training data.As a result of this selection process, the model generates text.Figure 2 presents a simplified large language model processing algorithm.</p>
<p>Large language models in critical care</p>
<p>LLMs are still in their infancy concerning use in critical care, with very few clinically validated applications and a glaring lack of scientific consensus on their actual use.Today's truths may be rapidly swept away by exponentially improving technology.Yet, considering how these tools might be integrated into critical care could help frame the essential discussion on their future role in clinical decision-making.LLMs will likely be used across the critical care continuum to assist in triage and documentation, diagnosis and prediction of patient deterioration, and patient management.LLMs have demonstrated a high median score for appropriateness in addressing clinical questions related to critical care [10] and have also been proposed to support patient rehabilitation after discharge from the ICU [11,12].</p>
<p>As of this writing, at least six additional papers are under review in prepublication databases that propose using LLMs in critical care for treatment planning, patient care management, and prediction of deterioration and mortality.</p>
<p>Triage</p>
<p>Early identification of patients at risk of rapid clinical deterioration can improve triage and enable early response, including ICU admission and implementation of care interventions, which machine learning models aim to predict.Efforts are being made to improve the</p>
<p>Table 1 Key terms related to artificial intelligence and large language models</p>
<p>Application Programming Interface (API)</p>
<p>A framework that facilitates communication and data exchange between software applications, enabling integration of features and functionalities.</p>
<p>Artificial Intelligence (AI)</p>
<p>Computer systems that are designed to perform tasks that usually require human intelligence.These may be classified into narrow AIs focused on specific tasks like language translation or playing chess and general AIs capable of broader functions like learning, reasoning, and problem-solving.</p>
<p>Artificial Neural Network</p>
<p>Interconnected layers of computational units (neurons) that process information.</p>
<p>Bayesian Statistic</p>
<p>A statistical framework that applies Bayes' theorem to update probabilities based on new evidence.It is particularly suited for decision-making in circumstances of uncertainty, providing a probabilistic approach to data analysis and model inference.</p>
<p>Big Data</p>
<p>Large datasets, distinguished by their size, diversity, and processing speed, that may facilitate advanced data analysis and pattern recognition essential for machine learning and AI applications.</p>
<p>Deep learning</p>
<p>A subset of machine learning that uses artificial neural networks with multiple layers to model complex patterns.The term "deep" refers to the number of layers in the network, with deeper networks enabling the execution of more intricate tasks.</p>
<p>Embedding</p>
<p>A mathematical representation of data (such as words, sentences, or images) in a dense, low-dimensional space.Embeddings capture semantic relationships between items, allowing AI systems to analyze similarity and contextual meaning efficiently.</p>
<p>Encoding and Decoding</p>
<p>Processes in machine learning and AI that transform input data into structured formats (encoding) and convert structured representations back into human-readable formats (decoding).</p>
<p>Generative Artificial Intelligence</p>
<p>A technology that produces content by identifying patterns within large datasets.Depending on the model, outputs may include text, images, music, and more.</p>
<p>Intelligence Augmentation</p>
<p>The ability of computer systems to enhance human capabilities and improve performance rather than merely automating tasks.</p>
<p>Large Language Model</p>
<p>A type of neural network-based AI capable of performing diverse linguistic tasks by analyzing large volumes of text data.LLMs identify relationships between token sequences and compute probabilities, enabling the performance of a variety of tasks such as language translation, summarization, and content generation.</p>
<p>Machine Learning (ML)</p>
<p>A practical subfield of computer science and AI based on statistical models.ML utilizes algorithms that allow systems to learn patterns from data without explicit programming.Through iterative learning from experience, these systems may improve performance over time.</p>
<p>Natural Language Processing</p>
<p>A field that employs computational techniques to represent text using algorithmic structures based on word co-occurrence frequencies within a given dataset.</p>
<p>Retrieval Augmented Generation (RAG)</p>
<p>A framework that enhances LLMs by incorporating relevant and updated data from appropriate sources to produce more informed responses.</p>
<p>Tokens</p>
<p>Discrete units of text (such as words, subwords, or characters) that are used by language models to process and analyze language.Tokens are the building blocks for the computational understanding of text, allowing models to generate or interpret language.</p>
<p>accuracy of ICU admission predictions, including integrating NLP technology to enhance the quality of the data used for model development [13].</p>
<p>Retrieval-augmented generation (RAG) is a framework that augments a Large Language Model (LLM) with updated data to generate more informed responses.The retrieval model accesses, selects, and prioritizes the most relevant documents and data from appropriate sources, transforms these into an enriched contextual prompt, and invokes the LLM through an application programming interface (API, see Table 1) to generate the response.This type of machine learning is comparable to stock traders' use of publicly available historical financial information and live market data feeds to make decisions.Numerous approaches to integrating LLMs for patient triage into clinical practice are being explored, including a RAG approach.Yazaki et al. used Chat-GPT3.5 with RAG to enhance contextual understanding and achieved a 70% accuracy rate in triaging emergency cases from the Japanese National Examination for Emergency Medical Technicians [14].A retrospective study used real-world data from seven hospitals to evaluate ChatGPT-4's accuracy in predicting hospital admissions after Department of Emergency Medicine visits.When RAG was incorporated, the prediction accuracy was 81.3% [15].</p>
<p>Documentation</p>
<p>Documentation is essential to any clinical care process, starting from patient intake.LLMs have been proposed for creating clinical notes based on the assumption that such use may reduce physician burnout [16].In the demanding field of critical care, where clinicians face significant workload pressures, yet daily notetaking must cover most physiological systems, such use may be particularly beneficial.</p>
<p>Madden et al. highlighted the transformative potential of ChatGPT in processing and synthesizing real-time summaries from the daily free-text entries from ICU Fig. 1 Token-based processing of a large language model in a Clinical Context electronic health records [17].These entries, authored by doctors, nurses, and allied health professionals, often contain critical information but are typically informal, abbreviated, and poorly structured.In their study, ChatGPT-4 generated concise, actionable summaries and responded to queries (e.g., provided timelines of administered medications).A pilot feasibility study also demonstrated the ability of LLMs to generate concise summaries of ICU admissions for discharge documentation [18].Another single-blind trial found that the quality of discharge letters generated by Chat-GPT4 was comparable to those written by junior clinicians [19].</p>
<p>Z codes (Z55-Z65) are the International Classification of Diseases, Tenth Revision Clinical (ICD-10) Modification diagnosis codes used to document social determinants of health data (e.g., housing, food insecurity, transportation, etc.).Guevara et al. investigated the potential use of LLMs for extracting six social determinants of health categories from narrative text in electronic health records, including employment, housing, transportation, and parental status.The best-performing models accurately identified 95.7% of patients with at least one mention of an SDoH category, compared to just 2.0% identified through structured Z-codes in the electronic health record during the same timeframe [20].Early identification of poor social determinants of health could be invaluable for the prevention of ICU admissions as well as for planning for post-ICU rehabilitation, particularly in patients with complex medical conditions that are subsequently more likely to require such admission.</p>
<p>Another study found that LLMs outperformed human coders in extracting ICD-10 codes from patient notes [21].</p>
<p>Informed consent is another critical domain of documentation.A cross-sectional study of surgical procedures revealed that LLM-based, chatbot-generated presentations of risk, benefit, and possible alternatives to surgery outperformed those presented by surgeons in both composite completeness and accuracy scores, based on expert evaluation and readability assessments, compared to presentations by surgeons.Based on these results, the authors suggested that LLMs be integrated into electronic health records to provide personalized risk and benefit assessments before performing invasive procedures [22].</p>
<p>Medication prescription and clinical documentation share similarities, requiring precise and detailed writing.Given the burden of work imposed on physicians, errors can occur in both processes.The "Healthy Technology Act of 2025, " a bill introduced in the 119 th Congress of the US House of Representatives (H.R.238), proposes permitting the use of AI for medication prescribing (albeit with precautions) [23].This development introduces a new dimension to the potential role of AI, including LLMs, in this domain.</p>
<p>Finally, LLMs are used to summarize doctor-patient conversations during palliative care teleconsultations performed almost similarly in medical conversation summarization.Chat-GPT4 balanced content understanding and preserved structural similarity to the source Fig. 2 A simplified large language model processing algorithm somewhat better than other models, suggesting clinicians could use this LLM to generate medical summaries of such meetings.These summaries could then be given to the patient and/or their family, who may need to reflect on the content of the meeting [24].</p>
<p>Diagnostic support</p>
<p>Diagnostics is another field where LLMs can play a role in critical care.A randomized, double-blind crossover study compared the performance of the LLM tool AMIE (Articulate Medical Intelligence Explorer) to that of twenty primary care physicians during text-based consultations modeled after an Objective Structured Clinical Examination (OSCE).The study included 149 clinical vignettes evaluated by specialist physicians and patient actors.AMIE showed greater diagnostic accuracy and superior performance on 28 of the 32 axes assessed by the specialist physicians and 24 of the 26 axes evaluated by the patient actors [25].</p>
<p>Another retrospective cohort study conducted in a 40-bed PICU demonstrated the capability of domainspecific LLMs, such as those trained on specific medical data, to generate differential diagnoses.While their performance was inferior to that of human clinicians in terms of quality, pediatric critical care specialists gave them high evaluation scores [26].</p>
<p>In the complex diagnostic landscape of the ICU, the perspectives of family members and caregivers are often fraught with misinterpretations and unanswered questions.Scquizzato et al. evaluated the accuracy of ChatGPT in responding to non-professional questions about cardiac arrest.ChatGPT provided highly accurate answers, as assessed by clinicians and researchers specializing in out-of-hospital cardiac arrest, as well as by laypersons.Given the emotionally charged nature of scenarios such as cardiac arrest, which are integral to daily critical care practice, this suggests that leveraging the capabilities of LLMs to help address and clarify clinical situations for families has significant potential [27].</p>
<p>Imaging</p>
<p>The last decades have seen a surge in the use of diagnostic imaging with a related increase in the need for an efficient image interpretation and reporting process.This rising workload has led to concerns regarding decreased efficacy and a higher likelihood of mistakes due to system overload and radiology staff burnout.Radiologists are expected to handle substantial textual information -from diagnostic request forms, medical charts and summaries, information from prior or other examinations, and the most updated medical literature.LLMs may be used to ameliorate this burden if used wisely.While this use may improve the efficiency of radiology services overall, those most likely to benefit are critically ill patients who often require frequent testing and rapid results.Medical imaging of critically ill patients poses unique challenges, including the need to meet stringent time frames and minimize complications stemming from redundant patient transfers.LLMs may be used to improve radiology service efficacy and effectiveness in ways that may be particularly relevant for critically ill patients.</p>
<p>A study comparing human radiologists to Chat-GPT-4 V and Gemini Pro Vision concluded that human radiologists still outperform these LLMs in diagnostic accuracy across various subspecialties (neuroradiology, gastrointestinal, genitourinary) but concluded that LLMs may potentially be used to support clinical decision-making [28].Another model, CXR-LLaVa, which integrates an LLM with an image encoder, demonstrated 81% diagnostic accuracy in identifying six common clinical conditions from test sets of X-ray images using the Medical Information Mart for Intensive Care (MIMIC) database [29].</p>
<p>These findings have been supported by an additional study that showed that ClotCatcher, a natural language model with data augmentation, can rapidly and accurately identify venous thromboembolism (VTE) from radiology reports.The authors concluded that the model may improve the efficiency and accuracy of incident VTE adjudication in large databases [30].</p>
<p>Monitoring and early prediction of patient deterioration</p>
<p>Critically ill patients may rapidly deteriorate, a situation that requires early diagnosis and effective treatment decisions in complex clinical situations.Additional difficult decisions that typically need to be addressed in the critical care environment are those relating to patient preferences that must be made in conjunction with the families, often on behalf of patients unable to make decisions themselves.Time constraints, cultural reluctance to address end-of-life issues, and clinician burdens may limit the ability to elucidate individual patients' value judgments and preferences.A proof-of-concept study explored the potential of LLMs to integrate patient values into critical care decision-making for incapacitated patients.Automated extractions of the treatment in question were accurate in 88% of scenarios.LLM treatment recommendations were rated by adjudicators with an average Likert score of 3.92 out of 5.00 for being medically plausible and reasonable and 3.58 out of 5.00 for reflecting documented patient values [31].</p>
<p>The possible use of LLMs to predict patient deterioration has also been explored in the context of respiratory failure and support.A machine learning model integrated with natural language processing, ARDSFlag, demonstrated an overall accuracy of 89.0% in identifying ARDS cases [32].Another small, prospective study found that Chat-GPT4 demonstrated an accuracy comparable to that of specialized physicians in predicting the need for endotracheal intubation in patients receiving high-flow nasal cannula therapy for 48 h [33].A third study used natural language processing to identify under-documentation of ARDS in ICU discharge notes [34].Such use has more than just research implications -it can also serve as an educational tool.</p>
<p>Sepsis remains a leading cause of ICU mortality [35], yet remains a significant diagnostic challenge in the ICU.The SERA algorithm is an AI-enabled tool that uses natural language processing of physicians' clinical notes using structured electronic medical records (EMR) data.SERA had a high predictive accuracy for identifying sepsis 12 h before its onset, with an AUC of 94%.Compared to physician predictions, the SERA algorithm increased early detection of sepsis by as much as 32% while reducing false positives by 17% [36].</p>
<p>Acute kidney injury (AKI) affects 30-57% of critically ill patients and is associated with high morbidity and mortality [37].Among patients discharged from the ICU with normal renal function after AKI, almost one in three will relapse into renal failure within 5 years [38].One study evaluated the effectiveness of Chat-GPT4 in teaching patients about AKI and continuous renal replacement therapy (CRRT).The model demonstrated a 97-98% overall accuracy, consistent performance across question types, and no significant differences between AKI and CRRT responses [39].</p>
<p>Management of treatment</p>
<p>Critical care involves providing a broad spectrum of treatment regimens tailored to diverse clinical scenarios.Integrating LLMs into this process may optimize time and efficiency in care delivery.Howard et al. explored whether ChatGPT (version unspecified) may be used to provide antimicrobial treatment recommendations in eight hypothetical infection scenarios.While limitations were noted in addressing complex cases, ChatGPT demonstrated an overall ability to suggest appropriate antimicrobial spectra and regimens for the diagnoses and recognized the implications of clinical responses [40].</p>
<p>Delirium occurs in approximately 30% of ICU patients, with rates rising to 90% among mechanically ventilated patients [41].Delirium is also associated with increased mortality after ICU admission.One of the studies still in preprint, suggests that DeLLirium -an LLM-based prediction model -achieved better results than other deep-learning models in predicting delirium from electronic health records [42].Although this tool is primarily intended for critical care research rather than clinical practice, its potential for detecting delirium through conversations with patients or relatives may enable early identification of at-risk individuals.Alternative models may be developed for predicting post-ICU depression among patients and caregivers.</p>
<p>LLMs may also become an essential educational resource for families and caregivers after discharge from the ICU.For example, non-professional caregivers rarely have the training or preparation required for this challenging role.The quality of post-ICU care and the degree of caregiver strain may both be affected by poor preparation.The CaLM (caregiver large language model) has been proposed as a tool for teaching caregivers.The developers of this model aimed to provide caregivers with at least some of the knowledge they require to undertake this challenging role.They showed that by incorporating retrieval-augmented generation (a method used for improving model performance through connection with external knowledge bases), a valuable support tool tailored to specific caregiver scenarios could be created [43].</p>
<p>Patients recovering from ICU admission often require a lengthy and multidisciplinary rehabilitation process.A study that evaluated individualized exercise recommendations generated by an AI chatbot found them to be 41.2% comprehensive and 90.7% accurate.The chatbot could not provide complete and precise recommendations.Still, chatbots are early precursors of the LLMs existing at the time of this writing, and this study represents the potential for supporting rehabilitation efforts through such tools [44].</p>
<p>Figure 3 shows a timeline of patient management in the ICU with the potential application of LLMs at each treatment point.</p>
<p>While the examples presented illustrate potential directions for integrating LLMs into critical care daily practice, these remain exploratory.Figure 4</p>
<p>The challenges and limitations of large Language models</p>
<p>Since the introduction of ChatGPT by OpenAI in November 2022, the public adoption of virtual assistants powered by large language models (LLMs) has grown rapidly.The interest in their application in healthcare, including critical care settings, highlights their potential, as shown above.This article summarizes a rapidly evolving technology whose clinical impact remains hypothetical.LLMs are still at the stage of isolated experiments in exploratory studies (for assessment of the studies presented above, refer to Table 2) with limited incorporation of real-world patient care data; a recent systematic review by Bedi et al. found that only 5% of studies use such data [45].There is no robust clinical validation, and the widespread use of these tools has also brought attention to their limitations and associated challenges [46,47].</p>
<p>A critical consideration in incorporating LLMs into clinical practice is their susceptibility to various biases, among them sycophancy bias, which may lead to outputs reinforcing clinicians' preexisting beliefs, potentially increasing errors [48].Our knowledge of such biases highlights the need to recognize and address how they may influence outputs and the importance of ongoing vigilance when integrating LLM-generated recommendations into clinical decision-making.</p>
<p>Another broader concern regarding the use of AI in general (not limited to LLMs alone) is the phenomenon of overreliance.Clinicians may trust AI-generated diagnoses even when the model produces inaccurate results (Supplementary A) [49].One study investigated whether providing explanations alongside model-generated diagnoses could help clinicians discern and disregard incorrect outputs.Paradoxically, adding explanations did not improve decision-making accuracy, and reliance on the AI model persisted [50].</p>
<p>Finally, the hurdle of integrating LLMs into clinical workflows remains.These models often function as "black boxes, " with limited transparency regarding their internal decision-making processes -a challenge that extends even to their developers and is particularly pronounced among clinicians without even the basic appropriate training.This lack of clarity, coupled with insufficient familiarity among physicians regarding the known capabilities and limitations of these tools, impairs their ability to engage with LLMs in a safe, informed, and clinically meaningful manner.Physicians in family medicine, internal medicine, and emergency medicine exhibited better diagnostic performance on their own compared to when assisted by an LLM.This was assessed based on the accuracy of differential diagnoses, the relevance of supporting and opposing clinical factors, and the appropriateness of the diagnostic evaluation process.The authors interpreted this finding as highlighting "the need for technology and workforce development to realize the potential of physician-artificial intelligence collaboration in clinical practice" [51].</p>
<p>AI tools are rapidly transitioning from simple tools to assistants and potentially even collaborative partners in medicine.They should, therefore, be upheld to similarly rigorous quality assurance standards.The Transparent Reporting of a Multivariable Model for Individual Prognosis Or Diagnosis for LLMs (TRIPOD-LLM) framework has recently been proposed for reporting clinical prediction models developed using large language models [52].Several critical care leaders have also called for action on AI technologies, emphasizing the need to address technical, ethical, social, and practical issues posed by these tools.Their call highlighted the importance of ensuring that AIs, who may someday be viewed as equal partners to physicians, meet the same ethical and professional standards expected of humans.LLMs must uphold integrity, foster trust in clinical environments, and support   their physician colleagues while maintaining the highest standards of care [53].</p>
<p>Conclusion</p>
<p>The integration of LLMs into critical care is an evolving process that may become transformative in the future.As these models may increasingly permeate various aspects of patient management, it is imperative to avoid overoptimism by emphasising that current results are still far from actual application.That said, if developed and implemented correctly, these models could potentially improve clinical decision-making, alleviate the cognitive and administrative burdens on healthcare professionals, and improve patient and caregiver comprehension of the complexities associated with critical illness during and after hospitalization.The trajectory towards leveraging LLMs for improving patient care and possibly outcomes is increasingly evident, highlighting the need for responsible and evidence-based integration of these tools into critical care practice.</p>
<p>offers one possible roadmap from model development to clinical integration.</p>
<p>Fig. 3 AFig. 4
34
Fig. 3 A timeline of patient management in the ICU with the potential application of LLMs at each treatment point</p>
<p>Authors Study Design Healthcare Context and Intended Use Source of Data Objective Evaluation - Metrics and Assessors Subjective Evalua- tion -Metrics and Assessors
Validation Approach(internal, exter-nal, or no formalvalidation)InternalNo formal validationInternal and externalInternal and externalInternal and externalNo formal validationInternalNo formal validationNo formal validationInternalPerformanceComparators(other LLMs, humans, otherbenchmarks, or standards)Clinicians vs. general LLMs(BioGPT-Large, LLaMa-65B),fine-tuned LLMs (fine-tunedBioGPT-Large, fine-tunedLLaMa-7B)GPT-3.5, GPT-4, LLaMA-2-7B, LLaMA-2-13B, andLLaMA-2-70BNoneML models vs. GPT-4General LLMs (GPT-3.5 andGPT-4) vs. fine tuned LLM(BERT-base and Flan-T5)GPT-3.5 vs. GPT-4LLMs (GPT-3.5, GPT-4.0) vs.respiratory and critical carespecialist physicians and non-specialist physiciansNoneNoneNew LLM (CaLM) and GPT-3.5A 5-point Likert scaleof overall qualityNoneNoneNoneNoneA 5-point Likert scalefor appropriatenessand consistencyNoneClinician feedback onthe usefulness andclarity of generatedsummariesA 5-point Likert scalesfor medical plausibilityand alignment withpatient valuesNoneNoneStandardized metrics forprecision and similar-ity to reference text(e.g., ROUGE, BLEU,BERTScore)Standard statisticalmetrics of AUCStandard statisticalmetrics of AUC, AUPRC,and accuracyAutomated evaluationusing macro-F1 scoreFlesch-Kincaid GradeLevel (objective read-ability assessment)Standard statistical met-rics of AUC, sensitivity,specificity, and precisionNoneNoneStandardized metrics forprecision and similarityto reference text (e.g.,ROUGE, BLEU)Admission notes from 10years period for model devel-opment, 130 notes randomlyselected for evaluationSummary of a simulateddoctor-patient conversationduring teleconsultationeICU Collaborative ResearchDatabase, MIMIC-IV and theUniversity of Florida Health'sIntegrated Data RepositoryElectronic health recordsfrom seven hospitalsElectronic health records50 Clinical critical care ques-tions synthesized by theauthorsElectronic health records of71 patientsNone50 Text-based scenarios ofdecisionally incapacitatedpatientsCargiving knowledge bases,including journal articles, careguidelines, and forumsGenerating differential diag-noses from the admissionnotes of PICU patientsSummarization of palliativecare teleconsultationIntroducing LLM-basedDelirium prediction modelin the ICUPredicting the admission ofpatients arriving at the EDIdentify SDoH in EHRsEvaluation of critical carerecommendationsPredicting efficacy of high-flow oxygen therapyQuery and summarize medi-cal notes in ICUIntegrate patient valuesinto clinical decision-making processes in criticalcare for patients who areincapacitatedDevelop a new model forcaregivers' questionsSingle-centerretrospectivecohort studyPilot studyMulti-centerstudyRetrospectivestudyComparativestudyCross-sectionalcomparativestudyProspectivemulticentercohort studyLetter to theeditorProof-of-cocn-cept studyExploratorystudyAkhondi-Aslet al., 2024[26]Chen et al.,2024 [24]Contreras etal., 2024 <a href="preprint">42</a>Glicksberg etal., 2024 [15]Guevara etal., 2024 [20]Balta et al.,2024 [10]Liu et al.,2024 [33]Madden etal., 2023 [17]Nolan et al.,2024 [31]Parmanto etal., 2024 [43]</p>
<p>Table 2
2
[52]itative assessment of LLM studies based on the transparent reporting of a multivariable model for individual prognosis or diagnosis (TRIPOD)-LLM recommendations[52]Acute kidney injury; AUC: Area under the receiver operating characteristic curve; AUPRC: Area under the precision-recall curve; BERT: bert large uncased whole word masking finetuned squad; BERTScore: Bidirectional encoder representations from transformers score; BLEU: Bilingual evaluation understudy; CPR: Cardiopulmonary resuscitation; CRRT: Continous renal replacement therapy; ED: Emergency department; EHRs: Electronic health records; GPT: Generative Pre-trained Transformer; ICD: International classification of diseases; ICU: Intensive care unit; MIMIC-IV: Medical Information Mart for Intensive Care; ML: machine learning; PICU: Pediatrics intensive care unit; RAG: Retrieval augmented generation; ROUGE-L: Recall-oriented understudy for gisting evaluation; SDoH: Social determinants of health; VS: versus
Validation Approach(internal, exter-nal, or no formalvalidation)InternalInternalInternalInternalInternalPerformanceComparators(other LLMs, humans, otherbenchmarks, or standards)NoneNoneChatGPT, GPT-4 API, andLlama 2GPT-3.5 with RAG, GPT-3.5without RAG, and GPT-4 with-out RAG vs. emergency medi-cal technicians and emergencyphysiciansNoneSubjective Evalua-tion -Metrics andAssessorsSubjective accuracyratingA 5-point Likert scalesfor accuracy, clarity,relevance, comprehen-siveness, and overallvalueSubjective evaluationby staff intensivistsNoneSubjective assessmentof comprehensivenessand factual accuracySource of Data Objective Evaluation -Metrics and Assessors89 questions from the Mayo NoneClinic Handbook for educat-ing patients on AKI and CRRT40 questions Readability assessedusing the Flesch ReadingEase scoreText from five ICU episodes None100 simulated triage Standard statistical met-scenarios rics of triage accuracy26 queries on exercise advice Flesch-Kincaid GradeLevel (objective read-ability assessment)Study Design Healthcare Context andIntended UseNot specified Assessing accuracy inby the authors responding to patient edu-cation questionsNot specified Address public inquiriesby the authors related to cardiac arrest andCPRPilot study Synthesize discharge sum-mary of ICU patientsNot specified Triaging ED patientsby the authorsMix methods Providing individualizedstudy exercise recommendationsAuthorsSheikh et al.,2024 [39]Tommaso etal., 2024 [27]Urquhart etal., 2024 [18]Yazaki et al.,2024 [14]Zaleski et al.,2024 [44]AKI:</p>
<p>Table 2
2
(continued)</p>
<p>AcknowledgementsWe are grateful to Leehee Barak, Medint Data Analyst, for her valuable assistance in verifying the accuracy of the figures and terminology.We also extend our sincere thanks to Prof. Leo Anthony Celi for his insightful contributions to the conceptual development and overall flow of the paper.Data availabilityNo datasets were generated or analysed during the current study.Supplementary InformationThe online version contains supplementary material available at h t t p s : / / d o i .o r g / 1 0 . 1 1 8 6 / s 1 3 0 5 4 -0 2 5 -0 5 4 7 9 -4.Supplementary Material 1Author contributions D.I. and S.E. were responsible for the conceptualization of the manuscript idea, drafted the main manuscript text, and prepared Figs. 1, 2 and 3.All authors reviewed and approved the final manuscript.FundingNone.Declarations Competing interestsDaphna Idan is a medical student and data analyst and has no relevant conflict of interests to disclose.Sharon Einav is a Cochrane Editor and is involved in developing an LLM for use by clinicians.Publisher's noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Nestor Maslej, L Fattorini, R Perrault, V Parli, A Reuel, E Brynjolfsson, J Etchemendy, K Ligett, T Lyons, J Manyika, J C Niebles, Y Shoham, R , Wald Clark, J , The AI Index 2024 Annual Report. Stanford, CAApril 2024AI Index Steering Committee, Institute for Human-Centered AI, Stanford University</p>
<p>Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices. FDA [Internet. C Health, D , R , 2021Available from: h t t p s : / /</p>
<p>The potential for artificial intelligence to transform healthcare: perspectives from international health leaders. C Silcox, E Zimlichmann, K Huber, N Rowen, R Saunders, M Mcclellan, NPJ Digital Medicine [Internet]. 712024</p>
<p>Artificial intelligence: A modern approach. S J Russell, P Norvig, global edition</p>
<p>AI and ML in radiology: Making progress. A G Rockall, S C Shelmerdine, M Chen, Clinical radiology. 7822023Internet</p>
<p>ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences. E Kasneci, K Sessler, S Küchemann, M Bannert, D Dementieva, F Fischer, 2023. 102274103Internet. Available from: h t t p s : / /</p>
<p>Embedding-based Query Language Models. H W Zamani, Bruce Croft, 2016</p>
<p>Natural Language processing. K R Chowdhary, Fundamentals Artif Intell. 2020</p>
<p>Learn Your Tokens: Word-Pooled Tokenization for Language Modeling. Avijit Thawani, S Ghanekar, X Zhu, J Pujara, Internet</p>
<p>. Openreview, 2023G 7 N B 3 X</p>
<p>Evaluating the appropriateness, consistency, and readability of ChatGPT in critical care recommendations. K Y Balta, A P Javidan, E Walser, R Arntfield, R Prager, J Intensive Care Med. 4022024</p>
<p>Large Language model application in emergency medicine and critical care. Haw Hwai, Y J Ho, C H Wang, C H Huang, 10.1016/j.jfma.2024.08.032J Formos Med Assoc. 2024h t t p s : / /</p>
<p>Find and participate in clinical trials and research. studies happening around the world | TrialScreen. Internet</p>
<p>. Trialscreen, Org, 2025. 2025 Feb 14</p>
<p>Predicting Intensive Care Unit admission among patients presenting to the emergency department using machine learning and natural language processing. M Fernandes, R Mendes, S M Vieira, F Leite, C Palos, Johnson A , PLoS ONE. 1532020 Mar 3. 2023 Mar 25Internet</p>
<p>Emergency Patient Triage Improvement through a Retrieval-Augmented Generation Enhanced Large-Scale Language Model. Megumi Yazaki, S Maki, T Furuya, K Inoue, K Nagai, Y Nagashima, Prehospital Emergency Care. 3Internet]. 2024;1-7. Available from: h t t p s : / / p u b m e d</p>
<p>Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room. B S Glicksberg, P Timsina, D Patel, A Sawant, A Vaid, G Raut, Journal of the American Medical Informatics Association. JAMIAInternet]. 2024;ocae103. Available from: h t t p s : / /</p>
<p>Should Artificial Intelligence Be Used for Physician Documentation to Reduce Burnout?. J Miao, Charat Thongprayoon, W C , 2024 Mar 25. 2024 Aug 185Kidney360 [Internet. Available from: h t t p s : / /</p>
<p>Assessing the usefulness of a large Language model to query and summarize unstructured medical notes in intensive care. M G Madden, B A Mcnicholas, J G Laffey, Intensive Care Med. 4982023</p>
<p>A pilot feasibility study comparing large Language models in extracting key information from ICU patient text records from an Irish population. E Urquhart, J Ryan, S Hartigan, C Nita, C Hanley, P Moran, Intensive Care Med Experimental. 12172024</p>
<p>Comparison of the Quality of Discharge Letters Written by Large Language Models and Junior Clinicians: Single-Blinded Study. J Yi, S R Gill, G Gui, D Yan, Y Ke, F Ting, Tan , Journal of Medical Internet Research. 262024 Jul 24. 2024 Sep 9Internet. Available from: h t t p s : / /</p>
<p>Large language models to identify social determinants of health in electronic health records. NPJ Digital Medicine. M Guevara, S Chen, S Thomas, T L Chaunzwa, I Franco, B H Kann, 2024. 4 6 -0 2 3 -0 0 9 7 0 -07Internet</p>
<p>Extracting international classification of diseases codes from clinical Documentation using large Language models. A Simmons, K Takkavatakarn, M Mcdougal, B Dilcher, J Pincavitch, L Meadows, Appl Clin Inf. 1622024</p>
<p>Large Language Model -Based Chatbot vs Surgeon-Generated Informed Consent Documentation for Common Procedures. H Decker, Trang K Ramirez, J Colley, A Pierce, L Coleman, M , JAMA Network Open. Internet</p>
<p>To amend the Federal Food, Drug, and Cosmetic Act to clarify that artificial intelligence and machine learning technologies can qualify as a practitioner eligible to prescribe drugs if authorized by the State involved and approved, cleared, or authorized by the Food and Drug Administration, and for other purposes. R-Az-1 , D R Text -H, 238-119th Congress. 2025-2026Internet</p>
<p>Exploring the opportunities of large language models for summarizing palliative care consultations: A pilot comparative study. X Chen, W Zhou, R Hoda, A Li, C Bain, P Poon, 2024. 2055207624129393210</p>
<p>. T Tu, Anil Palepu, M Schaekermann, K Saab, J Freyberg, R Tanno, Conversational Towards, A I Diagnostic, Arxiv, 2024Cornell University</p>
<p>Comparing the quality of Domain-Specific versus general Language models for artificial Intelligence-Generated differential diagnoses in PICU patients**. Aa-A Yang, Y Luchette, M Burns, J P Mehta, Alon Geva, Pediatr Crit Care Med. 2562024</p>
<p>Testing ChatGPT ability to answer laypeople questions about cardiac arrest and cardiopulmonary resuscitation. Tommaso Scquizzato, F Semeraro, P Swindell, R Simpson, M Angelini, A Gazzato, Resuscitation. 1942024</p>
<p>Comparing diagnostic accuracy of radiologists versus GPT-4V and gemini pro vision using image inputs from diagnosis please cases. P S Suh, W H Shim, C H Suh, H Heo, C R Park, H J Eom, Radiology. 3121e2402732024</p>
<p>CXR-LLaVA: a multimodal large Language model for interpreting chest X-ray images. S Lee, J Youn, H Kim, M Kim, S H Yoon, 10.1007/s00330-024-11339-6Eur Radiol. 2025. 1 0 . 1 0 0 7 / s 0 0 3 3 0 -0 2 4 -1 1 3 3</p>
<p>ClotCatcher: a novel natural Language model to accurately adjudicate venous thromboembolism from radiology reports. J Wang, Joao Gupta, S Upadhyaya, P Lisboa, F A Schobel, S A , BMC Med Inf Decis Mak. 2312622023</p>
<p>Incorporating Patient Values in Large Language Model Recommendations for Surrogate and Proxy Decisions. V J Nolan, J A Balch, N P Baskaran, B Shickel, P A Efron, G R Upchurch, 20246Critical Care Explorations. Internet</p>
<p>ARDSFlag: an NLP/machine learning algorithm to visualize and detect high-probability ARDS admissions independent of provider recognition and billing codes. BMC medical informatics and decision making. A Gandomi, P Wu, D R Clement, J Xing, R Aviv, M Federbush, 2024 Winter. 24Internet</p>
<p>ChatGPT achieves comparable accuracy to specialist physicians in predicting the efficacy of high-flow oxygen therapy. T Liu, Y Duan, Y Li, Y Hu, L Su, A Zhang, 2024. 2 4 0 5 8 4 4 0 2 4 0 7 7 8 1 810Internet</p>
<p>Natural Language processing to assess Documentation of features of critical illness in discharge documents of acute respiratory distress syndrome survivors. G E Weissman, M O Harhay, R M Lugo, B D Fuchs, S D Halpern, M E Mikkelsen, Annals Am Thorac Soc. 1392016</p>
<p>Society of Critical Care Medicine. Society of Critical Care Medicine (SCCM). 2024. Available from: h t t p s. Critical care statistics. Internet</p>
<p>Artificial intelligence in infection management in the ICU. T De Corte, S Van Hoecke, De Waele, J , Crit Care. 261792022</p>
<p>G Remuzzi editor 2020 A systematic review and metaanalysis of acute kidney injury in the intensive care units of developed and developing countries. F Melo, De, E Macedo, Fonseca Bezerra, A C De Melo, Wal Mehta, R L De A Burdmann, E , PLoS ONE. 15e0226325</p>
<p>Clinical trajectories and impact of acute kidney disease after acute kidney injury in the intensive care unit: a 5-year single-centre cohort study. Nephrology, dialysis, transplantation: official publication of the European Dialysis and Transplant Association -European Renal Association. A Orieux, M Prezelin-Reydit, R Prevel, C Combe, D Gruson, A Boyer, 2023 Autumn. 38Internet</p>
<p>Evaluating ChatGPT's Accuracy in Responding to Patient Education Questions on Acute Kidney Injury and Continuous Renal Replacement Therapy. M S Sheikh, C Thongprayoon, S Suppadungsuk, J Miao, F Qureshi, K Kashani, 2024 Apr 26. 2024 Jul 200</p>
<p>ChatGPT and antimicrobial advice: the end of the consulting infection doctor?. A Howard, W Hope, A Gerada, Lancet Infect Dis. 2342023</p>
<p>Confusion Assessment Method for the Intensive Care Unit (CAM-ICU) for the diagnosis of delirium in adults in critical care settings. The Cochrane Database of Systematic Reviews. F Miranda, F Gonzalez, M N Plana, J Zamora, T J Quinn, P Seron, Internet]. 11112023CD013126. Available from: h t t p s : / /</p>
<p>DeLLiriuM: A large language model for delirium prediction in the ICU using structured EHR. M Contreras, S Kapoor, J Zhang, A Davidson, Y Ren, Z Guan, arXiv.org. 20242025 Feb 14Internet. Available from: h t t p s : / /</p>
<p>A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study. B Parmanto, B Aryoyudanta, T W Soekinto, Ima Setiawan, Y Wang, H Hu, 2024 Jul 31. 2024 Oct 148e54633Available from: h t t p s : / / s / P M C 1 1 3 2 5 1 0 0 /</p>
<p>Comprehensiveness, accuracy, and readability of exercise recommendations provided by an AI-Based chatbot: mixed methods study. A L Zaleski, R Berkowsky, K Jean, L S Pescatello, JMIR Med Educ. 102024</p>
<p>Testing and evaluation of health care applications of large Language models: A systematic review. S Bedi, Y Liu, L Orr-Ewing, D Dash, S Koyejo, A Callahan, JAMA. 33342025</p>
<p>How could ChatGPT impact my practice as an intensivist? An overview of potential applications, risks and limitations. M Komorowski, M Del, A C Chang, Intensive Care Med. 492023</p>
<p>Evaluation and mitigation of the limitations of large Language models in clinical decision-making. P Hager, F Jungmann, R Holland, K Bhagat, I Hubrecht, M Knauer, Nat Med. 3092024</p>
<p>Artificial intelligence and qualitative research: The promise and perils of large language model (LLM) assistance. Critical Perspectives on Accounting. J Roberts, M Baker, J Andrew, 1 0 4 5 2 3 5 4 2 4 0 0 0 2 1 2Internet]. 2024;99:102722. Available from: h t t p s : / / i / S</p>
<p>To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making. Z Buçinca, M B Malaya, K Z Gajos, Proceedings of the ACM on Human-Computer Interaction. 5CSCW12021</p>
<p>Measuring the Impact of AI in the Diagnosis of Hospitalized Patients: A Randomized Clinical Vignette Survey Study. S Jabbour, D Fouhey, S Shepard, T S Valley, E A Kazerooni, N Banovic, JAMA. 330232023. 2 8 1 2 9 0 8Internet</p>
<p>Large Language model influence on diagnostic reasoning. E Goh, R Gallo, J Hom, E Strong, Y Weng, H Kerman, JAMA Netw Open. 710e24409692024</p>
<p>The TRIPOD-LLM reporting guideline for studies using large language models. J Gallifant, M Afshar, S Ameen, Yindalon Aphinyanaphongs, S Chen, G Cacciamani, Nature Medicine. 312025. 1 5 9 1 -0 2 4 -0 3 4 2Internet</p>
<p>Artificial intelligence in acute medicine: a call to action. M Cecconi, M Greco, B Shickel, J L Vincent, Azra Bihorac, Crit Care. 282582024</p>            </div>
        </div>

    </div>
</body>
</html>