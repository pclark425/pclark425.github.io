<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1929 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1929</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1929</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-41.html">extraction-schema-41</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <p><strong>Paper ID:</strong> paper-280401875</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2507.23445v1.pdf" target="_blank">Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility</a></p>
                <p><strong>Paper Abstract:</strong> Simulation-to-real transfer using domain randomization for robot control often relies on low-gear-ratio, backdrivable actuators, but these approaches break down when the sim-to-real gap widens. Inspired by the traditional PID controller, we reinterpret its gains as surrogates for complex, unmodeled plant dynamics. We then introduce a physics-guided gain regularization scheme that measures a robot's effective proportional gains via simple real-world experiments. Then, we penalize any deviation of a neural controller's local input-output sensitivities from these values during training. To avoid the overly conservative bias of naive domain randomization, we also condition the controller on the current plant parameters. On an off-the-shelf two-wheeled balancing robot with a 110:1 gearbox, our gain-regularized, parameter-conditioned RNN achieves angular settling times in hardware that closely match simulation. At the same time, a purely domain-randomized policy exhibits persistent oscillations and a substantial sim-to-real gap. These results demonstrate a lightweight, reproducible framework for closing sim-to-real gaps on affordable robotic hardware.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1929.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1929.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Balboa balancing sim-to-real</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sim-to-real transfer experiment on Pololu Balboa 32U4 two-wheeled balancing robot</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sim-to-real study transferring controllers trained in simulation (proportional, domain-randomized RNN, and gain-constrained domain-randomized RNN) to an off-the-shelf Balboa 32U4 two-wheeled balancing robot, with explicit modeling of motor and viscous damping terms and evaluation using settling times, peak times, and angular-velocity envelopes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Two-wheeled inverted-pendulum balancing (stand-up and balance recovery)</td>
                        </tr>
                        <tr>
                            <td><strong>task_timescale</strong></td>
                            <td>seconds to tens of seconds (transient/settling dynamics shown around 10--20 s; 5% settling-time contours used)</td>
                        </tr>
                        <tr>
                            <td><strong>task_contact_ratio</strong></td>
                            <td>minimal contact (wheels on ground only)</td>
                        </tr>
                        <tr>
                            <td><strong>task_precision_requirement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_modeled</strong></td>
                            <td>DC motor scalar model including gear ratio, wheel radius, battery voltage, magnetic flux (Φ_PM), winding resistance (R_winding), and an empirical scale c_emp; viscous damping terms in plant dynamics (D_c for cart, D_p for pole pivot) treated as actuator/plant friction proxies</td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_simplified</strong></td>
                            <td>Friction simplified to purely viscous damping (Coulomb and static friction ignored); motor electrical/dynamic effects collapsed to a scalar c_emp (model absorbs unmodeled dynamics); gearbox dynamics (backlash, hysteresis) not explicitly modeled; actuator bandwidth and motor inductance/time-constant not explicitly modeled</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level_description</strong></td>
                            <td>Simplified physics: planar cart-pole with viscous damping and a simplified DC motor static mapping from PWM duty to force (constants from datasheets/rough estimates, with an empirical gain c_emp to absorb errors); domain randomization over plant parameters used to increase robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>parameter_specific_fidelity</strong></td>
                            <td>Nominal numeric values reported (e.g., D_c_nom=3 kg/s, D_p_nom=0.007 Nms/rad, R_winding=4.3 Ω, Φ_PM≈2.7e-3, gear ≃110.2, wheel radius=0.03825 m) and c_emp tuned per model (1.2 for proportional, 2.0 for DR-RNN, 1.5 for GC-DR-RNN); no explicit quantitative error bounds or percentage fidelity reported.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Controller transient metrics: 5% angular settling-time contours, peak time alignment between sim and real, angular velocity envelopes and peak amplitudes, and qualitative/quantitative detection of oscillations (e.g., ±5 rad/s oscillations observed in DR-RNN vs ±2.5 rad/s for GC-DR-RNN and proportional).</td>
                        </tr>
                        <tr>
                            <td><strong>sim_vs_real_performance</strong></td>
                            <td>GC-DR-RNN and proportional controller: nearly identical decay envelopes and peak timings between sim and real (good transfer). DR-RNN: simulation predicted faster convergence but real robot exhibited persistent ~5 Hz oscillations and larger angular-velocity amplitudes (substantial sim-to-real mismatch); numerically, DR-RNN angular velocity exceeded ±5 rad/s in hardware while GC-DR-RNN and proportional stayed within ±2.5 rad/s.</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_performed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_results</strong></td>
                            <td>Systematic parameter sweeps and contour maps over cart/pole masses and viscous damping were performed. Key findings: (1) naive domain randomization biases policy toward 'easy' regions (e.g., large masses) that reduce performance at nominal parameters; (2) DR-RNN inflated equivalent angular-velocity gains (∂f/∂ω up to ≈4.0) causing hardware oscillations; (3) gain-constrained DR-RNN kept equivalent gains below ≈2.0 and preserved robustness near nominal parameters; (4) friction/damping parameters strongly influenced robustness and optimal context values could be out-of-domain.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_reported</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_details</strong></td>
                            <td>Control-side timings reported: matrix-vector multiplication 0.168 ms, full control routine (signal processing + math on Raspberry Pi) 2.76 ms; control period varied between 10 ms and 30 ms due to communication; no wall-clock training time or comparative simulation speedups between fidelity levels were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td>Yes — three controller/training variants compared: (1) hand-tuned proportional baseline (narrow but accurate around nominal), (2) domain-randomized RNN (wider simulated robustness but degraded nominal performance and sim-to-real mismatch), (3) gain-constrained domain-randomized RNN (GC-DR-RNN) which balanced global robustness with accurate transfer near nominal; GC-DR-RNN suppressed gain inflation and matched sim and real transients best.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td>Plant parameters randomized during training: cart+pole mass (M, m), pole length l, viscous damping D_c and D_p. Multiplicative uniform sampling around nominal (e.g., U(0.5, 2.0) × nominal for many parameters; some parameters had narrower ranges such as pole mass sampled in a smaller multiplier range like 0.5–1.0 as reported). Controller was conditioned on the sampled plant parameters (parameter-conditioned domain randomization).</td>
                        </tr>
                        <tr>
                            <td><strong>robot_type</strong></td>
                            <td>Two-wheeled balancing robot (Pololu Balboa 32U4 assembled with Raspberry Pi 3B+); final gear ratio ≃ 110.2</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_analysis</strong></td>
                            <td>DR-RNN failures traced to inflated equivalent angular-velocity gains and mismatch in damping/friction modeling; domain randomization bias toward easier (out-of-nominal) samples caused policies that perform poorly at true hardware parameters; lack of realistic actuator gain/bandwidth constraints allowed the simulator to reward unrealistic virtual gains leading to oscillations on hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_for_theory</strong></td>
                            <td>Constraining learned controllers' local input-output sensitivities to match measured hardware-equivalent proportional gains (kx, kv, kθ, kω) prevents the policy from exploiting unrealistic actuator capabilities in simulation; mismatches in viscous damping/friction and inflated effective angular-velocity gains are primary causes of sim-to-real transfer failure for high-gear-ratio, non-backdrivable platforms, and parameter-conditioned domain randomization plus gain regularization achieves close sim-to-real alignment.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sim-to-real of humanoid locomotion policies via joint torque space perturbation injection. <em>(Rating: 2)</em></li>
                <li>Aligning simulation and real-world physics for learning agile humanoid whole-body skills. <em>(Rating: 2)</em></li>
                <li>Integrating model-based control and rl for sim2real transfer of tight insertion policies. <em>(Rating: 2)</em></li>
                <li>Learning bipedal locomotion on gear-driven humanoid robot using foot-mounted imus. <em>(Rating: 2)</em></li>
                <li>Quantifying the sim2real gap for gps and imu sensors. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1929",
    "paper_id": "paper-280401875",
    "extraction_schema_id": "extraction-schema-41",
    "extracted_data": [
        {
            "name_short": "Balboa balancing sim-to-real",
            "name_full": "Sim-to-real transfer experiment on Pololu Balboa 32U4 two-wheeled balancing robot",
            "brief_description": "Sim-to-real study transferring controllers trained in simulation (proportional, domain-randomized RNN, and gain-constrained domain-randomized RNN) to an off-the-shelf Balboa 32U4 two-wheeled balancing robot, with explicit modeling of motor and viscous damping terms and evaluation using settling times, peak times, and angular-velocity envelopes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "task_name": "Two-wheeled inverted-pendulum balancing (stand-up and balance recovery)",
            "task_timescale": "seconds to tens of seconds (transient/settling dynamics shown around 10--20 s; 5% settling-time contours used)",
            "task_contact_ratio": "minimal contact (wheels on ground only)",
            "task_precision_requirement": null,
            "actuator_parameters_modeled": "DC motor scalar model including gear ratio, wheel radius, battery voltage, magnetic flux (Φ_PM), winding resistance (R_winding), and an empirical scale c_emp; viscous damping terms in plant dynamics (D_c for cart, D_p for pole pivot) treated as actuator/plant friction proxies",
            "actuator_parameters_simplified": "Friction simplified to purely viscous damping (Coulomb and static friction ignored); motor electrical/dynamic effects collapsed to a scalar c_emp (model absorbs unmodeled dynamics); gearbox dynamics (backlash, hysteresis) not explicitly modeled; actuator bandwidth and motor inductance/time-constant not explicitly modeled",
            "fidelity_level_description": "Simplified physics: planar cart-pole with viscous damping and a simplified DC motor static mapping from PWM duty to force (constants from datasheets/rough estimates, with an empirical gain c_emp to absorb errors); domain randomization over plant parameters used to increase robustness.",
            "parameter_specific_fidelity": "Nominal numeric values reported (e.g., D_c_nom=3 kg/s, D_p_nom=0.007 Nms/rad, R_winding=4.3 Ω, Φ_PM≈2.7e-3, gear ≃110.2, wheel radius=0.03825 m) and c_emp tuned per model (1.2 for proportional, 2.0 for DR-RNN, 1.5 for GC-DR-RNN); no explicit quantitative error bounds or percentage fidelity reported.",
            "transfer_success_metric": "Controller transient metrics: 5% angular settling-time contours, peak time alignment between sim and real, angular velocity envelopes and peak amplitudes, and qualitative/quantitative detection of oscillations (e.g., ±5 rad/s oscillations observed in DR-RNN vs ±2.5 rad/s for GC-DR-RNN and proportional).",
            "sim_vs_real_performance": "GC-DR-RNN and proportional controller: nearly identical decay envelopes and peak timings between sim and real (good transfer). DR-RNN: simulation predicted faster convergence but real robot exhibited persistent ~5 Hz oscillations and larger angular-velocity amplitudes (substantial sim-to-real mismatch); numerically, DR-RNN angular velocity exceeded ±5 rad/s in hardware while GC-DR-RNN and proportional stayed within ±2.5 rad/s.",
            "sensitivity_analysis_performed": true,
            "sensitivity_analysis_results": "Systematic parameter sweeps and contour maps over cart/pole masses and viscous damping were performed. Key findings: (1) naive domain randomization biases policy toward 'easy' regions (e.g., large masses) that reduce performance at nominal parameters; (2) DR-RNN inflated equivalent angular-velocity gains (∂f/∂ω up to ≈4.0) causing hardware oscillations; (3) gain-constrained DR-RNN kept equivalent gains below ≈2.0 and preserved robustness near nominal parameters; (4) friction/damping parameters strongly influenced robustness and optimal context values could be out-of-domain.",
            "computational_cost_reported": true,
            "computational_cost_details": "Control-side timings reported: matrix-vector multiplication 0.168 ms, full control routine (signal processing + math on Raspberry Pi) 2.76 ms; control period varied between 10 ms and 30 ms due to communication; no wall-clock training time or comparative simulation speedups between fidelity levels were reported.",
            "fidelity_comparison": "Yes — three controller/training variants compared: (1) hand-tuned proportional baseline (narrow but accurate around nominal), (2) domain-randomized RNN (wider simulated robustness but degraded nominal performance and sim-to-real mismatch), (3) gain-constrained domain-randomized RNN (GC-DR-RNN) which balanced global robustness with accurate transfer near nominal; GC-DR-RNN suppressed gain inflation and matched sim and real transients best.",
            "domain_randomization_used": true,
            "domain_randomization_details": "Plant parameters randomized during training: cart+pole mass (M, m), pole length l, viscous damping D_c and D_p. Multiplicative uniform sampling around nominal (e.g., U(0.5, 2.0) × nominal for many parameters; some parameters had narrower ranges such as pole mass sampled in a smaller multiplier range like 0.5–1.0 as reported). Controller was conditioned on the sampled plant parameters (parameter-conditioned domain randomization).",
            "robot_type": "Two-wheeled balancing robot (Pololu Balboa 32U4 assembled with Raspberry Pi 3B+); final gear ratio ≃ 110.2",
            "transfer_failure_analysis": "DR-RNN failures traced to inflated equivalent angular-velocity gains and mismatch in damping/friction modeling; domain randomization bias toward easier (out-of-nominal) samples caused policies that perform poorly at true hardware parameters; lack of realistic actuator gain/bandwidth constraints allowed the simulator to reward unrealistic virtual gains leading to oscillations on hardware.",
            "key_finding_for_theory": "Constraining learned controllers' local input-output sensitivities to match measured hardware-equivalent proportional gains (kx, kv, kθ, kω) prevents the policy from exploiting unrealistic actuator capabilities in simulation; mismatches in viscous damping/friction and inflated effective angular-velocity gains are primary causes of sim-to-real transfer failure for high-gear-ratio, non-backdrivable platforms, and parameter-conditioned domain randomization plus gain regularization achieves close sim-to-real alignment.",
            "uuid": "e1929.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Sim-to-real of humanoid locomotion policies via joint torque space perturbation injection.",
            "rating": 2
        },
        {
            "paper_title": "Aligning simulation and real-world physics for learning agile humanoid whole-body skills.",
            "rating": 2
        },
        {
            "paper_title": "Integrating model-based control and rl for sim2real transfer of tight insertion policies.",
            "rating": 2
        },
        {
            "paper_title": "Learning bipedal locomotion on gear-driven humanoid robot using foot-mounted imus.",
            "rating": 2
        },
        {
            "paper_title": "Quantifying the sim2real gap for gps and imu sensors.",
            "rating": 1
        }
    ],
    "cost": 0.009725999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility
August 1, 2025</p>
<p>Yuta Kawachi 
DENSO IT Laboratory</p>
<p>Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility
August 1, 2025280B8132351DE6ECE4E9F46D05B9F264arXiv:2507.23445v1[cs.RO]
Simulation-to-real transfer using domain randomization for robot control often relies on low-gear-ratio, backdrivable actuators, but these approaches break down when the sim-to-real gap widens.Inspired by the traditional PID controller, we reinterpret its gains as surrogates for complex, unmodeled plant dynamics.We then introduce a physics-guided gain regularization scheme that measures a robot's effective proportional gains (kx, kv, k θ , kω) via simple real-world experiments.Then, we penalize any deviation of a neural controller's local input-output sensitivities from these values during training.To avoid the overly conservative bias of naïve domain randomization, we also condition the controller on the current plant parameters.On an off-the-shelf two-wheeled balancing robot with a 110:1 gearbox, our gain-regularized, parameter-conditioned RNN achieves angular settling times in hardware that closely match simulation.At the same time, a purely domain-randomized policy exhibits persistent oscillations and a substantial sim-to-real gap.These results demonstrate a lightweight, reproducible framework for closing sim-to-real gaps on affordable robotic hardware.</p>
<p>Introduction</p>
<p>Simulation-to-real (sim-to-real) transfer has achieved significant success on robotic platforms equipped with low-gear-ratio, backdrivable actuators.In these systems, such as small humanoids that learn to walk, reinforcement learning (RL) combined with domain randomization (DR) often closes the gap between virtual training and physical deployment [14] [1][16].By exposing the controller to modest parameter perturbations in simulation, these methods can operate on real hardware without detailed modeling of friction, backlash, or sensor delay [7].</p>
<p>However, this success does not readily extend to tasks with a wider sim-to-real gap [10] [15].High-gearratio mechanisms [7], tight object-insertion assemblies [11], and aggressive maneuvers such as parkour jumps [2] or skateboarding [9] require additional hardware or training tricks.When the randomization range in simulation is enlarged by these requirements, 1. the probability that a sampled model matches the real plant decreases, which lowers the hit rate, and 2. the learned policy is marginalized over many inaccurate models, which yields the "overly conservative policies" problem [5] [6].</p>
<p>From a scientific standpoint, the RL+DR methodology is closer to gambling than engineering: an RL agent gets lucky if it converges to a policy that transfers.In industrial settings, in which reproducibility and certifiable performance are critical, depending on serendipity is unacceptable.Therefore, closing significant sim-to-real gaps requires more accurate knowledge of the physical system.A straightforward remedy is real-to-sim system identification [17] or iterative simulator refinement.Although this approach can improve fidelity, it demands extensive data collection limited by safety considerations and hardware wear.Furthermore, any unmeasured or hazardous operating regime remains poorly modeled, so the refined simulator can still diverge from reality when the robot executes aggressive motions.Another option is to abandon physics modeling altogether and gauge the hardware directly.The only practical controller family that is both human-interpretable and suitable for direct gauging is the classical proportional-integral-derivative (PID) controller.Nevertheless, PID control is inherently linear and cannot deliver the nonlinear performance required for wide-amplitude swing-up, contact-rich manipulation, or motion with large gear reductions.</p>
<p>In this work, we adopt a different perspective.We reinterpret proportional gains, which are traditionally treated as human-tuned design knobs, as surrogates for the complex nature of unmodeled plant characteristics, encapsulating bandwidth, friction, and gear-train dynamics.We incorporate physics-guided gain regularization into the learning loop.We measure the robot's effective proportional gains (k x , k v , k θ , k ω ) and penalize any deviation of a neural controller's local input-output sensitivities from these hardware gains during training.This mechanism prevents the simulator from rewarding unrealistically large virtual gains and keeps the learned policy within the feasible actuation envelope of the real machine while maintaining the theoretical nonlinear control capability.</p>
<p>To counteract the "overly conservative policies" that emerge from naïve DR, we introduce parameterconditioned domain randomization.The current plant parameters are appended to the policy input so the network can specialize its output instead of collapsing toward a single compromise solution.The combination of physics-guided gain regularization and parameter conditioning delivers reproducible, high-performance control on an off-the-shelf two-wheeled balancing robot with a 110:1 gearbox, which demonstrates that lightweight physics guidance, rather than enlarging randomization ranges, is the practical key to affordable robotics.</p>
<p>In summary, our contributions are as follows.</p>
<ol>
<li>
<p>Physics-guided gain regularization: we formulate a loss that forces the input-output partial derivatives of the neural controller to match hardware gains, which prevents the simulator from rewarding unrealistically large virtual gains.</p>
</li>
<li>
<p>Parameter-conditioned domain randomization: by feeding the plant parameters into the policy, we remove the bias toward overly conservative behaviors.</p>
</li>
<li>
<p>Quantitative analysis of the sim-to-real gap: we visualize how unconstrained policies inflate equivalent gains and we compare both simulated and real responses, which clearly shows the sim-toreal discrepancy in naïve DR.</p>
</li>
</ol>
<p>4.</p>
<p>Hardware validation on a low-cost robot: We verified our method on a low-cost, off-the-shelf, two-wheeled, high-gear-ratio (110:1) balancing robot Balboa 32U4, which is considered to be a hard example for the naïve RL+DR approaches.</p>
<p>Method 2.1 Modeling</p>
<p>We consider a two-wheeled balancing robot as a surrogate for a low-cost robotics platform.We adopt a planar cart-pole model with no wheel slip.This simplification captures key nonlinear control challenges while enabling analytical modeling.</p>
<p>The nonlinear state-space model is defined as follows [4]:
∆ = M (ml 2 + J) − (ml cos θ) 2 ,(1) ẋ= v,(2)
∆ v = −(ml) 2 g sin θ cos θ+
(ml 2 + J)(f + mlω 2 sin θ − D c v) + mlD p ω cos θ,(3)θ = ω,(4)
∆ ω = M mgl sin θ−
ml cos θ(f + mlω 2 sin θ − D c v) − M D p ω,(5)
where x, v, θ, ω denote horizontal position, velocity, angle, and angular velocity.m, m c are the pole and cart masses, M = m + m c , l is pole length, J is its inertia, g is gravity, and D c , D p are viscous damping terms.We treat all friction as viscous as an engineering approximation.We use nominal parameters based on empirical tuning (Table 2).</p>
<p>Controller Design and Training</p>
<p>We adopt a single-layer Elman RNN controller based on [8] to handle the plant's nonlinear dynamics with minimal computation.It receives the plant state x = [x, v, θ, ω] ⊤ and hidden state h, and outputs force f :
f = G(x, h) = c out • C(σ(Ah + Bx + b 1 )) + b 2 ,(6)
with trainable weights A, B, C, b 1 , b 2 , and activation σ.The RNN hidden state h is initialized to zeros.c out scales the NN output to match the force range.The matrix A is decomposed as in [8] to suppress the divergence of the training loss.Unlike deep RL, we exploit known dynamics and define direct losses for control objectives.The state tracking loss is
L s = E b,t (ŝ − s)/s base(7)
where s ∈ {x, v, θ, ω}, ŝ = [0, 0, 0, 0] ⊤ (means upright and stationary), The operator E b,t denotes the average over mini-batches and time.States are normalized by reference scales s base in the loss calculation.</p>
<p>To stabilize training, we apply a continuous curriculum learning (CCL) strategy as shown in Table 1: the initial training phase uses short horizons and low noise.The simulation length, noise levels, and parameter variations gradually increase as learning proceeds.Plant parameters are randomized in the fine-tuning phase.</p>
<p>At the initial time step, Gaussian noise is added to the initial state variables (e.g.x ← x noise(scale) • N (0, 1)).The cart-pole cannot move beyond the max values (clamped so that |x| ≤ x max ).When we get the output force f from a controller, a time-consistent external force f noise(scale) • N (0, 1) is added to increase robustness.The total force is also clamped so that |f | ≤ f max .The system is discretized using RK4.</p>
<p>Physics-Guided Regularization</p>
<p>Gain-Constrained Learning Classical proportional control uses:
f prop = −k x x − k v v − k θ θ − k ω ω,(8)
where k s are empirically tunable gains.We originated the idea of embedding this classical structure into the learning process to guide the RNN-based controller using the same methodology developed for solving partial differential equations [13], which is typically used straightforwardly as a model of motion in the context of control [3].Using automatic differentiation, we can compute a gain-equivalent of the RNN:
∂f ∂x , ∂f ∂v , ∂f ∂θ , ∂f ∂ω ,(9)
and minimize their deviation from experimentally observed gains k s :
L grad = 1 4 s E b,t ∂f ∂s − k s , L total = s L s + L grad .(10)
This constraint implicitly reflects real-world actuation characteristics and forces the RNN to align with them.
+ 0.1, 0.6 f noise(scale) 0 1 Plant Parameter Domain Randomization M M nom U(0.5, 2.0) • M nom m m nom 0.8 U(0.5, 1.0) • M l l nom U(0.5, 2.0) • l nom D c D c nom U(0.5, 2.0) • D c nom D p D p nom U(0.5, 2.0) • D p nom
Conditioned Domain Randomization We apply domain randomization over plant parameters (mass, length, and damping) to generalize across hardware uncertainty.However, naïve domain randomization leads to "overly conservative policies" [5], due to averaging over all variations.To mitigate this, we explicitly condition the controller on the current plant parameters, which are appended to the input state.This allows the network to avoid overly conservative policies.</p>
<p>Unified View</p>
<p>The gain constraint anchors the controller's sensitivity within physically meaningful bounds, while parameter conditioning enables adaptation across plant variations.Together, they suppress overgeneralization from domain randomization and preserve robustness near nominal parameters, forming a lightweight yet effective regularization scheme for sim-to-real transfer.The total training pipeline is shown in Fig. 1.</p>
<p>Deployment setting</p>
<p>Sensor smoothing (exponential moving average with smoothing factor 0.2) is applied to velocities.We formulated a simplified DC motor model:
f (t) = c emp • c gear r wheel • Φ PM R winding V bat (t)u duty (t),(11)
where u duty (t) is the signed PWM duty ratio, V bat (t) is the battery voltage, Φ PM is the magnetic flux, R winding is the winding resistance, c gear is the total gear ratio, and r is the wheel radius.Each constant is determined from datasheets or rough estimates and c emp absorbs modeling error.The c emp values are 1.2 (proportional control), 2.0 (only domain-randomized RNN), and 1.5 (gain-constrained domain-randomized RNN).We use the reverse function on the output of the controller RNN.</p>
<p>3 Experimental Condition</p>
<p>Hardware Setup</p>
<p>We bought the "Balboa 32U4 Balancing Robot Kit" with 50:1 gearboxes (item numbers 3575, 3073, and 1430) [12].We assembled it with Raspberry Pi 3B+.The final gear ratio is chosen as 110.2.The basic properties are shown in Table 2.The system architecture is shown in Fig. 2 and Fig. 3.</p>
<p>Device condition evaluation</p>
<p>The reference value of the matrix-vector multiplication is 0.168 ms, and the whole routine, including the signal processing on Raspberry Pi, is 2.76 ms (without raw sensor I/O and communication bottleneck between 2π × r wheel m two boards).Due to communication implementation, the actual control period varies from 10 ms to 30 ms.However, we observed that the degradation in control performance is not visible to humans, while it becomes evident when even slightly mismatched control weights are used.The battery voltage was 7.6 V to 8.0 V throughout the experiments.</p>
<p>Pre-experiments</p>
<p>We empirically determined the nominal proportional gains that were used in gain regularization in the loss function Equation 7. The upper and lower ranges were obtained from trial-and-error experiments on a real machine.</p>
<p>Simulated Results</p>
<p>We first compared the training loss s L s curves, as shown in Fig. 4. We truncated both domain-randomized (DR) RNNs with or without gain constraint (GC), at 3900 training epochs.The two models achieve nearly identical training losses computed from simulated state errors.A close-up of the curves over the initial epochs is shown in Fig. 5.The GC model converges faster than the baseline DR-RNN.We observed that this corresponds to the faster acquisition of the fundamental inverted pendulum control strategies.The equivalent gains E b,t ∂f ∂s are shown in Fig. 6.The effect of gain constraining on the GC model is evident in these results.In the GC model, the gains remain below 2.0, whereas those of the baseline DR-RNN fluctuate between roughly 1.0 and 4.0.</p>
<p>The simulated performances are calculated for each pole and cart mass pair.The contour plots for the proportional controller, the DR-RNN, and the GC-DR-RNN are shown in Fig. 7, Fig. 8, and Fig. 9.These plots indicate that domain-randomized RNNs exhibit wider robustness over plant parameters.This observation supports the effectiveness of domain-randomized training, widely used in recent robotics, for mitigating the sim-to-real gap.However, a closer look at robustness around the nominal parameters reveals a drawback of straightforward domain randomization: the stable region near the nominal point becomes narrower.</p>
<p>To investigate the cause of this effect, we visualized the final angular velocity loss and the final mini-batch samples, shown in Fig. 10 and Fig. 11.These visualizations reveal interesting properties of domain randomization, such that the randomization range and the generalization (stabilization) ranges broadly differ.Although the maximum randomized value of M is below 0.8 kg, the minimum-loss point in the DR model lies around 2.0 kg.This visualization implies that the task is "easier"at large masses, biasing the model toward such easy samples and degrading performance near the nominal plant parameters.The proposed GC model suppresses this tendency and maintains robustness near the nominal parameters, lying between the proportional and DR controllers.To determine the RNNs' context plant parameters, we varied the friction coefficients, which are difficult to identify accurately.The results are shown in Fig. 12, Fig. 13, and Fig. 14.The result is intuitive because the performance landscape is deforming towards the contextualized plant values.However, it is also counterintuitive in that the RNN also generalizes on the out-of-domain plant context values, and the in-domain robustness in the friction plane is best at these out-of-domain plant context values.Thus, we selected out-of-domain context values of D c = 17.06351 kg/s, D p = 0.024376 Nms/rad for the experiments.</p>
<p>Experimental Results</p>
<p>The angle and angular velocity records from the balancing experiment are shown in Fig. 15 and Fig. 16. 1 All models exhibit basic balancing capability on the real hardware.However, in the close-up shown in Fig. 17, anomalous oscillations appear in the DR-RNN.This phenomenon was also visible to human eyes.This observation is consistent with the proportional gain search in pre-experiment Table 3 and the relatively high equivalent angular velocity gain in DR-RNN, which is nearly outside the range of the working proportional gains.We used a peak-detection algorithm on the angular response of the simulator and real data, and watched the transient recovery responses of the states.We show the aligned angular velocity responses in Fig. 18, Fig. 19, and Fig. 20.These figures reveal the sim-to-real gap.Both the proportional controller and the GC-DR-RNN have similar exponentially decaying envelops, and the peak times are almost the same between the simulator and the real machine.However, the DR-RNN shows a clear discrepancy of peak times between the simulator and the real machine.The simulator result shows faster convergence than the other models, but the real response shows oscillation.</p>
<p>Conclusion</p>
<p>We adopted a simple consumer robot and plant model to expose the sim-to-real gap.We proposed a training constraint that reflects real-machine characteristics through the range of working proportional gains.The visualization in the plant parameter space showed that the domain randomization is effective in the wide robustness area, which may include multiple proportional controller performances in a single RNN.However, domain randomization alone enlarges sim-to-real mismatches around the nominal plant parameters by overemphasizing "easy" samples.Our proposed constraint suppresses the side-effect of domain randomization and shows better stability than the only domain-randomized controller on the real machine.</p>
<p>Limitations</p>
<p>Mismatch in conditioned physical parameters</p>
<p>We append simulated plant parameters (mass, length, damping, etc.) to the controller input, using identical values during training and deployment.However, our experiments revealed that the "best" performance did not always occur at the hardware parameters.To use the measured values directly as the RNN condition requires further research.</p>
<p>Performance parity with proportional control</p>
<p>Quantitatively, RNNs' settling times matched those of a well-tuned proportional controller, rather than exceeding them.Although some test runs yielded models that appeared to outperform proportional control in real-world trials, reliably achieving measurable advantages will require further refinement of loss functions or training strategies.</p>
<p>Remaining seed sensitivity</p>
<p>While our GC-DR-RNN shows far less training fragility than a pure RL+DR controller, it still inherits the seed sensitivity of deep networks.In practice, we found that only a few reruns, which filter out classicalcontrol-style instabilities, are sufficient to obtain a stable model.</p>
<p>Figure 2 :
2
Figure 2: Control system architecture: state estimates (position, velocity, angle, angular velocity) are computed from the Balboa 32U4 IMU and encoder, sent to a NumPy RNN on a Raspberry Pi 3B+ (via numpy.dot),and the resulting duty ratio is fed back to the Balboa Arduino at 10 ms intervals using Timer3 interrupts.</p>
<p>Figure 3 :
3
Figure 3: Physical experimental platform: a two-wheeled inverted-pendulum robot (Balboa 32U4) equipped with protective arms and a Raspberry Pi 3B+ on a carpeted surface.</p>
<p>Figure 4 :
4
Figure 4: Normalized training loss over 4000 epochs for two controllers: the domain-randomized RNN (gray) and the gain-constrained, domain-randomized RNN (red).Thin lines show raw loss; thick lines show smoothed trends.Both models converge to similar loss levels.</p>
<p>Figure 5 :
5
Figure 5: Zoom into the first 400 epochs of the normalized training loss.The GC-DR-RNN (red) converges more quickly than the only DR-RNN (gray), demonstrating faster acquisition of basic inverted-pendulum control strategies.</p>
<p>Figure 6 :
6
Figure 6: Suppression of sim-specific equivalent-gain ∂f ∂ω overfitting through regularization.</p>
<p>Figure 7 :
7
Figure 7: 5% settling-time contours of the proportional controller over the cart mass M vs. pole mass m plane.Fast convergence (dark blue) is confined to a narrow band around the nominal parameters, indicating limited robustness to parameter variations.</p>
<p>Figure 8 :
8
Figure 8: 5% settling-time contours of the DR-RNN over the cart mass M vs. pole mass m plane: the stable region is substantially wider than the proportional baseline, but the nominal point lies near the edge of the feasible zone, suggesting reduced local stability.</p>
<p>Figure 9 :
9
Figure 9: 5% settling-time contours for the GC-DR-RNN over the cart mass M vs. pole mass m plane.A broad dark-blue region surrounds the nominal point, showing that this model balances global robustness with high performance at the true hardware parameters.</p>
<p>Figure 10 :
10
Figure 10: Final minibatch sample locations (orange dots) overlaid on the contour map of angular velocity loss L ω in the M -m plane for the DR-RNN.The model's training is biased toward "easy" low-loss regions that lie away from the true hardware parameters.</p>
<p>Figure 11 :
11
Figure 11: Final minibatch sample locations (orange dots) overlaid on the contour map of angular velocity loss L ω in the M -m plane for the GC-DR-RNN.The loss minimum is centered near the nominal hardware parameters, demonstrating suppression of drift toward unrealistic configurations.</p>
<p>Figure 12 :
12
Figure 12: Angular 5% settling-time contours of the GC-DR-RNN across viscous damping parameters D c (cart) and D p (pole pivot), using nominal context values.</p>
<p>Figure 13 :
13
Figure 13: Angular 5% settling-time contours when conditioning the GC-DR-RNN on twice the nominal damping values.The stable region shifts upward but remains centered on moderate damping levels.</p>
<p>Figure 14 :
14
Figure 14: Angular 5% settling-time contours when the GC-DR-RNN is trained with extreme (out-of-domain) damping values.Despite this mismatch, the model achieves a wide stability region.</p>
<p>Figure 15 :
15
Figure 15: Real-world roll-angle responses under three controllers: proportional (green dashed), DR-RNN (gray dash-dot), and GC-DR-RNN (red solid).</p>
<p>Figure 16 :
16
Figure 16: Measured angular velocity traces: the DR-RNN (gray) oscillates beyond ±5 rad/s, whereas the GC-DR-RNN and proportional controller almost remain within ±2.5 rad/s and exhibit smooth corrections.</p>
<p>Figure 17 :
17
Figure 17: Zoom into 10-20 s of angular velocity data.The DR-RNN retains persistent ≃ 5 Hz oscillations, absent in both the GC-DR-RNN and the proportional controller.</p>
<p>Figure 18 :
18
Figure 18: Simulated vs. real angular velocity recovery for the proportional controller.Peak times and decay rates align closely, demonstrating high transfer fidelity.</p>
<p>Figure 19 :
19
Figure 19: Simulated vs. real angular velocity recovery for the DR-RNN: while simulation predicts fast convergence, the real system exhibits clear oscillations, highlighting the sim-to-real mismatch without gain regularization.</p>
<p>Figure 20 :
20
Figure 20: Simulated vs. real angular velocity recovery for the GC-DR-RNN: both domains show nearly identical decay envelopes and peak timings, confirming effective sim-to-real transfer with physics-guided regularization.</p>
<p>Table 1 :
1
Continuous Curriculum Learning Procedure
Parameter PretrainFinetuneSimulation Settingsepochs0 ≤ n &lt; 50 50 ≤ n &lt; 1000learn. rate5 × 10 −43 × 10 −4t sim /t dt50min ⌊(n − 50) • 500−50 950+ 50⌋, 500θ noise(scale)0.1min (n − 50) • 0.6−0.1 950</p>
<p>Table 2 :
2
Common Parameters
Parameter ValueUnitc out300Nf max20Nx max10mt sim≤ 5st dt10msn batch16-n≤ 2001-n hidden rnn256-x noise(scale)0.01mv noise(scale)0.01m/sθ noise(scale)≤ 35π/180radω noise(scale)0.01rad/sx base2mv base5m/sh base2πradw base2πrad/sM nom0.4kgm nom0.3kgl nom0.05mg nom9.8m/s 2D c nom3kg/sD p nom0.007Nms/radc gear10032/91 ≃ 110.2 -R winding4.3ΩΦ P M≃ 2.7×10 −3Wbr wheel38.25×10 −3ml wheel</p>
<p>Table 3 :
3
Working Proportional Gains from pre-experiment
Gains Lower Bound Nominal Upper BoundUnitk x&lt;113≥ 20N/mk v121517N/(m/s)k θ253140N/radk ω1.31.62.0-3.0N/(rad/s)
The first few seconds contain the machine holding time, after that, the machine is self-controlled before it falls (recording stops). Because the machine has relatively high friction in its moving parts, it sometimes becomes completely self-standing without control. We waited for the machine to fall again naturally in such a situation.
AcknowledgmentsI thank my colleague, Mitsuru Ambai, for insightful discussions on this paper.The manuscript uses "we" for stylistic consistency.This research was partially supported by OpenAI's ChatGPT, which was employed to reduce routine workload-such as generating source code, composing manuscripts, and improving grammar.The core ideas and research questions were conceived by the author.All AI-generated content was thoroughly proofread and debugged by the author.No AI-generated outputs were used to fabricate experimental results or to mislead readers.The author takes full responsibility for the scientific content presented herein.
Sim-to-real of humanoid locomotion policies via joint torque space perturbation injection. W Cha, J Cha, J Shin, D Kim, J Park, arXiv:2504.065852025</p>
<p>A black-box physics-informed estimator based on gaussian process regression for robot inverse dynamics identification. G Giacomuzzo, R Carli, D Romeres, A Dalla Libera, IEEE Transactions on Robotics. 2024</p>
<p>Equations of motion for the cart and pole control task. C D Green, January 2020Technical report</p>
<p>T He, J Gao, W Xiao, Y Zhang, Z Wang, J Wang, Z Luo, G He, N Sobanbab, C Pan, arXiv:2502.01143Aligning simulation and real-world physics for learning agile humanoid whole-body skills. 2025</p>
<p>Learning human-to-humanoid realtime whole-body teleoperation. T He, Z Luo, W Xiao, C Zhang, K Kitani, C Liu, G Shi, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2024</p>
<p>Learning bipedal locomotion on gear-driven humanoid robot using foot-mounted imus. S Katayama, Y Koda, N Nagatsuka, M Kinoshita, arXiv:2504.006142025</p>
<p>H Liu, S Teng, B Liu, W Zhang, M Ghaffari, arXiv:2503.01842Discrete-time hybrid automata learning: Legged locomotion meets skateboarding. 2025</p>
<p>I Mahajan, H Unjhawala, H Zhang, Z Zhou, A Young, A Ruiz, S Caldararu, N Batagoda, S Ashokkumar, D Negrut, arXiv:2403.11000Quantifying the sim2real gap for gps and imu sensors. 2024arXiv preprint</p>
<p>I Marougkas, D M Ramesh, J H Doerr, E Granados, A Sivaramakrishnan, A Boularias, K E Bekris, arXiv:2505.11858Integrating model-based control and rl for sim2real transfer of tight insertion policies. 2025</p>
<p>Pololu Balboa 32U4 Balancing Robot User's Guide. 2022</p>
<p>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G Karniadakis, Journal of Computational Physics. 3782019</p>
<p>Learning to walk in minutes using massively parallel deep reinforcement learning. N Rudin, D Hoeller, P Reist, M Hutter, Conference on robot learning. PMLR2022</p>            </div>
        </div>

    </div>
</body>
</html>