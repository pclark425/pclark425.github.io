<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1472 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1472</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1472</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-2afeafbc5998e090dc4d8f850d9ca3ff0dd0205f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2afeafbc5998e090dc4d8f850d9ca3ff0dd0205f" target="_blank">Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach</a></p>
                <p><strong>Paper Venue:</strong> AAAI Conference on Artificial Intelligence</p>
                <p><strong>Paper TL;DR:</strong> This research aims to focus on the creation and validation of safety frameworks that leverage multiple sources of information and establish a solid foundation for a long-term research program aimed at understanding the role of fidelity in simulators for safety validation and robot learning.</p>
                <p><strong>Paper Abstract:</strong> In recent years, learning-based autonomous systems have emerged as a promising tool for automating many crucial tasks. The key question is how we can build trust in such systems for safety-critical applications. My research aims to focus on the creation and validation of safety frameworks that leverage multiple sources of information. The ultimate goal is to establish a solid foundation for a long-term research program aimed at understanding the role of fidelity in simulators for safety validation and robot learning.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1472.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1472.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-fidelity simulators</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-fidelity simulated environments (low-fidelity and high-fidelity simulators)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper describes using multiple simulators with different fidelity levels (fast, simplified low-fidelity simulators and slower, more realistic high-fidelity simulators) as complementary information sources to accelerate safety validation and learning for autonomous/cyber-physical systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>multi-fidelity simulators (low-fidelity and high-fidelity)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Generic simulators for autonomous/cyber-physical systems and robot learning that vary in modelling detail: low-fidelity simulators employ strong simplifications for faster execution, while high-fidelity simulators model dynamics more realistically at higher computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>autonomous systems / robotics / cyber-physical systems</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>Low-fidelity: simplified models with strong assumptions and fast execution; High-fidelity: fewer simplifications, more realistic behaviors and dynamics, slower execution.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Paper-level description only: low-fidelity simulators 'make strong assumptions and simplifications' and run quickly; high-fidelity simulators 'consider fewer assumptions' and exhibit 'more realistic behaviors and dynamics' but are slower. No specific physical effects (e.g., friction, thermal, fluid dynamics) or numerical settings are specified.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Learning-enabled decision-making systems / autonomous agents (not specified further in architecture or training algorithm in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Safety validation and certification: identifying realistic failure modes of autonomous systems and accelerating the certification/testing process using multiple simulated environments.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Real-world data / real-world testing, human expert inputs, and varying-fidelity simulators (i.e., transfer across fidelity levels and to real-world experiments are discussed as objectives).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>The paper raises the research question of whether running many low-fidelity simulations combined with a small number of high-fidelity tests can identify failure modes efficiently, but it does not provide experimental results or conclude what minimum fidelity is required for successful transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No empirical failure cases reported in this paper; discussion is conceptual and proposes developing algorithms to optimally trade off between fidelities to discover likely failure events while minimizing simulation time and cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1472",
    "paper_id": "paper-2afeafbc5998e090dc4d8f850d9ca3ff0dd0205f",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "Multi-fidelity simulators",
            "name_full": "Multi-fidelity simulated environments (low-fidelity and high-fidelity simulators)",
            "brief_description": "The paper describes using multiple simulators with different fidelity levels (fast, simplified low-fidelity simulators and slower, more realistic high-fidelity simulators) as complementary information sources to accelerate safety validation and learning for autonomous/cyber-physical systems.",
            "citation_title": "Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach",
            "mention_or_use": "mention",
            "simulator_name": "multi-fidelity simulators (low-fidelity and high-fidelity)",
            "simulator_description": "Generic simulators for autonomous/cyber-physical systems and robot learning that vary in modelling detail: low-fidelity simulators employ strong simplifications for faster execution, while high-fidelity simulators model dynamics more realistically at higher computational cost.",
            "scientific_domain": "autonomous systems / robotics / cyber-physical systems",
            "fidelity_level": "Low-fidelity: simplified models with strong assumptions and fast execution; High-fidelity: fewer simplifications, more realistic behaviors and dynamics, slower execution.",
            "fidelity_characteristics": "Paper-level description only: low-fidelity simulators 'make strong assumptions and simplifications' and run quickly; high-fidelity simulators 'consider fewer assumptions' and exhibit 'more realistic behaviors and dynamics' but are slower. No specific physical effects (e.g., friction, thermal, fluid dynamics) or numerical settings are specified.",
            "model_or_agent_name": null,
            "model_description": "Learning-enabled decision-making systems / autonomous agents (not specified further in architecture or training algorithm in the paper).",
            "reasoning_task": "Safety validation and certification: identifying realistic failure modes of autonomous systems and accelerating the certification/testing process using multiple simulated environments.",
            "training_performance": null,
            "transfer_target": "Real-world data / real-world testing, human expert inputs, and varying-fidelity simulators (i.e., transfer across fidelity levels and to real-world experiments are discussed as objectives).",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": null,
            "minimal_fidelity_discussion": "The paper raises the research question of whether running many low-fidelity simulations combined with a small number of high-fidelity tests can identify failure modes efficiently, but it does not provide experimental results or conclude what minimum fidelity is required for successful transfer.",
            "failure_cases": "No empirical failure cases reported in this paper; discussion is conceptual and proposes developing algorithms to optimally trade off between fidelities to discover likely failure events while minimizing simulation time and cost.",
            "uuid": "e1472.0",
            "source_info": {
                "paper_title": "Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.00596425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Safety Validation of Learning-Based Autonomous Systems: A Multi-Fidelity Approach</h1>
<p>Ali Baheri*<br>Rochester Institute of Technology<br>akbeme@rit.edu</p>
<h4>Abstract</h4>
<p>In recent years, learning-based autonomous systems have emerged as a promising tool for automating many crucial tasks. The key question is how we can build trust in such systems for safety-critical applications. My research aims to focus on the creation and validation of safety frameworks that leverage multiple sources of information. The ultimate goal is to establish a solid foundation for a long-term research program aimed at understanding the role of fidelity in simulators for safety validation and robot learning.</p>
<h2>Introduction</h2>
<p>The deployment of learning-enabled decision-making systems into the real world can be risky and error-prone. Reasoning about the safety behavior of a complex autonomous system in a dynamic environment is a challenging task. Our goal is to develop safety verification and validation algorithms for complex autonomous systems operating in a highly evolving and stochastic environment. Specifically, our focus is on the creation of principled general frameworks that fuse insights from machine learning, formal methods, control theory, and optimization communities for safety verification and validation of learning-enabled autonomous systems.</p>
<p>One potential approach to the process of ensuring the safe behavior of autonomous systems is through the use of white box approaches, also referred to as formal methods, that can provide formal guarantees and proofs for the safe behavior of autonomous systems. However, increasing the level of complexity in autonomous systems is a barrier to the use of formal methods for safety assessment due to the problem of scalability. Black-box safety validation has recently gained interest to assess the safety behavior of an autonomous system where the only thing needed to examine the system's safety is a transition function that generates the next state of the system. The black-box safety validation approaches, while dispersed across many application domains, face a key drawback: the current methods do not take into account data from multiple sources, including varying levels of fidelity in simulated environments.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Research Vision</h2>
<p>Fidelity indicates the degree to which the simulator takes simplifications and assumptions into account when modeling the system. Low-fidelity simulators make strong assumptions and simplifications about the underlying system, resulting in relatively fast execution. On the other hand, high-fidelity simulators consider fewer assumptions about the underlying system and exhibit much more realistic behaviors and dynamics. However, they are slower to execute than low-fidelity simulators. With this insight in mind, our focus is to develop frameworks that aim to optimally tradeoff between low-fidelity, computationally cheap and highfidelity, computationally expensive simulators to maximize the discovered number of most likely failure events while minimizing the associated simulation time and cost.</p>
<p>We argue that a robot, or a cyber-physical system (CPS), can query data from multiple sources, including different levels of simulators, real-world data, and/or human expert inputs. Our hypothesis is that incorporating data from different sources could accelerate the certification task of a CPS and, broadly speaking, the learning process of an autonomous system. With multiple testing environments available at different fidelity levels, monetary costs, and test times, our goal is to answer the following research questions: (i) How can we optimally coordinate and use these testing environments to achieve the safety validation and certification objectives, such as identifying realistic failure modes? (ii) Can we get the benefit of running a large number of lowfidelity simulations with a cheaper cost and shorter time as well as adaptively performing as few high-fidelity tests as possible to identify the failure modes? In that line, our vision is to develop a new class of validation and verification algorithms that optimally take into account multiple sources of information with varying degrees of fidelity in simulated environments.</p>
<p>In summary, the goal of this research is to build trust in learning-enabled decision-making systems for safetycritical applications. We believe that systematic approaches that capture the information from multiple simulated environments could significantly speed up the certification process and reduce the overall computational time and cost. Hence, the outcome of this research will establish new results and contribute to filling a gap in the state-of-the-art for the safety validation of autonomous systems.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Ali Baheri is with the Department of Aeronautics \&amp; Astronautics at Stanford University.
Copyright (C) 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>