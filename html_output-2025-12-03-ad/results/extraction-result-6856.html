<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6856 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6856</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6856</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-265308911</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.12410v3.pdf" target="_blank">nach0: multimodal natural and chemical languages foundation model</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have substantially driven scientific progress in various domains, and many papers have demonstrated their ability to tackle complex problems with creative solutions. Our paper introduces a new foundation model, nach0, capable of solving various chemical and biological tasks: biomedical question answering, named entity recognition, molecular generation, molecular synthesis, attributes prediction, and others. nach0 is a multi-domain and multi-task encoder–decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge. We employed instruction tuning, where specific task-related instructions are utilized to fine-tune nach0 for the final set of tasks. To train nach0 effectively, we leverage the NeMo framework, enabling efficient parallel optimization of both base and large model versions. Extensive experiments demonstrate that our model outperforms state-of-the-art baselines on single-domain and cross-domain tasks. Furthermore, it can generate high-quality outputs in molecular and textual formats, showcasing its effectiveness in multi-domain setups.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6856.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6856.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>nach0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>nach0: Multimodal Natural and Chemical Languages Foundation Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An encoder-decoder foundation LLM (T5-family) pretrained on natural language (scientific abstracts and patents) and large-scale chemical string data (SMILES) and instruction-tuned in a multi-task setup to perform NLP, chemical prediction and molecule generation tasks in a unified text-to-text framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>nach0</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder-decoder, instruction-tuned, multi-task LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base ≈ 250M params; large ≈ 780M params</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained on filtered chemistry-related textual corpora (PubMed abstracts: ~13M documents, 355M tokens; USPTO patents: ~119K documents, 2.9B tokens) and chemical SMILES from ZINC (~100M documents, 4.7B tokens). Continued with multi-task supervised fine-tuning on a mixture of NLP, CHEM, and cross-domain datasets (MOSES, Mol-Instructions, MoleculeNet subsets, QM9, USPTO-derived reaction data, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Text-to-text prompt-based SMILES generation using instruction tuning; sampling at generation time with nucleus (top-p) sampling (p in [0.3,0.7], step 0.05). Fine-tuned for direct SMILES output; prompts for descriptor-guided generation and description-to-SMILES tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES strings tokenized with special SMILES tokens (<sm_{token}>); canonicalization used where applicable. (SELFIES discussed as a future alternative but not used.)</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Drug discovery (lead generation), reaction prediction (forward reaction, reagent prediction, retrosynthesis), molecular property prediction, molecular description generation; demonstrated case studies include Diabetes mellitus lead generation and Janus Kinase 3 (JAK3) inhibitor generation.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>When used standalone, generation relied on prompt design and sampling; in Chemistry42 experiment generated molecules were post-filtered by 2D/3D constraints (Medicinal Chemistry Filters, Lipinski Ro5, synthetic accessibility scoring, drug-likeness descriptors, pharmacophore/shape/3D similarity filters) provided by the Chemistry42 platform. Human expert selection used in case studies.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Training and deployment used NVIDIA NeMo toolkit (PyTorch Lightning, tensor & pipeline parallelism). For lead optimization experiments nach0 outputs were passed into the Chemistry42 platform for 2D/3D scoring (ConfGen, Pharmacophore, Shape Similarity, Pocket and Pocket-Ligand Interaction modules, SOM classifier, Structure Morphing). No internal docking/QM during generation by nach0 itself.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Pretraining: PubMed abstracts (chemistry-filtered), USPTO patents, ZINC SMILES (~100M). Fine-tune / evaluation: MOSES (unconditional generation), Mol-Instructions (cross-domain tasks), MoleculeNet subsets (ESOL, FreeSolv, Lipophilicity, BBBP, HIV, BACE), QM9, USPTO reaction splits, EMB-PICO, MedMCQA, BioASQ and others (see paper Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Molecular generation: MOSES metrics (validity %, uniqueness@10k, novelty %, internal diversity, SNN, fragment & scaffold similarity, Fréchet ChemNet Distance (FCD)); cross-domain: BLEU-2 for description-guided generation and molecular description generation; reaction tasks: accuracy@top1 (reagents, retrosynthesis, forward reaction); property prediction: balanced accuracy (BA) for classification tasks, R2 and RMSE for regression tasks; standard NLP metrics (F1, accuracy, Pearson).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Selected numbers (from paper Table 3, large model unless noted): validity 99.93%, Unique@10000 99.97%, FCD/Test = 0.3038, SNN/Test = 0.6222, Fragment/Test = 1.00, Scaffold/Test = 0.9292, IntDiv = 0.8585, Filters = 99.67%, Novelty = 93.87%. Description‑guided molecule design BLEU-2 ≈ 48.76% (large), Molecular description generation BLEU-2 ≈ 41.73% (large). Reaction metrics (large): reagent prediction top-1 = 13.08%, retrosynthesis top-1 = 56.26%, forward reaction prediction top-1 = 89.94%. Property tasks (large): BACE AUC ≈ 0.71, BBBP BA ≈ 0.68, HIV BA ≈ 0.60. Zero-shot information retrieval F1 ≈ 82.24% (base). (Pretraining: base model ≈250M, large ≈780M; see paper for full per-task tables.)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Relies on 2D SMILES strings (no explicit 3D geometry), prompt-sensitivity and potential prompt/data bias, multiple equivalent SMILES representations (canonicalization issues), no wet‑lab synthesis reported, not yet expert‑level outputs per human evaluation, lacks reinforcement-learning feedback in generation (no RL fine-tuning used yet), limited chemical diversity in training data (datasets biased to known drugs/probes), potential for hallucinated or invalid chemistry mitigated but not eliminated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'nach0: multimodal natural and chemical languages foundation model', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6856.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6856.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chemistry42 integration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chemistry42 generative platform (Integration experiment with nach0)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Insilico Medicine's Chemistry42 drug design platform with multiple generative models and scoring modules; in the paper, the authors replaced the platform's 42 generative models with nach0 outputs and scored/ranked them with Chemistry42's 2D/3D filters and modules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Chemistry42 (platform)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>generative platform + scoring pipeline (external toolset)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>platform (not a single LLM); n/a</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Platform modules use structure-based inputs (3LXK JAK3 crystal in the case study), pharmacophore hypotheses, property constraints and internal datasets for scoring; generative models in Chemistry42 historically are varied (42 models) but in the experiment replaced by nach0 outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>In the experiment nach0 generated SMILES (prompt-based), which were then scored and filtered by Chemistry42's modules; Chemistry42 normally uses multi-model generative ensemble and reinforcement learning/optimization but that RL feedback was not available to nach0 in the integration experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES input/output for generation; 3D conformers generated downstream by Chemistry42 modules (ConfGen) for 3D scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Structure-based design of JAK3 inhibitors (case study); more generally lead generation in drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Chemistry42 applied 2D modules (Medicinal Chemistry Filters, Lipinski Ro5, drug-likeness descriptors, SA score, novelty filters) and 3D modules (ConfGen conformer generation, pharmacophore matching, 3D-shape similarity, pocket/PLI scoring), plus SOM classifier and Structure Morphing for metabolic instability.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Full integration used Chemistry42's internal 2D/3D modules for filtering/scoring (ConfGen, Pharmacophore Module, Shape Similarity, Pocket and PLI modules), with nach0 providing candidate SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Not applicable as a dataset; used a structure-based case study (JAK3 crystal 3LXK) and Chemistry42 internal scoring modules and filters.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Discovery rate: percentage of generated molecules passing all 2D and 3D constraints; time-to-discovery (45 minutes experiment: 15 min generation + 30 min scoring). Also qualitative binding mode assessment (hinge binder presence) and comparison to Chemistry42 and combinatorial generator.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>In the 45-minute run with nach0 replacing the 42 generative models, nach0 discovered 8 molecules satisfying all 2D and 3D requirements; discovered molecules had hinge binding motifs and fit active site according to Chemistry42 scoring. Authors note these molecules were inferior to 72‑hour Chemistry42 generations, attributed to lack of RL feedback and lack of experiment-specific knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>nach0 lacked direct access to experiment-specific inputs (e.g., crystal structure and configured rewards) when generating candidates and therefore underperformed compared to Chemistry42 runs that include RL and tailored model configuration; generation quality could improve with RL feedback and explicit structure-conditioned prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'nach0: multimodal natural and chemical languages foundation model', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6856.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6856.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MOSES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MOSES benchmark (Molecular Sets)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used benchmark and dataset for evaluating generative molecular models (distribution matching, validity, uniqueness, novelty and diversity metrics); used in the paper to evaluate unconditional molecular generation quality from nach0.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MOSES (benchmark/dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>dataset / evaluation benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈ 2M filtered molecules in the MOSES dataset (per original MOSES description)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>MOSES dataset contains ~2 million druglike molecules filtered by Medicinal Chemistry Filters and other rules; used as target distribution for unconditional generation evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Benchmark expects model to generate SMILES/unconditional molecules; nach0 generated 30,000 molecules for MOSES metric computation.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES (canonicalized for evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Benchmarking generative models for drug-like molecule generation / distribution matching.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>MOSES dataset itself enforces prefiltering rules (MCFs, PAINS, etc.) for ground truth; evaluation includes counting how many generated molecules pass similar filters.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Evaluation of nach0 outputs used standard MOSES metrics computation scripts (fragment/scaffold similarity, FCD etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>MOSES (benchmark dataset), authors generated 30,000 molecules to compute metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Validity %, uniqueness@10k, novelty %, internal diversity, SNN, fragment similarity, scaffold similarity, Fréchet ChemNet Distance (FCD).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>For nach0 (base/large) reported MOSES-style metrics: validity up to 99.93%, Unique@10000 up to 99.97%, FCD/Test = 0.3038 (large), SNN/Test = 0.6222, Frag/Test = 1.00, Scaf/Test = 0.9292, IntDiv = 0.8585, Filters pass rate 99.67%, Novelty ≈ 93.87%. (See Table 3 in paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>MOSES evaluates distributional similarity to known datasets and cannot assess novelty beyond literature; MOSES metrics do not measure experimental synthesizability beyond SA proxies and do not validate biological activity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'nach0: multimodal natural and chemical languages foundation model', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6856.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6856.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mol-Instructions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mol-Instructions (cross-domain molecule instruction dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cross-domain dataset containing molecule-oriented instructions, protein-oriented instructions and biomolecular text instructions, used here for cross-domain tasks such as description-guided molecule design, molecular description generation, and reaction prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mol-Instructions (dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>dataset for cross-domain instruction tuning</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>contains multiple subsets including molecule‑oriented instruction examples and reaction examples (exact size per subset in original data)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Dataset built from PubChem and other sources; contains pairs of natural-language instructions and molecule SMILES or reaction entries intended for text-to-text learning.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used to fine-tune nach0 for tasks such as description-guided molecule generation, molecular description generation, forward reaction prediction, reagent prediction and retrosynthesis in a text-to-text prompt/response format.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES used as target and/or condition; also textual molecular descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Cross-domain generation: converting textual descriptions/instructions into SMILES, producing textual descriptions from SMILES, reaction prediction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Dataset examples include descriptor-guided instructions; generation constrained by prompt content (descriptor constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Used in fine-tuning pipeline within NeMo; downstream generated outputs evaluated with BLEU-2 for description tasks and reaction accuracy metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Mol-Instructions (first subset: molecule-oriented instructions) as cited in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>BLEU-2 for description-guided molecule design and molecular description generation; top-k accuracy for reaction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Description-guided molecule design BLEU-2: nach0 base ≈ 48.97%, nach0 large ≈ 48.76%; molecular description generation BLEU-2: nach0 base ≈ 43.91%, large ≈ 41.73%. Reaction task performance (see Table 3): forward reaction top-1 large ≈ 89.94%, retrosynthesis top-1 large ≈ 56.26%.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Mol-Instructions and PubChem-derived descriptions largely reflect known chemistry (drugs and probes) and may not cover novel chemical diversity; quality of generation depends on prompt specificity; dataset noise and alignment between text and structure can be imperfect.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'nach0: multimodal natural and chemical languages foundation model', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mol-Instructions <em>(Rating: 2)</em></li>
                <li>MOSES <em>(Rating: 2)</em></li>
                <li>MolT5 <em>(Rating: 2)</em></li>
                <li>SELFIES <em>(Rating: 2)</em></li>
                <li>Galactica: A Large Language Model for Science <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6856",
    "paper_id": "paper-265308911",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "nach0",
            "name_full": "nach0: Multimodal Natural and Chemical Languages Foundation Model",
            "brief_description": "An encoder-decoder foundation LLM (T5-family) pretrained on natural language (scientific abstracts and patents) and large-scale chemical string data (SMILES) and instruction-tuned in a multi-task setup to perform NLP, chemical prediction and molecule generation tasks in a unified text-to-text framework.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "nach0",
            "model_type": "encoder-decoder, instruction-tuned, multi-task LLM",
            "model_size": "base ≈ 250M params; large ≈ 780M params",
            "training_data_description": "Pretrained on filtered chemistry-related textual corpora (PubMed abstracts: ~13M documents, 355M tokens; USPTO patents: ~119K documents, 2.9B tokens) and chemical SMILES from ZINC (~100M documents, 4.7B tokens). Continued with multi-task supervised fine-tuning on a mixture of NLP, CHEM, and cross-domain datasets (MOSES, Mol-Instructions, MoleculeNet subsets, QM9, USPTO-derived reaction data, etc.).",
            "generation_method": "Text-to-text prompt-based SMILES generation using instruction tuning; sampling at generation time with nucleus (top-p) sampling (p in [0.3,0.7], step 0.05). Fine-tuned for direct SMILES output; prompts for descriptor-guided generation and description-to-SMILES tasks.",
            "chemical_representation": "SMILES strings tokenized with special SMILES tokens (&lt;sm_{token}&gt;); canonicalization used where applicable. (SELFIES discussed as a future alternative but not used.)",
            "target_application": "Drug discovery (lead generation), reaction prediction (forward reaction, reagent prediction, retrosynthesis), molecular property prediction, molecular description generation; demonstrated case studies include Diabetes mellitus lead generation and Janus Kinase 3 (JAK3) inhibitor generation.",
            "constraints_used": "When used standalone, generation relied on prompt design and sampling; in Chemistry42 experiment generated molecules were post-filtered by 2D/3D constraints (Medicinal Chemistry Filters, Lipinski Ro5, synthetic accessibility scoring, drug-likeness descriptors, pharmacophore/shape/3D similarity filters) provided by the Chemistry42 platform. Human expert selection used in case studies.",
            "integration_with_external_tools": "Training and deployment used NVIDIA NeMo toolkit (PyTorch Lightning, tensor & pipeline parallelism). For lead optimization experiments nach0 outputs were passed into the Chemistry42 platform for 2D/3D scoring (ConfGen, Pharmacophore, Shape Similarity, Pocket and Pocket-Ligand Interaction modules, SOM classifier, Structure Morphing). No internal docking/QM during generation by nach0 itself.",
            "dataset_used": "Pretraining: PubMed abstracts (chemistry-filtered), USPTO patents, ZINC SMILES (~100M). Fine-tune / evaluation: MOSES (unconditional generation), Mol-Instructions (cross-domain tasks), MoleculeNet subsets (ESOL, FreeSolv, Lipophilicity, BBBP, HIV, BACE), QM9, USPTO reaction splits, EMB-PICO, MedMCQA, BioASQ and others (see paper Table 1).",
            "evaluation_metrics": "Molecular generation: MOSES metrics (validity %, uniqueness@10k, novelty %, internal diversity, SNN, fragment & scaffold similarity, Fréchet ChemNet Distance (FCD)); cross-domain: BLEU-2 for description-guided generation and molecular description generation; reaction tasks: accuracy@top1 (reagents, retrosynthesis, forward reaction); property prediction: balanced accuracy (BA) for classification tasks, R2 and RMSE for regression tasks; standard NLP metrics (F1, accuracy, Pearson).",
            "reported_results": "Selected numbers (from paper Table 3, large model unless noted): validity 99.93%, Unique@10000 99.97%, FCD/Test = 0.3038, SNN/Test = 0.6222, Fragment/Test = 1.00, Scaffold/Test = 0.9292, IntDiv = 0.8585, Filters = 99.67%, Novelty = 93.87%. Description‑guided molecule design BLEU-2 ≈ 48.76% (large), Molecular description generation BLEU-2 ≈ 41.73% (large). Reaction metrics (large): reagent prediction top-1 = 13.08%, retrosynthesis top-1 = 56.26%, forward reaction prediction top-1 = 89.94%. Property tasks (large): BACE AUC ≈ 0.71, BBBP BA ≈ 0.68, HIV BA ≈ 0.60. Zero-shot information retrieval F1 ≈ 82.24% (base). (Pretraining: base model ≈250M, large ≈780M; see paper for full per-task tables.)",
            "experimental_validation": false,
            "challenges_or_limitations": "Relies on 2D SMILES strings (no explicit 3D geometry), prompt-sensitivity and potential prompt/data bias, multiple equivalent SMILES representations (canonicalization issues), no wet‑lab synthesis reported, not yet expert‑level outputs per human evaluation, lacks reinforcement-learning feedback in generation (no RL fine-tuning used yet), limited chemical diversity in training data (datasets biased to known drugs/probes), potential for hallucinated or invalid chemistry mitigated but not eliminated.",
            "uuid": "e6856.0",
            "source_info": {
                "paper_title": "nach0: multimodal natural and chemical languages foundation model",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Chemistry42 integration",
            "name_full": "Chemistry42 generative platform (Integration experiment with nach0)",
            "brief_description": "Insilico Medicine's Chemistry42 drug design platform with multiple generative models and scoring modules; in the paper, the authors replaced the platform's 42 generative models with nach0 outputs and scored/ranked them with Chemistry42's 2D/3D filters and modules.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Chemistry42 (platform)",
            "model_type": "generative platform + scoring pipeline (external toolset)",
            "model_size": "platform (not a single LLM); n/a",
            "training_data_description": "Platform modules use structure-based inputs (3LXK JAK3 crystal in the case study), pharmacophore hypotheses, property constraints and internal datasets for scoring; generative models in Chemistry42 historically are varied (42 models) but in the experiment replaced by nach0 outputs.",
            "generation_method": "In the experiment nach0 generated SMILES (prompt-based), which were then scored and filtered by Chemistry42's modules; Chemistry42 normally uses multi-model generative ensemble and reinforcement learning/optimization but that RL feedback was not available to nach0 in the integration experiment.",
            "chemical_representation": "SMILES input/output for generation; 3D conformers generated downstream by Chemistry42 modules (ConfGen) for 3D scoring.",
            "target_application": "Structure-based design of JAK3 inhibitors (case study); more generally lead generation in drug discovery.",
            "constraints_used": "Chemistry42 applied 2D modules (Medicinal Chemistry Filters, Lipinski Ro5, drug-likeness descriptors, SA score, novelty filters) and 3D modules (ConfGen conformer generation, pharmacophore matching, 3D-shape similarity, pocket/PLI scoring), plus SOM classifier and Structure Morphing for metabolic instability.",
            "integration_with_external_tools": "Full integration used Chemistry42's internal 2D/3D modules for filtering/scoring (ConfGen, Pharmacophore Module, Shape Similarity, Pocket and PLI modules), with nach0 providing candidate SMILES.",
            "dataset_used": "Not applicable as a dataset; used a structure-based case study (JAK3 crystal 3LXK) and Chemistry42 internal scoring modules and filters.",
            "evaluation_metrics": "Discovery rate: percentage of generated molecules passing all 2D and 3D constraints; time-to-discovery (45 minutes experiment: 15 min generation + 30 min scoring). Also qualitative binding mode assessment (hinge binder presence) and comparison to Chemistry42 and combinatorial generator.",
            "reported_results": "In the 45-minute run with nach0 replacing the 42 generative models, nach0 discovered 8 molecules satisfying all 2D and 3D requirements; discovered molecules had hinge binding motifs and fit active site according to Chemistry42 scoring. Authors note these molecules were inferior to 72‑hour Chemistry42 generations, attributed to lack of RL feedback and lack of experiment-specific knowledge.",
            "experimental_validation": false,
            "challenges_or_limitations": "nach0 lacked direct access to experiment-specific inputs (e.g., crystal structure and configured rewards) when generating candidates and therefore underperformed compared to Chemistry42 runs that include RL and tailored model configuration; generation quality could improve with RL feedback and explicit structure-conditioned prompting.",
            "uuid": "e6856.1",
            "source_info": {
                "paper_title": "nach0: multimodal natural and chemical languages foundation model",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "MOSES",
            "name_full": "MOSES benchmark (Molecular Sets)",
            "brief_description": "A widely-used benchmark and dataset for evaluating generative molecular models (distribution matching, validity, uniqueness, novelty and diversity metrics); used in the paper to evaluate unconditional molecular generation quality from nach0.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "MOSES (benchmark/dataset)",
            "model_type": "dataset / evaluation benchmark",
            "model_size": "≈ 2M filtered molecules in the MOSES dataset (per original MOSES description)",
            "training_data_description": "MOSES dataset contains ~2 million druglike molecules filtered by Medicinal Chemistry Filters and other rules; used as target distribution for unconditional generation evaluation.",
            "generation_method": "Benchmark expects model to generate SMILES/unconditional molecules; nach0 generated 30,000 molecules for MOSES metric computation.",
            "chemical_representation": "SMILES (canonicalized for evaluation).",
            "target_application": "Benchmarking generative models for drug-like molecule generation / distribution matching.",
            "constraints_used": "MOSES dataset itself enforces prefiltering rules (MCFs, PAINS, etc.) for ground truth; evaluation includes counting how many generated molecules pass similar filters.",
            "integration_with_external_tools": "Evaluation of nach0 outputs used standard MOSES metrics computation scripts (fragment/scaffold similarity, FCD etc.).",
            "dataset_used": "MOSES (benchmark dataset), authors generated 30,000 molecules to compute metrics.",
            "evaluation_metrics": "Validity %, uniqueness@10k, novelty %, internal diversity, SNN, fragment similarity, scaffold similarity, Fréchet ChemNet Distance (FCD).",
            "reported_results": "For nach0 (base/large) reported MOSES-style metrics: validity up to 99.93%, Unique@10000 up to 99.97%, FCD/Test = 0.3038 (large), SNN/Test = 0.6222, Frag/Test = 1.00, Scaf/Test = 0.9292, IntDiv = 0.8585, Filters pass rate 99.67%, Novelty ≈ 93.87%. (See Table 3 in paper.)",
            "experimental_validation": false,
            "challenges_or_limitations": "MOSES evaluates distributional similarity to known datasets and cannot assess novelty beyond literature; MOSES metrics do not measure experimental synthesizability beyond SA proxies and do not validate biological activity.",
            "uuid": "e6856.2",
            "source_info": {
                "paper_title": "nach0: multimodal natural and chemical languages foundation model",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Mol-Instructions",
            "name_full": "Mol-Instructions (cross-domain molecule instruction dataset)",
            "brief_description": "A cross-domain dataset containing molecule-oriented instructions, protein-oriented instructions and biomolecular text instructions, used here for cross-domain tasks such as description-guided molecule design, molecular description generation, and reaction prediction.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mol-Instructions (dataset)",
            "model_type": "dataset for cross-domain instruction tuning",
            "model_size": "contains multiple subsets including molecule‑oriented instruction examples and reaction examples (exact size per subset in original data)",
            "training_data_description": "Dataset built from PubChem and other sources; contains pairs of natural-language instructions and molecule SMILES or reaction entries intended for text-to-text learning.",
            "generation_method": "Used to fine-tune nach0 for tasks such as description-guided molecule generation, molecular description generation, forward reaction prediction, reagent prediction and retrosynthesis in a text-to-text prompt/response format.",
            "chemical_representation": "SMILES used as target and/or condition; also textual molecular descriptions.",
            "target_application": "Cross-domain generation: converting textual descriptions/instructions into SMILES, producing textual descriptions from SMILES, reaction prediction tasks.",
            "constraints_used": "Dataset examples include descriptor-guided instructions; generation constrained by prompt content (descriptor constraints).",
            "integration_with_external_tools": "Used in fine-tuning pipeline within NeMo; downstream generated outputs evaluated with BLEU-2 for description tasks and reaction accuracy metrics.",
            "dataset_used": "Mol-Instructions (first subset: molecule-oriented instructions) as cited in the paper.",
            "evaluation_metrics": "BLEU-2 for description-guided molecule design and molecular description generation; top-k accuracy for reaction tasks.",
            "reported_results": "Description-guided molecule design BLEU-2: nach0 base ≈ 48.97%, nach0 large ≈ 48.76%; molecular description generation BLEU-2: nach0 base ≈ 43.91%, large ≈ 41.73%. Reaction task performance (see Table 3): forward reaction top-1 large ≈ 89.94%, retrosynthesis top-1 large ≈ 56.26%.",
            "experimental_validation": false,
            "challenges_or_limitations": "Mol-Instructions and PubChem-derived descriptions largely reflect known chemistry (drugs and probes) and may not cover novel chemical diversity; quality of generation depends on prompt specificity; dataset noise and alignment between text and structure can be imperfect.",
            "uuid": "e6856.3",
            "source_info": {
                "paper_title": "nach0: multimodal natural and chemical languages foundation model",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mol-Instructions",
            "rating": 2,
            "sanitized_title": "molinstructions"
        },
        {
            "paper_title": "MOSES",
            "rating": 2
        },
        {
            "paper_title": "MolT5",
            "rating": 2
        },
        {
            "paper_title": "SELFIES",
            "rating": 2
        },
        {
            "paper_title": "Galactica: A Large Language Model for Science",
            "rating": 1,
            "sanitized_title": "galactica_a_large_language_model_for_science"
        }
    ],
    "cost": 0.015539999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>J o u r n a l Na me nach0: Multimodal Natural and Chemical Languages Foundation Model †
2 May 2024</p>
<p>Micha Livne 
Zulfat Miftahutdinov 
Elena Tutubalina 
Maksim Kuznetsov 
Daniil Polykovskiy 
Annika Brundyn 
Aastha Jhunjhunwala 
Anthony Costa 
Alex Aliper 
Alán Aspuru-Guzik 
Alex Zhavoronkov 
J o u r n a l Na me nach0: Multimodal Natural and Chemical Languages Foundation Model †
2 May 202451A6A29C5D068213990C13670C48B12EarXiv:2311.12410v3[cs.CL]
Large Language Models (LLMs) have substantially driven scientific progress in various domains, and many papers have demonstrated their ability to tackle complex problems with creative solutions.Our paper introduces a new foundation model, nach0, capable of solving various chemical and biological tasks: biomedical question answering, named entity recognition, molecular generation, molecular synthesis, attributes prediction, and others.nach0 is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge.We employed instruction tuning, where specific task-related instructions are utilized to fine-tune nach0 for the final set of tasks.To train nach0 effectively, we leverage the NeMo framework, enabling efficient parallel optimization of both base and large model versions.Extensive experiments demonstrate that our model outperforms state-ofthe-art baselines on single-domain and cross-domain tasks.Furthermore, it can generate high-quality outputs in molecular and textual formats, showcasing its effectiveness in multi-domain setups.J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 | 1</p>
<p>Introduction</p>
<p>Large-scale pre-training of language models (LMs), such as BERT 1 , T5 2 , BART 3 and GPT 4 , on vast amounts of text data has yielded impressive results on a variety of natural language processing (NLP) tasks.These models' success can be attributed to their ability to learn deeply contextualized representations of input tokens through self-supervision at scale 1 .Recently, foundation models have built upon the concept of self-supervised learning by pre-training a single model over unlabeled data that can be easily adapted to any task 5 .</p>
<p>The application of neural network architectures and LMs has significantly advanced the field of chemistry, particularly in domain-specific information retrieval, drug development, and clinical trial design [6][7][8][9][10][11][12][13][14][15] .These developments include neural molecular fingerprinting, generative approaches to small molecule design [11][12][13] , prediction of pharmacological properties, ‡ Email: alex@insilicomedicine.comand drug repurposing 13,14 .The clinical development of a drug is a time and money consuming process that typically requires several years and a billion-dollar budget to progress from phase 1 clinical trials to the patients 16 .The use of state-of-the-art neural network approaches and language models has the potential to facilitate the drug development process considerably.</p>
<p>A number of LMs have been proposed for the biomedical domain, utilizing a variety of model families: for instance, researchers have developed BioBERT 17 , based on BERT with 110 million parameters, and SciFive, based on T5-base and T5-large with 220 and 770 million parameters respectively, using biomedical literature from PubMed.NVIDIA has also developed BioMegatron models in the biomedical domain using a more extensive set of PubMed-derived free text, ranging from 345 million to 1.2 billion parameters.However, the datasets used in these models cover mainly biomedical natural language texts and contain biomedical named entities like drugs, genes, and cell lines names but omit important chemical structure descriptions in SMILES format.Enriching biomedical datasets with chemical structures is an important and challenging task.Recently, LMs such as Galactica 18 , based on Transformer architecture in a decoder-only setup 19 with 120 billion parameters in its largest setup, and MolT5 20 , based on T5-base and T5-large, were proposed to address this limitation.Both modes were pre-trained with natural language and chemical data, creating a shared representation space, yet were not fine-tuned on a diverse set of chemical tasks Fig. 1 A Venn diagram that shows the relationships between fine-tuning data used in our study and related work.It is important to highlight that the majority of models typically treat the chemical space and the semantic space in the natural language domain independently.Novel cross-domain datasets such as Mol-Instructions 25 and MolT5 data 20 have asked whether it is possible to unify representations of natural language and molecules for NLP and molecule generation tasks within a single model.In this work, we seek to answer this question.</p>
<p>with instruction tuning in a multi-task fashion.The Venn diagram in Fig. 1 provides a summary of the existing LMs.Furthermore, simple language models trained with molecular structures can reproduce complex molecular distributions 21 , and even their 3D structure of molecules, materials and proteins using a GPT framework 22 .</p>
<p>In this paper, we propose a unified encoder-decoder transformer named nach0 for natural language, chemical generalization and cross-domain tasks.We pre-train on both natural language and chemical data using Self Supervised Learning and employ nach0 as the foundation model for a wide range of downstream tasks (Fig. 2).The tasks include well-known NLP problems such as information extraction, question answering, textual entailment, molecular structures and description generation, chemical property prediction, and reaction predictions.Inspired by Raffel et al. 2 , Chung et al. 23 , we follow the intuition that tasks can be described via natural language instructions, such as "What reactants could be used to synthesize O=C(NC1CCN(Cc2ccccc2)CC1)c1c(Cl)cccc1 [</p>
<p>N+](=O)[O-]" or "describe a molecule C1=CC(=CC=C1C<a href="C(=O)[O-]">C@H</a>N)O".</p>
<p>Prompt design and instruction tuning are employed for model training using NVIDIA's Neural Modules (NeMo) framework 24 , which provides scientists with a way to train and deploy LLMs using NVIDIA GPUs.Extensive evaluation in both in-domain and cross-domain setup demonstrates that nach0 is a powerful tool for the chemistry domain.</p>
<p>Contribution Our contributions are three-fold:</p>
<ol>
<li>
<p>We introduce a biochemical foundation model nach0 and pre-train base and large versions of nach0 on molecular structures and textual data from scientific articles and patents.</p>
</li>
<li>
<p>We fine-tune nach0 in a supervised and multi-task manner, using a combination of diverse tasks specified through natural language prompts.datasets, focusing on both single-domain and cross-domain tasks, we show that our model achieves competitive results with state-of-the-art encoder-decoder models specialized for single domain.</p>
</li>
</ol>
<p>Through the experimental validation on benchmark</p>
<p>Methods</p>
<p>Framework nach0</p>
<p>The aim of nach0 is to create a unified transformer capable of performing natural language, chemical generalization, and translation tasks simultaneously.Fig. 3 shows a diagram of our framework with several input/output examples.The model's representations are learned from extensive and diverse chemical SMILES data and related textual data from scientific articles and patents.Similar to Raffel et al. 2 , Chung et al. 23 , nach0 follows an encoder-decoder architecture that takes textual input and generates target responses.To train the model on a mixture of datasets partitioned into different tasks, we formulate all the tasks in a "text-to-text" format, where the model is given some text as a context or condition and produces the output in a text format.Each dataset is associated with multiple prompt templates used to format datasets' instances into input and target pairs.In particular, we train nach0 on three types of tasks (Fig. 2):</p>
<p>• NLP tasks: named entity recognition (NER), PICO extraction, textual entailment, relation extraction, sentence similarity, document classification, question answering (yes/no, multi-choice, open);</p>
<p>• chemistry-related (CHEM) tasks: molecular property prediction, molecular generation, forward reaction prediction, reagent prediction, retrosynthesis;</p>
<p>• cross-domain (NLP↔CHEM) tasks: description-guided molecule design, molecular description generation; Fig. 3 shows our model and prompt format.Details on train/test splits are presented in Table 1.Datasets' descriptions  Given the presence of textual and molecular modalities, different tokenization technique is a crucial aspect of dataset design.One way to represent molecular structures is a simplified molecular-input line-entry system (SMILES) string 41 .SMILES describe a molecule as a sequence of atoms in a depth-first traversal order and uses special symbols to depict branching, cycle opening/closing, bond types, and stereochemistry.We use the following tokenization:</p>
<p>• Textual domain sub-word tokens adopted from FLAN-T5 23 for natural language sequences;</p>
<p>• Tokenization for SMILES: we annotate each SMILES token with special symbols: <sm_{token}> and extend the vocabulary with such tokens.</p>
<p>Model and Training Configuration</p>
<p>In our study, we predominantly employ a model featuring the default T5 architecture, which is derived from Raffel et al.For both models, we conduct pre-training with a language modeling (LM) objective and subsequent fine-tuning.The base models were trained using NVIDIA A4000 and A5000 GPUs, while the larger models were trained on NVIDIA's DGX cloud platform.Both the pre-training and fine-tuning stages were executed using the subsequent hyperparameters: a batch size of 1024, a learning rate set to 1e-4, and a weight decay of 0.01.The pre-training stage lasted for a single epoch, whereas the fine-tuning stage for 10 epochs.</p>
<p>To execute the pre-training phase of our model with the LM objective, we leveraged two textual data sources in addition to one chemical data source.These textual data sources encompassed abstract texts extracted from Pubmed and patent descriptions derived from USPTO.All the textual data underwent a filtering process, eliminating documents that were not related to the chemistry domain.Consequently, the number of documents was curtailed to 13M for abstracts and 119K for patents.The chemical data component was sourced from the ZINC dataset, encompassing approximately 100 million documents.In aggregate, the textual data set contained 355M tokens for abstracts and 2.9B tokens for patents, whereas the chemical data encompassed 4.7B tokens.</p>
<p>The entirety of the investigations in this paper was conducted using the multi-task model, with the exception of the ablation part.Each multi-task model underwent fine-tuning by leveraging the entire spectrum of available datasets, encompassing all domains, as elucidated in Sec. 1.For data mixing and balancing we followed the "Examples-proportional mixing strategy" from Raffel et al. 2 .The outcomes of these models are explicitly detailed in Sec. 3. Conversely, in the context of ablation studies, fine-tuning was specifically performed utilizing only those datasets relevant to the corresponding domain, as detailed in the discussion.</p>
<p>The training was performed using NVIDIA NeMo Toolkit 42 , which consists of pre-built modules for end-to-end workflows in Automatic Speech Recognition (ASR), NLP, and Text-to-Speech (TTS) synthesis.NeMo uses PyTorch Lightning for optimized multinode/multi-GPU (MNMG) mixed-precision training.In this work, we leveraged the NeMo NLP collection to train and evaluate our LMs.We trained our model on a variety of tasks such as information extraction, question answering, molecular property prediction, and description-guided molecule design using the NeMo toolkit.A custom connector was added to extend the vocabulary size of the pre-trained model when continuing the training of the model with chemistry and biomedical datasets.The original vocabulary was extended to match the target vocabulary which was larger.The corresponding embedding matrix was initialized with learned embeddings of the original model.The extra tokens were initialized by re-using the first embeddings.</p>
<p>Data was parsed using Mem-Map Datasets from the NeMo toolkit to allow efficient data handling.The mem-map dataset relies on memory mapping directly to files, allowing the handling of very large datasets with small memory footprints and optimal reading speed.The data was loaded as raw text files and the tokenization occurred on-the-fly.Pre-fetching of the data mitigated the effects of online tokenization when compared to pretokenized data.The model was trained using tensor and pipeline parallelism 43 , both of which are model parallel methods for distributed training and are implemented in the NeMo toolkit for efficient scaling of large language model training.</p>
<p>Results and discussion</p>
<p>Use case: End-to-end drug discovery</p>
<p>In the first case study, we generate molecular structures against Diabetes mellitus (DM) using just one model, nach0: discover biological targets with potential therapeutic activity, analyze the mechanism of action, generate molecular structure, propose one-step synthesis, and predict molecular properties.In a series of questions, we generate the model's responses using top-p sampling with values from 0.3 to 0.7 and step equals 0.05 and ask an expert chemist to pick the best response (Fig. 4).In total, we generate 200 SMILES on the molecule generation prompt and select one structure, CC(C)(C)NC(=O)CN1CCC(C(=O)Nc2cccc(-c3nc4ccccc4n3Cc3cc ccc3)c2)CC1, as the most promising based on a chemical expert knowledge perspective.This semi-automated approach is efficient for discovering novel molecules and assessing their properties.We predict that further iterations of this model will require less supervision, and medicinal chemists will start using it as a side-car for generating and validating ideas.</p>
<p>Use case: Chemistry42 generative model</p>
<p>Chemistry42 is Insilico Medicine's AI drug discovery platform that efficiently generates novel active molecules using 42 generative models 44 .In this experiment, we apply nach0 to one of the published case study setups available on demand at demo.chemistry42.com-Structure-BasedDesign of Janus Kinase 3 Inhibitors.In Chemistry42, we use 3LXK crystal structure, pharmacophore hypothesis, and a set of physicochemical properties to set up the search space for the generative models.All generative models search the chemical space to find the best possible structures.</p>
<p>Chemistry42 provides a set of filters ans reward modules.The 2D modules comprise of various tools including Medicinal Chemistry Filters (MCFs), Lipinski's Rule of Five (Ro5), and descriptors for Drug-likeness, Weighted atom-type portion, Drug-likeness and Novelty, the synthetic accessibility (SA) scores.Additionally, Chemistry42 use the Self-Organizing Maps (SOM) Classifier Module to navigate the generation of molecular structures towards a specific target class in the chemical space.The Structure Morphing module, another integral part of 2D modules, is utilized to tackle metabolic instability issues.</p>
<p>The 3D modules include the ConfGen Module, which is responsible for generating conformational ensembles for each molecular structure.Subsequently, these molecules are ranked based on their intrinsic rigidity using a flexibility assessment tool.The 3D similarity between the generated structures and a reference molecule is evaluated using the 3D-Descriptors Module.The Pharmacophore Module is then used to find any matches with the specified pharmacophore hypothesis.The Shape Similarity Module plays its part in evaluating the 3D shape similarity to a reference molecule.Lastly, the Pocket Module and the Pocket-Ligand Interaction (PLI) modules are used to assess how well the molecules fit the chosen binding site.</p>
<p>In this experiment, we replaced all 42 generative models with nach0 and generated a set of structures using a prompt "Generate a random druglike small inhibitor molecule for the Janus Kinase Table 2 Comparison between nach0 and Chemistry42 models on JAK3 inhibitors generation.nach0 can discover multiple molecules passing all constraints, even though it only uses implicit knowledge about the protein target.Discovery rate (percentage of good molecules from all generated molecules) indicates that our models acts better than random combinatorial generator when solving the problem.3 JAK3 that contains a classic kinase hinge binding motif".Note that nach0 does not have access to the specific crystal structure and other required properties, so the model generated molecules using solely its knowledge about JAK3.</p>
<p>Combinatorial generator nach0 Chemistry42</p>
<p>In Tab. 2, we compare generation results using a combinatorial generator 45 , Chemistry42 44 , and our model.In just 45 minutes (consisting of 15 minutes for generation and 30 minutes for scoring in Chemistry42), our model discovered 8 molecules satisfying all the 2D and 3D requirements; see Ivanenkov et al. 44 for more details on requirements.All these structures have a hinge binder and properly bind in the active site.While our model can discover multiple molecules satisfying all constraints, the discovered structures are currently worse than those found in 72 hour generations in Chemistry42, since nach0 does not yet learn from the reinforcement learning feedback during generation and because it does not have exact knowledge of the experiment setup.In future work, we will expand our model with reinforcement learning capabilities to improve generation quality.</p>
<p>Comparison of multi-task models</p>
<p>Table 3 compares nach0 base and large models with two existing NLP encoder-decoder models (general-domain FLAN 23 and domain-specific SciFive 46 ), and a multi-domain encoder-decoder model MolT5 20 .The table contains metrics for each task and model, with the results of the top-performing base model emphasized in bold.First, FLAN base and nach0 base exhibit similar results on NLP tasks on average, demonstrating superior performance on different tasks.With single-domain models for tasks such as NER or NLI, where molecule information is not required, traditional LMs may indeed provide the best results.However, when it comes to molecular tasks that involve molecular data, nach0 has distinct advantages over similar-scale models due to its specialized architecture and ability to effectively incorporate and process molecule-related information.In particular, nach0 benefits from training on diverse datasets and the proposed tokenization approach, outperforming baselines (including FLAN) with a significant gap in molecular tasks.For regression tasks, nach0 shows the best results on both RMSE and R2 scores.Moreover, in the molecular generation task, nach0 substantially surpasses FLAN by the FCD metric, which assesses the closeness of the generated molecules distribution to the ground truth.We added this explanation to the manuscript.Second, as expected, large nach0 performed best among all the models.In terms of base models, nach0 base achieved the best results on chemical and crossdomain tasks over existing models, confirming that pre-training on two types of data with different tokens can be effective.</p>
<p>Furthermore, we conducted zero-shot experiments involving nach0, FLAN, and SciFive (all base versions) in an information retrieval task.The objective was to detect whether an abstract is relevant to a given disease or gene query.The dataset used for these experiments, along with its specific details, can be found in Tutubalina et al. 47 .In these experiments, we employed the following prompt: "Given the following passage, answer the question: Is the following text related to the synonym?Passage: text".To evaluate the models' performance, we utilized precision (P), recall (R), and F-measure (F1).Our findings indicate that nach0 achieved an F1 score of 82.24% (with a recall of 96.32% and precision of 71.76%), while FLAN and SciFive achieved F1 scores of 82.24% and 77.20%, respectively.However, it is worth noting that the supervised BERT-based pipeline from Tutubalina et al. 47 achieved a higher F1 score of 88.81%.Based on these results, we can conclude that these models exhibit the ability to perform slightly different NLP tasks in a zero-shot setup.However, they still fall significantly behind supervised models in terms of performance.</p>
<p>Ablations</p>
<p>To examine the impact of cross-domain data on multi-task finetuning, we conducted training on mono-domain data.The results of four pre-trained checkpoints (SciFive, FLAN, MolT5, nach0) fine-tuned exclusively on NLP data are presented in Supplementary Information, Sec. 1.When considering average performance on the NLP group, nach0, SciFive, and FLAN exhibit similar results, MolT5 achieves lower scores compared to the other models.</p>
<p>Next, we investigate how chemical tasks groups combination effects on joint model performance in comparison with individ- The results of this ablation study can be found in Tab. 4 and show that nach0 benefits from combining chemical tasks groupmodel trained on the whole set of chemical data without NLP outperforms in total set of metrics models trained on distinct task groups.It is important to mention that despite the joint model showing worse metrics than the model trained only on molecular generation and cross-domain tasks, it works better since it does not overfit on training data-the novelty metric is more prevail here over all other molecule generation metrics.</p>
<p>Also, experiments show that the special chemical tokens and pre-training on both natural language and chemical data improve the model quality-nach0 outperforms MolT5 baseline or show equal metrics on each chemical task group.We miss some MolT5 metrics on molecule generation task since it produces non-valid SMILES sequences.</p>
<p>Comparison with ChatGPT</p>
<p>Recently, a comprehensive benchmark for biomedical text generation and mining problems with ChatGPT was conducted, revealing its poor performance on several biomedical NLP benchmark datasets 48,49 .Chen et al. 49 specifically evaluated ChatGPT on a BLURB benchmark 50 , which encompasses BC5-chem, BC5disease, NCBI-disease, BC2GM, JNLPBA, EMB-PICO, ChemProt, DDI, GAD, BIOSSES, HoC, PubMedQA, BioASQ.In particular, ChatGPT got an average BLURB score of 48.27 on NER, while fine-tuned BERT achieved 86.27.For more details on evaluation scores, please refer to Chen et al. 49 .In our evaluation setup, we focus on three specific datasets: EMB-PICO, MedMCQA-Open, and molecular description generation (Mol-Instructions).The inclusion of EMB-PICO dataset was driven by its practical importance.This dataset involves the task of identifying and extracting specific fragments of text related to the Population/Patient/Problem (P), Intervention (I), Comparator (C), and Outcome (O) elements from unstructured biomedical texts, such as research articles and clinical trial reports.It is worth noting that the clinical trial domain holds particular significance for inClinico, a transformer-based artificial intelligence software platform designed to predict the outcome of Phase II clinical trials 10 .The molecular generation task is relevant to the Chemistry42 platform 44 .</p>
<p>To evaluate the zero-shot performance, we had to limit the evaluation to a subset of 2000 samples from the test set for each of the three datasets, considering the computational constraints of ChatGPT.As well we utilized the GPT-3.5-turbomodel through the OpenAI API and multi-task nach0 base for evaluation purposes.In the case of the PICO dataset, ChatGPT achieved a wordlevel F1 score of 64.43%, comparable to the results obtained by fine-tuned nach0 base on this subset (F1 score of 67.60%).For MedMCQA-Open, ChatGPT achieved a BLEU2 score of 1.68%, while the fine-tuned nach0 base attained a BLEU2 score of 6.30%.In the molecular description generation task, ChatGPT achieved a BLEU2 score of 2.23%, whereas the fine-tuned nach0 base excelled with a BLEU2 score of 42.80%.Based on our preliminary findings, it is evident that utilizing ChatGPT directly leads to subpar performance compared to models trained specifically on the domain-specific dataset, how it was done in nach0.</p>
<p>Discussion</p>
<p>In this study, we pretrained and fine-tuned T5 models, which have an encoder-decoder architecture.Nevertheless, a broad range of model families, including T5, BERT-based BioMegatron 51 , decoder-only PaLM 52 and GPT 4 , exist.To determine the most suitable architecture for pre-training and fine-tuning on chemical-related data, it may be necessary to evaluate these alternatives.We suggest it as a potential topic for future research.</p>
<p>There have been several efforts to train large language models (LLMs) on biomedical corpora, particularly on PubMed.Notable examples include BioGPT (347M and 1.5B) 53 , PubMedGPT (2.7B) 54 , and Galactica (120B) 18 .Through our experiments with scaling from a base model (250M) to a large model (780M), we demonstrated the benefits of scale on several datasets.Based on our findings, we can conclude that scaling can further enhance the chemical capabilities of models, particularly in terms of generation and reasoning skills.</p>
<p>Limitations</p>
<p>Key LLM capabilities for chemistry</p>
<p>Although our LM was able to reach state-of-the-art performance on several chemistry-related benchmarks, our human evaluations clearly suggested that these models are not at the chemist expert level.In order to bridge this gap, several new LLM capabilities need to be researched and developed including (i) knowledge alignment between textual and chemical sources as well as domain-specific knowledge graphs; (ii) ability to perform chemical reasoning and provide explanations for their predictions; (iii) ability to learn from and adapt to feedback from human experts, (iv) ability to generate novel chemical reactions and materials.</p>
<p>Molecular representations</p>
<p>One limitation of our LM is its focus on string representations of molecules, specifically the SMILES notation.Although SMILES is a widely used notation for representing molecules, it provides only 2D information of the molecule, missing the 3D geometry and spatial arrangement of atoms and bonds in a molecule.This can result in inaccuracies in predicting molecular properties and interactions.To address these limitations, it would be beneficial to incorporate additional modalities of molecules, such as the molecular graphs in terms of 2D or 3D representations, in the training of the language model.Another significant drawback of the SMILES format is the absence of a one-to-one translation between molecules and SMILES strings.Typically, a molecule can have multiple SMILES representations that differ from each other due to factors such as the starting atom, molecular graph traversal, and kekulization.In practice, SMILES strings are often converted to a canonical form using an unambiguous algorithm.A molecular representation called SELFIES 55,56 was defined from scratch to be attractive as a sequential representation for molecules.All random SELFIES are valid molecular representations.SELFIES was extened to treat molecular groups as well 57 .As SELFIES have been repeatedly shown to have advantages over other representations in the context of generative models, exploring their use as the main representation for a language model is a future potential direction.</p>
<p>Prompt design</p>
<p>Our language model has a limitation in that it heavily relies on the quality and specificity of the prompts, as well as the potential for biases in both the training data and the prompts themselves.To enhance the performance of the model, incorporating domain-specific and information-rich prompts is essential.One potential approach to achieving this is by leveraging the knowledge of domain experts to design effective biomedical prompts.Yet, over-reliance on domain-specific prompts may lead to a lack of diversity in the model's responses, which can limit its usefulness.</p>
<p>Chemical diversity</p>
<p>Mol-Instructions includes cross-domain datasets that consist of compounds and their corresponding descriptions collected from PubChem.PubChem is a publicly available database administered by the National Center for Biotechnology Information (NCBI).It is important to note that the datasets primarily encompass current drugs and known chemical probes, representing only a fraction of the vast predicted chemical space.Furthermore, these datasets do not encompass testing on novel chemical diversity distinct from molecules documented in the literature.</p>
<p>Conclusion</p>
<p>Our study integrates a diverse range of one-domain and multidomain task types and biomolecular text instructions to address the landscape of chemical research on drug design, reaction prediction, and retrosynthesis and leverage the advancements in NLP and LLMs.EThe multi-domain training approach allows our model, nach0, to leverage a broader understanding of both chemical and linguistic knowledge.xtensive experiments and two case studies demonstrate that nach0's capabilities in translating between natural language and chemical language enable it to tackle tasks effectively.Considering the unique training methodology and the broader scope of tasks that our model can effectively handle, we believe our work presents a significant contribution to the field.</p>
<p>Based on our findings, we foresee several promising directions for future research.One direction could involve such as protein sequences, which would require adding special tokens into the model similar to SMILES.This task could be easily achieved with Group SELFIES.New modalities require collecting diverse tasks with natural language prompts for fine-tuning.A second direction involves extending NLP datasets and conducting zero-shot evaluations to assess the reasoning and generalization capabilities of nach0.Finally, exploring the fusion of information from textual sequences and relevant knowledge graphs as input in a self-supervised approach remains an area to be explored.</p>
<p>• nach0 Large is available via https://huggingface.co/ insilicomedicine/nach0_large;</p>
<p>• For pre-processing scripts, see https://github.com/insilicomedicine/nach0.</p>
<p>Supplementary</p>
<p>NLP Ablation</p>
<p>To examine the impact of cross-domain data on multi-task finetuning, we conducted training on mono-domain data.The results of four pre-trained checkpoints fine-tuned exclusively on NLP data are presented in Supplementary Information, Tab. 5. Several noteworthy observations can be made based on these findings.</p>
<p>Firstly, when considering average performance, nach0, SciFive, and FLAN exhibit similar results.However, each model demonstrates superior performance on different tasks.FLAN, being a general-domain model, outperforms others in textual entailment, binary QA, and sentence similarity.On the other hand, the domain-specific SciFive shows best results in NER, while nach0in relation extraction, classification, and multi-choice QA.</p>
<p>Secondly, MolT5 achieves lower scores compared to the other models.This can be related to the pre-training strategy, where molecules and natural language texts share the same tokens in the semantic space.In contrast, nach0 utilizes specialized tokenization for molecular data, which does not significantly impact overall performance on NLP tasks compared to SciFive and FLAN.</p>
<p>Chemistry: Tasks and Datasets</p>
<p>We've integrated several chemical domain tasks from widely-used benchmarks and datasets.It covers distribution match, molecular property prediction, reaction prediction and related problems.Where it's possible, we use the provided standard train/validation/test split procedures, otherwise, we employ the random data split.We choose this data preparation strategy to enable comparison with baseline models, however, we don't guarantee that one can't find chemical objects with similar structures in the different subsets. 45is a benchmarking platform that provides a large dataset and set of metrics to compare generative models on an unconditional molecular generation task.The dataset provided by MOSES contains almost 2 million samples filtered by MCF, PAINS, and additional rules.The metrics set estimates the quality of the generative model from several points of view: validity of generated structures, molecular distribution matching quality, and the ability of the model to produce novel, diverse molecules.</p>
<p>MOSES</p>
<p>MOSES dataset</p>
<p>Evaluation metric:</p>
<p>The MOSES benchmark provides established set metrics for assessing the ability of models to produce unique, diverse, valid molecules similar to ground-truth distribution.In our work, we adopt several metrics: uniqueness, validity, novelty, internal diversity, similarity to a nearestneighbor (SNN), fragment similarity, scaffold similarity and FCD 58 .We've generated 30000 new molecules to compute these metrics.</p>
<p>Example on molecular distribution matching:</p>
<p>input text with prompt: Generate random molecule from MOSES dataset.</p>
<p>output text: CC1C2CCC(C2)C1CN(CCO)C(=O)c1ccc(Cl)cc1.</p>
<p>Mol-Instructions</p>
<p>The recently published Mol-Instructions dataset 25 covers three significant modalities: molecule-oriented instructions, proteinoriented instructions, and biomolecular text instructions.In our study, we specifically focus on the first subset, which is the most relevant and contains chemical tasks.</p>
<p>Example on descriptor-guided molecule generation:</p>
<p>input text with prompt: Synthesize a molecule that matches the given characteristics: The molecule is the (R)-enantiomer of aceprometazine.It is an enantiomer of a (S)-aceprometazine.output text: The molecule is a manufactured chemical that is widely used for dry cleaning of fabrics and for metal-degreasing.It is also used to make other chemicals and is used in some consumer products.</p>
<p>Example on forward reaction prediction: input text with prompt:</p>
<p>With the provided reactants and reagents, propose a potential product:
CO.C<a href="C">Si</a>(C)C#Cc1ccc(C=O)cc1.ClCCl.O=C([O-])[O-].[K+].[K+].
output text: C#Cc1ccc(C=O)cc1.</p>
<p>Example on reagent prediction:</p>
<p>input text with prompt: Please propose potential reagents that might have been utilized in the provided chemical reaction:
COC(=O)c1c(F)cc(NC(=O)c2cc(C(C)C)c(C(C)C)s2)cc1F ≫ CC(C)c1c(C(C)C)sc(C(=O)Nc2cc(F)c(C(=O)O)c(F)c2)c1. output text: [Na+].</p>
<p>[OH-] Example on retrosynthesis:</p>
<p>input text with prompt: Provide a list of potential reactants that may have produced the given product.: Cc1ccc(-c2ccccc2N)cc1 output text: Cc1ccc(B(O)O)cc1.Nc1ccccc1I</p>
<p>Property Prediction</p>
<p>We adopt several binary classification and regression tasks from the MoleculeNet benchmark to assess the model's ability to predict molecular properties.Evaluation metric: Binary classification tasks include BBBP, HIV, and BACE datasets from MoleculeNet 26 and use balanced accuracy as the main metric.Regression tasks involve ESOL, Free-SOLV and Lipo datasets from MoleculeNet 26 , QM9 dataset from MolInstructions 25 and rely on the R2 metric.In our work, we utilized the code provided by the MoleculeNet benchmark to prepare data splits.</p>
<p>Example on the BBBP classification task:</p>
<p>input text with prompt: input text with prompt:
Can CN(C)[C@H]1[C@@H]2C[C@H]3C(=C(O)c4c(O)cccc4[C@@]3 (C)O)C(=O)[C@]Please evaluate the ability of S(=O)(=O)(CCCCC)C<a href="NC(=O)c1cccnc1">C@@H</a>C(=O) N<a href="[C@H](O)C[NH2+]Cc1cc(ccc1)CC">C@H</a>Cc1cc(F)cc(F)lipophilic is COc1cc(OC)c(cc1NC(=O)CCC(=O)O)S(=O) (=O)NCc2ccccc2N3CCCCC3?
output text: -0.720000</p>
<p>NLP: Tasks and Datasets 5.3.1 Named entity recognition</p>
<p>Named entity recognition (NER) is a fundamental aspect of natural language processing, involving the identification and classification of entities in a given text into predefined categories.In biomedical NER, the focus lies in extracting mentions of diseases, genes, chemicals, and other biologically relevant entity types.To conduct this study, we carefully selected five datasets:</p>
<p>• BC2GM 29 ;</p>
<p>• BC5CDR-Disease 27 ;</p>
<p>• BC5CDR-Chemical 27 ;</p>
<p>• JNLPBA 30 ;</p>
<p>• NCBI-Disease 28 .</p>
<p>BC2GM</p>
<p>The BC2GM dataset encompasses an extensive collection of over 20,000 sentences extracted from the MED-LINE database, spanning the years 1991 to 2003.Each document in this dataset is annotated with gene mention spans, amounting to a total of 24,583 mentions.</p>
<p>BC5CDR</p>
<p>The BioCreative V CDR dataset was specifically designed for named entity recognition tasks involving disease and chemical entity types.It contains 12,850 disease and 15,935 chemical mentions, drawn from 1,500 PubMed articles.</p>
<p>JNLPBA</p>
<p>The JNLPBA involves gene mention annotations across more than 2,000 PubMed abstracts.The creation of this dataset entailed a meticulous search on the MEDLINE database, using specific MeSH terms such as 'human', 'blood cells', and 'transcription factors'.In total, JNLPBA comprises 59,963 gene mention spans.</p>
<p>NCBI-Disease</p>
<p>The NCBI-disease corpus, developed by the National Center for Biotechnology Information (NCBI), constitutes a vast collection of 793 PubMed abstracts that have undergone meticulous annotation by domain experts.These annotations include disease names and their corresponding concept IDs, sourced from the Medical Subject Headings (MeSH) vocabulary 59 .</p>
<p>In order to train the neural network in a text-to-text format, we designed five prompts.Each prompt asks to highlight the spans corresponding to mentions of specific entity.In order to achieve this, we insert specific tokens before and after the mention of an entity in the text.Evaluation metric: the evaluation of the NER task's quality is performed using the entity level F-measure.</p>
<p>Example:</p>
<p>input text with prompt: Please find all instances of diseases in the given text.Each mention should be surrounded by "diso<em>" and "</em>diso": Identification of APC2, a homologue of the adenomatous polyposis coli tumor suppressor;</p>
<p>output text: Identification of APC2 , a homologue of the diso<em> adenomatous polyposis coli tumour </em>diso suppressor.</p>
<p>Question Answering</p>
<p>Question Answering (QA) is an important area of NLP research.The objective of QA is to develop intelligent systems that can understand and accurately answer questions posed in natural language.Within the biomedical domain, QA refers to the specific applications and models designed to address questions related to biomedical and healthcare information.It is required for model to understand and respond to questions pertaining to medical knowledge, clinical data, scientific literature, drug information, and other relevant biomedical topics.In this study, we conducted experiments on four biomedical QA datasets:</p>
<p>• BioASQ 40 ;</p>
<p>• PubMedQA 39 ;</p>
<p>• MedMCQA 60 ;</p>
<p>• MMLU 61 .</p>
<p>The first two datasets are employed to evaluate the neural network's ability to answer binary Yes/No questions, while the remaining two datasets are used in scenarios that involve multichoice and open question answering.</p>
<p>BioASQ and PubMedQA</p>
<p>BioASQ (Biomedical Question Answering) is a widely recognized dataset in the biomedical domain, specifically designed for evaluating question answering systems.Following the 50 we restrict the dataset to yes/no questions.We use the official train/dev/test split where each contains 670/75/140 questions respectively.</p>
<p>Similar to BioASQ, the PubMedQA dataset as well presents questions with limited number of answers.In contrast to the previous dataset, the answers to the questions in PubMedQA are selected from yes, no, or maybe.We use the original train/dev/test split with 450, 50, and 500 questions, respectively.</p>
<p>MedMCQA and MMLU</p>
<p>For multiple choice question answering, we employ the concatenation of the MedMCQA and MMLU datasets from 25 , resulting in a total of 12,398 multiplechoice questions.As 25 does not provide train/dev/test partitions, we randomly split the dataset into a ratio of 75: 25.To perform open question answering, we adopted a dataset introduced in 25 , which comprises 27,574 question-answer pairs.This dataset was curated from the MedMCQA dataset.</p>
<p>Evaluation metric: to evaluate the performance of yes/no and multiple-choice question-answering tasks, we utilized the accuracy metric.For open-ended question-answering tasks, we adopted the BLEU-2 metric as our evaluation criterion.Yes/No QA example:</p>
<p>input text with prompt: Given a passage: De novo DNA methylation in Arabidopsis thaliana is catalyzed by the methyltransferase DRM2, a homolog of the mammalian de novo methyltransferase DNMT3.Here we describe DNA methyltransferase genes from both Arabidopsis and maize that show a high level of sequence similarity to Dnmt3, suggesting that they encode plant de novo methyltransferases.Relative to all known eukaryotic methyltransferases, these plant proteins contain a novel arrangement of the motifs required for DNA methyltransferase catalytic activity.The N termini of these methyltransferases contain a series of ubiquitin-associated (UBA) domains.BLASTX searches and phylogenetic analysis suggested that five cDNAs belonged to four classes (Dnmt1, Dnmt2, CMT and Dnmt3) of DNA methyltransferase genes, answer the question: Are there any DNMT3 proteins present in plants?;</p>
<p>Relation Extraction</p>
<p>Relation extraction (RE) is a NLP task that involves identifying and classifying the relationships between entities mentioned in a text.In the biomedical domain, RE refers to the specific application of RE techniques and models to extract and classify relationships between biomedical entities mentioned in text.Biomedical RE focuses on identifying and categorizing the associations between various biomedical entities, including genes, proteins, diseases, drugs, and other molecular entities.For experiments, we use three corpora:</p>
<p>• ChemProt 34 ;</p>
<p>• DDI 35 ;</p>
<p>• GAD 36 .</p>
<p>ChemProt</p>
<p>The ChemProt dataset is a widely used benchmark for the task of chemical-protein RE.The dataset comprises PubMed abstracts that are annotated with chemical-protein interactions, where the chemicals typically represent drug compounds or small molecules, and the proteins denote specific biological targets or enzymes.Each annotated interaction is labeled with the corresponding chemical and protein mentions, along with the following types of relationship: upregulator, downregulator, antagonist, agonist, and substrate.The training set of the dataset contains 9,995 relation pairs, and the test set contains 5,744 relation pairs.</p>
<p>DDI</p>
<p>The DDI (Drug-Drug Interaction) corpus is a dataset designed for the purpose of identifying drug-drug interactions mentioned in biomedical texts.The corpus consists of annotated sentences or text passages that describe interactions between pairs of drugs.Each annotated interaction is labeled with the names of the drugs involved and the specific type of interaction.We employ the train/test split produced in 50 , where the training set contains 4,021 relation pairs and the test set contains 979 relation pairs.</p>
<p>GAD</p>
<p>The GAD dataset is a comprehensive collection of genetic association information that was semi-automatically compiled using the Genetic Association Archive.In our study, we utilize an existing preprocessed version of GAD and its corresponding train/test split, which was created by Lee et al. 17  In our experimental framework, we adopt a binary classification approach for relation extraction.Here, the positive class indicates the presence of the specified type of relationship between two entities.</p>
<p>Evaluation metric: to evaluate the quality of RE tasks we utilize the F-1 measure of positive class.</p>
<p>Example:</p>
<p>input text with prompt: does the Chlorprothixene and lithium are said to have mechanism type of interaction in the following passage:</p>
<p>Chlorprothixene may increase the plasma-level of concomitantly given lithium.In order to avoid lithium intoxication, lithium plasma levels should be monitored closely.If chlorprothixene is given concomitantly with opioids, the opioid dose should be reduced (by approx.50%), because chlorprothixene amplifies the therapeutic actions and side-effects of opioids massively.Avoid the concomitant use of chlorprothixene and tramadol (Ultram).Massive seizures may be encountered with this combination.Consider additive sedative effects and confusional states to emerge, if chlorprothixene is given with benzodiazepines or barbituates.Choose particular low doses of these drugs.Exert particular caution in combining chlorprothixene with other anticholinergic drugs (tricyclic antidepressants and antiparkinsonian agents): Particularly the elderly may develop delirium, high fever, severe obstipation, even ileus and glaucoma.</p>
<p>Textual Entailment</p>
<p>Textual entailment (TE) is a natural language processing task that involves determining the logical relationship between two pieces of text: a text fragment known as the "premise" and another text fragment known as the "hypothesis."The task is to decide whether the meaning of the hypothesis can be logically inferred or entailed from the meaning of the premise.For conducting our experiments, we utilize the following corpora:</p>
<p>• MedNLI 32 ;</p>
<p>• SciTail 33 ; 5.3.4.1 MedNLI MedNLI (Medical Natural Language Inference) is a specialized dataset designed to facilitate research in natural language inference within the medical and healthcare domain.It consists of pairs of sentences, where each pair comprises a premise and a hypothesis.The premise represents a clinical or biomedical context, while the hypothesis is a medical statement or claim that may or may not logically follow from the premise.Each sentence pair is annotated with one of three labels: "entailment," indicating that the hypothesis can be logically inferred from the premise; "contradiction," suggesting that the hypothesis contradicts the information in the premise; and "neutral," signifying that there is no logical relationship between the two sentences.The dataset comprises a total of 12,627 sentence pairs in the training set and 1,422 sentence pairs in the testing set.</p>
<p>SciTail</p>
<p>The SciTail dataset is similar to the MedNLI dataset was designed for the task of natural language inference.Except that it covers a broader scientific domain.The train part of the corpora contains 24900 sentence pairs and the test part of the corpora contains 2126.</p>
<p>Evaluation metric: to evaluate the quality of TE tasks we utilize the Accuracy score.</p>
<p>Example:</p>
<p>input text with prompt: Given that "At [<strong>Hospital 1456</strong>] Hospital the patient was experiencing 10 out of 10 chest pain and received nitropaste two inches, three sublingual nitroglycerins, morphine 4 mg intravenously, Lopressor 5 mg intravenously."Does it follow that " The patient is asymptomatic."yes or no? output text: No</p>
<p>Sentence similarity</p>
<p>Textual similarity tasks in the biomedical domain involve assessing the degree of semantic similarity or relatedness between pairs of biomedical texts.The goal of these tasks is to determine how closely two pieces of text, such as sentences or documents, are semantically or conceptually aligned.To conduct our experiments, we employ the BIOSSES dataset 37 .</p>
<p>BIOSSES</p>
<p>The BIOSSES (Biomedical Sentence Similarity Benchmark) dataset is a specialized dataset designed to evaluate sentence similarity models in the biomedical domain.It contains pairs of biomedical sentences that are carefully selected to represent different levels of semantic similarity.Each sentence pair is annotated with a similarity score that represents the degree of semantic relatedness between the two sentences.The scores are typically on a continuous scale, indicating how similar or dissimilar the sentences are in meaning.The dataset comprises a total of 80 sentence pairs in the training set and 20 sentence pairs in the testing set.Evaluation metric: to evaluate the quality of Textual Similarity tasks we utilize the Pearson corellation score.</p>
<p>Example:</p>
<p>input text with prompt: Please assess the similarity between these two sentences on a scale of 0.0 (lowest) to 4.0 (highest).First sentence: "It has recently been shown that Craf is essential for Kras G12D-induced NSCLC."Second sentence:"It has recently become evident that Craf is essential for the onset of Kras-driven non-small cell lung cancer."</p>
<p>output text: 4.0</p>
<p>Document Classification</p>
<p>In the biomedical domain, the document classification task involves categorizing entire documents, such as scientific articles, research papers, or clinical reports, into predefined categories or classes.The goal is to automatically assign each document to the most relevant category based on its content and subject matter.For our experimental purposes, we utilize the Hallmarks of Cancer dataset.</p>
<p>Hallmarks of Cancer</p>
<p>The Hallmarks of Cancer (HoC) dataset serves as a document classification task, centered around the concept of cancer hallmarks as established in the referenced work 38 .This corpus comprises PubMed abstracts, each labeled with binary annotations, denoting the presence of specific discussions related to individual cancer hallmarks.We utilize the train/test split from 50 which comprises 13917 sentences in train part and 3547 sentences in test part.Evaluation metric: to evaluate the quality of Document Classification tasks we utilize the F-1 score.</p>
<p>Example:</p>
<p>input text with prompt: Pick one category for the following text.The options are -activating invasion and metastasis, avoiding immune destruction, cellular energetics, enabling replicative immortality, evading growth suppressors, genomic instability and mutation, inducing angiogenesis, resisting cell death, none, sustaining proliferative signaling, tumor promoting inflammation.</p>
<p>Biopsy of a skin lesion showed lymphoproliferative infiltration of the dermis with a follicular and angiocentric growth pattern and regional epidermal necrosis.</p>
<p>output text: resisting cell death</p>
<p>PICO extraction</p>
<p>PICO extraction is an essential NLP task that aims to automatically identify and extract specific fragments of text pertaining to the Patient (P), Intervention (I), Comparator (C), and Outcome (O) elements from unstructured biomedical texts, such as research articles and clinical trial reports.Typically, Comparator labels are omitted from the annotations, as they conform to established clinical trial norms, with "placebo" as the passive control and "standard of care" as the active control.To conduct our study, we leveraged the EBM PICO 31 dataset for this purpose.</p>
<p>Notes and references</p>
<p>a</p>
<p>NVIDIA, 2788 San Tomas Expressway, Santa Clara, 95051, CA, US b Insilico Medicine Canada Inc., 3710-1250 René-Lévesque west, Montreal, Quebec, Canada c Insilico Medicine Hong Kong Ltd., Unit 310, 3/F, Building 8W, Phase 2, Hong Kong Science Park, Pak Shek Kok, New Territories, Hong Kong d Insilico Medicine AI Ltd., Level 6, Unit 08, Block A, IRENA HQ Building, Masdar City, Abu Dhabi, United Arab Emirates e University of Toronto, Lash Miller Building 80 St. George Street, Toronto, Ontario, Canada.Email: alan@aspuru.com† These authors contributed equally to this work.</p>
<p>Fig. 2
2
Fig. 2 Datasets used for training and evaluation.Colour represents the type of tasks.Yellow and blue datasets are single-domain, typically requiring regression/classification losses or generation in the target domain (natural language or SMILES strings).Gradients from yellow to blue represent cross-domain generation tasks that require natural language input and SMILES output, or vise versa.</p>
<p>Fig. 3 A
3
Fig. 3 A diagram of nach0 which is a text-to-text framework.The model takes text as input and is trained to generate the desired target text for each specific task.This unified approach enables us to utilize the same model architecture, loss function, hyperparameters, and other components across our diverse range of mono-domain (NLP, CHEM) and cross-domain (NLP↔CHEM) tasks.</p>
<p>Fig. 4
4
Fig. 4 Input request from a human (gray color) and nach0's response (blue color).</p>
<p>J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 | 7</p>
<p>output text: CC(=O)c1cc2c(cc1)Sc1ccccc1N2C<a href="C">C@@H</a>N(C)C.Example on molecular description generation: input text with prompt: What can you tell me about this molecule?: C(=C(Cl)Cl)(Cl)Cl.</p>
<p>2(O)C(=O)C(=C(/O)NCN5CCCC5)C1=O penetrate the BBB? output text: 1 Example on HIV classification task: input text: Is CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC) CC(CC)=[O+]2 an HIV inhibitor?output text: 0 Example on BACE classification task: J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 | 9</p>
<p>output text: Yes.Multi-choice QA example: input text with prompt: Which of the following is antifibrinolytic drug: What of the following is the right choice?(A) Tenecteplase (B) Heparin (C) Urokinase (D) Tranexaemic acid output text: The final answer is (D).Open ended QA example: input text with prompt: 1,25 dihydrocholecalciferol acts on?output text: Intranuclear receptors</p>
<p>. The training set of the dataset consists of 4,796 relation pairs, while the testing set includes 534 relation pairs.</p>
<p>output text: Yes J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 | 11</p>
<ol>
<li>3 . 7 . 1 EBM
371
PICO The EBM PICO dataset was specifically created to facilitate PICO extraction tasks.It employs token-level labeling, where each token is categorized into one of the PIO classes (Patient, Intervention, Outcome).The dataset comprises a total of 4,800 labeled abstracts for training purposes and 200 labeled abstracts for testing purposes.To conduct the PICO extraction task in a text-to-text format, we adopted the same prompt style as used for the Named Entity Recognition (NER) dataset.Evaluation metric: to evaluate the quality of PICO extraction tasks we utilize the word-level F-1 score.Example: input text with prompt: Please find all instances of Interventions in the given text.Each mention should be surrounded by "Intervention<em>" and "</em>Intervention": Study protocol : Rehabilitation including Social and Physical activity and Education in Children and Teenagers with Cancer ( RESPECT ) output text: Study protocol : Intervention<em> Rehabilitation including Social and Physical activity and Education </em>Intervention in Children and Teenagers with Cancer ( RESPECT ) .</li>
</ol>
<p>Table 1
1
25st of datasets used in our study.We note that ESOL, FreeSolv, Lipophilicity, BBBP, HIV, BACE are included in the MoleculeNet benchmark26; QM9, MoleculeNet and USPTO_500MT data are collected from Mol-Instructions25.
TaskDatasetLinkTrain/TestsplitBC5CDR-Chemical 27linkpredefinedBC5CDR-Disease 27linkpredefinedNERNCBI-disease 28linkpredefinedBC2GM 29linkpredefinedJNLPBA 30linkpredefinedPICOEBM PICO 31linkpredefinedTextual EntailmentMedNLI 32 SciTail 33link linkpredefined predefinedChemProt 34linkpredefinedRelation ExtractionDDI 35linkpredefinedGAD 36linkpredefinedSentence similarityBIOSSES 37linkpredefinedDocument Classifica-HoC 38linkpredefinedtionQuestion answeringPubMedQA 39linkpredefined(Yes/No)BioASQ 40linkpredefinedESOL 26FreeSolv 26Molecular property predictionLipophilicity 26 BBBP 26 HIV 26linkpredefinedBACE 26QM9 25linkrandomMoleculargenera-MOSES 12linkpredefinedtionForwardReactionPredictionMol-Instructions 25linkrandomReagent PredictionRetrosynthesisDescription-guided molecule designMol-Instructions 25linkrandomMolecular descrip-tion generation
with example instances are reported in Supplementary Information, Sec. 2.</p>
<ol>
<li>Our experimentation involves two model sizes: a base model consisting of 250 million parameters, characterized by 12 layers, a hidden state of 768 dimensions, a feed-forward hidden state of 3072 dimensions, and 12 attention heads; and a larger model with 780 million parameters, consisting of 24 layers, a hidden state of 1024 dimensions, a feed-forward hidden state of 4096 dimensions, and 16 attention heads.</li>
</ol>
<p>Table 3
3
Full results of nach0 on NLP, CHEM and cross-domain tasks in comparison with FLAN (250M parameters), SciFive (220M parameters), MolT5 (220M parameters).All models are trained in a multi-task fashion.Bold number is the highest score on each dataset and the underscore stands for the second best result over base models only.We mark the results of Nach0 Large with a green color to indicate improvements over Nach0 Base.
DatasetMetricMolT5SciFiveFLAN Basenach0 LargeBC5-chem77.82%91.02%88.03%90.96%92.78%BC5-disease71.62%82.24%78.29%81.67%85.51%NCBI-diseaseF-1↑74.96%84.22%81.37%84.30%85.82%BC2GM53.47%69.55%62.53%71.12%80.41%JNLPBA63.06%72.99%70.74%73.70%79.80%EBM PICOF1↑67.37%67.32%69.48%67.60%94.44%MedNLI SciTailAccuracy↑58.69% 56.54%70.29% 80.73%79.66% 90.68%73.40% 84.12%89.22% 93.87%ChemProt70.52%75.83%84.38%83.61%94.46%DDIF-1↑56.02%59.53%85.96%88.69%93.13%GAD52.10%64.53%66.93%75.47%78.24%BIOSSESPearson↑24.55%56.51%61.21%52.58%52.37%HoCF-1↑70.24%72.49%72.37%80.40%85.86%PubMedQA BioASQF-1↑49.12% 61.71%59.44% 80.29%62.80% 87.14%58.76% 79.43%74.21% 89.21%MedMCQA and MMLUAccuracy↑25.97%25.06%25.42%26.61%46.10%MedMCQA-OpenBLEU-2↑4.52%5.83%5.10%6.30%2.26%Reagent predictionAccuracy@top1↑ 1.10%3.80%4.00%6.30%13.08%RetrosynthesisAccuracy@top1↑ 15.00%31.00%31.00%53.00%56.26%Forward reaction predictionAccuracy@top1↑ 27.00%60.00%59.00%88.00%89.94%BACEBA↑0.580.650.650.740.71BBBPBA↑0.550.660.60.670.68HIVBA↑0.50.530.530.560.60HFER2↑ RMSE↓-0.36 1.10.51 0.40.55 0.370.77 0.190.78 0.19HOMO-LUMOR2↑ RMSE↓0.98 0.00080.99 0.00030.99 0.00031.00 0.00011.00 0.0001LOGDR2↑ RMSE↓-0.6 2.4-0.27 1.9-0.32 1.90.28 1.10.28 1.1LOGSR2↑ RMSE↓-0.49 1.40.31 0.630.001 0.910.48 0.480.48 0.48Valid↑98.30%95.79%97.63%99.86%99.93%Unique@10000↑ 99.93%99.94%99.95%99.92%99.97%FCD/Test↓0.52120.57780.52890.31060.3038SNN/Test↑0.57450.56880.57420.61180.6222MOSESFrag/Test↑0.99740.99670.99650.99851.00Scaf/Test↑0.87480.87370.88230.92050.9292IntDiv↑0.84600.84640.84620.84780.8585Filters↑98.89%98.67%98.68%99.54%99.67%Novelty↑93.92%93.98%93.67%87.60%93.87%Description-guided molecule designBLEU-2↑30.32%44.17%43.64%48.97%48.76%Molecular description generationBLEU-2↑35.61%39.56%38.58%43.91%41.73%
ual models trained on each separate chemical tasks group-on predictive tasks group, on reaction tasks group and molecular generation/cross-domain tasks group.We perform the same experiments with MolT5 model to elaborate on how pretraining data and special chemical tokens affect the quality of the model on chemical tasks.</p>
<p>Table 4
4
Performance of nach0 on chemical tasks groups in comparison with MolT5.We list the scores for each task (see Supplementary Information about datasets and metrics).Bold number is the best result on each dataset.All models are base models.
DatasetMetricAllnach0 Pred. React. Mol. Gen. AllMolT5 Pred. React. Mol. Gen.Prediction tasksBACEBA ↑0.740.67--0.580.52 --BBBPBA ↑0.670.62--0.550.57 --HIVBA ↑0.560.65 --0.50.51 --HFER2 ↑ RMSE ↓0.77 0.190.015 -0.81 ----0.36 1.1-0.74 -1.4 ---HOMO-LUMOR2 ↑ RMSE ↓1.0 1e-41.0 1e-5 ----0.98 7e-40.94 -2e-4 ---LOGDR2 ↑ RMSE ↓0.28 1.10.27 1.1-----0.6 2.4-2.9 5.7----LOGSR2 ↑ RMSE ↓0.48 0.480.32 0.62-----0.49 1.4-1.2 2.0----Reaction tasksReagent predictionAccuracy ↑0.063-0.14-0.011-0.13-RetrosynthesisAccuracy ↑0.53-0.39-0.15-0.39-Forward reaction predictionAccuracy ↑0.88-0.89-0.27-0.89-Molecular generation and cross-domain tasksValidity ↑99.86% --99.99%98.3%--0.0%Unique@10000 ↑ 99.92% --99.81%99.93% --N/AFCD/Test ↓0.3106 --0.24110.5212--N/ASNN/Test ↑0.6118 --0.65510.5745--N/AMolecule generationFrag/Test ↑0.9985 --0.99880.9974--N/AScaf/Test ↑0.9205 --0.94030.8748--N/AIntDiv ↑0.8478 --0.84930.846--N/AFilters ↑99.54% --99.95%98.89% --N/ANovelty ↑87.6%--64.34%93.92% --N/ADescription-guided molecule gen.BLEU-2 ↑48.97% --52.90%30.32% --30.78%Molecular description generationBLEU-2 ↑43.91% --46.22%35.61% --31.32%</p>
<p>Table 5
5
Performance of nach0 on NLP tasks in comparison with FLAN, SciFive, MolT5.We list the scores for each task (see Sec. 5.3 about datasets and metrics).All models are base models.
nach0FLAN-T5 SciFiveMolT5Named Entity Recognition80.63% 75.01%81.14% 56.48%BC5-chem91.14% 87.56%91.81% 64.28%BC5-disease81.72% 76.61%82.33% 61.56%NCBI-disease84.43% 79.46%85.33% 54.74%BC2GM72.44% 61.75%72.76% 45.87%JNLPBA73.42% 69.68%73.45% 55.93%PICO extraction67.10% 68.94%67.62% 66.39%EBM PICO67.10% 68.94%67.62% 66.39%Textual Entailment86.03% 87.53%86.96% 55.63%MedNLI81.28% 81.75%82.90% 55.67%SciTail90.77% 93.31%91.01% 55.58%Relation Extraction84.06% 73.84%73.22% 63.38%ChemProt89.40% 84.48%82.77% 75.98%DDI89.67% 72.85%66.08% 63.23%GAD73.11% 64.19%70.82% 50.93%Sentence similarity27.45% 32.78%1.17%14.95%BIOSSES27.45% 32.78%1.17%14.95%Document Classification83.83% 75.48%82.49% 70.99%HoC83.83% 75.48%82.49% 70.99%Question answering (Yes/No)63.87% 65.04%63.66% 51.6%PubMedQA51.32% 50.36%52.04% 47.20%BioASQ76.43% 79.71%75.29% 56.00%Question answering (Multi Choice) 27.71% 25.61%26.29% 25.54%MedMCQA and MMLU27.71% 25.61%26.29% 25.54%Question answering (Open)2.43%2.34%2.25%1.83%MedMCQA-Open2.43%2.34%2.25%1.83%
-15 J o u r n a l N a me , [ y e a r ] , [ v o l . ] ,
1-15 J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 J o u r n a l N a me , [ y e a r ] , [ v o l .] , 1-15 J o u r n a l N a me , [ y e a r ] , [ v o l .] ,Data availabilityAll datasets used in the study for pre-training and fine-tuning are publicly available.Code availabilityThe nach0 framework is available for research purposes:• nach0 Base is available via https://huggingface.co/ insilicomedicine/nach0_base;Author ContributionsThese authors contributed equally: Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov.ET, DP, AA, and AZ contributed to the conception and design of the work.ET, ZM, and MK contributed to the data acquisition and curation.ZM, MK, ML, AC, AB, and AJ contributed to the technical implementation with the NeMo framework, provided technical and infrastructure guidance.ET, ZM, and MK contributed to the evaluation framework used in the study.All authors contributed to the drafting and revising of the manuscript.Conflicts of interestThe authors declare no competing interests.This study is a collaboration of NVIDIA and Insilico Medicine employees.
J Devlin, M.-W Chang, K Lee, K Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinnesota20191Minneapolis</p>
<p>. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Journal of Machine Learning Research. 212020</p>
<p>M Lewis, Y Liu, N Goyal, M Ghazvininejad, A Mohamed, O Levy, V Stoyanov, L Zettlemoyer, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline2020</p>
<p>T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, Advances in Neural Information Processing Systems. 2020</p>
<p>. R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S Arx, M S Bernstein, J Bohg, A Bosselut, E Brunskill, arXiv:2108.072582021arXiv preprint</p>
<p>E Tutubalina, Z Miftahutdinov, V Muravlev, A Shneyderman, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP): Industry Track. the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP): Industry TrackAbu Dhabi, UAE2022</p>
<p>. Z Miftahutdinov, A Kadurin, R Kudrin, E Tutubalina, Bioinformatics. 372021</p>
<p>Z Miftahutdinov, A Kadurin, R Kudrin, E Tutubalina, 2021, 12656 LNCS. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics. </p>
<p>E Tutubalina, A Kadurin, Z Miftahutdinov, COLING 2020 -28th International Conference on Computational Linguistics, Proceedings of the Conference. 2020</p>
<p>. A Aliper, R Kudrin, D Polykovskiy, P Kamya, E Tutubalina, S Chen, F Ren, A Zhavoronkov, Clinical Pharmacology &amp; Therapeutics. 2023</p>
<p>. E Putin, A Asadulaev, Q Vanhaelen, Y Ivanenkov, A V Aladinskaya, A Aliper, A Zhavoronkov, Molecular pharmaceutics. 152018</p>
<p>. D Polykovskiy, A Zhebrak, D Vetrov, Y Ivanenkov, V Aladinskiy, P Mamoshina, M Bozdaganyan, A Aliper, A Zhavoronkov, A Kadurin, Molecular pharmaceutics. 152018</p>
<p>. R Shayakhmetov, M Kuznetsov, A Zhebrak, A Kadurin, S Nikolenko, A Aliper, D Polykovskiy, Frontiers in Pharmacology. 112692020</p>
<p>. A Aliper, S Plis, A Artemov, A Ulloa, P Mamoshina, A Zhavoronkov, Molecular pharmaceutics. 132016</p>
<p>M Kuznetsov, D Polykovskiy, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>. H Dowden, J Munro, Nature Reviews Drug Discovery. 182019</p>
<p>. J Lee, W Yoon, S Kim, D Kim, S Kim, C H So, J Kang, Bioinformatics. 362020</p>
<p>R Taylor, M Kardas, G Cucurull, T Scialom, A Hartshorn, E Saravia, A Poulton, V Kerkez, R Stojnic, Galactica: A Large Language Model for Science. 2022</p>
<p>A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L U Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. 2017</p>
<p>C Edwards, T Lai, K Ros, G Honke, K Cho, H Ji, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language Processing2022</p>
<p>. D Flam-Shepherd, K Zhu, A Aspuru-Guzik, Nature Communications. 1332932022</p>
<p>. D Flam-Shepherd, A Aspuru-Guzik, arXiv:2305.057082023arXiv preprint</p>
<p>. H W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:2210.114162022arXiv preprint</p>
<p>. O Kuchaiev, J Li, H Nguyen, O Hrinchuk, R Leary, B Ginsburg, S Kriman, S Beliaev, V Lavrukhin, J Cook, P Castonguay, M Popova, J Huang, J M Cohen, CoRR, 2019, abs/1909.09577, year</p>
<p>Y Fang, X Liang, N Zhang, K Liu, R Huang, Z Chen, X Fan, H Chen, The Twelfth International Conference on Learning Representations. 2024</p>
<p>. Z Wu, B Ramsundar, E N Feinberg, J Gomes, C Geniesse, A S Pappu, K Leswing, V Pande, Chemical science. 92018</p>
<p>. J Li, Y Sun, R J Johnson, D Sciaky, C.-H Wei, R Leaman, A P Davis, C J Mattingly, T C Wiegers, Z Lu, Database. 2016. 2016baw068. J o u r n a l N a me. y e a r</p>
<p>. R I Dogan, R Leaman, Z Lu, Journal of biomedical informatics. 472014</p>
<p>. L Smith, L K Tanabe, R J N Ando, C.-J Kuo, I.-F Chung, C.-N Hsu, Y.-S Lin, R Klinger, C M Friedrich, K Ganchev, Genome biology. 92008</p>
<p>N Collier, T Ohta, Y Tsuruoka, Y Tateisi, J.-D Kim, Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications. the International Joint Workshop on Natural Language Processing in Biomedicine and its ApplicationsGeneva, Switzerland2004</p>
<p>B Nye, J J Li, R Patel, Y Yang, I J Marshall, A Nenkova, B C Wallace, Proceedings of the conference. the conferenceAssociation for Computational Linguistics. Meeting2018197</p>
<p>C Shivade, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics2019</p>
<p>T Khot, A Sabharwal, P Clark, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2018</p>
<p>M Krallinger, O Rabal, S A Akhondi, M P Pérez, J Santamaría, G P Rodríguez, G Tsatsaronis, A Intxaurrondo, J A López, U , Proceedings of the sixth BioCreative challenge evaluation workshop. the sixth BioCreative challenge evaluation workshop2017</p>
<p>. M I Segura-Bedmar, P Martínez, T Declerck, Journal of biomedical informatics. 462013</p>
<p>. À Bravo, J Piñero, N Queralt-Rosinach, M Rautschka, L I Furlong, BMC bioinformatics. 162015</p>
<p>. G Sogancıoglu, H Öztürk, A Özgür, Bioinformatics. 332017</p>
<p>. D Hanahan, R A Weinberg, cell. 1002000</p>
<p>Q Jin, B Dhingra, Z Liu, W Cohen, X Lu, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingEMNLP-IJCNLP2019</p>
<p>A Nentidis, K Bougiatiotis, A Krithara, G Paliouras, Machine Learning and Knowledge Discovery in Databases: International Workshops of ECML PKDD 2019. Würzburg, GermanySeptember 16-20, 2019. 2020Proceedings, Part II</p>
<p>. D Weininger, Journal of Chemical Information and Computer Sciences. 281988</p>
<p>E Harper, S Majumdar, O Kuchaiev, L Jason, Y Zhang, E Bakhturina, V Noroozi, S Subramanian, K Nithin, H Jocelyn, F Jia, J Balam, X Yang, M Livne, Y Dong, S Naren, B Ginsburg, a toolkit for Conversational AI and Large Language Models. NeMo2019</p>
<p>D Narayanan, M Shoeybi, J Casper, P Legresley, M Patwary, V Korthikanti, D Vainbrand, P Kashinkunti, J Bernauer, B Catanzaro, A Phanishayee, M Zaharia, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisNew York, NY, USA2021</p>
<p>. Y A Ivanenkov, D Polykovskiy, D Bezrukov, B Zagribelnyy, V Aladinskiy, P Kamya, A Aliper, F Ren, A Zhavoronkov, Journal of Chemical Information and Modeling. 632023</p>
<p>. D Polykovskiy, A Zhebrak, B Sanchez-Lengeling, S Golovanov, O Tatanov, S Belyaev, R Kurbanov, A Artamonov, V Aladinskiy, M Veselov, Frontiers in pharmacology. 5656442020</p>
<p>. L N Phan, J T Anibal, H Tran, S Chanana, E Bahadroglu, A Peltekian, G Altan-Bonnet, arXiv:2106.035982021arXiv preprint</p>
<p>E Tutubalina, Z Miftahutdinov, V Muravlev, A Shneyderman, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track. the 2022 Conference on Empirical Methods in Natural Language Processing: Industry Track2022</p>
<p>. R Tang, X Han, X Jiang, X Hu, arXiv:2303.043602023arXiv preprint</p>
<p>. Q Chen, H Sun, H Liu, Y Jiang, T Ran, X Jin, X Xiao, Z Lin, H Chen, Z Niu, Bioinformatics. 2023, 39, btad557</p>
<p>. Y Gu, R Tinn, H Cheng, M Lucas, N Usuyama, X Liu, T Naumann, J Gao, H Poon, ACM Transactions on Computing for Healthcare. 32021</p>
<p>H.-C Shin, Y Zhang, E Bakhturina, R Puri, M Patwary, M Shoeybi, R Mani, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language Processing2020</p>
<p>. R Luo, L Sun, Y Xia, T Qin, S Zhang, H Poon, T.-Y Liu, Briefings in Bioinformatics. 4092022</p>
<p>. E E A Bolton, 2022Stanford University</p>
<p>. M Krenn, F Häse, A Nigam, P Friederich, A Aspuru-Guzik, Machine Learning: Science and Technology. 2020, 1, 045024</p>
<p>. M Krenn, Q Ai, S Barthel, N Carson, A Frei, N C Frey, P Friederich, T Gaudin, A A Gayle, K M Jablonka, R F Lameiro, D Lemm, A Lo, S M Moosavi, J M Nápoles-Duarte, A Nigam, R Pollice, K Rajan, U Schatzschneider, P Schwaller, M Skreta, B Smit, F Strieth-Kalthoff, C Sun, G Tom, G Falk Von Rudorff, A Wang, A D White, A Young, R Yu, A Aspuru-Guzik, 2022, 3, 100588Patterns</p>
<p>. A H Cheng, A Cai, S Miret, G Malkomes, M Phielipp, A Aspuru-Guzik, Digital Discovery. 22023</p>
<p>. K Preuer, P Renz, T Unterthiner, S Hochreiter, G Klambauer, Journal of Chemical Information and Modeling. 582018</p>
<p>. C E Lipscomb, Bulletin of the Medical Library Association. 882652000</p>
<p>A Pal, L K Umapathi, M Sankarasubbu, Conference on Health, Inference, and Learning. 2022</p>
<p>. D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, 20202009arXiv e-prints</p>            </div>
        </div>

    </div>
</body>
</html>