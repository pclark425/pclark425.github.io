<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8974 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8974</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8974</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-158.html">extraction-schema-158</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-0729515f62042d1274c131360c33a121df71c856</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/0729515f62042d1274c131360c33a121df71c856" target="_blank">Generation from Abstract Meaning Representation using Tree Transducers</a></p>
                <p><strong>Paper Venue:</strong> North American Chapter of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This paper addresses generating English from the Ab-stract Meaning Representation, consisting of re-entrant graphs whose nodes are concepts and edges are relations, and consists of generating an appropriate spanning tree for the AMR and applying tree-to-string transducers to generate English.</p>
                <p><strong>Paper Abstract:</strong> Language generation from purely semantic representations is a challenging task. This paper addresses generating English from the Ab-stract Meaning Representation (AMR), consisting of re-entrant graphs whose nodes are concepts and edges are relations. The new method is trained statistically from AMR-annotated English and consists of two major steps: (i) generating an appropriate spanning tree for the AMR, and (ii) applying tree-to-string transducers to generate English. The method relies on discriminative learning and an argument realization model to overcome data sparsity. Initial tests on held-out data show good promise despite the complexity of the task. The system is available open-source as part of JAMR at:</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8974.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8974.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TI representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transducer Input representation (TI representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-shaped textual encoding of an AMR graph node and its outgoing edges used as the input to a tree-to-string transducer; internal node is X plus a concept label and children are relation-labeled subtrees, with child edges lexicographically sorted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>TI representation (tree serialization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Convert an AMR graph (rooted directed acyclic graph) into a tree by removing re-entrancies, then represent each node n with label C and outgoing edges n -L_i-> n_i as the parenthesized form (X C (L1 T1) ... (Lm Tm)), where Ti are TI representations of children and relation labels are sorted lexicographically. This LISP-like textual serialization is used as the transducer input.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Abstract Meaning Representation (AMR) graphs — rooted, directed, acyclic graphs with possible re-entrancies</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Delete re-entrancies (edges that introduce re-use of variables), compute a spanning tree (see spanning tree method) and then recursively emit (X concept (REL child-tree) ...) with child relations sorted lexicographically to form a textual tree representation.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Surface realisation / natural language generation: generate English sentences from AMR graphs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Indirect: used within full system that attains BLEU 22.1 (test set single-reference) and 21.2 (MT09 four-reference). No isolated metric for TI representation alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Not directly compared to other graph-to-text encodings in the paper; argued as suitable input for tree-to-string transducers and compatible with grammar-extraction methods.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Explicitly organizes graph into a tree form compatible with tree transducers; clean, structured LISP-like format; deterministic representation given chosen spanning tree and sorted relation order; enables direct application of tree-to-string transduction methods.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Requires removing AMR re-entrancies (information loss); representation depends on the chosen spanning tree and edge ordering which can affect realizations; ambiguous when duplicate child edge labels exist (ordering ambiguity handled later in transducer rules).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When re-entrancies encode important surface phenomena (e.g., coreference), deleting them may remove cues needed for correct realization; poor spanning-tree choices can limit generation due to projective reordering constraints of the transducer.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8974.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Spanning tree heuristic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Breadth-First-Spanning-Tree with lexicographic child order</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple heuristic to convert AMR graphs with re-entrancies into trees by performing BFS and visiting child nodes in lexicographic order of relation labels (with inverse relations visited last), including traversed edges in the tree and omitting others.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>spanning-tree-based linearization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Compute a spanning tree G' of the AMR graph G by breadth-first search, visiting child nodes in lexicographic order of relation labels and marking inverse relations to be visited last. Edges traversed by BFS form the tree; non-traversed/re-entrant edges are deleted from the tree input.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs (rooted directed graphs with re-entrancies)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Breadth-first-search traversal from AMR root, include traversed edges in resulting spanning tree, delete relations that use variables (re-entrancies). Child nodes are visited in lexicographic order of their relation labels.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation (surface realisation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No isolated numeric metric for the spanning-tree choice; system-level BLEU reported with this spanning-tree heuristic: 22.1 (test), 21.2 (MT09). Authors note spanning-tree choice can have big effect on output.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Described as a simple baseline heuristic; no empirical comparison to alternative spanning-tree methods in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Simple deterministic procedure; easy to implement; produces a tree suitable for tree-to-string transducers.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Heuristic (not learned) and may be suboptimal; choice of spanning tree constrains allowable surface reorderings because transducer outputs are projective relative to tree.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Poor spanning-tree choices can lead to suboptimal or incorrect word order in generated sentences; edges deleted to remove re-entrancies may remove necessary information for correct realization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8974.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>1-xRLNs transducer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>One-state extended linear non-deleting tree-to-string transducer (1-xRLNs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formal tree-to-string transducer used to map TI tree representations to output strings; rules map input tree fragments with argument variables to output strings, allowing composition via derivations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Statistical syntax-directed translation with extended domain of locality.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>tree-to-string transduction (1-xRLNs)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Use a 1-xRLNs transducer (N, Σ, W, R) where left-hand sides are input trees over nonterminals and terminals, RHS are strings over words and variables, and φ maps variables to nonterminals; derivations recursively substitute subderivations into variables to produce output strings.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Trees derived from AMR graphs (TI representations)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Apply extracted weighted tree-to-string rules to the TI tree (derivation produced by transducer) to produce an output string; decoding finds highest-scoring derivation combining rule features and an external language model.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Natural language generation (AMR graph -> English sentence)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used in full system achieving BLEU 22.1 (test) and 21.2 (MT09). No separate metric for the transducer alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Related to grammar-based NLG and synchronous grammars; authors note strong similarity to state-of-the-art machine translation decoding frameworks and earlier tree transducer work (Graehl & Knight 2004, Huang et al. 2006). No direct empirical comparison to other decoder formalisms in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Formal, well-studied transduction model that supports hierarchical rules with variables; aligns well with tree-structured input and enables extraction of reusable rules; supports features over rules for discriminative scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>One-state limitation (no extra states) reduces ability to model long-range dependencies in output; transducer output is restricted to projective reorderings of tree leaves.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Cannot represent non-projective reorderings relative to the chosen tree; limited modeling power compared to multi-state transducers for some dependencies (authors note multiple states would be useful but are not used).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8974.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Basic rule extraction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Basic tree-to-string rule extraction via JAMR alignments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An alignment-driven algorithm that extracts basic tree-to-string transducer rules from AMR-sentence pairs using the JAMR aligner to align graph fragments to word spans, then punching out child spans to create rule RHS with argument slots.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A discriminative graph-based parser for the abstract meaning representation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>alignment-based rule extraction (fragment-to-span rules)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Use JAMR aligner to align non-overlapping AMR fragments (which are trees) to contiguous word spans; for each aligned fragment, build a TI LHS and create an RHS by taking the fragment's aligned span and replacing aligned child fragments with argument variables ordered by child-span positions.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR fragments (subtrees extracted from spanning-tree-converted AMR)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Run JAMR aligner to produce fragment-to-span alignments; compute node spans b(i), e(i) bottom-up; for each aligned fragment, produce a rule mapping the fragment (plus argument relation labels) to the word subsequence with child fragments replaced by X_i slots; only extract if child spans don't overlap.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation; source of corpus-derived transducer rules</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Contributes to full-system BLEU (22.1). Ablation: removing basic rules has little impact (Full - basic: 22.1 test), suggesting synthetic rules compensate; no isolated metric for basic rules alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Algorithm is similar to rule extraction from tree-string aligned parallel corpora (Galley et al., 2004). The paper does not present a direct quantitative comparison between extracted basic rules and other extraction strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Directly grounded in corpus alignments; yields lexicalized rules reflecting observed realizations; provides data to populate synthetic rule lookup tables.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Sparse coverage given limited training data; many observed fragments don't generalize without further processing (hence need for synthetic and abstract rules).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>If JAMR aligner fails or produces incorrect fragment alignments, rule extraction will be faulty; overlapping child spans prevent rule extraction for those fragments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8974.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synthetic rule model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Synthetic rule generation model (generalization of basic rules)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learned model that generalizes basic extracted rules to produce k-best synthetic tree-to-string rules per node by composing concept realizations and argument realizations drawn from lookup tables and scored by a linear model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>synthetic rule generalization (lookup-table + linear scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>For each TI LHS, produce RHS candidates by concatenating a concept realization and per-argument realizations (left/right lexical pieces) drawn from lex, left_lex, right_lex tables (populated from segmented basic rules). Score candidate RHSs with a linear model over features and produce K-best via brute-force over permutations and DP K-best semiring.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR nodes / TI representations (concepts with argument slots)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Populate lex/left_lex/right_lex from segmented basic rules; for a given LHS enumerate possible permutations of argument positions and possible concept/argument realizations, maximize a linear scoring objective (features include POS, distances, side L/R), use dynamic programming with K-best semiring to produce top-K synthetic RHSs; add resulting synthetic rules to transducer grammar.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation; addresses data sparsity by generalizing rules seen in training</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Crucial to performance: ablating synthetic rules reduces BLEU from 22.1 to 9.1 (test) and 21.2 to 7.8 (MT09), showing a ~13 BLEU absolute drop on test when synthetic rules removed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Compared implicitly via ablation to basic/abstract/handwritten rules: synthetic rules dominate performance; no comparison to external generalization methods (e.g., neural graph-to-sequence) in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Substantially improves coverage and performance by generalizing sparse basic rules; models argument realization explicitly; scored and ranked so only high-scoring candidates are used; implemented K-best search to limit combinatorial space.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Relies on lookup tables populated from basic rules and thus limited by what is extractable; model complexity requires feature design and training (AdaGrad perceptron); may still miss rare or novel realizations not present in training corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Without synthetic rules the system performs very poorly (large BLEU drop). Synthetic rules may still fail when lex/argument tables lack appropriate realizations or when permutation/ordering modeled is insufficient for a particular sentence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8974.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Abstract rules</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Part-of-speech-based abstract rule generalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A lightweight generalization that abstracts concept realizations to POS patterns and replaces the concept with a placeholder, allowing reuse of argument realization patterns across lexical items.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>POS-based abstract rules</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>From basic rules, build a POS abstract rule table keyed by (POS of concept-realization, child argument labels) mapping to RHS templates with the concept realization replaced by '*'; for a TI LHS and a candidate concept realization c, lookup the POS p and produce a rule by filling p's template with c.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR fragments / TI representations (concept + arguments)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Compute most common POS tag sequence for concept realization c, look up (POS, A1,...,Am) in the POS abstract rule table built from training data, recover RHS template and insert c at the concept position to produce an abstracted rule.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation; intended to generalize observed lexical patterns</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Ablation: removing abstract rules has little impact (Full - abstract: 22.0 test vs Full 22.1), indicating low marginal contribution when synthetic rules are present.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Abstract rules are a simpler generalization compared to synthetic rules; no direct external comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Simple to build and apply; captures common syntactic realizations that generalize across lexemes via POS abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Crude generalization (POS-level) may be insufficiently specific; low marginal benefit in presence of synthetic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When POS abstraction loses necessary lexical specificity leading to incorrect realizations; limited usefulness when synthetic rules already cover needed patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8974.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Handwritten rules</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Small set of manually authored pass-through and special-case rules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A small curated set of hand-authored rules handling dates, conjunctions, multi-sentence AMRs, have-org-role91, and pass-through rules by removing sense tags and quotes, included to cover cases not captured by automatic extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>handwritten special-case rules</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Manually constructed tree-to-string rules for specific phenomena (dates, conjunctions, multi-sentence handling, specific concepts) and pass-through rules that strip sense tags/quotes to output strings directly; included in grammar alongside extracted rules.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs and concepts requiring special handling</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Hard-coded rules inserted into transducer grammar; applied during decoding like extracted rules.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation; provide coverage for rare but important constructs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Ablation: removing handwritten rules slightly reduces BLEU (Full 22.1 -> Full - handwritten 21.9 on test; 21.2 -> 20.5 on MT09), showing modest but measurable impact.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Used as complements to learned rules; no external comparisons presented.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Provide reliable handling for known special cases absent or rare in training data; small but tangible BLEU gains.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Requires manual engineering; brittle and not scalable to all phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>If not comprehensive, remaining uncovered special cases still cause errors; overfitting to specific patterns might conflict with learned rules in rare cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8974.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8974.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Decoding + scoring (cdec)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discriminative decoding using cdec with language model + weighted rule features</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Decoding framework that finds the highest-scoring derivation of the TI tree under a linear model combining an external n-gram language model log-probability and per-rule feature weights; implemented using the cdec decoder and tuned with MERT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>feature-rich discriminative decoding (cdec)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Score(d; θ) = θ_LM * log p_LM(E(d)) + sum_{r in d} θ^T f(r), where f(r) are features per rule (e.g., rule type indicators, counts, synthetic score, word counts, stop-word counts, negation tokens). Use cdec to search derivation space of T and MERT to tune weights on development set.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>TI trees (from AMR)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Enumerate derivations of the TI input under the tree-to-string transducer and select the highest-scoring output string according to the linear model combining an external 5-gram LM and learned rule features; approximate search via cdec decoder.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-text generation; learning to rank candidate realizations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Full system BLEU: 22.1 (test), 21.2 (MT09). Feature ablations shown in Table 4; MERT used for weight tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Decoding approach is similar to state-of-the-art machine translation systems; no head-to-head comparison to neural decoders or alternative ranking approaches in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Combines global LM fluency with local rule features for robust scoring; leverages well-understood MT decoding infrastructure (cdec); feature-based approach affords interpretability and targeted ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Requires feature design and MERT tuning; decoding is approximate; relies on external LM trained on Gigaword which may mismatch domain.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Incorrect rule features or poor LM weights can lead to bad outputs; limited by derivation search quality and transducer grammar coverage — e.g., when synthetic rules absent performance collapses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generation from Abstract Meaning Representation using Tree Transducers', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Training tree transducers <em>(Rating: 2)</em></li>
                <li>Statistical syntax-directed translation with extended domain of locality. <em>(Rating: 2)</em></li>
                <li>What's in a translation rule? <em>(Rating: 2)</em></li>
                <li>A discriminative graph-based parser for the abstract meaning representation. <em>(Rating: 2)</em></li>
                <li>cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models. <em>(Rating: 2)</em></li>
                <li>Generation that exploits corpus-based statistical knowledge <em>(Rating: 1)</em></li>
                <li>Forest-based statistical sentence generation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8974",
    "paper_id": "paper-0729515f62042d1274c131360c33a121df71c856",
    "extraction_schema_id": "extraction-schema-158",
    "extracted_data": [
        {
            "name_short": "TI representation",
            "name_full": "Transducer Input representation (TI representation)",
            "brief_description": "A tree-shaped textual encoding of an AMR graph node and its outgoing edges used as the input to a tree-to-string transducer; internal node is X plus a concept label and children are relation-labeled subtrees, with child edges lexicographically sorted.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "TI representation (tree serialization)",
            "representation_description": "Convert an AMR graph (rooted directed acyclic graph) into a tree by removing re-entrancies, then represent each node n with label C and outgoing edges n -L_i-&gt; n_i as the parenthesized form (X C (L1 T1) ... (Lm Tm)), where Ti are TI representations of children and relation labels are sorted lexicographically. This LISP-like textual serialization is used as the transducer input.",
            "graph_type": "Abstract Meaning Representation (AMR) graphs — rooted, directed, acyclic graphs with possible re-entrancies",
            "conversion_method": "Delete re-entrancies (edges that introduce re-use of variables), compute a spanning tree (see spanning tree method) and then recursively emit (X concept (REL child-tree) ...) with child relations sorted lexicographically to form a textual tree representation.",
            "downstream_task": "Surface realisation / natural language generation: generate English sentences from AMR graphs",
            "performance_metrics": "Indirect: used within full system that attains BLEU 22.1 (test set single-reference) and 21.2 (MT09 four-reference). No isolated metric for TI representation alone.",
            "comparison_to_others": "Not directly compared to other graph-to-text encodings in the paper; argued as suitable input for tree-to-string transducers and compatible with grammar-extraction methods.",
            "advantages": "Explicitly organizes graph into a tree form compatible with tree transducers; clean, structured LISP-like format; deterministic representation given chosen spanning tree and sorted relation order; enables direct application of tree-to-string transduction methods.",
            "disadvantages": "Requires removing AMR re-entrancies (information loss); representation depends on the chosen spanning tree and edge ordering which can affect realizations; ambiguous when duplicate child edge labels exist (ordering ambiguity handled later in transducer rules).",
            "failure_cases": "When re-entrancies encode important surface phenomena (e.g., coreference), deleting them may remove cues needed for correct realization; poor spanning-tree choices can limit generation due to projective reordering constraints of the transducer.",
            "uuid": "e8974.0",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Spanning tree heuristic",
            "name_full": "Breadth-First-Spanning-Tree with lexicographic child order",
            "brief_description": "A simple heuristic to convert AMR graphs with re-entrancies into trees by performing BFS and visiting child nodes in lexicographic order of relation labels (with inverse relations visited last), including traversed edges in the tree and omitting others.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "spanning-tree-based linearization",
            "representation_description": "Compute a spanning tree G' of the AMR graph G by breadth-first search, visiting child nodes in lexicographic order of relation labels and marking inverse relations to be visited last. Edges traversed by BFS form the tree; non-traversed/re-entrant edges are deleted from the tree input.",
            "graph_type": "AMR graphs (rooted directed graphs with re-entrancies)",
            "conversion_method": "Breadth-first-search traversal from AMR root, include traversed edges in resulting spanning tree, delete relations that use variables (re-entrancies). Child nodes are visited in lexicographic order of their relation labels.",
            "downstream_task": "AMR-to-text generation (surface realisation)",
            "performance_metrics": "No isolated numeric metric for the spanning-tree choice; system-level BLEU reported with this spanning-tree heuristic: 22.1 (test), 21.2 (MT09). Authors note spanning-tree choice can have big effect on output.",
            "comparison_to_others": "Described as a simple baseline heuristic; no empirical comparison to alternative spanning-tree methods in this paper.",
            "advantages": "Simple deterministic procedure; easy to implement; produces a tree suitable for tree-to-string transducers.",
            "disadvantages": "Heuristic (not learned) and may be suboptimal; choice of spanning tree constrains allowable surface reorderings because transducer outputs are projective relative to tree.",
            "failure_cases": "Poor spanning-tree choices can lead to suboptimal or incorrect word order in generated sentences; edges deleted to remove re-entrancies may remove necessary information for correct realization.",
            "uuid": "e8974.1",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "1-xRLNs transducer",
            "name_full": "One-state extended linear non-deleting tree-to-string transducer (1-xRLNs)",
            "brief_description": "A formal tree-to-string transducer used to map TI tree representations to output strings; rules map input tree fragments with argument variables to output strings, allowing composition via derivations.",
            "citation_title": "Statistical syntax-directed translation with extended domain of locality.",
            "mention_or_use": "use",
            "representation_name": "tree-to-string transduction (1-xRLNs)",
            "representation_description": "Use a 1-xRLNs transducer (N, Σ, W, R) where left-hand sides are input trees over nonterminals and terminals, RHS are strings over words and variables, and φ maps variables to nonterminals; derivations recursively substitute subderivations into variables to produce output strings.",
            "graph_type": "Trees derived from AMR graphs (TI representations)",
            "conversion_method": "Apply extracted weighted tree-to-string rules to the TI tree (derivation produced by transducer) to produce an output string; decoding finds highest-scoring derivation combining rule features and an external language model.",
            "downstream_task": "Natural language generation (AMR graph -&gt; English sentence)",
            "performance_metrics": "Used in full system achieving BLEU 22.1 (test) and 21.2 (MT09). No separate metric for the transducer alone.",
            "comparison_to_others": "Related to grammar-based NLG and synchronous grammars; authors note strong similarity to state-of-the-art machine translation decoding frameworks and earlier tree transducer work (Graehl & Knight 2004, Huang et al. 2006). No direct empirical comparison to other decoder formalisms in this paper.",
            "advantages": "Formal, well-studied transduction model that supports hierarchical rules with variables; aligns well with tree-structured input and enables extraction of reusable rules; supports features over rules for discriminative scoring.",
            "disadvantages": "One-state limitation (no extra states) reduces ability to model long-range dependencies in output; transducer output is restricted to projective reorderings of tree leaves.",
            "failure_cases": "Cannot represent non-projective reorderings relative to the chosen tree; limited modeling power compared to multi-state transducers for some dependencies (authors note multiple states would be useful but are not used).",
            "uuid": "e8974.2",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Basic rule extraction",
            "name_full": "Basic tree-to-string rule extraction via JAMR alignments",
            "brief_description": "An alignment-driven algorithm that extracts basic tree-to-string transducer rules from AMR-sentence pairs using the JAMR aligner to align graph fragments to word spans, then punching out child spans to create rule RHS with argument slots.",
            "citation_title": "A discriminative graph-based parser for the abstract meaning representation.",
            "mention_or_use": "use",
            "representation_name": "alignment-based rule extraction (fragment-to-span rules)",
            "representation_description": "Use JAMR aligner to align non-overlapping AMR fragments (which are trees) to contiguous word spans; for each aligned fragment, build a TI LHS and create an RHS by taking the fragment's aligned span and replacing aligned child fragments with argument variables ordered by child-span positions.",
            "graph_type": "AMR fragments (subtrees extracted from spanning-tree-converted AMR)",
            "conversion_method": "Run JAMR aligner to produce fragment-to-span alignments; compute node spans b(i), e(i) bottom-up; for each aligned fragment, produce a rule mapping the fragment (plus argument relation labels) to the word subsequence with child fragments replaced by X_i slots; only extract if child spans don't overlap.",
            "downstream_task": "AMR-to-text generation; source of corpus-derived transducer rules",
            "performance_metrics": "Contributes to full-system BLEU (22.1). Ablation: removing basic rules has little impact (Full - basic: 22.1 test), suggesting synthetic rules compensate; no isolated metric for basic rules alone.",
            "comparison_to_others": "Algorithm is similar to rule extraction from tree-string aligned parallel corpora (Galley et al., 2004). The paper does not present a direct quantitative comparison between extracted basic rules and other extraction strategies.",
            "advantages": "Directly grounded in corpus alignments; yields lexicalized rules reflecting observed realizations; provides data to populate synthetic rule lookup tables.",
            "disadvantages": "Sparse coverage given limited training data; many observed fragments don't generalize without further processing (hence need for synthetic and abstract rules).",
            "failure_cases": "If JAMR aligner fails or produces incorrect fragment alignments, rule extraction will be faulty; overlapping child spans prevent rule extraction for those fragments.",
            "uuid": "e8974.3",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Synthetic rule model",
            "name_full": "Synthetic rule generation model (generalization of basic rules)",
            "brief_description": "A learned model that generalizes basic extracted rules to produce k-best synthetic tree-to-string rules per node by composing concept realizations and argument realizations drawn from lookup tables and scored by a linear model.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "synthetic rule generalization (lookup-table + linear scoring)",
            "representation_description": "For each TI LHS, produce RHS candidates by concatenating a concept realization and per-argument realizations (left/right lexical pieces) drawn from lex, left_lex, right_lex tables (populated from segmented basic rules). Score candidate RHSs with a linear model over features and produce K-best via brute-force over permutations and DP K-best semiring.",
            "graph_type": "AMR nodes / TI representations (concepts with argument slots)",
            "conversion_method": "Populate lex/left_lex/right_lex from segmented basic rules; for a given LHS enumerate possible permutations of argument positions and possible concept/argument realizations, maximize a linear scoring objective (features include POS, distances, side L/R), use dynamic programming with K-best semiring to produce top-K synthetic RHSs; add resulting synthetic rules to transducer grammar.",
            "downstream_task": "AMR-to-text generation; addresses data sparsity by generalizing rules seen in training",
            "performance_metrics": "Crucial to performance: ablating synthetic rules reduces BLEU from 22.1 to 9.1 (test) and 21.2 to 7.8 (MT09), showing a ~13 BLEU absolute drop on test when synthetic rules removed.",
            "comparison_to_others": "Compared implicitly via ablation to basic/abstract/handwritten rules: synthetic rules dominate performance; no comparison to external generalization methods (e.g., neural graph-to-sequence) in this paper.",
            "advantages": "Substantially improves coverage and performance by generalizing sparse basic rules; models argument realization explicitly; scored and ranked so only high-scoring candidates are used; implemented K-best search to limit combinatorial space.",
            "disadvantages": "Relies on lookup tables populated from basic rules and thus limited by what is extractable; model complexity requires feature design and training (AdaGrad perceptron); may still miss rare or novel realizations not present in training corpus.",
            "failure_cases": "Without synthetic rules the system performs very poorly (large BLEU drop). Synthetic rules may still fail when lex/argument tables lack appropriate realizations or when permutation/ordering modeled is insufficient for a particular sentence.",
            "uuid": "e8974.4",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Abstract rules",
            "name_full": "Part-of-speech-based abstract rule generalization",
            "brief_description": "A lightweight generalization that abstracts concept realizations to POS patterns and replaces the concept with a placeholder, allowing reuse of argument realization patterns across lexical items.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "POS-based abstract rules",
            "representation_description": "From basic rules, build a POS abstract rule table keyed by (POS of concept-realization, child argument labels) mapping to RHS templates with the concept realization replaced by '*'; for a TI LHS and a candidate concept realization c, lookup the POS p and produce a rule by filling p's template with c.",
            "graph_type": "AMR fragments / TI representations (concept + arguments)",
            "conversion_method": "Compute most common POS tag sequence for concept realization c, look up (POS, A1,...,Am) in the POS abstract rule table built from training data, recover RHS template and insert c at the concept position to produce an abstracted rule.",
            "downstream_task": "AMR-to-text generation; intended to generalize observed lexical patterns",
            "performance_metrics": "Ablation: removing abstract rules has little impact (Full - abstract: 22.0 test vs Full 22.1), indicating low marginal contribution when synthetic rules are present.",
            "comparison_to_others": "Abstract rules are a simpler generalization compared to synthetic rules; no direct external comparisons provided.",
            "advantages": "Simple to build and apply; captures common syntactic realizations that generalize across lexemes via POS abstraction.",
            "disadvantages": "Crude generalization (POS-level) may be insufficiently specific; low marginal benefit in presence of synthetic rules.",
            "failure_cases": "When POS abstraction loses necessary lexical specificity leading to incorrect realizations; limited usefulness when synthetic rules already cover needed patterns.",
            "uuid": "e8974.5",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Handwritten rules",
            "name_full": "Small set of manually authored pass-through and special-case rules",
            "brief_description": "A small curated set of hand-authored rules handling dates, conjunctions, multi-sentence AMRs, have-org-role91, and pass-through rules by removing sense tags and quotes, included to cover cases not captured by automatic extraction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "handwritten special-case rules",
            "representation_description": "Manually constructed tree-to-string rules for specific phenomena (dates, conjunctions, multi-sentence handling, specific concepts) and pass-through rules that strip sense tags/quotes to output strings directly; included in grammar alongside extracted rules.",
            "graph_type": "AMR graphs and concepts requiring special handling",
            "conversion_method": "Hard-coded rules inserted into transducer grammar; applied during decoding like extracted rules.",
            "downstream_task": "AMR-to-text generation; provide coverage for rare but important constructs",
            "performance_metrics": "Ablation: removing handwritten rules slightly reduces BLEU (Full 22.1 -&gt; Full - handwritten 21.9 on test; 21.2 -&gt; 20.5 on MT09), showing modest but measurable impact.",
            "comparison_to_others": "Used as complements to learned rules; no external comparisons presented.",
            "advantages": "Provide reliable handling for known special cases absent or rare in training data; small but tangible BLEU gains.",
            "disadvantages": "Requires manual engineering; brittle and not scalable to all phenomena.",
            "failure_cases": "If not comprehensive, remaining uncovered special cases still cause errors; overfitting to specific patterns might conflict with learned rules in rare cases.",
            "uuid": "e8974.6",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Decoding + scoring (cdec)",
            "name_full": "Discriminative decoding using cdec with language model + weighted rule features",
            "brief_description": "Decoding framework that finds the highest-scoring derivation of the TI tree under a linear model combining an external n-gram language model log-probability and per-rule feature weights; implemented using the cdec decoder and tuned with MERT.",
            "citation_title": "cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models.",
            "mention_or_use": "use",
            "representation_name": "feature-rich discriminative decoding (cdec)",
            "representation_description": "Score(d; θ) = θ_LM * log p_LM(E(d)) + sum_{r in d} θ^T f(r), where f(r) are features per rule (e.g., rule type indicators, counts, synthetic score, word counts, stop-word counts, negation tokens). Use cdec to search derivation space of T and MERT to tune weights on development set.",
            "graph_type": "TI trees (from AMR)",
            "conversion_method": "Enumerate derivations of the TI input under the tree-to-string transducer and select the highest-scoring output string according to the linear model combining an external 5-gram LM and learned rule features; approximate search via cdec decoder.",
            "downstream_task": "AMR-to-text generation; learning to rank candidate realizations",
            "performance_metrics": "Full system BLEU: 22.1 (test), 21.2 (MT09). Feature ablations shown in Table 4; MERT used for weight tuning.",
            "comparison_to_others": "Decoding approach is similar to state-of-the-art machine translation systems; no head-to-head comparison to neural decoders or alternative ranking approaches in this paper.",
            "advantages": "Combines global LM fluency with local rule features for robust scoring; leverages well-understood MT decoding infrastructure (cdec); feature-based approach affords interpretability and targeted ablations.",
            "disadvantages": "Requires feature design and MERT tuning; decoding is approximate; relies on external LM trained on Gigaword which may mismatch domain.",
            "failure_cases": "Incorrect rule features or poor LM weights can lead to bad outputs; limited by derivation search quality and transducer grammar coverage — e.g., when synthetic rules absent performance collapses.",
            "uuid": "e8974.7",
            "source_info": {
                "paper_title": "Generation from Abstract Meaning Representation using Tree Transducers",
                "publication_date_yy_mm": "2016-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Training tree transducers",
            "rating": 2
        },
        {
            "paper_title": "Statistical syntax-directed translation with extended domain of locality.",
            "rating": 2
        },
        {
            "paper_title": "What's in a translation rule?",
            "rating": 2
        },
        {
            "paper_title": "A discriminative graph-based parser for the abstract meaning representation.",
            "rating": 2
        },
        {
            "paper_title": "cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models.",
            "rating": 2
        },
        {
            "paper_title": "Generation that exploits corpus-based statistical knowledge",
            "rating": 1
        },
        {
            "paper_title": "Forest-based statistical sentence generation",
            "rating": 1
        }
    ],
    "cost": 0.014133999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Generation from Abstract Meaning Representation using Tree Transducers</h1>
<p>Jeffrey Flanigan ${ }^{\text {® }}$ Chris Dyer ${ }^{\text {® }}$ Noah A. Smith ${ }^{\text {® }}$ Jaime Carbonell ${ }^{\text {® }}$<br>${ }^{1}$ School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA<br>${ }^{\text {® }}$ Computer Science \&amp; Engineering, University of Washington, Seattle, WA, USA<br>{jflanigan,cdyer,jgc}@cs.cmu.edu, nasmith@cs.washington.edu</p>
<h4>Abstract</h4>
<p>Language generation from purely semantic representations is a challenging task. This paper addresses generating English from the Abstract Meaning Representation (AMR), consisting of re-entrant graphs whose nodes are concepts and edges are relations. The new method is trained statistically from AMRannotated English and consists of two major steps: (i) generating an appropriate spanning tree for the AMR, and (ii) applying tree-tostring transducers to generate English. The method relies on discriminative learning and an argument realization model to overcome data sparsity. Initial tests on held-out data show good promise despite the complexity of the task. The system is available open-source as part of JAMR at: http://github.com/jflanigan/jamr</p>
<h2>1 Introduction</h2>
<p>We consider natural language generation from the Abstract Meaning Representation (AMR; Banarescu et al., 2013). AMR encodes the meaning of a sentence as a rooted, directed, acyclic graph, where concepts are nodes, and edges are relationships among the concepts.</p>
<p>Because AMR models propositional meaning ${ }^{1}$ while abstracting away from surface syntactic realizations, and is designed with human annotation in mind, it suggests a separation of (i) engineering the application-specific propositions that need to be</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>communicated about from (ii) general-purpose realization details, modeled by a generator shareable across many applications. The latter is our focus here.</p>
<p>Because any AMR graph has numerous valid realizations, and leaves underspecified many important details-including tense, number, definiteness, whether a concept should be referred to nominally or verbally, and more-transforming an AMR graph into an English sentence is a nontrivial problem.</p>
<p>To our knowledge, our system is the first for generating English from AMR. The approach is a statistical natural language generation (NLG) system, trained discriminatively using sentences in the AMR bank (Banarescu et al., 2013). It first transforms the graph into a tree, then decodes into a string using a weighted tree-to-string transducer and a language model (Graehl and Knight, 2004). The decoder bears a strong similarity to state-of-the-art machine translation systems (Koehn et al., 2007; Dyer et al., 2010), but with a rule extraction approach tailored to the NLG problem.</p>
<h2>2 Overview</h2>
<p>Generation of English from AMR graphs is accomplished as follows: the input graph is converted to a tree, which is input into the weighted intersection of a tree-to-string transducer ( $\S 4$ ) with a language model. The output English sentence is the (approximately) highest-scoring sentence according to a feature-rich discriminatively trained linear model. After discussing notation (§3), we describe our approach in $\S 4$. The transducer's rules are extracted from the limited AMR corpus and learned general-</p>
<p>izations; they are of four types: basic rules ( $\S 5$ ), synthetic rules created using a specialized model (§6), abstract rules (§7), and a small number of handwritten rules (§8).</p>
<h2>3 Notation and Definitions</h2>
<p>AMR graphs are directed, weakly connected graphs with node labels from the set of concepts $L_{N}$ and edge labels from the set of relations $L_{E}$.</p>
<p>AMR graphs are transformed to eliminate cycles (details in $\S 4$ ); we refer to the resulting tree as a transducer input representation (TI representation). For a node $n$ with label $\mathcal{C}$ and outgoing edges $n \xrightarrow{L_{1}} n_{1}, \ldots, n \xrightarrow{L_{m}} n_{m}$ sorted lexicographically by $L_{i}$ (each an element of $L_{E}$ ), the TI representation of the tree rooted at $n$ is denoted: ${ }^{2}$</p>
<p>$$
\left(X \mathcal{C}\left(L_{1} T_{1}\right) \ldots\left(L_{m} T_{m}\right)\right)
$$</p>
<p>where each $T_{i}$ is the TI representation of the tree rooted at $n_{i}$. See Fig. 1 for an example. A LISP-like textual formatting of the TI representation in Fig. 1 is:</p>
<p>$$
\begin{aligned}
&amp; \text { ( } X \text { want-01 (ARGO }(X \text { boy }))(\text { ARG1 }(X \text { ride-01 } \
&amp; \quad(\text { ARG0 }(X \text { bicycle }(\bmod (X \text { red })))))))
\end{aligned}
$$</p>
<p>To ease notation, we use the function sort[] to lexicographically sort edge labels in a TI representation. Using this function, an equivalent way of representing the TI representation in Eq. 1, if the $L_{i}$ are unsorted, is:</p>
<p>$$
\left(\mathrm{X} \mathcal{C} \operatorname{sort}\left[\left(L_{1} T_{1}\right) \ldots\left(L_{m} T_{m}\right)\right]\right)
$$</p>
<p>The TI representation is converted into a word sequence using a tree-to-string transducer. The tree transducer formalism we use is one-state extended linear, non-deleting tree-to-string (1-xRLNs) transducers (Huang et al., 2006; Graehl and Knight, 2004). ${ }^{3}$</p>
<p>Definition 1. (From Huang et al., 2006.) A $\boldsymbol{1}$ $x$ RLNs transducer is a tuple $(N, \Sigma, W, \mathcal{R})$ where $N$</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>The boy wants to ride the red bicycle .
Figure 1: The generation pipeline. An AMR graph (top), with a deleted re-entrancy (dashed), is converted into a transducer input representation (TI representation, middle), which is transduced to a string using a tree-to-string transducer (bottom).
is the set of nonterminals (relation labels and $X$ ), $\Sigma$ is the input alphabet (concept labels), $W$ is the output alphabet (words), and $\mathcal{R}$ is the set of rules. $A$ rule in $\mathcal{R}$ is a tuple $(t, s, \phi)$ where:</p>
<ol>
<li>
<p>$t$ is the LHS tree, whose internal nodes are labeled by nonterminal symbols, and whose frontier nodes are labeled terminals from $\Sigma$ or variables from a set $\mathcal{X}=\left{X_{1}, X_{2}, \ldots\right}$</p>
</li>
<li>
<p>$s \in(\mathcal{X} \cup W)^{*}$ is the RHS string;</p>
</li>
<li>$\phi$ is a mapping from $\mathcal{X}$ to nonterminals $N$.</li>
</ol>
<p>A rule is a purely lexical rule if it has no variables.
As an example, the tree-to-string transducer rules which produce the output sentence from the TI representation in Fig. 1 are:</p>
<p>$$
\begin{gathered}
\left(X \text { want-01 }\left(\text { ARG0 } X_{1}\right)\left(\text { ARG1 } X_{2}\right)\right) \rightarrow \
\text { The } X_{1} \text { wants to } X_{2} . \
\left(X \text { ride-01 }\left(\text { ARG1 } X_{1}\right)\right) \rightarrow \text { ride the } X_{1} \
\left(X \text { bicycle }\left(\bmod X_{1}\right)\right) \rightarrow X_{1} \text { bicycle } \
(X \text { red }) \rightarrow \text { red } \
(X \text { boy }) \rightarrow \text { boy }
\end{gathered}
$$</p>
<p>Here, all $X_{i}$ are mapped by a trivial $\phi$ to the nonterminal $X$.</p>
<p>The output string of the transducer is the target projection of the derivation, defined as follows:
Definition 2. (From Huang et al., 2006.) A derivation $d$, its source and target projections, denoted $\mathcal{S}(d)$ and $\mathcal{E}(d)$ respectively, are recursively defined as follows:</p>
<ol>
<li>If $r=(t, s, \phi)$ is a purely lexical rule, then $d=r$ is a derivation, where $\mathcal{S}(d)=t$ and $\mathcal{E}(d)=s$</li>
<li>If $r=(t, s, \phi)$ is a rule, and $d_{i}$ is a (sub)derivation with the root symbol of its source projection maching the corresponding substition node in $r$, i.e., $\operatorname{root}\left(\mathcal{S}\left(d_{i}\right)\right)=\phi\left(x_{i}\right)$, then $d=r\left(d_{1}, \ldots, d_{m}\right)$ is also a derivation, where $\mathcal{S}(d)=\left[x_{i} \mapsto \mathcal{S}\left(d_{i}\right)\right] t$ and $\mathcal{E}(d)=\left[x_{i} \mapsto\right.$ $\left.\mathcal{E}\left(d_{i}\right)\right] s$.</li>
</ol>
<p>The notation $\left[x_{i} \mapsto y_{i}\right] t$ is shorthand for the result of substituting $y_{i}$ for each $x_{i}$ in $t$, where $x_{i}$ ranges over all variables in $t$.</p>
<p>The set of all derivations of a target string $e$ with a transducer $T$ is denoted</p>
<p>$$
\mathcal{D}(e, T)={d \mid \mathcal{E}(d)=e}
$$</p>
<p>where $d$ is a derivation in $T$.
We use a shorthand notation for the transducer rules that will be useful when discussing rule extraction and synthetic rules. Let $f_{i}$ be a TI representation. The TI representation has the form</p>
<p>$$
f_{i}=\left(X \mathcal{C}\left(L_{1} T_{1}\right) \ldots\left(L_{m} T_{m}\right)\right)
$$</p>
<p>where $L_{i} \in L_{E}$ and $T_{1}, \ldots, T_{m}$ are TI representations. ${ }^{4}$ Let $A_{1}, \ldots A_{n} \in L_{E}$. We use</p>
<p>$$
\left(f_{i}, A_{1}, \ldots, A_{n}\right) \rightarrow r
$$</p>
<p>as shorthand for the rule:</p>
<p>$$
\begin{gathered}
\left(X \mathcal{C} \operatorname{sort}\left[\left(L_{1} T_{1}\right) \ldots\left(L_{m} T_{m}\right)\right.\right. \
\left.\left.\left(A_{1} X_{1}\right) \ldots\left(A_{n} X_{n}\right)\right]\right) \rightarrow r
\end{gathered}
$$</p>
<p>Note $r$ must contain the variables $X_{1} \ldots X_{n}$. In (3) and (4), argument slots with relation labels $A_{i}$ have been added as children to the root node of the TI representation $f_{i}$.</p>
<p>For example, the shorthand for the transducer rules in (2) is:</p>
<p>$$
\begin{gathered}
((X \text { want-01 }), \text { ARG0, ARG1 }) \rightarrow \
\text { The } X_{1} \text { wants to } X_{2} . \
((X \text { ride-01 }), \text { ARG1 }) \rightarrow \text { ride the } X_{1} \
((X \text { bicycle }), \text { mod }) \rightarrow X_{1} \text { bicycle } \
((X \text { red })) \rightarrow \text { red }
\end{gathered}
$$</p>
<h2>4 Generation</h2>
<p>To generate a sentence $e$ from an input AMR graph $G$, a spanning tree $G^{\prime}$ of $G$ is computed, then transformed into a string using a tree-to-string transducer.</p>
<p>Spanning tree. The choice of the graph $G$ 's spanning tree $G^{\prime}$ could have a big effect on the output, since the transducer's output will always be a projective reordering of the tree's leaves. Our spanning tree results from a breadth-first-search traversal, visiting child nodes in lexicographic order of the relation label (inverse relations are visited last). The edges traversed are included in the tree. This simple heuristic is a baseline which can potentially be improved in future work.</p>
<p>Decoding. Let $T=(N, \Sigma, W, \mathcal{R})$ be a tree-tostring transducer. The output sentence is the highest scoring transduction of $G^{\prime}$ :</p>
<p>$$
e=\mathcal{E}\left(\underset{d \in \mathcal{D}\left(G^{\prime}, T\right)}{\arg \max } \operatorname{score}(d ; \boldsymbol{\theta})\right)
$$</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Eq. 6 is solved approximately using the cdec decoder for machine translation (Dyer et al., 2010). The score of the transduction is a linear function (with coefficients $\boldsymbol{\theta}$ ) of a vector of features including the output sequence's language model logprobability and features associated with the rules in the derivation (denoted $\mathbf{f}$; Table 1):</p>
<p>$$
\operatorname{score}(d ; \boldsymbol{\theta})=\theta_{L M} \log \left(p_{L M}(\mathcal{E}(d))\right)+\sum_{r \in d} \boldsymbol{\theta}^{\top} \mathbf{f}(r)
$$</p>
<p>The feature weights are trained on a development dataset using MERT (Och, 2003).</p>
<p>In the next four sections, we describe the rules extracted and generalized from the training corpus.</p>
<h2>5 Inducing Basic Rules</h2>
<p>The basic rules, denoted $\mathcal{R}<em 1="1">{B}$, are extracted from the training AMR data using an algorithm similar to extracting tree transucers from tree-string aligned parallel corpora (Galley et al., 2004). Informally, the rules are extracted from a sentence $\boldsymbol{w}=\left\langle w</em>\right\rangle$ with AMR graph $G$ as follows:}, \ldots, w_{n</p>
<ol>
<li>The AMR graph and the sentence are aligned; we use the JAMR aligner from Flanigan et al. (2014), which aligns non-overlapping subgraphs of the graph to spans of words. The subgraphs that JAMR aligns are called fragments. In JAMR's aligner, all fragments are trees.</li>
<li>$G$ is replaced by its spanning tree by deleting relations that use a variable in the AMR annotation.</li>
<li>In the spanning tree, for each node $i$, we keep track of the word indices $b(i)$ and $e(i)$ in the original sentence that trap all of $i$ 's descendants. (This is calculated using a simple bottom-up propagation from the leaves to the root.)</li>
<li>For each aligned fragment $i$, a rule is extracted by taking the subsequence $\left\langle w_{b(i)} \ldots w_{e(i)}\right\rangle$ and "punching out" the spans of the child nodes (and their descendants) and replacing them with argument slots.</li>
</ol>
<p>See Fig. 2 for examples.
More formally, assume the nodes in $G$ are numbered $1, \ldots, N$ and the fragments are numbered
$1, \ldots, F$. Let nodes $:{1, \ldots, F} \rightarrow 2^{{1, \ldots, N}}$ and root $:{1, \ldots, F} \rightarrow{1, \ldots, N}$ be functions that return the nodes in a fragment and the root of a fragment, respectively, and let children $:{1, \ldots, N} \rightarrow$ $2^{{1, \ldots, N}}$ return the child nodes of a node. We consider a node aligned if it belongs to an aligned fragment. Let the span of an aligned node $i$ be denoted by endpoints $a_{i}$ and $a_{i}^{\prime}$; for unaligned nodes, $a_{i}=\infty$ and $a_{i}^{\prime}=-\infty$ (depicted with superscripts in Fig. 2). The node alignments are propagated by defining $b(\cdot)$ and $e(\cdot)$ recursively, bottom up:</p>
<p>$$
\begin{aligned}
&amp; b(i)=\min \left(a_{j}, \min <em j="j">{j \in \operatorname{children}(i)} b(j)\right) \
&amp; e(i)=\max \left(a</em> e(j)\right)
\end{aligned}
$$}^{\prime}, \max _{j \in \operatorname{children}(i)</p>
<p>Also define functions $\tilde{b}$ and $\tilde{e}$, from fragment indices to integers, as:</p>
<p>$$
\begin{aligned}
&amp; \tilde{b}(i)=b(\operatorname{root}(i)) \
&amp; \tilde{e}(i)=e(\operatorname{root}(i))
\end{aligned}
$$</p>
<p>For fragment $i$, let $C_{i}=\operatorname{children}(\operatorname{root}(i))-$ $\operatorname{nodes}(i)$, which is the children of the fragment's root concept that are not included in the fragment. Let $f_{i}$ be the TI representation for fragment $i .{ }^{5}$ If $C_{i}$ is empty, then the rule extracted for fragment $i$ is:</p>
<p>$$
r_{i}:\left(f_{i}\right) \rightarrow w_{\tilde{b}(i): \tilde{e}(i)}
$$</p>
<p>Otherwise, let $m=\left|C_{i}\right|$, and denote the edge labels from $\operatorname{root}(i)$ to elements of $C_{i}$ as $A_{1}(i) \ldots A_{m}(i)$. For $j \in{1, \ldots, m}$, let $k_{j}$ select the elements $c_{k_{j}}$ of $C_{i}$ in ascending order of $b\left(k_{j}\right)$. Then the rule extracted for fragment $i$ is:</p>
<p>$$
\begin{gathered}
r_{i}:\left(f_{i}, A_{k_{1}}(i), \ldots A_{k_{m}}(i)\right) \rightarrow \
w_{\tilde{b}(i): \tilde{b}\left(k_{1}\right)} X_{1} w_{\tilde{e}\left(k_{1}\right): \tilde{b}\left(k_{2}\right)} X_{2} \ldots \
\ldots w_{\tilde{e}\left(k_{m-1}\right): \tilde{b}\left(k_{m}\right)} X_{m} w_{\tilde{e}\left(k_{m}\right): \tilde{e}(i)}
\end{gathered}
$$</p>
<p>A rule is only extracted if the fragment $i$ is aligned and the child spans do not overlap. Fig. 2 gives an example of a tree annotated with alignments, $b$ and $e$, and the extracted rules.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Rule</td>
<td style="text-align: left;">1 for every rule</td>
</tr>
<tr>
<td style="text-align: left;">Basic</td>
<td style="text-align: left;">1 for basic rules, else 0</td>
</tr>
<tr>
<td style="text-align: left;">Synthetic</td>
<td style="text-align: left;">1 for synthetic rules, else 0</td>
</tr>
<tr>
<td style="text-align: left;">Abstract</td>
<td style="text-align: left;">1 for abstract rules, else 0</td>
</tr>
<tr>
<td style="text-align: left;">Handwritten</td>
<td style="text-align: left;">1 for handwritten rules, else 0</td>
</tr>
<tr>
<td style="text-align: left;">Rule given concept</td>
<td style="text-align: left;">$\log$ (number of times rule extracted / number of times concept observed in training <br> data) (only for basic rules, 0 otherwise)</td>
</tr>
<tr>
<td style="text-align: left;">$\ldots$ without sense</td>
<td style="text-align: left;">same as above, but with sense tags for concepts removed</td>
</tr>
<tr>
<td style="text-align: left;">Synthetic score</td>
<td style="text-align: left;">model score for the synthetic rule (only for synthetic rules, 0 otherwise)</td>
</tr>
<tr>
<td style="text-align: left;">Word count</td>
<td style="text-align: left;">number of words in the rule</td>
</tr>
<tr>
<td style="text-align: left;">Stop word count</td>
<td style="text-align: left;">number of words not in a stop word list</td>
</tr>
<tr>
<td style="text-align: left;">Bad stop word</td>
<td style="text-align: left;">number of words in a list of meaning-changing stop words, such as "all, can, could, <br> only, so, too, until, very"</td>
</tr>
<tr>
<td style="text-align: left;">Negation word</td>
<td style="text-align: left;">number of words in "no, not, n't"</td>
</tr>
</tbody>
</table>
<p>Table 1: Rule features in the transducer. There is also an indicator feature for every handwritten rule.</p>
<h2>6 Modeling Synthetic Rules</h2>
<p>The synthetic rules, denoted $\mathcal{R}<em 1="1">{S}(G)$, are created to generalize the basic rules and overcome data sparseness resulting from our relatively small training dataset. Our synthetic rule model considers an AMR graph $G$ and generates a set of rules for each node in $G$. S synthetic rule's LHS is a TI representation $f$ with argument slots $A</em>$ (this is the same form as the LHS for basic rules). For each node in $G$, one or more LHS are created (we will discuss this further below), and for each LHS, a set of $k$-best synthetic rules are produced. The simplest case of a LHS is just a concept and argument slots corresponding to each of its children.} \ldots A_{m</p>
<p>For a given LHS, the synthetic rule model creates a RHS by concatenating together a string in $W^{<em>}$ (called a concept realization and corresponding to the concept fragment) with strings in $W^{</em>} \mathcal{X} W^{*}$ (called an argument realization and corresponding to the argument slots). See the top of Fig. 3 for a synthetic rule with concept and argument realizations highlighted.</p>
<p>Synthetic rules have the form:</p>
<p>$$
\begin{aligned}
&amp; r:\left(f, A_{1}, \ldots A_{m}\right) \rightarrow \
&amp; \mathbf{l}<em 1="1">{k</em>}} X_{k_{1}} \mathbf{r<em 1="1">{k</em>}} \ldots \mathbf{l<em c="c">{k</em>}} X_{k_{c}} \mathbf{r<em c="c">{k</em> \
&amp; \quad \mathbf{l}}} \mathbf{c<em c_1="c+1">{k</em>}} X_{k_{c+1}} \mathbf{r<em c_1="c+1">{k</em>}} \ldots \mathbf{l<em m="m">{k</em>}} X_{k_{m}} \mathbf{r<em m="m">{k</em>
\end{aligned}
$$}</p>
<p>where:</p>
<ul>
<li>$f$ is a TI representation.</li>
<li>Each $A_{i} \in L_{E}$.</li>
<li>$\left\langle k_{1}, \ldots, k_{m}\right\rangle$ is a permutation of $\langle 1, \ldots, m\rangle$</li>
<li>$\mathbf{c} \in W^{*}$ is the realization of TI representation $f$.</li>
<li>Each $\mathbf{l}<em i="i">{i}, \mathbf{r}</em>} \in W^{*}$ and $X_{i} \in \mathcal{X}$. Let $R_{i}=$ $\left\langle\mathbf{l<em i="i">{i}, \mathbf{r}</em>\right\rangle$ denote the realization of argument $i$.</li>
<li>$c \in[0, m]$ is the position of $\mathbf{c}$ among the realizations of the arguments.</li>
</ul>
<p>Let $\mathcal{F}$ be the space of all possible TI representations. Synthetic rules make use of three lookup tables (which are partial functions) to provide candidate realizations for concepts and arguments: a table for concept realizations lex : $\mathcal{F} \rightarrow 2^{W^{<em>}}$, a table for argument realizations when the argument is on the left left $<em E="E">{\text {lex }}: \mathcal{F} \times L</em> \rightarrow 2^{W^{</em>}}$, and a table for argument realizations when the argument is on the right right $<em E="E">{\text {lex }}: \mathcal{F} \times L</em>$. These tables are constructed during basic rule extraction, the details of which are discussed below .} \rightarrow 2^{W^{*}</p>
<p>Synthetic rules are selected using a linear model with features $\mathbf{g}$ and coefficients $\phi$, which scores each RHS for a given LHS. For LHS $=$ $\left(f, A_{1}, \ldots A_{m}\right)$, the RHS is specified completely by $\mathbf{c}, c, R_{1}, \ldots, R_{m}$ and a permutation $k_{1}, \ldots, k_{m}$. For each node in $G$, and for each TI representation $f$ in the domain of lex that matches the node, a LHS is created, and a set of $K$ synthetic rules is produced for each $\mathbf{c} \in \operatorname{lex}(f)$. The rules produced are the</p>
<p>${ }<em 1="1">{0}$ The ${ }</em>}$ ((boy) ${ <em 3="3">{2}$ wants ${ }</em>}$ to ${ <em 5="5">{4}$ (ride ${ }</em>}$ the ${ <em 7="7">{6}$ ((red) ${ }</em>$ bicycle))) 8
(a) Sentence annotated with indexes, and bracketed according to $b(i)$ and $e(i)$ from the graph in (b).
<img alt="img-1.jpeg" src="img-1.jpeg" />
(b) Tree annotated with $a_{i}, a_{i}^{\prime}$ (superscripts) and $b(i), e(i)$ (subscripts).
<img alt="img-2.jpeg" src="img-2.jpeg" />
(c) Extracted rules.</p>
<p>Figure 2: Example rule extraction from an AMRannotated sentence.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: Synthetic rule generation for the rule shown at top. In the rule RHS, the realization for ARG0 is blue, the realization for DEST is red, and the realization for ride-01 is black. For a fixed permutation of the concept and arguments, choosing the argument realizations can be seen as a sequence labeling problem (bottom). The highlighted sequence corresponds to the rule at top.</p>
<p>K-best solutions to:</p>
<p>$$
\begin{aligned}
&amp; \underset{c, k_{1} \ldots k_{m}, R_{1}, \ldots, R_{m}}{\arg \max }\left(\sum_{i=1}^{c} \boldsymbol{\psi}^{\top} \mathbf{g}\left(R_{k_{i}}, A_{k_{i}}, \mathbf{c}, i, c\right)\right. \
&amp; +\boldsymbol{\psi}^{\top} \mathbf{g}(\langle\epsilon, \epsilon\rangle, *, \mathbf{c}, c+1, c) \
&amp; \left.+\sum_{i=c+1}^{m} \boldsymbol{\psi}^{\top} \mathbf{g}\left(R_{k_{i}}, A_{k_{i}}, \mathbf{c}, i+1, c\right)\right)
\end{aligned}
$$</p>
<p>where the max is over $c \in 0 \ldots m, k_{1}, \ldots, k_{m}$ is any permutation of $1, \ldots, m$, and $R_{i} \in \operatorname{left}<em i="i">{l e x}\left(A</em>\right)$ for $i<c$ and $R_{i} \in \operatorname{right}_{l e x}\left(A_{i}\right)$ for $i>c . *$ is used to denote the concept position. $\epsilon$ is the empty string.</p>
<p>The best solution to Eq. 10 is found exactly by brute force search over concept position $c \in[0, m+$ $1]$ and the permutation $k_{1}, \ldots, k_{m}$. With fixed concept position and permutation, each $R_{i}$ for the $\arg \max$ is found independently. To obtain the exact $K$-best solutions, we use dynamic programming with a $K$-best semiring (Goodman, 1999) to keep track of the $K$ best sequences for each concept position and permutation, and take the best $K$ sequences over all values of $c$ and $k$.</p>
<p>The synthetic rule model's parameters are estimated using basic rules extracted from the training data. Basic rules are put into the form of Eq. 9 by</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Feature name</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">POS $+A_{i}+$ "dist"</td>
<td style="text-align: left;">$[c-i]$</td>
</tr>
<tr>
<td style="text-align: left;">POS $+A_{i}+$ side</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">POS $+A_{i}+$ side + "dist"</td>
<td style="text-align: left;">$[c-i]$</td>
</tr>
<tr>
<td style="text-align: left;">POS $+A_{i}+R_{i}+$ side</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{c}+A_{i}+$ "dist"</td>
<td style="text-align: left;">$[c-i]$</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{c}+A_{i}+$ side</td>
<td style="text-align: left;">1.0</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{c}+A_{i}+$ side + "dist"</td>
<td style="text-align: left;">$[c-i]$</td>
</tr>
<tr>
<td style="text-align: left;">$\mathbf{c}+\mathrm{POS}+A_{i}+$ side + "dist"</td>
<td style="text-align: left;">$[c-i]$</td>
</tr>
</tbody>
</table>
<p>Table 2: Synthetic rule model features. POS is the most common part-of-speech tag sequence for $\mathbf{c}$, "dist" is the string "dist", and side is "L" if $i&lt;c$, "R" otherwise. + denotes string concatenation.
segmenting the RHS into the form</p>
<p>$$
\mathbf{l}<em 1="1">{1} X</em>} \mathbf{r<em m="m">{1} \ldots \mathbf{c} \ldots \mathbf{l}</em>
$$} X_{m} \mathbf{r}_{m</p>
<p>by choosing $\mathbf{c}, \mathbf{l}<em i="i">{i}, \mathbf{r}</em>$ for $i \in{1, \ldots, m}$. An example segmentation is the rule RHS in Fig. 3.} \in W^{*</p>
<p>Segmenting the RHS of the basic rules into the form of Eq. 11 is done as follows: $\mathbf{c}$ is the aligned span for $f$. For the argument realizations, arguments to the left of $\mathbf{c}$ pick up words to their right, and arguments to the right pick up words to their left. Specifically, for $i<c$ ( $R_{i}$ to the left of $\mathbf{c}$ but not next to c), $\mathbf{l}_{i}$ is empty and $\mathbf{r}_{i}$ contains all words between $a_{i}$ and $a_{i+1}$. For $i=c\left(R_{i}\right.$ directly to the left of $\left.\mathbf{c}\right), \mathbf{l}_{i}$ is empty and $\mathbf{r}_{i}$ contains all words between $a_{c}$ and $\mathbf{c}$. For $i>c+1, \mathbf{l}<em i-1="i-1">{i}$ contains all words between $a</em>}$ and $a_{i}$, and for $i=c+1, \mathbf{l<em i="i">{i}$ contains all words between c and $a</em>$.</p>
<p>The tables for lex, left $<em _lex="{lex" _text="\text">{\text {lex }}$, and right $</em>}}$ are populated using the segmented basic rules. For each basic rule extracted from the training corpus and segmented according to the previous paragraph, $f \rightarrow \mathbf{c}$ is added to lex, and $A_{k_{i}} \rightarrow\left\langle\mathbf{l<em i="i">{i}, \mathbf{r}</em>$ is known during extraction in Eq. 8.}\right\rangle$ is added to left $t_{l e x}$ for $i \leq c$ and right $t_{l e x}$ for $i&gt;c$. The permutation $k_{i</p>
<p>The parameters $\psi$ are trained using AdaGrad (Duchi et al., 2011) with the perceptron loss function (Rosenblatt, 1957; Collins, 2002) for 10 iterations over the basic rules. The features $\mathbf{g}$ are listed in Table 2.</p>
<h2>7 Abstract Rules</h2>
<p>Like the synthetic rules, the abstract rules $\mathcal{R}_{A}(G)$ generalize the basic rules. However, abstract rules</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Split</th>
<th style="text-align: center;">Sentences</th>
<th style="text-align: center;">Tokens</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Train</td>
<td style="text-align: center;">10,000</td>
<td style="text-align: center;">210,000</td>
</tr>
<tr>
<td style="text-align: left;">Dev.</td>
<td style="text-align: center;">1,400</td>
<td style="text-align: center;">29,000</td>
</tr>
<tr>
<td style="text-align: left;">Test</td>
<td style="text-align: center;">1,400</td>
<td style="text-align: center;">30,000</td>
</tr>
<tr>
<td style="text-align: left;">MT09</td>
<td style="text-align: center;">204</td>
<td style="text-align: center;">5,000</td>
</tr>
</tbody>
</table>
<p>Table 3: Train/dev./test/MT09 split.
are much simpler generalizations which use part-of-speech (POS) tags to generalize. Abstract rules make use of a POS abstract rule table, which is a table listing every combination of the POS of the concept realization, the child arguments' labels, and rule RHS with the concept realization removed and replaced with $*$. This table is populated from the basic rules extracted from the training corpus. An example entry in the table is:</p>
<p>$$
\begin{gathered}
(\mathrm{VBD}, \mathrm{ARG} 0, \mathrm{DEST}) \rightarrow \
X_{1}\langle*\rangle \text { to the } X_{2}
\end{gathered}
$$</p>
<p>For the LHS $\left(f, A_{1}, \ldots A_{m}\right)$, an abstract rule is created for each member of $\mathbf{c} \in \operatorname{lex}(f)$ and the most common POS tag $p$ for $\mathbf{c}$ by looking up $p$, $A_{1}, \ldots A_{m}$ in the POS abstract rule table, finding the common RHS, and filling in the concept position with $\mathbf{c}$. The set of all such rules is returned.</p>
<h2>8 Handwritten Rules</h2>
<p>We have handwritten rules for dates, conjunctions, multiple sentences, and the concept have-org-role91. We also create pass-through rules for concepts by removing sense tags and quotes (for string literals).</p>
<h2>9 Experiments</h2>
<p>We evaluate on the AMR Annotation Release version 1.0 (LDC2014T12) dataset. We follow the recommended train/dev./test splits, except that we remove MT09 data (204 sentences) from the training data and use it as another test set. Statistics for this dataset and splits are given in Table 3. We use a 5gram language model trained with KenLM (Heafield et al., 2013) on Gigaword (LDC2011T07), and use 100-best synthetic rules.</p>
<p>We evaluate with the Bleu scoring metric (Papineni et al., 2002) (Table 4). We report single ref-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Rules</th>
<th style="text-align: right;">Test</th>
<th style="text-align: right;">MT09</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Full</td>
<td style="text-align: right;">22.1</td>
<td style="text-align: right;">21.2</td>
</tr>
<tr>
<td style="text-align: left;">Full - basic</td>
<td style="text-align: right;">22.1</td>
<td style="text-align: right;">20.9</td>
</tr>
<tr>
<td style="text-align: left;">Full - synthetic</td>
<td style="text-align: right;">9.1</td>
<td style="text-align: right;">7.8</td>
</tr>
<tr>
<td style="text-align: left;">Full - abstract</td>
<td style="text-align: right;">22.0</td>
<td style="text-align: right;">21.2</td>
</tr>
<tr>
<td style="text-align: left;">Full - handwritten</td>
<td style="text-align: right;">21.9</td>
<td style="text-align: right;">20.5</td>
</tr>
</tbody>
</table>
<p>Table 4: Uncased Bleu scores with various types of rules removed from the full system.
erence Bleu for the LCD2014T12 test set, and fourreference Bleu for the MT09 set. We report ablation experiments for different sources of rules. When ablating handwritten rules, we do not ablate passthrough rules.</p>
<p>The full system achieves 22.1 Bleu on the test set, and 21.2 on MT09. Removing the synthetic rules drops the results to 9.1 Bleu on test and 7.8 on MT09. Removing the basic and abstract rules has little impact on the results. This may be because the synthetic rule model already contains much of the information in the basic and abstract rules. Removing the handwritten rules has a slightly larger effect, demonstrating the value of handwritten rules in this statistical system.</p>
<h2>10 Related Work</h2>
<p>There is a large body of work for statistical and nonstatistical NLG from a variety of input representations. Statistical NLG systems have been built for input representations such as HPSG (Nakanishi et al., 2005), LFG (Cahill and Van Genabith, 2006; Hogan et al., 2007), and CCG (White et al., 2007), as well as surface and deep syntax (Belz et al., 2011). The deep syntax representations in Bohnet et al. (2010) and Belz et al. (2011) share similarities with AMR: the representations are graphs with re-entrancies, and have an concept inventory from PropBank (Palmer et al., 2005).</p>
<p>The Nitrogen and Halogen systems (Langkilde and Knight, 1998; Langkilde, 2000) used an input representation that was a precursor to the modern version of AMR, which was also called AMR, although it was not the same representation as Banarescu et al. (2013).</p>
<p>Techniques from statistical machine translation have been applied to the problem of NLG (Wong
and Mooney, 2006), and many grammar-based approaches can be formulated as weighted tree-tostring transducers. Jones et al. (2012) developed technology for generation and translation with synchronous hyperedge replacement (SHRG) grammars applied to the GeoQuery corpus (Wong and Mooney, 2006), which in principle could be applied to AMR generation.</p>
<h2>11 Conclusion</h2>
<p>We have presented a two-stage method for natural language generation from AMR, setting a baseline for future work. We have also demonstrated the importance of modeling argument realization for good performance. Our feature-based, tree-transducer approach can be easily extended with rules and features from other sources, allowing future improvements.</p>
<h2>Acknowledgments</h2>
<p>The authors would like to thank Adam Lopez and Nathan Schneider for valuable feedback, and Sam Thomson and the attendees of the Fred Jelinek Memorial Workshop in 2014 in Prague for helpful discussions. This work is supported by the U.S. Army Research Office under grant number W911NF-10-1-0533. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the U.S. Army Research Office or the United States Government.</p>
<h2>References</h2>
<p>Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract meaning representation for sembanking. In Proc. of the 7th Linguistic Annotation Workshop and Interoperability with Discourse.
Anja Belz, Michael White, Dominic Espinosa, Eric Kow, Deirdre Hogan, and Amanda Stent. 2011. The first surface realisation shared task: Overview and evaluation results. In Proc. of the 13th European Workshop on Natural Language Generation.
Bernd Bohnet, Leo Wanner, Simon Mille, and Alicia Burga. 2010. Broad coverage multilingual deep sentence generation with a stochastic multi-level realizer. In Proc. of COLING.</p>
<p>Aoife Cahill and Josef Van Genabith. 2006. Robust pcfgbased generation using automatically acquired LFG approximations. In Proc. of COLING-ACL.
Michael Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proc. of EMNLP.
John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. $J M L R, 12$.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models. In Proc. of ACL.
Jeffrey Flanigan, Sam Thomson, Jaime Carbonell, Chris Dyer, and Noah A. Smith. 2014. A discriminative graph-based parser for the abstract meaning representation. In Proc. of ACL.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What's in a translation rule? In Proc. of HLT-NAACL.
Joshua Goodman. 1999. Semiring parsing. CL, 25(4).
Jonathan Graehl and Kevin Knight. 2004. Training tree transducers. In Proc. of HLT-NAACL.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable modified KneserNey language model estimation. In Proc. of ACL.
Deirdre Hogan, Conor Cafferkey, Aoife Cahill, and Josef Van Genabith. 2007. Exploiting multi-word units in history-based probabilistic generation. In Proc. of ACL.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proc. of AMTA.
Bevan Jones, Jacob Andreas, Daniel Bauer, Karl Moritz Hermann, and Kevin Knight. 2012. Semanticsbased machine translation with hyperedge replacement grammars. In Proc. of COLING.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. of ACL.
Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proc. of COLING-ACL.
Irene Langkilde. 2000. Forest-based statistical sentence generation. In Proc. of NAACL 2000.
Hiroko Nakanishi, Yusuke Miyao, and Jun'ichi Tsujii. 2005. Probabilistic models for disambiguation of an HPSG-based chart generator. In Proc. of IWPT.
Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of ACL.</p>
<p>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. $C L, 31(1)$.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proc. of ACL.
Frank Rosenblatt. 1957. The perceptron-a perceiving and recognizing automaton. Technical Report 85-4601, Cornell Aeronautical Laboratory.
Michael White, Rajakrishnan Rajkumar, and Scott Martin. 2007. Towards broad coverage surface realization with CCG. In Proc. of the Workshop on Using Corpora for NLG: Language Generation and Machine Translation.
Yuk Wah Wong and Raymond J Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proc. of HLT-NAACL.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ I.e., the nodes in fragment $i$, with the edges between them, represented as a TI representation.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>