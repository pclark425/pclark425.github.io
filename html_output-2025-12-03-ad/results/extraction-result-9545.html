<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9545 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9545</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9545</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-272987156</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.19508v1.pdf" target="_blank">Transforming Scholarly Landscapes: Influence of Large Language Models on Academic Fields beyond Computer Science</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have ushered in a transformative era in Natural Language Processing (NLP), reshaping research and extending NLP's influence to other fields of study. However, there is little to no work examining the degree to which LLMs influence other research fields. This work empirically and systematically examines the influence and use of LLMs in fields beyond NLP. We curate $106$ LLMs and analyze $\sim$$148k$ papers citing LLMs to quantify their influence and reveal trends in their usage patterns. Our analysis reveals not only the increasing prevalence of LLMs in non-CS fields but also the disparities in their usage, with some fields utilizing them more frequently than others since 2018, notably Linguistics and Engineering together accounting for $\sim$$45\%$ of LLM citations. Our findings further indicate that most of these fields predominantly employ task-agnostic LLMs, proficient in zero or few-shot learning without requiring further fine-tuning, to address their domain-specific problems. This study sheds light on the cross-disciplinary impact of NLP through LLMs, providing a better understanding of the opportunities and challenges.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9545",
    "paper_id": "paper-272987156",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0038864999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Transforming Scholarly Landscapes: Influence of Large Language Models on Academic Fields beyond Computer Science
29 Sep 2024</p>
<p>Aniket Pramanick 
Department of Computer Science and Hessian Center for AI (hessian.AI)
Ubiquitous Knowledge Processing Lab (UKP Lab</p>
<p>Yufang Hou 
IBM Research Europe
Ireland</p>
<p>Saif M Mohammad 
National Research Council
Canada</p>
<p>Iryna Gurevych 
Department of Computer Science and Hessian Center for AI (hessian.AI)
Ubiquitous Knowledge Processing Lab (UKP Lab</p>
<p>Santo Fortunato 
Carl T Bergstrom 
Katy Börner 
James A Evans 
Dirk Helbing 
Staša Milojević 
Alexander M Petersen 
Filippo Radicchi 
Roberta Sinatra 
Deep Ganguli 
Liane Lovitt 
Jackson Kernion 
Amanda Askell 
Yuntao Bai 
Saurav Kadavath 
Ben Mann 
Ethan Perez 
Nicholas Schiefer 
Kamal Ndousse 
Jan Philip Wahle 
Terry Ruas 
Mohamed Abdalla 
Bela Gipp 
Jason Wei 
Maarten Bosma 
Vincent Y Zhao 
Kelvin Guu 
Adams Wei Yu 
Brian Lester 
Nan Du 
An- Drew M Dai 
Quoc V Le 
Finetuned Lan- 
Wayne Xin Zhao 
Kun Zhou 
Junyi Li 
Tianyi Tang 
Xiaolei Wang 
Yupeng Hou 
Yingqian Min 
Beichen </p>
<p>Adrian de Wynter
Alex SokolovXun Wang, Qilong Gu</p>
<p>Transforming Scholarly Landscapes: Influence of Large Language Models on Academic Fields beyond Computer Science
29 Sep 20243622DB8BB6503C9069043C5A337B9C7BarXiv:2409.19508v1[cs.CL]
Large Language Models (LLMs) have ushered in a transformative era in Natural Language Processing (NLP), reshaping research and extending NLP's influence to other fields of study.However, there is little to no work examining the degree to which LLMs influence other research fields.This work empirically and systematically examines the influence and use of LLMs in fields beyond NLP.We curate 106 LLMs and analyze ∼148k papers citing LLMs to quantify their influence and reveal trends in their usage patterns.Our analysis reveals not only the increasing prevalence of LLMs in non-CS fields but also the disparities in their usage, with some fields utilizing them more frequently than others since 2018, notably Linguistics and Engineering together accounting for ∼45% of LLM citations.Our findings further indicate that most of these fields predominantly employ task-agnostic LLMs, proficient in zero or few-shot learning without requiring further fine-tuning, to address their domainspecific problems.This study sheds light on the cross-disciplinary impact of NLP through LLMs, providing a better understanding of the opportunities and challenges. 1</p>
<p>Introduction</p>
<p>"What you do makes a difference, and you have to decide what kind of difference you want to make."</p>
<p>-Jane Goodall</p>
<p>Modern science heavily relies on citing past research to build upon past ideas, situate the proposed work, reject old hypotheses, etc., thereby facilitating the dissemination of good ideas (Jurgens et al., 2018).Some ideas are limited in the scope of their influence (being cited narrowly within a specific subfield).At the same time, others may be broadly applicable and influence not just a whole field of study (such as Computer Science or CS) but 1 code and data available at https://github.com/UKPLab/arxiv-2024-llm-trends also many outside fields.Since the number of published papers is too large for manual review (Fortunato et al., 2018;Bornmann et al., 2021), there is growing work in automatically and quantitatively tracking the influence of ideas within and across fields (Wahle et al., 2023a(Wahle et al., , 2024)).</p>
<p>Arguably, one of the most transformative ideas over the past decade is that of LLMs (Li et al., 2023).Originally proposed within NLP, LLMs have revolutionized almost all research areas within NLP itself (Radford et al., 2019;Henderson et al., 2023).Moreover, their utilization is not confined to NLP; other fields are leveraging LLMs as well (Wang et al., 2022(Wang et al., , 2023)).While it is well recognized that these models are being adopted outside of NLP, the full extent and nature of their usage remains unclear.Analyzing the widespread adoption and utilization of LLMs across various fields provides essential insights for promoting responsible AI practices.Although recent studies have begun to explore the influence of LLMs within CS (Movva et al., 2023;Zhu and Rzeszotarski, 2024), their impact on other disciplines beyond CS is still largely unknown.While it is evident that non-CS fields are paying attention to LLMs (Zhao et al., 2023), precise details about which fields are leveraging them and the specific purposes of their use are still to be understood.</p>
<p>The modes of influence are multifaceted and intricate in nature, which makes it challenging to empirically determine the degree of influence.In this work, we focus on a specific dimension of influence: the scientific impact that one field has on another (Singh et al., 2023).One notable marker of this inter-field influence is citation (Zhu et al., 2015).Therefore, we propose that the degree to which a source field cites the works of a target field can serve as a rough indicator of their mutual influence (Siddharthan and Teufel, 2007).Although citation patterns are susceptible to biases, we can glean meaningful insights at an aggregate level (Mohammad, 2020;Wahle et al., 2023b).</p>
<p>While no universally accepted definition of LLMs exists (Radford et al., 2019), in this work, we take LLMs as foundational models (Henderson et al., 2023) built on the transformer architecture, pretrained on massive textual datasets with over 100M parameters.We carefully curated a dataset of 106 well-cited LLM papers up to February 2024 including BERT (Devlin et al., 2019), T5 (Raffel et al., 2020), GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), ChatGPT (OpenAI, 2023), and LLaMA (Touvron et al., 2023).We then quantitatively investigate:</p>
<p>(A) Which non-CS fields are impacted by LLMs?</p>
<p>And to what degree?( § 4.1) (B) How do the usage patterns of LLMs evolve over time within these non-CS fields?( § 4.2) We complement the above discussions with an additional qualitative analysis exploring: (C) In what contexts are LLMs applied within these non-CS fields?( § 4.3)</p>
<p>In addressing the questions above, we utilize the Semantic Scholar data (Lo et al., 2020) to construct our dataset comprising ∼148k papers from 22 fields outside of CS, published between 2018 and February 2024, that cite LLMs.This dataset includes structured full texts extracted from the PDFs of the papers as well as their metadata, including the fields of study, year of publication, venue of publication, and author information.Additionally, we include similar data from the papers associated with 106 LLMs, along with ∼273k LLM citations from the aforementioned papers outside of CS.While the quantitative analyses (A and B) provide insights into the adoption of LLMs across diverse fields, they do not capture the nuances of how LLMs are being utilized within these fields.To gain deeper insights for C, we delve beyond metadata, exploring the content of the papers citing LLMs.Our qualitative examination of papers' contents not only illuminates diverse applications of LLMs outside of CS but also guides towards potential improvements and research directions for better LLM usability in various non-CS fields.Finally, we approximately assess and discuss the extent to which these papers, especially in fields like Biology, Medicine, Psychology, Law, etc., discuss ethical concerns associated with LLMs, such as hallucinations (Shi et al., 2023) or non-reproducible outputs (de Wynter et al., 2023), using a smaller human-annotated dataset.</p>
<p>In summary, our findings suggest that 1) linguistics, engineering, and medicine are the top three fields citing LLMs, and fields more closely aligned with CS tend to more readily adopt LLM technology compared to other domains ( § 4.1); 2) BERT continues to be the preferred LLM among non-CS fields, even in terms of average yearly citations.Moreover, many of these fields frequently cite task-agnostic models like GPT-3 (Brown et al., 2020) or LLaMA (Touvron et al., 2023), which excel in few-shot settings without needing additional fine-tuning.( § 4.2); and 3) non-CS fields mostly use LLMs to solve their domain-specific problems ( § 4.3); Our study is the first attempt to empirically and systematically investigate the impact and usage of LLMs in fields outside CS.</p>
<p>Study Goal:</p>
<p>The aim of our study is not to engage in debates regarding the advantages or disadvantages of increased LLM usage across diverse fields, nor do we seek to discuss whether and how non-CS fields effectively implement ethical review processes.Instead, our primary objective is to quantify and delineate the utilization of LLMs in fields beyond CS.Motivation and Audience: NLP researchers play a pivotal role in facilitating interdisciplinary exchange (Hovy and Spruit, 2016).Raising awareness about how NLP technologies are currently being used by other fields is the first step in helping them effectively reach other communities in the future.Therefore, the primary audience of this work is NLP researchers.The insights gleaned here can help them craft more effective interdisciplinary projects, foresee potential challenges, and effectively relay these insights and risks to colleagues outside of CS.Moreover, this work could potentially serve as a valuable resource for many early NLP researchers, broadening their understanding of NLP's intersection with other domains.Further, we anticipate that this paper will not only benefit the *CL community but also resonate with other research communities, thereby enriching the broader landscape of NLP research.</p>
<p>Related Work</p>
<p>Scientific Trends Analysis.Early work by Hall et al. (2008) served as a catalyst for exploring scientific trends in NLP.Research in scientific trends analysis primarily spans three dimensions, from citation patterns to metadata and content analysis.</p>
<p>A vast amount of research has been done into the study of citation patterns and the amalgamation of topological measures within citation networks to assess research trends (Small, 2006;Shibata et al., 2008;Boyack and Klavans, 2022).Complementary to this, Prabhakaran et al. ( 2016) did a content analysis, employing rhetorical framing to elucidate trend patterns.Grudin (2009) and Liu et al. (2015) take a metadata-driven approach, employing prevalence correlation to examine the interplay between publication topics and research grants.Pramanick et al. (2023) apply causal techniques to explore how tasks, methods, datasets, and metrics interact within the context of the evolution of NLP research.Koch et al. (2021)  NLP Scientometrics.In parallel, NLP scientometrics has witnessed significant advancements in recent years as researchers strive to understand the landscape of NLP research and its evolution (Mingers and Leydesdorff, 2015;Chen and Song, 2019).Prior studies have examined the engagement of NLP research with other disciplines, shaping the research trajectory (Hansson, 1999;Leydesdorff et al., 2019).While various studies have observed a rising trend in interdisciplinary interactions occurring both across fields and within subfields (Van Noorden et al., 2015;Truc et al., 2020), this growth primarily manifests in connections between closely related domains, with limited increases in associations between traditionally distant research areas, such as materials sciences and clinical medicine (Porter and Rafols, 2009).We add to this line of work by investigating how research fields that were traditionally distant from NLP are now incorporating LLM techniques to address their challenges.</p>
<p>LLM Abilities Assessment.LLMs are a category of transformer-based language models distinguished by their size, typically consisting of hundreds of millions or even more parameters.They are trained on vast and diverse data (Shanahan,</p>
<p>2022</p>
<p>).These models exhibit remarkable proficiency in understanding and generating natural language, enabling them to excel in complex languagerelated tasks (Sanh et al., 2021;Wei et al., 2021).However, LLMs come with challenges, including the generation of plausible yet factually incorrect text (Ganguli et al., 2022).Moreover, they can be manipulated to produce harmful content, raising ethical concerns about their misuse (Rae et al., 2021;Du et al., 2022).Our study does not assess LLM capabilities or risks but focuses on how non-CS fields use LLMs, and we examine ethical concerns related to LLMs based on the content of the papers within these fields.</p>
<p>Data</p>
<p>We initiate our study by compiling a list of 106 LLMs from the Stanford Ecosystem Graphs.2This curated compilation includes the names of the LLMs selected based on their number of citations. 3e manually identified and included in our list the papers that introduced these LLMs. 4ollowing Rungta et al. (2022), we use the Semantic Scholar (S2) dataset5 to obtain the target papers.Specifically, we include around 148k papers from non-CS fields from S2 that cite the abovementioned LLMs.Thus, our dataset contains structured full texts extracted from the PDFs of these papers along with their metadata, encompassing author details, publication year, publication venue, and field of study.In Table 1, we illustrate our dataset statistics.</p>
<p>We prefer S2 over other sources like the ArXiv dataset due to its broader coverage, including ArXiv papers.Additionally, S2 employs a fieldof-study classifier (S2FOS3) based on abstracts and titles to identify the field of study (with 86% accuracy).This dataset also contains information  on paper citations, including the time and venue of the first publication of the citation, citation context, and citation intents (S2 dataset overview and statistics in Appendix A and Table 4).Further, by analyzing author names, unique author ids, and their associations with published papers in S2, we identify the field where an author has published most frequently, which we consider as their primary field of interest.</p>
<p>Analysis</p>
<p>We use the dataset described above to examine the degree of LLM adoption in fields outside of NLP and CS, addressing three primary aspects: the scope of LLM influence ( § 4.1), their evolving utilization( § 4.2), and finally, their applications in these fields( § 4.3).Subsequently, we offer a detailed examination of each facet.</p>
<p>Breadth of LLM Adoption</p>
<p>To gauge the scope of LLM influence, we address three research questions: first, we investigate the extent of LLM adoption in fields beyond NLP and CS; second, we examine the depth of LLM adoption within these fields and finally, we compare LLM popularity to similar past technologies in non-CS fields.</p>
<p>Q1. How widely have LLMs permeated broader academic disciplines (beyond NLP and CS)?</p>
<p>We examine the citations in non-CS papers referencing LLM papers.If a citing paper is labeled to be in multiple fields, then it contributes to the citation count in each field.We calculate the percentage of LLM citations attributed to each non-CS field relative to the total citations from all non-CS fields.Further, we use the Gini Index (Lerman and Yitzhaki, 1984) on the relative citation counts to quantify the degree of deviation from a perfectly equal citation distribution across fields.A Gini index of 0 indicates a perfectly uniform distribution, while an index of 1 denotes all the probability mass concentrated on one value.</p>
<p>Results: Figure 1(a) is a Sankey plot of the incoming citations from non-CS fields to LLM papers (#citations, %citations), with the width of the grey flow path representing the citation volume.Certain fields stand out in terms of LLM citations.Linguistics accounts for the maximum number of citations (23.19%), followed by Engineering (22.28%), Medicine (17.63%),Environmental Science (6.89%), and Mathematics (5.08%).</p>
<p>Discussion: To illustrate the evolving citation trends, in Figure 12 (Appendix C), we present a year-wise analysis of citations to LLM research papers from non-CS fields.Our findings reveal that, in 2018, during the nascent stages of LLM research, a significant proportion of citations stemmed from Linguistics and Engineering.However, a shift becomes prominent as we progress toward 2023, with numerous non-CS fields increasingly adopting LLMs.In Figure 2, the Gini diversity index, declining over the years, supports this shift, indicating a broader adoption of LLMs.</p>
<p>To better understand the reasons behind the citation trends of LLMs, we investigate whether high LLM citations in some fields result from interdisciplinary research.To address this aspect, in Fig- 2018   ure 1(b), we calculate the percentage of Computer Science (CS) authors collaborating with each non-CS field relative to the total number of CS authors collaborating with all non-CS fields.Surprisingly, we find only a weak correlation (Pearson correlation: 0.28) between the proportion of LLM citations by a field and the proportion of CS collaborators.This suggests that high LLM citations in some fields are likely driven more by other factors, such as the utility of LLMs for the exploration of research questions of interest in the field.Further, to assess the depth of LLM penetration across each of these disciplines, examining the variations in publication volumes among these fields is important.In other words, a field with a high number of LLM citations may not be highly influenced by them when viewed in light of the total number of papers published in that field, and vice versa.This guides our exploration of the following section Q2.</p>
<p>Q2. To what degree have LLMs penetrated various non-CS fields?</p>
<p>Expanding the analysis in Q1, we now investigate the popularity of LLMs within these fields.For each non-CS field, we calculate the percentage of papers citing LLMs out of the total number of  papers published in that field.This acts as a rough indicator of how extensively the field is utilizing LLMs.Results: Figure 3 shows the LLM citation counts relative to the field's publication volume.Proportionally, Linguistics has the most extensive engagement with LLMs compared to other fields.It is followed by Law, Mathematics, Art, and Engineering in terms of LLM utilization.Discussion: Previously, we noticed that while many papers in Medicine cite LLMs, their proportion (concerning the total papers in the field) is smaller than in Mathematics or Environmental Science.We further analyze the influence of CS author collaborations on research papers within each field by calculating the average number of CS authors per paper within that field since 2018.As illustrated in Figure 4, the fields with the highest average number of CS author influence are Linguistics, Engineering, and Mathematics.We observe a positive Pearson correlation of 0.38 between the average number of CS authors per paper in a non-CS field and the percentage of papers within that field that cite LLMs (indicating moderate correlation).This empirical evidence indicates that although the total number of CS authors collaborating within a field has little consequence; an increased number of CS authors on a research paper raises the likelihood of using LLMs in that work.</p>
<p>Q3. To what extent do non-CS fields embrace LLMs compared to other technologies from CS?</p>
<p>Curious as NLP researchers, we were intrigued  by the reception of non-CS fields towards emerging technologies from CS beyond just LLMs.</p>
<p>To explore this, we examine the impact of two iconic technologies: Sequence Models (RNNs and LSTMs) and Hidden Markov Models (HMMs), whose revolutionary effects in CS subfields mirror the transformative influence of LLMs today and juxtapose their wide impact with that of LLMs.We compile all representative papers for RNNs-LSTMs and HMMs from Jurafsky (2023), highly cited not just within NLP but also across other CS sub-fields, and count the citations they receive from non-CS fields using a methodology the same as Q1.</p>
<p>To assess the diversity of their adoption, we use Gini indices on the citation distributions for these three technologies.</p>
<p>Results:</p>
<p>In Table 2, we present the diversity indices for LLMs alongside RNNs-LSTMs and HMMs.</p>
<p>Discussion: LLMs demonstrate the lowest Gini index among these technologies, suggesting more diverse adoption across various non-CS fields.Further, to compare the popularity of LLMs with previous technologies, we set four different thresholds and show the number of fields surpassing each threshold.Figure 5 shows that LLMs receive citations more broadly across different fields, emphasizing their wider range of applications. 6</p>
<p>6 Refer to Appendix C for additional analysis.</p>
<p>0 2 5 0 0 5 0 0 0 7 5 0 0 1 0 0 0 0 Average citation counts per year
BERT GPT-3 GPT-2 LLaMA T5 InstructGPT GPT-4 LLaMA 2 PaLM GPT-1 OPT Flan-U-PaLM FLAN BLOOM LaMDA Guanaco T0 PaLM 2 Med-PaLM Gopher UniLM GPT-Neo Pythia GLM-130B Megatron-LM</p>
<p>Evolving Usage Patterns of LLMs</p>
<p>To study how LLM utilization across various fields has evolved, we address two research questions: first, we identify the most widely used LLMs in these fields; second, we analyze which fields have embraced newer LLMs over time.Q4.What are the most popular LLMs in different non-CS fields, and why?We evaluate the popularity of LLMs across non-CS fields by computing the annual average number of citations each LLM receives from these fields.Results: Figure 6 shows the top 25 most popular LLMs across diverse non-CS fields7 .Below, we summarize the main findings.Discussion: BERT, despite being published in 2019 (relatively early in the evolution of LLMs), remains the most popular LLM among non-CS fields, with the highest average citations per year.This could be because when BERT was introduced, there were fewer LLM options, leading to more citations.Consequently, many papers that incorporated LLMs during that period likely cited BERT, contributing to its higher average citation count.Secondly, the extensive, wide, and successful use of BERT likely made it a reliable choice for non-CS fields.In contrast, the behaviors and capabilities of newer LLMs are still undergoing exploration and evaluation.</p>
<p>In Figure 7, we show the number of LLMs published in each year.We observe that, in recent years, the proliferation of LLM research has led     to the emergence of numerous new LLMs, resulting in some spread of citations away from the earlier favorites to newer LLMs (e.g., GPT-3, GPT-2, LLaMA, T5).Q5.What is the average LLM citation age in non-CS fields, and how does it differ across fields?</p>
<p>The LLM citation age represents the average age of the LLMs that papers in a particular field are citing.A low citation age indicates a preference for newer LLMs, while a high age suggests reliance on older ones.Fields falling in between use a mix of both.</p>
<p>If a paper x i from research field c (i.e., x i ∈ c) cites an LLM paper y j , then the age of LLM citation (AoC) is taken to be the difference between the year of publication (YoP) of x i and y j :
AoC(x i , y j ) = Y oP (x i ) − Y oP (y j )
We calculate the mean Age of LLM Citation (mAoC c ) for a field c as:
mAoC c = 1 M N M i=1 N j=1 AoC(x i , y j ), ∀x i ∈ c
Results and Discussion: Figure 8 shows the Age of LLM Citation in various non-CS fields, revealing insightful perspectives on their utilization of LLMs.Psychology and Linguistics, having a longer history with LLMs, are now exploring newer LLMs, leading to low mAoC.Environmental Science relies mainly on older LLMs, possibly due to established performance and a lack of LLMs specifically created for the field.However, fields like Biology and Chemistry keep a balance between older LLMs while embracing newer LLMs, which are suited for their task, leading to moderate mAoC.</p>
<p>Applications of LLMs in non-CS Fields</p>
<p>To examine LLM applications in non-CS fields, we qualitatively identify tasks where LLMs are applied, and additionally, using keyword searches, we roughly gauge the frequency with which the papers that cite LLMs in these fields mention ethical risks.</p>
<p>Q6. How are LLMs utilized in non-CS fields?</p>
<p>Understanding these field-specific tasks, where LLMs find applications, can help the NLP community better understand, adapt, and align LLMs and research with the distinct requirements of these communities.We examine LLM usage in various non-CS fields using trigrams in paper titles, abstracts, and citation contexts.By citation contexts, we precisely mean sentences that explicitly mention LLMs by name or citation (Anderson and Lemken, 2023).We further process them to identify trigrams indicative of tasks using regex-based heuristics, such as removing the stop-words and manually filtering out irrelevant trigrams.Unlike Mohammad (2020), we use trigrams over bigrams, as trigrams offer richer contextual information beneficial for task identification within each field.Results and Discussion: In Table 3, we highlight the top three most frequent trigrams that serve as representative tasks in papers citing LLMs for each of the non-CS fields.This table offers a glimpse into the specific problems LLMs are employed to address across various fields.We observe that the fields often use LLMs to solve their field-specific problems rather than focusing on analyzing the models themselves (Refer to Appendix C for additional analysis).In Table 8 (Appendix C), we present frequent bigrams from these research papers, offering insights into the topics that interest these fields.Q7.How frequently do research papers in non-CS fields mention ethical risks?Until the preceding sections, we studied the impact of LLMs on non-CS fields and their utilization trends.However, it is essential to acknowledge that LLMs come with inherent risks, such as bias   and hallucination (Kaddour et al., 2023).These concerns are particularly relevant when LLMs are applied to sensitive applications.While we acknowledge that pinpointing research papers that address ethical concerns about LLMs from a large collection presents a significant challenge (and requires huge manual efforts), we argue that identifying the contexts in which these papers discuss risks and ethical concerns can provide a rough idea and preliminary insight into how deeply non-CS fields are engaged with the ethical implications of LLMs.Hence, examine papers that cite LLMs, aiming to identify contexts where discussions of risks and ethical considerations closely coincide with mentions of LLMs within the same sentence.Additionally, we extend our scrutiny to the titles and abstracts of these papers, assessing whether these concerns are underscored as particularly significant.Results and Discussion: In Figure 9, we present the percentages of papers in each field that mention the risks associated with LLMs in their titles, abstracts, or citation contexts at least once relative to the total number of papers citing LLMs in that field.This acts as an approximate indicator of the relative importance of ethical considerations within various non-CS fields.Refer to Appendix B for a detailed description and manual evaluation of this analysis method.</p>
<p>Our analysis reveals that, on average, approximately 2.01% of non-CS papers citing LLMs mentions about the ethical risks of LLMs.This finding is concerning, as it suggests that many non-CS fields are actively using LLMs without recognizing the ethical risks that these models entail.</p>
<p>Discussion: Opportunities and Challenges</p>
<p>In this study, we explore the adoption of LLMs across 22 non-CS fields.To analyze the large number of research papers utilizing LLMs, we employ a combination of automatic content analysis, manual scrutiny, and citation and metadata analysis.Unlike previous technologies, LLMs are finding diverse applications across disciplines such as art and history, revealing their broad scope.However, there are very few LLMs specifically tailored to meet the unique demands of these non-CS fields, highlighting a significant opportunity for improvement.Additionally, inherent risks like hallucinations associated with LLMs pose challenges.It is important to implement safe, ethical practices and communicate these risks effectively to researchers in these fields, ensuring they can make informed decisions about using LLMs.We release our artifacts under a non-commercial license c b n a.</p>
<p>Limitations</p>
<p>In any study on field-to-field influence, having a dataset that includes both paper fields and citations is essential.This can be challenging since papers often relate to multiple fields to varying degrees, making it difficult for humans and automated systems to label them accurately.Additionally, defining distinct fields and gathering comprehensive paper sets for each field presents its own set of complexities.Nevertheless, by working with large datasets categorized based on field labels, we can derive valuable insights and identify trends in interdisciplinary research.</p>
<p>While citations serve as a quantifiable measure of influence (Siddharthan and Teufel, 2007), the degree of impact can vary between different cited works.Moreover, citation patterns are susceptible to various biases (Zhu et al., 2015;Singh et al., 2023).Given the large volume of papers citing LLMs, conducting an in-depth manual examination of each paper is impractical within the scope of this study.To address this, we combine automated methods with manual verification, which offers a high-precision approximate assessment of LLM influence in non-CS fields.This methodology enables us to examine a larger set of data, providing insights into the relative influence of LLMs across diverse non-CS fields.</p>
<p>Lastly, the dataset used for this analysis, provided by Semantic Scholar, is extensive but not exhaustive, leaving out papers and fields beyond its scope.Additionally, Semantic Scholar relies on a classifier, along with heuristics, to categorize papers into fields of study.It is essential to recognize that this classifier has limitations and does not fully capture the nuanced degrees of association with multiple fields for a given paper.In Appendix A.2, we discuss the reliability of the dataset for our analysis.</p>
<p>Ethics Statement</p>
<p>We clarify that the number of citations used in our analysis should not be employed to diminish any specific field or its investments based on low citation counts.Decisions in science and research should rely on a multifaceted evaluation that considers aspects like popularity, relevance, resources, impact, and geographical and temporal factors.This approach prevents oversimplified interpretations and recognizes the diversity and complexity of research fields and their contributions.</p>
<p>A Appendix: Supplementary Definitions and Discussions</p>
<p>A.1 Choosing the LLMs</p>
<p>The Computer Science community has yet to establish a universally accepted definition of LLMs (Radford et al.).The term LLM gained prominence recently amidst a paradigm shift in AI, marked by the emergence of models trained on broad data, which started with textual data but soon expanded to other data modalities (such as images, codes, proteins, etc).These models belong to a class called Foundation models (Bommasani et al., 2021).In our analysis, an LLM refers to an impactful foundation model (Henderson et al., 2023) based on the transformer architecture pre-trained on massive textual datasets.We curate these models from the Stanford Ecosystem Graphs (Bommasani et al., 2023), which contains 106 foundation models pretrained on textual data as of February 2024.</p>
<p>A.2 S2 Dataset Statistics and Reliability</p>
<p>The Semantic Scholar Dataset (S2) that we use in our analysis (which is the backbone of Semantic Scholar) covers all STM (Science, Technology, and Medicine) and SSH (Social Sciences and Humanities) disciplines, including biology, medicine, computer science, geography, business, history, and economics.</p>
<p>The February 2024 version of the S2 comprises approximately 200M papers metadata (Table 4), sourced from diverse partners such as PubMed, Springer Nature, Taylor &amp; Francis, SAGE, Wiley, ACM, IEEE, arXiv, and Unpaywall etc. Originally housing 84.1M papers, the dataset is continuously updated on a monthly basis.Further, each paper in the dataset is annotated with fields of study with an annotation accuracy of 86%, using a taxonomy adapted from the Microsoft Academic Graph (Kinney et al., 2023).</p>
<p>Compared to other datasets (e.g., arXiv, Scopus, Pubmed), S2 stands out as the largest and most upto-date open-access scholarly dataset that includes parsed text and metadata such as field of study, citation contexts, citation graph, etc.Overall, the S2 dataset is a good representative of the non-CS fields (Wahle et al., 2023a(Wahle et al., , 2024;;Illia et al., 2023;Guo et al., 2023).</p>
<p>A.3 Examining LLM citation within CS</p>
<p>The main objective of this work is to assess the impact of LLMs on fields outside of CS.However, in this section, we analyze a control, LLM citations within CS, to provide a broader context for our findings.To add to this, we found that the LLMs receive ∼91k citations from within CS, which is</p>
<p>C Appendix: Additional Results</p>
<p>C.1 Influence of Alternate CS Method (LDA) vs. LLM beyond CS.</p>
<p>In Section 4.1, our primary focus was on models commonly used in NLP for Language Modeling, aiming to compare their influence with that of LLMs.Our motivation was to assess whether LLMs are more prevalent and influential than traditional Language Modeling methods in non-CS fields.However, in this section, we further extend our analysis to compare the influence of LLMs with that of Latent Dirichlet Allocation (LDA), a popular method originating from CS but gaining traction outside CS domains as well.</p>
<p>In our analysis, we identified three seminal papers on LDA (Blei et al., 2003;Blei, 2012;Teh et al., 2004) based on their citation counts and examined the number of citations they received from non-CS fields.In total, these papers receive 8383 citations from non-CS fields cumulatively.Specifically, we found that 13 fields contribute more than 100 citations each, while 7 fields contribute over 500 citations each, and only one field contributes more than 1000 citations.Further, we find that the Gini index of the citation distribution of the aforementioned LDA papers among non-CS fields is 0.59 (higher than that of LLMs).From this analysis, we infer that LLMs are more popular in fields outside CS than LDA.</p>
<p>C.2 Usage Patterns of LLMs in non-CS Fields:</p>
<p>Inference vs. Fine-Tuning</p>
<p>We investigated the extent to which papers in non-CS fields utilize LLMs through fine-tuning or solely for inference in zero-shot settings.Specifically, we searched for the keywords "fine-tune," "zero-shot," and "inference" within the abstracts of the non-CS papers that cite LLMs.This filtering process resulted in 3675 papers.Further, we uniformly sampled and manually analyzed 50 papers out of 479 papers that mentioned fine-tuning, revealing an 86% precision.Similarly, we sampled 100 papers from the remaining 3196 papers (that did not contain the word "fine-tune" in their abstracts, and 3158 of these papers contained "zeroshot" in their abstracts) and manually analyzed them, finding a 79% precision rate in representing papers that use LLMs solely for inference.This analysis is an approximate indicator of the use of LLMs in non-CS fields, indicating that while some of the non-CS papers indeed fine-tine LLMs</p>
<p>Figure 1: % citations from non-CS fields to LLMs (left); % CS authors collaborating with non-CS fields (right).</p>
<p>Figure 3 :
3
Figure 3: % Papers in non-CS fields (Y-Axis) citing LLMs.</p>
<p>Figure 4 :
4
Figure 4: Avg.number of CS authors per paper by field (Y-Axis).</p>
<p>Figure 5 :
5
Figure 5: Number of fields surpassing the threshold number of citations for different NLP Technologies.</p>
<p>Figure 6 :
6
Figure 6: Popular LLMs in non-CS fields (Top 25).</p>
<p>Figure 7 :
7
Figure 7: No. of LLMs Published over the Years (until Feb.'24).</p>
<p>0</p>
<p>Figure 8 :
8
Figure 8: Age-of-Citation (AoC) of non-CS fields (Y-Axis).</p>
<p>Figure 9 :
9
Figure 9: % of papers per field (Y-Axis) discussing LLM risks.</p>
<p>Table 1 :
1
Statistics of LLMs and their citing papers citing.
LLM Timespan2018 -present# LLMs106# papers citing LLMs148,501# citations to LLMs273,030</p>
<p>Table 2 :
2
Diversity (Gini Index) in citation distribution across fields for NLP Technologies.
Cited Method Gini IndexHMMs0.66RNN-LSTMs0.63LLMs0.56No. non-CS fields 0 3 6 9 12 15 18 21 &gt;=100 &gt;=500 &gt;=1000 &gt;=5000 No. incoming citations HMMs RNNs-LSTMs LLMs</p>
<p>Table 3 :
3
Most frequent task trigrams in LLM citing papers from non-CS fields.
0 Philosophy Law Sociology Education Political Science Psychology Art History Economics Medicine Business Linguistics Geography Environmental Science Chemistry Materials Science Engineering Mathematics Biology5 % papers discussing LLMs' risks 10 15</p>
<p>Table 4 :
4
Overall Semantic Scholar Dataset Statistics.</p>
<p>Table 6 :
6
We can adopt this principle for the ethical use of generative AI in healthcare and ensure that human involvement is maintained when more powerful generative AI systems such as ChatGPT or clinical decision support systems are in use.The value alignment problem is one of the more difficult areas of the field of ethical AI, but also the most critical.Citation contexts mentioning LLM-related ethical concerns.
02000 4000 6000 8000 10000 12000 Average citation counts per year
https://crfm.stanford.edu/ecosystem-graphs/
For details refer Appendix A
For 8 LLMs, such as Claude or Vicuna, we cannot identify any associated papers, but we still include them in the content analysis in Section 4.3.
https://www.semanticscholar.org/
Plot for larger list of LLMs is in Figure 10, max. citation in Figure 11 (Appendix C).
papers engaged in discussions about the ethical concerns of LLMs without explicitly mentioning the LLMs. Additionally, we manually analyzed 200 papers and found no paper mentioning ethical concerns in the same context as LLMs but not discussing LLMs' ethical risks. This reveals the high reliability of our automatic method.
AcknowledgementsThis work has been funded by the German Research Foundation (DFG) as part of the Research Training Group KRITIS No. GRK 2222.We are thankful to Hiba Arnaout and Sukannya Purkayastha for their valuable feedback on the initial draft of this manuscript.ethics risks limitations drawbacks bias ethical consideration∼5.5 times higher than the citations it garners from Linguistics (the field that gives the highest LLM citations outside CS).This discrepancy is expected, considering the higher popularity of LLMs within CS.B Appendix: Human Evaluation of LLMCiting Papers That Discuss LLM RisksTitles and abstracts are primarily meant to provide a summary of a paper's focus, while citation contexts offer detailed insights into how the citing paper utilizes the cited work, specifically LLMs in this case.When referring to citation contexts, we mean sentences that include citation marks.More precisely, these are sentences that explicitly mention LLMs by name or citation.Hence, we use texts from these sections to filter papers that acknowledge the ethical risks of LLMs.Specifically, we look for the keywords in 0.00 0.00 2.00 9.00 15.00 6.00 0.00 3.00 50.00 9.00 0.00 1.00 0.00 2.00 325.00 1.00 48.00 47.00 2.00 9.00 1.00 13.00 2.00 0.00 6.00 9.00 99.00 109.00 38.00 15.00 56.00 344.00 94.00 10.00 4.00 4.00 48.00 1250.00 18.00 189.00 502.00 27.00 34.00 73.00 63.00 31.00
. Linguistics, 15.9k, 23.19%</p>
<p>Engineering (15.3k, 22.28%) Medicine (12.1k, 17.63%). </p>
<p>. Psychology. 2.2k, 3.23%) Business (2.1k, 3.01%)</p>
<p>Education (1.7k, 2.44%) Physics (1.4k, 2.04%). </p>
<p>Political Science (1.2k, 1.74%) Chemistry (1.1k, 1.61%) Law (1.0k, 1.52%). </p>
<p>. Sociology. 881, 1.28%) Materials Science (623, 0.91%) Philosophy (581, 0.85%) Economics (550, 0.80%) Art (452, 0.66%)</p>
<p>. Geography. 315, 0.46%) History (178, 0.26%) Geology (113, 0.16%)</p>
<p>. Agricultural And Food Sciences. 1, 0.00%) References</p>
<p>Citation context analysis as a method for conducting rigorous and impactful literature reviews. H Marc, Russell K Anderson, Lemken, Organizational Research Methods. 2612023</p>
<p>Probabilistic topic models. M David, Blei, Communications of the ACM. 5542012</p>
<p>Latent dirichlet allocation. Andrew Y David M Blei, Michael I Ng, Jordan, Journal of machine Learning research. 32003. Jan</p>
<p>Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney Von Arx, Jeannette Michael S Bernstein, Antoine Bohg, Emma Bosselut, Brunskill, arXiv:2108.07258On the opportunities and risks of foundation models. 2021arXiv preprint</p>
<p>Ecosystem graphs: The social footprint of foundation models. Rishi Bommasani, Dilara Soylu, Thomas I Liao, Kathleen A Creel, Percy Liang, arXiv:2303.157722023arXiv preprint</p>
<p>Growth rates of modern science: a latent piecewise growth curve approach to model publication numbers from established and new literature databases. Robin Lutz Bornmann, Rüdiger Haunschild, Mutz, Humanities and Social Sciences Communications. 812021</p>
<p>An improved practical approach to forecasting exceptional growth in research. Kevin W Boyack, Richard Klavans, 10.1162/qss_a_00202Quantitative Science Studies. 332022</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Visualizing a field of research: A methodology of systematic scientometric reviews. Chaomei Chen, Min Song, 10.1371/journal.pone.0223994PLOS ONE. 14102019</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, arXiv:2204.02311Palm: Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>Personalized jargon identification for enhanced interdisciplinary communication. Yue Guo, Joseph Chee Chang, Maria Antoniak, Erin Bransom, Trevor Cohen, Lucy Lu Wang, arXiv:2311.09481August. 2023arXiv preprint</p>
<p>Studying the history of ideas using topic models. David Hall, Daniel Jurafsky, Christopher D Manning, Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing. the 2008 Conference on Empirical Methods in Natural Language ProcessingHonolulu, HawaiiAssociation for Computational Linguistics2008</p>
<p>Interdisciplinarity: For what purpose?. Bengt Hansson, Policy Sciences. 3241999</p>
<p>Peter Henderson, Xuechen Li, Dan Jurafsky, Tatsunori Hashimoto, Mark A Lemley, Percy Liang, arXiv:2303.15715Foundation models and fair use. 2023arXiv preprint</p>
<p>The social impact of natural language processing. Dirk Hovy, Shannon L Spruit, 10.18653/v1/P16-2096Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics20162Short Papers)</p>
<p>Implementation of topic modeling in the analysis of topic trends in sdgs goal 6 research. Fathonah Illia, Rani Nooraeni, Lya Hulliyyatus, Suadaa , 2023 International Conference on Electrical Engineering and Informatics (ICEEI). IEEE2023</p>
<p>Speech &amp; language processing. Dan Jurafsky, 2023Pearson Education India</p>
<p>Measuring the evolution of a scientific field through citation frames. David Jurgens, Srijan Kumar, Raine Hoover, Dan Mc-Farland, Dan Jurafsky, 10.1162/tacl_a_00028Transactions of the Association for Computational Linguistics. 62018</p>
<p>Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, Robert Mchardy, arXiv:2307.10169Challenges and applications of large language models. 2023arXiv preprint</p>
<p>Rodney Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczynski, Isabel Cachola, Stefan Candra, Yoganand Chandrasekhar, Arman Cohan, arXiv:2301.10140The semantic scholar open data platform. 2023arXiv preprint</p>
<p>Reduced, reused and recycled: The life of a dataset in machine learning research. Bernard Koch, Emily Denton, Alex Hanna, Jacob Gates Foster, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021</p>
<p>A note on the calculation and interpretation of the gini index. Shlomo Robert I Lerman, Yitzhaki, Economics Letters. 153-41984</p>
<p>Interdisciplinarity as diversity in citation patterns among journals: Rao-stirling diversity, relative variety, and the gini coefficient. Loet Leydesdorff, Caroline S Wagner, Lutz Bornmann, Journal of informetrics. 1312019</p>
<p>Defining a new NLP playground. Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li, Xingyao Wang, Yi Fung, Charles Yu, Joel Tetreault, Eduard Hovy, Heng Ji, 10.18653/v1/2023.findings-emnlp.799Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023</p>
<p>Exploring topical lead-lag across corpora. Shixia Liu, Yang Chen, Hao Wei, J Yang, Kun Zhou, Steven Mark Drucker, IEEE Transactions on Knowledge and Data Engineering. 272015</p>
<p>S2ORC: The semantic scholar open research corpus. Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, Daniel Weld, 10.18653/v1/2020.acl-main.447Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020</p>
<p>A review of theory and practice in scientometrics. John Mingers, Loet Leydesdorff, European journal of operational research. 24612015</p>
<p>Examining citations of natural language processing literature. M Saif, Mohammad, arXiv:2005.009122020arXiv preprint</p>
<p>Large language models shape and are shaped by society: A survey of arxiv publication patterns. Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg, Emma Pierson, arXiv:2307.107002023arXiv preprint</p>
<p>Is science becoming more interdisciplinary? measuring and mapping six research fields over time. OpenAI. 2023. GPT-3.5 TurboScientometrics. 8132009Alan Porter and Ismael Rafols</p>
<p>Predicting the rise and fall of scientific topics from trends in their rhetorical framing. William L Vinodkumar Prabhakaran, Dan Hamilton, Dan Mcfarland, Jurafsky, 10.18653/v1/P16-1111Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics20161</p>
<p>A diachronic analysis of paradigm shifts in NLP research: When, how, and why?. Aniket Pramanick, Yufang Hou, Saif Mohammad, Iryna Gurevych, 10.18653/v1/2023.emnlp-main.142Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, 2019</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, </p>
<p>Sebastian Jack W Rae, Trevor Borgeaud, Katie Cai, Jordan Millican, Francis Hoffmann, John Song, Sarah Aslanides, Roman Henderson, Susannah Ring, Young, arXiv:2112.11446Scaling language models: Methods, analysis &amp; insights from training gopher. 2021arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 2112020</p>
<p>Geographic citation gaps in NLP research. Mukund Rungta, Janvijay Singh, Saif M Mohammad, Diyi Yang, 10.18653/v1/2022.emnlp-main.89Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>Teven Le Scao, Arun Raja, et al. 2021. Multitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, arXiv:2110.08207arXiv preprint</p>
<p>Murray Shanahan, arXiv:2212.03551Talking about large language models. 2022arXiv preprint</p>
<p>Large language models can be easily distracted by irrelevant context. Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, Denny Zhou, International Conference on Machine Learning. PMLR2023</p>
<p>Detecting emerging research fronts based on topological measures in citation networks of scientific publications. Naoki Shibata, Yuya Kajikawa, Yoshiyuki Takeda, Katsumori Matsushima, 10.1016/j.technovation.2008.03.009Technovation. 28112008</p>
<p>Whose idea was this, and why does it matter? attributing scientific work to citations. Advaith Siddharthan, Simone Teufel, Human language technologies 2007: The conference of the North American chapter of the Association for Computational Linguistics; proceedings of the main conference. 2007</p>
<p>Forgotten knowledge: Examining the citational amnesia in NLP. Janvijay Singh, Mukund Rungta, Diyi Yang, Saif Mohammad, 10.18653/v1/2023.acl-long.341Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231</p>
<p>Tracking and predicting growth areas in science. Henry Small, Scientometrics. 6832006</p>
<p>Sharing clusters among related groups: Hierarchical dirichlet processes. Yee Teh, Michael Jordan, Matthew Beal, David Blei, Advances in neural information processing systems. 200417</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>The interdisciplinarity of economics. Alexandre Truc, Olivier Santerre, Yves Gingras, François Claveau, Available at SSRN. 36693352020</p>
<p>Interdisciplinary research by the numbers. Richard Van Noorden, Nature. 52575692015</p>
<p>We are who we cite: Bridges of influence between natural language processing and other academic fields. Jan Philip Wahle, Terry Ruas, Mohamed Abdalla, Bela Gipp, Saif Mohammad, 10.18653/v1/2023.emnlp-main.797Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingapore2023aAssociation for Computational Linguistics</p>            </div>
        </div>

    </div>
</body>
</html>