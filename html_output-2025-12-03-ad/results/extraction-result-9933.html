<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9933 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9933</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9933</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-169.html">extraction-schema-169</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, focusing on what is lost, degraded, or different when using LLMs as judges instead of humans.</div>
                <p><strong>Paper ID:</strong> paper-40da525d570cec153979c7ff709a7783ec5561ca</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/40da525d570cec153979c7ff709a7783ec5561ca" target="_blank">"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> This study proposes to exploit LLMs to approximate HJDs using a small number of expert labels and explanations, and shows the importance of complementing instance-level distance measures with a global-level shape metric and visualization to more effectively evaluate MJDs against human judgment distributions.</p>
                <p><strong>Paper Abstract:</strong> Human label variation (HLV) is a valuable source of information that arises when multiple human annotators provide different labels for valid reasons. In Natural Language Inference (NLI) earlier approaches to capturing HLV involve either collecting annotations from many crowd workers to represent human judgment distribution (HJD) or use expert linguists to provide detailed explanations for their chosen labels. While the former method provides denser HJD information, obtaining it is resource-intensive. In contrast, the latter offers richer textual information but it is challenging to scale up to many human judges. Besides, large language models (LLMs) are increasingly used as evaluators ("LLM judges") but with mixed results, and few works aim to study HJDs. This study proposes to exploit LLMs to approximate HJDs using a small number of expert labels and explanations. Our experiments show that a few explanations significantly improve LLMs' ability to approximate HJDs with and without explicit labels, thereby providing a solution to scale up annotations for HJD. However, fine-tuning smaller soft-label aware models with the LLM-generated model judgment distributions (MJDs) presents partially inconsistent results: while similar in distance, their resulting fine-tuned models and visualized distributions differ substantially. We show the importance of complementing instance-level distance measures with a global-level shape metric and visualization to more effectively evaluate MJDs against human judgment distributions.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9933.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9933.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, focusing on what is lost, degraded, or different when using LLMs as judges instead of humans.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-as-judge (HJD approximation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models used as judges to approximate Human Judgment Distributions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper studies using instruction-tuned LLMs to transform a few expert explanations into model judgment distributions (MJDs) that approximate human judgment distributions (HJDs) on NLI, and compares those MJDs to crowd-derived HJDs across distributional and fine-tuning evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Natural Language Inference (NLI)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_model</strong></td>
                            <td>Mixtral-8x7b-Instruct-v0.1; Llama3-Chat-70b (used as representative LLM judges)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_setup</strong></td>
                            <td>Prompts converted NLI instances to 3-way MCQA (A/B/C) with three prompt types: without explanations, with explanations (comments only), and with explicit explanations (comment + 'so I choose X'). First-token logits for options [A,B,C] were extracted, normalized (p_norm) or softmaxed with temperature (p_sfmax) and permutations/averaging applied across option orders and explanation order (serial/parallel) to mitigate MCQ/order bias.</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_setup</strong></td>
                            <td>Target HJDs come from Chaos NLI: 1,599 MNLI instances each annotated by 100 crowd workers (used as 'true' HJD for comparison); comparison subset uses 341 instances with 4 expert explanations from VariErr NLI (expert annotators) paired to the Chaos NLI HJD for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_metric</strong></td>
                            <td>Instance-level distances: Kullback-Leibler Divergence (KL), Jensen-Shannon Distance (JSD), Total Variation Distance (TVD) (see Table 2 for values); global-level: distance correlation (D.Corr) across dataset (see Table 4). Example reported values (best setups): Mixtral p_sfmax + parallel explicit: KL=0.217, JSD=0.208, TVD=0.232; Llama3 p_sfmax + serial explicit: KL=0.212, JSD=0.232, TVD=0.245. Distance correlation: Mixtral p_norm = 0.609 (baseline) -> +parallel explicit = 0.719; Llama3 p_norm = 0.689 -> +parallel explicit = 0.809.</td>
                        </tr>
                        <tr>
                            <td><strong>losses_identified</strong></td>
                            <td>Using LLMs as judges can miss or distort cross-sample (global) distributional shape and produce local instance-level similarity that does not guarantee downstream usefulness: (1) instance-level distance metrics (KL/JSD/TVD) can be misleading — low instance-level distance does not ensure good fine-tuning performance; (2) LLM MJDs can differ in smoothness/entropy and shape (global correlations) relative to HJDs, which affects model training; (3) LLMs exhibit MCQ/order biases and may misinterpret explanation phrasing (e.g., neutral-supporting language misread as contradiction) without explicit disambiguation; (4) different LLMs produce qualitatively different MJDs (scattered large per-instance errors vs. smoother centralized distributions), so some human nuances are degraded or redistributed rather than faithfully preserved.</td>
                        </tr>
                        <tr>
                            <td><strong>examples_of_loss</strong></td>
                            <td>Concrete divergences shown in the paper: (a) Mixtral and Llama3 reach similar instance-level distances to HJD, but Mixtral's MJDs produce far worse downstream weighted F1 after fine-tuning (Mixtral fine-tuned models have lower F1 than Llama3 despite comparable KL), indicating lost training utility (Table 3, §5.2). (b) Visualization (ternary plots and pairwise error plots) show Mixtral sample points exhibit larger movements from HJD (more scattered absolute errors), while Llama3 points are more centrally smoothed (Figures 4–6, §6.1). (c) Example linguistic failure mode: phrases like 'do not mention' or 'cannot explain' (which support Neutral) can be misinterpreted by LLMs as Contradiction unless prompts include explicit 'so I choose X' clarifiers (§3.1, §5.1). (d) Uniform distributions can have low KL compared to one-hot MNLI labels but are uninformative for training — illustrating that low instance-level divergence can still represent a useless loss of signal (§6.3).</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_caveats</strong></td>
                            <td>There are clear mitigations and cases where LLM judges match or help human evaluation: (1) Adding a few expert explanations substantially improves MJDs' alignment with HJDs across metrics — best setups (explicit explanations, permutation averaging, temperature smoothing) reduce KL/JSD/TVD and increase distance correlation (§5.1, Table 2). (2) Llama3 MJDs, especially with explicit explanations, produced smoother, higher-entropy distributions that improved fine-tuning performance (higher weighted F1 than MNLI/VariErr baselines) — i.e., LLM judges can outperform simpler human-derived single labels for downstream tasks if their MJDs capture useful smoothness (§5.2, §6.3). (3) Global measures (distance correlation) and visual inspection predict fine-tuning utility better than instance metrics, so combining evaluation types can recover trust in LLM judges (§6.2).</td>
                        </tr>
                        <tr>
                            <td><strong>paper_reference</strong></td>
                            <td>Title: "Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations? — see §3 (method), §5.1 (distribution comparison, Table 2), §5.2 (fine-tuning, Table 3), §6.1-6.3 (visualization, distance correlation, analysis).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9933.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9933.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, focusing on what is lost, degraded, or different when using LLMs as judges instead of humans.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixtral MJDs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MJDs produced by Mixtral-8x7b-Instruct-v0.1</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Model-judgment distributions generated by Mixtral under multiple prompt conditions (without explanations; serial/parallel explanations; explicit explanations) and transformations (p_norm, p_sfmax, temperature scaling), compared to Chaos NLI HJDs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Natural Language Inference (NLI)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_model</strong></td>
                            <td>Mixtral-8x7b-Instruct-v0.1</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_setup</strong></td>
                            <td>MCQA prompts (A/B/C) with permutations on option labels and explanation order; p_norm or p_sfmax transformations of first-token logits; serial vs parallel feeding of up to 4 expert explanations; averaging across permutations to mitigate order bias (§3.1–3.3).</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_setup</strong></td>
                            <td>Comparison target: Chaos NLI HJDs (100 crowd annotators) on 341 overlapping instances; VariErr provides the 4 expert explanations used as LLM input (§4.1).</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_metric</strong></td>
                            <td>Instance-level: best observed Mixtral alignment (p_sfmax + parallel explicit explanations) KL=0.217, JSD=0.208, TVD=0.232 (Table 2). Distance correlation: Mixtral p_norm baseline 0.609 -> p_norm + parallel explicit 0.719 (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>losses_identified</strong></td>
                            <td>Mixtral MJDs showed larger per-instance absolute errors (more scattered movements away from HJD) and less globally similar dataset shape compared to Llama3, leading to worse downstream classification F1 despite similar instance-level distance scores; sensitivity to number and presentation of explanations (performance decreased for Mixtral when more explanations were presented in serial mode), and MCQ/order bias requiring permutation averaging (§5.1, §6.1–6.3).</td>
                        </tr>
                        <tr>
                            <td><strong>examples_of_loss</strong></td>
                            <td>Visualizations demonstrate Mixtral points move farther from Chaos NLI HJD; Mixtral fine-tuned BERT/RoBERTa achieved substantially lower weighted F1 (e.g., BERT FT weighted F1 dev/test as low as ~0.416/0.422 for p_norm baseline) compared to Llama3-based MJDs and Chaos NLI training (§5.2, Table 3; Figures 4–6). Adding explicit explanations and choosing the correct feeding mode (parallel) improved metrics but did not eliminate scattered absolute errors (§5.1, Table 7).</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_caveats</strong></td>
                            <td>Mixtral benefits substantially from explicit explanations and parallel feeding (best Mixtral fine-tuning results when using p_clmax with parallel explicit explanations: BERT weighted F1 up to 0.522/0.517, KL down to 0.095, Table 3), showing that prompt engineering and aggregation strategies can recover some losses; temperature scaling and softmax choices affect smoothness and downstream effectiveness (§5.1, §6.3, Appendix H–I).</td>
                        </tr>
                        <tr>
                            <td><strong>paper_reference</strong></td>
                            <td>See §3.1–3.3 (prompt and transformation), §5.1 (distribution comparison Table 2), §5.2 (fine-tuning Table 3), §6.1–6.3 (visualization and distance correlation).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9933.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9933.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge and human evaluations, focusing on what is lost, degraded, or different when using LLMs as judges instead of humans.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama3 MJDs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MJDs produced by Llama3-Chat-70b</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Model-judgment distributions generated by Llama3 under the same prompt/aggregation setups as Mixtral, which tended to produce smoother, higher-entropy MJDs that better preserved global dataset shape and yielded stronger downstream fine-tuning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Natural Language Inference (NLI)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_model</strong></td>
                            <td>Llama3-Chat-70b</td>
                        </tr>
                        <tr>
                            <td><strong>llm_judge_setup</strong></td>
                            <td>Same MCQA prompt forms and processing pipeline as Mixtral: first-token logits mapped to options, permutations and serial/parallel explanation feeding, p_norm and p_sfmax transformations; explicit-explanation prompts used to disambiguate labels where needed (§3.1–3.3).</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_setup</strong></td>
                            <td>Compared to Chaos NLI HJDs (100 crowd annotators) on the 341 overlapping instances; explanations drawn from VariErr's expert annotations (§4.1).</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_metric</strong></td>
                            <td>Instance-level: Llama3 best observed (p_sfmax + serial explicit): KL=0.212, JSD=0.232, TVD=0.245 (Table 2). Distance correlation: Llama3 p_norm = 0.689 -> +parallel explicit = 0.809 (Table 4). Fine-tuning: Llama3 MJDs produced higher weighted F1 (e.g., BERT FT weighted F1 up to ~0.582/0.586 dev/test; RoBERTa up to ~0.645/0.621) in Table 3.</td>
                        </tr>
                        <tr>
                            <td><strong>losses_identified</strong></td>
                            <td>Although Llama3 MJDs are closer overall and more useful for fine-tuning, they still differ from true HJDs in that they tend to be smoother (higher entropy), which can alter the original annotation massing (e.g., centralizing ambiguous instances) and potentially mask some specific human disagreement modes; also Llama3 can be sensitive to prompt length and benefits from serial explanation feeding, indicating differences in how it aggregates multi-annotator evidence compared to humans (§6.1–6.3).</td>
                        </tr>
                        <tr>
                            <td><strong>examples_of_loss</strong></td>
                            <td>Ternary plots show Llama3 distributions are more centralized (higher entropy) than Chaos NLI HJD though in the same general region; Llama3's smoother labels act like label smoothing and while beneficial for training, they represent a transformation of the original human variance (Figures 4–5, §6.1). Instance-level KL/JSD still non-zero, indicating residual per-instance discrepancies (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_caveats</strong></td>
                            <td>Llama3 frequently outperformed Mixtral and other baselines in downstream fine-tuning (higher F1, better KL and CE loss after fine-tuning) — demonstrating LLMs can match or improve on human-derived signal for some purposes when provided with explanations and careful prompting; adjusting temperature (τ) produced smoother or sharper MJDs and affected fine-tuning outcomes positively in some ranges, suggesting controllable trade-offs (§6.3, Appendix H–I).</td>
                        </tr>
                        <tr>
                            <td><strong>paper_reference</strong></td>
                            <td>See §3.1–3.3 (prompt/transformation), §5.1 (distribution results Table 2), §5.2 (fine-tuning Table 3), §6.1–6.3 (visualization, distance correlation, analysis).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Can large language models be an alternative to human evaluations? <em>(Rating: 2)</em></li>
                <li>Can large language models capture dissenting human voices? <em>(Rating: 2)</em></li>
                <li>What can we learn from collective human opinions on natural language inference data? <em>(Rating: 2)</em></li>
                <li>VariErr NLI: Separating Annotation Error from Human Label Variation <em>(Rating: 2)</em></li>
                <li>Ecologically valid explanations for label variation in NLI <em>(Rating: 2)</em></li>
                <li>The effectiveness of LLMs as annotators: A comparative overview and empirical analysis of direct representation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9933",
    "paper_id": "paper-40da525d570cec153979c7ff709a7783ec5561ca",
    "extraction_schema_id": "extraction-schema-169",
    "extracted_data": [
        {
            "name_short": "LLM-as-judge (HJD approximation)",
            "name_full": "Large Language Models used as judges to approximate Human Judgment Distributions",
            "brief_description": "The paper studies using instruction-tuned LLMs to transform a few expert explanations into model judgment distributions (MJDs) that approximate human judgment distributions (HJDs) on NLI, and compares those MJDs to crowd-derived HJDs across distributional and fine-tuning evaluations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "task_domain": "Natural Language Inference (NLI)",
            "llm_judge_model": "Mixtral-8x7b-Instruct-v0.1; Llama3-Chat-70b (used as representative LLM judges)",
            "llm_judge_setup": "Prompts converted NLI instances to 3-way MCQA (A/B/C) with three prompt types: without explanations, with explanations (comments only), and with explicit explanations (comment + 'so I choose X'). First-token logits for options [A,B,C] were extracted, normalized (p_norm) or softmaxed with temperature (p_sfmax) and permutations/averaging applied across option orders and explanation order (serial/parallel) to mitigate MCQ/order bias.",
            "human_evaluation_setup": "Target HJDs come from Chaos NLI: 1,599 MNLI instances each annotated by 100 crowd workers (used as 'true' HJD for comparison); comparison subset uses 341 instances with 4 expert explanations from VariErr NLI (expert annotators) paired to the Chaos NLI HJD for evaluation.",
            "agreement_metric": "Instance-level distances: Kullback-Leibler Divergence (KL), Jensen-Shannon Distance (JSD), Total Variation Distance (TVD) (see Table 2 for values); global-level: distance correlation (D.Corr) across dataset (see Table 4). Example reported values (best setups): Mixtral p_sfmax + parallel explicit: KL=0.217, JSD=0.208, TVD=0.232; Llama3 p_sfmax + serial explicit: KL=0.212, JSD=0.232, TVD=0.245. Distance correlation: Mixtral p_norm = 0.609 (baseline) -&gt; +parallel explicit = 0.719; Llama3 p_norm = 0.689 -&gt; +parallel explicit = 0.809.",
            "losses_identified": "Using LLMs as judges can miss or distort cross-sample (global) distributional shape and produce local instance-level similarity that does not guarantee downstream usefulness: (1) instance-level distance metrics (KL/JSD/TVD) can be misleading — low instance-level distance does not ensure good fine-tuning performance; (2) LLM MJDs can differ in smoothness/entropy and shape (global correlations) relative to HJDs, which affects model training; (3) LLMs exhibit MCQ/order biases and may misinterpret explanation phrasing (e.g., neutral-supporting language misread as contradiction) without explicit disambiguation; (4) different LLMs produce qualitatively different MJDs (scattered large per-instance errors vs. smoother centralized distributions), so some human nuances are degraded or redistributed rather than faithfully preserved.",
            "examples_of_loss": "Concrete divergences shown in the paper: (a) Mixtral and Llama3 reach similar instance-level distances to HJD, but Mixtral's MJDs produce far worse downstream weighted F1 after fine-tuning (Mixtral fine-tuned models have lower F1 than Llama3 despite comparable KL), indicating lost training utility (Table 3, §5.2). (b) Visualization (ternary plots and pairwise error plots) show Mixtral sample points exhibit larger movements from HJD (more scattered absolute errors), while Llama3 points are more centrally smoothed (Figures 4–6, §6.1). (c) Example linguistic failure mode: phrases like 'do not mention' or 'cannot explain' (which support Neutral) can be misinterpreted by LLMs as Contradiction unless prompts include explicit 'so I choose X' clarifiers (§3.1, §5.1). (d) Uniform distributions can have low KL compared to one-hot MNLI labels but are uninformative for training — illustrating that low instance-level divergence can still represent a useless loss of signal (§6.3).",
            "counterexamples_or_caveats": "There are clear mitigations and cases where LLM judges match or help human evaluation: (1) Adding a few expert explanations substantially improves MJDs' alignment with HJDs across metrics — best setups (explicit explanations, permutation averaging, temperature smoothing) reduce KL/JSD/TVD and increase distance correlation (§5.1, Table 2). (2) Llama3 MJDs, especially with explicit explanations, produced smoother, higher-entropy distributions that improved fine-tuning performance (higher weighted F1 than MNLI/VariErr baselines) — i.e., LLM judges can outperform simpler human-derived single labels for downstream tasks if their MJDs capture useful smoothness (§5.2, §6.3). (3) Global measures (distance correlation) and visual inspection predict fine-tuning utility better than instance metrics, so combining evaluation types can recover trust in LLM judges (§6.2).",
            "paper_reference": "Title: \"Seeing the Big through the Small\": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations? — see §3 (method), §5.1 (distribution comparison, Table 2), §5.2 (fine-tuning, Table 3), §6.1-6.3 (visualization, distance correlation, analysis).",
            "uuid": "e9933.0",
            "source_info": {
                "paper_title": "\"Seeing the Big through the Small\": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mixtral MJDs",
            "name_full": "MJDs produced by Mixtral-8x7b-Instruct-v0.1",
            "brief_description": "Model-judgment distributions generated by Mixtral under multiple prompt conditions (without explanations; serial/parallel explanations; explicit explanations) and transformations (p_norm, p_sfmax, temperature scaling), compared to Chaos NLI HJDs.",
            "citation_title": "",
            "mention_or_use": "use",
            "task_domain": "Natural Language Inference (NLI)",
            "llm_judge_model": "Mixtral-8x7b-Instruct-v0.1",
            "llm_judge_setup": "MCQA prompts (A/B/C) with permutations on option labels and explanation order; p_norm or p_sfmax transformations of first-token logits; serial vs parallel feeding of up to 4 expert explanations; averaging across permutations to mitigate order bias (§3.1–3.3).",
            "human_evaluation_setup": "Comparison target: Chaos NLI HJDs (100 crowd annotators) on 341 overlapping instances; VariErr provides the 4 expert explanations used as LLM input (§4.1).",
            "agreement_metric": "Instance-level: best observed Mixtral alignment (p_sfmax + parallel explicit explanations) KL=0.217, JSD=0.208, TVD=0.232 (Table 2). Distance correlation: Mixtral p_norm baseline 0.609 -&gt; p_norm + parallel explicit 0.719 (Table 4).",
            "losses_identified": "Mixtral MJDs showed larger per-instance absolute errors (more scattered movements away from HJD) and less globally similar dataset shape compared to Llama3, leading to worse downstream classification F1 despite similar instance-level distance scores; sensitivity to number and presentation of explanations (performance decreased for Mixtral when more explanations were presented in serial mode), and MCQ/order bias requiring permutation averaging (§5.1, §6.1–6.3).",
            "examples_of_loss": "Visualizations demonstrate Mixtral points move farther from Chaos NLI HJD; Mixtral fine-tuned BERT/RoBERTa achieved substantially lower weighted F1 (e.g., BERT FT weighted F1 dev/test as low as ~0.416/0.422 for p_norm baseline) compared to Llama3-based MJDs and Chaos NLI training (§5.2, Table 3; Figures 4–6). Adding explicit explanations and choosing the correct feeding mode (parallel) improved metrics but did not eliminate scattered absolute errors (§5.1, Table 7).",
            "counterexamples_or_caveats": "Mixtral benefits substantially from explicit explanations and parallel feeding (best Mixtral fine-tuning results when using p_clmax with parallel explicit explanations: BERT weighted F1 up to 0.522/0.517, KL down to 0.095, Table 3), showing that prompt engineering and aggregation strategies can recover some losses; temperature scaling and softmax choices affect smoothness and downstream effectiveness (§5.1, §6.3, Appendix H–I).",
            "paper_reference": "See §3.1–3.3 (prompt and transformation), §5.1 (distribution comparison Table 2), §5.2 (fine-tuning Table 3), §6.1–6.3 (visualization and distance correlation).",
            "uuid": "e9933.1",
            "source_info": {
                "paper_title": "\"Seeing the Big through the Small\": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama3 MJDs",
            "name_full": "MJDs produced by Llama3-Chat-70b",
            "brief_description": "Model-judgment distributions generated by Llama3 under the same prompt/aggregation setups as Mixtral, which tended to produce smoother, higher-entropy MJDs that better preserved global dataset shape and yielded stronger downstream fine-tuning performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "task_domain": "Natural Language Inference (NLI)",
            "llm_judge_model": "Llama3-Chat-70b",
            "llm_judge_setup": "Same MCQA prompt forms and processing pipeline as Mixtral: first-token logits mapped to options, permutations and serial/parallel explanation feeding, p_norm and p_sfmax transformations; explicit-explanation prompts used to disambiguate labels where needed (§3.1–3.3).",
            "human_evaluation_setup": "Compared to Chaos NLI HJDs (100 crowd annotators) on the 341 overlapping instances; explanations drawn from VariErr's expert annotations (§4.1).",
            "agreement_metric": "Instance-level: Llama3 best observed (p_sfmax + serial explicit): KL=0.212, JSD=0.232, TVD=0.245 (Table 2). Distance correlation: Llama3 p_norm = 0.689 -&gt; +parallel explicit = 0.809 (Table 4). Fine-tuning: Llama3 MJDs produced higher weighted F1 (e.g., BERT FT weighted F1 up to ~0.582/0.586 dev/test; RoBERTa up to ~0.645/0.621) in Table 3.",
            "losses_identified": "Although Llama3 MJDs are closer overall and more useful for fine-tuning, they still differ from true HJDs in that they tend to be smoother (higher entropy), which can alter the original annotation massing (e.g., centralizing ambiguous instances) and potentially mask some specific human disagreement modes; also Llama3 can be sensitive to prompt length and benefits from serial explanation feeding, indicating differences in how it aggregates multi-annotator evidence compared to humans (§6.1–6.3).",
            "examples_of_loss": "Ternary plots show Llama3 distributions are more centralized (higher entropy) than Chaos NLI HJD though in the same general region; Llama3's smoother labels act like label smoothing and while beneficial for training, they represent a transformation of the original human variance (Figures 4–5, §6.1). Instance-level KL/JSD still non-zero, indicating residual per-instance discrepancies (Table 2).",
            "counterexamples_or_caveats": "Llama3 frequently outperformed Mixtral and other baselines in downstream fine-tuning (higher F1, better KL and CE loss after fine-tuning) — demonstrating LLMs can match or improve on human-derived signal for some purposes when provided with explanations and careful prompting; adjusting temperature (τ) produced smoother or sharper MJDs and affected fine-tuning outcomes positively in some ranges, suggesting controllable trade-offs (§6.3, Appendix H–I).",
            "paper_reference": "See §3.1–3.3 (prompt/transformation), §5.1 (distribution results Table 2), §5.2 (fine-tuning Table 3), §6.1–6.3 (visualization, distance correlation, analysis).",
            "uuid": "e9933.2",
            "source_info": {
                "paper_title": "\"Seeing the Big through the Small\": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Can large language models be an alternative to human evaluations?",
            "rating": 2
        },
        {
            "paper_title": "Can large language models capture dissenting human voices?",
            "rating": 2
        },
        {
            "paper_title": "What can we learn from collective human opinions on natural language inference data?",
            "rating": 2
        },
        {
            "paper_title": "VariErr NLI: Separating Annotation Error from Human Label Variation",
            "rating": 2
        },
        {
            "paper_title": "Ecologically valid explanations for label variation in NLI",
            "rating": 2
        },
        {
            "paper_title": "The effectiveness of LLMs as annotators: A comparative overview and empirical analysis of direct representation",
            "rating": 1
        }
    ],
    "cost": 0.01646225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>"Seeing the Big through the Small": Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations?</h1>
<p>Beiduo Chen ${ }^{\text {® }}$ Xinpeng Wang ${ }^{\text {® }}$ Siyao Peng ${ }^{\text {® }}$ Robert Litschko ${ }^{\text {® }}$ Anna Korhonen ${ }^{\text {® }}$ Barbara Plank ${ }^{\text {® }}$<br>${ }^{A}$ MaiNLP, Center for Information and Language Processing, LMU Munich, Germany Munich Center for Machine Learning (MCML), Munich, Germany<br>${ }^{\text {® }}$ Language Technology Lab, University of Cambridge, United Kingdom<br>{beiduo.chen, xinpeng.wang, siyao.peng, robert.litschko}@lmu.de<br>alk23@cam.ac.uk, b.plank@lmu.de</p>
<h4>Abstract</h4>
<p>Human label variation (HLV) is a valuable source of information that arises when multiple human annotators provide different labels for valid reasons. In Natural Language Inference (NLI) earlier approaches to capturing HLV involve either collecting annotations from many crowd workers to represent human judgment distribution (HJD) or use expert linguists to provide detailed explanations for their chosen labels. While the former method provides denser HJD information, obtaining it is resource-intensive. In contrast, the latter offers richer textual information but it is challenging to scale up to many human judges. Besides, large language models (LLMs) are increasingly used as evaluators ("LLM judges") but with mixed results, and few works aim to study HJDs. This study proposes to exploit LLMs to approximate HJDs using a small number of expert labels and explanations. Our experiments show that a few explanations significantly improve LLMs' ability to approximate HJDs with and without explicit labels, thereby providing a solution to scale up annotations for HJD. However, fine-tuning smaller soft-label aware models with the LLM-generated model judgment distributions (MJDs) presents partially inconsistent results: while similar in distance, their resulting fine-tuned models and visualized distributions differ substantially. We show the importance of complementing instance-level distance measures with a global-level shape metric and visualization to evaluate MJDs more effectively against human judgment distributions.</p>
<h2>1 Introduction</h2>
<p>In Natural Language Processing (NLP), we are faced with many situations in which more than one plausible label (or reading) exists, a phenomenon referred to as Human Label Variation (HLV, Plank 2022). HLV could be caused by inherent disagreement (Pavlick and Kwiatkowski, 2019), subjectivity (Cabitza et al., 2023), or cases where multi-
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Comparison between approaches to investigate HLV in NLI. Experts first explain the sample individually and then select a label, while crowd workers only record their choices. Explanations provide details for labels to understand HLV. However, it is not clear how to use explanations effectively to model HLV.
answers are plausible. An increasing body of work suggests that HLV provides rich information that should not be discarded as noise (e.g. Aroyo and Welty, 2015; Plank et al., 2014; Uma et al., 2021) as it impacts every step of the learning process (Plank, 2022). As one of the fundamental natural language understanding tasks, Natural Language Inference (NLI) (Dagan et al., 2005; Bowman et al., 2015; Williams et al., 2018; Manning, 2006) has embraced HLV especially (e.g. Pavlick and Kwiatkowski, 2019; Nie et al., 2020; Jiang and de Marneffe, 2022a; Zhou et al., 2022).</p>
<p>There are two common approaches to investigating HLV in NLI, illustrated in Figure 1. One way is to collect annotations from a "big" number of crowd workers (Pavlick and Kwiatkowski, 2019), enabling smoother label probabilities from a statistical standpoint to represent "collective" human opinion (Nie et al., 2020). The obtained hu-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The overall structure of our LLM approximation system. Explanations from 4 annotators in VariErr NLI (Weber-Genzel et al., 2024) are transformed with corresponding NLI samples together into multiple-choice questions, and the generated soft labels (model judgment distributions) are compared with human judgment distributions from 100 crowed workers in Chaos NLI (Nie et al., 2020). Two SOTA open-source LLMs, Mixtral (Jiang et al., 2024), and Llama3 (Meta, 2024), interpret the explanations, and we conduct comparisons on <em>distribution</em> and <em>fine-tuning</em>.</p>
<p>Human judgment distributions (HJDs) are typically soft labels suitable for model training and evaluation (Fornaciari et al., 2021a; Uma et al., 2021; Anand et al., 2024). It provides a rich resource to study and model HLV via soft labels or other methods (Uma et al., 2021; Gruber et al., 2024; Davani et al., 2022; Fornaciari et al., 2021a; Jiang and de Marneffe, 2022a). However, this annotation scheme is labor intensive, and despite offering limited insights on how label variation arises (Jiang and de Marneffe, 2022b). Contrary to the former dense HJD-based annotation, some NLI variation datasets are annotated by a "small" number of expert linguists, delivering annotated labels along with corresponding explanations shown to contain richer linguistic information than explicit labels alone (Jiang et al., 2023b; Weber-Genzel et al., 2024), as each annotator explains the label they selected. These accompanying explanations, however, are scarce, and it is not clear how to use them effectively for modeling.</p>
<p>LLMs, benefiting from enormous training data, are capable of generalizing across various tasks (Zhao et al., 2023), from text generation (Lee et al., 2023a), model distillation (Xu et al., 2024), to name a few, to more recently, functioning as "LLM judges," for example in evaluation (Chiang and Lee, 2023; Verga et al., 2024) or linguistic annotation (e.g., Ettinger et al., 2023). This suggests that LLMs can serve as a good bridge between humans and machines. In this paper, our main research questions are: <em>Can LLMs provided with a "small" number of detailed explanations better approximate the human judgment distributions collected by a "big" number of annotators?</em> If this is the case, <em>are the obtained model judgment distributions (MJDs) suitable as soft labels for fine-tuning smaller models to predict distributions?</em> To investigate these questions, we provide two sets of main experiments, as illustrated in Figure 2.</p>
<p>Experiments on <em>distribution comparison</em> show that a few explanations can improve the capabilities of LLMs to approximate human judgment distributions among various metrics. To demonstrate the practical significance of the generated MJDs from our method, we applied them in a <em>fine-tuning comparison</em> to train pre-trained transformer models such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019). Interestingly, our analysis shows that the effectiveness of the generated MJDs serving as fine-tuning data cannot be predicted well by <em>distribution comparison</em>. We hypothesize that instance-level measures, e.g., KL Divergence (Kullback and Leibler, 1951) and Jensen-Shannon Distance (Endres and Schindelin, 2003), overlook the dependencies across sample points, which captures the global-level HLV useful for training models. Therefore, we utilize distance correlation (Székely et al., 2007) to measure the global-level association between the generated MJDs over the whole dataset and the corresponding target HJD. We empirically show that distance correlation can reliably predict the performance of MJDs on <em>fine-tuning comparison</em>, as supported by visual investigations. All our code is available at https://github.com/mainlp/MJD-Estimator for reproduction.</p>
<h2>2 Related Work</h2>
<p>Human label variation Human label variation represents a phenomenon in which inherent disagreement exists in annotation due to genuine disagreement, subjectivity or simply because two (or</p>
<p>more) views are plausible (Plank, 2022). Aroyo and Welty (2015) propose that disagreement is not noise but signal, which is giving us information, as human labels are bound to be scarce yet at the same time critical as they provide human interpretations and values. With substantial datasets, providing many judgments by high-quality coders for each item, training directly with soft labels achieved better results than training from aggregated or even gold labels (Uma et al., 2021). For example, Fornaciari et al. (2021b) find that the soft-label prediction auxiliary task reduces the penalty for errors on ambiguous entities and thereby mitigates overfitting. Thus, Pavlick and Kwiatkowski (2019) argue for a refined evaluation objective that requires models to explicitly capture the full distribution of plausible human judgments.</p>
<p>Human label variation in NLI For NLI—the task to determine whether a given premise entails, contradicts, or is neutral towards a target hypothesis—there exist several datasets addressing human label variation (HLV). On the one hand, Variation NLI (Pavlick and Kwiatkowski, 2019) and Chaos NLI (Nie et al., 2020) collect annotations from 50 and 100 crowd workers for human judgment distributions (HJDs). On the other, Live NLI (Jiang et al., 2023b) and VariErr NLI (Weber-Genzel et al., 2024) are annotated by only 5 or 4 linguists, but add textual explanations to their NLI labels. While these works have used NLI with explanations, their goals differ: either to unravel more on reasons for disagreement from the annotators (Jiang et al., 2023b) or to use explanations to facilitate separation of plausible variation from annotation errors (Weber-Genzel et al., 2024). However, little research has been done on estimating HJDs from a few labels and explanations.</p>
<p>Human explanations &amp; LLM estimators Human explanations, particularly ecologically valid ones where the same annotator provides both the label and explanation (Jiang et al., 2023b), are effective in improving LLMs' performance (Wei et al., 2022b; Lampinen et al., 2022). Wadhwa et al. (2023) investigate the levels of missing information in a provided answer for a target question in the context of a given article. They use LLMs to rescale the coarse-grained (4-level) labels and accompanying explanations to a 100-point scale and compare them with manually annotated HJDs. Pavlovic and Poesio (2024) use GPT-3.5 to estimate HJDs directly, but in contrast to us focus on datasets with inherently subjective NLP tasks provided by the SemEval 2023 shared task 11 (Leonardelli et al., 2023). Their exploration shows that GPT-3.5 tends to produce distributions not well aligned with HJDs for subjective tasks.</p>
<p>LLMs are also employed on the two NLI datasets with explanations. Jiang et al. (2023b) prompt GPT-3 to predict labels and generate explanations on LiveNLI items. They show that the predict-then-explain (post-prediction explanation) strategy significantly outperforms explain-then-predict (chain-of-thought prompting). They also observe through qualitative analysis that over half of the LLM-generated explanations lack informativeness, i.e., only restate the premise/hypothesis. Weber-Genzel et al. (2024) ask GPT-3.5 and GPT-4 to judge the probability of whether individual explanations in VariErr make sense for the corresponding NLI labels. Results show that GPT-4 outperforms traditional error detection methods, but the latter only evaluate the labels without factoring in the explanations, leaving several questions open.</p>
<p>Lee et al. (2023b) is the closest to our work. They propose an LLM Distribution Estimator that reads premise-hypothesis pairs and generates label distributions. However, their MJDs align poorly with HJDs. Moreover, explanation-contained NLI datasets were not yet available when Lee et al. (2023b) was published. Our paper bridges the recently released detailed explanation annotations with LLMs to estimate HJD on NLI efficiently.</p>
<h2>3 LLMs to Estimate HJDs</h2>
<p>As LLM outputs are typically in text form and fluctuate based on inputs and parameters, obtaining model judgment distributions (MJDs) directly from the outputs to approximate human judgment distributions (HJDs) is challenging. We propose LLM prompts with multiple-choice questions (§3.1), to illustrate how we estimate MJD using first-token probability (§3.2) and reduce biases via permutations of choice options and explanations (§3.3).</p>
<h3>3.1 Prompt Types</h3>
<p>To facilitate asking LLMs to estimate MJDs, we transform the NLI problem into a multiple-choice question answering (MCQA) prompt, selecting one answer from the three options [A, B, C]. The prompts are shown in detail in Table 5 in Appendix</p>
<p><sup>1</sup>In preliminary experiments, we found that directly asking LLMs for MJDs was challenging. We also found another interesting prompt format in Appendix J.</p>
<p>A. We design three prompt types: a base prompt "without explanations", a prompt "with explanations", and one "with explicit explanations" which contains both label and explanation.</p>
<p>Without explanation Our base prompt informs LLMs about the NLI task, provides the premise and hypothesis of NLI instances and instructs the LLMs to choose an NLI label via a MCQA format. We constrain the label selection space by asking LLMs to "select ONE of the listed options" and restrict the initial letter of the output to one of $[\mathrm{A}, \mathrm{B}, \mathrm{C}]$ by instructing "start your answer with a single letter."</p>
<p>With explanations This prompt incorporates human explanations of label choices as "comments" without disclosing the annotators' chosen labels directly. Specifically, we place these comments in the prompt after the hypothesis and premise but before the MCQA part.</p>
<p>With explicit explanations This prompt type reveals the NLI labels in addition to the corresponding explanations to the LLMs. Our preliminary experiments found that LLMs sometimes misinterpret phrases that support a Neutral label (e.g., "do not mention" or "cannot explain") as supporting a Contradiction label. Therefore, we include a prompt type where the corresponding explanation by the annotator is appended with the phrase "so I choose X" to clarify the intended NLI label.</p>
<h3>3.2 First-token Probability</h3>
<p>Conditioned by the prompts above, we next map LLMs' output from [A,B,C] to probabilities as MJDs. In particular, we set up a one-to-one mapping $f: O \rightarrow L$ from the option set $O$ to the label space $L$, where $O={A, B, C}$ and $L={$ Entailment, Neutral, Contradiction $}$ with permutations on both $O$ and $L$ (cf. §3.3).</p>
<p>Denote the text output of LLMs as a list of words $\boldsymbol{w}=\left[w_{1}, w_{2}, \ldots, w_{k}\right], w_{i} \in V$ where $k$ is the length of the text output and $V$ is the vocabulary used for LLMs. We extract the logits of the first-token $w_{1}$ before the decoding process as $\boldsymbol{s}<em 1="1">{w</em>}}=\left[s_{w_{1}}, s_{w_{2}}, \ldots, s_{w_{k}}, s_{w_{k+1}}, \ldots, s_{w_{n}}\right], w_{i} \in V$ where $n$ is the vocabulary size. As shown in Figure 2, we only use part of the first-token logits $\boldsymbol{s<em 1="1">{w</em>}}^{O}=\left[s_{A}, s_{B}, s_{C}\right]$ which present the distribution scores of the option set $O$. To transform $\boldsymbol{s<em 1="1">{w</em>$}}^{O}$ into a probability distributions $\boldsymbol{p}^{O}$, we utilize normalization and softmax (with temperature $\tau$ ) functions: ${ }^{2</p>
<p>$$
\begin{gathered}
p_{\text {norm }}^{O}(j)=\frac{s_{j}}{\sum_{j}^{|O|} s_{j}} \
p_{\text {sfmax }}^{O}(j)=\frac{\exp \left(s_{j} / \tau\right)}{\sum_{j}^{|O|} \exp \left(s_{j} / \tau\right)}
\end{gathered}
$$</p>
<p>Finally, we obtain the model judgement distribution $\boldsymbol{p}^{L}$ through the mapping function $f$ :</p>
<p>$$
\boldsymbol{p}^{L}=f\left(\boldsymbol{p}^{O}\right)
$$</p>
<h3>3.3 Bias Consideration</h3>
<p>Previous studies (e.g., Dominguez-Olmedo et al., 2023; Zheng et al., 2024; Tjuatja et al., 2023) reveal that LLMs are biased when processing multiplechoice questions, such as preferring the first option A. To address this, we shuffle the option set $O$ of the mapping relationship $f$, totaling $A\binom{3}{3}=6$ permutations. We ask LLMs to process all permutations, thus averaging all MJDs obtained to mitigate bias. Namely, each of the three NLI labels has been mapped to option A, reducing biases caused by the initial letters of the options. Moreover, the order of multiple explanations may also exert unequal influence on LLMs, as shown in a case study in Appendix K. To address this bias, we adopt two ways to feed explanations (i.e., "comments") to the LLMs: "serial" and "parallel" modes.</p>
<p>Serial mode We input all explanations together to LLMs as in the prompt shown in Table 5, asking LLMs to process them at once. To mitigate the bias caused by the position of the explanations in the prompt, we shuffle the order of all $m$ explanations with full permutations $A\binom{m}{m}$ and use the average output as the model's final answer.</p>
<p>Parallel mode We feed one explanation (i.e., "comment") at a time under the "parallel" mode to the prompt. Namely, to process $m$ explanation annotations on an NLI item, we create $m$ prompts and ask LLMs to handle them separately. We then average the $m$ outputs to obtain the final MJD. Although this approach prevents LLMs from obtaining an overall impression of all explanations, it allows them to focus more on interpreting each explanation and significantly reduces the computational cost from $A\binom{m}{m}$ ("serial") to $m$ ("parallel").</p>
<p>| Datasets | |Samples| | |Valid overlap| | $\mid$ Annotators| | Explanations | Description |
| :-- | :--: | :--: | :--: | :--: | :--: |
| MNLI (Williams et al., 2018) | 433 k | 341 | 1 or 5 | $\boldsymbol{X}$ | Majority with single label, subset with 5. |
| VariErr NLI (Weber-Genzel et al., 2024) | 500 | 341 | 4 | $\checkmark$ | Ecologically valid explanations. |
| MNLI subset of Chaos NLI (Nie et al., 2020) | 1,599 | 341 | 100 | $\boldsymbol{X}$ | Human judgment distributions. |</p>
<p>Table 1: Datasets statistics. Numbers represent either the sample count or the annotator count.</p>
<h2>4 Experimental Setup</h2>
<h3>4.1 Datasets</h3>
<p>We experiment with two NLI datasets containing HLV, Chaos NLI (Nie et al., 2020) and VariErr NLI (Weber-Genzel et al., 2024). The former contains 1,599 MNLI (Williams et al., 2018) instances with HJDs collected from 100 crowd workers. In contrast, the latter contains 500 MNLI instances randomly sampled from Chaos NLI re-annotated with explanations and labels by 4 expert linguists. Note that the source MNLI corpus is much larger than Chaos NLI and VariErr NLI, ${ }^{3}$ and is used only for pre-training of the fine-tuning experiments. To ensure fairness and to facilitate follow-up analyses, we focus our comparisons on a subset of 341 VariErr items that receive exactly 4 explanation annotations. ${ }^{4}$ Table 1 presents detailed data statistics.</p>
<h3>4.2 Models</h3>
<p>We utilized two open-source instruction-tuned LLMs: Mixtral-8x7b-Instruct-v0.1 (Jiang et al., 2024) and Llama3-Chat-70b (Meta, 2024). We adopt the original chat templates for both models and set the parameter do_sample=False in decoding to ensure consistent outputs for the same input. Discussion regarding the risk of data leakage is elaborated in Appendix G.</p>
<h3>4.3 Distribution Comparison</h3>
<p>Our first experiment compares the LLM-derived MJDs to the HJDs. To derive MJDs, we fed LLMs with the three prompt types exemplified in Table 5 in the Appendix using the 341 VariErr instances. We then compare the resulting MJD to the HJDs of the corresponding Chaos NLI instances. We investigate these distribution differences between humans and LLMs at the instance level following prior work (Nie et al., 2020; Chiang and Lee,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>2023; Lee et al., 2023b): Kullback-Leibler Divergence (KL, Kullback and Leibler 1951) and JensenShannon Distance (JSD, Endres and Schindelin 2003). In addition, we follow Baan et al. (2022) to measure the human Distribution Calibration Error, namely measured as Total Variation Distance (TVD, Devroye and Lugosi 2001) between MJDs and HJDs. MNLI single labels were transformed into one-hot vectors to compute the metrics.</p>
<h3>4.4 Fine-tuning Comparison</h3>
<p>Our second experiment investigates how well the resulting MJDs approximate human labels for model training. To do so, we compare the generated MJDs and original HJDs to annotated labels of the parallel instances in MNLI, VariErr NLI and Chaos NLI, for fine-tuning smaller language models, namely, BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) base. These models were first fine-tuned on the large single-labelled MNLI dataset to learn the generic NLI task. We then few-shot-tune them on the HJDs or MJDs above; see Appendix B for fine-tuning details.</p>
<p>To evaluate the resulting classifiers, we split the remaining 1,258 MNLI instances from Chaos NLI that do not overlap with VariErr NLI into the development and test sets. We use KL and weighted F1 scores as evaluation metrics between the outputs of the fine-tuned models and HJDs from Chaos NLI. All metrics are detailed in Appendix C.</p>
<h2>5 Results</h2>
<h3>5.1 Distribution Comparison</h3>
<p>Table 2 presents the distribution comparison results. Firstly, we analyze baseline HJDs and observe that the MNLI single-label data (i.e., with no HLV) is the farthest from Chaos NLI's HJD, followed by MNLI and VariErr distributions. We add a distribution comparison to the uniform distribution as a sanity check to understand the obtained MJDs.</p>
<p>When comparing MJDs, we observe that for the "without explanation" prompt, Llama3 is closer than Mixtral to Chaos NLI HJD. However, both models benefit from adding explanations, i.e., their MJDs gradually get closer to the HJD. The two</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Distributions\Metrics</th>
<th style="text-align: center;">KL $\downarrow$</th>
<th style="text-align: center;">JSD $\downarrow$</th>
<th style="text-align: center;">TVD $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Baseline</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Chaos NLI</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: left;">MNLI single label</td>
<td style="text-align: center;">9.288</td>
<td style="text-align: center;">0.422</td>
<td style="text-align: center;">0.435</td>
</tr>
<tr>
<td style="text-align: left;">MNLI distributions</td>
<td style="text-align: center;">1.242</td>
<td style="text-align: center;">0.281</td>
<td style="text-align: center;">0.295</td>
</tr>
<tr>
<td style="text-align: left;">VariErr distributions</td>
<td style="text-align: center;">3.604</td>
<td style="text-align: center;">0.282</td>
<td style="text-align: center;">0.296</td>
</tr>
<tr>
<td style="text-align: left;">Uniform distribution</td>
<td style="text-align: center;">0.364</td>
<td style="text-align: center;">0.307</td>
<td style="text-align: center;">0.350</td>
</tr>
<tr>
<td style="text-align: left;">MJDs from Mixtral</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">$\boldsymbol{p}_{\text {norm }}$ of Mixtral</td>
<td style="text-align: center;">0.433</td>
<td style="text-align: center;">0.291</td>
<td style="text-align: center;">0.340</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explanations</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">0.265</td>
<td style="text-align: center;">0.306</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.382</td>
<td style="text-align: center;">0.246</td>
<td style="text-align: center;">0.286</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explanations</td>
<td style="text-align: center;">0.339</td>
<td style="text-align: center;">0.258</td>
<td style="text-align: center;">0.295</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">$\mathbf{0 . 2 4 5}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 1 1}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 3 9}$</td>
</tr>
<tr>
<td style="text-align: left;">$\boldsymbol{p}_{\text {sfmax }}$ of Mixtral</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">0.292</td>
<td style="text-align: center;">0.342</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explanations</td>
<td style="text-align: center;">0.349</td>
<td style="text-align: center;">0.258</td>
<td style="text-align: center;">0.296</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.235</td>
<td style="text-align: center;">0.269</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explanations</td>
<td style="text-align: center;">0.310</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.290</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">$\mathbf{0 . 2 1 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 0 8}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 3 2}$</td>
</tr>
<tr>
<td style="text-align: left;">MJDs from Llama3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">$\boldsymbol{p}_{\text {norm }}$ of Llama3</td>
<td style="text-align: center;">0.259</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.284</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explanations</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.259</td>
<td style="text-align: center;">0.281</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explicit explanations</td>
<td style="text-align: center;">$\mathbf{0 . 2 3 5}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 4 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 6 6}$</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explanations</td>
<td style="text-align: center;">0.257</td>
<td style="text-align: center;">0.261</td>
<td style="text-align: center;">0.283</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.253</td>
<td style="text-align: center;">0.273</td>
</tr>
<tr>
<td style="text-align: left;">$\boldsymbol{p}_{\text {sfmax }}$ of Llama3</td>
<td style="text-align: center;">0.231</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.260</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explanations</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.258</td>
</tr>
<tr>
<td style="text-align: left;">+ "serial" explicit explanations</td>
<td style="text-align: center;">$\mathbf{0 . 2 1 2}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 3 2}$</td>
<td style="text-align: center;">$\mathbf{0 . 2 4 5}$</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explanations</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.260</td>
</tr>
<tr>
<td style="text-align: left;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">0.254</td>
</tr>
</tbody>
</table>
<p>Table 2: Distribution comparison results. MJDs and HJDs are compared on 341 overlapping instances.</p>
<p>LLMs reach similar scores overall, exceeding those of MNLI and VariErr distributions regardless of whether the transformation method is $\boldsymbol{p}<em _sfmax="{sfmax" _text="\text">{\text {norm }}$ or $\boldsymbol{p}</em>$. Mixtral benefits more from the additional information (KL/JSD/TVD drop more from its base), and the best setup uses explicit explanations.}</p>
<p>Parallel vs serial Regarding bias considerations, the two LLMs exhibit slightly different patterns. "Serial" mode is better for Llama, while "parallel" suits Mixtral. "Serial" mode intuitively feels better because it provides multiple explanations at the same time, allowing models to estimate each label relative to all other labels and explanations. For example, LLMs may discriminate which explanation is more convincing and thus favor the label indicated by that explanation. We conduct an ablation study by adding $4,3,2$, or 1 explanations at a time to LLM prompts. However, Figure 3 shows that adding more explanations to a prompt makes the Mixtral MJDs less similar to HJD but more for Llama3 MJDs. The distribution similarity be-
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Distribution comparison results. "n in one" denotes the way LLMs process $n$ explanations at a time.
tween Mixtral MJDs and HJDs seems to gradually decrease as the number of input explanations increases, whereas Llama3 shows almost no fluctuation and even performs better with longer texts. We hypothesize that Llama3 is better at longer prompts. More detailed scores are listed in Table 7 in Appendix D.</p>
<h3>5.2 Fine-tuning Comparison</h3>
<p>We present results on fine-tuning smaller models and comparing their MJDs to the HJDs on the heldout Chaos NLI dev and test sets. As comparison to LLM-predicted HJDs, we also train models on the existing datasets; see Table 3 for the results. All detailed scores of fine-tuning comparison are in Table 8 and Table 9 in Appendix E.</p>
<p>Models trained on the Chaos NLI train set perform best, noticeably higher than MNLI and VariErr models. Regarding the KL and CE Loss metrics, both LLMs demonstrate strong approximation performance, approaching Chaos NLI more closely than MNLI or VariErr NLI. Mixtral gets slightly better KL and CE Loss on "parallel", while Llama3 wins on "serial", mirroring results in $\S 5.1$.</p>
<p>However, fine-tuned LLM models show divergent results on F1. Overall, adding explicit explanations contributes to the best models. Llama3 improves fine-tuning results by yielding closer MJD to HJD and achieving better F1 scores than MNLI/VariErr HJDs. In contrast, while Mixtral only achieves slightly worse results in distribution comparison, it is much inferior in F1 score, even be-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Distributions</th>
<th style="text-align: center;">BERT FT (dev / test)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RoBERTa FT (dev / test)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
</tr>
<tr>
<td style="text-align: center;">Baseline</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Chaos NLI train set</td>
<td style="text-align: center;">0.626 / 0.646</td>
<td style="text-align: center;">0.074 / 0.077</td>
<td style="text-align: center;">0.972 / 0.974</td>
<td style="text-align: center;">0.699 / 0.650</td>
<td style="text-align: center;">0.061 / 0.067</td>
<td style="text-align: center;">0.932 / 0.943</td>
</tr>
<tr>
<td style="text-align: center;">MNLI single label</td>
<td style="text-align: center;">0.561 / 0.589</td>
<td style="text-align: center;">0.665 / 0.704</td>
<td style="text-align: center;">2.743 / 2.855</td>
<td style="text-align: center;">0.635 / 0.603</td>
<td style="text-align: center;">0.844 / 0.867</td>
<td style="text-align: center;">3.281 / 3.344</td>
</tr>
<tr>
<td style="text-align: center;">MNLI distributions</td>
<td style="text-align: center;">0.546 / 0.543</td>
<td style="text-align: center;">0.099 / 0.102</td>
<td style="text-align: center;">1.046 / 1.048</td>
<td style="text-align: center;">0.613 / 0.604</td>
<td style="text-align: center;">0.100 / 0.096</td>
<td style="text-align: center;">1.047 / 1.029</td>
</tr>
<tr>
<td style="text-align: center;">VariErr distributions</td>
<td style="text-align: center;">0.557 / 0.559</td>
<td style="text-align: center;">0.179 / 0.186</td>
<td style="text-align: center;">1.286 / 1.299</td>
<td style="text-align: center;">0.617 / 0.589</td>
<td style="text-align: center;">0.174 / 0.197</td>
<td style="text-align: center;">1.269 / 1.333</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Mixtral</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {norm }}$ of Mixtral</td>
<td style="text-align: center;">0.416 / 0.422</td>
<td style="text-align: center;">0.134 / 0.133</td>
<td style="text-align: center;">1.152 / 1.142</td>
<td style="text-align: center;">0.486 / 0.466</td>
<td style="text-align: center;">0.123 / 0.127</td>
<td style="text-align: center;">1.118 / 1.123</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.443 / 0.454</td>
<td style="text-align: center;">0.145 / 0.141</td>
<td style="text-align: center;">1.183 / 1.166</td>
<td style="text-align: center;">0.509 / 0.514</td>
<td style="text-align: center;">0.128 / 0.128</td>
<td style="text-align: center;">1.132 / 1.126</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.506 / 0.511</td>
<td style="text-align: center;">0.130 /0.130</td>
<td style="text-align: center;">1.139 / 1.132</td>
<td style="text-align: center;">0.569 / 0.572</td>
<td style="text-align: center;">0.114 / 0.122</td>
<td style="text-align: center;">1.091 / 1.107</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.404 / 0.428</td>
<td style="text-align: center;">0.134 / 0.131</td>
<td style="text-align: center;">1.150 / 1.136</td>
<td style="text-align: center;">0.483 / 0.502</td>
<td style="text-align: center;">0.123 / 0.122</td>
<td style="text-align: center;">1.118 / 1.109</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.507 / 0.514</td>
<td style="text-align: center;">0.108 / 0.108</td>
<td style="text-align: center;">1.074 / 1.065</td>
<td style="text-align: center;">0.558 / 0.565</td>
<td style="text-align: center;">0.092 / 0.098</td>
<td style="text-align: center;">1.025 / 1.037</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Mixtral</td>
<td style="text-align: center;">0.427 / 0.432</td>
<td style="text-align: center;">0.131 / 0.129</td>
<td style="text-align: center;">1.140 / 1.130</td>
<td style="text-align: center;">0.497 / 0.472</td>
<td style="text-align: center;">0.121 / 0.125</td>
<td style="text-align: center;">1.112 / 1.118</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.452 / 0.462</td>
<td style="text-align: center;">0.121 / 0.118</td>
<td style="text-align: center;">1.113 / 1.096</td>
<td style="text-align: center;">0.506 / 0.525</td>
<td style="text-align: center;">0.110 / 0.109</td>
<td style="text-align: center;">1.078 / 1.069</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.509 / 0.520</td>
<td style="text-align: center;">0.105 / 0.105</td>
<td style="text-align: center;">1.064 / 1.057</td>
<td style="text-align: center;">0.568 / 0.573</td>
<td style="text-align: center;">0.093 / 0.098</td>
<td style="text-align: center;">1.026 / 1.036</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.397 / 0.429</td>
<td style="text-align: center;">0.121 / 0.119</td>
<td style="text-align: center;">1.112 / 1.098</td>
<td style="text-align: center;">0.497 / 0.505</td>
<td style="text-align: center;">0.110 / 0.111</td>
<td style="text-align: center;">1.079 / 1.074</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.522 / 0.517</td>
<td style="text-align: center;">0.095 / 0.095</td>
<td style="text-align: center;">1.035 / 1.026</td>
<td style="text-align: center;">0.567 / 0.576</td>
<td style="text-align: center;">0.082 / 0.087</td>
<td style="text-align: center;">0.994 / 1.003</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Llama3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {norm }}$ of Llama3</td>
<td style="text-align: center;">0.514 / 0.526</td>
<td style="text-align: center;">0.097 / 0.098</td>
<td style="text-align: center;">1.038 / 1.036</td>
<td style="text-align: center;">0.541 / 0.528</td>
<td style="text-align: center;">0.091 / 0.094</td>
<td style="text-align: center;">1.023 / 1.025</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.574 / 0.574</td>
<td style="text-align: center;">0.096 / 0.097</td>
<td style="text-align: center;">1.037 / 1.033</td>
<td style="text-align: center;">0.618 / 0.601</td>
<td style="text-align: center;">0.091 / 0.093</td>
<td style="text-align: center;">1.020 / 1.022</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.578 / 0.574</td>
<td style="text-align: center;">0.091 / 0.092</td>
<td style="text-align: center;">1.022 / 1.018</td>
<td style="text-align: center;">0.634 / 0.598</td>
<td style="text-align: center;">0.085 / 0.088</td>
<td style="text-align: center;">1.003 / 1.006</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.573 / 0.582</td>
<td style="text-align: center;">0.098 / 0.098</td>
<td style="text-align: center;">1.041 / 1.038</td>
<td style="text-align: center;">0.636 / 0.598</td>
<td style="text-align: center;">0.093 / 0.095</td>
<td style="text-align: center;">1.026 / 1.028</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.582 / 0.586</td>
<td style="text-align: center;">0.094 / 0.095</td>
<td style="text-align: center;">1.030 / 1.026</td>
<td style="text-align: center;">0.639 / 0.620</td>
<td style="text-align: center;">0.089 / 0.091</td>
<td style="text-align: center;">1.014 / 1.016</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Llama3</td>
<td style="text-align: center;">0.528 / 0.524</td>
<td style="text-align: center;">0.091 / 0.093</td>
<td style="text-align: center;">1.023 / 1.021</td>
<td style="text-align: center;">0.546 / 0.535</td>
<td style="text-align: center;">0.085 / 0.089</td>
<td style="text-align: center;">1.005 / 1.009</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.567 / 0.576</td>
<td style="text-align: center;">0.091 / 0.091</td>
<td style="text-align: center;">1.021 / 1.016</td>
<td style="text-align: center;">0.626 / 0.608</td>
<td style="text-align: center;">0.082 / 0.086</td>
<td style="text-align: center;">0.996 / 1.000</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.585 / 0.568</td>
<td style="text-align: center;">0.086 / 0.087</td>
<td style="text-align: center;">1.008 / 1.004</td>
<td style="text-align: center;">0.646 / 0.610</td>
<td style="text-align: center;">0.077 / 0.081</td>
<td style="text-align: center;">0.981 / 0.987</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.584 / 0.583</td>
<td style="text-align: center;">0.092 / 0.093</td>
<td style="text-align: center;">1.024 / 1.020</td>
<td style="text-align: center;">0.643 / 0.611</td>
<td style="text-align: center;">0.085 / 0.089</td>
<td style="text-align: center;">1.004 / 1.008</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.581 / 0.578</td>
<td style="text-align: center;">0.088 / 0.089</td>
<td style="text-align: center;">1.014 / 1.010</td>
<td style="text-align: center;">0.645 / 0.621</td>
<td style="text-align: center;">0.081 / 0.085</td>
<td style="text-align: center;">0.993 / 0.996</td>
</tr>
</tbody>
</table>
<p>Table 3: Results of fine-tuning comparison on Chaos NLI dev/test set. The KL and Cross-Entropy (CE) Loss reflected the distance between distributions, whereas Weighted F1 reflected the capability in handling NLI problems.
low that of MNLI/VariErr HJDs. The next section investigates this discrepancy in LLM performances between distribution and fine-tuning comparisons.</p>
<h2>6 Analysis and Discussion</h2>
<p>We observe from $\S 5$ that even though Llama3 and Mixtral are equally similar to Chaos NLI HJDs in distribution comparisons (see Table 2), their finetuned F1 scores differ, with Llama3 MJDs achieving a higher F1 than MNLI/VariErr HJDs while Mixtral being lower (see Table 3). We further inspect these distributions visually (§6.1) and using distance correlation (§6.2). We then explore the potential causes for the observed differences (§6.3). Finally, we highlight the contributions of this paper and suggest future directions for reference (§6.4).</p>
<h3>6.1 Visualization</h3>
<p>To inspect MJDs against HJD, we use the visualization tool by Gruber et al. (2024) to plot each instance's distribution in the ternary plot. For consistency, we focus on a single setting with "explicit
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Visualization of distributions in ternary plot. Each point represents one of the 341 samples.
explanations" prompt, "parallel" mode, and $\boldsymbol{p}_{\text {norm }}$ transformation. Figure 4 compares the Chaos NLI HJD to Mixtral and Llama3's MJDs. Interestingly, Llama3 and Mixtral exhibit rather different clusters: Llama3 has an overall higher entropy with instances closer to the center, whereas Mixtral is seemingly closer to the Chaos NLI HJD. We also see that the original Chaos NLI HJD is slightly skewed towards Contradiction, i.e., the right side of the triangle, while Mixtral MJD is slightly skewed towards Entailment, i.e., the opposite left side. Figure 5 further zooms in on Llama3 MJD and shows that Llama3 is slightly skewed towards the right</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Zooming in (<em>scale=3.3</em>) on Llama3 MJD.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Error visualization. Corresponding sample points from the MJD and Chaos NLI HJD connected by a green line. Darker green means more distant.</p>
<p>side (Contradiction), more in line with Chaos NLI.</p>
<h3>Pairwise distance plots</h3>
<p>While triangle plots provide insights on the overall distributions, they lack information regarding <em>how far</em> a particular instance (sample point) is in MJD, e.g., <em>[E=0.4, N=0.5, C=0.1]</em> from its correspondence in the HJD. Therefore, we calculate and visualize pair-wise distances (or errors) between the corresponding sample points in MJDs and Chaos NLI HJDs. Namely, if many samples "moved" dramatically from an HJD to an MJD, this is a worse MJD estimation.</p>
<p>Figure 6 illustrates that Mixtral MJD has more substantial movements, i.e., erroneous estimates, than Llama3 MJD to Chaos NLI HJD. Figure 7 in Appendix F further provides pairwise error comparisons and shows that the absolute errors of Mixtral are scattered while Llama3 errors are more concentrated. These observations motivate us to look for a more suitable error measure in §6.2.</p>
<h3>6.2 Quantifying the Visual Observations: Distance Correlation</h3>
<p>Visualizations clearly show that, compared to Mixtral, the MJDs produced by Llama3 exhibit shapes more similar to HJDs, which corroborates Llama's superior performance in fine-tuning comparisons. Given that the previous metrics used in <em>distribution comparison</em> are focusing on instance-level, while visualizations represent the distribution of all data points, we propose to further evaluate MJDs against HJDs using a global-level measure, distance correlation (D.Corr, Székely et al. 2007), to capture the differences between general distributions.</p>
<table>
<thead>
<tr>
<th>Distributions\Metrics</th>
<th>D.Corr ↑</th>
</tr>
</thead>
<tbody>
<tr>
<td>Uniform distribution</td>
<td>0</td>
</tr>
<tr>
<td>MNLI single label</td>
<td>0.612</td>
</tr>
<tr>
<td>MNLI distributions</td>
<td>0.795</td>
</tr>
<tr>
<td>VariErr distributions</td>
<td>0.688</td>
</tr>
<tr>
<td>MJDs from Mixtral</td>
<td></td>
</tr>
<tr>
<td>p norm of Mixtral</td>
<td>0.609</td>
</tr>
<tr>
<td>+ "parallel" explicit explanations</td>
<td>0.719</td>
</tr>
<tr>
<td>p dmax of Mixtral</td>
<td>0.593</td>
</tr>
<tr>
<td>+ "parallel" explicit explanations</td>
<td>0.709</td>
</tr>
<tr>
<td>MJDs from Llama3</td>
<td></td>
</tr>
<tr>
<td>p norm of Llama3</td>
<td>0.689</td>
</tr>
<tr>
<td>+ "parallel" explicit explanations</td>
<td>0.809</td>
</tr>
<tr>
<td>p dmax of Llama3</td>
<td>0.677</td>
</tr>
<tr>
<td>+ "parallel" explicit explanations</td>
<td>0.802</td>
</tr>
</tbody>
</table>
<p>Table 4: Distance Correlation (D.Corr) on distribution comparisons between MJDs and Chaos NLI HJD. A higher correlation indicates better performance.</p>
<p>We consider all the samples' soft labels from a dataset as a 3-D array. The D.Corr between the source dataset <em>X</em> and the target dataset <em>Y</em> is calculated as:</p>
<p>$$dCor^2(X, Y) = \frac{dCov^2(X, Y)}{\sqrt{dVar^2(X) dVar^2(Y)}}.\qquad (4)$$</p>
<p>where <em>dCov²(X, Y)</em> means the distance covariance of the two arrays, and <em>dVar</em> means the distance standard deviation of the array.</p>
<p>This measure accounts for all soft labels across the dataset and thus should be considered a global measure of the overall datasets. Results from Table 4 show that Llama3 MJDs have a substantially higher distance correlation with Chaos NLI's HJD than Mixtral. This further proves Llama3 is globally better aligned with the HJD than Mixtral and supports its better fine-tuning performances. Appendix I shows more results with different temperatures <em>τ</em> and numbers of explanations.</p>
<h3>6.3 Why did the Llama3 MJD Work Better than Mixtral's in Fine-tuning?</h3>
<p>To sum up, both the visualization in §6.1 and distance correlations in §6.2 provide additional insights into the differences between Mixtral's and Llama3's MJDs. We hypothesize that one advantage of the Llama3-generated soft labels is its <strong>smoothness</strong>. As the benefit of label smoothness for model training has been validated extensively in the past (Müller et al., 2019; Wei et al., 2022a), when we observe that Llama3's MJD has a smoother</p>
<p>distribution, we then assume that smoother labels could be beneficial based on intuition from previous papers. The overall higher entropy of the Llama3 non-scaled MJD (used for fine-tuning) has a regularizing effect similar to label smoothing. In other words, Llama3-generated MJD looks similar to the temperature-scaled (i.e., squished, within a certain range of $\tau$ ) version of Chaos NLI. Appendix H further visualizes $\boldsymbol{p}_{\text {sfmax }}$-transformed Llama3 MJDs with $\tau$ in [5, 10, 20]. From the D.Corr results in Table 11 in Appendix I, we indeed found that higher $\tau$-values (smoother label distributions) can lead to better scores with $\tau$ from 5, 10 to 20. This somehow supports our hypothesis that smoothness might be beneficial.</p>
<p>It is important to note that instance-level distribution distance measures such as KL and JSD cannot reliably predict models' performance when fine-tuned on the generated MJDs. A lower KL divergence cannot guarantee that it contains more information for fine-tuning. In the most extreme case, the KL divergence between a uniform random distribution and Chaos NLI is 0.364 , much lower than the one-hot distribution on MNLI (0.665), while providing no helpful information for training. By further inspecting the visualization result, we hypothesize that the second advantage of the Llama3generated soft labels is the shape of the sample distribution. That means the cross-sample dependency of the Llama3-generated soft labels is more similar to Chaos NLI than that of Mixtral. One way to capture this cross-sample dependency is to calculate a distance matrix recording the distances between every sample pair in the MJD.</p>
<p>To compare the global level similarity between the generated and the target dataset, we thus proposed to use visual inspections and measure the distance correlation, which measures the distance matrix in the covariance. We empirically show that distance correlation can better reflect the effectiveness of the generated MJDs for fine-tuning. This led us to conclude that metrics like KL, JSD, and TVD, which measure the distance between distributions at the instance level, are better complemented by additional investigations on the shape of the resulting annotations using visualization techniques and global measures.</p>
<h3>6.4 Potential benefits beyond NLI</h3>
<p>In this study we validate the effectiveness of our approach on NLI. Given that NLI requires different linguistic capabilities (Wang et al., 2019) such as,
e.g., reasoning about word order, or understanding active/passive voice, we strongly believe that our findings generalize to other NLP tasks requiring similar capabilities. We aim to extend our study to other tasks in future work.</p>
<p>Furthermore, for a large number of tasks, constructing HLV datasets requires extensive annotation by crowd workers to obtain HJDs. This paper explores a method that only needs a small number of explanations (reasons why annotators made certain annotations) to approximate labor-intensive HJDs using LLMs. If datasets for more tasks include reasons for annotators' choices, our approach can be applied to approximate HJDs using LLMs for tasks such as sentiment analysis, stance detection and hate speech, etc., where there also exists disagreement and need for HJDs, see for example (Sandri et al., 2023). This would allow researchers to better explore the impact of HLV.</p>
<p>On a broader scale, research into HLV is akin to aligning current machine models with human values and addressing discrepancies in human viewpoints, different interpretations, and aligning them with machine judgment.</p>
<h2>7 Conclusion</h2>
<p>This paper analyzes to what extent LLMs can approximate human judgment distributions from a few explanations. Our results show that a few explanations improve LLM's ability to approximate HJDs. However, measuring the distance of the resulting MJD is insufficient: while similar in distance, their resulting fine-tuned models and visualized distributions differ substantially. We adopt an error visualization tool and a global-level metric, aligning our distribution and fine-tuning results. Our method can also be extended to other tasks beyond NLI, and we encourage an uptake of explanation-informed datasets.</p>
<h2>Limitations</h2>
<p>Approximating human judgment distributions from a few explanations is a challenging task. The generalizability of LLMs empowers our approach to transform textual data (prompts with comments) into numeric form (MJDs) and thus approximate the human label distribution. However, we are constrained to existing crowd-annotated NLI datasets as our approximation target, which is not necessarily the best or most representative human label distribution. In future it would be interesting to test</p>
<p>our approach on diverse HJDs. For the same reason, our fine-tuning experiments use the standard softlabel training, which is one of the most prominent but not the only HLV-embracing procedure.</p>
<p>There are further considerations we could take into account in our experimental design. Firstly, the VariErr dataset also includes a second round of validity judgments regarding the explanations to identify erroneous labels. In the current study, this was not in scope. We could further leverage these quality judgments as features to subset better and worse explanations and investigate LLMs' performances when fed with different explanation qualities. Secondly, we could further explore the temperature $\tau$ or other normalization ways to scale or zoom in to better understand the differences in shapes between HJDs and MJDs. Thirdly, traditional divergence metrics, such as KL, JSD, and TVD, are not particularly designed to measure global-level differences between two distributions, especially concerning the distribution shapes. While we proposed one distance correlation measure to address this, there can be other metrics to measure these macroscopic differences. Similarly, error visualizations partially prove our hypothesis but alone do not provide quantifiable evidence.</p>
<h2>Acknowledgements</h2>
<p>We thank the members of the MaiNLP lab for their insightful feedback on earlier drafts of this paper. We specifically appreciate the suggestions of Philipp Mondorf, Bolei Ma, Kassem Sabeh, Verena Blaschke, Diego Frassinelli, Sondre Wold, Jian Lan, and Rob van der Goot. BC acknowledges his membership in the European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program. We are also grateful to the anonymous reviewers for their constructive feedback. This research is supported by ERC Consolidator Grant DIALECT 101043235, and UK Research and Innovation (UKRI) Frontier Research Grant EP/Y031350/1.</p>
<h2>References</h2>
<p>Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Maxamed Axmed, Kalika Bali, and Sunayana Sitaram. 2024. MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks. Preprint, arXiv:2311.07463.</p>
<p>Abhishek Anand, Negar Mokhberian, Prathyusha Kumar, Anweasha Saha, Zihao He, Ashwin Rao, Fred Morstatter, and Kristina Lerman. 2024. Don't blame the data, blame the model: Understanding noise and bias when learning from subjective annotations. In Proceedings of the 1st Workshop on UncertaintyAware NLP (UncertaiNLP 2024), pages 102-113, St Julians, Malta. Association for Computational Linguistics.</p>
<p>Lora Aroyo and Chris Welty. 2015. Truth is a lie: Crowd truth and the seven myths of human annotation. AI Mag., 36(1):15-24.</p>
<p>Joris Baan, Wilker Aziz, Barbara Plank, and Raquel Fernandez. 2022. Stop measuring calibration when humans disagree. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 1892-1915, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Simone Balloccu, Patrícia Schmidtová, Mateusz Lango, and Ondrej Dusek. 2024. Leak, cheat, repeat: Data contamination and evaluation malpractices in closedsource LLMs. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 67-93, St. Julian's, Malta. Association for Computational Linguistics.</p>
<p>Parishad BehnamGhader, Vaibhav Adlakha, Marius Mosbach, Dzmitry Bahdanau, Nicolas Chapados, and Siva Reddy. 2024. LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders. Preprint, arXiv:2404.05961.</p>
<p>Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 632-642. The Association for Computational Linguistics.</p>
<p>Federico Cabitza, Andrea Campagner, and Valerio Basile. 2023. Toward a perspectivist turn in ground truthing for predictive computing. In Proceedings of the AAAI Conference on Artificial Intelligence.</p>
<p>Cheng-Han Chiang and Hung-yi Lee. 2023. Can large language models be an alternative to human evaluations? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15607-15631, Toronto, Canada. Association for Computational Linguistics.</p>
<p>Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger Schwenk, and Veselin Stoyanov. 2018. XNLI: Evaluating crosslingual sentence representations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2475-2485, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The PASCAL recognising textual entailment challenge. In Machine Learning Challenges, Evaluating Predictive Uncertainty, Visual Object Classification and Recognizing Textual Entailment, First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers, volume 3944 of Lecture Notes in Computer Science, pages 177-190. Springer.</p>
<p>Aida Mostafazadeh Davani, Mark Díaz, and Vinodkumar Prabhakaran. 2022. Dealing with disagreements: Looking beyond the majority vote in subjective annotations. Trans. Assoc. Comput. Linguistics, 10:92110 .</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171-4186. Association for Computational Linguistics.</p>
<p>Luc Devroye and Gábor Lugosi. 2001. Combinatorial methods in density estimation. Springer series in statistics. Springer.</p>
<p>Ricardo Dominguez-Olmedo, Moritz Hardt, and Celestine Mendler-Dünner. 2023. Questioning the Survey Responses of Large Language Models. CoRR, abs/2306.07951.</p>
<p>Dominik Maria Endres and Johannes E. Schindelin. 2003. A new metric for probability distributions. IEEE Trans. Inf. Theory, 49(7):1858-1860.</p>
<p>Allyson Ettinger, Jena Hwang, Valentina Pyatkin, Chandra Bhagavatula, and Yejin Choi. 2023. "you are an expert linguistic annotator": Limits of LLMs as analyzers of Abstract Meaning Representation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 8250-8263, Singapore. Association for Computational Linguistics.</p>
<p>Tommaso Fornaciari, Alexandra Uma, Silviu Paun, Barbara Plank, Dirk Hovy, and Massimo Poesio. 2021a. Beyond black \&amp; white: Leveraging annotator disagreement via soft-label multi-task learning. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACLHLT 2021, Online, June 6-11, 2021, pages 25912597. Association for Computational Linguistics.</p>
<p>Tommaso Fornaciari, Alexandra Uma, Silviu Paun, Barbara Plank, Dirk Hovy, and Massimo Poesio. 2021b. Beyond black \&amp; white: Leveraging annotator disagreement via soft-label multi-task learning. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2591-2597, Online. Association for Computational Linguistics.</p>
<p>Cornelia Gruber, Katharina Hechinger, Matthias Assenmacher, Göran Kauermann, and Barbara Plank. 2024. More labels or cases? assessing label variation in natural language inference. In Proceedings of the Third Workshop on Understanding Implicit and Underspecified Language, pages 22-32, Malta. Association for Computational Linguistics.</p>
<p>Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023a. Mistral 7B. Preprint, arXiv:2310.06825.</p>
<p>Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, MarieAnne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2024. Mixtral of Experts. CoRR, abs/2401.04088.</p>
<p>Nan-Jiang Jiang and Marie-Catherine de Marneffe. 2022a. Investigating reasons for disagreement in natural language inference. Transactions of the Association for Computational Linguistics, 10:13571374 .</p>
<p>Nan-Jiang Jiang, Chenhao Tan, and Marie-Catherine de Marneffe. 2023b. Ecologically valid explanations for label variation in NLI. In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 1062210633. Association for Computational Linguistics.</p>
<p>Nanjiang Jiang and Marie-Catherine de Marneffe. 2022b. Investigating reasons for disagreement in natural language inference. Trans. Assoc. Comput. Linguistics, 10:1357-1374.</p>
<p>Solomon Kullback and Richard A Leibler. 1951. On information and sufficiency. The annals of mathematical statistics, 22(1):79-86.</p>
<p>Andrew K. Lampinen, Ishita Dasgupta, Stephanie C. Y. Chan, Kory W. Mathewson, Michael Henry Tessler, Antonia Creswell, James L. McClelland, Jane Wang, and Felix Hill. 2022. Can language models learn</p>
<p>from explanations in context? In Findings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 537-563. Association for Computational Linguistics.</p>
<p>Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryen White, and Sujay Kumar Jauhar. 2023a. Making large language models better data creators. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 15349-15360. Association for Computational Linguistics.</p>
<p>Noah Lee, Na An, and James Thorne. 2023b. Can large language models capture dissenting human voices? In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 45694585. Association for Computational Linguistics.</p>
<p>Elisa Leonardelli, Gavin Abercrombie, Dina Almanea, Valerio Basile, Tommaso Fornaciari, Barbara Plank, Verena Rieser, Alexandra Uma, and Massimo Poesio. 2023. SemEval-2023 task 11: Learning with disagreements (LeWiDi). In Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023), pages 2304-2318, Toronto, Canada. Association for Computational Linguistics.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR, abs/1907.11692.</p>
<p>Christopher D. Manning. 2006. Local textual inference : It's hard to circumscribe, but you know it when you see it - and nlp needs it.</p>
<p>Meta. 2024. Introducing Meta Llama 3: The most capable openly available LLM to date. https://ai. meta.com/blog/meta-llama-3/.</p>
<p>Rafael Müller, Simon Kornblith, and Geoffrey E. Hinton. 2019. When does label smoothing help? In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 4696-4705.</p>
<p>Yixin Nie, Xiang Zhou, and Mohit Bansal. 2020. What can we learn from collective human opinions on natural language inference data? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 9131-9143. Association for Computational Linguistics.</p>
<p>Yonatan Oren, Nicole Meister, Niladri S. Chatterji, Faisal Ladhak, and Tatsunori Hashimoto. 2024. Proving test set contamination in black-box language models. In The Twelfth International Conference on Learning Representations.</p>
<p>Ellie Pavlick and Tom Kwiatkowski. 2019. Inherent disagreements in human textual inferences. Trans. Assoc. Comput. Linguistics, 7:677-694.</p>
<p>Maja Pavlovic and Massimo Poesio. 2024. The effectiveness of LLMs as annotators: A comparative overview and empirical analysis of direct representation. In Proceedings of the 3rd Workshop on Perspectivist Approaches to NLP (NLPerspectives) @ LREC-COLING 2024, pages 100-110, Torino, Italia. ELRA and ICCL.</p>
<p>Barbara Plank. 2022. The "problem" of human label variation: On ground truth in data, modeling and evaluation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 10671-10682. Association for Computational Linguistics.</p>
<p>Barbara Plank, Dirk Hovy, and Anders Søgaard. 2014. Learning part-of-speech taggers with inter-annotator agreement loss. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 742-751, Gothenburg, Sweden. Association for Computational Linguistics.</p>
<p>Marta Sandri, Elisa Leonardelli, Sara Tonelli, and Elisabetta Jezek. 2023. Why don't you do it right? analysing annotators' disagreement in subjective tasks. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023, pages 2420-2433. Association for Computational Linguistics.</p>
<p>Gábor J. Székely, Maria L. Rizzo, and Nail K. Bakirov. 2007. Measuring and testing dependence by correlation of distances. The Annals of Statistics, 35(6):2769-2794.</p>
<p>Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, and Graham Neubig. 2023. Do LLMs exhibit human-like response biases? A case study in survey design. CoRR, abs/2311.04076.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu,</p>
<p>Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2: Open foundation and finetuned chat models. Preprint, arXiv:2307.09288.</p>
<p>Alexandra Uma, Tommaso Fornaciari, Dirk Hovy, Silviu Paun, Barbara Plank, and Massimo Poesio. 2021. Learning from disagreement: A survey. J. Artif. Intell. Res., 72:1385-1470.</p>
<p>Pat Verga, Sebastian Hofstatter, Sophia Althammer, Yixuan Su, Aleksandra Piktus, Arkady Arkhangorodsky, Minjie Xu, Naomi White, and Patrick Lewis. 2024. Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models. Preprint, arXiv:2404.18796.</p>
<p>Manya Wadhwa, Jifan Chen, Junyi Jessy Li, and Greg Durrett. 2023. Using Natural Language Explanations to Rescale Human Judgments. CoRR, abs/2305.14770.</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In International Conference on Learning Representations.</p>
<p>Leon Weber-Genzel, Siyao Peng, Marie-Catherine de Marneffe, and Barbara Plank. 2024. VariErr NLI: Separating Annotation Error from Human Label Variation. CoRR, abs/2403.01931.</p>
<p>Hongxin Wei, Renchunzi Xie, Hao Cheng, Lei Feng, Bo An, and Yixuan Li. 2022a. Mitigating neural network overconfidence with logit normalization. In International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 23631-23644. PMLR.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022b. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022.</p>
<p>Adina Williams, Nikita Nangia, and Samuel R. Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACLHLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), pages 1112-1122. Association for Computational Linguistics.</p>
<p>Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, and Tianyi Zhou. 2024. A Survey on Knowledge Distillation of Large Language Models. CoRR, abs/2402.13116.</p>
<p>Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of Large Language Models. CoRR, abs/2303.18223.</p>
<p>Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang. 2024. Large language models are not robust multiple choice selectors. In The Twelfth International Conference on Learning Representations.</p>
<p>Xiang Zhou, Yixin Nie, and Mohit Bansal. 2022. Distributed NLI: Learning to predict human opinion distributions for language reasoning. In Findings of the Association for Computational Linguistics: ACL 2022, pages 972-987, Dublin, Ireland. Association for Computational Linguistics.</p>
<h2>A Prompt</h2>
<p>All prompts used in this paper are listed in Table 5. We adopted the original chat templates for both LLMs to input the prompt.</p>
<h2>B Experimental Implementation</h2>
<p>We first fine-tuned BERT-base-uncased (Devlin et al., 2019) and Roberta-base (Liu et al., 2019) with the standard NLI training process on MNLI single labels (Williams et al., 2018), and then finetuned them on the label distributions of MNLI, VariErr NLI (Weber-Genzel et al., 2024) and Chaos NLI (Nie et al., 2020), as well as the MJDs generated by the LLMs. We used cross-entropy as a loss function for soft-label training. For validation on the dev set, we measured the distribution distance by calculating KL divergence and cross-entropy between the logits of the model and the soft label. We also measured the prediction performance by calculating the F1 score using the largest logits of the model against the majority-voted label. We selected the model with the best macro-F1 score performance on the dev set for final testing. Detailed hyperparameter choices are listed in Table 6. Fine-tuning was conducted with NVIDIA A100 80GB within several hours.</p>
<h2>C Metrics</h2>
<p>Kullback-Leibler Divergence Kullback-Leibler divergence, often referred to as KL divergence (KL), is a measure of how one probability distribution diverges from a second, reference probability distribution (Kullback and Leibler, 1951). It is</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">General Instruction Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><code>Without explanations</code></td>
<td style="text-align: center;">"role": "user", "content": <br> Please determine whether the following Statement is true (entailment), undetermined (neutral), or false (contradiction) given the Context below and select ONE of the listed options and start your answer with a single letter. <br> Context: {promise} <br> Statement: {hypothesis} <br> A. Entailment <br> B. Neutral <br> C. Contradiction. <br> Answer:```</td>
</tr>
<tr>
<td style="text-align: center;">With explanations</td>
<td style="text-align: center;">"role": "user", "content": <br> Please carefully and fairly base your selection on the comments below to determine whether the following Statement is true (entailment), undetermined (neutral), or false (contradiction) given the Context below and select ONE of the listed options and start your answer with a single letter. <br> Context: {promise} <br> Statement: {hypothesis} <br> Comment 1: {explanation 1} <br> Comment 2: {explanation 2} <br> A. Entailment <br> B. Neutral <br> C. Contradiction. <br> Answer:</td>
</tr>
<tr>
<td style="text-align: center;">With explicit explanations</td>
<td style="text-align: center;">"role": "user", "content": <br> Please carefully and fairly base your selection on the comments below to determine whether the following Statement is true (entailment), undetermined (neutral), or false (contradiction) given the Context below and select ONE of the listed options and start your answer with a single letter. <br> Context: {promise} <br> Statement: {hypothesis} <br> Comment 1: {explanation 1}, so I choose (label 1) <br> Comment 2: {explanation 2}, so I choose (label 2) <br> A. Entailment <br> B. Neutral <br> C. Contradiction. <br> Answer:</td>
</tr>
</tbody>
</table>
<p>Table 5: Instruction prompt of different types to transform NLI into a multi-choice question format.
useful for capturing the relative entropy or information loss when approximating one distribution with another. It is a non-symmetric measure of the difference between two probability distributions $P$ and $Q$.</p>
<p>KL divergence is very sensitive to differences between the two distributions. If there are points where one distribution assigns a high probability and the other assigns a low probability, KL divergence will highlight these differences significantly.</p>
<p>For discrete probability distributions $P$ and $Q$ :</p>
<p>$$
D_{\mathrm{KL}}(P \mid Q)=\sum_{x \in \mathcal{X}} P(x) \log \frac{P(x)}{Q(x)}
$$</p>
<p>For continuous probability distributions, the sum</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Hyperparameter</th>
<th style="text-align: center;">Our Model</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Learning Rate Decay</td>
<td style="text-align: center;">Linear</td>
</tr>
<tr>
<td style="text-align: left;">Weight Decay</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Optimizer</td>
<td style="text-align: center;">AdamW</td>
</tr>
<tr>
<td style="text-align: left;">Adam $\epsilon$</td>
<td style="text-align: center;">$1 \mathrm{e}-8$</td>
</tr>
<tr>
<td style="text-align: left;">Adam $\beta_{1}$</td>
<td style="text-align: center;">0.9</td>
</tr>
<tr>
<td style="text-align: left;">Adam $\beta_{2}$</td>
<td style="text-align: center;">0.999</td>
</tr>
<tr>
<td style="text-align: left;">Warmup Ratio</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Learning Rate</td>
<td style="text-align: center;">$2 \mathrm{e}-5$</td>
</tr>
<tr>
<td style="text-align: left;">Batch size</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: left;">Num Epoch</td>
<td style="text-align: center;">5</td>
</tr>
</tbody>
</table>
<p>Table 6: Hyperparameter used for fine-tuning BERT and RoBERTa models.
is replaced by an integral:</p>
<p>$$
D_{\mathrm{KL}}(P \mid Q)=\int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} d x
$$</p>
<p>In this paper, we adopted the discrete version, as our target distributions are 3-dimensional probabilities. KL divergence is asymmetric $\left(D_{\mathrm{KL}}(P \mid Q) \neq\right.$ $\left.D_{\mathrm{KL}}(Q \mid P)\right)$, which can be beneficial when the distributions have a clear direction of reference or when one distribution is considered the true distribution and the other is an approximation. Thus, we set Chaos NLI HJD as the true distribution $P$, and MJDs as the approximation $Q$.</p>
<p>Jensen-Shannon Distance Jensen-Shannon distance (JSD) is a symmetric and smoothed version of the KL divergence (Endres and Schindelin, 2003). Unlike KL divergence, Jensen-Shannon distance is symmetric $\left(D_{\mathrm{JS}}(P \mid Q)=D_{\mathrm{JS}}(Q \mid P)\right)$. This makes it suitable when there is no inherent reference direction between the two distributions. Jensen-Shannon distance is always finite and bounded between 0 and 1, making it easier to interpret and compare. By averaging the two distributions, it mitigates the impact of any extreme values, providing a more stable measure of similarity.</p>
<p>For discrete probability distributions $P$ and $Q$, let $M=\frac{1}{2}(P+Q)$. The Jensen-Shannon divergence is defined as:</p>
<p>$$
D_{\mathrm{JS}}(P \mid Q)=\sqrt{\frac{\left(D_{\mathrm{KL}}(P \mid M)+D_{\mathrm{KL}}(Q \mid M)\right)}{2}}
$$</p>
<p>Same as KL, we also set HJD from Chaos NLI as $P$, while MJDs as $Q$.</p>
<p>Total Variation Distance Total Variation distance (TVD) is a measure of the maximum difference between the probabilities assigned to the same event by two different probability distributions (Devroye and Lugosi, 2001) . It provides a way to quantify the difference between two distributions.</p>
<p>TV distance can be interpreted as the maximum proportion of the distribution that needs to be altered to transform one distribution into the other. This makes it an intuitive measure of overall dissimilarity. Unlike KL divergence and JS distance, which involve logarithms and averages, TV distance is based on absolute differences. This can be particularly useful when you need a straightforward measure of discrepancy. TV distance is robust to small changes in probability values, making it a reliable measure when comparing distributions that may have minor variations.</p>
<p>For discrete probability distributions $P$ and $Q$ :</p>
<p>$$
D_{\mathrm{TV}}(P, Q)=\frac{1}{2} \sum_{x \in \mathcal{X}}|P(x)-Q(x)|
$$</p>
<p>For continuous probability distributions, the sum is replaced by an integral:</p>
<p>$$
D_{\mathrm{TV}}(P, Q)=\frac{1}{2} \int_{-\infty}^{\infty}|p(x)-q(x)| d x
$$</p>
<p>In this paper, we still used the discrete version, as same as KL. We set HJD from Chaos NLI as $P$, while MJDs as $Q$.</p>
<p>Weighted F1 Score The weighted F1 score is an extension of the standard F1 score that accounts for class imbalance in multi-class classification problems. In multi-class classification, different classes can have varying frequencies, and the weighted F1 score adjusts for this by giving more importance to classes that have more instances.</p>
<p>The F1 score is the harmonic mean of precision and recall:</p>
<p>$$
\text { F1 Score }=2 \times \frac{\text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}
$$</p>
<p>where precision $(\mathrm{P})$ is the proportion of true positives among all predicted positives:</p>
<p>$$
\text { Precision }=\frac{T P}{T P+F P}
$$</p>
<p>and recall (R) is the proportion of true positives among all actual positives:</p>
<p>$$
\text { Recall }=\frac{T P}{T P+F N}
$$</p>
<p>In a multi-class setting, we calculate the F1 score for each class, then take a weighted average based on the number of true instances of each class. This alters macro F1 Score to account for label imbalance; it can result in an F-score that is not between precision and recall.</p>
<p>The formula for the weighted F1 score is:</p>
<p>$$
\text { Weighted } \mathrm{F} 1=\frac{1}{N} \sum_{i=1}^{k} w_{i} \times F 1_{i}
$$</p>
<p>where $k$ is the total number of classes, $F 1_{i}$ is the F1 score for class $i, w_{i}$ is the weight for class $i$, which is proportional to the number of true instances of class $i\left(w_{i}=\frac{n_{i}}{N}\right.$, where $n_{i}$ is the number of true instances of class $i$, and $N$ is the total number of instances across all classes.).</p>
<p>The weighted F1 score is particularly useful when dealing with imbalanced datasets because it adjusts the contribution of each class's F1 score based on how common the class is. This prevents the model from being overly influenced by the performance on the majority class, which can be misleading in an imbalanced dataset. In this paper, the weighted F1 score is implemented with sklearn ${ }^{5}$.</p>
<h2>D Detailed Result of Ablation Study</h2>
<p>All results of the ablation study ("serial"/"parallel") were listed in Table 7, which were depicted by Figure 3 in $\S 4.3$. To pursue maximizing the evaluation metrics, we can indeed make greater sacrifices in computational resources, especially since Llama3 has a strong capability to process all explanations at once. However, we have considered the possible sequence bias of explanations. To eliminate these biases we consider a shuffling setup, where the computational resource consumption will increase significantly as the number of explanations increases. Therefore, presenting both parallel and serial results is valuable.</p>
<h2>E Details of Fine-tuning Comparison</h2>
<p>Here we provided more details regarding the results of fine-tuning comparison, as listed in Table 8 and 9 , which were the complete versions of Table 3.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Distributions</th>
<th style="text-align: center;">$P_{\text {norm }}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$P_{\text {sfmax }}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$\mathbf{K L} \downarrow$</td>
<td style="text-align: center;">$\mathbf{J S D} \downarrow$</td>
<td style="text-align: center;">TVD $\downarrow$</td>
<td style="text-align: center;">$\mathbf{K L} \downarrow$</td>
<td style="text-align: center;">$\mathbf{J S D} \downarrow$</td>
<td style="text-align: center;">TVD $\downarrow$</td>
</tr>
<tr>
<td style="text-align: center;">Mixtral original</td>
<td style="text-align: center;">0.433</td>
<td style="text-align: center;">0.291</td>
<td style="text-align: center;">0.340</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">0.292</td>
<td style="text-align: center;">0.342</td>
</tr>
<tr>
<td style="text-align: center;">4 explanations at a time</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">0.265</td>
<td style="text-align: center;">0.306</td>
<td style="text-align: center;">0.349</td>
<td style="text-align: center;">0.258</td>
<td style="text-align: center;">0.296</td>
</tr>
<tr>
<td style="text-align: center;">3 explanations at a time</td>
<td style="text-align: center;">0.385</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.303</td>
<td style="text-align: center;">0.338</td>
<td style="text-align: center;">0.257</td>
<td style="text-align: center;">0.295</td>
</tr>
<tr>
<td style="text-align: center;">2 explanations at a time</td>
<td style="text-align: center;">0.368</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.301</td>
<td style="text-align: center;">0.329</td>
<td style="text-align: center;">0.257</td>
<td style="text-align: center;">0.293</td>
</tr>
<tr>
<td style="text-align: center;">1 explanations at a time</td>
<td style="text-align: center;">0.339</td>
<td style="text-align: center;">0.258</td>
<td style="text-align: center;">0.295</td>
<td style="text-align: center;">0.310</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.290</td>
</tr>
<tr>
<td style="text-align: center;">4 explicit explanations at a time</td>
<td style="text-align: center;">0.382</td>
<td style="text-align: center;">0.246</td>
<td style="text-align: center;">0.286</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.235</td>
<td style="text-align: center;">0.269</td>
</tr>
<tr>
<td style="text-align: center;">3 explicit explanations at a time</td>
<td style="text-align: center;">0.331</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">0.270</td>
<td style="text-align: center;">0.275</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.257</td>
</tr>
<tr>
<td style="text-align: center;">2 explicit explanations at a time</td>
<td style="text-align: center;">0.296</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.261</td>
<td style="text-align: center;">0.254</td>
<td style="text-align: center;">0.221</td>
<td style="text-align: center;">0.251</td>
</tr>
<tr>
<td style="text-align: center;">1 explicit explanations at a time</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.211</td>
<td style="text-align: center;">0.239</td>
<td style="text-align: center;">0.217</td>
<td style="text-align: center;">0.208</td>
<td style="text-align: center;">0.232</td>
</tr>
<tr>
<td style="text-align: center;">Llama3 original</td>
<td style="text-align: center;">0.259</td>
<td style="text-align: center;">0.262</td>
<td style="text-align: center;">0.284</td>
<td style="text-align: center;">0.231</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.260</td>
</tr>
<tr>
<td style="text-align: center;">4 explanations at a time</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.259</td>
<td style="text-align: center;">0.281</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.258</td>
</tr>
<tr>
<td style="text-align: center;">3 explanations at a time</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.260</td>
<td style="text-align: center;">0.282</td>
<td style="text-align: center;">0.225</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.258</td>
</tr>
<tr>
<td style="text-align: center;">2 explanations at a time</td>
<td style="text-align: center;">0.256</td>
<td style="text-align: center;">0.260</td>
<td style="text-align: center;">0.283</td>
<td style="text-align: center;">0.224</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.258</td>
</tr>
<tr>
<td style="text-align: center;">1 explanation at a time</td>
<td style="text-align: center;">0.257</td>
<td style="text-align: center;">0.261</td>
<td style="text-align: center;">0.283</td>
<td style="text-align: center;">0.226</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.260</td>
</tr>
<tr>
<td style="text-align: center;">4 explicit explanations at a time</td>
<td style="text-align: center;">0.235</td>
<td style="text-align: center;">0.247</td>
<td style="text-align: center;">0.266</td>
<td style="text-align: center;">0.212</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.245</td>
</tr>
<tr>
<td style="text-align: center;">3 explicit explanations at a time</td>
<td style="text-align: center;">0.235</td>
<td style="text-align: center;">0.248</td>
<td style="text-align: center;">0.266</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.232</td>
<td style="text-align: center;">0.244</td>
</tr>
<tr>
<td style="text-align: center;">2 explicit explanations at a time</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">0.250</td>
<td style="text-align: center;">0.269</td>
<td style="text-align: center;">0.209</td>
<td style="text-align: center;">0.233</td>
<td style="text-align: center;">0.245</td>
</tr>
<tr>
<td style="text-align: center;">1 explicit explanation at a time</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.253</td>
<td style="text-align: center;">0.273</td>
<td style="text-align: center;">0.214</td>
<td style="text-align: center;">0.237</td>
<td style="text-align: center;">0.254</td>
</tr>
</tbody>
</table>
<p>Table 7: All results of "serial"/"parallel". Scores are compared with Chaos NLI HJD. Note that since all the results are averaged scores of $A\binom{1 m}{m}$ combinations (described in $\S 3.3$ ), which means LLMs actually obtain all 4 explanations' information in every setting. "Serial" represents " 4 explanations at a time", while "parallel" represents " 1 explanations at a time". For the settings of 2 and 3, they are the transition form from "serial" to "parallel".</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Distributions</th>
<th style="text-align: center;">BERT FT</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RoBERTa FT</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ACC. $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">Macro F1 $\uparrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
<td style="text-align: center;">ACC. $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">Macro F1 $\uparrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
</tr>
<tr>
<td style="text-align: center;">Baseline</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Chaos NLI train set</td>
<td style="text-align: center;">0.628</td>
<td style="text-align: center;">0.074</td>
<td style="text-align: center;">0.626</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.972</td>
<td style="text-align: center;">0.698</td>
<td style="text-align: center;">0.061</td>
<td style="text-align: center;">0.699</td>
<td style="text-align: center;">0.659</td>
<td style="text-align: center;">0.932</td>
</tr>
<tr>
<td style="text-align: center;">MNLI single label</td>
<td style="text-align: center;">0.552</td>
<td style="text-align: center;">0.665</td>
<td style="text-align: center;">0.561</td>
<td style="text-align: center;">0.523</td>
<td style="text-align: center;">2.743</td>
<td style="text-align: center;">0.628</td>
<td style="text-align: center;">0.844</td>
<td style="text-align: center;">0.635</td>
<td style="text-align: center;">0.616</td>
<td style="text-align: center;">3.281</td>
</tr>
<tr>
<td style="text-align: center;">MNLI distributions</td>
<td style="text-align: center;">0.542</td>
<td style="text-align: center;">0.099</td>
<td style="text-align: center;">0.546</td>
<td style="text-align: center;">0.518</td>
<td style="text-align: center;">1.046</td>
<td style="text-align: center;">0.607</td>
<td style="text-align: center;">0.100</td>
<td style="text-align: center;">0.613</td>
<td style="text-align: center;">0.598</td>
<td style="text-align: center;">1.047</td>
</tr>
<tr>
<td style="text-align: center;">Varifor distributions</td>
<td style="text-align: center;">0.558</td>
<td style="text-align: center;">0.179</td>
<td style="text-align: center;">0.557</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">1.286</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;">0.174</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">1.269</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Mistral</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {mean }}$ of Mistral</td>
<td style="text-align: center;">0.404</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.416</td>
<td style="text-align: center;">0.400</td>
<td style="text-align: center;">1.152</td>
<td style="text-align: center;">0.464</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.486</td>
<td style="text-align: center;">0.451</td>
<td style="text-align: center;">1.118</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.459</td>
<td style="text-align: center;">0.145</td>
<td style="text-align: center;">0.443</td>
<td style="text-align: center;">0.452</td>
<td style="text-align: center;">1.183</td>
<td style="text-align: center;">0.506</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.509</td>
<td style="text-align: center;">0.502</td>
<td style="text-align: center;">1.132</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.515</td>
<td style="text-align: center;">0.130</td>
<td style="text-align: center;">0.506</td>
<td style="text-align: center;">0.492</td>
<td style="text-align: center;">1.139</td>
<td style="text-align: center;">0.569</td>
<td style="text-align: center;">0.114</td>
<td style="text-align: center;">0.569</td>
<td style="text-align: center;">0.554</td>
<td style="text-align: center;">1.091</td>
</tr>
<tr>
<td style="text-align: center;">o "parallel" explanations</td>
<td style="text-align: center;">0.409</td>
<td style="text-align: center;">0.134</td>
<td style="text-align: center;">0.404</td>
<td style="text-align: center;">0.407</td>
<td style="text-align: center;">1.150</td>
<td style="text-align: center;">0.472</td>
<td style="text-align: center;">0.123</td>
<td style="text-align: center;">0.483</td>
<td style="text-align: center;">0.472</td>
<td style="text-align: center;">1.118</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">0.108</td>
<td style="text-align: center;">0.507</td>
<td style="text-align: center;">0.492</td>
<td style="text-align: center;">1.074</td>
<td style="text-align: center;">0.558</td>
<td style="text-align: center;">0.092</td>
<td style="text-align: center;">0.558</td>
<td style="text-align: center;">0.542</td>
<td style="text-align: center;">1.025</td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {slope }}$ of Mistral</td>
<td style="text-align: center;">0.413</td>
<td style="text-align: center;">0.131</td>
<td style="text-align: center;">0.427</td>
<td style="text-align: center;">0.408</td>
<td style="text-align: center;">1.140</td>
<td style="text-align: center;">0.477</td>
<td style="text-align: center;">0.121</td>
<td style="text-align: center;">0.497</td>
<td style="text-align: center;">0.460</td>
<td style="text-align: center;">1.112</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.467</td>
<td style="text-align: center;">0.121</td>
<td style="text-align: center;">0.452</td>
<td style="text-align: center;">0.459</td>
<td style="text-align: center;">1.113</td>
<td style="text-align: center;">0.504</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.506</td>
<td style="text-align: center;">0.498</td>
<td style="text-align: center;">1.078</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.517</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.509</td>
<td style="text-align: center;">0.495</td>
<td style="text-align: center;">1.064</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">0.549</td>
<td style="text-align: center;">1.026</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.404</td>
<td style="text-align: center;">0.121</td>
<td style="text-align: center;">0.397</td>
<td style="text-align: center;">0.402</td>
<td style="text-align: center;">1.112</td>
<td style="text-align: center;">0.483</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.497</td>
<td style="text-align: center;">0.482</td>
<td style="text-align: center;">1.079</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.528</td>
<td style="text-align: center;">0.095</td>
<td style="text-align: center;">0.522</td>
<td style="text-align: center;">0.502</td>
<td style="text-align: center;">1.035</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">0.082</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">0.549</td>
<td style="text-align: center;">0.994</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Llama3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {mean }}$ of Llama3</td>
<td style="text-align: center;">0.556</td>
<td style="text-align: center;">0.097</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">0.473</td>
<td style="text-align: center;">1.038</td>
<td style="text-align: center;">0.593</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.541</td>
<td style="text-align: center;">0.505</td>
<td style="text-align: center;">1.023</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.561</td>
<td style="text-align: center;">0.096</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.534</td>
<td style="text-align: center;">1.037</td>
<td style="text-align: center;">0.610</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.618</td>
<td style="text-align: center;">0.580</td>
<td style="text-align: center;">1.020</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.571</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.578</td>
<td style="text-align: center;">0.536</td>
<td style="text-align: center;">1.022</td>
<td style="text-align: center;">0.630</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.634</td>
<td style="text-align: center;">0.589</td>
<td style="text-align: center;">1.003</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.561</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;">0.531</td>
<td style="text-align: center;">1.041</td>
<td style="text-align: center;">0.634</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.636</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">1.026</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.094</td>
<td style="text-align: center;">0.582</td>
<td style="text-align: center;">0.539</td>
<td style="text-align: center;">1.030</td>
<td style="text-align: center;">0.634</td>
<td style="text-align: center;">0.089</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.596</td>
<td style="text-align: center;">1.014</td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {slope }}$ of Llama3</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.528</td>
<td style="text-align: center;">0.487</td>
<td style="text-align: center;">1.023</td>
<td style="text-align: center;">0.601</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.546</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">1.005</td>
</tr>
<tr>
<td style="text-align: center;">o "serial" explanations</td>
<td style="text-align: center;">0.555</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">0.532</td>
<td style="text-align: center;">1.021</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;">0.082</td>
<td style="text-align: center;">0.626</td>
<td style="text-align: center;">0.588</td>
<td style="text-align: center;">0.996</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.577</td>
<td style="text-align: center;">0.086</td>
<td style="text-align: center;">0.585</td>
<td style="text-align: center;">0.544</td>
<td style="text-align: center;">1.008</td>
<td style="text-align: center;">0.641</td>
<td style="text-align: center;">0.077</td>
<td style="text-align: center;">0.646</td>
<td style="text-align: center;">0.604</td>
<td style="text-align: center;">0.981</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.092</td>
<td style="text-align: center;">0.584</td>
<td style="text-align: center;">0.541</td>
<td style="text-align: center;">1.024</td>
<td style="text-align: center;">0.638</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.643</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">1.004</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.088</td>
<td style="text-align: center;">0.581</td>
<td style="text-align: center;">0.540</td>
<td style="text-align: center;">1.014</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">0.081</td>
<td style="text-align: center;">0.645</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.993</td>
</tr>
</tbody>
</table>
<p>Table 8: All results for fine-tuning comparison on Chaos NLI dev set.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Distributions</th>
<th style="text-align: center;">BERT FT</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RoBERTa FT</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ACC. $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">Macro F1 $\uparrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
<td style="text-align: center;">ACC. $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">Macro F1 $\uparrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
</tr>
<tr>
<td style="text-align: center;">Baseline</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Chaos NLI-M train set</td>
<td style="text-align: center;">0.645</td>
<td style="text-align: center;">0.077</td>
<td style="text-align: center;">0.646</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;">0.974</td>
<td style="text-align: center;">0.650</td>
<td style="text-align: center;">0.067</td>
<td style="text-align: center;">0.650</td>
<td style="text-align: center;">0.630</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr>
<td style="text-align: center;">MNLI single label</td>
<td style="text-align: center;">0.585</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">0.589</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;">2.855</td>
<td style="text-align: center;">0.599</td>
<td style="text-align: center;">0.867</td>
<td style="text-align: center;">0.603</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">3.344</td>
</tr>
<tr>
<td style="text-align: center;">MNLI distributions</td>
<td style="text-align: center;">0.547</td>
<td style="text-align: center;">0.102</td>
<td style="text-align: center;">0.543</td>
<td style="text-align: center;">0.539</td>
<td style="text-align: center;">1.048</td>
<td style="text-align: center;">0.599</td>
<td style="text-align: center;">0.096</td>
<td style="text-align: center;">0.604</td>
<td style="text-align: center;">0.594</td>
<td style="text-align: center;">1.029</td>
</tr>
<tr>
<td style="text-align: center;">Varifor distributions</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.186</td>
<td style="text-align: center;">0.559</td>
<td style="text-align: center;">0.548</td>
<td style="text-align: center;">1.299</td>
<td style="text-align: center;">0.590</td>
<td style="text-align: center;">0.197</td>
<td style="text-align: center;">0.589</td>
<td style="text-align: center;">0.569</td>
<td style="text-align: center;">1.333</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Mistral</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {mean }}$ of Mistral</td>
<td style="text-align: center;">0.417</td>
<td style="text-align: center;">0.133</td>
<td style="text-align: center;">0.422</td>
<td style="text-align: center;">0.416</td>
<td style="text-align: center;">1.142</td>
<td style="text-align: center;">0.459</td>
<td style="text-align: center;">0.127</td>
<td style="text-align: center;">0.466</td>
<td style="text-align: center;">0.453</td>
<td style="text-align: center;">1.123</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.479</td>
<td style="text-align: center;">0.141</td>
<td style="text-align: center;">0.454</td>
<td style="text-align: center;">0.466</td>
<td style="text-align: center;">1.166</td>
<td style="text-align: center;">0.517</td>
<td style="text-align: center;">0.128</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">1.126</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.523</td>
<td style="text-align: center;">0.130</td>
<td style="text-align: center;">0.511</td>
<td style="text-align: center;">0.509</td>
<td style="text-align: center;">1.132</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">1.107</td>
</tr>
<tr>
<td style="text-align: center;">o "parallel" explanations</td>
<td style="text-align: center;">0.436</td>
<td style="text-align: center;">0.131</td>
<td style="text-align: center;">0.428</td>
<td style="text-align: center;">0.434</td>
<td style="text-align: center;">1.136</td>
<td style="text-align: center;">0.498</td>
<td style="text-align: center;">0.122</td>
<td style="text-align: center;">0.502</td>
<td style="text-align: center;">0.499</td>
<td style="text-align: center;">1.109</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.526</td>
<td style="text-align: center;">0.108</td>
<td style="text-align: center;">0.514</td>
<td style="text-align: center;">0.510</td>
<td style="text-align: center;">1.065</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.565</td>
<td style="text-align: center;">0.559</td>
<td style="text-align: center;">1.037</td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {slope }}$ of Mistral</td>
<td style="text-align: center;">0.423</td>
<td style="text-align: center;">0.129</td>
<td style="text-align: center;">0.432</td>
<td style="text-align: center;">0.421</td>
<td style="text-align: center;">1.130</td>
<td style="text-align: center;">0.464</td>
<td style="text-align: center;">0.125</td>
<td style="text-align: center;">0.472</td>
<td style="text-align: center;">0.457</td>
<td style="text-align: center;">1.118</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.485</td>
<td style="text-align: center;">0.118</td>
<td style="text-align: center;">0.462</td>
<td style="text-align: center;">0.473</td>
<td style="text-align: center;">1.096</td>
<td style="text-align: center;">0.526</td>
<td style="text-align: center;">0.109</td>
<td style="text-align: center;">0.525</td>
<td style="text-align: center;">0.522</td>
<td style="text-align: center;">1.069</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.531</td>
<td style="text-align: center;">0.105</td>
<td style="text-align: center;">0.520</td>
<td style="text-align: center;">0.517</td>
<td style="text-align: center;">1.057</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.573</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">1.036</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.436</td>
<td style="text-align: center;">0.119</td>
<td style="text-align: center;">0.429</td>
<td style="text-align: center;">0.433</td>
<td style="text-align: center;">1.098</td>
<td style="text-align: center;">0.501</td>
<td style="text-align: center;">0.111</td>
<td style="text-align: center;">0.505</td>
<td style="text-align: center;">0.501</td>
<td style="text-align: center;">1.074</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.528</td>
<td style="text-align: center;">0.095</td>
<td style="text-align: center;">0.517</td>
<td style="text-align: center;">0.510</td>
<td style="text-align: center;">1.026</td>
<td style="text-align: center;">0.577</td>
<td style="text-align: center;">0.087</td>
<td style="text-align: center;">0.576</td>
<td style="text-align: center;">0.567</td>
<td style="text-align: center;">1.003</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Llama3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {mean }}$ of Llama3</td>
<td style="text-align: center;">0.561</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.526</td>
<td style="text-align: center;">0.506</td>
<td style="text-align: center;">1.036</td>
<td style="text-align: center;">0.583</td>
<td style="text-align: center;">0.094</td>
<td style="text-align: center;">0.528</td>
<td style="text-align: center;">0.513</td>
<td style="text-align: center;">1.025</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">0.097</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.555</td>
<td style="text-align: center;">1.033</td>
<td style="text-align: center;">0.596</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.601</td>
<td style="text-align: center;">0.585</td>
<td style="text-align: center;">1.022</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.571</td>
<td style="text-align: center;">0.092</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.550</td>
<td style="text-align: center;">1.018</td>
<td style="text-align: center;">0.595</td>
<td style="text-align: center;">0.088</td>
<td style="text-align: center;">0.598</td>
<td style="text-align: center;">0.581</td>
<td style="text-align: center;">1.006</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.572</td>
<td style="text-align: center;">0.098</td>
<td style="text-align: center;">0.582</td>
<td style="text-align: center;">0.560</td>
<td style="text-align: center;">1.038</td>
<td style="text-align: center;">0.595</td>
<td style="text-align: center;">0.095</td>
<td style="text-align: center;">0.598</td>
<td style="text-align: center;">0.579</td>
<td style="text-align: center;">1.028</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.580</td>
<td style="text-align: center;">0.095</td>
<td style="text-align: center;">0.586</td>
<td style="text-align: center;">0.560</td>
<td style="text-align: center;">1.026</td>
<td style="text-align: center;">0.615</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.620</td>
<td style="text-align: center;">0.598</td>
<td style="text-align: center;">1.016</td>
</tr>
<tr>
<td style="text-align: center;">$p_{\text {slope }}$ of Llama3</td>
<td style="text-align: center;">0.564</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.524</td>
<td style="text-align: center;">0.507</td>
<td style="text-align: center;">1.021</td>
<td style="text-align: center;">0.595</td>
<td style="text-align: center;">0.089</td>
<td style="text-align: center;">0.535</td>
<td style="text-align: center;">0.524</td>
<td style="text-align: center;">1.009</td>
</tr>
<tr>
<td style="text-align: center;">o "serial" explanations</td>
<td style="text-align: center;">0.569</td>
<td style="text-align: center;">0.091</td>
<td style="text-align: center;">0.576</td>
<td style="text-align: center;">0.556</td>
<td style="text-align: center;">1.016</td>
<td style="text-align: center;">0.603</td>
<td style="text-align: center;">0.086</td>
<td style="text-align: center;">0.608</td>
<td style="text-align: center;">0.591</td>
<td style="text-align: center;">1.000</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.566</td>
<td style="text-align: center;">0.087</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">0.548</td>
<td style="text-align: center;">1.004</td>
<td style="text-align: center;">0.607</td>
<td style="text-align: center;">0.081</td>
<td style="text-align: center;">0.610</td>
<td style="text-align: center;">0.591</td>
<td style="text-align: center;">0.987</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.093</td>
<td style="text-align: center;">0.583</td>
<td style="text-align: center;">0.560</td>
<td style="text-align: center;">1.020</td>
<td style="text-align: center;">0.606</td>
<td style="text-align: center;">0.089</td>
<td style="text-align: center;">0.611</td>
<td style="text-align: center;">0.590</td>
<td style="text-align: center;">1.008</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.574</td>
<td style="text-align: center;">0.089</td>
<td style="text-align: center;">0.578</td>
<td style="text-align: center;">0.551</td>
<td style="text-align: center;">1.010</td>
<td style="text-align: center;">0.617</td>
<td style="text-align: center;">0.085</td>
<td style="text-align: center;">0.621</td>
<td style="text-align: center;">0.601</td>
<td style="text-align: center;">0.996</td>
</tr>
</tbody>
</table>
<p>Table 9: All results for fine-tuning comparison on Chaos NLI test set.</p>
<p>Metrics of KL, CE Loss, Accuracy, Weighted F1 and Macro F1 were included. The same pattern was observed as illustrated in $\S 5.2$.</p>
<h2>F Detailed Visualizations</h2>
<p>As shown in Figure 7, we plotted the distributions and the absolute errors from Chaos NLI HLV to provide more details. When (explicit) explanations were added, the absolute errors of MJDs became smaller, meaning they got closer to HJD.</p>
<h2>G Data Leakage for LLMs</h2>
<p>The lack of complete pre-training details on Large Language Models (LLMs) raises the potential risk of data contamination and the skepticism on LLM performance evaluation (Balloccu et al., 2024; BehnamGhader et al., 2024). To the best of our knowledge, there lacks concrete evidence showing either Mixtral-8x7b-Instruct-v0.1 (Jiang et al., 2024) or Llama3-Chat-70b (Meta, 2024) being contaminated by any of these tested datasets, MNLI (Williams et al., 2018), VariErr NLI (Wei et al., 2022b), and Chaos NLI (Nie et al., 2020). For the VariErr NLI dataset that provides explanations, its release date is later than that of Mixtral and Llama3, so it does not pose a leakage risk. Moreover, closely related to our datasets, Ahuja et al. (2024) conduct the Black Box contamination test (Oren et al., 2024) and show that XNLI (Conneau et al., 2018), a sub-sampled multilingual extension dataset of MNLI, did not leak data to either the Llama-2-7B (Touvron et al., 2023) or the Mistral-7B-Instruct (Jiang et al., 2023a) model. Since Mixtral or Llama have only released their weights, we do not have access to their training corpora. Therefore, we can only offer our perspectives and discussions on data leakage.</p>
<p>For the MNLI training part, to familiarize BERT and RoBERTa with the NLI task, we first finetuned the models on MNLI training set and then further fine-tuned them on our samples, which contain both HJDs and MJDs. Please note that in our fine-tuning comparison, the "gold" labels are derived from the distribution of 100 annotations in ChaosNLI, not the single labels from MNLI. Besides, the corpora we evaluated, 341 ChaosNLI training set and 629 dev/test set, were all extracted from MNLI-matched development set (Nie et al., 2020), which did not overlap with MNLI training set used for MNLI fine-tuning. Therefore, there is no risk of data leakage in this process.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Visualization of distributions and absolute errors in ternary plot and 3D Cartesian coordinate system. Each point represents one sample from the valid overlapped 341 instances.</p>
<h2>H Discussion for Temperature in Softmax</h2>
<p>Equation 3.2 is a standard softmax function used to convert the logits obtained from the LLM into a label probability distribution. Zhou et al. (2022) explores various methods for obtaining probability distributions, including Monte Carlo Dropout, among others. Since these methods are not significantly different from the conventional softmax, and exploring which normalization method is better is not the focus of this paper, we have directly adopted the most commonly used non-parametric normalization and parametric softmax approach. In the softmax function, the parameter $\tau$ is often referred to as the temperature coefficient, which smooths the probability distribution (a smaller $\tau$ makes the label distribution sharper, while a larger $\tau$ makes it smoother). Typically, for converting LLM logits into a probability distribution, $\tau$ should be set to a moderately sized value to prevent excessively small $\tau$ values from sharpening the probability distribution, thereby potentially losing the HLV information we aim to obtain.</p>
<p>Thus, during the distribution comparison, we adopted $\tau=20$ to obtain $\boldsymbol{p}<em _norm="{norm" _text="\text">{\text {sfmax }}$ that can be compared with $\boldsymbol{p}</em>}}$. In fact, for the metrics in Table 2, the results of $\boldsymbol{p<em _norm="{norm" _text="\text">{\text {sfmax }}$ improve initially as $\tau$ increases from 0 , and then decline, as shown in our toy trials. However, we did not specifically adjust the value of $\tau$ because it is not relevant to the focus of our study. $\boldsymbol{p}</em>$ does not have any parameters and still yields the desired results.}</p>
<p>During our in-depth investigation at $\S 6.1$, we discovered that the value of $\tau$ has an amplifying effect on the distribution shape within a certain range (not a true proportional amplification, but very similar within that range). Given our focus on exploring possible amplification patterns in the Llama3 MJDs, we adjusted $\tau$ from 20 to 10 to 5. This adjustment allowed us to better observe the intrinsic shape of the Llama3 MJD and investigate its correlation with Chaos NLI HJD. All the "scaled" MJDs are shown in Figure 8, including distributions of Mixtral and Llama3 under different settings. Also, we conducted fine-tuning comparison, same as $\S 5.2$, and listed all results in Table 10, for further analysis.</p>
<p>The results show that as $\tau$ decreases, the distribution becomes sharper, but this does not result in a linear change in metrics such as F1, KL divergence, and CE Loss. Since this parameter is highly dependent on the dataset and model, we did not spend extensive computational resources on a broader exploration of $\tau$ values.</p>
<h2>I All Results for Distance Correlation</h2>
<p>All results for distance correlation (Székely et al., 2007) of MJDs, including $p_{\text {norm }}$ and $p_{\text {sfmax }}$ with different $\tau$, are listed in Table 11 for further exploring. There are many methods to achieve smoothness, and finding the most suitable one for the task at hand goes beyond the current focus of this paper. We will delve deeper into how smoothness can enhance performance in future work.</p>
<h2>J "Assistant" Mode for Mixtral Prompt</h2>
<p>Here we'd introduce a really interesting way to prompt. Because this approach lacks a complete theoretical basis and currently proves effective only in Mixtral, not in Llama3, we are presenting the concept here without providing complete experimental evidence. We have proposed a special prompt method for chat templates based on Mixtral, which we refer to as "assistant" mode. We hope that anyone reading this who is interested or knowledgeable about this prompt method will be encouraged to further explore this approach.</p>
<p>We expected that LLM could focus more on the explanations in the "assistant" mode, since it is the text form that contains rich human label variation information. So we put the explanations in the content of assistant role as "comments" as shown in Table 13. In that case, we divide the MCQA into two part, first to ask LLM about their opinion on the original NLI instances, then out human explanations in the position of LLM response ("assistant" role). LLM would assume that the comments are its own previous answers and take more account on them. And finally let LLM give a choice among three NLI labels. It's a way to extract the potential of LLM's understanding capability for human label variation. Results are shown in Table 12.</p>
<p>We observed that in this approach, LLM's output becomes more sensitive to the input of explanations and seems to be more influenced by their content. However, our understanding is speculative. For example, Mixtral may emphasize "assistant" training during instruct tuning, or the architecture of a Mixture of Experts model might prioritize "assistant" content (as valuable global information to a specific expert). Yet, we lack the means to prove these speculations. Therefore, we present this as an interesting attempt in the appendix, acknowledging</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Distributions</th>
<th style="text-align: center;">BERT FT (dev / test)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">RoBERTa FT (dev / test)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
<td style="text-align: center;">Weighted F1 $\uparrow$</td>
<td style="text-align: center;">KL $\downarrow$</td>
<td style="text-align: center;">CE Loss $\downarrow$</td>
</tr>
<tr>
<td style="text-align: center;">Baseline</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Chaos NLI train set</td>
<td style="text-align: center;">0.626 / 0.646</td>
<td style="text-align: center;">0.074 / 0.077</td>
<td style="text-align: center;">0.972 / 0.974</td>
<td style="text-align: center;">0.699 / 0.650</td>
<td style="text-align: center;">0.061 / 0.067</td>
<td style="text-align: center;">0.932 / 0.943</td>
</tr>
<tr>
<td style="text-align: center;">MNLI single label</td>
<td style="text-align: center;">0.561 / 0.589</td>
<td style="text-align: center;">0.665 / 0.704</td>
<td style="text-align: center;">2.743 / 2.855</td>
<td style="text-align: center;">0.635 / 0.603</td>
<td style="text-align: center;">0.844 / 0.867</td>
<td style="text-align: center;">3.281 / 3.344</td>
</tr>
<tr>
<td style="text-align: center;">MNLI distributions</td>
<td style="text-align: center;">0.546 / 0.543</td>
<td style="text-align: center;">0.099 / 0.102</td>
<td style="text-align: center;">1.046 / 1.048</td>
<td style="text-align: center;">0.613 / 0.604</td>
<td style="text-align: center;">0.100 / 0.096</td>
<td style="text-align: center;">1.047 / 1.029</td>
</tr>
<tr>
<td style="text-align: center;">VariErr distributions</td>
<td style="text-align: center;">0.557 / 0.559</td>
<td style="text-align: center;">0.179 / 0.186</td>
<td style="text-align: center;">1.286 / 1.299</td>
<td style="text-align: center;">0.617 / 0.589</td>
<td style="text-align: center;">0.174 / 0.197</td>
<td style="text-align: center;">1.269 / 1.333</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Mixtral</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {norm }}$ of Mixtral</td>
<td style="text-align: center;">0.416 / 0.422</td>
<td style="text-align: center;">0.134 / 0.133</td>
<td style="text-align: center;">1.152 / 1.142</td>
<td style="text-align: center;">0.486 / 0.466</td>
<td style="text-align: center;">0.123 / 0.127</td>
<td style="text-align: center;">1.118 / 1.123</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.443 / 0.454</td>
<td style="text-align: center;">0.145 / 0.141</td>
<td style="text-align: center;">1.183 / 1.166</td>
<td style="text-align: center;">0.509 / 0.514</td>
<td style="text-align: center;">0.128 / 0.128</td>
<td style="text-align: center;">1.132 / 1.126</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.506 / 0.511</td>
<td style="text-align: center;">0.130 /0.130</td>
<td style="text-align: center;">1.139 / 1.132</td>
<td style="text-align: center;">0.569 / 0.572</td>
<td style="text-align: center;">0.114 / 0.122</td>
<td style="text-align: center;">1.091 / 1.107</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.404 / 0.428</td>
<td style="text-align: center;">0.134 / 0.131</td>
<td style="text-align: center;">1.150 / 1.136</td>
<td style="text-align: center;">0.483 / 0.502</td>
<td style="text-align: center;">0.123 / 0.122</td>
<td style="text-align: center;">1.118 / 1.109</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.507 / 0.514</td>
<td style="text-align: center;">0.108 / 0.108</td>
<td style="text-align: center;">1.074 / 1.065</td>
<td style="text-align: center;">0.558 / 0.565</td>
<td style="text-align: center;">0.092 / 0.098</td>
<td style="text-align: center;">1.025 / 1.037</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Mixtral $(\tau=20)$</td>
<td style="text-align: center;">0.427 / 0.432</td>
<td style="text-align: center;">0.131 / 0.129</td>
<td style="text-align: center;">1.140 / 1.130</td>
<td style="text-align: center;">0.497 / 0.472</td>
<td style="text-align: center;">0.121 / 0.125</td>
<td style="text-align: center;">1.112 / 1.118</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.452 / 0.462</td>
<td style="text-align: center;">0.121 / 0.118</td>
<td style="text-align: center;">1.113 / 1.096</td>
<td style="text-align: center;">0.506 / 0.525</td>
<td style="text-align: center;">0.110 / 0.109</td>
<td style="text-align: center;">1.078 / 1.069</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.509 / 0.520</td>
<td style="text-align: center;">0.105 / 0.105</td>
<td style="text-align: center;">1.064 / 1.057</td>
<td style="text-align: center;">0.568 / 0.573</td>
<td style="text-align: center;">0.093 / 0.098</td>
<td style="text-align: center;">1.026 / 1.036</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.397 / 0.429</td>
<td style="text-align: center;">0.121 / 0.119</td>
<td style="text-align: center;">1.112 / 1.098</td>
<td style="text-align: center;">0.497 / 0.505</td>
<td style="text-align: center;">0.110 / 0.111</td>
<td style="text-align: center;">1.079 / 1.074</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.522 / 0.517</td>
<td style="text-align: center;">0.095 / 0.095</td>
<td style="text-align: center;">1.035 / 1.026</td>
<td style="text-align: center;">0.567 / 0.576</td>
<td style="text-align: center;">0.082 / 0.087</td>
<td style="text-align: center;">0.994 / 1.003</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Mixtral $(\tau=10)$</td>
<td style="text-align: center;">0.445 / 0.435</td>
<td style="text-align: center;">0.210 / 0.214</td>
<td style="text-align: center;">1.380 / 1.384</td>
<td style="text-align: center;">0.487 / 0.492</td>
<td style="text-align: center;">0.207 / 0.209</td>
<td style="text-align: center;">1.369 / 1.370</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.457 / 0.461</td>
<td style="text-align: center;">0.198 / 0.195</td>
<td style="text-align: center;">1.344 / 1.328</td>
<td style="text-align: center;">0.522 / 0.533</td>
<td style="text-align: center;">0.181 / 0.182</td>
<td style="text-align: center;">1.290 / 1.288</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.522 / 0.532</td>
<td style="text-align: center;">0.184 / 0.188</td>
<td style="text-align: center;">1.302 / 1.306</td>
<td style="text-align: center;">0.599 / 0.584</td>
<td style="text-align: center;">0.176 / 0.191</td>
<td style="text-align: center;">1.275 / 1.314</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.426 / 0.432</td>
<td style="text-align: center;">0.175 / 0.176</td>
<td style="text-align: center;">1.275 / 1.269</td>
<td style="text-align: center;">0.518 / 0.514</td>
<td style="text-align: center;">0.157 / 0.158</td>
<td style="text-align: center;">1.221 / 1.217</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.521 / 0.524</td>
<td style="text-align: center;">0.143 / 0.145</td>
<td style="text-align: center;">1.177 / 1.176</td>
<td style="text-align: center;">0.576 / 0.567</td>
<td style="text-align: center;">0.126 / 0.140</td>
<td style="text-align: center;">1.128 / 1.162</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Mixtral $(\tau=5)$</td>
<td style="text-align: center;">0.453 / 0.439</td>
<td style="text-align: center;">0.330 / 0.338</td>
<td style="text-align: center;">1.737 / 1.757</td>
<td style="text-align: center;">0.559 / 0.542</td>
<td style="text-align: center;">0.143 / 0.150</td>
<td style="text-align: center;">1.177 / 1.192</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.452 / 0.464</td>
<td style="text-align: center;">0.287 / 0.287</td>
<td style="text-align: center;">1.610 / 1.604</td>
<td style="text-align: center;">0.573 / 0.581</td>
<td style="text-align: center;">0.113 / 0.116</td>
<td style="text-align: center;">1.088 / 1.091</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.525 / 0.530</td>
<td style="text-align: center;">0.295 / 0.308</td>
<td style="text-align: center;">1.634 / 1.665</td>
<td style="text-align: center;">0.593 / 0.588</td>
<td style="text-align: center;">0.131 / 0.138</td>
<td style="text-align: center;">1.142 / 1.156</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.435 / 0.430</td>
<td style="text-align: center;">0.217 / 0.221</td>
<td style="text-align: center;">1.398 / 1.406</td>
<td style="text-align: center;">0.593 / 0.599</td>
<td style="text-align: center;">0.095 / 0.098</td>
<td style="text-align: center;">1.034 / 1.037</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.520 / 0.527</td>
<td style="text-align: center;">0.180 / 0.184</td>
<td style="text-align: center;">1.289 / 1.294</td>
<td style="text-align: center;">0.589 / 0.574</td>
<td style="text-align: center;">0.098 / 0.101</td>
<td style="text-align: center;">1.043 / 1.045</td>
</tr>
<tr>
<td style="text-align: center;">MJDs from Llama3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {norm }}$ of Llama3</td>
<td style="text-align: center;">0.514 / 0.526</td>
<td style="text-align: center;">0.097 / 0.098</td>
<td style="text-align: center;">1.038 / 1.036</td>
<td style="text-align: center;">0.541 / 0.528</td>
<td style="text-align: center;">0.091 / 0.094</td>
<td style="text-align: center;">1.023 / 1.025</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.574 / 0.574</td>
<td style="text-align: center;">0.096 / 0.097</td>
<td style="text-align: center;">1.037 / 1.033</td>
<td style="text-align: center;">0.618 / 0.601</td>
<td style="text-align: center;">0.091 / 0.093</td>
<td style="text-align: center;">1.020 / 1.022</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.578 / 0.574</td>
<td style="text-align: center;">0.091 / 0.092</td>
<td style="text-align: center;">1.022 / 1.018</td>
<td style="text-align: center;">0.634 / 0.598</td>
<td style="text-align: center;">0.085 / 0.088</td>
<td style="text-align: center;">1.003 / 1.006</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.573 / 0.582</td>
<td style="text-align: center;">0.098 / 0.098</td>
<td style="text-align: center;">1.041 / 1.038</td>
<td style="text-align: center;">0.636 / 0.598</td>
<td style="text-align: center;">0.093 / 0.095</td>
<td style="text-align: center;">1.026 / 1.028</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.582 / 0.586</td>
<td style="text-align: center;">0.094 / 0.095</td>
<td style="text-align: center;">1.030 / 1.026</td>
<td style="text-align: center;">0.639 / 0.620</td>
<td style="text-align: center;">0.089 / 0.091</td>
<td style="text-align: center;">1.014 / 1.016</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Llama3 $(\tau=20)$</td>
<td style="text-align: center;">0.528 / 0.524</td>
<td style="text-align: center;">0.091 / 0.093</td>
<td style="text-align: center;">1.023 / 1.021</td>
<td style="text-align: center;">0.546 / 0.535</td>
<td style="text-align: center;">0.085 / 0.089</td>
<td style="text-align: center;">1.005 / 1.009</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.567 / 0.576</td>
<td style="text-align: center;">0.091 / 0.091</td>
<td style="text-align: center;">1.021 / 1.016</td>
<td style="text-align: center;">0.626 / 0.608</td>
<td style="text-align: center;">0.082 / 0.086</td>
<td style="text-align: center;">0.996 / 1.000</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.585 / 0.568</td>
<td style="text-align: center;">0.086 / 0.087</td>
<td style="text-align: center;">1.008 / 1.004</td>
<td style="text-align: center;">0.646 / 0.610</td>
<td style="text-align: center;">0.077 / 0.081</td>
<td style="text-align: center;">0.981 / 0.987</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.584 / 0.583</td>
<td style="text-align: center;">0.092 / 0.093</td>
<td style="text-align: center;">1.024 / 1.020</td>
<td style="text-align: center;">0.643 / 0.611</td>
<td style="text-align: center;">0.085 / 0.089</td>
<td style="text-align: center;">1.004 / 1.008</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.581 / 0.578</td>
<td style="text-align: center;">0.088 / 0.089</td>
<td style="text-align: center;">1.014 / 1.010</td>
<td style="text-align: center;">0.645 / 0.621</td>
<td style="text-align: center;">0.081 / 0.085</td>
<td style="text-align: center;">0.993 / 0.996</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Llama3 $(\tau=10)$</td>
<td style="text-align: center;">0.550 / 0.541</td>
<td style="text-align: center;">0.090 / 0.093</td>
<td style="text-align: center;">1.020 / 1.021</td>
<td style="text-align: center;">0.571 / 0.547</td>
<td style="text-align: center;">0.085 / 0.089</td>
<td style="text-align: center;">1.003 / 1.009</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.571 / 0.582</td>
<td style="text-align: center;">0.084 / 0.085</td>
<td style="text-align: center;">1.000 / 0.996</td>
<td style="text-align: center;">0.644 / 0.619</td>
<td style="text-align: center;">0.072 / 0.078</td>
<td style="text-align: center;">0.964 / 0.976</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.582 / 0.602</td>
<td style="text-align: center;">0.081 / 0.083</td>
<td style="text-align: center;">0.993 / 0.992</td>
<td style="text-align: center;">0.656 / 0.621</td>
<td style="text-align: center;">0.070 / 0.079</td>
<td style="text-align: center;">0.960 / 0.978</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.588 / 0.588</td>
<td style="text-align: center;">0.083 / 0.084</td>
<td style="text-align: center;">0.998 / 0.995</td>
<td style="text-align: center;">0.649 / 0.612</td>
<td style="text-align: center;">0.071 / 0.077</td>
<td style="text-align: center;">0.962 / 0.973</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.576 / 0.587</td>
<td style="text-align: center;">0.079 / 0.080</td>
<td style="text-align: center;">0.985 / 0.982</td>
<td style="text-align: center;">0.661 / 0.616</td>
<td style="text-align: center;">0.066 / 0.073</td>
<td style="text-align: center;">0.946 / 0.960</td>
</tr>
<tr>
<td style="text-align: center;">$\boldsymbol{p}_{\text {clmax }}$ of Llama3 $(\tau=5)$</td>
<td style="text-align: center;">0.484 / 0.502</td>
<td style="text-align: center;">0.345 / 0.347</td>
<td style="text-align: center;">1.785 / 1.783</td>
<td style="text-align: center;">0.588 / 0.555</td>
<td style="text-align: center;">0.144 / 0.150</td>
<td style="text-align: center;">1.182 / 1.193</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explanations</td>
<td style="text-align: center;">0.531 / 0.525</td>
<td style="text-align: center;">0.271 / 0.276</td>
<td style="text-align: center;">1.563 / 1.570</td>
<td style="text-align: center;">0.657 / 0.621</td>
<td style="text-align: center;">0.104 / 0.118</td>
<td style="text-align: center;">1.061 / 1.097</td>
</tr>
<tr>
<td style="text-align: center;">+ "serial" explicit explanations</td>
<td style="text-align: center;">0.599 / 0.590</td>
<td style="text-align: center;">0.311 / 0.331</td>
<td style="text-align: center;">1.682 / 1.735</td>
<td style="text-align: center;">0.663 / 0.622</td>
<td style="text-align: center;">0.132 / 0.150</td>
<td style="text-align: center;">1.145 / 1.192</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explanations</td>
<td style="text-align: center;">0.516 / 0.524</td>
<td style="text-align: center;">0.207 / 0.210</td>
<td style="text-align: center;">1.370 / 1.373</td>
<td style="text-align: center;">0.658 / 0.611</td>
<td style="text-align: center;">0.082 / 0.093</td>
<td style="text-align: center;">0.995 / 1.022</td>
</tr>
<tr>
<td style="text-align: center;">+ "parallel" explicit explanations</td>
<td style="text-align: center;">0.577 / 0.568</td>
<td style="text-align: center;">0.171 / 0.191</td>
<td style="text-align: center;">1.262 / 1.315</td>
<td style="text-align: center;">0.672 / 0.623</td>
<td style="text-align: center;">0.083 / 0.096</td>
<td style="text-align: center;">0.996 / 1.030</td>
</tr>
</tbody>
</table>
<p>Table 10: Results for " $\tau$ " discussion of fine-tuning comparison on Chaos NLI dev/test set. The KL and CrossEntropy (CE) Loss reflected the distance between distributions, whereas Weighted F1 reflected the capability to handle NLI problems. When $\tau$ gets smaller the F1 of Llama3 will improve. However, the change of KL and CE Loss is not linear. It seems we could find a balance point for both performance between single label evaluation and distribution evaluation by searching $\tau$, which could be a future study.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Distributions</th>
<th style="text-align: center;">$p_{\text {norm }}$</th>
<th style="text-align: center;">$p_{\text {sfmax }} \tau=20$</th>
<th style="text-align: center;">$p_{\text {sfmax }} \tau=10$</th>
<th style="text-align: center;">$p_{\text {sfmax }} \tau=5$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">D.Corr $\uparrow$</td>
<td style="text-align: center;">D.Corr $\uparrow$</td>
<td style="text-align: center;">D.Corr $\uparrow$</td>
<td style="text-align: center;">D.Corr $\uparrow$</td>
</tr>
<tr>
<td style="text-align: left;">Chaos NLI</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">MNLI single label</td>
<td style="text-align: center;">0.612</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">MNLI distribution</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">VariErr NLI</td>
<td style="text-align: center;">0.688</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral original</td>
<td style="text-align: center;">0.609</td>
<td style="text-align: center;">0.593</td>
<td style="text-align: center;">0.584</td>
<td style="text-align: center;">0.577</td>
</tr>
<tr>
<td style="text-align: left;">4 explanations at a time</td>
<td style="text-align: center;">0.642</td>
<td style="text-align: center;">0.621</td>
<td style="text-align: center;">0.612</td>
<td style="text-align: center;">0.605</td>
</tr>
<tr>
<td style="text-align: left;">3 explanations at a time</td>
<td style="text-align: center;">0.659</td>
<td style="text-align: center;">0.636</td>
<td style="text-align: center;">0.625</td>
<td style="text-align: center;">0.617</td>
</tr>
<tr>
<td style="text-align: left;">2 explanations at a time</td>
<td style="text-align: center;">0.685</td>
<td style="text-align: center;">0.662</td>
<td style="text-align: center;">0.651</td>
<td style="text-align: center;">0.644</td>
</tr>
<tr>
<td style="text-align: left;">1 explanations at a time</td>
<td style="text-align: center;">0.731</td>
<td style="text-align: center;">0.713</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">0.697</td>
</tr>
<tr>
<td style="text-align: left;">4 explicit explanations at a time</td>
<td style="text-align: center;">0.623</td>
<td style="text-align: center;">0.608</td>
<td style="text-align: center;">0.601</td>
<td style="text-align: center;">0.596</td>
</tr>
<tr>
<td style="text-align: left;">3 explicit explanations at a time</td>
<td style="text-align: center;">0.651</td>
<td style="text-align: center;">0.637</td>
<td style="text-align: center;">0.629</td>
<td style="text-align: center;">0.624</td>
</tr>
<tr>
<td style="text-align: left;">2 explicit explanations at a time</td>
<td style="text-align: center;">0.678</td>
<td style="text-align: center;">0.664</td>
<td style="text-align: center;">0.606</td>
<td style="text-align: center;">0.652</td>
</tr>
<tr>
<td style="text-align: left;">1 explicit explanation at a time</td>
<td style="text-align: center;">0.719</td>
<td style="text-align: center;">0.709</td>
<td style="text-align: center;">0.704</td>
<td style="text-align: center;">0.701</td>
</tr>
<tr>
<td style="text-align: left;">Llama3 original</td>
<td style="text-align: center;">0.689</td>
<td style="text-align: center;">0.677</td>
<td style="text-align: center;">0.665</td>
<td style="text-align: center;">0.656</td>
</tr>
<tr>
<td style="text-align: left;">4 explanations at a time</td>
<td style="text-align: center;">0.750</td>
<td style="text-align: center;">0.740</td>
<td style="text-align: center;">0.730</td>
<td style="text-align: center;">0.714</td>
</tr>
<tr>
<td style="text-align: left;">3 explanations at a time</td>
<td style="text-align: center;">0.770</td>
<td style="text-align: center;">0.763</td>
<td style="text-align: center;">0.754</td>
<td style="text-align: center;">0.743</td>
</tr>
<tr>
<td style="text-align: left;">2 explanations at a time</td>
<td style="text-align: center;">0.795</td>
<td style="text-align: center;">0.790</td>
<td style="text-align: center;">0.783</td>
<td style="text-align: center;">0.774</td>
</tr>
<tr>
<td style="text-align: left;">1 explanations at a time</td>
<td style="text-align: center;">0.818</td>
<td style="text-align: center;">0.812</td>
<td style="text-align: center;">0.807</td>
<td style="text-align: center;">0.797</td>
</tr>
<tr>
<td style="text-align: left;">4 explicit explanations at a time</td>
<td style="text-align: center;">0.733</td>
<td style="text-align: center;">0.725</td>
<td style="text-align: center;">0.716</td>
<td style="text-align: center;">0.703</td>
</tr>
<tr>
<td style="text-align: left;">3 explicit explanations at a time</td>
<td style="text-align: center;">0.757</td>
<td style="text-align: center;">0.752</td>
<td style="text-align: center;">0.746</td>
<td style="text-align: center;">0.739</td>
</tr>
<tr>
<td style="text-align: left;">2 explicit explanations at a time</td>
<td style="text-align: center;">0.784</td>
<td style="text-align: center;">0.779</td>
<td style="text-align: center;">0.774</td>
<td style="text-align: center;">0.769</td>
</tr>
<tr>
<td style="text-align: left;">1 explicit explanation at a time</td>
<td style="text-align: center;">0.809</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.796</td>
<td style="text-align: center;">0.787</td>
</tr>
</tbody>
</table>
<p>Table 11: Distance Correlation (D.Corr) results. All ablation results for comments numbers. Scores are compared with Chaos NLI's HJD.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ https://scikit-learn.org/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>