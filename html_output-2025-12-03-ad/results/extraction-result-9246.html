<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9246 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9246</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9246</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-267280972</p>
                <p><strong>Paper Title:</strong> LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models</p>
                <p><strong>Paper Abstract:</strong> System logs are a valuable source of information for monitoring and maintaining the security and stability of computer systems. Techniques based on Deep Learning and Natural Language Processing have demonstrated effectiveness in detecting abnormal behaviour from these system logs. However, existing anomaly detection approaches have limitations in terms of flexibility and practicality. Techniques that rely on log templates such as DeepLog and LogBERT fail to capture semantic information and are unable to handle variability in log content. On the other hand, classification-based approaches such as LogSy, LogRobust and HitAnomaly require time-consuming data labelling for supervised training. In this paper, a novel log anomaly detection model named LogFiT is proposed. The LogFiT model doesn’t make use of a vocabulary of log templates and it doesn’t require any labeled data as the model only requires self-supervised training. The LogFiT model uses a pretrained Bidirectional Encoder Representations from Transformers (BERT)-based language model fine-tuned to recognise the linguistic patterns of the normal log data. The LogFiT model is trained using masked sentence prediction on the normal log data only. Consequently, when presented with the new log data, the model’s top- ${k}$ token prediction accuracy serves as a threshold for determining whether the new log data deviates from the normal log data. Experimental results show that LogFiT’s F1 score exceeds that of baselines on the HDFS, BGL, and Thunderbird datasets. Critically, when variability is introduced in the log data during evaluation, LogFiT retains its effectiveness compared to that of baselines.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9246.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9246.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogFiT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-supervised log anomaly detection system that fine-tunes a pretrained BERT-family encoder (RoBERTa or Longformer) on normal log paragraphs using a novel masked sentence prediction objective and uses top-k masked token prediction accuracy as an anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa / Longformer (pretrained, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT-family)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Ordered sequences of log sentences grouped into 'log paragraphs' (sequence data; tokenized natural-language log lines)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs / operational telemetry (HDFS, BGL, Thunderbird datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Operational anomalies in logs (abnormal sequences/events, out-of-distribution or unexpected log sentence content, error/failure events)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Self-supervised fine-tuning of a pretrained transformer encoder using a masked sentence prediction objective: randomly mask a variable fraction of sentences in a log paragraph (default 0.5) and mask a large fraction of tokens in those sentences (default 0.8), then minimise cross-entropy of predicted masked tokens; during inference use the model's top-k token prediction accuracy on masked tokens as anomaly score and threshold it to label paragraphs as anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared primarily against DeepLog (LSTM forecasting on log template IDs) and LogBERT (BERT-style reconstruction with centroid loss / template-key prediction); other referenced baselines include LogRobust, HitAnomaly, LogSy (supervised methods) and parsing-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 score, Specificity; also throughput (samples/sec) reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Authors report LogFiT's F1 exceeds DeepLog and LogBERT on HDFS, BGL, and Thunderbird datasets. In a robustness test (BGL with top-10 verbs replaced by WordNet lemmas) reported F1: LogFiT dropped from 91.22 to 89.38 (≈2% drop); LogBERT dropped from 88.63 to 44.22; DeepLog dropped from 79.25 to 53.38. Specificity for LogFiT exceeded baselines on HDFS and BGL and was comparable on Thunderbird. Throughput: LogFiT was slower than baselines (due to larger 50K subword vocab and longer token support up to 4096 tokens), exact throughput numbers are reported in tables but not quoted in text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Better — LogFiT outperformed DeepLog and LogBERT on standard metrics (F1, specificity) across evaluated datasets and showed much higher robustness to lexical variability; however LogFiT had lower throughput than some baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower inference throughput due to large vocabulary and larger embedding layers; centroid distance minimisation (added and tested) did not improve detection and was removed; hyperparameter selection (top-k and threshold) required tuning; k-fold cross-validation may cause temporal leakage in time-ordered logs; not optimised for runtime efficiency (authors propose LoRA, quantisation, optimized serving as future work).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Masked sentence prediction (masking whole sentences as well as tokens) forces the model to learn inter-sentence sequential relationships as well as intra-sentence context; using pretrained LMs' subword vocabulary yields robustness to lexical variation in logs, eliminating need for log-template parsing; top-k token prediction accuracy is an effective reconstruction-style anomaly score for unlabeled normal-only training; heuristic to choose RoBERTa vs Longformer based on 0.8-quantile token length of training samples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9246.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa: A Robustly Optimized BERT Pretraining Approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-family pretrained Transformer encoder used as the base model in LogFiT for datasets whose tokenized samples do not exceed 512 tokens; fine-tuned on normal logs with the masked sentence prediction objective.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RoBERTa: A robustly optimized BERT pretraining approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (pretrained)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT variant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of tokenized log sentences (log paragraphs up to 512 tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (HDFS, BGL, Thunderbird where sample length <=512 tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log paragraphs / abnormal sequences</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used as the fine-tuning backbone in LogFiT (fine-tuned on normal logs using masked sentence prediction), selected by heuristic when 0.8-quantile of training sample lengths ≤ 512 tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Used in place of (or compared with) Longformer; compared against systems that use log-template vocabularies.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1, Specificity, throughput</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Contributes to LogFiT's higher F1 and robustness on datasets with shorter sequences; specific per-model numbers not separately reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>As a pretrained encoder fine-tuned by LogFiT, RoBERTa-based LogFiT outperformed baseline methods in experiments where RoBERTa was applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Token limit of 512 requires switching to Longformer for longer log paragraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Fine-tuning a strong pretrained encoder (RoBERTa) on normal-only logs with sentence-level masking gives substantial gains in contextual understanding for anomaly detection without template parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9246.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Longformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Longformer: The Long-Document Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer variant that supports long input sequences using a combination of local and global attention; used in LogFiT for datasets where log paragraphs exceed 512 tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Longformer: The long-document transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Longformer (pretrained)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder with sliding-window local attention (long-document transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Long sequences of tokenized log sentences (log paragraphs exceeding 512 tokens, up to 4096 tokens supported by LogFiT)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs with long paragraphs (e.g., Thunderbird with long sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous long log paragraphs / sequence anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used as the fine-tuning backbone in LogFiT for long sequences; fine-tuned with masked sentence prediction to learn long-range inter-sentence patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Selected instead of RoBERTa based on a 0.8-quantile length heuristic; compared against transformer baselines like LogBERT and LSTM-based DeepLog.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1, Specificity, throughput</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Enables LogFiT to handle long samples (up to 4096 tokens) and contributed to superior F1 on datasets with longer sequences; Longformer-based LogFiT had lower throughput but sustained detection performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Provided practical advantage over base BERT/RoBERTa when handling long sequences; when used in LogFiT outperformed baselines on long-sequence datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Higher compute and throughput cost compared to some baselines; needs careful model selection heuristic.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Using Longformer permits end-to-end LM fine-tuning on long log paragraphs, enabling modeling of long-range dependencies in logs without template parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9246.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogBERT: Log anomaly detection via BERT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-based reconstruction-style log anomaly detector that relies on log parsing/templates and uses masked key prediction and centroid-distance minimisation as part of its anomaly scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogBERT: Log anomaly detection via BERT</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Custom BERT (task-specific BERT trained from scratch in original LogBERT work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log template IDs (parsing-based representation derived from log templates)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (same datasets used as baseline comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous sequences of log templates (out-of-distribution template sequences, reconstruction failures)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mask and predict log keys (template-based tokens) and optionally minimise centroid distance of semantic vectors; anomaly decision via top-k prediction accuracy and/or centroid-distance thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against DeepLog and LogFiT in this paper; originally compared to other LSTM and template-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Top-k accuracy, Precision, Recall, F1, Specificity, centroid distance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>In the paper's experiments LogBERT was outperformed by LogFiT on F1 across HDFS, BGL, and Thunderbird; in variability test LogBERT's F1 dropped sharply (88.63 -> 44.22) when top verbs were replaced by lemmas, indicating sensitivity to lexical/template variation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>LogFiT showed superior robustness and higher F1 than LogBERT, particularly under lexical variation; LogBERT's reliance on parsed templates and training-from-scratch limited adaptability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Dependency on log parsing and template vocabularies reduces robustness to unseen or evolving log sentences; training from scratch forfeits benefits of pretrained semantic knowledge; centroid distance minimisation may not help generalisation (as found when authors tried similar objective in LogFiT).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>LogBERT's template-based reconstruction combined with centroid heuristics can perform well in static settings but is brittle under lexical/schema evolution; using pretrained LMs and avoiding template parsing (as LogFiT does) improves robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9246.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepLog: Anomaly detection and diagnosis from system logs through deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LSTM-based forecasting approach that predicts the next log template ID from previous templates and flags anomalies when the true template is not within top-k predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DeepLog: Anomaly detection and diagnosis from system logs through deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepLog LSTM model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM (sequential RNN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log template IDs derived from log parsing</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (HDFS, BGL, Thunderbird)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous next-event predictions (missing expected subsequent templates, rare sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Forecasting-based approach: train LSTM on sequences of log template IDs to predict the next template; at inference consider top-k predictions and flag anomalies if ground truth not in top-k.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Serves as a primary baseline for LogFiT and LogBERT comparisons in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Top-k accuracy, Precision, Recall, F1, Specificity, throughput</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>DeepLog was outperformed by LogFiT on F1 across datasets; DeepLog also showed substantial performance degradation under lexical variation (F1 79.25 -> 53.38 in BGL verb-lemma test). DeepLog had high throughput on the HDFS dataset (short sequences) but lower throughput on datasets with longer sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>LogFiT (LM fine-tuning) yielded higher F1 and better robustness to lexical changes than DeepLog; DeepLog can be faster for short sequences but is limited by template vocabulary and LSTM sequence modeling limits.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on log parsing/templates and an LSTM architecture limiting long-range context learning and robustness to lexical variability; implementations may leak test set into parsing step if not careful (authors corrected such issues).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Forecasting-based template prediction works well in stable, template-rich environments but is brittle under schema/lexical evolution; transformer-based LM fine-tuning on raw text (no parsing) can overcome those weaknesses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9246.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LAnoBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LAnoBERT: System log anomaly detection based on BERT masked language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parsing-free BERT-based approach that uses BERT's masked language modelling to detect anomalies in logs without conventional parsing, but which trains a BERT model from scratch (per referenced summaries).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LAnoBERT: System log anomaly detection based on BERT masked language model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (task-specific BERT trained in LAnoBERT work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of log sentences tokenized as natural language (parsing-free)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs (parsing-free approaches)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous log sentences/sequences detected via masked prediction reconstruction error</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses BERT masked language modelling to detect anomalies in raw log sentences without template parsing; however LAnoBERT trains a BERT model from scratch rather than leveraging pretrained weights.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Mentioned in related work as a parsing-free approach; contrasted with LogFiT which fine-tunes pretrained LMs rather than training from scratch.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in this paper (cited work), but typically reconstruction-based metrics (top-k accuracy, F1, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>LAnoBERT is parsing-free like LogFiT but less practical because it trains from scratch and therefore misses advantages of pretrained semantic knowledge and transfer learning (as discussed by authors).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Training from scratch limits cross-dataset reuse and forfeits benefits of pretrained language models; potential lack of robustness compared to fine-tuned pretrained LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9246.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9246.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained Transformer encoder (masked language model) that provides contextualized token representations and reconstruction ability; used as conceptual and technical foundation for LogFiT and many related log-anomaly works.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BERT: Pre-training of deep bidirectional transformers for language understanding</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (pretrained)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer encoder (masked language model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Natural language sequences / tokenized sentences (applied here to log sentences and paragraphs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>General NLP and system logs (adapted via fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Reconstruction/failure to predict masked tokens indicating anomalous or out-of-distribution input</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Provides pretrained weights that can be fine-tuned on normal logs using masked-token/sentence prediction; reconstruction/top-k prediction accuracy used as anomaly signal.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Basis for RoBERTa, LogBERT, LAnoBERT, and LogFiT approaches</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used indirectly; enables improved F1 and robustness when fine-tuned compared to training-from-scratch or template-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Using pretrained BERT-family models and fine-tuning (LogFiT) outperformed approaches that trained BERT from scratch or used template-only representations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Vanilla BERT has token length limit (512) and high compute; requires adaptions (Longformer) for long sequences; fine-tuning can distort pretrained features if not done carefully (noted in related literature).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Pretrained LMs capture sentence-level contextual and semantic information and better handle out-of-vocabulary tokens, which improves anomaly detection robustness when logs evolve lexically.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models', 'publication_date_yy_mm': '2024-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogBERT: Log anomaly detection via BERT <em>(Rating: 2)</em></li>
                <li>DeepLog: Anomaly detection and diagnosis from system logs through deep learning <em>(Rating: 2)</em></li>
                <li>LAnoBERT: System log anomaly detection based on BERT masked language model <em>(Rating: 2)</em></li>
                <li>Robust and transferable anomaly detection in log data using pre-trained language models <em>(Rating: 2)</em></li>
                <li>Pretrained Transformers Improve Out-of-Distribution Robustness <em>(Rating: 1)</em></li>
                <li>Log-based anomaly detection without log parsing <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9246",
    "paper_id": "paper-267280972",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "LogFiT",
            "name_full": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
            "brief_description": "A self-supervised log anomaly detection system that fine-tunes a pretrained BERT-family encoder (RoBERTa or Longformer) on normal log paragraphs using a novel masked sentence prediction objective and uses top-k masked token prediction accuracy as an anomaly score.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RoBERTa / Longformer (pretrained, fine-tuned)",
            "model_type": "Transformer encoder (BERT-family)",
            "model_size": null,
            "data_type": "Ordered sequences of log sentences grouped into 'log paragraphs' (sequence data; tokenized natural-language log lines)",
            "data_domain": "System logs / operational telemetry (HDFS, BGL, Thunderbird datasets)",
            "anomaly_type": "Operational anomalies in logs (abnormal sequences/events, out-of-distribution or unexpected log sentence content, error/failure events)",
            "method_description": "Self-supervised fine-tuning of a pretrained transformer encoder using a masked sentence prediction objective: randomly mask a variable fraction of sentences in a log paragraph (default 0.5) and mask a large fraction of tokens in those sentences (default 0.8), then minimise cross-entropy of predicted masked tokens; during inference use the model's top-k token prediction accuracy on masked tokens as anomaly score and threshold it to label paragraphs as anomalous.",
            "baseline_methods": "Compared primarily against DeepLog (LSTM forecasting on log template IDs) and LogBERT (BERT-style reconstruction with centroid loss / template-key prediction); other referenced baselines include LogRobust, HitAnomaly, LogSy (supervised methods) and parsing-based approaches.",
            "performance_metrics": "Precision, Recall, F1 score, Specificity; also throughput (samples/sec) reported.",
            "performance_results": "Authors report LogFiT's F1 exceeds DeepLog and LogBERT on HDFS, BGL, and Thunderbird datasets. In a robustness test (BGL with top-10 verbs replaced by WordNet lemmas) reported F1: LogFiT dropped from 91.22 to 89.38 (≈2% drop); LogBERT dropped from 88.63 to 44.22; DeepLog dropped from 79.25 to 53.38. Specificity for LogFiT exceeded baselines on HDFS and BGL and was comparable on Thunderbird. Throughput: LogFiT was slower than baselines (due to larger 50K subword vocab and longer token support up to 4096 tokens), exact throughput numbers are reported in tables but not quoted in text.",
            "comparison_to_baseline": "Better — LogFiT outperformed DeepLog and LogBERT on standard metrics (F1, specificity) across evaluated datasets and showed much higher robustness to lexical variability; however LogFiT had lower throughput than some baselines.",
            "limitations_or_failure_cases": "Lower inference throughput due to large vocabulary and larger embedding layers; centroid distance minimisation (added and tested) did not improve detection and was removed; hyperparameter selection (top-k and threshold) required tuning; k-fold cross-validation may cause temporal leakage in time-ordered logs; not optimised for runtime efficiency (authors propose LoRA, quantisation, optimized serving as future work).",
            "unique_insights": "Masked sentence prediction (masking whole sentences as well as tokens) forces the model to learn inter-sentence sequential relationships as well as intra-sentence context; using pretrained LMs' subword vocabulary yields robustness to lexical variation in logs, eliminating need for log-template parsing; top-k token prediction accuracy is an effective reconstruction-style anomaly score for unlabeled normal-only training; heuristic to choose RoBERTa vs Longformer based on 0.8-quantile token length of training samples.",
            "uuid": "e9246.0",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "RoBERTa",
            "name_full": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
            "brief_description": "A BERT-family pretrained Transformer encoder used as the base model in LogFiT for datasets whose tokenized samples do not exceed 512 tokens; fine-tuned on normal logs with the masked sentence prediction objective.",
            "citation_title": "RoBERTa: A robustly optimized BERT pretraining approach",
            "mention_or_use": "use",
            "model_name": "RoBERTa (pretrained)",
            "model_type": "Transformer encoder (BERT variant)",
            "model_size": null,
            "data_type": "Sequences of tokenized log sentences (log paragraphs up to 512 tokens)",
            "data_domain": "System logs (HDFS, BGL, Thunderbird where sample length &lt;=512 tokens)",
            "anomaly_type": "Anomalous log paragraphs / abnormal sequences",
            "method_description": "Used as the fine-tuning backbone in LogFiT (fine-tuned on normal logs using masked sentence prediction), selected by heuristic when 0.8-quantile of training sample lengths ≤ 512 tokens.",
            "baseline_methods": "Used in place of (or compared with) Longformer; compared against systems that use log-template vocabularies.",
            "performance_metrics": "Precision, Recall, F1, Specificity, throughput",
            "performance_results": "Contributes to LogFiT's higher F1 and robustness on datasets with shorter sequences; specific per-model numbers not separately reported.",
            "comparison_to_baseline": "As a pretrained encoder fine-tuned by LogFiT, RoBERTa-based LogFiT outperformed baseline methods in experiments where RoBERTa was applicable.",
            "limitations_or_failure_cases": "Token limit of 512 requires switching to Longformer for longer log paragraphs.",
            "unique_insights": "Fine-tuning a strong pretrained encoder (RoBERTa) on normal-only logs with sentence-level masking gives substantial gains in contextual understanding for anomaly detection without template parsing.",
            "uuid": "e9246.1",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "Longformer",
            "name_full": "Longformer: The Long-Document Transformer",
            "brief_description": "A Transformer variant that supports long input sequences using a combination of local and global attention; used in LogFiT for datasets where log paragraphs exceed 512 tokens.",
            "citation_title": "Longformer: The long-document transformer",
            "mention_or_use": "use",
            "model_name": "Longformer (pretrained)",
            "model_type": "Transformer encoder with sliding-window local attention (long-document transformer)",
            "model_size": null,
            "data_type": "Long sequences of tokenized log sentences (log paragraphs exceeding 512 tokens, up to 4096 tokens supported by LogFiT)",
            "data_domain": "System logs with long paragraphs (e.g., Thunderbird with long sequences)",
            "anomaly_type": "Anomalous long log paragraphs / sequence anomalies",
            "method_description": "Used as the fine-tuning backbone in LogFiT for long sequences; fine-tuned with masked sentence prediction to learn long-range inter-sentence patterns.",
            "baseline_methods": "Selected instead of RoBERTa based on a 0.8-quantile length heuristic; compared against transformer baselines like LogBERT and LSTM-based DeepLog.",
            "performance_metrics": "Precision, Recall, F1, Specificity, throughput",
            "performance_results": "Enables LogFiT to handle long samples (up to 4096 tokens) and contributed to superior F1 on datasets with longer sequences; Longformer-based LogFiT had lower throughput but sustained detection performance.",
            "comparison_to_baseline": "Provided practical advantage over base BERT/RoBERTa when handling long sequences; when used in LogFiT outperformed baselines on long-sequence datasets.",
            "limitations_or_failure_cases": "Higher compute and throughput cost compared to some baselines; needs careful model selection heuristic.",
            "unique_insights": "Using Longformer permits end-to-end LM fine-tuning on long log paragraphs, enabling modeling of long-range dependencies in logs without template parsing.",
            "uuid": "e9246.2",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "LogBERT",
            "name_full": "LogBERT: Log anomaly detection via BERT",
            "brief_description": "A BERT-based reconstruction-style log anomaly detector that relies on log parsing/templates and uses masked key prediction and centroid-distance minimisation as part of its anomaly scoring.",
            "citation_title": "LogBERT: Log anomaly detection via BERT",
            "mention_or_use": "use",
            "model_name": "Custom BERT (task-specific BERT trained from scratch in original LogBERT work)",
            "model_type": "Transformer encoder (BERT)",
            "model_size": null,
            "data_type": "Sequences of log template IDs (parsing-based representation derived from log templates)",
            "data_domain": "System logs (same datasets used as baseline comparisons)",
            "anomaly_type": "Anomalous sequences of log templates (out-of-distribution template sequences, reconstruction failures)",
            "method_description": "Mask and predict log keys (template-based tokens) and optionally minimise centroid distance of semantic vectors; anomaly decision via top-k prediction accuracy and/or centroid-distance thresholds.",
            "baseline_methods": "Compared against DeepLog and LogFiT in this paper; originally compared to other LSTM and template-based approaches.",
            "performance_metrics": "Top-k accuracy, Precision, Recall, F1, Specificity, centroid distance metrics.",
            "performance_results": "In the paper's experiments LogBERT was outperformed by LogFiT on F1 across HDFS, BGL, and Thunderbird; in variability test LogBERT's F1 dropped sharply (88.63 -&gt; 44.22) when top verbs were replaced by lemmas, indicating sensitivity to lexical/template variation.",
            "comparison_to_baseline": "LogFiT showed superior robustness and higher F1 than LogBERT, particularly under lexical variation; LogBERT's reliance on parsed templates and training-from-scratch limited adaptability.",
            "limitations_or_failure_cases": "Dependency on log parsing and template vocabularies reduces robustness to unseen or evolving log sentences; training from scratch forfeits benefits of pretrained semantic knowledge; centroid distance minimisation may not help generalisation (as found when authors tried similar objective in LogFiT).",
            "unique_insights": "LogBERT's template-based reconstruction combined with centroid heuristics can perform well in static settings but is brittle under lexical/schema evolution; using pretrained LMs and avoiding template parsing (as LogFiT does) improves robustness.",
            "uuid": "e9246.3",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "DeepLog",
            "name_full": "DeepLog: Anomaly detection and diagnosis from system logs through deep learning",
            "brief_description": "An LSTM-based forecasting approach that predicts the next log template ID from previous templates and flags anomalies when the true template is not within top-k predictions.",
            "citation_title": "DeepLog: Anomaly detection and diagnosis from system logs through deep learning",
            "mention_or_use": "use",
            "model_name": "DeepLog LSTM model",
            "model_type": "LSTM (sequential RNN)",
            "model_size": null,
            "data_type": "Sequences of log template IDs derived from log parsing",
            "data_domain": "System logs (HDFS, BGL, Thunderbird)",
            "anomaly_type": "Anomalous next-event predictions (missing expected subsequent templates, rare sequences)",
            "method_description": "Forecasting-based approach: train LSTM on sequences of log template IDs to predict the next template; at inference consider top-k predictions and flag anomalies if ground truth not in top-k.",
            "baseline_methods": "Serves as a primary baseline for LogFiT and LogBERT comparisons in the paper.",
            "performance_metrics": "Top-k accuracy, Precision, Recall, F1, Specificity, throughput",
            "performance_results": "DeepLog was outperformed by LogFiT on F1 across datasets; DeepLog also showed substantial performance degradation under lexical variation (F1 79.25 -&gt; 53.38 in BGL verb-lemma test). DeepLog had high throughput on the HDFS dataset (short sequences) but lower throughput on datasets with longer sequences.",
            "comparison_to_baseline": "LogFiT (LM fine-tuning) yielded higher F1 and better robustness to lexical changes than DeepLog; DeepLog can be faster for short sequences but is limited by template vocabulary and LSTM sequence modeling limits.",
            "limitations_or_failure_cases": "Relies on log parsing/templates and an LSTM architecture limiting long-range context learning and robustness to lexical variability; implementations may leak test set into parsing step if not careful (authors corrected such issues).",
            "unique_insights": "Forecasting-based template prediction works well in stable, template-rich environments but is brittle under schema/lexical evolution; transformer-based LM fine-tuning on raw text (no parsing) can overcome those weaknesses.",
            "uuid": "e9246.4",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "LAnoBERT",
            "name_full": "LAnoBERT: System log anomaly detection based on BERT masked language model",
            "brief_description": "A parsing-free BERT-based approach that uses BERT's masked language modelling to detect anomalies in logs without conventional parsing, but which trains a BERT model from scratch (per referenced summaries).",
            "citation_title": "LAnoBERT: System log anomaly detection based on BERT masked language model",
            "mention_or_use": "mention",
            "model_name": "BERT (task-specific BERT trained in LAnoBERT work)",
            "model_type": "Transformer encoder (BERT)",
            "model_size": null,
            "data_type": "Sequences of log sentences tokenized as natural language (parsing-free)",
            "data_domain": "System logs (parsing-free approaches)",
            "anomaly_type": "Anomalous log sentences/sequences detected via masked prediction reconstruction error",
            "method_description": "Uses BERT masked language modelling to detect anomalies in raw log sentences without template parsing; however LAnoBERT trains a BERT model from scratch rather than leveraging pretrained weights.",
            "baseline_methods": "Mentioned in related work as a parsing-free approach; contrasted with LogFiT which fine-tunes pretrained LMs rather than training from scratch.",
            "performance_metrics": "Not reported in this paper (cited work), but typically reconstruction-based metrics (top-k accuracy, F1, etc.)",
            "performance_results": null,
            "comparison_to_baseline": "LAnoBERT is parsing-free like LogFiT but less practical because it trains from scratch and therefore misses advantages of pretrained semantic knowledge and transfer learning (as discussed by authors).",
            "limitations_or_failure_cases": "Training from scratch limits cross-dataset reuse and forfeits benefits of pretrained language models; potential lack of robustness compared to fine-tuned pretrained LMs.",
            "uuid": "e9246.5",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        },
        {
            "name_short": "BERT (general)",
            "name_full": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "brief_description": "A pretrained Transformer encoder (masked language model) that provides contextualized token representations and reconstruction ability; used as conceptual and technical foundation for LogFiT and many related log-anomaly works.",
            "citation_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
            "mention_or_use": "mention",
            "model_name": "BERT (pretrained)",
            "model_type": "Transformer encoder (masked language model)",
            "model_size": null,
            "data_type": "Natural language sequences / tokenized sentences (applied here to log sentences and paragraphs)",
            "data_domain": "General NLP and system logs (adapted via fine-tuning)",
            "anomaly_type": "Reconstruction/failure to predict masked tokens indicating anomalous or out-of-distribution input",
            "method_description": "Provides pretrained weights that can be fine-tuned on normal logs using masked-token/sentence prediction; reconstruction/top-k prediction accuracy used as anomaly signal.",
            "baseline_methods": "Basis for RoBERTa, LogBERT, LAnoBERT, and LogFiT approaches",
            "performance_metrics": "Used indirectly; enables improved F1 and robustness when fine-tuned compared to training-from-scratch or template-based methods.",
            "performance_results": null,
            "comparison_to_baseline": "Using pretrained BERT-family models and fine-tuning (LogFiT) outperformed approaches that trained BERT from scratch or used template-only representations.",
            "limitations_or_failure_cases": "Vanilla BERT has token length limit (512) and high compute; requires adaptions (Longformer) for long sequences; fine-tuning can distort pretrained features if not done carefully (noted in related literature).",
            "unique_insights": "Pretrained LMs capture sentence-level contextual and semantic information and better handle out-of-vocabulary tokens, which improves anomaly detection robustness when logs evolve lexically.",
            "uuid": "e9246.6",
            "source_info": {
                "paper_title": "LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models",
                "publication_date_yy_mm": "2024-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogBERT: Log anomaly detection via BERT",
            "rating": 2,
            "sanitized_title": "logbert_log_anomaly_detection_via_bert"
        },
        {
            "paper_title": "DeepLog: Anomaly detection and diagnosis from system logs through deep learning",
            "rating": 2,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        },
        {
            "paper_title": "LAnoBERT: System log anomaly detection based on BERT masked language model",
            "rating": 2,
            "sanitized_title": "lanobert_system_log_anomaly_detection_based_on_bert_masked_language_model"
        },
        {
            "paper_title": "Robust and transferable anomaly detection in log data using pre-trained language models",
            "rating": 2,
            "sanitized_title": "robust_and_transferable_anomaly_detection_in_log_data_using_pretrained_language_models"
        },
        {
            "paper_title": "Pretrained Transformers Improve Out-of-Distribution Robustness",
            "rating": 1,
            "sanitized_title": "pretrained_transformers_improve_outofdistribution_robustness"
        },
        {
            "paper_title": "Log-based anomaly detection without log parsing",
            "rating": 1,
            "sanitized_title": "logbased_anomaly_detection_without_log_parsing"
        }
    ],
    "cost": 0.014075999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models
25 January 2024</p>
<p>Crispin Almodovar crispin.almodovar@cqumail.com 0000-0002-6435-7119
School of Engineering and Technology
Central Queensland University
4701RockhamptonQLDAustralia</p>
<p>CSIRO
2015SydneyNSWAustralia</p>
<p>Member, IEEEFariza Sabrina f.sabrina@cqu.edu.au 0000-0002-8455-2499
School of Engineering and Technology
Central Queensland University
4701RockhamptonQLDAustralia</p>
<p>CSIRO
2015SydneyNSWAustralia</p>
<p>Sarvnaz Karimi sarvnaz.karimi@csiro.au 
School of Engineering and Technology
Central Queensland University
4701RockhamptonQLDAustralia</p>
<p>Member, IEEESalahuddin Azad s.azad@cqu.edu.au 
School of Engineering and Technology
Central Queensland University
4701RockhamptonQLDAustralia</p>
<p>CSIRO
2015SydneyNSWAustralia</p>
<p>LogFiT: Log Anomaly Detection Using Fine-Tuned Language Models
25 January 2024DE1C86BCE73221360923486EAAD00ED010.1109/TNSM.2024.3358730received 13 March 2023; revised 15 September 2023 and 9 December 2023; accepted 23 December 2023. Date of publicationService monitoringfault managementlog anomaly detectiondeep learningnatural language processinglanguage modeling
System logs are a valuable source of information for monitoring and maintaining the security and stability of computer systems.Techniques based on Deep Learning and Natural Language Processing have demonstrated effectiveness in detecting abnormal behaviour from these system logs.However, existing anomaly detection approaches have limitations in terms of flexibility and practicality.Techniques that rely on log templates such as DeepLog and LogBERT fail to capture semantic information and are unable to handle variability in log content.On the other hand, classification-based approaches such as LogSy, LogRobust and HitAnomaly require time-consuming data labelling for supervised training.In this paper, a novel log anomaly detection model named LogFiT is proposed.The LogFiT model doesn't make use of a vocabulary of log templates and it doesn't require any labeled data as the model only requires self-supervised training.The LogFiT model uses a pretrained Bidirectional Encoder Representations from Transformers (BERT)-based language model fine-tuned to recognise the linguistic patterns of the normal log data.The LogFiT model is trained using masked sentence prediction on the normal log data only.Consequently, when presented with the new log data, the model's top-k token prediction accuracy serves as a threshold for determining whether the new log data deviates from the normal log data.Experimental results show that LogFiT's F1 score exceeds that of baselines on the HDFS, BGL, and Thunderbird datasets.Critically, when variability is introduced in the log data during evaluation, LogFiT retains its effectiveness compared to that of baselines.</p>
<p>human operators are increasingly unable to cope with the volume and velocity of log data generated by the systems being monitored.Consequently, Machine Learning (ML) and Deep Learning (DL)-based solutions have been proposed to automatically detect anomalies from system log data, thereby reducing the burden on human operators [4], [5], [6].</p>
<p>System logs are produced by the logging instructions that software engineers insert in a computer program's source code to communicate the program's run-time state.The system logs thus produced consist of ordered sequences of log sentences that assert the occurrence of certain events in the system [7].Typically, log sentences are grouped according to some criteria, such as time window (e.g., 60 second intervals) or unique identifier (e.g., HDFS block ID).In this study, such grouping of log sentences is referred to as a "log paragraph".The idea behind log anomaly detection is to learn a model of the normal behaviour of a computer system based on the sequence of log sentences that it generates during normal operations.If there is a significant deviation in the new observed behaviour from the learned normal behaviour, the deviation can be regarded as an anomaly.For instance, a normal sequence of log sentences may consist of one or more "File opened successfully" entries followed by "File write operation completed" and/or "File read operation completed" entries.However, a sequence of log sentences that only contains "File opened successfully" entries without corresponding "read" or "write" entries can be considered an anomaly.</p>
<p>There are several considerations in the study of log anomaly detection.The first consideration is the overall Machine Learning approach to be used for anomaly detection.In literature, approaches based on Deep Learning have been proven to be more effective than traditional Machine Learning based approaches such as Principal Component Analysis (PCA), Support Vector Machines (SVM) and Isolation Forest [6], [8], [9].</p>
<p>A further consideration is whether to use supervised or unsupervised Machine Learning.Due to the high cost of preparing labelled data, supervised methods such as LogSy [10], LogRobust [11] and HitAnomaly [12] have limited utility in production settings.As a result, unsupervised techniques dominate; these techniques assume a zero-positive training scenario, where normal log data is the only data available for training [4].The study in [13] identified two categories for unsupervised models for log anomaly detection: forecasting-based model which learns by predicting the next log sentence based on immediately preceding log sentences; and reconstructionbased model which learns by reconstructing sequences of log sentences that have been intentionally corrupted.Another consideration is the use of a log parser and log templates to generate representations of log sentences.The quality of the representation of log sequences is a critical factor that impacts the effectiveness of log anomaly detection models, especially when the evolution of log content is taken into account [14], [15].As shown in Figure 1, log parsers [8], [9] extract string templates from the log data to build a vocabulary of all known log templates (steps 1 and 2).Subsequently, all input log sentences are mapped to an entry in the log template vocabulary (step 3).Thus a sequence of log sentences is represented by a sequence of log template IDs.This approach has been shown to negatively affect model effectiveness because of its semantically deficient representation of log sentences.Furthermore, the unseen input log sentences are expected to match a log template, which makes this approach incapable of handling variability in log sentences over time [10], [16], [17].</p>
<p>An important consideration is the choice of model architecture.DL-based approaches have taken inspiration from the field of Natural Language Processing (NLP) to process log data that are in the form of natural language sentences.Literature reveals that state-of-the-art research in this area employs the Long Short-Term Memory (LSTM) architecture, as exemplified by the DeepLog model [8], and Transformers, represented by the LogBERT model [9].The problems identified with LSTMs are (1) Inability to cater to longer sequences owing to their sequential nature; and, (2) Deficient capacity to learn complex and ambiguous contextual relationships in the input data [9].Being an LSTM-based architecture, DeepLog inherits the limitations of LSTM.On the other hand, Bidirectional Encoder Representations from Transformers (BERT) [18] has several advantages over LSTM.It inherits Transformer's [19] self-attention mechanism which helps it avoid local bias, and its use of bidirectional context allows it to capture complex and ambiguous contextual relationships.Although LogBERT inherits the advantages of BERT, its dependency on log parsing and log templates makes it less adaptable to changes in log structures.Moreover, LogBERT trains a BERT model customised to a specific dataset from scratch, which limits its ability to generalise to other datasets.Furthermore, LogBERT does not benefit from prior semantic knowledge already learned by a pretrained BERT model.</p>
<p>To address the limitations of existing approaches, this work introduces the following contributions:  [20], outlined as follows.Firstly, the robustness of LogFiT against gradual changes to the lexical content of log data has been demonstrated.Secondly, the centroid minimisation training objective that was used in the earlier method has been removed, and the model's effectiveness is not degraded by its removal.Furthermore, the present paper leverages k-fold cross-validation to improve the reliability of the experiments, and includes experiments that explore the effect of varying the top-k and top-k accuracy threshold values, and different time windows.</p>
<p>The rest of the paper is organised as follows.Section II discusses the related works on Deep Learning and natural language-based approaches for anomaly detection using log data and the pros and cons of those approaches.Section III illustrates the proposed LogFiT model in detail.Section IV describes the datasets, experimental setup and implementation details.Section V analyses the experimental results.Finally, Section V concludes the paper with future directions.</p>
<p>II. RELATED WORK</p>
<p>Considerable research has been done on Deep Learning based supervised and unsupervised anomaly detection.Many of the approaches [8], [9], [11], [12] require log parsing, while recent studies [11], [16] suggested that log parsing can reduce accuracy.Graph-based anomaly detection [21], [22], [23], [24], [25], [26] is an emerging topic, drawing interest from researchers.</p>
<p>A. Supervised vs. Unsupervised Methods 1) Unsupervised Methods: DeepLog [8] pioneered the application of Deep Learning and Natural Language Processing to the log anomaly detection problem domain.By utilising a forecasting-based approach based on the patterns of past log sentences, it improved upon previous methods, such as Principal Component Analysis (PCA), Support Vector Machines (SVM) and Isolation Forest.However, its use of LSTM and log template indexes negatively affects its capability to handle complex semantic relationships between log sentences.LogAnomaly [27] built upon the principles set by DeepLog by introducing the encoding of semantic information.LogAnomaly used the template2vec method to encode the semantic content of log data, enhancing the model's ability to detect anomalies.However, LogAnomaly's use of LSTM hampers its ability to process longer sequences and complex log relationships.LogBERT [9] adopted the BERT architecture to learn more nuanced patterns in the log data, which allowed it to perform better than previous methods.However, LogBERT's use of log parsing and log templates makes it less adaptable to changes in the lexical structure of log data.</p>
<p>2) Supervised Methods: LogRobust [11] and HitAnomaly [12] integrate semantic vectorisation, bidirectional LSTM with attention, and transformer architecture, offering more accurate anomaly classification.However, the supervised nature limits their generalisability and scalability, demanding a significant effort in labelling data.The requirement for labelled data makes them less flexible in scenarios where obtaining labelled anomalies is challenging.Additionally, domain-specific embedding might limit their applicability across various domains.Furthermore, their reliance on specific log parsers like the Drain parser may also limit flexibility.LogSy [10] introduced flexible preprocessing through its use of a Transformer architecture.LogSy also introduced a spherical loss function, which was later adopted by LogBERT.However, LogSy's classification-based approach can create challenges in scenarios where labelled data is not readily available.The method's requirement for abnormal log lines imported from an auxiliary data source creates an external dependency, which hinders its usability in settings where auxiliary data sources are not available.</p>
<p>B. Parsing-Based vs. Parsing-Free Methods</p>
<p>1) Parsing-Based Log Anomaly Detection:</p>
<p>As mentioned earlier, DeepLog [8] and LogBERT's [9] dependency on standardized templates limits their adaptability to new or rare log sentence structures.Also, the use of a log parsing tool might affect its ability to capture the nuanced differences in log messages.Similarly, LogRobust [11] and HitAnomaly's [12] dependency on log parsing tools limits flexibility in capturing nuanced differences.</p>
<p>2) Parsing-Free Log Anomaly Detection: As mentioned earlier, while LogSy's [10] use of flexible pre-processing and Transformer architecture makes it robust against the evolution of log data, its classification-based approach poses a challenge where labelled data is not readily available.LAnoBERT [28] utilises BERT's natural language understanding to detect anomalies without relying on conventional parsing.This approach allows it to handle variability in formats.However, similar to the LogBERT method, this approach trains a BERT model from scratch.This limits its reuse for other datasets and schemas and foregoes the benefits of a pretrained model's prior semantic knowledge.</p>
<p>C. Graph-Based Approaches</p>
<p>Log analysis for the intrusion detection use case primarily use graph-based models, requiring substantial feature engineering and domain knowledge to identify entities and their interactions [21], [22], [23], [24], [25], [26].The input to graph-based models is formatted as information triples, such as (user1, authenticate, computer2).In contrast, LogFiT operates on well-formed sentences, leveraging its transformer architecture to understand both structural and semantic properties of log data [29], [30].Recent studies indicate that Transformer models can learn representations comparable to graph-based approaches [31], [32].Therefore in future, we aim to adapt LogFiT for intrusion detection scenarios, for example by converting intrusion detection log data into processable sentence structures.</p>
<p>D. Log Anomaly Detection Workflow</p>
<p>The log anomaly detection workflow involves four steps as identified in prior studies [5], [33], [34], [35]: pre-processing for data quality, vectorisation for Machine Learning, model development and evaluation, and final operationalisation in production.Current research does not recommend log parsing for vectorisation due to accuracy issues [11], [16], and recommends NLP-based architectures like LSTM and Transformers for optimal performance [8], [9], [10], [16].</p>
<p>E. Pretrained Language Models</p>
<p>In recent research, there has been a growing interest in the use of pretrained language models (LMs) such as BERT [18] to improve anomaly detection in system logs.Studies in [15], [16] demonstrated that pretrained LMs can offer significant advantages over word embeddings, that were used in the LogRobust model [11].According to these studies, pretrained LMs capture contextual information at the level of the whole log sentence, whereas word embeddings only provide representations for individual words in a single sentence.Furthermore, pretrained LMs are capable of handling out-ofvocabulary words, unlike static word embeddings.Existing research suggests that pretrained LMs such as BERT can learn both syntactic and semantic information, which can improve the effectiveness of Natural Language Processing tasks [29], [30], [36], [37].The BERT model is a Transformer encoder model that has the capabilities of an auto-encoder.The BERT model's encoder capability allows it to generate semantic vectors that are sensitive to the full context of the input log sequence, and to reconstruct log sequences that have been corrupted [18].Therefore, in this study, a pretrained LM is incorporated into the LogFiT model to leverage its ability Authorized licensed use limited to the terms of the applicable license agreement with IEEE.Restrictions apply.</p>
<p>TABLE I COMPARATIVE ANALYSIS OF LOG ANOMALY DETECTION METHODS</p>
<p>to understand the sequential properties and linguistic structure of system logs.</p>
<p>In Table I, various log anomaly detection methods are summarised and compared, highlighting their key technical aspects and limitations.Table I presents the landscape of existing approaches to highlight the research gap addressed by the proposed LogFiT method.LogFiT distinguishes itself from other methods by leveraging transfer learning and LM fine-tuning through masked sentence prediction, enabling it to adapt more robustly to evolving log data, unlike other methods that require log templates, LSTM, labelled data, from-scratch training, or extensive domain knowledge.Furthermore, it is important to note that LogFiT is not limited to using RoBERTa or Longformer.It is straightforward to swap out LogFiT's underlying model and replace it with other Transformer encoder models available on the Hugging Face model hub.</p>
<p>III. LOGFIT</p>
<p>The proposed LogFiT approach takes advantage of advancements in Deep Learning and NLP for system log anomaly detection.It employs pretrained foundation models [38], specifically fine-tuning RoBERTa [39] or Longformer [40] to learn the linguistic and sequential properties of normal log data.Longformer is selected for its support of sequences exceeding 512 tokens, overcoming limitations in BERT [18] and RoBERTa.LogFiT incorporates a heuristic to choose between RoBERTa and Longformer based on log sequence lengths: RoBERTa for sequences up to 512 tokens, and Longformer for longer log sequences.</p>
<p>LogFiT utilises a self-supervised training strategy, focusing exclusively on normal log data to learn its linguistic and sequential patterns.The model aims to predict masked tokens in log sentences, employing cross-entropy loss to optimise its predictions.This loss function is logarithmic, penalising incorrect predictions more severely than correct ones.LogFiT's semantic vectors, stored in the [CLS] token, are suitable for downstream tasks like clustering and visualisation.As shown in Figure 2, the LogFiT architecture and workflow involve:</p>
<p>(1) preprocessing raw log lines; (2) and (3) fine-tuning a pretrained RoBERTa/Longformer model on normal logs using masked sentence prediction and cross-entropy loss; and, (4) detecting anomalies in new log data.Additionally, Figure 3 shows LogFiT can be integrated into a system observability platform (such as the Elasticsearch stack) and configured In its early version [20], LogFiT incorporated centroid loss, inspired by the LogBERT [9] method.Subsequent research indicated that centroid loss is unnecessary, thus the present version of LogFiT does not incorporate it.</p>
<p>A. Framework</p>
<p>Input Representation: The LogFiT model utilises normal log data for training, which is converted to semantic vectors before being passed to the model.In contrast to both the DeepLog and LogBERT methods, the LogFiT model does not require the input log data to first be converted to log templates.Rather, log data is directly tokenised using the pretrained RoBERTa Authorized licensed use limited to the terms of the applicable license agreement with IEEE.Restrictions apply.or Longformer model's default tokeniser component.LogFiT takes inspiration from recent models [15], [16] that forego the log template extraction step and directly convert the log data into semantic vectors using a pretrained LM.These models however treat the pretrained language model as a static semantic embedding generator, whereas LogFiT fine tunes it to the log anomaly task.</p>
<p>Transformer Architecture: LogFiT inherits from the innovations introduced by the BERT-based language models.BERT's ability to accurately reconstruct corrupted input logs can be used as a threshold-based anomaly detection method.Thus by inheriting from BERT, LogFiT includes both the vectoriser and log anomaly detection component in a single package, allowing for end-to-end training that does not require intermediate log template extraction or vectorisation steps.As mentioned earlier, LogFiT makes use of the RoBERTa model to process log datasets containing up to 512 tokens per sample, and the Longformer model for datasets where the token count per sample exceeds 512.The Longformer model overcomes BERT's limitation on the number of tokens, which is due to the quadratic computational complexity of BERT's self-attention mechanism, by introducing a sliding window strategy that effectively reduces attention computation to a linear time [40].The LogFiT model consists of 12 stacked Transformer encoders, 12 attention heads per layer, 768-dimension vectors, and a maximum possible sequence length of 4096 tokens -as illustrated in Figure 2.</p>
<p>Heuristic: The LogFiT tool also includes a heuristic to automatically select between RoBERta and Longformer based on the 0.8-quantile length (in words) of the training log samples, found during preprocessing.LogFiT selects RoBERTa for datasets with log samples containing no more than 512 tokens.For log datasets with samples that exceed 512 tokens, LogFiT switches to Longformer to take advantage of its ability to handle longer log samples via its use of local and global attention.</p>
<p>Fine-tuning: To adapt the RoBERTa or Longformer model to the log anomaly detection task, LogFiT utilises finetuning methods based on super-convergence techniques [41] implemented in the FastAI/ULMFiT framework [42], [43].Research has demonstrated that fine-tuning yields significant performance improvements (an average gain of 2%) [44] and that gradual unfreezing [42], [44] counters the negative effects of weight dissipation during fine-tuning of pretrained language models [45].</p>
<p>B. Training Objective</p>
<p>As mentioned previously, the LogFiT model is trained in a self-supervised manner using masked sentence prediction.This training objective is a modified version of the self-supervised masked language modelling (MLM) training objective used to pretrain BERT-based language models [18].In LogFiT a variable ratio (default 0.5) of the sentences that constitute a log paragraph is randomly chosen for masking, unlike BERT which randomly chooses a set ratio (0.15) of all the tokens that make up a log paragraph is randomly chosen for masking.Subsequently, LogFiT masks a variable ratio (default 0.8) of the tokens that make up each log sentence.Afterwards, the model is tasked with predicting what the masked tokens were.The intuition behind this training objective is to force the model to learn not just the contextual relationships between the tokens that make up a log sentence, but also the contextual relationships between the log sentences to accurately predict the masked tokens.This enables the model to develop an understanding of the language rules used by the normal system logs.As a result, it can differentiate normal log data from anomaly log data.</p>
<p>To satisfy the masked token prediction training objective, the model minimises the cross-entropy loss between its masked token predictions and the actual tokens.The computation of the cross-entropy loss for a mini-batch of log data is shown in Equation ( 1).The LogFiT model minimises the training loss using the Adam optimiser, initialised using default values from the FastAI [43] Deep Learning library: momentum = 0.9, sqr_momentum = 0.99, epsilon = 1e − 5, and weight decay = 0.01.
Loss = − 1 b b j =1 m i=1 y j mask i log p j mask i , (1)
where b is size of the mini-batch, m is the number of masked tokens, y and p are the true and predicted values, respectively.</p>
<p>C. Anomaly Detection</p>
<p>The LogFiT model, which is exclusively trained on normal data, can then be used to detect abnormal log data.During the inference stage, log paragraphs are processed in the same way as during training.To determine whether a log paragraph is anomalous, LogFiT uses a technique adopted from LogBERT.The trained model's top-k accuracy in correctly predicting the masked tokens is used as an anomaly score.If the model's top-k predictions for a masked token contain the correct token, the model's prediction is considered correct.A log paragraph is considered normal if the model's accuracy in correctly the masked tokens is above some threshold.If the model's accuracy falls below the threshold, the log paragraph is deemed an anomaly.LogFiT includes a heuristic to determine the optimal threshold during hyperparameter tuning, as described in the Experimental Setup section.</p>
<p>IV. EXPERIMENTS</p>
<p>In this section, the datasets, experimental setup, and implementation details are described.Subsequently, the results of running the experiments are evaluated.</p>
<p>A. Experimental Setup</p>
<p>Datasets: The LogFiT model is trained and evaluated using three public datasets: HDFS [46], BGL [47] and Thunderbird [47], as used by baseline models [8], [9].While these datasets are partially labelled, LogFiT uses the labels solely for model validation.In real-world applications, logs are often unlabeled.HDFS logs were generated by the Hadoop Distributed File System and contain both normal and anomalous events, manually tagged by experts.Anomalies in this dataset pertain to abnormal file system operations.The dataset comprises 11,175,629 log sentences, with 284,818 identified as anomalies.BGL logs come from the Blue Gene/L supercomputer at Lawrence Livermore National Laboratory.It has 4,747,963 log sentences, with 348,460 categorised as anomalies.Thunderbird logs were produced by the Thunderbird supercomputer system at Sandia National Laboratories.The full dataset contains 211,212,192 log sentences; this study considers the first 20,000,000, of which 758,562 are anomalies.</p>
<p>Log paragraphs: The HDFS log sentences are chunked into log paragraphs using the HDFS block ID, which represents a session in HDFS.The BGL and Thunderbird datasets do not have a natural grouping field, so the log sentences are grouped using time windows of 10, 30 and 60 seconds.A shorter time window facilitates timely feedback for system operators.Table II shows some statistics about the HDFS, BGL, and Thunderbird datasets.</p>
<p>K-fold Cross-validation:</p>
<p>In the experiments, k-fold crossvalidation was used, specifically using a five-fold approach.For each dataset, a total of 25,000 normal and 2,000 anomaly log paragraphs were allocated for this process.The normal logs were used exclusively for training, while the anomaly logs were reserved for hyperparameter tuning and model evaluation.During each five-fold iteration, 5,000 logs sampled from the 20,000 training split were utilised for training.For hyperparameter tuning, 1,000 normal logs (from the training split) were used, supplemented with 1,000 anomaly logs.The final model evaluation exclusively used the 5,000 logs from the test split, supplemented with 1,000 anomaly logs.</p>
<p>Log Content Variability: To test the models' ability to handle variation in the syntactic structure of the log data, the evaluation set is dynamically modified during model evaluation on the BGL dataset, so that the top 10% most commonly occurring verbs are replaced with their WordNet [48] lemmas.</p>
<p>Baselines: The performance of the LogFiT model is compared against two key baselines.DeepLog [8] and LogBERT [9].DeepLog utilised an LSTM-based architecture and a forecasting-based approach for anomaly detection by predicting the next log template based on its preceding ones.The model deems a log sequence normal if the correct template falls within its top-k predictions.The results are produced using the logdeep library,1 and it should be noted that the original DeepLog performance metrics are not reproducible with this implementation.LogBERT, on the other hand, employs a BERT-based architecture and a reconstruction-based approach.It learns normal log patterns through masked log key prediction and centroid distance minimisation.Anomalies are identified by predicting masked log keys and calculating an anomaly score based on top-k accuracy and centroid distance.If either metric exceeds a certain threshold, the sequence is classified as anomalous.Results are produced from publicly available LogBERT source code, and it is noted that the original evaluations are also not reproducible.</p>
<p>Implementation Details: LogFiT was implemented using Python and leveraged several well-known libraries to accelerate the development and evaluation of the model, such as Pytorch, FastAI and Hugging Face.The details of the implementation can be found in the pre-print version of this paper [49].The source code implementing the LogFiT model, datasets and model checkpoints will be made available online.</p>
<p>Evaluation Metrics: To evaluate the effectiveness of the models, the experiments use the following metrics:</p>
<p>• Precision (P) measures the proportion of correctly identified anomaly samples (TP), out of all the anomalies detected by the model, and is calculated as P = TP / (TP + FP).• Recall (R) measures the proportion of correctly identified anomaly samples (TP) out of all real anomalies and is calculated as R = TP / (TP + FN).• F1 Score (F1) is the harmonic mean of the Precision and Recall and is calculated as F1 = 2 * (P*R)/(P + R). • Specificity (S) measures the proportion of correctly identified normal samples (TN) out of all real normal samples and is calculated as S = TN/(TN + FP).In real-world deployment scenarios, having a predictive model with high Specificity is more advantageous since it minimises the chances of producing false positives or false alarms.Furthermore, in [4] it was noted that a high Specificity can help mitigate the impact of having an imbalanced class distribution on the model's overall performance.</p>
<p>Hyperparameter tuning: During the hyperparameter tuning step, LogFiT iterates through top-k values in the range: 5, 9, and 12. Subsequently, for the top-k accuracy threshold, LogFiT iterates through values based on the top-1 token prediction accuracy of the model during training.For example, if the model's top-1 token prediction accuracy during training was 0.9, the range of values for the top-k accuracy threshold search is derived by computing 3 evenly spaced numbers in the range [(0.9 − 0.1), 0.9].This computation is facilitated by the linspace function from the NumPy library, yields the values 0.8, 0.85, and 0.9.</p>
<p>Observations: In our experiments, we observed that the implementations of LogBERT and DeepLog included the test set during the log parsing step (which builds the vocabulary of log templates), thus artificially avoiding out-of-vocabulary issues.The implementations also filtered out log instances with fewer than 10 log template IDs, which avoided a failure condition when the input sequence length is 1.We modified the implementations to align with LogFiT's setup.</p>
<p>We note that k-fold cross-validation may lead the models to peek into the future, by processing log samples that only occur at later times leading to the model's effectiveness improvement.This has been shown in the past in time-based datasets [50].</p>
<p>V. EXPERIMENTAL RESULTS</p>
<p>Log Anomaly Detection Effectiveness: Table III, Table IV and Table V show the results of running anomaly detection inference using LogFiT, as compared to the results from running DeepLog and LogBERT using the available source code implementation.The results show that LogFiT's F1 scores exceed that of LogBERT and DeepLog on all three datasets, while LogFiT's specificity exceeds that of the baseline models on the HDFS and BGL datasets and is very close to LogBERT's on the Thunderbird dataset.The DeepLog and LogBERT models were trained and evaluated using the source code implementation mentioned earlier.</p>
<p>Analysis: The LogFiT results indicate that fine-tuning pretrained RoBERTa or Longformer models with a novel masked sentence prediction training objective is effective for adapting these language models to the task of detecting anomalies in system logs.This training approach enhances LogFiT's contextual understanding of log data.LogFiT's extensive sub-word token vocabulary and its lack of need for log parsing allow it to easily adapt to diverse log content.Additionally, we corrected implementation issues in DeepLog and LogBERT, which may have influenced these methods' performance.It is emphasized that while LogFiT improves upon baseline methods on standard metrics, the LogFiT method's true effectiveness is evident in scenarios where the textual content of log data changes due to log schema evolution.LogFiT's superior adaptability and robustness in handling dynamic changes in log data -achieved through LM fine-tuning -underscores its significant contribution to the domain of log anomaly detection.</p>
<p>Anomaly Detection Throughput: Table VI presents the throughput rates (in samples per second) for DeepLog, LogBERT and LogFiT on the HDFS, BGL and Thunderbird datasets.DeepLog excels in throughput on the HDFS dataset, owing to this dataset's shorter sequence lengths.However, its LSTM architecture limits its efficiency on the BGL and Thunderbird datasets, where sequence lengths are longer.LogBERT achieves superior throughput on these latter datasets, benefiting from its parallel token processing due to its use of a transformer architecture.LogFiT lags in throughput primarily due to its larger vocabulary size of 50K, which dictates the size of its embedding layer.Unlike     [CLS] vector to a mean vector calculated from normal logs.A specific q-quantile (with q between 0.65 to 0.9) centroid distance was also calculated to serve as a threshold during inference.However, experimental results indicated that the incorporation of centroid distance did not enhance the effectiveness of the model in distinguishing normal from anomalous log entries.Despite these modifications, the extended model's performance remained comparable to the original LogFiT model.Furthermore, the semantic vectors of the training set did not form distinct clusters, after dimensionality reduction via the UMAP algorithm [51], as shown in Figure 4. Consequently, we concluded that centroid distance minimisation does not offer an advantage and can be omitted from the model.
Loss = Loss cross−entropy + cw * 1 b b j =1 CV j − centroid 2 .
(
)2
Variability in input data: In practical applications, it is expected that the content of the log sentences changes over time.This can be because the programmers may change some words in the log sentences, or introduce misspellings.The LogFiT model contains built-in support for log sentence variability due to its large vocabulary of sub-word tokens (around 50K).In contrast, the DeepLog and LogBERT models would fail if they encounter variations in log sentences that cannot be mapped to their list of known log templates.To test the LogFiT model's ability to handle log sentence variability, the evaluation set is dynamically modified during inference so that the top 10 occurring action words (that can be mapped to synonyms in WordNet) are replaced with their WordNet lemmas.Table VII shows the results of feeding the modified BGL evaluation set to the trained LogFiT, DeepLog and LogBERT models.The results indicate that the LogFiT model is robust to changes in the log sentences, as the reduction in F1 is around 2% (from 91.22 to 89.38).However, the drop in F1 performance for LogBERT is large, from 88.63 to 44.22.Similarly for DeepLog, F1 dropped from 79.25 to 53.38.</p>
<p>VI. CONCLUSION</p>
<p>The paper has introduced LogFiT, a novel log anomaly detection model that leverages the general linguistic knowledge of a pretrained BERT-based LM by adapting it to learn the linguistic patterns of normal system logs.LogFiT is trained using a novel self-supervised masked sentence prediction objective, using only normal log data.This approach enables LogFiT to recognise the linguistic structure of normal system logs only, thus anomalies can be flagged when the model fails to predict the correct log sentences for new log data.Critically, LogFiT can handle variability in the content of system logs because of its use of a BERT-based LM.The performance of LogFiT on the HDFS, BGL, and Thunderbird datasets has been evaluated and it has been that LogFiT's F1 score outperformed that of the baseline models.Moreover, LogFiT's specificity exceeded that of the baselines on the HDFS and BGL datasets and was comparable to LogBERT on the Thunderbird dataset.In addition, LogFiT demonstrated superior effectiveness over LogBERT in experiments that tested for variations in the content of input log paragraphs, which is attributed to its ability to handle out-of-vocabulary tokens.LogFiT integrates with the popular Hugging Face ecosystem, making it easy to adapt in future work.Overall, LogFiT presents a flexible approach to detecting abnormal behaviour in computer systems through language model adaptation and fine-tuning.</p>
<p>A. Future Work</p>
<p>While the LogFiT model is intended to be used as a threshold-based anomaly detector trained in a self-supervised manner, it can easily be converted to a classifier.If at some point after the model is deployed, operators can collect and label anomaly log samples, the model can be converted to a classifier by replacing its language modelling head with a classification head.Additionally, the LogFiT LM can be pretrained on diverse log datasets, allowing it to be used as the foundation for downstream NLP and log anomaly detection tasks.Furthermore, LogFiT's suitability for the intrusion detection use case can be considered in future studies.Lastly, ongoing research to address LogFiT's suboptimal throughput performance focuses on efficient training and deployment strategies.These include the use of LoRA adapters, quantisation, and optimised model serving environments.These initiatives are aimed at improving LogFiT's operational effectiveness in real-world scenarios, balancing its throughput with its anomaly detection capabilities.</p>
<p>Fig. 1 .
1
Fig. 1.Log parsing applied to HDFS log data.</p>
<p>Fig. 2 .
2
Fig. 2. Logical architecture of the LogFiT log anomaly detection approach.</p>
<p>Fig. 3 .
3
Fig. 3. LogFiT integrated into existing system observability platform.</p>
<p>Fig. 4 .
4
Fig. 4. UMAP plot of Thunderbird semantic vectors, where the blue, pink, and yellow colours of the points represent training samples, normal predictions, and anomaly predictions respectively.</p>
<p>•</p>
<p>We propose LogFiT, a log anomaly detection model implemented as a Python package.LogFiT leverages a fine-tuned, pretrained BERT-based model to semantically analyse logs without requiring an intermediate parsing step.During inference, top-k prediction accuracy is used for anomaly identification, with heuristics to set the threshold automatically.LogFiT works directly on raw logs, eliminating the need for a separate log parsing step to extract log templates.LogFiT uses the pretrained model's extensive vocabulary of sub-word tokens to adapt to diverse log content.•LogFiT offers a provision of using one of two base models -RoBERTa and Longformer.The former allows faster training, while the latter is capable of handling longer log sequences.
• The model employs a novel masked sentence predictiontraining objective to enhance the contextual understand-ing of log sentences and their constituent tokens, thusimproving anomaly detection performance.LogFiT is designed for easy integration into existing NLPtool sets and the larger system observability ecosystem.• We compare LogFiT against established methods,DeepLog and LogBERT, to demonstrate its effectiveness.The present paper differs from the authors' earlier confer-ence paper
• • Heuristics are used for base model selection and hyperparameter tuning, enhancing ease of use.•LogFiT can also serve as a semantic embedding tool, generating log representations that can be used for other tasks outside of anomaly detection.•</p>
<p>TABLE II PER
II
-PARAGRAPH WORD AND SENTENCE STATISTICS FOR THE DATASETS</p>
<p>The LogFiT model was extended to include a centroid distance minimisation objective (as used in LogBERT) alongside the standard masked token prediction.The loss function, as shown in Equation (2), was thus a combination of the cross-entropy loss from Equation (1) and a new term representing the centroid distance weighted by a hyperparameter cw (set to 0.25).The centroid distance is essentially the proximity of each log paragraph's
TABLE VIANOMALY DETECTION THROUGHPUT (IN SAMPLES PER SECOND) OFDIFFERENT METHODS ON THE HDFS, BGL AND THUNDERBIRDDATASETS. BGL AND THUNDERBIRD VALUES ARE AVERAGED ACROSSTIME WINDOWS OF 10S, 30S, AND 60S. BOLD VALUES REPRESENT THEHIGHEST IN A COLUMNDeepLog and LogBERT, whose vocabularies are based on thenumber of unique log templates, LogFiT's vocabulary is moreextensive -which allows it to handle variability in log content.Additionally, LogFiT accommodates up to 4096 tokens, asopposed to the 512-token limit in DeepLog and LogBERT.Finally, LogFiT's lower throughput is also influenced by itsgeneration of detailed metrics and artifacts at inference time.In contrast, DeepLog and LogBERT's outputs are simplestatements printed out to the terminal. It is important to clarifythat the primary objective of our research was not centredon throughput optimization. Throughput enhancements forLogFiT is a subject we explore in the future.Centroid Distance Minimisation:</p>
<p>TABLE VII ANOMALY
VII
DETECTION PRECISION RECALL (R), F1 SCORE (F) AND SPECIFICITY (S) OF DIFFERENT METHODS ON THE BGL DATASET.THE EVALUATION DATA WAS MODIFIED TO REPLACE THE TOP 10 VERBS WITH THEIR WORDNET LEMMAS</p>
<p>Authorized licensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply.
Included in the LogBERT source code distribution.Authorized licensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply.
. This work was supported in part by the Central Queensland University's School of Graduate Research and in part by the Commonwealth Scientific and Industrial Research Organisation (CSIRO)'s Data61 unit.The associate editor coordinating the review of this article and approving it for publication was Y. Diao.
The Evil Internet Minute 2019. Riskiq Inc, San Francisco, C A , 2019</p>
<p>Australia's Cyber Security Strategy 2020. Australia Dept, Home Affairs. Belconnen, Australia2020pdf Authorized licensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply</p>
<p>Cost of a Data Breach Report 2022. Int. Bus. Mach. Technol. Corp. 2022</p>
<p>Log-based anomaly detection with deep learning: How far are we?. V H Le, H Zhang, Proc. 44th Int. 44th Int2022</p>
<p>A survey on automated log analysis for reliability engineering. S He, P He, Z Chen, T Yang, Y Su, M R Lyu, ACM Comput. Surveys. 5462021</p>
<p>Experience report: Deep learning-based system log analysis for anomaly detection. Z Chen, J Liu, W Gu, Y Su, M R Lyu, arXiv:2107.059082022</p>
<p>Characterizing the natural language descriptions in software logging statements. P He, Z Chen, S He, M R Lyu, Proc. 33rd ACM/IEEE Int. 33rd ACM/IEEE Int2018</p>
<p>DeepLog: Anomaly detection and diagnosis from system logs through deep learning. M Du, F Li, G Zheng, V Srikumar, Proc. ACM Conf. Comput. Commun. Secur. ACM Conf. Comput. Commun. Secur2017</p>
<p>LogBERT: Log anomaly detection via BERT. H Guo, S Yuan, X Wu, Proc. Int. Joint Conf. Neural Netw. Int. Joint Conf. Neural Netw2021</p>
<p>Selfattentive classification-based anomaly detection in unstructured logs. S Nedelkoski, J Bogatinovski, A Acker, J Cardoso, O Kao, Proc.-IEEE Int. Conf. Data Min., (ICDM). -IEEE Int. Conf. Data Min., (ICDM)2020</p>
<p>Robust log-based anomaly detection on unstable log data. X Zhang, 10.1145/3338906.3338931Proc. 27th ACM Joint Meet. 27th ACM Joint Meet2019</p>
<p>Hitanomaly: Hierarchical transformers for anomaly detection in system log. S Huang, IEEE Trans. Netw. Service Manag. 174Dec. 2020</p>
<p>Recompose event sequences vs. predict next events: A novel anomaly detection approach for discrete event logs. L.-P Yuan, P Liu, S Zhu, Proc. null2021</p>
<p>Pretrained Transformers Improve Out-of-Distribution Robustness. D Hendrycks, X Liu, E Wallace, A Dziedzic, R Krishnan, D Song, Proc. 58th Annu. 58th Annu2020</p>
<p>Robust and transferable anomaly detection in log data using pre-trained language models. H Ott, J Bogatinovski, A Acker, S Nedelkoski, O Kao, Proc. IEEE/ACM Int. Workshop Cloud Intell. IEEE/ACM Int. Workshop Cloud Intell2021</p>
<p>Log-based anomaly detection without log parsing. V.-H Le, H Zhang, Proc. 36th IEEE/ACM Int. Conf. Autom. Softw. Eng. (ASE). 36th IEEE/ACM Int. Conf. Autom. Softw. Eng. (ASE)2021</p>
<p>A2Log: Attentive Augmented Log Anomaly Detection. T Wittkopp, Proc. Hawaii Int. Conf. Syst. Sci. (HICSS). Hawaii Int. Conf. Syst. Sci. (HICSS)2021</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M W Chang, K Lee, K Toutanova, Proc. Conf. North Am. Chapter Assoc. Conf. North Am. Chapter Assoc2019</p>
<p>Attention is all you need. A Vaswani, Proc. 31st. 31st2017</p>
<p>Can language models help in system security? investigating log anomaly detection using BERT. C Almodovar, F Sabrina, S Karimi, S Azad, Proc. 20th Annu. 20th Annu2022</p>
<p>ATLAS: A sequence-based learning approach for attack investigation. A Alsaheel, Proc. 30th USENIX Secur. Symp. (USENIX Secur. 30th USENIX Secur. Symp. (USENIX Secur</p>
<p>Holmes: Real-time apt detection through correlation of suspicious information flows. S M Milajerdi, R Gjomemo, B Eshete, R Sekar, V N Venkatakrishnan, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)2019</p>
<p>Euler: Detecting network lateral movement via scalable temporal link prediction. I J King, H H Huang, ACM Trans. Privacy Secur. 2632023</p>
<p>Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise. F Liu, Y Wen, D Zhang, X Jiang, X Xing, D Meng, Proc. ACM SIGSAC Conf. ACM SIGSAC Conf2019</p>
<p>UIScope: Accurate, instrumentation-free, and visible attack investigation for gui applications. R Yang, S Ma, H Xu, X Zhang, Y Chen, Proc. NDSS. NDSS2020</p>
<p>Detecting unknown encrypted malicious traffic in real time via flow interaction graph analysis. C Fu, Q Li, K Xu, arXiv:2301.136862023</p>
<p>Loganomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs. W Meng, Proc. 28th Int. Joint Conf. Artif. Intell. (IJCAI). 28th Int. Joint Conf. Artif. Intell. (IJCAI)2019</p>
<p>LAnoBERT: System log anomaly detection based on BERT masked language model. Y Lee, J Kim, P Kang, arXiv:2111.095642023</p>
<p>What does BERT learn about the structure of language. G Jawahar, B Sagot, D Seddah, Proc. 57th Annu. 57th Annu2020</p>
<p>How does BERT capture semantics? A closer look at polysemous words. D Yenicelik, F Schmidt, Y Kilcher, Proc. 3rd BlackboxNLP Workshop Anal. 3rd BlackboxNLP Workshop Anal2020</p>
<p>Do transformers really perform bad for graph representation. C Ying, arXiv:2106.052342021</p>
<p>A generalization of transformer networks to graphs. V P Dwivedi, X Bresson, arXiv:2012.096992021</p>
<p>Deep learning for anomaly detection: A review. G Pang, C Shen, L Cao, A V D Hengel, 10.1145/3439950ACM Comput. Surv. 542Mar. 2021</p>
<p>Deep learning for anomaly detection: A survey. R Chalapathy, S Chawla, arXiv:1901.034072019</p>
<p>An empirical investigation of practical log anomaly detection for online service systems. N Zhao, 10.1145/3468264.3473933Proc. 29th ACM Joint Meet. 29th ACM Joint Meet2021</p>
<p>Open Sesame: Getting inside BERT's Linguistic Knowledge. Y Lin, Y C Tan, R Frank, Proc. ACL Workshop BlackboxNLP Anal. ACL Workshop BlackboxNLP Anal2019</p>
<p>Assessing BERT's syntactic abilities. Y Goldberg, arXiv:1901.052872019</p>
<p>On the opportunities and risks of foundation models. R Bommasani, arXiv:2108.072582022</p>
<p>RoBERTa: A robustly optimized BERT pretraining approach. Y Liu, arXiv:1907.116922019</p>
<p>Longformer: The longdocument transformer. I Beltagy, M E Peters, A Cohan, arXiv:2004.051502020</p>
<p>Super-convergence: very fast training of neural networks using large learning rates. L N Smith, N Topin, Proc. SPIE Commer. Sens. SPIE Commer. Sens201936</p>
<p>Universal language model fine-tuning for text classification. J Howard, S Ruder, Proc. 56th Annu. 56th Annu2018</p>
<p>Fastai: A layered API for deep learning. J Howard, S Gugger, Information. 1121082020</p>
<p>Don't stop pretraining: Adapt language models to domains and tasks. S Gururangan, Proc. 58th Annu. 58th Annu2020</p>
<p>Fine-tuning can distort pretrained Features and underperform out-ofdistribution. A Kumar, A Raghunathan, R Jones, T Ma, P Liang, arXiv:2202.100542022</p>
<p>Detecting large-scale system problems by mining console logs. W Xu, L Huang, A Fox, D Patterson, M I Jordan, Proc. 27th Int. Conf. Mach. Learn. (ICML). 27th Int. Conf. Mach. Learn. (ICML)2010</p>
<p>What supercomputers say: A study of five system logs. A Oliner, J Stearley, Proc. Int. Conf. Dependable Syst. Netw. Int. Conf. Dependable Syst. Netw2007</p>
<p>Wordnet: A lexical database for english. G A Miller, Commun. ACM. 38111995</p>
<p>LogFiT: Log anomaly detection using fine-tuned language models. C Almodovar, F Sabrina, S Karimi, S Azad, 2023Techrxiv</p>
<p>Evaluation methods for statistically dependent text. S Karimi, J Yin, J Baum, Comput. Linguist. 4132015</p>
<p>UMAP: Uniform manifold approximation and projection for dimension reduction. L Mcinnes, J Healy, J Melville, arXiv:1802.034262020</p>            </div>
        </div>

    </div>
</body>
</html>