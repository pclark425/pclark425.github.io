<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3771 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3771</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3771</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-89.html">extraction-schema-89</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <p><strong>Paper ID:</strong> paper-267053bfcc4c249ca2ec8f0ad261988ec73163b2</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/267053bfcc4c249ca2ec8f0ad261988ec73163b2" target="_blank">Extracting human interpretable structure-property relationships in chemistry using XAI and large language models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically.</p>
                <p><strong>Paper Abstract:</strong> Explainable Artificial Intelligence (XAI) is an emerging field in AI that aims to address the opaque nature of machine learning models. Furthermore, it has been shown that XAI can be used to extract input-output relationships, making them a useful tool in chemistry to understand structure-property relationships. However, one of the main limitations of XAI methods is that they are developed for technically oriented users. We propose the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically. We conducted 5 case studies to evaluate the performance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3771.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3771.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>XpertAI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>XpertAI framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A chemistry-focused framework that combines model-agnostic XAI (SHAP/LIME) with retrieval-augmented large language model generation to produce dataset-specific natural-language explanations of structure–property relationships using curated literature evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (via OpenAI API)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Used as the generative LLM backend (accessed via LangChain) to ingest XAI-identified features and retrieved literature snippets and produce chain-of-thought prompted natural-language explanations; architecture: OpenAI GPT-4 (large transformer; exact size not specified in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>Chemistry (structure–property relationships across domains: MOFs, small-molecule toxicity, solubility, flammability)</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td>Curated small-to-moderate literature sets per case study (reported 11–19 publications per task in experiments); system supports user-provided corpora and arXiv scraping for larger collections.</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Qualitative structure–property heuristics and mechanistic relationships (interpretable rules/heuristics linking molecular/crystal features to target properties).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Retrieval-augmented generation: feature set from XAI (SHAP/LIME) passed to LLM; literature excerpts selected by Maximal Marginal Relevance (MMR) from Chroma vector DB; fed to GPT-4 with chain-of-thought style prompting to produce natural-language explanations and cite evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Human expert evaluation (3 chemists scored XpertAI vs. ChatGPT vs. SHAP plots); automated comparative review by Claude AI; RMSE/model diagnostics used to interpret failure cases.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>XpertAI produced dataset-specific, literature-backed natural-language explanations that map XAI-identified features to mechanistic or heuristic relationships for five chemistry case studies; experts judged these explanations as more specific and interpretable than LLM-only or XAI-only outputs, though sometimes less familiar than general ChatGPT explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Relies on surrogate model fidelity (spurious correlations in the trained model lead to incorrect explanations); explanation quality depends on the quality/coverage of the supplied literature corpus; current implementation depends on GPT-4 (non-open) and uses relatively small curated corpora in experiments; hyperparameters are hardcoded which may limit technical control; potential for hallucination mitigated but not eliminated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting human interpretable structure-property relationships in chemistry using XAI and large language models', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3771.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3771.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-scale pretrained autoregressive transformer language model from OpenAI used here both as the backbone for XpertAI's NL explanation generation and as a baseline (ChatGPT/GPT-4) in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gpt-4technicalreport</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's GPT-4, a large transformer-based generative language model (exact parameter count/architecture details not specified in this paper); used via API for retrieval-augmented generation and also used standalone as a baseline ChatGPT-style explainer.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>General pretrained model applied to chemistry literature and XAI outputs (multidisciplinary but used here in chemistry).</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td>Pretrained on web-scale corpora (not specified); in this application GPT-4 consumed curated literature snippets (11–19 publications) passed by the retrieval component.</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Natural-language summaries and hypothesized mechanistic links (heuristic/qualitative explanations tying features to properties).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Prompting (including chain-of-thought examples) and retrieval-augmented generation via LangChain + Chroma + MMR to ground outputs in selected literature excerpts; also used in a standalone prompted baseline setting.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Human expert scoring comparing GPT-4 (ChatGPT) outputs to XpertAI outputs and SHAP visualizations; also compared by Claude AI.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>As a standalone LLM, GPT-4 produced broad, high-level scientific hypotheses that experts found familiar and sometimes rated more 'accurate' due to generality; when integrated with XAI+retrieval (XpertAI) it helped produce more dataset-specific, literature-cited explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>When used alone, lacked specificity to the dataset and could produce general statements not grounded in the provided data; susceptible to hallucination/unsupported claims if retrieval grounding or XAI inputs are weak.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting human interpretable structure-property relationships in chemistry using XAI and large language models', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3771.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3771.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LangChain + Chroma + MMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LangChain (retrieval orchestration) + Chroma (vector DB) + Maximal Marginal Relevance (MMR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented pipeline: LangChain orchestrates queries, Chroma stores vectorized literature passages for similarity retrieval, and MMR selects diverse, relevant excerpts to provide grounding context to the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>retrieval stack (LangChain orchestration + Chroma vector DB)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LangChain is a prompt-and-chain orchestration library; Chroma is an embedding-indexed vector database used to store literature embeddings; MMR is used to select a diverse subset of relevant excerpts for prompting the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>Scholarly literature in chemistry (user-curated sets and arXiv-scraped papers).</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td>Experimentally small curated sets (11–19 papers per case study) but system supports larger scraped corpora via arXiv integration.</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Supports extraction of literature evidence to ground qualitative heuristics and explanations (helps LLM link XAI-identified features to published findings).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Retrieval (semantic search) + MMR selection to assemble supporting textual evidence which is then concatenated into prompts ('stuffing') for the LLM with chain-of-thought examples.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Indirect: quality assessed via the grounded explanations produced by the LLM and subsequent human expert evaluation and comparison with baseline LLM-only outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>This pipeline enabled XpertAI to ground data-driven XAI observations in literature citations and produce more scientifically referenced explanations than LLM-only prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Effectiveness depends on the coverage and quality of the indexed literature and on embedding/retrieval quality; small curated corpora in experiments limit claims about scaling to very large collections.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting human interpretable structure-property relationships in chemistry using XAI and large language models', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3771.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3771.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Seshadri et al. 2022</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Why does that molecule smell? (Seshadri et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work (cited by the authors) that combined LLMs with XAI to generate human-interpretable explanations in a chemistry context; in that work LLMs were used primarily to summarize XAI findings in natural language rather than to perform literature-grounded distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Why does that molecule smell?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM (in cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Cited study used LLMs in conjunction with XAI to produce explanations; specific model architecture/size not detailed in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>Chemistry (olfaction/structure–property relationships).</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Generation of human-interpretable explanations of model predictions (qualitative mechanistic summaries).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>LLM-based summarization of XAI outputs (per authors' description in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not detailed in this paper (only cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as earlier evidence that combining LLMs and XAI can yield human-interpretable explanations, but distinguished by the present work which additionally integrates literature retrieval to ground explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>According to this paper, the prior work used LLMs only to summarize XAI outputs and did not perform literature-grounded distillation of qualitative scientific rules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting human interpretable structure-property relationships in chemistry using XAI and large language models', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3771.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3771.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) or related AI systems being used to distill, extract, or induce qualitative laws, rules, or scientific principles from large collections of scholarly or scientific papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Jablonka et al. 2023</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Leveraging large language models for predictive chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work demonstrating that fine-tuning LLMs can help address chemistry-specific representation challenges and support predictive tasks in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Leveraging large language models for predictive chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>The cited study demonstrates fine-tuning LLMs for chemistry tasks; architectural/size details are in the cited paper (not specified here).</td>
                        </tr>
                        <tr>
                            <td><strong>input_domain</strong></td>
                            <td>Chemistry (predictive modeling).</td>
                        </tr>
                        <tr>
                            <td><strong>corpus_size</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Predictive model behavior and possibly distilled heuristics via fine-tuned LLMs (as discussed by the cited authors).</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Fine-tuning LLMs on domain-specific chemistry data (per the cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not detailed here; referenced as supportive literature for LLM utility in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Referenced as demonstrating that adapting LLMs to chemistry can help overcome representation issues and improve task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Details and limitations are in the original cited paper; the present paper only references it as motivation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting human interpretable structure-property relationships in chemistry using XAI and large language models', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Leveraging large language models for predictive chemistry <em>(Rating: 2)</em></li>
                <li>Chemcrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>Why does that molecule smell? <em>(Rating: 2)</em></li>
                <li>Generating visual explanations with natural language <em>(Rating: 1)</em></li>
                <li>Gpt-4technicalreport <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3771",
    "paper_id": "paper-267053bfcc4c249ca2ec8f0ad261988ec73163b2",
    "extraction_schema_id": "extraction-schema-89",
    "extracted_data": [
        {
            "name_short": "XpertAI",
            "name_full": "XpertAI framework",
            "brief_description": "A chemistry-focused framework that combines model-agnostic XAI (SHAP/LIME) with retrieval-augmented large language model generation to produce dataset-specific natural-language explanations of structure–property relationships using curated literature evidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (via OpenAI API)",
            "model_description": "Used as the generative LLM backend (accessed via LangChain) to ingest XAI-identified features and retrieved literature snippets and produce chain-of-thought prompted natural-language explanations; architecture: OpenAI GPT-4 (large transformer; exact size not specified in paper).",
            "input_domain": "Chemistry (structure–property relationships across domains: MOFs, small-molecule toxicity, solubility, flammability)",
            "corpus_size": "Curated small-to-moderate literature sets per case study (reported 11–19 publications per task in experiments); system supports user-provided corpora and arXiv scraping for larger collections.",
            "law_type": "Qualitative structure–property heuristics and mechanistic relationships (interpretable rules/heuristics linking molecular/crystal features to target properties).",
            "distillation_method": "Retrieval-augmented generation: feature set from XAI (SHAP/LIME) passed to LLM; literature excerpts selected by Maximal Marginal Relevance (MMR) from Chroma vector DB; fed to GPT-4 with chain-of-thought style prompting to produce natural-language explanations and cite evidence.",
            "evaluation_method": "Human expert evaluation (3 chemists scored XpertAI vs. ChatGPT vs. SHAP plots); automated comparative review by Claude AI; RMSE/model diagnostics used to interpret failure cases.",
            "results_summary": "XpertAI produced dataset-specific, literature-backed natural-language explanations that map XAI-identified features to mechanistic or heuristic relationships for five chemistry case studies; experts judged these explanations as more specific and interpretable than LLM-only or XAI-only outputs, though sometimes less familiar than general ChatGPT explanations.",
            "limitations_or_challenges": "Relies on surrogate model fidelity (spurious correlations in the trained model lead to incorrect explanations); explanation quality depends on the quality/coverage of the supplied literature corpus; current implementation depends on GPT-4 (non-open) and uses relatively small curated corpora in experiments; hyperparameters are hardcoded which may limit technical control; potential for hallucination mitigated but not eliminated.",
            "uuid": "e3771.0",
            "source_info": {
                "paper_title": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large-scale pretrained autoregressive transformer language model from OpenAI used here both as the backbone for XpertAI's NL explanation generation and as a baseline (ChatGPT/GPT-4) in comparisons.",
            "citation_title": "Gpt-4technicalreport",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "OpenAI's GPT-4, a large transformer-based generative language model (exact parameter count/architecture details not specified in this paper); used via API for retrieval-augmented generation and also used standalone as a baseline ChatGPT-style explainer.",
            "input_domain": "General pretrained model applied to chemistry literature and XAI outputs (multidisciplinary but used here in chemistry).",
            "corpus_size": "Pretrained on web-scale corpora (not specified); in this application GPT-4 consumed curated literature snippets (11–19 publications) passed by the retrieval component.",
            "law_type": "Natural-language summaries and hypothesized mechanistic links (heuristic/qualitative explanations tying features to properties).",
            "distillation_method": "Prompting (including chain-of-thought examples) and retrieval-augmented generation via LangChain + Chroma + MMR to ground outputs in selected literature excerpts; also used in a standalone prompted baseline setting.",
            "evaluation_method": "Human expert scoring comparing GPT-4 (ChatGPT) outputs to XpertAI outputs and SHAP visualizations; also compared by Claude AI.",
            "results_summary": "As a standalone LLM, GPT-4 produced broad, high-level scientific hypotheses that experts found familiar and sometimes rated more 'accurate' due to generality; when integrated with XAI+retrieval (XpertAI) it helped produce more dataset-specific, literature-cited explanations.",
            "limitations_or_challenges": "When used alone, lacked specificity to the dataset and could produce general statements not grounded in the provided data; susceptible to hallucination/unsupported claims if retrieval grounding or XAI inputs are weak.",
            "uuid": "e3771.1",
            "source_info": {
                "paper_title": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LangChain + Chroma + MMR",
            "name_full": "LangChain (retrieval orchestration) + Chroma (vector DB) + Maximal Marginal Relevance (MMR)",
            "brief_description": "A retrieval-augmented pipeline: LangChain orchestrates queries, Chroma stores vectorized literature passages for similarity retrieval, and MMR selects diverse, relevant excerpts to provide grounding context to the LLM.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "retrieval stack (LangChain orchestration + Chroma vector DB)",
            "model_description": "LangChain is a prompt-and-chain orchestration library; Chroma is an embedding-indexed vector database used to store literature embeddings; MMR is used to select a diverse subset of relevant excerpts for prompting the LLM.",
            "input_domain": "Scholarly literature in chemistry (user-curated sets and arXiv-scraped papers).",
            "corpus_size": "Experimentally small curated sets (11–19 papers per case study) but system supports larger scraped corpora via arXiv integration.",
            "law_type": "Supports extraction of literature evidence to ground qualitative heuristics and explanations (helps LLM link XAI-identified features to published findings).",
            "distillation_method": "Retrieval (semantic search) + MMR selection to assemble supporting textual evidence which is then concatenated into prompts ('stuffing') for the LLM with chain-of-thought examples.",
            "evaluation_method": "Indirect: quality assessed via the grounded explanations produced by the LLM and subsequent human expert evaluation and comparison with baseline LLM-only outputs.",
            "results_summary": "This pipeline enabled XpertAI to ground data-driven XAI observations in literature citations and produce more scientifically referenced explanations than LLM-only prompts.",
            "limitations_or_challenges": "Effectiveness depends on the coverage and quality of the indexed literature and on embedding/retrieval quality; small curated corpora in experiments limit claims about scaling to very large collections.",
            "uuid": "e3771.2",
            "source_info": {
                "paper_title": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Seshadri et al. 2022",
            "name_full": "Why does that molecule smell? (Seshadri et al.)",
            "brief_description": "Prior work (cited by the authors) that combined LLMs with XAI to generate human-interpretable explanations in a chemistry context; in that work LLMs were used primarily to summarize XAI findings in natural language rather than to perform literature-grounded distillation.",
            "citation_title": "Why does that molecule smell?",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM (in cited work)",
            "model_description": "Cited study used LLMs in conjunction with XAI to produce explanations; specific model architecture/size not detailed in the present paper.",
            "input_domain": "Chemistry (olfaction/structure–property relationships).",
            "corpus_size": "Not specified in this paper.",
            "law_type": "Generation of human-interpretable explanations of model predictions (qualitative mechanistic summaries).",
            "distillation_method": "LLM-based summarization of XAI outputs (per authors' description in this paper).",
            "evaluation_method": "Not detailed in this paper (only cited as related work).",
            "results_summary": "Cited as earlier evidence that combining LLMs and XAI can yield human-interpretable explanations, but distinguished by the present work which additionally integrates literature retrieval to ground explanations.",
            "limitations_or_challenges": "According to this paper, the prior work used LLMs only to summarize XAI outputs and did not perform literature-grounded distillation of qualitative scientific rules.",
            "uuid": "e3771.3",
            "source_info": {
                "paper_title": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Jablonka et al. 2023",
            "name_full": "Leveraging large language models for predictive chemistry",
            "brief_description": "Cited work demonstrating that fine-tuning LLMs can help address chemistry-specific representation challenges and support predictive tasks in chemistry.",
            "citation_title": "Leveraging large language models for predictive chemistry",
            "mention_or_use": "mention",
            "model_name": "LLMs (fine-tuned)",
            "model_description": "The cited study demonstrates fine-tuning LLMs for chemistry tasks; architectural/size details are in the cited paper (not specified here).",
            "input_domain": "Chemistry (predictive modeling).",
            "corpus_size": "Not specified in this paper.",
            "law_type": "Predictive model behavior and possibly distilled heuristics via fine-tuned LLMs (as discussed by the cited authors).",
            "distillation_method": "Fine-tuning LLMs on domain-specific chemistry data (per the cited work).",
            "evaluation_method": "Not detailed here; referenced as supportive literature for LLM utility in chemistry.",
            "results_summary": "Referenced as demonstrating that adapting LLMs to chemistry can help overcome representation issues and improve task performance.",
            "limitations_or_challenges": "Details and limitations are in the original cited paper; the present paper only references it as motivation.",
            "uuid": "e3771.4",
            "source_info": {
                "paper_title": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Leveraging large language models for predictive chemistry",
            "rating": 2
        },
        {
            "paper_title": "Chemcrow: Augmenting large-language models with chemistry tools",
            "rating": 2
        },
        {
            "paper_title": "Why does that molecule smell?",
            "rating": 2
        },
        {
            "paper_title": "Generating visual explanations with natural language",
            "rating": 1
        },
        {
            "paper_title": "Gpt-4technicalreport",
            "rating": 1
        }
    ],
    "cost": 0.01315775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Extracting human interpretable structure-property relationships in chemistry using XAI and large language models</h1>
<p>Geemi P. Wellawatte Philippe Schwaller<br>Laboratory of Artificial Chemical Intelligence<br>Institute of Chemical Sciences and Engineering<br>Ecole Polytechnique Fédérale de Lausanne (EPFL)<br>Lausanne, Switzerland<br>{geemi.wellawatte,philippe.schwaller}@epfl.ch</p>
<h4>Abstract</h4>
<p>Explainable Artificial Intelligence (XAI) is an emerging field in AI that aims to address the opaque nature of machine learning models. Furthermore, it has been shown that XAI can be used to extract input-output relationships, making them a useful tool in chemistry to understand structure-property relationships. However, one of the main limitations of XAI methods is that they are developed for technically oriented users. We propose the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically. We conducted 5 case studies to evaluate the performance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.</p>
<h2>1 Introduction</h2>
<p>Understanding structure-property relationships has been a long-standing challenge in chemistry ${ }^{1-3}$ Seybold et al. ${ }^{2}$ highlight a fundamental concept in chemistry: the "properties and behaviors of molecules follow from their structures". Therefore, elucidating these relationships facilitates the manipulation of molecules to achieve desired properties. Machine learning (ML) is a routinely used tool to complement human expertise, which solves complex tasks in chemistry by modeling structure-property relationships. ${ }^{4-8}$ While ML has been proven to be successful in solving such tasks in chemistry, ${ }^{9-15}$ experimental chemists often harbor skepticism toward predictions generated by such models, primarily due to the inherent opacity of these models. In essence, these ML models usually do not provide a rationale as to why a certain prediction was made. EXplainable Artificial Intelligence (XAI) is a new branch of AI that is rapidly growing and aims to explain the opacity nature of ML models. Therefore, developing XAI tools for chemistry is critical for increasing trust in ML models and expanding the possibilities of experimental and computational chemistry.
Justifications, explanations, and interpretability are three terms associated with XAI. ${ }^{16-18}$ While a justification simply provides evidence for a prediction ${ }^{19}$, an explanation describes the rationale for the prediction. ${ }^{20}$ However, the true potency of XAI lies in its interpretability, which concerns the extent to which a human can comprehend the provided explanation. ${ }^{21}$ In a recent survey, Cambria et al. ${ }^{22}$ emphasized that there is a pressing need to refine the presentation of explanations. This means that although XAI addresses the opacity of ML models, they are not user-friendly for non-domain experts or non-technical users. Therefore, there is growing interest in incorporating natural language (NL) with XAI to produce more accessible explanations. ${ }^{22,23}$ Furthermore, it's</p>
<p>worth noting that existing XAI methods often lack the flexibility to address specific user queries can usually answer only one specific question, impeding their adaptability. ${ }^{24-27}$
To meet the demand for creating intelligent, adaptable, and user-friendly XAI tools for chemistry, we introduce a Python package named "XpertAI". Our tool combines XAI methods with large language models (LLMs) to extract structure-property relationships from raw data. LLMs are generative models which can predict an output sequence given an input sequence. LLMs can be made into powerful agents that query databases, scrape and summarize literature, interpret, and generate text in NL. ${ }^{28}$ However, LLMs in isolation are limited in addressing domain-specific problems within the field of chemistry. For example, in the work by Hendricks et al., ${ }^{29}$, the authors provide a promising workflow for generating NLEs in image classification tasks. However, such approaches are not readily adaptable in chemistry applications due to a number of limitations, including the molecular representation issue commonly associated with deep learning in chemistry. To circumvent such challenges at the intersection of chemistry and LLMs, Jablonka et al. ${ }^{30}$ demonstrated that finetuning LLMs could provide a solution to this. Additionally, Bran et al. ${ }^{31}$ showed LLMs can be enhanced to tackle tasks such as organic synthesis, drug discovery, and materials design. Previously, it has been suggested that "black-box modeling first, followed by XAI" as a means to establish structure-property relationships without compromising accuracy or interpretability. ${ }^{18}$ Seshadri et al. ${ }^{32}$ showed that LLMs combined with XAI can generate human interpretable explanations. Unlike our approach, this work used LLMs only to summarize the findings from the XAI analysis in natural language. Following a similar direction, we demonstrate that LLMs combined with XAI tools and literature evidence, play a powerful role in generating both interpretable and scientifically accurate explanations.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of XpertAI. The proposed tool combines XAI with LLMs to uncover human interpretable structure-property relationships from raw data.</p>
<p>XpertAI aims to establish connections between black-box models, XAI tools, and literature through LLMs to uncover relationships between molecular features and target properties. As shown in Figure 1, XpertAI employs XAI methods to identify crucial features within the dataset and subsequently drawing on scientific evidence to articulate structure-property connections based on these features. One of the key advantages of XpertAI is its ability to deliver precise natural language explanations (NLEs) tailored to specific datasets, as opposed to providing generalized explanations drawn from the broader literature. As illustrated in Figure 2 XpertAI combines the strengths of XAI and LLMs in terms of specificity, interpretability, accessibility, and scientific nature of the explanations. To the best of our knowledge, currently there is no such</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Attributes of XpertAI explanations in comparison to baseline methods.
tool in chemistry, which extracts NL structure-property relationships from user-given raw data. Furthermore, our application is generalizable to any domain that requires extracting input-output relationships as NLEs.</p>
<h1>2 Method</h1>
<p>We begin the workflow by training an ML model using the initial raw data. This model serves as a surrogate for mapping input to output. The initial dataframe includes featurized molecular structures and target labels for training. Note that these features must be human-interpretable (e.g., molecular descriptors/properties or MACCS keys). We currently employ gradient-boosting decision trees with the XGBoost framework, utilizing the Scikit-learn API for regression and classification tasks. ${ }^{33,34}$ Once the model is trained, users can select from SHAP ${ }^{35}$, LIME $^{36}$, or both to estimate the "most impactful" features. SHAP and LIME are commonly used to generate local explanations. Therefore, we compute mean SHAP values and Z-scores for LIME explanations to extract globally impactful features. For the LIME analysis, we only use a sample of the initial dataset due to time and resource constraints. The default sample size is either 500 or the entire dataset if its length is less than 500. After identifying impactful features, we draw knowledge from the literature to elucidate physicochemical relationships between these features and the target property. As seen in the overview of our proposed workflow (Figure 1) LLMs are used to unite the backend modules generating human interpretable explanations. We leverage on LangChain python package (https://github.com/langchain-ai/langchain), OpenAI's GPT-4 ${ }^{37}$ language model, and Chroma vector database (https://github.com/chroma-core/ chroma) to query multiple literature publications and generate intelligent explanations. Users have the flexibility to upload a literature dataset or scrape arxiv.org to gather relevant literature information. The latter is enabled via the arXiv python API.
Once the literature is collected, we select the most related literature excerpts using maximal marginal relevance search (MMR) to validate XAI observations. Following a similar approach as the "StuffDocumentsChain" in LangChain, we stuff these excerpts to a specialized prompt to generate the complete explanation. We utilize the chain-of-thought prompting approach ${ }^{38}$ to create the NLEs - we provide a series of intermediate steps and examples within the prompt to improve the output NLE's interpretability. XpertAI also generates and adds citations in the final NLEs to improve the accountability of the explanations. We would like to highlight that, in addition to the NLEs, XpertAI also provides the surrogate model's evaluation plot (error plot) and XAI analysis plots for the users. To streamline this complete workflow, we have deployed a Streamlit App (https://xpert-ai.streamlit.app/) that can be used with an OpenAI API key. The GitHub repository of our work can be found at: https://github.com/geemi725/XpertAI.</p>
<h1>3 Results</h1>
<p>We used the XpertAI tool to suggest structure-property relationships for five case studies in chemistry; 1) the presence of open metal sites in metal-organic frameworks (classification), 2) pore limiting diameter in metal-organic frameworks (regression), 3) toxicity of small molecules (classification), 4) solubility of small molecules (regression), and 5) upper flammability limit of organic molecules (regression). Please note that we used the SHAP method as the chosen XAI method, and the default hyperparameters to generate NLEs in the following case studies. We chose the SHAP method due to its consistency in generating global explanations in comparison to LIME. Complete NLEs and SHAP plots for each case study from XpertAI are provided in Appendices A and D respectively.
Case studies 1 and 2: Structure-property relationships in Metal-organic frameworks (MOFs). MOFs, a hybrid class of materials in chemistry, consist of metal nodes connected by organic linkers. ${ }^{39}$ Their porous nature lends them versatile properties such as gas separation and storage ${ }^{40-42}$, catalysis ${ }^{43,44}$, and drug delivery ${ }^{45,46}$. Understanding MOF structure-property relationships is crucial for optimizing their design in specific applications. Open metal sites, characterized by coordinative unsaturation, find valuable use in catalysis. ${ }^{39}$ Additionally, the pore-limiting diameter is a key feature for screening them in selective gas capture applications. ${ }^{47}$ However, the precise relationship between MOF atomic structure and open metal sites or pore-limiting diameter remains incompletely understood.
In case study 1, we sampled 3734 MOFs from the CoRE MOF 2019 database ${ }^{48}$. These crystal structures obtained as CIF files were then featurized using the CrystalFeatures tool ${ }^{49}$. Generated features are meaningful descriptors encompassing atomic and crystal characteristics, geometry features, and one-shot ab initio descriptors. Next, we uploaded the featurized inputs along with the binary target labels (presence/absence of open metal sites) as a CSV dataframe along with a literature dataset containing 19 publications to our XpertAI Streamlit App. The list of publications can be found in our GitHub repository. The generated NLE from XpertAI explains how a) metals fraction, b) density of solid, c) average cationic radius correlate with the presence of open metal sites. This explanation aligns with the findings of Hall et al. ${ }^{39}$, where the authors identify metal identity and oxidation state, defect density, and site proximity to be impactful structural components. Note that we did not include this review paper ${ }^{39}$ in the literature dataset uploaded to XpertAI to avoid data tampering. Although the input raw dataset did not include features such as the fraction of electrons in d orbitals, the average ionization energy, and the average electron affinity, XpertAI suggests these features to be correlated with the open metal sites based on literature data.
Following a similar approach in case study 2, we used the same MOF dataset but with pore-limiting diameters as the label. Unlike case study 1, this is a regression-type problem. According to the XpertAI explanation, volume per atom, symmetry function G, and unoccupied energy levels at the conduction band influence the pore-limiting diameter. According to XpertAI, "The Volume Per Atom can affect the Pore-limiting diameter in MOFs as it determines the size of the atoms in the MOF structure. Larger atoms may result in smaller pore sizes (Haldoupis, Nair, \&amp; Sholl, 2010) ${ }^{50}$. The symmetry function $G$ is a measure of the symmetry of the MOF structure, which can also influence the Pore-limiting diameter. MOFs with higher symmetry may have more uniform pore sizes (Yang et al., 2022). ${ }^{51 \text { " }}$ Please see Appendix A for the complete textual explanation.
Case study 3: Small molecule toxicity. Toxicity prediction of small molecules is a benchmark task in chemistry, particularly in drug discovery. ${ }^{52,53}$ Despite the extensive research in this area, a precise understanding of the relationship between molecular structure and toxicity remains elusive. In this case study, we used 1478 molecules from the Tox21 database ${ }^{52}$ where binary labels indicate toxicity (a classification task). Then we featurized the input molecules in SMILES format using MACCS descriptors ${ }^{53}$ implemented in the RDKit package ${ }^{54}$. These descriptors are human-interpretable binary features containing 167 yes/no questions regarding molecular structure. Next, we provided a curated literature dataset with 17 related publications. Our XpertAI explanation summarizes: "The features identified by the XAI analysis that affect the toxicity of small molecules include the presence of a heteroatom bonded to three Oxygen atoms, the presence of an aminomethyl group, and the presence of a Tertiary Amine. Additional features that may be correlated with the toxicity of small molecules include the solubility of the molecule, the presence of aromatic rings, and the presence of nucleophilic $\mathrm{N}, \mathrm{O}$, and aryl containing</p>
<p>substructures." XpertAI suggests that these features alter toxicity as they affect the reactivity of the molecules and their ability to form reactive species, which can cause cellular damage and disrupt cellular processes. This explanation aligns with the findings in work by Meanwell 55 and, Limban et al. ${ }^{56}$ which state that aromatic amines and nitro groups are associated with increasing molecular toxicity. Please note that these references were not included in the literature dataset uploaded to XpertAI. The complete XpertAI NLE can be found in Appendix A. Additionally, XpertAI suggests how to reduce the toxicity of a molecule - the toxicity of a molecule can be reduced by removing the aminomethyl group or the tertiary amine because these increase the reactivity of the molecule, potentially leading to increased toxicity.
Case study 4: Small molecule solubility. Aqueous solubility of small molecules is a critical property in drug discovery as solubility determines the interaction of the drug in a biological environment. ${ }^{57}$ To explain the relationship between the molecular structure and its solubility, we used a sample dataset with 9982 molecules from the AqSolDB ${ }^{58}$ dataset for training. Once again, we used MACCS descriptors to convert the molecules into a binary vector. We uploaded a literature dataset with 18 related publications. References to these can be found in our GitHub repository. XpertAI explains the structure-solubility relationship as follows. "The solubility of small molecules is a complex property that is influenced by a variety of factors. The XAI analysis has identified three key features that significantly impact the solubility of small molecules: the presence of an atom at an aromatic/non-aromatic boundary, the presence of two heteroatoms bonded to each other, and the presence of an atom with three heteroatom neighbors. Presence of an atom at an aromatic/non-aromatic boundary: This feature refers to the location of an atom at the boundary between an aromatic ring and a non-aromatic part of the molecule. Aromatic rings are typically hydrophobic, while non-aromatic parts of the molecule can be either hydrophilic or hydrophobic. Therefore, an atom at this boundary can influence the overall solubility of the molecule by affecting its polarity and ability to form hydrogen bonds with water molecules (Lee at al., 202359)." This excerpt demonstrates that XpertAI provides self-explanatory explanations with references to relevant literature.
Case study 5: Compound flammability.The upper flammability limit (UFL) of an organic compound is an important characteristic that determines the hazardous nature of the compound. ${ }^{60}$ This is an interesting topic of study in both experimental and computational studies. ${ }^{61-64}$ We used the UFL dataset used by Yuan et al. ${ }^{44}$, which was extracted from reference Crowl and Louvar ${ }^{65}$. This dataset only contained 79 organic compounds. We used the same quantum and non-quantum molecular descriptor set used in reference 60 to featurize the molecules. After uploading the initial dataset and 11 curated publications, we obtained the following explanation. "The Structural Information Content Index (Neighborhood Symmetry of Order Zero) and Information Content Index (Neighborhood Symmetry of Order Zero) are measures of the complexity and symmetry of the molecule's structure. Molecules with higher complexity and less symmetry may have higher upper flammability limits due to the increased number of potential reaction pathways (Yuan et al., 2019) ${ }^{66}$. The highest occupied molecular orbital (HOMO) represents the energy level of the highest energy electron in the molecule. Molecules with higher HOMO energy levels may have higher upper flammability limits because they have more energy available for combustion reactions (Yuan et al., 2019) ${ }^{66}$. The Dipole Moment is a measure of the molecule's polarity. Molecules with higher dipole moments may have lower upper flammability limits because the increased polarity can inhibit the dispersion of the molecule in the air, reducing the likelihood of combustion (Yuan et al., 2019). ${ }^{66 \text { " }}$ Based on this explanation, we can conclude that XpertAI provides complete, textual explanations of molecular structure-function relationships extracted from raw data. As these explanations are equipped with literature references, users can evaluate the accuracy of the explanations easily.</p>
<h1>4 Evaluation</h1>
<p>Firstly, to evaluate the explanations for the listed case studies, we compared three different explanations from; 1) XpertAI 2) ChatGPT (GPT-4), and 3) Graphical plots from the XAI analysis (See Appendix D for SHAP plots). We selected these three setups to evaluate if combining LLMs with XAI can harness the advantages of both approaches rather than using one alone. We asked three expert chemists to score 15 explanations in total ( 5 tasks $\times 3$ explanations). The experts were given a scorecard (given in Appendix C) to evaluate each answer based on</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Human expert consensus. 3 human experts were asked to evaluate explanations from XpertAI, ChatGPT, and SHAP plots for each case study based on accuracy and interpretability. Expert consensus is given as a percentage.
accuracy and interpretability. As seen in Figure 3, evaluators associated XpertAI NLEs with being specific to a given dataset/task, providing scientific explanations, and having high accessibility to non-technical experts. However, LLMs by themselves (ChatGPT) were associated with a lack of specificity to the given data, and XAI with a lack of interpretability. As summarized in Figure 2, the evaluations conclude that XpertAI effectively leverages the advantages of both ChatGPT and XAI to provide a complete explanation. These results validate the accomplishment of our goal to extract accessible and interpretable structure-property relationships in chemistry from raw data.
Based on the expert scores, we note that XpertAI's explanations are considered "accurate" or "somewhat accurate". Although ChatGPT scored higher in terms of accuracy, we argue this is because human experts excel at validating generalized scientific hypotheses. However, XpertAI's explanations are specific to relationships established from provided datasets which may be different from familiar concepts in chemistry. Therefore, we conclude that XpertAI shows promise in generating interpretable and accurate natural language descriptions of structure-function relationships. Furthermore, we noted that the explanations remained consistent, indicating less probability of hallucinations over multiple generations. However, it should be emphasized that the accuracy and specificity of the generated explanations are dependent on the quality of the literature dataset provided. To maintain the quality of explanations, we only used specifically curated publications in case studies 1-5. The lists of references used can be found in our GitHub repository.
Next, we asked Claude AI assistant (https://claude.ai/) by Anthropic https://www. anthropic.com/ to compare the two explanations from XpertAI and ChatGPT based on accuracy and interpretability. The responses from Claude are given in Appendix B. Based on the responses, Claude rates the explanations from XpertAI higher than ChatGPT's for 4/5 tasks. We list a few reasons for Claude's higher ratings for XpertAI below. Note that we anonymized the two explanations during the scoring; Explanation A is by XpertAI and Explanation B is by ChatGPT.</p>
<ul>
<li>The language and terminology used in Explanation A is more accessible and easier to understand for a non-expert compared to Explanation B.</li>
<li>Explanation A provides more details on the specific features that impact the target property, including both the top features from XAI analysis and other correlated features (from literature). In contrast, Explanation B only broadly refers to a few features.</li>
<li>Explanation A provides mechanistic explanations and states how the target property can be altered by changing each feature in the desired direction. Explanation B lacks this level of mechanistic detail and only generally mentions that the features can be changed, but not how.</li>
</ul>
<p>However, Claude rates XpertAI's explanation in case study 5 less than ChatGPT's. A similar observation was made from the expert evaluations, where 1 out of 3 evaluators indicated the XpertAI's NLE as not accurate. According to Claude "Explanation B demonstrates strong domain knowledge by linking features to concepts like vapor pressure, steric hindrance, and</p>
<p>flame retardants. Explanation A does not connect to these chemistry concepts." We hypothesize this is due to the underperformance of the trained XGBoost model, as evidenced by a higher root-mean-square error (RMSE) during testing, which results in XpertAI's lower-rated explanation. This possibly stems from the limited size of the training dataset (only 63 data points for training). As a result, the XAI analysis reveals the model could have learned non-causal correlations within the dataset. Therefore, the essential features may not be faithfully represented, thereby leading XpertAI to generate a flawed explanation.</p>
<h1>5 Conclusion \&amp; Outlook</h1>
<p>XAI is becoming increasingly important in ML workflows due to developmental, scientific, and regulatory needs. With the recent growth of XAI, more tools and techniques are emerging. In this context, we addressed a key challenge in applying XAI to chemistry - the lack of interpretability of explanations generated by XAI tools. Generally, XAI tools target technical experts, reducing usability. We proposed "XpertAI", a framework leveraging XAI and LLMs to generate intelligent natural language explanations of structure-property relationships from raw chemistry data. XpertAI produces readily interpretable and specific explanations while uncovering structure-property relationships. XpertAI works for both regression and classification tasks. We showed combining XAI and LLMs is more powerful than using either alone and demonstrated that XpertAI can accurately explain input-output relationships, not just model predictions.
Importantly, XpertAI's performance depends on the surrogate model used by the XAI methods. If the surrogate model has acquired spurious data relationships, it will inevitably yield an inaccurate explanation. In the current version of XpertAI, hyperparameters are hardcoded to enhahnce non-expert usability. However, technically oriented users can implement XpertAI locally using our GitHub repository.
We aim to incorporate other ML models and enable user-provided models, giving more flexibility and making XpertAI model-agnostic. Upcoming work will integrate automated hyperparameter optimization. This will further increase accessibility for non-technical users to generate accurate explanations. Moreover, future work will incorporate additional open-source XAI methods and LLMs into a fully open-source XpertAI without GPT4 dependencies.
Despite current limitations, XpertAI demonstrates promising potential as an interpretable tool for uncovering novel structure-property relationships and generating scientific insights in chemistry. By leveraging AI's strengths in explanation and language, XpertAI aims to democratize chemical knowledge extraction to accelerate scientific progress. With ongoing improvements to the framework, XpertAI represents an exciting advancement in elucidating meaningful chemical structure-property relationships to propel discovery.</p>
<h2>6 Code and Data Availability</h2>
<p>Code to XpertAI can be found at: https://github.com/geemi725/XpertAI and the XpertAI App can be found at: https://xpert-ai.streamlit.app/</p>
<h2>7 Acknowledgments</h2>
<p>We thank the expert evaluators for their contributions to this work. GPW acknowledges funding from the EPFL large-scale Solutions4Sustainability demonstrator project (SusEcoCCUS). PS acknowledges support from the NCCR Catalysis (grant number 180544), a National Centre of Competence in Research funded by the Swiss National Science Foundation.</p>
<p>References</p>
<ul>
<li>[1] Harry Wiener. Structural determination of paraffin boiling points. Journal of the American chemical society, 69(1):17–20, 1947.</li>
<li>[2] Paul G Seybold, Michael May, and Ujjvala A Bagal. Molecular structure: Property relationships. Journal of Chemical Education, 64(7):575, 1987.</li>
<li>[3] Zlatko Mihalić and Nenad Trinajstić. A graph-theoretical approach to structure-property relationships. Journal of Chemical Education, 69(9):701, 1992.</li>
<li>[4] Feng Ren, Xiao Ding, Min Zheng, Mikhail Korzinkin, Xin Cai, Wei Zhu, Alexey Mantsyzov, Alex Aliper, Vladimir Aladinskiy, Zhongying Cao, et al. Alphafold accelerates artificial intelligence powered drug discovery: efficient discovery of a novel cdk20 small molecule inhibitor. Chemical Science, 14(6):1443–1452, 2023.</li>
<li>[5] Ji-Young Kim, Dongkyu Oh, Kiyoung Sung, Hongyoon Choi, Jin Chul Paeng, Gi Jeong Cheon, Keon Wook Kang, Dong Young Lee, and Dong Soo Lee. Visual interpretation of [18 f] florbetaben pet supported by deep learning–based estimation of amyloid burden. European Journal of Nuclear Medicine and Molecular Imaging, 48:1116–1123, 2021.</li>
<li>[6] Erik Gawehn, Jan A Hiss, and Gisbert Schneider. Deep learning in drug discovery. Molecular informatics, 35(1):3–14, 2016.</li>
<li>[7] Artem Lysenko, Alok Sharma, Keith A Boroevich, and Tatsuhiko Tsunoda. An integrative machine learning approach for prediction of toxicity-related drug safety. Life science alliance, 1(6), 2018.</li>
<li>[8] Aayush Jaiswal, Neha Gianchandani, Dilbag Singh, Vijay Kumar, and Manjit Kaur. Classification of the covid-19 infected patients using densenet201 based deep transfer learning. Journal of Biomolecular Structure and Dynamics, 39(15):5682–5689, 2021.</li>
<li>[9] Volker L. Deringer, Miguel A. Caro, and Gábor Csányi. Machine learning interatomic potentials as emerging tools for materials science. Advanced Materials, 31(46):1902765, 2019.</li>
<li>[10] Felix A. Faber, Luke Hutchison, Bing Huang, Justin Gilmer, Samuel S. Schoenholz, George E. Dahl, Oriol Vinyals, Steven Kearnes, Patrick F. Riley, and O. Anatole von Lilienfeld. Prediction errors of molecular machine learning models lower than hybrid dft error. Journal of Chemical Theory and Computation, 13(11):5255–5264, 2017. PMID: 28926232.</li>
<li>[11] Rohan Gupta, Devesh Srivastava, Mehar Sahu, Swati Tiwari, Rashmi K. Ambasta, and Pravir Kumar. Artificial intelligence to deep learning: machine intelligence approach for drug discovery. Molecular diversity, 25:1315–1360, 2021.</li>
<li>[12] Wlodzislaw Duch, Karthikeyan Swaminathan, and Jaroslaw Meller. Artificial intelligence approaches for rational drug design and discovery. Current Pharmaceutical Design, 13:1497–1508, 2007.</li>
<li>[13] Suresh Dara, Swetha Dhamercherla, Surender Singh Jadav, CH Madhu Babu, Mohamed Jawed Ahsan, Suresh Dara darasuresh, and S Dara. Machine learning in drug discovery: A review. Artificial Intelligence Review, 55(3):1947–1999, 2022.</li>
<li>[14] Adam J Gormley and Michael A Webb. Machine learning in combinatorial polymer chemistry. Nature Reviews Materials, 6(8):642–644, 2021.</li>
<li>[15] Carla P Gomes, Daniel Fink, R Bruce Van Dover, and John M Gregoire. Computational sustainability meets materials science. Nature Reviews Materials, 6(8):645–647, 2021.</li>
<li>[16] W James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu. Definitions, methods, and applications in interpretable machine learning. Proceedings of the National Academy of Sciences, 116(44):22071–22080, 2019.</li>
<li>[17] Gesina Schwalbe and Bettina Finzel. A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Data Mining and Knowledge Discovery, pages 1–59, 2023.</li>
<li>[18] Geemi P. Wellawatte, Heta A. Gandhi, Aditi Seshadri, and Andrew D. White. A perspective on explanations of molecular prediction models. Journal of Chemical Theory and Computation, 19(8):2149–2160, 2023. PMID: 36972469.</li>
<li>[19] Tim Miller. Explanation in artificial intelligence: Insights from the social sciences. Artificial intelligence, 267:1–38, 2019.</li>
</ul>
<p>[20] Or Biran and Courtenay Cotton. Explanation and justification in machine learning: A survey. In IJCAI-17 workshop on explainable AI (XAI), volume 8, pages 8-13, 2017.
[21] W. James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu. Definitions, methods, and applications in interpretable machine learning. Proceedings of the National Academy of Sciences, 116(44):22071-22080, 2019.
[22] Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Mario Mezzanzanica, and Navid Nobani. A survey on xai and natural language explanations. Information Processing \&amp; Management, 60(1):103111, 2023.
[23] Ettore Mariotti, Jose M Alonso, and Albert Gatt. Towards harnessing natural language generation to explain black-box models. In 2nd Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence, pages 22-27, 2020.
[24] Atsushi Kanehira and Tatsuya Harada. Learning to explain with complemental examples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8603-8611, 2019.
[25] Robert P Sheridan. Interpretation of QSAR Models by Coloring Atoms According to Changes in Predicted Activity: How Robust Is It? Journal of Chemical Information and Modeling, 59(4):13241337, 2019.
[26] Chris Russell. Efficient search for diverse coherent explanations. In Proceedings of the Conference on Fairness, Accountability, and Transparency, pages 20-28, 2019.
[27] Geemi P. Wellawatte, Aditi Seshadri, and Andrew D. White. Model agnostic generation of counterfactual explanations for molecules. Chemical Science, 13:3697-3705, 2022.
[28] Andrew D White. The future of chemistry is language. Nature Reviews Chemistry, pages 1-2, 2023.
[29] Lisa Anne Hendricks, Anna Rohrbach, Bernt Schiele, Trevor Darrell, and Zeynep Akata. Generating visual explanations with natural language. Applied AI Letters, 2(4):e55, 2021.
[30] Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit. Leveraging large language models for predictive chemistry. ChemRxiv, 2023.
[31] Andres M Bran, Sam Cox, Andrew D White, and Philippe Schwaller. Chemcrow: Augmenting large-language models with chemistry tools. arXiv preprint arXiv:2304.05376, 2023.
[32] Aditi Seshadri, Heta A. Gandhi, Geemi P. Wellawatte, and Andrew D. White. Why does that molecule smell? ChemRxiv, 2022.
[33] Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '16, pages 785-794, New York, NY, USA, 2016. ACM.
[34] Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. Journal of machine learning research, 12(Oct):2825-2830, 2011.
[35] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.
[36] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. "why should i trust you?": Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '16, page 1135-1144, New York, NY, USA, 2016. Association for Computing Machinery.
[37] OpenAI. Gpt-4technicalreport. ArXiv, 2023.
[38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837, 2022.
[39] Jacklyn N Hall and Praveen Bollini. Structure, characterization, and catalytic properties of openmetal sites in metal organic frameworks. Reaction Chemistry \&amp; Engineering, 4(2):207-222, 2019.</p>
<p>[40] Meili Ding, Robinson W. Flaig, Hai-Long Jiang, and Omar M. Yaghi. Carbon capture and conversion using metal-organic frameworks and mof-based materials. Chem. Soc. Rev., 48:2783-2828, 2019.
[41] Alexander Schoedel, Zhe Ji, and Omar M Yaghi. The role of metal-organic frameworks in a carbon-neutral energy cycle. Nature Energy, 1(4):1-13, 2016.
[42] Sibo Wang and Xinchen Wang. Imidazolium ionic liquids, imidazolylidene heterocyclic carbenes, and zeolitic imidazolate frameworks for co2 capture and photochemical reduction. Angewandte Chemie International Edition, 55(7):2308-2320, 2016.
[43] JeongYong Lee, Omar K Farha, John Roberts, Karl A Scheidt, SonBinh T Nguyen, and Joseph T Hupp. Metal-organic framework materials as catalysts. Chemical Society Reviews, 38(5):1450-1459, 2009 .
[44] Dong Yang and Bruce C Gates. Catalysis by metal organic frameworks: perspective and suggestions for future research. Acs Catalysis, 9(3):1779-1798, 2019.
[45] Patricia Horcajada, Christian Serre, Guillaume Maurin, Naseem A Ramsahye, Francisco Balas, María Vallet-Regí, Muriel Sebban, Francis Taulelle, and Gérard Férey. Flexible porous metalorganic frameworks for a controlled drug delivery. Journal of the American Chemical Society, 130(21):6774-6780, 2008.
[46] Patricia Horcajada, Ruxandra Gref, Tarek Baati, Phoebe K Allan, Guillaume Maurin, Patrick Couvreur, Gérard Férey, Russell E Morris, and Christian Serre. Metal-organic frameworks in biomedicine. Chemical reviews, 112(2):1232-1268, 2012.
[47] Ting-Hsiang Hung, Qiang Lyu, Li-Chiang Lin, and Dun-Yen Kang. Transport-relevant pore limiting diameter for molecular separations in metal-organic framework membranes. The Journal of Physical Chemistry C, 125(37):20416-20425, 2021.
[48] Yongchul G Chung, Emmanuel Haldoupis, Benjamin J Bucior, Maciej Haranczyk, Seulchan Lee, Hongda Zhang, Konstantinos D Vogiatzis, Marija Milisavljevic, Sanliang Ling, Jeffrey S Camp, et al. Advances, updates, and analytics for the computation-ready, experimental metal-organic framework database: Core mof 2019. Journal of Chemical \&amp; Engineering Data, 64(12):5985-5998, 2019.
[49] Sherif Abdulkader Tawfik and Salvy P Russo. Naturally-meaningful and efficient descriptors: machine learning of material properties based on robust one-shot ab initio descriptors. Journal of Cheminformatics, 14(1):1-11, 2022.
[50] Emmanuel Haldoupis, Sankar Nair, and David S Sholl. Efficient calculation of diffusion limitations in metal organic framework materials: a tool for identifying materials for kinetic separations. Journal of the American Chemical Society, 132(21):7528-7539, 2010.
[51] Peisong Yang, Gang Lu, Qingyuan Yang, Lei Liu, Xin Lai, and Duli Yu. Analyzing acetylene adsorption of metal-organic frameworks based on machine learning. Green Energy \&amp; Environment, 7(5):1062-1070, 2022.
[52] Ruili Huang, Menghang Xia, Dac-Trung Nguyen, Tongan Zhao, Srilatha Sakamuru, Jinghua Zhao, Sampada A Shahane, Anna Rossoshek, and Anton Simeonov. Tox21challenge to build predictive models of nuclear receptor and stress response pathways as mediated by exposure to environmental chemicals and drugs. Frontiers in Environmental Science, 3:85, 2016.
[53] Joseph L Durant, Burton A Leland, Douglas R Henry, and James G Nourse. Reoptimization of mdl keys for use in drug discovery. Journal of chemical information and computer sciences, 42(6):1273-1280, 2002.
[54] G Landrum. Rdkit: open-source cheminformatics http://www. rdkit. org. Google Scholar There is no corresponding record for this reference, 3(8), 2016.
[55] Nicholas A Meanwell. The influence of bioisosteres in drug design: tactical applications to address developability problems. Tactics in Contemporary Drug Design, pages 283-381, 2015.
[56] Carmen Limban, Diana C Nuță, Cornel Chiriță, Simona Negres, Andreea L Arsene, Marina Goumenou, Spyros P Karakitsios, Aristidis M Tsatsakis, and Dimosthenis A Sarigiannis. The use of structural alerts to avoid the toxicity of pharmaceuticals. Toxicology reports, 5:943-953, 2018.
[57] Debra L Peterson and Samuel H Yalkowsky. Comparison of two methods for predicting aqueous solubility. Journal of chemical information and computer sciences, 41(6):1531-1534, 2001.</p>
<p>[58] Murat Cihan Sorkun, Abhishek Khetan, and Süleyman Er. Aqsoldb, a curated reference set of aqueous solubility and 2d descriptors for a diverse set of compounds. Scientific data, 6(1):143, 2019.
[59] Sangho Lee, Hyunwoo Park, Chihyeon Choi, Wonjoon Kim, Ki Kang Kim, Young-Kyu Han, Joohoon Kang, Chang-Jong Kang, and Youngdoo Son. Multi-order graph attention network for water solubility prediction and interpretation. Scientific Reports, 13(1):957, 2023.
[60] Shuai Yuan, Zeren Jiao, Noor Quddus, Joseph Sang-II Kwon, and Chad V Mashuga. Developing quantitative structure-property relationship models to predict the upper flammability limit using machine learning. Industrial \&amp; Engineering Chemistry Research, 58(8):3531-3537, 2019.
[61] Sam Mannan. Chapter 8 - hazard identification. In Lees' Loss Prevention in the Process Industries (Fourth Edition), pages 204-283. Butterworth-Heinemann, Oxford, fourth edition edition, 2012.
[62] M Vidal, WJ Rogers, JC Holste, and MS Mannan. A review of estimation methods for flash points and flammability limits. Process safety progress, 23(1):47-55, 2004.
[63] Farhad Gharagheizi. Prediction of upper flammability limit percent of pure compounds from their molecular structures. Journal of Hazardous Materials, 167(1-3):507-510, 2009.
[64] Yong Pan, Juncheng Jiang, Rui Wang, Hongyin Cao, and Yi Cui. Prediction of the upper flammability limits of organic compounds from molecular structures. Industrial \&amp; engineering chemistry research, 48(10):5064-5069, 2009.
[65] Daniel A Crowl and Joseph F Louvar. Chemical process safety: fundamentals with applications. Pearson Education, 2001.
[66] Shuai Yuan, Zeren Jiao, Noor Quddus, Joseph Kwon, and Chad Mashuga. Developing quantitative structure-property relationship models to predict the upper flammability limit using machine learning. Industrial \&amp; Engineering Chemistry Research, 58, 022019.</p>
<h1>Appendix A: Textual Structure-function relationships</h1>
<h2>Case study 1: Presence of open metal sites in MOFs</h2>
<h2>XpertAI Explanation</h2>
<ul>
<li>The features identified by the XAI analysis affecting the Presence of open metal sites in MOFs are Fraction of Metals, Density of Solid, and Average Cationic Radius. Additional features that may be correlated with the Presence of open metal sites in MOFs include the fraction of electrons in d orbitals, the average ionization energy, and the average electron affinity (Guo et al., Not mentioned).</li>
<li>The Fraction of Metals feature indicates the proportion of metal atoms in the MOF structure. A higher fraction of metals may increase the likelihood of open metal sites, as metals often form the nodes of MOFs where open metal sites can occur. The Density of Solid feature refers to the mass per unit volume of the MOF. A higher density may suggest a more tightly packed structure, potentially reducing the likelihood of open metal sites. The Average Cationic Radius feature represents the average size of the metal cations in the MOF. Larger cations may lead to larger pores and potentially more open metal sites (Guo et al., Not mentioned).</li>
<li>The Presence of open metal sites in MOFs can be affected by these features in various ways. For instance, increasing the Fraction of Metals could potentially increase the number of open metal sites, assuming the additional metals form part of the MOF nodes. Similarly, decreasing the Density of Solid could potentially increase the number of open metal sites, as a less densely packed structure may have more available space for open metal sites. Increasing the Average Cationic Radius could also potentially increase the number of open metal sites, as larger cations may lead to larger pores and more open metal sites (Guo et al., Not mentioned).</li>
<li>In summary, the Presence of open metal sites in MOFs is influenced by various structural and chemical features of the MOFs, including the $&lt;$ Fraction of Metals $&gt;$, Density of Solid, and Average Cationic Radius. These features can affect the likelihood of open metal sites by influencing the structure and composition of the MOFs. Understanding these relationships can help in the rational design of MOFs with desired properties (Guo et al., Not mentioned).</li>
<li>References:</li>
<li>Guo, H., Ma, J., Zhong, Y., Yin, Y., \&amp; Chen, M. (Not mentioned). Machine learning prediction of open metal sites in metal-organic framework catalysts.</li>
</ul>
<h2>ChatGPT Explanation</h2>
<p>Metal-organic frameworks (MOFs) are a class of compounds consisting of metal ions or clusters coordinated to organic ligands to form one-, two-, or three-dimensional structures. The presence of open metal sites (OMS) in MOFs is a crucial factor that determines their properties and applications, especially in gas storage, separation, and catalysis.
The presence of OMS in MOFs can be altered by several factors:</p>
<ul>
<li>Choice of Metal Ions: The type of metal ions used in the synthesis of MOFs can influence the presence of OMS. Some metal ions have a higher tendency to form OMS due to their coordination preferences. For example, MOFs made with transition metals often have OMS because these metals typically have a higher coordination number.</li>
<li>Choice of Organic Ligands: The type and structure of the organic ligands used can also affect the presence of OMS. Ligands with larger sizes or more complex structures can create more space in the MOF structure, leading to the formation of OMS. Additionally, ligands that can form strong bonds with metal ions can stabilize the OMS.</li>
<li>
<p>Synthetic Conditions: The conditions under which the MOFs are synthesized, such as temperature, pressure, and solvent, can also influence the formation of OMS. For example, lower synthesis temperatures may favor the formation of OMS because they slow down the reaction rate, allowing for more control over the MOF structure.</p>
</li>
<li>
<p>Post-Synthetic Modifications: After the MOFs are synthesized, their structures can be further modified to create or remove OMS. This can be done through methods such as solvent exchange, thermal treatment, or chemical modification.</p>
</li>
<li>Use of Modulators: Modulators are additives used during the synthesis of MOFs to control their growth and structure. By choosing appropriate modulators, the presence of OMS can be controlled.</li>
</ul>
<p>In summary, the presence of open metal sites in metal-organic frameworks can be altered by manipulating the choice of metal ions and organic ligands, the synthetic conditions, post-synthetic modifications, and the use of modulators. These factors can be adjusted to tailor the properties of MOFs for specific applications.</p>
<h1>Case study 2: Pore-limiting diameter in MOFs</h1>
<h2>XpertAI Explanation</h2>
<ul>
<li>The features identified by the XAI analysis that affect the Pore-limiting diameter in MOFs are Volume Per Atom, symmetry function G, and Unoccupied Energy Levels at Conduction Band Minimum. Other features that may be correlated with the Pore-limiting diameter in MOFs include the type of metal center, the type of ligand, and the topology of the MOF structure.</li>
<li>The Volume Per Atom can affect the Pore-limiting diameter in MOFs as it determines the size of the atoms in the MOF structure. Larger atoms may result in smaller pore sizes (Haldoupis, Nair, \&amp; Sholl, 2010). The symmetry function G is a measure of the symmetry of the MOF structure, which can also influence the Pore-limiting diameter. MOFs with higher symmetry may have more uniform pore sizes (Yang et al., 2022). The Unoccupied Energy Levels at Conduction Band Minimum can affect the electronic properties of the MOF, which may indirectly influence the Pore-limiting diameter.</li>
<li>The Pore-limiting diameter in MOFs can be altered by changing these features. For example, using smaller atoms or increasing the symmetry of the MOF structure can increase the Pore-limiting diameter. Similarly, altering the electronic properties of the MOF by changing the Unoccupied Energy Levels at Conduction Band Minimum may also affect the Pore-limiting diameter.</li>
<li>In summary, the Pore-limiting diameter in MOFs is influenced by several features including the Volume Per Atom, symmetry function G, and Unoccupied Energy Levels at Conduction Band Minimum. These features can be manipulated to alter the Pore-limiting diameter, which can have significant implications for the performance of MOFs in various applications.</li>
<li>References:</li>
<li>Haldoupis, E., Nair, S., \&amp; Sholl, D. S. (2010). Efficient calculation of diffusion limitations in metal organic framework materials: A tool for identifying materials for kinetic separations. Journal of the American Chemical Society, 132(21), 7528-7539.</li>
<li>Yang, P., Lu, G., Yang, Q., Liu, L., Lai, X., \&amp; Yu, D. (2022). Machine learning prediction of acetylene adsorption capacity in metal-organic frameworks. Journal of Physical Chemistry C, 126(4), 2159-2169.</li>
</ul>
<h2>ChatGPT Explanation</h2>
<ul>
<li>Metal-Organic Frameworks (MOFs) are porous materials that are constructed from metal ions or clusters and organic linkers. The pore limiting diameter in MOFs refers to the smallest diameter of the pores within the framework. This property is crucial as it determines the type and size of molecules that can be adsorbed or transported through the MOF.</li>
<li>The pore limiting diameter in MOFs can be altered by changing the size and shape of the organic linkers and the metal ions or clusters. The organic linkers act as spacers between the metal ions or clusters, and their length, flexibility, and geometry can significantly influence the pore size. For instance, using longer linkers or linkers with larger functional</li>
</ul>
<p>groups can increase the pore size. Similarly, the choice of metal ions or clusters can also affect the pore size. Larger metal ions or clusters can lead to larger pores.</p>
<ul>
<li>In addition, the pore limiting diameter can also be tuned by varying the synthesis conditions, such as temperature, pressure, and solvent. These conditions can influence the assembly of the metal ions or clusters and the organic linkers, thereby affecting the pore size.</li>
<li>Furthermore, post-synthetic modifications, such as the insertion of additional organic or inorganic species into the pores, can also be used to adjust the pore limiting diameter. These modifications can either increase or decrease the pore size, depending on the size and shape of the inserted species.</li>
<li>In summary, the pore limiting diameter in MOFs is a tunable property that can be controlled by carefully selecting the organic linkers and metal ions or clusters, adjusting the synthesis conditions, and performing post-synthetic modifications.</li>
</ul>
<h1>Case study 3: Toxicity of small drug-like molecules</h1>
<h2>XpertAI Explanation</h2>
<ul>
<li>The features identified by the XAI analysis that affect the toxicity of small molecules include the presence of a heteroatom bonded to three Oxygen atoms, the presence of an aminomethyl group, and the presence of a Tertiary Amine. Additional features that may be correlated with the toxicity of small molecules include the solubility of the molecule, the presence of aromatic rings, and the presence of nucleophilic $\mathrm{N}, \mathrm{O}$, and aryl containing substructures (Sharma et al., 2017; Sharma et al., 2023).</li>
<li>The presence of a heteroatom bonded to three Oxygen atoms can increase the reactivity of the molecule, potentially leading to increased toxicity. The aminomethyl group and the Tertiary Amine can also increase the reactivity of the molecule, potentially leading to increased toxicity (Kalgutkar et al., 2005). The solubility of the molecule can affect its absorption, with molecules with poor solubility showing limited absorption and hence reduced toxicity (Sharma et al., 2017). The presence of aromatic rings and nucleophilic $\mathrm{N}, \mathrm{O}$, and aryl containing substructures can also influence the toxicity of the molecule (Sharma et al., 2023).</li>
<li>The toxicity of small molecules can be altered by changing these features. For example, the toxicity of a molecule can be reduced by decreasing the number of Oxygen atoms bonded to a heteroatom, by removing the aminomethyl group or the Tertiary Amine, or by reducing the solubility of the molecule (Sharma et al., 2017; Kalgutkar et al., 2005).</li>
<li>In summary, the toxicity of small molecules is influenced by several features, including the presence of a heteroatom bonded to three Oxygen atoms, the presence of an aminomethyl group, the presence of a Tertiary Amine, the solubility of the molecule, the presence of aromatic rings, and the presence of nucleophilic $\mathrm{N}, \mathrm{O}$, and aryl containing substructures. Changes in these features can alter the toxicity of the molecule.</li>
<li>References:</li>
<li>Sharma, B., Chenthamarakshan, V., Dhurandhar, A., Pereira, S., Hendler, J. A., Dordick, J. S., \&amp; Das, P. (2023). Deep learning framework for toxicity prediction.</li>
<li>Sharma, A. K., Srivastava, G. N., Roy, A., \&amp; Sharma, V. K. (2017). Toxicity prediction tool for small molecules. Frontiers in Pharmacology, 8, Article 880.</li>
<li>Kalgutkar, A. S., Shaffer, C. L., Henne, K. R., \&amp; Mutlib, A. (2005). Bioactivation pathways of functional groups/structural motifs used in drug design. Current Drug Metabolism, 6(3), 161-185.</li>
</ul>
<h2>ChatGPT Explanation</h2>
<p>Toxicity in small molecules is determined by their chemical structure and properties. These properties include size, shape, charge, polarity, and the presence of specific functional groups. Altering these properties can change the toxicity of the molecule.</p>
<ul>
<li>Size and Shape: The size and shape of a molecule can affect its ability to interact with biological systems. Larger molecules may have difficulty penetrating cell membranes, reducing their toxicity. Conversely, smaller molecules may easily enter cells and interact with critical components, increasing their toxicity. Changing the size or shape of a molecule can therefore alter its toxicity.</li>
<li>Charge: The charge of a molecule can also affect its toxicity. Positively charged molecules can interact with negatively charged cell membranes, potentially disrupting their function and increasing toxicity. Conversely, negatively charged molecules may be repelled by the cell membrane, reducing their toxicity. Altering the charge of a molecule can therefore change its toxicity.</li>
<li>Polarity: The polarity of a molecule can affect its solubility in water and other solvents. Polar molecules are more soluble in water, which can increase their bioavailability and therefore their potential toxicity. Non-polar molecules are less soluble in water, which can reduce their bioavailability and therefore their toxicity. Changing the polarity of a molecule can therefore alter its toxicity.</li>
<li>Functional Groups: The presence of specific functional groups can also affect a molecule's toxicity. For example, molecules with hydroxyl (-OH) groups can form hydrogen bonds with biological molecules, potentially disrupting their function and increasing toxicity. Conversely, molecules with methyl (-CH3) groups are less likely to form such bonds, reducing their toxicity. Altering the functional groups present in a molecule can therefore change its toxicity.</li>
<li>Metabolic Stability: The metabolic stability of a molecule can also influence its toxicity. Molecules that are rapidly metabolized and excreted from the body are generally less toxic, while those that persist in the body can accumulate and cause toxicity. Changing the metabolic stability of a molecule can therefore alter its toxicity.</li>
</ul>
<p>In conclusion, the toxicity of small molecules can be altered by changing their size, shape, charge, polarity, functional groups, and metabolic stability. These changes can be made through chemical synthesis or modification.</p>
<h1>Case study 4: Solubility of small molecules</h1>
<h2>XpertAI Explanation</h2>
<ul>
<li>The solubility of small molecules is a complex property that is influenced by a variety of factors. The XAI analysis has identified three key features that significantly impact the solubility of small molecules: the presence of an atom at an aromatic/non-aromatic boundary, the presence of two heteroatoms bonded to each other, and the presence of an atom with three heteroatom neighbors.</li>
<li>Presence of an atom at an aromatic/non-aromatic boundary: This feature refers to the location of an atom at the boundary between an aromatic ring and a non-aromatic part of the molecule. Aromatic rings are typically hydrophobic, while non-aromatic parts of the molecule can be either hydrophilic or hydrophobic. Therefore, an atom at this boundary can influence the overall solubility of the molecule by affecting its polarity and ability to form hydrogen bonds with water molecules (Lee et al., 2023). Presence of two heteroatoms bonded to each other: Heteroatoms are atoms other than carbon and hydrogen. When two heteroatoms are bonded to each other, they can form polar bonds, which can increase the solubility of the molecule in water. This is because polar molecules are more likely to dissolve in polar solvents like water (Zhang et al., 2011). Presence of an atom with three heteroatom neighbors: An atom with three heteroatom neighbors is likely to be part of a polar functional group, which can increase the solubility of the molecule in water. This is because polar functional groups can form hydrogen bonds with water molecules, which facilitates dissolution (Cisneros et al., 2016).</li>
<li>
<p>In conclusion, the solubility of small molecules is significantly influenced by the presence of an atom at an aromatic/non-aromatic boundary, the presence of two heteroatoms bonded to each other, and the presence of an atom with three heteroatom neighbors. By manipulating these features, it may be possible to alter the solubility of small molecules, which could have important implications for drug design and other applications.</p>
</li>
<li>
<p>References:</p>
</li>
<li>Lee, S., Park, H., Choi, C., Kim, W., Kim, K. K., Han, Y. K., Kang, J., Kang, C. J., \&amp; Son, Y. (2023). Multi-order graph attention network for water solubility prediction. Scientific Reports, 13, 957.</li>
<li>Zhang, L., Zhu, H., Mathiowetz, A. M., \&amp; Gao, H. (2011). Matched molecular pair analysis of changes in the free energy of binding, solubility, and lipophilicity in the course of lead optimization. Journal of Medicinal Chemistry, 54(13), 4325-4336.</li>
<li>Cisneros, J. A., Robertson, M. J., Mercado, B. Q., \&amp; Jorgensen, W. L. (2016). Systematic study of effects of structural modifications on the aqueous solubility of drug-like molecules. Journal of Medicinal Chemistry, 59(3), 1090-1097.</li>
</ul>
<h1>ChatGPT Explanation</h1>
<p>Solubility in small molecules can be altered by changing the molecular properties of the substance. This is based on the principle "like dissolves like", which means that polar substances tend to dissolve in polar solvents, and nonpolar substances tend to dissolve in nonpolar solvents.</p>
<ul>
<li>Polarity: The polarity of a molecule can greatly affect its solubility. Polar molecules have a positive and negative end, which allows them to interact with other polar molecules and dissolve in polar solvents like water. Nonpolar molecules, on the other hand, do not have a charge and therefore do not interact with polar molecules, making them insoluble in polar solvents.</li>
<li>Size: The size of the molecule can also affect its solubility. Smaller molecules are generally more soluble than larger ones because they can more easily interact with the solvent molecules.</li>
<li>Shape: The shape of a molecule can affect its solubility. Linear molecules, for example, can pack closely together and are therefore more soluble in nonpolar solvents. Branched or spherical molecules, on the other hand, cannot pack as closely and are therefore more soluble in polar solvents.</li>
<li>Functional Groups: The presence of certain functional groups can also affect a molecule's solubility. For example, molecules with hydroxyl (-OH) or amino (-NH2) groups are more soluble in water because these groups can form hydrogen bonds with water molecules.</li>
<li>Temperature and Pressure: The solubility of a substance can also be affected by changes in temperature and pressure. Generally, solubility increases with increasing temperature and decreases with increasing pressure.</li>
</ul>
<p>By manipulating these properties, scientists can alter the solubility of a substance in small molecules. This is particularly useful in fields like pharmaceuticals, where the solubility of a drug can greatly affect its effectiveness.</p>
<h2>Case study 5: Upper flammability limit of organic molecules</h2>
<h2>XpertAI Explanation</h2>
<ul>
<li>The features identified by the XAI analysis that affect the upper flammability limit of organic molecules are Structural Information Content Index (Neighborhood Symmetry of Order Zero), Information Content Index (Neighborhood Symmetry of Order Zero), the highest occupied molecular orbital (HOMO), and Dipole Moment. Additional features that may be correlated with the upper flammability limit of organic molecules could include molecular weight, number of carbon atoms, and the presence of specific functional groups.</li>
<li>The Structural Information Content Index (Neighborhood Symmetry of Order Zero) and Information Content Index (Neighborhood Symmetry of Order Zero) are measures of the complexity and symmetry of the molecule's structure. Molecules with higher complexity and less symmetry may have higher upper flammability limits due to the increased number of potential reaction pathways (Yuan et al., 2019). The highest occupied molecular orbital (HOMO) represents the energy level of the highest energy electron in the molecule.</li>
</ul>
<p>Molecules with higher HOMO energy levels may have higher upper flammability limits because they have more energy available for combustion reactions (Yuan et al., 2019). The Dipole Moment is a measure of the molecule's polarity. Molecules with higher dipole moments may have lower upper flammability limits because the increased polarity can inhibit the dispersion of the molecule in the air, reducing the likelihood of combustion (Yuan et al., 2019).</p>
<ul>
<li>By altering these features, such as by adding functional groups to increase the complexity of the molecule or by changing the molecule's structure to alter its dipole moment, it may be possible to influence the upper flammability limit of the molecule.</li>
<li>In summary, the upper flammability limit of organic molecules is influenced by a variety of features, including the complexity and symmetry of the molecule's structure, the energy level of the highest energy electron, and the molecule's polarity. By understanding these relationships, it may be possible to predict and potentially control the flammability of organic compounds.</li>
<li>References:</li>
<li>Yuan, S., Jiao, Z., Quddus, N., Kwon, J. S., \&amp; Mashuga, C. V. (2019). Developing Quantitative Structure-Property Relationship Models To Predict the Upper Flammability Limit Using Machine Learning. Industrial \&amp; Engineering Chemistry Research, 58(12), 4905-4913.</li>
</ul>
<h1>ChatGPT Explanation</h1>
<p>The upper flammability limit (UFL) of an organic molecule is the highest concentration (in terms of percentage volume in air) at which the molecule can ignite or explode. It is a critical property for safety considerations in various industries, especially those dealing with volatile organic compounds. The UFL can be influenced by several molecular properties, including molecular structure, functional groups, and molecular weight.</p>
<ul>
<li>Molecular Structure: The structure of a molecule can significantly affect its flammability. For instance, molecules with a high degree of branching tend to have lower flammability limits due to the increased steric hindrance that prevents effective collisions with oxygen molecules. Similarly, cyclic or aromatic structures tend to have higher flammability limits due to their stability and the ease with which they can undergo combustion reactions.</li>
<li>Functional Groups: The presence and type of functional groups in a molecule can also influence its flammability. For example, molecules with oxygen-containing functional groups (like alcohols, ethers, and esters) generally have lower flammability limits due to the presence of oxygen, which can facilitate combustion. On the other hand, molecules with halogen-containing functional groups (like chlorides, bromides, and iodides) usually have higher flammability limits because halogens act as flame retardants.</li>
<li>Molecular Weight: The molecular weight of an organic molecule can also affect its flammability. Generally, as the molecular weight increases, the flammability limit decreases. This is because heavier molecules have lower vapor pressures and require higher temperatures to achieve the necessary vapor concentration for ignition.</li>
<li>Other Factors: Other factors like temperature, pressure, and the presence of inert gases can also alter the upper flammability limit. Higher temperatures and pressures generally increase the flammability limit, while the presence of inert gases can decrease it by diluting the fuel-air mixture.</li>
</ul>
<p>In conclusion, by altering these molecular properties, one can influence the upper flammability limit of organic molecules. This understanding is crucial in designing safer chemical processes and materials.</p>
<h1>Appendix B: Claude Evaluations</h1>
<p>Please note that we used the question prompt given below to get ratings from https://claude. ai/. Explanation A: from XpertAI and Explanation B: from ChatGPT.</p>
<h2>Question prompt:</h2>
<p>Compare Explanations A and B and give a score based on its interpretability and accuracy. Describe the reasons for your score.</p>
<h2>Case study 1: Presence of open metal sites in MOFs</h2>
<p>Based on my analysis, I would rate Explanation A as more accurate and interpretable compared to Explanation B.</p>
<p>Reasons for my assessment:</p>
<ul>
<li>Explanation A provides more details on the specific features that impact the presence of open metal sites in MOFs. It lists out the top features identified by XAI analysis ('Metals Fraction', 'Density of Solid', 'Average Cationic Radius') and also mentions other correlated features ('Surface Area', 'Pore Volume', 'Functional Group'). In contrast, Explanation B only broadly refers to choice of metal ions, organic ligands, synthetic conditions etc.</li>
<li>Explanation A clearly explains the reasons behind why each feature affects open metal sites in MOFs. For example, it states that a higher metals fraction leads to more open sites because the metal ions create the open sites. Explanation B does not provide these mechanistic insights. Explanation A links the features to the composition and structure of MOFs. It explains how manipulating the features can alter the number and distribution of open metal sites by influencing the MOF structure. Explanation B lacks these connections.</li>
<li>Explanation A provides specific recommendations for further study with relevant references. This demonstrates interpretability by enabling further research. Explanation B does not have these recommendations.</li>
<li>The language and terminology used in Explanation A is more accessible and easier to understand for a non-expert compared to Explanation B.</li>
</ul>
<p>In summary, I would give Explanation A a higher score for accuracy and interpretability due to its detailed feature analysis, clear mechanistic explanations, structural insights, recommendations for further research, and accessible terminology. Explanation B covers the topic more broadly but lacks in-depth analysis and connections</p>
<h2>Case study 2: Pore limiting diameter in MOFs</h2>
<p>Based on my analysis, I would rate Explanation A as more accurate and interpretable compared to Explanation B. Here are the key reasons:</p>
<ul>
<li>Explanation A provides more specific details on the features that impact pore limiting diameter, including both the top features from XAI analysis and other correlated features. Explanation B only broadly refers to organic linkers, metal ions, and synthesis conditions.</li>
<li>Explanation A clearly explains the quantitative relationships between each feature and pore limiting diameter (directly proportional, inversely proportional). This level of mechanistic detail is not present in Explanation B.</li>
<li>Explanation A breaks down exactly how each feature impacts pore limiting diameter through their effects on MOF structure and properties. Explanation B lacks this level of structural analysis.</li>
<li>
<p>Explanation A states how pore limiting diameter can be altered by changing each feature in the desired direction. Explanation B only generally mentions that the features can be changed but not how.</p>
</li>
<li>
<p>Explanation A provides specific recommendations for further reading. This enhances interpretability. Explanation B does not have any recommendations.</p>
</li>
<li>The terminology used in Explanation A is more accessible to a non-expert audience compared to Explanation B.</li>
</ul>
<p>In summary, Explanation A demonstrates greater accuracy through its quantitative relationships, mechanistic insights, and specific recommendations. It also shows higher interpretability through its detailed feature analysis, structural explanations, and clear language. I would thus give Explanation A a higher score compared to Explanation B in both accuracy and interpretability.</p>
<h1>Case study 3: Toxicity of small molecules</h1>
<p>Based on my analysis, I would rate Explanation A as more accurate and interpretable compared to Explanation B.</p>
<p>Here are the key reasons:</p>
<ul>
<li>Explanation A identifies specific features from XAI analysis and literature that impact toxicity, while Explanation B only broadly refers to size, shape, charge, etc.</li>
<li>Explanation A provides mechanistic explanations for how each feature impacts toxicity through reactivity and formation of reactive species. Explanation B lacks this level of mechanistic detail.</li>
<li>Explanation A states how toxicity can be altered by adding/removing specific features. Explanation B only generally states toxicity can be changed by modifying features.</li>
<li>Explanation A uses more accessible language and defines key terms like "heteroatom" and "aminomethyl group". Explanation B uses more technical vocabulary without definitions.</li>
<li>Explanation A provides references for further study, enhancing interpretability. Explanation B does not include any references.</li>
<li>Explanation A demonstrates an understanding of the domain by linking features to reactivity and cellular damage. Explanation B lacks these connections to the biological effects of toxicity.</li>
</ul>
<p>In summary, Explanation A shows greater accuracy through its use of specific features from XAI analysis, detailed mechanistic explanations, and links to biological impacts. It also demonstrates higher interpretability through accessible language, definitions, and references. I would thus give Explanation A a higher score than Explanation B in both accuracy and interpretability.</p>
<h2>Case study 4: Solubility of small molecules</h2>
<p>Based on my analysis, I would rate Explanation A as more accurate and interpretable compared to Explanation B.</p>
<p>Here are the key reasons:</p>
<ul>
<li>Explanation A identifies specific features from XAI analysis and literature that impact solubility, while Explanation B refers broadly to polarity, size, shape, etc.</li>
<li>Explanation A provides mechanistic explanations for how each feature affects solubility through interactions with water. Explanation B does not provide this level of mechanistic insight.</li>
<li>Explanation A demonstrates domain knowledge by linking features to concepts like hydrophobicity, electronegativity, and hydrogen bonding. Explanation B lacks these connections.</li>
<li>Explanation A states how solubility can be altered by manipulating specific features. Explanation B only generally states that properties can be changed.</li>
<li>
<p>"Explanation A uses more accessible language and defines terms like "heteroatom" and "aromatic region". Explanation B uses more technical vocabulary.</p>
</li>
<li>
<p>Explanation A provides sources for further study, enhancing interpretability. Explanation B does not have references.</p>
</li>
</ul>
<p>In summary, Explanation A exhibits greater accuracy through its use of specific features, detailed mechanistic explanations, and connections to chemistry concepts. It also shows higher interpretability through its accessible language, definitions, and references. I would thus give Explanation A, a higher score than Explanation B in both accuracy and interpretability.</p>
<h1>Case study 5: Upper flammability of organic molecules</h1>
<p>Based on my analysis, I would rate Explanation B as more accurate and interpretable compared to Explanation A.</p>
<p>Here are the key reasons:</p>
<ul>
<li>Explanation B identifies specific molecular features like structure, functional groups, and molecular weight that impact upper flammability limit. Explanation A refers broadly to physicochemical properties without clear examples.</li>
<li>Explanation B provides clear mechanistic explanations for how each feature affects flammability through combustion kinetics and thermodynamics. Explanation A lacks this level of mechanistic detail.</li>
<li>Explanation B demonstrates strong domain knowledge by linking features to concepts like vapor pressure, steric hindrance, and flame retardants. Explanation A does not connect to these chemistry concepts.</li>
<li>Explanation B states how upper flammability limit can be altered by modifying specific molecular features. Explanation A only generically mentions "changing these features".</li>
<li>Explanation B uses more common terminology that is accessible to a non-expert audience. Explanation A uses highly technical vocabulary without definitions.</li>
<li>Explanation B contextualizes the explanation in terms of safety considerations and chemical process design. Explanation A lacks this contextual framing.</li>
</ul>
<p>In summary, Explanation B exhibits greater accuracy through its use of precise molecular features, detailed mechanistic explanations, and connections to core chemistry concepts. It also demonstrates higher interpretability through its accessible language, contextual framing, and clear statements on how to alter upper flammability limit. I would thus give Explanation B a higher score than Explanation A on both accuracy and interpretability.</p>
<h1>Appendix C: Evaluation Keys</h1>
<p>Expert evaluators were asked to rate 2 textual explanations (from XpertAI, ChatGPT) and 1 visual explanation (SHAP plot) based on the following keys.</p>
<h2>Expert score:</h2>
<ul>
<li>What can you say about the accuracy of the explanation to the best of your knowledge?
$\square$ Not accurate
$\square$ Somewhat accurate
$\square$ Accurate
$\square$ Cannot comment</li>
<li>Select all that apply
$\square$ Explanation is easy to comprehend
$\square$ Cannot comprehend the explanation without more information
$\square$ Provides scientific justifications from literature
$\square$ Explanation is specific to a given task/dataset
$\square$ Explanation is broad
$\square$ Non-ML/XAI users can this explanation to describe structure-property relationships
$\square$ Non-ML/XAI users cannot this explanation to describe structure-property relationships</li>
</ul>            </div>
        </div>

    </div>
</body>
</html>