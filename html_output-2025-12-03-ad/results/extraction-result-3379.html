<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3379 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3379</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3379</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-79.html">extraction-schema-79</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <p><strong>Paper ID:</strong> paper-269501995</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.00972v1.pdf" target="_blank">CACTUS: Chemistry Agent Connecting Tool Usage to Science</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have shown remarkable potential in various domains but often lack the ability to access and reason over domain-specific knowledge and tools. In this article, we introduce Chemistry Agent Connecting Tool-Usage to Science (CACTUS), an LLM-based agent that integrates existing cheminformatics tools to enable accurate and advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama3-8b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b, Mistral-7b, and Llama3-8b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without a significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with widely used domain-specific tools provided by RDKit, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3379.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3379.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CACTUS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chemistry Agent Connecting Tool-Usage to Science</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source tool-augmented LLM agent (implemented in LangChain) that composes LLM reasoning with cheminformatics tools (RDKit, PubChem, ChEMBL, ZINC) to answer chemistry questions, compute molecular descriptors, perform similarity searches, and (in future) assist de novo molecular design and experiment prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CACTUS agent (uses multiple open-source LLMs including Gemma-7b, Mistral-7b, Falcon-7b, MPT-7b, Llama2-7b, Phi2, OLMo-1b)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>CACTUS is an agent framework (LangChain MRKL/zero-shot ReAct agent) that orchestrates external LLMs (7B and smaller open-source models) with a suite of cheminformatics tools (RDKit wrappers, PubChem/ChEMBL/ZINC interfaces). The paper reports experiments with 7B-class models (Gemma-7b, Mistral-7b, Falcon-7b, MPT-7b, Llama2-7b) and smaller models (Phi2 ~2.7B, OLMo-1b). Models were used as-is (no reported chemical-domain fine-tuning) and prompted with either a minimal or a domain-aligned prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not used in this paper to generate novel molecules; CACTUS currently uses LLMs to select and run cheminformatics tools on user-provided SMILES (tool orchestration). The paper states future plans to integrate generative/physics-based molecular models (e.g., 3D-scaffold, reinforcement learning, graph neural networks) to enable de novo design, fragment identification, and scaffold-based generation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Proposed: de novo drug design, molecular discovery, prioritization of experiments, catalysts and materials design; Actual experiments in paper: molecular property prediction, similarity searching, and drug-likeness / ADME estimation (i.e., cheminformatics question-answering).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>For the agent benchmark used in this work: accuracy on a 1000-question cheminformatics benchmark (500 qualitative, 500 quantitative; combined 1000), runtime/inference time on different GPUs. For prospective generative functionality (not performed here) no generation-specific metrics are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>This work did not report generation of novel chemicals. Instead CACTUS was benchmarked on 1000 cheminformatics QA tasks; it 'significantly outperforms baseline LLMs' on those tasks, with Gemma-7b and Mistral-7b achieving the highest accuracy across prompting strategies. The paper demonstrates tool orchestration, domain-prompt benefits, and viable deployment on consumer GPUs, but contains no experimental results of de novo molecule generation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>Comparison is to baseline LLMs answering the same QA tasks (minimal vs domain prompt). For the cheminformatics QA benchmark CACTUS (with tool usage) outperformed baseline LLM-only responses; Gemma-7b and Mistral-7b were top performers. No comparison to specialized molecule-generative models is reported because no generation experiments were performed.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>The paper explicitly notes that CACTUS has not yet been used to perform de novo molecule generation in reported experiments. Reported challenges include prompt engineering sensitivity (models require model-specific prompt tuning), slow local inference on CPU (mitigated via vLLM), variability across LLMs and prompts, and the need to integrate physics-based generative models and symbolic reasoning for explainability and reliable design. Safety, synthesizability, and evaluation of generated molecules are discussed as future work rather than addressed in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CACTUS: Chemistry Agent Connecting Tool Usage to Science', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3379.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3379.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow: Augmenting large-language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-assisted chemistry synthesis planner cited as inspiration; it augments LLM reasoning with chemistry-specific tools to plan chemical syntheses and assist chemists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chemcrow: Augmenting large-language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemCrow (LLM-assisted synthesis planner)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in cited work as an LLM-augmented system combining large language models with chemistry tools to plan and propose synthetic routes; CACTUS authors cite ChemCrow as inspiration for tool-augmented chemistry agents.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Synthesis planning / tool-augmented LLM actions (planner rather than explicit molecule generative model) as described by the cited work. In this paper ChemCrow is only referenced; no implementation details or new experiments provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Synthesis planning and chemistry automation (drug discovery/chemical synthesis workflows).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Mentioned only as prior work/inspiration; this paper does not report ChemCrow's limitations or results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CACTUS: Chemistry Agent Connecting Tool Usage to Science', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3379.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3379.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>3D-scaffold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>3D-scaffold: A deep learning framework to generate 3D coordinates of drug-like molecules with desired scaffolds</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced deep-learning method that generates 3D molecular coordinates consistent with a user-specified scaffold; cited as an example of physics-based molecular generative models that CACTUS plans to integrate.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>3d-scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>3D-scaffold</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Cited as a deep learning framework capable of producing 3D coordinates for drug-like molecules conditioned on scaffolds (reference only; no implementation or benchmarking of 3D-scaffold is presented in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Scaffold-conditioned 3D coordinate generation (deep learning). This is described as planned integration to enable de novo molecular generation in CACTUS in future work.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>De novo molecular design for drug-like molecules; improving 3D-aware generation and downstream property prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Only cited as future integration; no experimental details, performance, or limitations are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CACTUS: Chemistry Agent Connecting Tool Usage to Science', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chemcrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>3d-scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds. <em>(Rating: 2)</em></li>
                <li>De novo design of protein target specific scaffold-based Inhibitors via Reinforcement Learning <em>(Rating: 2)</em></li>
                <li>Ai-accelerated design of targeted covalent inhibitors for sars-cov-2 <em>(Rating: 2)</em></li>
                <li>Gentopia <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3379",
    "paper_id": "paper-269501995",
    "extraction_schema_id": "extraction-schema-79",
    "extracted_data": [
        {
            "name_short": "CACTUS",
            "name_full": "Chemistry Agent Connecting Tool-Usage to Science",
            "brief_description": "An open-source tool-augmented LLM agent (implemented in LangChain) that composes LLM reasoning with cheminformatics tools (RDKit, PubChem, ChEMBL, ZINC) to answer chemistry questions, compute molecular descriptors, perform similarity searches, and (in future) assist de novo molecular design and experiment prioritization.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "CACTUS agent (uses multiple open-source LLMs including Gemma-7b, Mistral-7b, Falcon-7b, MPT-7b, Llama2-7b, Phi2, OLMo-1b)",
            "model_description": "CACTUS is an agent framework (LangChain MRKL/zero-shot ReAct agent) that orchestrates external LLMs (7B and smaller open-source models) with a suite of cheminformatics tools (RDKit wrappers, PubChem/ChEMBL/ZINC interfaces). The paper reports experiments with 7B-class models (Gemma-7b, Mistral-7b, Falcon-7b, MPT-7b, Llama2-7b) and smaller models (Phi2 ~2.7B, OLMo-1b). Models were used as-is (no reported chemical-domain fine-tuning) and prompted with either a minimal or a domain-aligned prompt.",
            "generation_method": "Not used in this paper to generate novel molecules; CACTUS currently uses LLMs to select and run cheminformatics tools on user-provided SMILES (tool orchestration). The paper states future plans to integrate generative/physics-based molecular models (e.g., 3D-scaffold, reinforcement learning, graph neural networks) to enable de novo design, fragment identification, and scaffold-based generation.",
            "application_domain": "Proposed: de novo drug design, molecular discovery, prioritization of experiments, catalysts and materials design; Actual experiments in paper: molecular property prediction, similarity searching, and drug-likeness / ADME estimation (i.e., cheminformatics question-answering).",
            "evaluation_metrics": "For the agent benchmark used in this work: accuracy on a 1000-question cheminformatics benchmark (500 qualitative, 500 quantitative; combined 1000), runtime/inference time on different GPUs. For prospective generative functionality (not performed here) no generation-specific metrics are reported in this paper.",
            "results_summary": "This work did not report generation of novel chemicals. Instead CACTUS was benchmarked on 1000 cheminformatics QA tasks; it 'significantly outperforms baseline LLMs' on those tasks, with Gemma-7b and Mistral-7b achieving the highest accuracy across prompting strategies. The paper demonstrates tool orchestration, domain-prompt benefits, and viable deployment on consumer GPUs, but contains no experimental results of de novo molecule generation.",
            "comparison_to_baselines": "Comparison is to baseline LLMs answering the same QA tasks (minimal vs domain prompt). For the cheminformatics QA benchmark CACTUS (with tool usage) outperformed baseline LLM-only responses; Gemma-7b and Mistral-7b were top performers. No comparison to specialized molecule-generative models is reported because no generation experiments were performed.",
            "limitations_challenges": "The paper explicitly notes that CACTUS has not yet been used to perform de novo molecule generation in reported experiments. Reported challenges include prompt engineering sensitivity (models require model-specific prompt tuning), slow local inference on CPU (mitigated via vLLM), variability across LLMs and prompts, and the need to integrate physics-based generative models and symbolic reasoning for explainability and reliable design. Safety, synthesizability, and evaluation of generated molecules are discussed as future work rather than addressed in experiments.",
            "uuid": "e3379.0",
            "source_info": {
                "paper_title": "CACTUS: Chemistry Agent Connecting Tool Usage to Science",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow: Augmenting large-language models with chemistry tools",
            "brief_description": "An LLM-assisted chemistry synthesis planner cited as inspiration; it augments LLM reasoning with chemistry-specific tools to plan chemical syntheses and assist chemists.",
            "citation_title": "Chemcrow: Augmenting large-language models with chemistry tools",
            "mention_or_use": "mention",
            "model_name": "ChemCrow (LLM-assisted synthesis planner)",
            "model_description": "Described in cited work as an LLM-augmented system combining large language models with chemistry tools to plan and propose synthetic routes; CACTUS authors cite ChemCrow as inspiration for tool-augmented chemistry agents.",
            "generation_method": "Synthesis planning / tool-augmented LLM actions (planner rather than explicit molecule generative model) as described by the cited work. In this paper ChemCrow is only referenced; no implementation details or new experiments provided here.",
            "application_domain": "Synthesis planning and chemistry automation (drug discovery/chemical synthesis workflows).",
            "evaluation_metrics": null,
            "results_summary": null,
            "comparison_to_baselines": null,
            "limitations_challenges": "Mentioned only as prior work/inspiration; this paper does not report ChemCrow's limitations or results.",
            "uuid": "e3379.1",
            "source_info": {
                "paper_title": "CACTUS: Chemistry Agent Connecting Tool Usage to Science",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "3D-scaffold",
            "name_full": "3D-scaffold: A deep learning framework to generate 3D coordinates of drug-like molecules with desired scaffolds",
            "brief_description": "A referenced deep-learning method that generates 3D molecular coordinates consistent with a user-specified scaffold; cited as an example of physics-based molecular generative models that CACTUS plans to integrate.",
            "citation_title": "3d-scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds.",
            "mention_or_use": "mention",
            "model_name": "3D-scaffold",
            "model_description": "Cited as a deep learning framework capable of producing 3D coordinates for drug-like molecules conditioned on scaffolds (reference only; no implementation or benchmarking of 3D-scaffold is presented in this paper).",
            "generation_method": "Scaffold-conditioned 3D coordinate generation (deep learning). This is described as planned integration to enable de novo molecular generation in CACTUS in future work.",
            "application_domain": "De novo molecular design for drug-like molecules; improving 3D-aware generation and downstream property prediction.",
            "evaluation_metrics": null,
            "results_summary": null,
            "comparison_to_baselines": null,
            "limitations_challenges": "Only cited as future integration; no experimental details, performance, or limitations are reported in this paper.",
            "uuid": "e3379.2",
            "source_info": {
                "paper_title": "CACTUS: Chemistry Agent Connecting Tool Usage to Science",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chemcrow: Augmenting large-language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "chemcrow_augmenting_largelanguage_models_with_chemistry_tools"
        },
        {
            "paper_title": "3d-scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds.",
            "rating": 2,
            "sanitized_title": "3dscaffold_a_deep_learning_framework_to_generate_3d_coordinates_of_druglike_molecules_with_desired_scaffolds"
        },
        {
            "paper_title": "De novo design of protein target specific scaffold-based Inhibitors via Reinforcement Learning",
            "rating": 2,
            "sanitized_title": "de_novo_design_of_protein_target_specific_scaffoldbased_inhibitors_via_reinforcement_learning"
        },
        {
            "paper_title": "Ai-accelerated design of targeted covalent inhibitors for sars-cov-2",
            "rating": 2,
            "sanitized_title": "aiaccelerated_design_of_targeted_covalent_inhibitors_for_sarscov2"
        },
        {
            "paper_title": "Gentopia",
            "rating": 1
        }
    ],
    "cost": 0.0106655,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CACTUS: CHEMISTRY AGENT CONNECTING TOOL-USAGE TO SCIENCE A PREPRINT
2 May 2024</p>
<p>Ramal 0000-0001-6713-2129
Carter R Knutson 0000-0002-1953-2272
Rohith A Varikoti 0000-0002-2355-1484
Neeraj Kumar neeraj.kumar@pnnl.gov 0000-0001-6713-2129</p>
<p>1 Pacific Northwest National Laboratory,
Richland, WA 99354</p>
<p>CACTUS: CHEMISTRY AGENT CONNECTING TOOL-USAGE TO SCIENCE A PREPRINT
2 May 2024F29F292303FDBC324AC30FE18CBEC2D5arXiv:2405.00972v1[cs.CL]LLMsTool-Augmented Language ModelMolecular DiscoveryDrug DesignCheminformaticsAutomated Molecular Design
Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools.In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery.We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions.Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used.Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy.By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment.Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery.By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials.Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.The agent can design and prioritize experiments, analyze results, and iteratively refine its hypotheses, leading to more efficient and targeted exploration of chemical space.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) are foundation models that are combined under a single paradigm to support various tasks or services.Despite being trained on vast corpora of data, these transformer-based LLMs have a limited understanding of the curated or parsed text.[Chiesurin et al., 2023].Current research has revealed the possibility of augmenting LLMs with tools that aid in efficiently solving various problems and tasks [Mialon et al., 2023, Xu et al., 2023, Qin et al., 2023].Previous work has also shown that providing specific prompts, curated towards a specific task, can enhance the time and quality of the text generated by the models [Cai et al., 2023].Combining these two approaches is the Tool Augmented Language Model (TALM) framework, detailed in Parisi et al. [2022], which outperforms existing models on the tasks it is configured for.However with any of these approaches, although the generated answers may appear correct, LLMs fail to reason or demonstrate subject knowledge as is typically demonstrated by humans [Huang et al., 2023, Kambhampati, 2024].Mistakes made by the model due to the statistical relationships it learned from data might appear in a similar way across different applications [Bommasani et al., 2021].If foundation models become integrated with important systems that leverage the foundation model's ability to quickly adapt to many different tasks and situations, failures could result in significantly unwanted outcomes.</p>
<p>The resourceful LLMs like GPT4 [OpenAI, 2023], LLaMA [Touvron et al., 2023], Gemma [Team et al., 2024], MPT [Team, 2023], Falcon [Almazrouei et al., 2023], and Mistral [Jiang et al., 2023] show improved performance over a range of activities [Chiang et al., 2024, Zheng et al., 2023, Hendrycks et al., 2020].Despite these strides, the inherent limitations of such models become apparent when faced with challenges that require access to dynamic, real-time, or confidential data, which remain inaccessible within their static training datasets.This gap underscores a critical need for LLMs to evolve beyond their current capacities, leveraging external APIs to fetch or interact with live data, thereby extending their utility in real-world applications [Parisi et al., 2022].In the domain-specific applications, particularly within the chemical, biological and material sciences, the limitations of LLMs are even more pronounced.The intricate nature of chemical data coupled with the dynamic landscape of drug discovery and development, presents a complex challenge that pure computational models alone cannot address effectively.Recognizing this, the integration of cheminformatics tools with the cognitive and analytical ability of LLMs offers a promising pathway.</p>
<p>At the forefront of this transformation are Intelligent Agents, autonomous entities capable of designing, planning, and executing complex chemistry-related tasks with exceptional efficiency and precision [Boiko et al., 2023].These systems are not only capable of utilizing a variety of LLMs for specific tasks but also adept at employing APIs and internet search tools to gather relevant material and data.For example, integrating an Agent into large, tool-based platforms such as KNIME [Berthold et al., 2007] or Galaxy [Goecks et al., 2010] could form a natural language interface between the user and their analysis.By acting as intermediaries, these Agents could significantly streamline the process of scientific discovery and autonomous experimentation with or without human in the loop.Towards that end and taking inspiration from ChemCrow [Bran et al., 2023], an LLM-assisted chemistry synthesis planner, we have developed an Intelligent Cheminformatics Agent focused on assisting scientists with de novo drug design and molecular discovery.Cheminformatics focuses on storing, retrieving, analyzing, and manipulating chemical data.It provides the framework and methodologies to connect computational linguistics with chemical science.This synergistic approach aims to leverage the strengths of both domains by facilitating a more comprehensive and effective exploration of therapeutic compounds, streamlining the drug development process, and ultimately accelerating the discovery from conceptualization to clinical application.In this work, we developed CACTUS (Chemistry Agent Connecting Tool Usage to Science) an LLM-powered agent that possesses the ability to intelligently determine the most suitable tools for a given task and the optimal sequence in which they should be applied, effectively optimizing workflows for chemical research and development.</p>
<p>The implications of these intelligent agents are far-reaching.They enable the autonomous operation of complex tasks from data analysis to experimental planning, hypothesis generation, testing, and push the boundaries of what can be achieved through computational chemistry.The synergistic relationship between human intelligence, artificial intelligence, and specialized software tools holds the potential to transform the landscape of drug discovery, catalysis, material science, and beyond.This relationship and combination of domains makes the molecular discovery process more efficient, accurate, and innovative.As we stand on the precipice of this new era in cheminformatics, the integration of LLMs and computational tools through intelligent agents like CACTUS promises to unlock a future where the limits of scientific discovery are bound only by the depths of our imagination.</p>
<p>Methods</p>
<p>Tool-augmented language models consist of two major components: external tools and language models.This section will discuss the approaches used to implement the language model agent and provide a focused look at the tools used.We will also go into great detail about the strategies used when prompting our agent and how we performed benchmarking.Each of these steps is a critical component of forming a complete intelligent agent able to solve a wide range of problems with the added ability of quick model swapping.</p>
<p>The Agent</p>
<p>An important consideration when building a TALM is the framework in which it will be implemented.We have selected the commonly used open-source platform, LangChain [Chase, 2022], for this purpose.This framework simplifies the integration of prompts with LLMs through a comprehensive set of pre-built Python modules known as "chains".It also provides convenient integration with popular LLM hosting/inference platforms such as the OpenAI API and HuggingFace Transformers [Wolf et al., 2020].CACTUS utilizes LangChain's implementation of a custom MRKL agent [Karpas et al., 2022] which can be broken into 3 parts: tools, LLMChain, and agent class.The tools in this instance are a collection of cheminformatics helper functions that wrap well-known Python libraries into well-described tools for an agent to use.These tools are explained in much more detail in Section 2.2.The LLMChain is a LangChain specific feature that helps chain the tools and the agent together.This is the prompt provided to the LLM when running any inference and helps to instantiate the model and parse the user input.In CACTUS, we provide a prompt that guides the agent to answer cheminformatics questions by describing the typical steps involved in answering such questions.The last requirement for CACTUS is the agent class.These are also LangChain implemented functions that are used to interpret the user input after the initial prompt and make decisions on which actions to take to best solve the question.CACTUS sticks with a general purpose implementation of the zero-shot agent class that uses the ReAct [Yao et al., 2022] framework to determine which tool to use from the tool's description.This combination of tools, LLMChain, and zero-shot agent makes CACTUS an extensible LLM tool that can quickly integrate new tools to solve a range of cheminformatics questions.</p>
<p>Here, we introduce mathematical formulation to describe the key components and processes of the CACTUS framework:</p>
<p>Let's consider T = t 1 , t 2 , . . ., t n the set of cheminformatics tools available to CACTUS as discussed above, where each tool t i is a function that takes an input x i and produces an output y i :
t i (x i ) = y i (1)
The LLMChain is represented as a function L that takes a user input u and a set of tools T as input, and outputs a sequence of actions A = a 1 , a 2 , . . ., a m :
L(u, T ) = A(2)
Each action a i in the sequence A corresponds to the application of a specific tool t j on an input x j , resulting in an output y j :
a i = t j (x j ) = y j(3)
The zero-shot agent class is modeled as a function Z that takes the user input u, the set of tools T , and the LLMChain output A as input, and produces a final output o:
Z(u, T, A) = o(4)
The This combination of cheminformatics tools, LLMChain, and zero-shot agent makes CACTUS an extensible LLM tool that can quickly integrate new tools to solve a range of cheminformatics questions.</p>
<p>Figure 1: General workflow of the CACTUS Agent that details how the LLM interprets an input to arrive at the correct tool to use to obtain an answer.Starting from the user input, CACTUS follows a standard "Chain-of-thought" reasoning method with a Planning, Action, Execution, and Observation phase to obtain an informed output</p>
<p>Cheminformatics Tools</p>
<p>For the purpose of creating a robust LLM agent able to answer a variety of cheminformatics questions, CACTUS includes a wide range of tools integrating common functions found in Python libraries such as RDKit [Landrum et al., 2013] and SciPy [Virtanen et al., 2020], along with interfaces to databases such as PubChem [Kim et al., 2023], ChEMBL [Davies et al., 2015], and ZINC [Irwin et al., 2020].These tools allow for a chat-based analysis of molecules starting with a SMILES string and ending with information such as molecular descriptors, similarity, or absorption, distribution, metabolism, and excretion (ADME) attributes.The model consists of ten different tools providing information on various descriptors for any given chemical compound used as input.Table 1 contains a list of currently available tools that can assist in obtaining different physio-chemical properties and molecular descriptors of the input chemical compounds.This includes molecular weight, log of the partition coefficient (LogP), topological polar surface area (TPSA), quantitative estimate of drug-likeness (QED), and synthetic accessibility (SA) of the input chemical compounds.Moreover, using the BOILED-Egg method, CACTUS can also estimate the pharmacokinetic properties like blood-brain barrier permeability and gastrointestinal absorption of any given chemical compound [Daina and Zoete, 2016].Our model also implements drug-likeness, PAINS, and Brenk filters to identify structural and toxicity alerts.All these tools in our model will assist in identifying and screening both currently available and new lead compounds.Currently restricted to using a simple SMILES as input, future releases will allow for varied user input (compound name, molecular formula, InChI key, CAS number, SMILES, ChEMBL ID, or ZINC ID) where the agent will first convert it to SMILES notation, and then used as input for the available tools.</p>
<p>Tool Description
MolWt Float [0, ∞] -Molecular weight LogP Float [−∞, ∞] -Predicted partition coefficient TPSA Float [0, ∞] -Topological Polar Surface Area QED Float [0, 1] -Quantitative Estimate of Druglikeness SA Float [1, 10] -Synthetic Accessibility BBB Permeant String [Y es, N o] -Is in "yolk" of BOILED-Egg model GI Absorption String [Low, High] -Is in "white" of BOILED-Egg model Druglikeness
Boolean -Passes Lipinski Rule of 5 Brenk Filter Boolean -Passes Brenk filter PAINS Filter Boolean -Passes PAINS filter Table 1: Cheminformatics tools currently supported by CACTUS.These tools provide a comprehensive assessment of a molecular and physicochemical properties.Apart from conversions between different molecular representations, all tools require input in the SMILES format.By leveraging these tools, CACTUS enables researchers to make informed decisions in the molecular discovery process and prioritize compounds with the most promising characteristics.</p>
<p>Prompting Strategy</p>
<p>One important aspect investigated was the significance of the prompt for the agent.Through the LangChain implementation of LLM agents, there is a default prompt that provides a generic instruction of what tools are available and what the task of the LLM is.However, this is not necessarily primed for understanding domain-specific information.To test the hypothesis we ran 2 scenarios: one where we left the default prompt unchanged and only included tool descriptions (Minimal Prompt), and one where we modified the prompt to align the agent more with the domain of chemistry (Domain Prompt).The belief is that a domain aligned prompt will steer the LLM towards better interpretation of the questions being asked, and therefore be more effective in answering user queries.Since we were using a wide range of LLMs for testing, the minimal prompt also included model-specific tokens so that we weren't unfairly evaluating models against the domain prompt.</p>
<p>Benchmarking</p>
<p>Results and Discussion</p>
<p>The implementation of CACTUS represents a significant step forward in the field of cheminformatics, offering a powerful and flexible tool for researchers and chemists engaged in molecular discovery and drug design.The benchmarking studies conducted on various 7b parameter models demonstrate the robustness and efficiency of the CACTUS framework, highlighting its potential to streamline and accelerate the drug discovery process as an example.</p>
<p>Benchmarking and Performance Evaluation</p>
<p>The performance of CACTUS was evaluated using a comprehensive set of 1000 questions, covering 10 different tools (Table 1, with and without the domain prompt on each 7b parameter model as shown in the Figure 2. Correct answers were scored as correct, while wrong answers, inability to converge on an answer, or inability to use the provided tool correctly were marked as incorrect.In this paper, we did not differentiate between incorrect tool usage and simply providing a wrong answer.Any answers that did not coherently address the question were considered incorrect.We accepted correct answers that contained additional formatted text after the correct answer, although this is not the preferred format.This additional information can be programmatically removed before returning the response to the user, or further prompts can be engineered to reduce additional text.Each type of question in the full question set was asked 100 times, resulting in 10 types of questions corresponding to the 10 tools provided in Table 1.This approach allowed us to identify which tools posed a greater challenge for the model, and where improvements to either the tool description or model prompt could be made.</p>
<p>The results shown in Figure 2 highlight the importance of domain-specific prompting in improving the accuracy of the model's responses; particularly for qualitative questions.This finding aligns with recent research emphasizing the role of prompt engineering in enhancing the performance of language models [Liu et al., 2023].</p>
<p>In the progression of AI and its applications in scientific inquiry, it is crucial to analyze the comparative effectiveness of various models in handling domain-specific tasks.The benchmarking analysis presented in Figure 3 offers significant insights into the performance of different language models when prompted with both minimal and domain-specific information.A comprehensive review of the performance data across the full spectrum of question types reveals that Gemma-7b and Mistral-7b models showcase robustness and versatility, performing admirably regardless of the nature of the prompt.Their consistent accuracy across different types of questions ranging from physiochemical properties like druglikeness and blood-brain barrier permeability to more complex metrics like quantitative estimate of drug-likeness (QED) highlight their reliability for a broad range of inquiries within the domain of molecular science.In contrast, models like Falcon-7b exhibit a noticeable disparity between performances with minimal and domain prompts.This variability suggests that Falcon-7b, while capable, may require more fine-tuned prompting to leverage its full potential effectively.The substantial difference in performance based on the prompt type points to an intrinsic model sensitivity to input structure and content, which can be pivotal in crafting effective inquiry strategies.Furthermore, the successful Figure 2: Comparison of the Gemma -7b model with different prompting strategies on the full question set benchmark shows significant improvement in the qualitative question set when comparing the minimal prompt (Figure 2a) to the domain prompt (Figure 2b), while demonstrating similar performance in the quantitative question set.</p>
<p>deployment of smaller models, such as Phi2 and OLMo-1b, on consumer-grade hardware (Figure 4) highlights the potential for democratizing access to powerful cheminformatics tools, enabling researchers with limited computational resources to harness the capabilities of CACTUS.</p>
<p>Open Source Models in Varied Settings</p>
<p>This comprehensive model comparison and analysis has broader implications for the employment of open-source models in scientific environments.The ability of models to perform well with domain-specific prompts is particularly encouraging, as it implies that with proper configuration, open-source models can be highly effective tools.The adaptability demonstrated by the Gemma-7b and Mistral-7b models indicates their potential for widespread applicability across various computational settings, from high-performance clusters to more modest research setups.Moreover, the ability to effectively prompt open-source models opens the door to their use in a variety of scientific contexts.It allows researchers to customize models to their specific domain, potentially bridging the gap between generalized AI capabilities and specialized knowledge areas.</p>
<p>Figure 3: Comparison of model performance among 7B parameter models using minimal and domain-specific prompts.The Gemma-7b and Mistral-7b models demonstrate strong performance and adaptability across prompting strategies, highlighting their potential for widespread applicability in various computational settings, from high-performance clusters to more modest research setups.</p>
<p>The flexibility and performance of these models have significant implications for scientific research, particularly in fields like synthetic organic chemistry and drug discovery.For researchers in these domains, the ability to utilize open-source models effectively can accelerate the discovery process, enhance predictive accuracy, and optimize computational resources.The insights from this benchmarking study provide a roadmap for selecting and tailoring models to specific research needs, thereby maximizing their utility in advancing scientific goals.The benchmarking study of the selected 7b parameter models serves as a testament to the progress in AI-driven research tools.It highlights the necessity of prompt optimization and the promise of open-source models in diverse scientific inquiries.The analysis underscores the potential of these models to become integral components in the computational chemist's toolkit, paving the way for innovative breakthroughs in molecular design and drug discovery.</p>
<p>Hardware Performance and Model Efficacy</p>
<p>The deployment of CACTUS models through vLLM offers a significant advantage by optimizing performance across a variety of GPUs used for LLM inference.In our benchmarking studies we utilized three types of NVIDIA GPUs: the A100 80GB, V100, and RTX 2080 Ti.Our objective was to evaluate the performance of models under different combinations of model size, GPU type, and prompting strategy (minimal or domain-specific).The performance metric was determined by the inference speed in relation to the model's accuracy.Figure 4 shows the summary of LLMs deployed under different conditions (GPU hardware used, prompt, and benchmark set used) and how well they performed.The efficiency of these models across diverse hardware highlights their potential for widespread implementation in a range of research settings.</p>
<p>The models evaluated include Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, Mistral-7b, as well as two smaller models, Phi2 and OLMo-1b.The inclusion of these smaller models highlights the potential for successfully deploying models on local resources with limited computational power (e.g., consumer-grade GPUs like the RTX 2080 Ti) while still achieving accurate results.Overall, the model performance was found to be relatively quick on both the 500-question sets (Qualitative/Quantitative) and the 1000-question combined set (Full).One notable outlier was the Llama2-7b model with domain prompting, which took 185 minutes to complete the inference on the full dataset; however, its accuracy was similar to the minimally prompted version.This model is considered to be an outlier and therefor not included in Figure 4.A full list of the data used to plot these summary figures can be found in the Appendix.The most interesting outcome is that smaller models deployed on consumer grade hardware do not perform drastically worse than their larger parameter model counterparts.Looking at the performance of the Phi2 model (2.7B parameters), it quickly and accurately tackles the 500 question quantitative benchmark with similar performance regardless of the GPU used with the A100 80GB version unsurprisingly as the fastest.Another interesting outcome is the performance of the OLMo-1b parameter model on the combined question set and the RTX 2080 Ti GPU.While unable to obtain any correct answers for the minimal prompt, it jumps up to a surprising 52.2% accuracy when provided a domain prompt.These results are promising that these smaller models can be deployed locally by users and still be able to interpret questions, possibly by providing more specialized prompts.</p>
<p>In general, inference time increased as question set size increased (e.g., from quantitative/qualitative to full) , while accuracy tended to decrease with longer inference times.Domain prompts achieved faster inference and accuracy than minimal prompts for models like Falcon-7b, MPT-7b, and Mistral-7b.However, there was an exception in the case of the Phi2 model on the full question set, where the minimal prompt resulted in faster inference but lower accuracy.</p>
<p>The hardware performance analysis highlights the importance of considering the interplay between model size, GPU capabilities, and prompting strategies when deploying CACTUS models for molecular property prediction and drug discovery.The ability to achieve accurate results with smaller models on consumer-grade hardware opens up the possibility of wider adoption and accessibility of CACTUS for researchers with limited computational resources.Furthermore, the impact of domain-specific prompting on both inference speed and accuracy emphasizes the need for carefully designed prompts tailored to the specific application domain.As CACTUS continues to evolve and integrate with other computational tools and autonomous discovery platforms, optimizing hardware performance will remain a critical consideration.Future research should explore the development of more efficient algorithms and architectures (energy efficiency) for deploying CACTUS models on a variety of hardware configurations, ensuring that the benefits of this powerful tool can be realized across a wide range of research settings and computational resources.</p>
<p>Issues Encountered and Resolutions</p>
<p>During the development and benchmarking of CACTUS agent using open-source models and the LangChain framework, several key challenges were identified.These issues, along with the solutions implemented, provide valuable insights for researchers and developers working on similar workflows.</p>
<p>One of the primary issues encountered was the slow inference speed when hosting open-source language models locally on machines utilizing CPUs.Most APIs quickly provide inference results when making calls and this is not something locally hosted models typically replicate well, especially when running on CPUs over GPUs.For this work, we initially used models from HuggingFace and deployed through the HuggingFace Pipelines python package.This allowed us to serve models, but the inference time was quite slow when wrapped in the LangChain agent.To address this, we began utilizing vLLM to host HuggingFace models instead.This substantially decreased our inference time, and allowed for API-like response times from models, even those hosted on less powerful consumer grade GPU hardware.</p>
<p>The second major challenge was related to prompt engineering.Our results shown previously highlight that for some models the prompt has a great effect on not only the model accuracy, but the inference time.We spent a good amount of time trying to hone our prompting strategy to yield consistently accurate and efficient results with mixed effect.We ended up needing specialized prompts for each open-source LLM we used, as some were fine-tuned much differently than others and required a very specific prompt style to return usable results.</p>
<p>These challenges highlight the need for continued research and development in the areas of model deployment and prompt engineering.Future work will be focused on optimizing the deployment of open-source models on various hardware configurations, including CPUs and GPUs, to ensure that CACTUS can be efficiently utilized across a wide range of computational resources.This may involve the development of novel algorithms and architectures that can better leverage the capabilities of different hardware setups, as well as the creation of more user-friendly tools and frameworks for model deployment and management.In terms of prompt engineering, the development of standardized prompt templates and best practices for prompt engineering in the context of molecular property prediction and drug discovery could help streamline the development process and improve the consistency of results across different models and datasets.</p>
<p>Future Outlook -Molecular Design</p>
<p>CACTUS has already demonstrated its potential in estimating basic metrics for input chemical compounds, but its future lies in its evolution into a comprehensive, open-source tool specifically designed for chemists and researchers working on therapeutic drug design and discovery.This will be achieved by the integration of physics-based molecular AI/ML models, such as 3D-scaffold The development plan also includes implementing advanced functionalities for identifying compounds that exhibit structural and chemical similarities, as well as pinpointing key fragments crucial for biological activity.This feature will allow researchers to explore a vast chemical space more efficiently, identifying lead compounds with higher precision.These additions are expected to significantly accelerate and deepen the agent's ability to understand compound behaviors in 3D spaces and allow researchers to develop more comprehensive and effective workflows for drug discovery and materials design.Additionally, we plan to include tools that identify key fragments and compounds with similar structural and chemical features from the vast available chemical databases.Tools which can calculate physio-chemical, pharmacokinetic properties, and about sixty other descriptors will be added to the agent to identify quantitative structureactivity relationship (QSAR) and quantitative structure-property relationship (QSPR) to help us with screening the compounds and identifying toxic groups.</p>
<p>Beyond these technical enhancements, there's a focus on making CACTUS more explainable and capable of symbolic reasoning.The aim is to address common criticisms of LLMs, particularly their struggle with reasoning and providing explainable outputs.By integrating more advanced symbolic reasoning capabilities, CACTUS will not only become more powerful in its predictive and analytical functions but also provide users with understandable, logical explanations for its recommendations and predictions.This feature would automate the process of predicting how small molecules, such as drug candidates, interact with targets like proteins, thereby providing invaluable insights into the potential efficacy of new compounds.</p>
<p>The applications of CACTUS extend beyond drug discovery and can be leveraged in other domains such as chemistry, catalysis, and materials science.In the field of catalysis, CACTUS could aid in the discovery and optimization of novel catalysts by predicting their properties and performance based on their structural and chemical features [Goldsmith et al., 2018].Similarly, in materials science, CACTUS could assist in the design of new materials with desired properties by exploring the vast chemical space and identifying promising candidates for further experimental validation [Agrawal and Choudhary, 2016].</p>
<p>The future development of CACTUS is geared towards creating an intelligent, comprehensive cheminformatics tool for molecular discovery that not only aids in the identification and design of therapeutic drugs but also ensures a high degree of safety and efficacy.Through the integration of advanced computational techniques and models, alongside improvements in usability and explainability, CACTUS is set to become an indispensable resource in the quest for novel, effective, and safe therapeutic agents, as well as in the discovery and optimization of catalysts and materials.</p>
<p>Conclusions</p>
<p>In this paper, we have introduced CACTUS, an innovative open-source agent that leverages the power of large language models and cheminformatics tools to revolutionize the field of drug discovery and molecular property prediction.By integrating a wide range of computational tools and models, CACTUS provides a comprehensive and user-friendly platform for researchers and chemists to explore the vast chemical space for molecular discovery and identify promising compounds for therapeutic applications.</p>
<p>We assessed CACTUS performance using various open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, across a set of one thousand chemistry questions.Our findings indicate that CACTUS outperforms baseline LLMs significantly, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy employed.Additionally, we investigated the impact of domain-specific prompting and hardware configurations on model performance, highlight the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy.The ability to achieve accurate results with smaller models such Phi on consumer-grade hardware opens up the possibility of wider adoption and accessibility of CACTUS, even for researchers with limited computational resources.</p>
<p>One of the key takeaways from the development and benchmarking of CACTUS is the importance of addressing the challenges associated with model deployment and prompt engineering.The solutions implemented in this work, such as the use of vLLM for hosting models and the development of tailored prompts for each open-source LLM, serve as a valuable foundation for future efforts in this field.As the field of AI continues to evolve rapidly, it is essential to keep abreast of new developments in language modeling and related technologies to further enhance the capabilities and performance of CACTUS.The development and benchmarking of CACTUS also highlighted key challenges in integrating open-source LLMs with domain-specific tools, such as optimizing inference speed and developing effective prompting strategies.We discussed the solutions implemented to address these challenges, including the use of vLLM for model hosting and the creation of tailored prompts for each LLM.</p>
<p>Looking ahead, the future of CACTUS is incredibly promising, with the potential to transform not only drug discovery but also various other domains such as chemistry, catalysis, and materials science.The integration of advanced physicsbased AI/ML models, such as 3D-scaffold, reinforcement learning and graph neural networks, will enable a deeper understanding of compound behaviors in 3D spaces, leading to more accurate predictions of molecular interactions and the efficacy and safety of potential therapeutic agents.Moreover, the addition of tools for identifying key fragments, calculating molecular properties, and screening compounds for toxic groups will significantly enhance the efficiency and precision of the drug discovery process.The focus on improving the explainability and symbolic reasoning capabilities of CACTUS will address common criticisms of large language models and provide users with understandable, logical explanations for the tool's recommendations and predictions.</p>
<p>As CACTUS continues to evolve and integrate with other computational tools and autonomous discovery platforms, it has the potential to revolutionize the way we approach drug discovery, catalyst design, and materials science.By leveraging the power of AI and machine learning, CACTUS can help researchers navigate the vast parameter spaces associated with complex chemical systems, identifying promising candidates for experimental validation and optimization.The future development of CACTUS is geared towards creating an intelligent, comprehensive cheminformatics tool that ensures a high degree of safety and efficacy in the identification and design of therapeutic drugs, catalysts, and materials for various application.Through the integration of advanced computational techniques and models, alongside improvements in usability and explainability, CACTUS is set to become an indispensable resource for researchers across various scientific disciplines.</p>
<p>In summary, CACTUS represents a significant milestone in the field of cheminformatics, offering a powerful and adaptable tool for researchers engaged in drug discovery, molecular property prediction, and beyond.As we continue to advance AI-driven scientific discovery, agent like CACTUS will play a pivotal role in shaping the future of research, innovation, and human health.By embracing the potential of open-source language models and cheminformatics tools, we can accelerate the pace of scientific advancement and unlock new frontiers in the quest for novel, effective, and safe therapeutic agents, catalysts, and materials.</p>
<p>final output o is the result of executing the sequence of actions A determined by the LLMChain, given the user input u and the available tools T .Here, The ReAct framework used by the zero-shot agent class was represented as a function R that takes the user input u, the set of tools T , and the tool descriptions D = d 1 , d 2 , . . ., d n as input, and outputs the most appropriate tool t k to use: R(u, T, D) = t k (5)</p>
<p>(a) Benchmark performance on the Gemma-7b model with a minimal prompt on each of the 10 question types.(b)Benchmark performance on the Gemma-7b model with a domain prompt on each of the 10 question types.</p>
<p>Figure 4 :
4
Figure 4: Comparison of model performance using accuracy and execution time as key metrics.The study evaluates various open-source models available on the HuggingFace including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, phi2 and olmo1b.Different combinations of conditions, such as model type (Vicuna, LLaMa, MPT), prompting strategy (minimal or domain-specific), GPU hardware (A100, V100, or consumer-grade), and benchmark size (small or large) were used to assess the model's capabilities.</p>
<p>Table 2 :
2
The second is quantitative, which represents tools that return numerical values to be interpreted by the agent.The third is a combination of both qualitative and quantitative which we call full or combined set.Table2highlights examples of questions passed as user-input to the CACTUS agent.The qualitative and quantitative datasets each contain 500 questions, and the combined dataset contains 1000.Most tests will be done on the combined dataset as we want to test the LLM agent's ability to perform a diverse set of tasks.Table demonstrating examples of the questions asked of the CACTUS agent in the cheminformatics benchmark used in this paper.
Qualitative QuestionsQuestionStepAnswerDoes CCON=O pass the blood brain bar-Use BBB Tool w/ SMILESYesrier?What is the GI absorption of C#C?Use GI tool w/ SMILESLowQuantitative QuestionsQuestionStepAnswerWhat is the QED of CCCC=O?Use QED Tool w/ SMILES0.44What is the TPSA of C(CS)OUse TPSA Tool w/ SMILES20.23
[Li et al., 2023, Farn and Shin, 2023an be a dif, Xu et al., 2023] can follow the examples set by general benchmarking suites[Li et al., 2023, Farn and Shin, 2023, Gen, 2023, Xu et al., 2023].Therefore, we rely on sets of questions that replicate the typical questions the agent would see and score how many the agent is able to answer correctly without requiring extra prompting effort from the user (i.e.having to rephrase the typed question to get a correct answer).To evaluate CACTUS we created sets of cheminformatics questions that test 3 sets of questions depending on the output of the tool.The first set is of qualitative questions, and is represented by questions that return answers like Yes/No, or True/False.</p>
<p>[Joshi et al., 2021], reinforcement learning [McNaughton et al., 2022], and graph neural networks (GNNs) [Knutson et al., 2022] accompanied with molecular dynamics simulations, quantum chemistry calculations, and high-throughput virtual screening [Joshi et al., 2021, Knutson et al., 2022, Joshi et al., 2023, Varikoti et al., 2023, Joshi and Kumar, 2021].Such capabilities are essential for accurately modeling molecular interactions and predicting the efficacy and safety of potential therapeutic agents [Jiang et al., 2021].</p>
<p>AcknowledgmentsThis research was supported by the I3T Investment, under the Laboratory Directed Research and Development (LDRD) Program at Pacific Northwest National Laboratory (PNNL).The computational work was performed using PNNL's research computing at Pacific Northwest National Laboratory.The initial concept of integrating LLM and tools received support from the Exascale Computing Project (17-SC-20-SC), a collaborative effort of two U.S. Department of Energy organizations (Office of Science and the National Nuclear Security Administration) responsible for the planning and preparation of a capable exascale ecosystem, including software, applications, hardware, advanced system engineering, and early testbed platforms, in support of the nation's exascale computing imperative.PNNL is a multi-program national laboratory operated for the U.S. Department of Energy (DOE) by Battelle Memorial Institute under Contract No. DE-AC05-76RL01830.Code and Data AvailabilityThe code to run CACTUS and the associated benchmark data can be found on GitHub: https://github.com/pnnl/cactus.Conflict of InterestThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.Model
Ioannis Papaioannou, Verena Rieser, and Ioannis Konstas. The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering. Sabrina Chiesurin, Dimitris Dimakopoulos, Marco Antonio Sobrevilla, Arash Cabezudo, Eshghi, may 2023</p>
<p>. Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Timo Baptiste Rozière, Jane Schick, Asli Dwivedi-Yu, Edouard Celikyilmaz, Yann Grave, Thomas Lecun, Scialom, 2023Augmented language models: a survey</p>
<p>On the tool manipulation capability of open-source large language models. Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, Jian Zhang, 2023</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis. 2023</p>
<p>Large language models as tool makers. Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou, 52023</p>
<p>TALM: Tool Augmented Language Models. Aaron Parisi, Yao Zhao, Noah Fiedel, may 2022</p>
<p>Large language models cannot self-correct reasoning yet. Jie Huang, Xinyun Chen, Swaroop Mishra, Steven Huaixiu, Adams Wei Zheng, Xinying Yu, Denny Song, Zhou, arXiv:2310.017982023arXiv preprint</p>
<p>Can large language models reason and plan?. Subbarao Kambhampati, Annals of the New York Academy of Sciences. 153412024</p>
<p>On the opportunities and risks of foundation models. Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney Von Arx, Jeannette Michael S Bernstein, Antoine Bohg, Emma Bosselut, Brunskill, arXiv:2108.072582021arXiv preprint</p>
<p>. OpenAI. Gpt-4 technical report. 2023</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Aurelien Azhar, Armand Rodriguez, Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. 2023</p>
<p>Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, arXiv:2403.08295Open models based on gemini research and technology. 2024arXiv preprint</p>
<p>Introducing mpt-7b: A new standard for open-source, commercially usable llms. Nlp Mosaicml, Team, 2023</p>
<p>The falcon series of open language models. Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, arXiv:2311.168672023arXiv preprint</p>
<p>Jiang, Sablayrolles, Mensch, Bamford, D Chaplot, F De Las Casas, Bressand, Lengyel, Lample, Saulnier, arXiv:2310.06825Mistral 7b. 2023. 2023arXiv preprint</p>
<p>Chatbot arena: An open platform for evaluating llms by human preference. Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E Gonzalez, arXiv:2403.041322024arXiv preprint</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, arxiv: 230605685. 2023arxiv preprint</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, arXiv:2009.03300Measuring massive multitask language understanding. 2020arXiv preprint</p>
<p>Emergent autonomous scientific research capabilities of large language models. A Daniil, Robert Boiko, Gabe Macknight, Gomes, 2023</p>
<p>KNIME: The Konstanz Information Miner. R Michael, Nicolas Berthold, Fabian Cebron, Thomas R Dill, Tobias Gabriel, Thorsten Kötter, Peter Meinl, Christoph Ohl, Kilian Sieb, Bernd Thiel, Wiswedel, Studies in Classification, Data Analysis, and Knowledge Organization. SpringerGfKL 2007. 2007</p>
<p>Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Jeremy Goecks, Anton Nekrutenko, James Taylor, Team The Galaxy, 10.1186/gb-2010-11-8-r86Genome Biology. 1474-760X118R862010</p>
<p>Chemcrow: Augmenting large-language models with chemistry tools. Sam Andres M Bran, Andrew D Cox, Philippe White, Schwaller, 42023</p>
<p>. Harrison Chase, Langchain, October 2022</p>
<p>Transformers: State-of-the-Art Natural Language Processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Le Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest, Rush, 10.18653/v1/2020.emnlp-demos.6Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsStroudsburg, PA, USAAssociation for Computational Linguistics2020</p>
<p>Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, arXiv:2205.004452022arXiv preprint</p>
<p>ReAct: Synergizing Reasoning and Acting in Language Models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, oct 2022</p>
<p>Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling. Greg Landrum, Greg Landrum. 83152812013</p>
<p>Scipy 1.0: fundamental algorithms for scientific computing in python. Pauli Virtanen, Ralf Gommers, Travis E Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Nature methods. 1732020</p>
<p>Pubchem 2023 update. Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, Nucleic acids research. 51D12023</p>
<p>Chembl web services: streamlining access to drug discovery data and utilities. Mark Davies, Michał Nowotka, George Papadatos, Nathan Dedman, Anna Gaulton, Francis Atkinson, Louisa Bellis, John P Overington, Nucleic acids research. 43W12015</p>
<p>Zinc20-a free ultralarge-scale chemical database for ligand discovery. Khanh G John J Irwin, Jennifer Tang, Chinzorig Young, Dandarchuluun, Munkhzul Benjamin R Wong, Khurelbaatar, S Yurii, John Moroz, Roger A Mayfield, Sayle, Journal of chemical information and modeling. 60122020</p>
<p>A boiled-egg to predict gastrointestinal absorption and brain penetration of small molecules. Antoine Daina, Vincent Zoete, ChemMedChem. 11112016</p>
<p>Api-bank: A comprehensive benchmark for tool-augmented llms. Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang, Yongbin Li, 2023</p>
<p>Tooltalk: Evaluating tool-usage in a conversational setting. Nicholas Farn, Richard Shin, 2023</p>
<p>Gentopia. 2023</p>
<p>. Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang, 2023Gpt understands, too. AI Open</p>
<p>3d-scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds. P Rajendra, Niklas Wa Joshi, Mridula Gebauer, Mercedeh Bontha, Khazaieli, M Rhema, James B James, Neeraj Brown, Kumar, The Journal of Physical Chemistry B. 125442021</p>
<p>De novo design of protein target specific scaffold-based Inhibitors via Reinforcement Learning. Andrew D Mcnaughton, Mridula S Bontha, Carter R Knutson, Jenna A Pope, Neeraj Kumar, may 2022</p>
<p>Decoding the protein-ligand interactions using parallel graph neural networks. Carter Knutson, Mridula Bontha, Jenna A Bilbrey, Neeraj Kumar, Scientific reports. 12176242022</p>
<p>Quantum mechanical methods predict accurate thermodynamics of biochemical reactions. P Rajendra, Andrew Joshi, Dennis G Mcnaughton, Christopher S Thomas, Henry, Lee Shane R Canon, Ann Mccue, Neeraj Kumar, ACS omega. 6142021</p>
<p>Ai-accelerated design of targeted covalent inhibitors for sars-cov-2. P Rajendra, Katherine J Joshi, Jesse William Schultz, Agustin Wilson, Kruel, Anand Rohith, Varikoti, J Chathuri, Daniel W Kombala, Stephanie Kneller, Gwyndalyn Galanie, Qiu Phillips, Zhang, Journal of Chemical Information and Modeling. 6352023</p>
<p>Integrated data-driven and experimental approaches to accelerate lead optimization targeting sars-cov-2 main protease. Anand Rohith, Katherine J Varikoti, Chathuri J Schultz, Agustin Kombala, Kruel, Mowei Kristoffer R Brandvold, Neeraj Zhou, Kumar, Journal of Computer-Aided Molecular Design. 3782023</p>
<p>Artificial Intelligence for Autonomous Molecular Design: A Perspective. P Rajendra, Neeraj Joshi, Kumar, 10.3390/molecules26226761Molecules. 1420-304926226761nov 2021</p>
<p>Could graph neural networks learn better molecular representation for drug discovery? a comparison study of descriptor-based and graph-based models. Dejun Jiang, Zhenxing Wu, Chang-Yu Hsieh, Guangyong Chen, Ben Liao, Zhe Wang, Chao Shen, Dongsheng Cao, Jian Wu, Tingjun Hou, Journal of cheminformatics. 132021</p>
<p>Machine learning for heterogeneous catalyst design and discovery. Bryan R Goldsmith, Jacques Esterhuizen, Jin-Xun Liu, Christopher J Bartel, Christopher Sutton, 10.1002/aic.16198AIChE Journal. 0001-1541647jul 2018</p>
<p>Perspective: Materials informatics and big data: Realization of the "fourth paradigm" of science in materials science. Ankit Agrawal, Alok Choudhary, Apl Materials. 452016A Benchmark Data</p>            </div>
        </div>

    </div>
</body>
</html>