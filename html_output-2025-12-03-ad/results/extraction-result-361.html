<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-361 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-361</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-361</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-15.html">extraction-schema-15</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <p><strong>Paper ID:</strong> paper-272714505</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.19472v3.pdf" target="_blank">PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning</a></p>
                <p><strong>Paper Abstract:</strong> Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines. It involves integrating common-sense knowledge to reason about complex and often contextualized situations, e.g. ``scheduling a doctor's appointment without a phone''. While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues. In this paper, we advocate planning using smaller language models. We present PlaSma, a novel two-pronged approach to endow small language models with procedural knowledge and (constrained) language planning capabilities. More concretely, we develop symbolic procedural knowledge distillation to enhance the commonsense knowledge in small language models and an inference-time algorithm to facilitate more structured and accurate reasoning. In addition, we introduce a new related task, Replanning, that requires a revision of a plan to cope with a constrained situation. In both the planning and replanning settings, we show that orders-of-magnitude smaller models (770M-11B parameters) can compete and often surpass their larger teacher models' capabilities. Finally, we showcase successful application of PlaSma in an embodied environment, VirtualHome.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e361.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e361.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLASMA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLASMA (PLAn with SMAll models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of small, fine-tuned T5-based language models (770M–11B params) trained via symbolic procedural knowledge distillation on an LLM-verbalized procedural dataset (COPLAN) to perform goal-based, constrained, and counterfactual language-based planning and to be applicable to embodied environments via textual-to-action mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5 (fine-tuned students)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>770M-11B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>T5-family encoder-decoder models fine-tuned with an autoregressive objective on COPLAN (LLM-generated plans/conditions/counterfactuals). Variants include task-specific and multi-task (PLASMA-Mul) students; used with/without verifier-guided decoding at inference. No direct sensory encoders were added.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Language-based procedural planning; applied to VirtualHome for embodied executability evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a high-level goal (and optionally a contextual constraint), generate a temporally ordered sequence of steps (plan), or revise an existing plan to satisfy constraints (replanning). In VirtualHome, generated natural-language steps are mapped to the simulator's executable action programs to assess executability and task correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step planning; instruction following; household/embodied task execution (via program mapping)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural + object-relational (affordances, equipment) + contextual constraints (some location/condition information); limited direct spatial layout reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>pretraining on text corpora (T5 backbone) + symbolic distillation from GPT-3 teachers (few-shot verbalizations stored in COPLAN) + fine-tuning on human-labeled VirtualHome examples (for the embodied adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>fine-tuning on COPLAN (task-specific and multi-task distillation), few-shot prompting used by teachers to generate COPLAN, inference-time decoding (regular beam or verifier-guided step-wise beam search)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>procedural knowledge represented as natural-language ordered action sequences (textual scripts) that become implicit knowledge in student model weights after distillation; when applied to embodied tasks, generated text is mapped to executable action programs (discrete supported actions + arguments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>human evaluation (coverage, ordering, overall quality on 5-point Likert), constrained/counterfactual success rate (human judgment), VirtualHome: executability (automatic), correctness (human), LCS (longest common subsequence)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Goal-based planning: best student (PLASMA-Mul+ 11B) achieves human-rated overall quality comparable to much larger models and humans (overall quality ≈ 4.58/5 in Table 1). Constrained planning: 11B PLASMA-Mul+ success ≈ 93.33% (human-rated). Counterfactual replanning: best PLASMA+ ≈ 86.33% (human-rated). VirtualHome (embodied): PLASMA-Mul+ (11B) executability 94.18%, LCS 31.93%, correctness 43.68% (automatic/human metrics); baselines: Planner (GPT-3 175B) executability 77.17%, LCS 19.10%, correctness 18.33%.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Generates temporally ordered, semantically coherent multi-step procedures; adapts plans to contextual constraints (location, equipment, safety, preferences); when fine-tuned+paired with verifier and mapping heuristics, produces steps that map to executable simulator actions at higher rates than prior GPT-3 based baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Common errors include missing necessary steps, unnecessary/repetitive steps, occasional illogical ordering; failures in replanning sometimes due to capacity limits or distributional mismatch; cultural/coverage biases in COPLAN could produce culturally-limited procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with teacher text-curie-001 and much larger GPT-3/Davinci (175B) few/zero-shot variants, PLASMA students (especially 11B PLASMA-Mul+) match or surpass the teacher and are competitive with larger models when paired with verifier-guided decoding; in VirtualHome PLASMA-Mul+ outperforms the Planner (GPT-3 175B) on executability and correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Multi-task distillation (PLASMA-Mul) generally outperforms task-specific students except for the smallest (770M); verifier-guided decoding (PLASMA+) yields 7%–48% relative improvements in overall human quality across student sizes (larger gains for smaller models); training on COPLAN vs. ProScript vs. Mix shows COPLAN transfers better and Mix performs best (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Procedural and object-affordance knowledge can be verbalized by large LLMs and successfully distilled into much smaller text-only models as natural-language plans; these models, operating without direct sensory inputs, can perform constrained planning and re-planning and — with a text→action mapping + verifier — produce steps that are executable in an embodied simulator, demonstrating that textual procedural representations + inference-time verification can substitute for direct perception for many planning aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e361.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e361.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLASMA+ (verifier-guided decoding)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Verifier-guided step-wise beam search (PLASMA+)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An inference-time tree search that combines the distilled student's sequence likelihood with a step-level verifier score to select next-step candidates, improving temporal/causal coherence and reducing common generation errors (ordering, missing steps, repetition).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PLASMA student + step verifier (RoBERTa)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>works with 770M–11B students (examples reported for 770M, 3B, 11B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoding algorithm that, at each generated step, expands N next-step candidates (beam/nucleus sampling), scores candidates with a value function mixing student log-prob and verifier validity score (weighted by α), and maintains a diverse K-beam of partial plans until completion.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Language-based planning and replanning (inference-time decoding enhancement); applied in both textual planning benchmarks and embodied VirtualHome mapping</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Improves the step-by-step generation of plans by pruning candidates that are semantically/temporally invalid, thereby increasing ordering, completeness, and executability of generated plans.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step planning; inference-time constrained decoding</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural (temporal/causal ordering) and semantic completeness checks; indirectly supports object-relational correctness via step validity</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>verifier trained on human-written plans (positives) and pseudo-negatives (perturbed plans); student probabilities from distilled PLASMA models</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>inference-time scoring and tree search combining student model log-probabilities and verifier scores (α-weighted), using multiple decoding schemes to propose candidates</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>student: implicit procedural knowledge in weights (text sequences); verifier: explicit step-level validity scoring (continuous scalar p_verifier in [0,1]) trained as a RoBERTa classifier</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>human evaluation (coverage, order, overall quality), verifier classification F1 on held-out test; downstream embodied metrics (executability, correctness) when used in VirtualHome pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Verifier achieves F1 ≈ 78% on held-out test for next-step validity. Using verifier-guided decoding improves overall plan quality by 7%–48% relative versus regular beam search across student sizes; yields larger improvements for smaller students. In VirtualHome, pairing with verifier (and finetuning) contributed to PLASMA-Mul+ achieving executability 94.18% and correctness 43.68%.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Reduces illogical/repeated steps and ordering errors; enforces semantic completeness and causal consistency step-by-step; enables recovery from early-step errors by exploring multiple candidate continuations.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Remaining errors include missing steps and some trivial or perfunctory edits in constrained replanning; effectiveness depends on verifier quality and tuning of α (student vs verifier weight), and verifier may not capture all environment-specific affordances without finetuning data.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to regular beam search decoding on the same students, PLASMA+ yields 7%–48% relative improvements in human-rated overall quality; ablation (removing verifier) leads to the reported drop in quality (percentage varies by model size).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Varying α shows trade-off between trusting the student vs verifier (experiments used α ∈ {0.5, 0.75, 0.8}); removing/verifier=off reduces ordering/completeness and lowers human quality scores by the reported 7%–48% range across models.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A step-level verifier combined with search is an effective way to impose temporal/semantic constraints on text-only planners, improving plan coherence and enabling small models to approach or match larger LLMs' planning performance without access to per-token logits or gradients from the teacher.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e361.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e361.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>COPLAN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>COPLAN (LLM-verbalized procedural dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-scale dataset of goals, procedural plans, contextual conditions, and counterfactual replans generated by LLM teachers (GPT-3 variants) via few-shot prompting and filtered by learned critics and human annotation to create high-quality procedural supervision for distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>dataset (used to fine-tune PLASMA students generated by GPT-3 teachers)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>COPLAN contains LLM-generated goal-plan pairs (~140k initial pairs) plus generated conditions and counterfactual plans; filtered using RoBERTa-Large critics trained on human annotations to maintain validity/quality.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Data source for goal-based planning, constrained planning, and counterfactual replanning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Provides textual examples of how to decompose high-level goals into ordered steps, how to adapt plans given environment/user constraints, and how to rewrite plans to satisfy counterfactual conditions; intended for distilling procedural/common-sense knowledge into smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dataset for multi-step planning, constrained planning, replanning</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural + object-relational (equipment/affordance mentions) + contextual constraints (location, safety, equipment, physical condition, preferences); minimal explicit spatial maps</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>generated by GPT-3 few-shot prompting (teacher models), curated by learned critics (RoBERTa) trained on 13K human annotations and additional human verification for test sets</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>few-shot prompting of GPT-3 teachers for goals, plans, conditions, and counterfactual plans; automatic critic filtering and human annotation for quality control</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>procedural knowledge represented as natural-language ordered step sequences, condition statements, and counterfactual plan rewrites (human-readable symbolic textual format)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>dataset scale and quality: COPLAN is ~11x larger than ProScript for planning, with critic-filtered precision ≈ 74%; downstream transfer evaluated by student model human-rated planning quality and VirtualHome executability</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>COPLAN enabled distilled students to outperform their GPT-3 teacher in goal-based planning (average relative improvement 17.57% across students vs teacher), and models trained on COPLAN transferred better to ProScript than models trained only on ProScript; mixing COPLAN+ProScript yielded best results (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Provides diverse, context-rich constraints and counterfactuals enabling models to learn how to adapt plans to equipment, location, and safety constraints; increases textual procedural coverage and diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>LLM-generated data can reflect cultural biases and occasional low-quality generations; there is a precision/size trade-off and critics/human checks are required to maintain quality.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to ProScript (human-written), COPLAN is larger (~11x) and when used for training yields better transfer to human-written testsets; training on Mix (COPLAN+ProScript) gives best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Training T5-11B on ProScript vs COPLAN vs Mix: COPLAN outperforms ProScript alone on out-of-domain transfer; Mix yields highest scores across coverage/order/quality (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM verbalizations of procedural knowledge, when curated, form an effective scalable supervisory signal for teaching smaller models procedural and constraint-aware planning; textual/symbolic representations (plans + conditions) are sufficient to encode the procedural knowledge needed for many planning and embodied-execution tasks without direct sensory input.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e361.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e361.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Step Verifier</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Step Verifier (RoBERTa-based next-step validity classifier)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A RoBERTa-Large binary classifier fine-tuned to score candidate next steps given a goal and plan-so-far, trained with positive examples from human plans and pseudo-negative perturbations to detect ordering, completeness, topicality, and fluency errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa-Large (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Fine-tuned RoBERTa-Large as a step-level verifier that outputs a continuous validity score p_verifier(s_t | g, s_<t) ∈ [0,1]; trained on ~47k positive/negative (plan-so-far,next-step) pairs derived from 3k human-written plans using perturbation strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Next-step validity classification to guide step-wise plan generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given a goal and the partial plan, classify candidate next steps as valid or invalid to guide decoding towards temporally/causally/semantically coherent plans.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>procedural validation; auxiliary verification module for decoding</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural (temporal/causal ordering) and semantic completeness checks</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>supervised fine-tuning on human-written plan next-step positives plus automatically constructed pseudo-negative perturbations (reordering, repetition, missing steps)</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>classification scoring during inference as part of step-wise beam search; trained via standard supervised fine-tuning with early stopping</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>explicit scalar validity score per candidate next-step derived from textual context (goal + plan-so-far + candidate step)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>binary classification F1 on held-out test; impact on downstream plan quality when integrated into decoder</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Verifier achieves F1 ≈ 78% on held-out test; integrating verifier in PLASMA+ yields 7%–48% relative improvements in human-rated overall plan quality and contributes to increased executability/correctness in VirtualHome.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Detects and down-weights candidates with incorrect ordering, semantic incompleteness, topical drift, and obvious fluency degenerations; effectively biases search away from common LM failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Limited by the diversity of pseudo-negatives and may miss environment-specific affordances without finetuning; classifier biases mirror training data limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Used in place of unconstrained student-only scoring (regular beam); outperforms student-only decoding by substantial margins in human-rated plan quality; ablation removing verifier reduces those gains.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Training verifier with different perturbation strategies (reorder, repetition, missing steps) enabled detection of varied errors; turning off verifier during decoding reproduces the 7%–48% reduction in plan quality depending on student size.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A learned, text-based verifier that evaluates candidate next steps provides an effective, low-cost substitute for environment-level affordance checks at decoding time and substantially improves procedural coherence of plans generated by text-only models operating without sensory input.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e361.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e361.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models encode, represent, or utilize spatial knowledge, procedural knowledge, or object-relational knowledge for embodied planning, navigation, or manipulation tasks, particularly when the model operates without direct sensory input.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VirtualHome evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VirtualHome: Simulating household activities via programs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embodied simulator of household activities where tasks are specified as high-level goals and agents execute programs composed of a set of supported actions and arguments; used here as an extrinsic testbed to measure executability and correctness of plans generated by text-only PLASMA models after mapping text to simulator actions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>VirtualHome: Simulating household activities via programs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PLASMA-Mul / PLASMA-Mul+ (11B) evaluated in VirtualHome pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>11B (reported best student)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>PLASMA-Mul 11B fine-tuned on COPLAN plus ~4K human-labeled (task, natural-language plan) examples and mapped to VirtualHome supported actions via nearest-neighbor embedding matching (stsb-roberta-large), with verifier fine-tuned on same data to prioritize executability.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>VirtualHome planning-to-program mapping and execution evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Translate generated natural-language plan steps to executable VirtualHome actions (42 supported actions + arguments) by finding nearest supported action in embedding space, run the program in the simulator, and measure executability (whether actions are supported/executable), correctness (human judge: accomplishes task) and LCS (similarity to human program).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>embodied household task execution; multi-step planning → program translation</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>procedural + object-relational (action affordances and arguments) with limited explicit spatial/layout reasoning (mapping to available simulator actions rather than raw perception)</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_source</strong></td>
                            <td>text-only model outputs (PLASMA) trained on COPLAN and human-labeled mapping examples; mapping uses sentence embeddings (stsb-roberta-large) to nearest supported action; verifier finetuned on mapping data</td>
                        </tr>
                        <tr>
                            <td><strong>has_direct_sensory_input</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>elicitation_method</strong></td>
                            <td>fine-tuned generation (PLASMA-Mul), verifier-guided decoding (PLASMA+), natural-language to action mapping by nearest-neighbor in embedding space, execution in simulator</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_representation</strong></td>
                            <td>textual action sequences generated by PLASMA, then discrete simulator programs derived by mapping to action tokens/arguments (symbolic program representation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Executability (automatic % of generated actions that are executable in simulator), Correctness (% judged by humans to achieve goal), LCS (longest common subsequence similarity to human program)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>PLASMA-Mul (11B) without verifier: executability 76.38%, LCS 28.36%, correctness 41.38%. PLASMA-Mul+ (11B) with verifier-guided decoding and finetuning: executability 94.18%, LCS 31.93%, correctness 43.68%. Baseline Planner (GPT-3 175B): executability 77.17%, LCS 19.10%, correctness 18.33%. Human: executability 100% and correctness 66.66%.</td>
                        </tr>
                        <tr>
                            <td><strong>success_patterns</strong></td>
                            <td>Text-only planners can generate steps that map to executable simulator actions at high rates when paired with a verifier and moderate human-labeled finetuning mapping data; gains are most pronounced in executability and correctness vs prior GPT-3 baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_patterns</strong></td>
                            <td>Mapping errors (nearest-neighbor embedding mismatch), missing or extra steps relative to human program, limitations in representing fine-grained spatial relations/layout that would require perceptual input, and residual incorrect arguments or ordering mistakes.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Planner (GPT-3 175B) reported executability 77.17%, LCS 19.10%, correctness 18.33%; PLASMA-Mul+ (11B) substantially improved LCS and correctness and greatly improved executability when paired with verifier and mapping finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Finetuning PLASMA-Mul on ~4K human-labeled examples and finetuning the verifier on same data materially improved VirtualHome metrics; removing verifier or finetuning reduces executability/correctness (exact numbers not reproduced but reflected in comparisons between PLASMA-Mul and PLASMA-Mul+).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Language models operating without direct sensory input can still produce plans that are executable in simulated embodied environments by (1) learning procedural/action-affordance mappings from textual data and a small amount of human-labeled mapping data, and (2) using verifier-guided decoding to prioritize actionable and temporally coherent steps; however, fine-grained spatial/layout reasoning remains constrained by the lack of perceptual input and by the quality of the text→action mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models are few-shot learners <em>(Rating: 2)</em></li>
                <li>VirtualHome: Simulating household activities via programs <em>(Rating: 2)</em></li>
                <li>Symbolic knowledge distillation: from general language models to commonsense models <em>(Rating: 2)</em></li>
                <li>Language models as zeroshot planners: Extracting actionable knowledge for embodied agents <em>(Rating: 2)</em></li>
                <li>Do as i can and not as i say: Grounding language in robotic affordances <em>(Rating: 2)</em></li>
                <li>Distilling script knowledge from large language models for constrained language planning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-361",
    "paper_id": "paper-272714505",
    "extraction_schema_id": "extraction-schema-15",
    "extracted_data": [
        {
            "name_short": "PLASMA",
            "name_full": "PLASMA (PLAn with SMAll models)",
            "brief_description": "A family of small, fine-tuned T5-based language models (770M–11B params) trained via symbolic procedural knowledge distillation on an LLM-verbalized procedural dataset (COPLAN) to perform goal-based, constrained, and counterfactual language-based planning and to be applicable to embodied environments via textual-to-action mapping.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "T5 (fine-tuned students)",
            "model_size": "770M-11B",
            "model_description": "T5-family encoder-decoder models fine-tuned with an autoregressive objective on COPLAN (LLM-generated plans/conditions/counterfactuals). Variants include task-specific and multi-task (PLASMA-Mul) students; used with/without verifier-guided decoding at inference. No direct sensory encoders were added.",
            "task_name": "Language-based procedural planning; applied to VirtualHome for embodied executability evaluation",
            "task_description": "Given a high-level goal (and optionally a contextual constraint), generate a temporally ordered sequence of steps (plan), or revise an existing plan to satisfy constraints (replanning). In VirtualHome, generated natural-language steps are mapped to the simulator's executable action programs to assess executability and task correctness.",
            "task_type": "multi-step planning; instruction following; household/embodied task execution (via program mapping)",
            "knowledge_type": "procedural + object-relational (affordances, equipment) + contextual constraints (some location/condition information); limited direct spatial layout reasoning",
            "knowledge_source": "pretraining on text corpora (T5 backbone) + symbolic distillation from GPT-3 teachers (few-shot verbalizations stored in COPLAN) + fine-tuning on human-labeled VirtualHome examples (for the embodied adaptation)",
            "has_direct_sensory_input": false,
            "elicitation_method": "fine-tuning on COPLAN (task-specific and multi-task distillation), few-shot prompting used by teachers to generate COPLAN, inference-time decoding (regular beam or verifier-guided step-wise beam search)",
            "knowledge_representation": "procedural knowledge represented as natural-language ordered action sequences (textual scripts) that become implicit knowledge in student model weights after distillation; when applied to embodied tasks, generated text is mapped to executable action programs (discrete supported actions + arguments)",
            "performance_metric": "human evaluation (coverage, ordering, overall quality on 5-point Likert), constrained/counterfactual success rate (human judgment), VirtualHome: executability (automatic), correctness (human), LCS (longest common subsequence)",
            "performance_result": "Goal-based planning: best student (PLASMA-Mul+ 11B) achieves human-rated overall quality comparable to much larger models and humans (overall quality ≈ 4.58/5 in Table 1). Constrained planning: 11B PLASMA-Mul+ success ≈ 93.33% (human-rated). Counterfactual replanning: best PLASMA+ ≈ 86.33% (human-rated). VirtualHome (embodied): PLASMA-Mul+ (11B) executability 94.18%, LCS 31.93%, correctness 43.68% (automatic/human metrics); baselines: Planner (GPT-3 175B) executability 77.17%, LCS 19.10%, correctness 18.33%.",
            "success_patterns": "Generates temporally ordered, semantically coherent multi-step procedures; adapts plans to contextual constraints (location, equipment, safety, preferences); when fine-tuned+paired with verifier and mapping heuristics, produces steps that map to executable simulator actions at higher rates than prior GPT-3 based baselines.",
            "failure_patterns": "Common errors include missing necessary steps, unnecessary/repetitive steps, occasional illogical ordering; failures in replanning sometimes due to capacity limits or distributional mismatch; cultural/coverage biases in COPLAN could produce culturally-limited procedures.",
            "baseline_comparison": "Compared with teacher text-curie-001 and much larger GPT-3/Davinci (175B) few/zero-shot variants, PLASMA students (especially 11B PLASMA-Mul+) match or surpass the teacher and are competitive with larger models when paired with verifier-guided decoding; in VirtualHome PLASMA-Mul+ outperforms the Planner (GPT-3 175B) on executability and correctness.",
            "ablation_results": "Multi-task distillation (PLASMA-Mul) generally outperforms task-specific students except for the smallest (770M); verifier-guided decoding (PLASMA+) yields 7%–48% relative improvements in overall human quality across student sizes (larger gains for smaller models); training on COPLAN vs. ProScript vs. Mix shows COPLAN transfers better and Mix performs best (Table 2).",
            "key_findings": "Procedural and object-affordance knowledge can be verbalized by large LLMs and successfully distilled into much smaller text-only models as natural-language plans; these models, operating without direct sensory inputs, can perform constrained planning and re-planning and — with a text→action mapping + verifier — produce steps that are executable in an embodied simulator, demonstrating that textual procedural representations + inference-time verification can substitute for direct perception for many planning aspects.",
            "uuid": "e361.0",
            "source_info": {
                "paper_title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "PLASMA+ (verifier-guided decoding)",
            "name_full": "Verifier-guided step-wise beam search (PLASMA+)",
            "brief_description": "An inference-time tree search that combines the distilled student's sequence likelihood with a step-level verifier score to select next-step candidates, improving temporal/causal coherence and reducing common generation errors (ordering, missing steps, repetition).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "PLASMA student + step verifier (RoBERTa)",
            "model_size": "works with 770M–11B students (examples reported for 770M, 3B, 11B)",
            "model_description": "Decoding algorithm that, at each generated step, expands N next-step candidates (beam/nucleus sampling), scores candidates with a value function mixing student log-prob and verifier validity score (weighted by α), and maintains a diverse K-beam of partial plans until completion.",
            "task_name": "Language-based planning and replanning (inference-time decoding enhancement); applied in both textual planning benchmarks and embodied VirtualHome mapping",
            "task_description": "Improves the step-by-step generation of plans by pruning candidates that are semantically/temporally invalid, thereby increasing ordering, completeness, and executability of generated plans.",
            "task_type": "multi-step planning; inference-time constrained decoding",
            "knowledge_type": "procedural (temporal/causal ordering) and semantic completeness checks; indirectly supports object-relational correctness via step validity",
            "knowledge_source": "verifier trained on human-written plans (positives) and pseudo-negatives (perturbed plans); student probabilities from distilled PLASMA models",
            "has_direct_sensory_input": false,
            "elicitation_method": "inference-time scoring and tree search combining student model log-probabilities and verifier scores (α-weighted), using multiple decoding schemes to propose candidates",
            "knowledge_representation": "student: implicit procedural knowledge in weights (text sequences); verifier: explicit step-level validity scoring (continuous scalar p_verifier in [0,1]) trained as a RoBERTa classifier",
            "performance_metric": "human evaluation (coverage, order, overall quality), verifier classification F1 on held-out test; downstream embodied metrics (executability, correctness) when used in VirtualHome pipeline",
            "performance_result": "Verifier achieves F1 ≈ 78% on held-out test for next-step validity. Using verifier-guided decoding improves overall plan quality by 7%–48% relative versus regular beam search across student sizes; yields larger improvements for smaller students. In VirtualHome, pairing with verifier (and finetuning) contributed to PLASMA-Mul+ achieving executability 94.18% and correctness 43.68%.",
            "success_patterns": "Reduces illogical/repeated steps and ordering errors; enforces semantic completeness and causal consistency step-by-step; enables recovery from early-step errors by exploring multiple candidate continuations.",
            "failure_patterns": "Remaining errors include missing steps and some trivial or perfunctory edits in constrained replanning; effectiveness depends on verifier quality and tuning of α (student vs verifier weight), and verifier may not capture all environment-specific affordances without finetuning data.",
            "baseline_comparison": "Compared to regular beam search decoding on the same students, PLASMA+ yields 7%–48% relative improvements in human-rated overall quality; ablation (removing verifier) leads to the reported drop in quality (percentage varies by model size).",
            "ablation_results": "Varying α shows trade-off between trusting the student vs verifier (experiments used α ∈ {0.5, 0.75, 0.8}); removing/verifier=off reduces ordering/completeness and lowers human quality scores by the reported 7%–48% range across models.",
            "key_findings": "A step-level verifier combined with search is an effective way to impose temporal/semantic constraints on text-only planners, improving plan coherence and enabling small models to approach or match larger LLMs' planning performance without access to per-token logits or gradients from the teacher.",
            "uuid": "e361.1",
            "source_info": {
                "paper_title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "COPLAN",
            "name_full": "COPLAN (LLM-verbalized procedural dataset)",
            "brief_description": "A large-scale dataset of goals, procedural plans, contextual conditions, and counterfactual replans generated by LLM teachers (GPT-3 variants) via few-shot prompting and filtered by learned critics and human annotation to create high-quality procedural supervision for distillation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "dataset (used to fine-tune PLASMA students generated by GPT-3 teachers)",
            "model_size": null,
            "model_description": "COPLAN contains LLM-generated goal-plan pairs (~140k initial pairs) plus generated conditions and counterfactual plans; filtered using RoBERTa-Large critics trained on human annotations to maintain validity/quality.",
            "task_name": "Data source for goal-based planning, constrained planning, and counterfactual replanning tasks",
            "task_description": "Provides textual examples of how to decompose high-level goals into ordered steps, how to adapt plans given environment/user constraints, and how to rewrite plans to satisfy counterfactual conditions; intended for distilling procedural/common-sense knowledge into smaller models.",
            "task_type": "dataset for multi-step planning, constrained planning, replanning",
            "knowledge_type": "procedural + object-relational (equipment/affordance mentions) + contextual constraints (location, safety, equipment, physical condition, preferences); minimal explicit spatial maps",
            "knowledge_source": "generated by GPT-3 few-shot prompting (teacher models), curated by learned critics (RoBERTa) trained on 13K human annotations and additional human verification for test sets",
            "has_direct_sensory_input": false,
            "elicitation_method": "few-shot prompting of GPT-3 teachers for goals, plans, conditions, and counterfactual plans; automatic critic filtering and human annotation for quality control",
            "knowledge_representation": "procedural knowledge represented as natural-language ordered step sequences, condition statements, and counterfactual plan rewrites (human-readable symbolic textual format)",
            "performance_metric": "dataset scale and quality: COPLAN is ~11x larger than ProScript for planning, with critic-filtered precision ≈ 74%; downstream transfer evaluated by student model human-rated planning quality and VirtualHome executability",
            "performance_result": "COPLAN enabled distilled students to outperform their GPT-3 teacher in goal-based planning (average relative improvement 17.57% across students vs teacher), and models trained on COPLAN transferred better to ProScript than models trained only on ProScript; mixing COPLAN+ProScript yielded best results (Table 2).",
            "success_patterns": "Provides diverse, context-rich constraints and counterfactuals enabling models to learn how to adapt plans to equipment, location, and safety constraints; increases textual procedural coverage and diversity.",
            "failure_patterns": "LLM-generated data can reflect cultural biases and occasional low-quality generations; there is a precision/size trade-off and critics/human checks are required to maintain quality.",
            "baseline_comparison": "Compared to ProScript (human-written), COPLAN is larger (~11x) and when used for training yields better transfer to human-written testsets; training on Mix (COPLAN+ProScript) gives best performance.",
            "ablation_results": "Training T5-11B on ProScript vs COPLAN vs Mix: COPLAN outperforms ProScript alone on out-of-domain transfer; Mix yields highest scores across coverage/order/quality (Table 2).",
            "key_findings": "LLM verbalizations of procedural knowledge, when curated, form an effective scalable supervisory signal for teaching smaller models procedural and constraint-aware planning; textual/symbolic representations (plans + conditions) are sufficient to encode the procedural knowledge needed for many planning and embodied-execution tasks without direct sensory input.",
            "uuid": "e361.2",
            "source_info": {
                "paper_title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Step Verifier",
            "name_full": "Step Verifier (RoBERTa-based next-step validity classifier)",
            "brief_description": "A RoBERTa-Large binary classifier fine-tuned to score candidate next steps given a goal and plan-so-far, trained with positive examples from human plans and pseudo-negative perturbations to detect ordering, completeness, topicality, and fluency errors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RoBERTa-Large (fine-tuned)",
            "model_size": null,
            "model_description": "Fine-tuned RoBERTa-Large as a step-level verifier that outputs a continuous validity score p_verifier(s_t | g, s_&lt;t) ∈ [0,1]; trained on ~47k positive/negative (plan-so-far,next-step) pairs derived from 3k human-written plans using perturbation strategies.",
            "task_name": "Next-step validity classification to guide step-wise plan generation",
            "task_description": "Given a goal and the partial plan, classify candidate next steps as valid or invalid to guide decoding towards temporally/causally/semantically coherent plans.",
            "task_type": "procedural validation; auxiliary verification module for decoding",
            "knowledge_type": "procedural (temporal/causal ordering) and semantic completeness checks",
            "knowledge_source": "supervised fine-tuning on human-written plan next-step positives plus automatically constructed pseudo-negative perturbations (reordering, repetition, missing steps)",
            "has_direct_sensory_input": false,
            "elicitation_method": "classification scoring during inference as part of step-wise beam search; trained via standard supervised fine-tuning with early stopping",
            "knowledge_representation": "explicit scalar validity score per candidate next-step derived from textual context (goal + plan-so-far + candidate step)",
            "performance_metric": "binary classification F1 on held-out test; impact on downstream plan quality when integrated into decoder",
            "performance_result": "Verifier achieves F1 ≈ 78% on held-out test; integrating verifier in PLASMA+ yields 7%–48% relative improvements in human-rated overall plan quality and contributes to increased executability/correctness in VirtualHome.",
            "success_patterns": "Detects and down-weights candidates with incorrect ordering, semantic incompleteness, topical drift, and obvious fluency degenerations; effectively biases search away from common LM failure modes.",
            "failure_patterns": "Limited by the diversity of pseudo-negatives and may miss environment-specific affordances without finetuning; classifier biases mirror training data limitations.",
            "baseline_comparison": "Used in place of unconstrained student-only scoring (regular beam); outperforms student-only decoding by substantial margins in human-rated plan quality; ablation removing verifier reduces those gains.",
            "ablation_results": "Training verifier with different perturbation strategies (reorder, repetition, missing steps) enabled detection of varied errors; turning off verifier during decoding reproduces the 7%–48% reduction in plan quality depending on student size.",
            "key_findings": "A learned, text-based verifier that evaluates candidate next steps provides an effective, low-cost substitute for environment-level affordance checks at decoding time and substantially improves procedural coherence of plans generated by text-only models operating without sensory input.",
            "uuid": "e361.3",
            "source_info": {
                "paper_title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "VirtualHome evaluation",
            "name_full": "VirtualHome: Simulating household activities via programs",
            "brief_description": "An embodied simulator of household activities where tasks are specified as high-level goals and agents execute programs composed of a set of supported actions and arguments; used here as an extrinsic testbed to measure executability and correctness of plans generated by text-only PLASMA models after mapping text to simulator actions.",
            "citation_title": "VirtualHome: Simulating household activities via programs",
            "mention_or_use": "use",
            "model_name": "PLASMA-Mul / PLASMA-Mul+ (11B) evaluated in VirtualHome pipeline",
            "model_size": "11B (reported best student)",
            "model_description": "PLASMA-Mul 11B fine-tuned on COPLAN plus ~4K human-labeled (task, natural-language plan) examples and mapped to VirtualHome supported actions via nearest-neighbor embedding matching (stsb-roberta-large), with verifier fine-tuned on same data to prioritize executability.",
            "task_name": "VirtualHome planning-to-program mapping and execution evaluation",
            "task_description": "Translate generated natural-language plan steps to executable VirtualHome actions (42 supported actions + arguments) by finding nearest supported action in embedding space, run the program in the simulator, and measure executability (whether actions are supported/executable), correctness (human judge: accomplishes task) and LCS (similarity to human program).",
            "task_type": "embodied household task execution; multi-step planning → program translation",
            "knowledge_type": "procedural + object-relational (action affordances and arguments) with limited explicit spatial/layout reasoning (mapping to available simulator actions rather than raw perception)",
            "knowledge_source": "text-only model outputs (PLASMA) trained on COPLAN and human-labeled mapping examples; mapping uses sentence embeddings (stsb-roberta-large) to nearest supported action; verifier finetuned on mapping data",
            "has_direct_sensory_input": false,
            "elicitation_method": "fine-tuned generation (PLASMA-Mul), verifier-guided decoding (PLASMA+), natural-language to action mapping by nearest-neighbor in embedding space, execution in simulator",
            "knowledge_representation": "textual action sequences generated by PLASMA, then discrete simulator programs derived by mapping to action tokens/arguments (symbolic program representation)",
            "performance_metric": "Executability (automatic % of generated actions that are executable in simulator), Correctness (% judged by humans to achieve goal), LCS (longest common subsequence similarity to human program)",
            "performance_result": "PLASMA-Mul (11B) without verifier: executability 76.38%, LCS 28.36%, correctness 41.38%. PLASMA-Mul+ (11B) with verifier-guided decoding and finetuning: executability 94.18%, LCS 31.93%, correctness 43.68%. Baseline Planner (GPT-3 175B): executability 77.17%, LCS 19.10%, correctness 18.33%. Human: executability 100% and correctness 66.66%.",
            "success_patterns": "Text-only planners can generate steps that map to executable simulator actions at high rates when paired with a verifier and moderate human-labeled finetuning mapping data; gains are most pronounced in executability and correctness vs prior GPT-3 baseline.",
            "failure_patterns": "Mapping errors (nearest-neighbor embedding mismatch), missing or extra steps relative to human program, limitations in representing fine-grained spatial relations/layout that would require perceptual input, and residual incorrect arguments or ordering mistakes.",
            "baseline_comparison": "Planner (GPT-3 175B) reported executability 77.17%, LCS 19.10%, correctness 18.33%; PLASMA-Mul+ (11B) substantially improved LCS and correctness and greatly improved executability when paired with verifier and mapping finetuning.",
            "ablation_results": "Finetuning PLASMA-Mul on ~4K human-labeled examples and finetuning the verifier on same data materially improved VirtualHome metrics; removing verifier or finetuning reduces executability/correctness (exact numbers not reproduced but reflected in comparisons between PLASMA-Mul and PLASMA-Mul+).",
            "key_findings": "Language models operating without direct sensory input can still produce plans that are executable in simulated embodied environments by (1) learning procedural/action-affordance mappings from textual data and a small amount of human-labeled mapping data, and (2) using verifier-guided decoding to prioritize actionable and temporally coherent steps; however, fine-grained spatial/layout reasoning remains constrained by the lack of perceptual input and by the quality of the text→action mapping.",
            "uuid": "e361.4",
            "source_info": {
                "paper_title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 2,
            "sanitized_title": "language_models_are_fewshot_learners"
        },
        {
            "paper_title": "VirtualHome: Simulating household activities via programs",
            "rating": 2,
            "sanitized_title": "virtualhome_simulating_household_activities_via_programs"
        },
        {
            "paper_title": "Symbolic knowledge distillation: from general language models to commonsense models",
            "rating": 2,
            "sanitized_title": "symbolic_knowledge_distillation_from_general_language_models_to_commonsense_models"
        },
        {
            "paper_title": "Language models as zeroshot planners: Extracting actionable knowledge for embodied agents",
            "rating": 2,
            "sanitized_title": "language_models_as_zeroshot_planners_extracting_actionable_knowledge_for_embodied_agents"
        },
        {
            "paper_title": "Do as i can and not as i say: Grounding language in robotic affordances",
            "rating": 2,
            "sanitized_title": "do_as_i_can_and_not_as_i_say_grounding_language_in_robotic_affordances"
        },
        {
            "paper_title": "Distilling script knowledge from large language models for constrained language planning",
            "rating": 1,
            "sanitized_title": "distilling_script_knowledge_from_large_language_models_for_constrained_language_planning"
        }
    ],
    "cost": 0.02231275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PROCEDURAL KNOWLEDGE MODELS FOR LANGUAGE-BASED PLANNING AND RE-PLANNING
18 Sep 2024</p>
<p>Faeze Brahman faezeb@allenai.org 
Chandra Bhagavatula 
Allen Institute for Artificial Intelligence</p>
<p>Valentina Pyatkin 
Allen Institute for Artificial Intelligence</p>
<p>Jena D Hwang 
Allen Institute for Artificial Intelligence</p>
<p>† Xiang 
Lorraine Li 
Hirona J Arai 
University of Southern California</p>
<p>Soumya Sanyal 
University of Southern California</p>
<p>Keisuke Sakaguchi 
Tohoku University</p>
<p>Xiang Ren 
Yejin Choi </p>
<p>University of Washington</p>
<p>University of Pittsburg</p>
<p>PROCEDURAL KNOWLEDGE MODELS FOR LANGUAGE-BASED PLANNING AND RE-PLANNING
18 Sep 2024B0638E45056283B14AB88C1A1E19BD4AarXiv:2305.19472v3[cs.CL]
Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines.It involves integrating common-sense knowledge to reason about complex and often contextualized situations, e.g."scheduling a doctor's appointment without a phone".While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues.In this paper, we advocate planning using smaller language models.We present PLASMA, a novel two-pronged approach to endow small language models with procedural knowledge and (constrained) language planning capabilities.More concretely, we develop symbolic procedural knowledge distillation to enhance the commonsense knowledge in small language models and an inference-time algorithm to facilitate more structured and accurate reasoning.In addition, we introduce a new related task, Replanning, that requires a revision of a plan to cope with a constrained situation.In both the planning and replanning settings, we show that orders-of-magnitude smaller models (770M-11B parameters) can compete and often surpass their larger teacher models' capabilities.Finally, we showcase successful application of PLASMA in an embodied environment, VirtualHome. 1</p>
<p>INTRODUCTION</p>
<p>Powered by massive scale, large language models (LLMs) excel on many downstream tasks that require commonsense.One such task is procedural planning (Schank &amp; Abelson, 1975b;Pearson &amp; Laird, 2005), a task that involves decomposing a high-level goal into a sequence of coherent, logical, and goal-oriented steps (plan) (e.g."see a movie" → "Look up movie showings", "Choose a movie" . ..).Recent approaches model this task as a conditional language generation problem using LLMs (Madaan et al., 2022;Huang et al., 2022;Ahn et al., 2022;Zhao et al., 2023).Despite their reasonable performance on the task, their steep computational cost and inaccessibility to models' parameters hinder the wider adoption of LLMs (OpenAI, 2023) for procedural planning.</p>
<p>We present PLASMA (PLAn with SMAll models), a novel framework and model to impart procedural knowledge and language-based planning abilities in small LMs. 2 In the first phase of the framework, we enhance the implicit commonsense knowledge in small LMs through symbolic procedural knowledge distillation (West et al., 2022;Bhagavatula et al., 2023) as illustrated in Figure 1.We formulate it in two stages: (i) Knowledge verbalization to generate procedural knowledge from an LLM, and (ii) Knowledge distillation to transfer LLM-generated knowledge to a smaller LM.</p>
<p>For the knowledge distillation stage, we introduce two constrained settings: Constrained planning and Counterfactual replanning in addition to the standard language planning task.These tasks enable † Authors contributed equally. 1 Our data and code is publicly available at: https://github.com/allenai/PlaSma 2 Hereafter, we will use 'planning' to refer to 'language-based planning' for brevity.a more realistic setting by requiring models to reason about contextually constrained situations in real-world applications.Specifically, the model generates or revises a plan based on a given goal (e.g., "see a movie") while adhering to an additional condition (e.g., "at home").Our knowledge verbalization process results in a large dataset for (i) language-based planning, (ii) language-based planning under constraints, and (iii) language-based re-planning of existing plans under constraints.Our dataset, COPLAN, is then used to train smaller models, PLASMA, using both task-specific and multi-task distillation.</p>
<p>For the second phase of PLASMA, we enable structured, tree-based reasoning via a novel inferencetime decoding algorithm (Figure 2).We observe that the standard next-token prediction objective in auto-regressive LMs (applied during distillation) does not equip them with sufficient causal and temporal reasoning abilities to generate high-quality plans, or a mechanism to rectify their mistakes in earlier steps.To address this challenge, we develop a verifier-guided step-wise beam search to better leverage the multi-step structure of plans (resulting in PLASMA+).Concretely, we incorporate a step-wise verifier in a tree-based decoding algorithm to guide PLASMA+ to generate more semantically coherent and temporally accurate plans.</p>
<p>Experimental results show that our approach is effective at endowing smaller LMs with planning abilities.For the standard planning task, smaller student models (of varying sizes) achieve 17.57% relative improvements, on average, over their teacher.The best student model is comparable even to GPT-3, a model 16 times the student's size.For the first time, we distill constrained and counterfactual planning abilities in small-size models, achieving 93% and 86% validity rates according to human evaluation.Interestingly, in the VirtualHome environment (Puig et al., 2018), our model significantly outperforms previous work based on GPT-3 (Huang et al., 2022) on executability (absolute 17%) and correctness (absolute 25%).Our framework including symbolic procedural distillation, decoding-time algorithm, and the proposed tasks and the accompanying COPLAN dataset provide valuable resource and direction for advancing research in the field of procedural language-based planning.</p>
<p>SMALL LANGUAGE MODELS AS PROCEDURAL KNOWLEDGE MODELS</p>
<p>In this section, we discuss how to endow small student models with procedural knowledge for (constrained and counterfactual) planning capabilities.We first describe our knowledge verbalization and distillation framework which we collectively refer to as Symbolic Procedural Knowledge Distillation ( §2.1, §2.2).We then propose a strategy to enhance the reasoning capabilities of small students via a novel verifier-guided step-wise decoding algorithm ( §2.3).</p>
<p>COPLAN: PROCEDURAL KNOWLEDGE VERBALIZATION FROM LARGE TEACHERS</p>
<p>Large language model can perform new tasks by adapting to a few in-context examples (Brown et al., 2020).We thus leverage this emergent reasoning capabilities of LLM to circumvent the challenge of crowdsourcing supervised datasets at scale.We collect data targeting the following three tasks:</p>
<ol>
<li>Goal-based Planning (pl.), decomposing a high-level goal g into a sequence of temporally extended steps y = {s t } T t=1 .2. Constrained Planning (cp.), decomposing a high-level goal g into a sequence of temporally extended steps y = {s t } T t=1 while satisfying a given condition c. 3. Counterfactual Replanning (cr.), rewriting an initial plan y to a given goal g into a new plan y ′ in order to satisfy a given condition c.</li>
</ol>
<p>Our knowledge verbalization pipeline shown in the left side of Figure 1 is a two-stage process: 1) instance generation through few-shot prompting, and 2) automatic data curation using a critic to filter out the low quality data.The process results in COPLAN, a quality dataset containing goals, plans, conditions, and counterfactual plans.</p>
<p>Step 1. Data Generation We start by generating a large pool of goals G with a diverse range of topics in a bootstrapping fashion.Concretely, we start with 5 manually written goals and expand them through prompting GPT-3.We then manually filter out low-quality (in terms of acceptability/achievability) ones and repeat this expansion/filtering for several iterations until we obtain a seed goal pool with 100 goals.We subsequently use this goal pool for randomly selecting few-shot examples for prompting and generating a large number of goals in our final dataset.</p>
<p>For each generated goal g ∈ G, we few-shot prompt a teacher model M to generate a set of ordered steps, as a plan y to achieve the goal.The input to M, including instruction and few-shot examples, takes the format shown in Appendix Figure 7. Since LLMs can be sensitive to instruction, and/or few-shot examples (Perez et al., 2021;Lu et al., 2022b), we randomize the prompt by (i) manually creating a set of semantically similar instructions and each time randomly sample from the instruction set, and (ii) using different set of in-context examples for each input.We use a subset of the existing ProScript (Sakaguchi et al., 2021) and DeScript (Wanzare et al., 2016) datasets as our seed source to form in-context examples, P = {(g j , y j )} M j=1 :
y i ∼ M(y i |g i , P)
The result is a pool of 140k pairs of goal and plans, (g, y), generated from the teacher model.</p>
<p>For the constrained and counterfactual (re)planning tasks, we also obtain conditions c, and modified plans y ′ from a teacher model M through few-shot prompting.We manually design our prompts P to collect natural language conditions concerning the environment the task is performed in such as Location ("the store is closed"), Equipment ("you don't have a sharp tool"), Safety ("the car breaks down") or user's specifications such as Physical Condition and Preference ("you have an injury").For a given goal g i and plan y i , we sample conditions:
c i ∼ M(c i |g i , y i , P)
Next, we few-shot prompt M to rewrite an initial plan y for a given goal g such that it satisfies the requirement of a condition c:
y ′ i ∼ M(y ′ i |g i , y i , c i , P)
The prompting templates and examples of conditions are shown in Appendix Figure 8 and Table 6.</p>
<p>Step 2. Automatic Data Curation To retain high-quality data for (re)planning under the original and constrained settings, we filter out generated samples from Step 1, i.e. generated plans, conditions and counterfactuals, that are invalid or of low quality.A plan y is considered invalid if it contains an illogical order of steps, is off-topic (w.r.t the goal) or incomplete.Whereas a modified plan y ′ should not only satisfies these general criteria but should also adhere to the condition.</p>
<p>To this end, we train separate supervised critic models to judge the quality of generated samples of different types.We collect 13K human annotations of valid vs. invalid samples on Amazon Mechanical Turk to train a RoBERTa-Large (Liu et al., 2019a) as our critic models (see Appendix B.1 and B.2 for more details on annotation instruction and hyper-parameter tuning).All critics are binary classifiers which identify whether a tuple of either (goal, plan), (goal, plan, condition) or (goal, plan, condition, modified plan) is valid.</p>
<p>Naturally, there is a trade-off between dataset size and precision.Following West et al. (West et al., 2022), we test several confidence thresholds at which the critic rejects a pair and choose the best values (0.65, 0.76, 0.82)3 according to precision-recall curves.After filtering out low quality</p>
<p>Buy a new car</p>
<p>Plan-so-far:</p>
<p>Step ).On the original planning task, COPLAN is ×11 larger in scale than existing datasets (Sakaguchi et al., 2021;Wanzare et al., 2016) while keeping the precision at 74%.On the proposed constrained and counterfactual settings, our dataset is to the best of our knowledge the first large-scale constrained procedural (re)planning dataset with free-form (open vocabulary) conditions.Analyses show that the COPLAN includes a diverse array of topics covered by goals ( §A.1) and conditions ( §A.2).</p>
<p>PLASMA: PROCEDURAL KNOWLEDGE DISTILLATION INTO SMALL STUDENTS</p>
<p>After obtaining our procedural planning data COPLAN, we use it to fine-tune student models on the three different task settings described in §2.1.We consider both task-specific and multi-task distillation objectives to transfer generated procedural knowledge into the student models:</p>
<p>Task-specific Distillation.Following the common practice, we use the standard autoregressive language modeling objective (Radford et al., 2018) to fine-tune separate student models for each task:</p>
<p>L(θ) = E (x,y)∼D task − log p θ (y|T (x)) , for task∈{pl.,cp.,cr.}(1)</p>
<p>where T (x) is a task-specific template for each task-specific input x (see right side of Figure 1).</p>
<p>Multi-task Distillation.We aim to improve the generalization of the student by exploiting the knowledge found in the three related tasks as an inductive bias (Raffel et al., 2020;Wei et al., 2022).We thus minimize the joint loss including all three task settings.We name this student PLASMA-Mul.</p>
<p>PLASMA+: ADVANCING STUDENT WITH VERIFIER-GUIDED DECODING</p>
<p>During inference, the student may generate logically and/or temporally ill-formed sequence of steps y = {s t } T t=1 as it is only trained to maximize the next-token probability.For example, in Figure 2, it may generate "write a check" at step 3 with relatively high confidence due to a spurious correlation between "sales price" and "check".We mitigate this issue via step-wise guided decoding.Rather than generating plans greedily, we instead generate step-by-step by sampling several candidate next steps and searching for those with a high log-probability under both the distilled student and a verifier.The verifier is tasked to check for sequential ordering and semantic completeness.In an embodied setting, the verifier could be taken over by any affordance or safety module (Ahn et al., 2022) that determines the executability of an action in a given environment.</p>
<p>Step Verifier.We introduce a verifier, which is trained to check the validity of plan steps and encourage PLASMA to produce more temporally and causally valid plans.The verifier takes as input a goal, the plan-so-far and a candidate next step and outputs a continuous validity score p verifier (s t |g, s &lt;t ) ∈ [0, 1].</p>
<p>We implement the verifier by fine-tuning a RoBERTa model (Liu et al., 2019b) to classify a candidate step as valid or invalid.For training, we reuse only 3K human-written plans from existing datasets (Sakaguchi et al., 2021) to form positive examples (valid next steps).However, since no negative examples are readily available, we automatically create a set of invalid steps as pseudo-negative examples.Inspired by the common model errors, we design perturbations over ground-truth plans to target sequential ordering , semantic completeness , topicality, and fluency .4See Appendix B.3 for details on perturbation strategies.Our verifier achieves an F1 score of 78% on a held out test set.</p>
<p>Verifier-guided</p>
<p>Step-wise Beam Search.We illustrate our verifier-guided decoding in Figure 2. The procedure generates a plan y = (s 1 , ..., s T ) by sequentially sampling and pruning the next step candidate s t .Concretely, at each iteration, it selects and expands a size-K beam of plan-so-far, Y t−1 = {s k &lt;t } K k=1 , and generates N next-step candidates,
Y t = ∪ s&lt;t∈Yt−1 {(s &lt;t ||s n t ) | s n t ∼ q(.|T (x, s &lt;t )} N n=1 (2)
where || is concatenation, x is a task-specific input, and q is a decoding algorithm.We encourage exploration at each step, by generating candidates using multiple decoding methods such as beam search, and nucleus sampling with temperature 1.0.</p>
<p>To select the top-K scoring next-step candidates S * t , we use a value function v(s ≤t ) − → R which returns the weighted sum of normalized sequence log-likelihood from the student model and the verifier validity score,
S * t = arg top-K s ≤t ∈Yt v(s ≤t ) (3) v(s ≤t ) = α log p θ (s ≤t ) + (1 − α) log p verifier (s t |g, s &lt;t )(4)
with α controlling the impact of the distilled student and the verifier.The search ends when the beam contains K completed plans.We return the highest-scored plan as the final output.Our step-wise beam search strategy maintains a diverse set of candidate plans during the decoding process, allowing the model to explore multiple plausible paths before converging on a most promising one.</p>
<p>EXPERIMENTS</p>
<p>Implementation Details.While any model with few-shot capabilities could be used, we choose our teacher model M to be GPT-3 text-curie-001 (Brown et al., 2020) for collecting the goals and initial plans, and GPT-3 text-davinci-003 for collecting conditions and counterfactual plans. 5e sample data points from GPT-3 using nucleus sampling (p = 0.98) and temperature of T = 0.9.</p>
<p>For our student models, we try a range of model sizes in T5 family (Raffel et al., 2020), such as T5-large, T5-3B, and T5-11B.Student models are trained using Huggingface Transformers (Wolf et al., 2020).Main experiments can be done on 2 GPUs with 48GB of memory.</p>
<p>During inference, we use a beam K = 5 for regular beam search, and N = 10 (next-step candidates), beam K = 5, p = 0.9, and α = 0.5 for our verifier-guided step-wise decoding (see §2.3).</p>
<p>Baselines.For each task, we compare our distilled students with their corresponding teacher, zero-shot and few-shot variants of GPT-3 (Brown et al., 2020), COCOGEN (Madaan et al., 2022) and human performance (when available).COCOGEN frames the planning task as a code generation task and use a pre-trained code LM (code-davinci-002) in a few-shot setting.</p>
<p>Next, we present the experimental setup for each task, along with their results.</p>
<p>GOAL-BASED PLANNING</p>
<p>In this section, we aim to study two key research questions through our experiments.Firstly, we seek to investigate the extent to which scale impacts the distillation of procedural knowledge.Secondly, we aim to examine whether the scale gap can be bridged through the use of multitasking and/or a novel decoding algorithm.In essence, we seek to determine whether small language models can perform procedural planning tasks with the same level of proficiency as large language models.</p>
<p>Evaluation Set.For the original planning task, we use human-written plans from the test set of ProScript (Sakaguchi et al., 2021) dataset as our evaluation data.</p>
<p>Setup.We compare several student models of varying scales (770M-11B) with the teacher model, text-curie-001, and extremely large scale models (175B).For all student models, we decode using both regular beam search (PLASMA) and our verifier-guided step-wise beam search (PLASMA+).</p>
<p>Metrics.Since there may exist many equally valid plans to a goal, we conduct human evaluations for the main results and report automatic metrics such as BLEU (Papineni et al., 2002), ROUGE (Lin, 2004) and BERTScore (Zhang et al., 2020) in Appendix Table 7.We ask human annotators on the Amazon Mechanical Turk (AMT) platform to rate the generated plans for 250 randomly sampled goals on three aspects: 1) Order: how well-ordered the plan is (captures sequential correctness), 2) Coverage: how well the plan covers the necessary steps to accomplish the goal (captures semantic completeness), and 3) Overall quality: overall quality and correctness of the plan.Details of the human evaluation can be found in Appendix D.3 Figure 10.Table 1 and Figure 3 summarize the human evaluation for the original planning task.</p>
<p>Does scale matter?Larger models perform relatively better across all aspects.</p>
<p>Does multi-task distillation help bridge the scale gap?As we observe, multi-task distillation almost always wins over its task-specific counterpart with the exception of the smallest student, PLASMA (770M).We posit that very small student models might not have enough capacity to leverage the related tasks efficiently during multitasking.</p>
<p>Does verifier-guided decoding help bridge the scale gap?Pairing models with our verifier-guided step-wise decoding substantially improves performance across students of varying sizes over all aspects.Specifically, compared with regular beam search, our proposed decoding results in 7%48% relative improvements in overall quality across different student sizes.The improvements achieved by the proposed decoding is larger for smaller students.We showcase the comparisons with qualitative examples in Table 8.</p>
<p>The best distilled students with 770M, 3B, and 11B parameters achieved respectively 14.13%, 16%, and 22.59% relative improvements over their teacher model (text-curie-001).Finally, our best distilled model (11B PLASMA-Mul+) performs equally well as human and is competitive with orders-of-magnitude larger models (175B). 6These results support our claim that a smaller model can, in fact, be as powerful as larger models when augmented with smarter decoding-time techniques.Figure 3 visualizes how we bridge the scale gap using our multi-task distillation and verifier-guided decoding.Since the initial submission, we conduct an additional comparison with GPT-4 (see Table 14), indicating similar trends.</p>
<p>Effect of symbolic distillation.In this experiment, we investigate the utility of CoPlan that is obtained through symbolic distillation in the presence of manually curated ProScript dataset (Sakaguchi et al., 2021).We thus compare a T5-11B distilled model trained on CoPlan with a T5-11B model trained only on ProScript, and the mix of both.Due to potential distribution shifts, we evaluated them on both their in-and out-of-domain test sets.We generate plans using our proposed verifier-guided decoding for randomly sampled 150 goals from ProScript and COPLAN.We use the same human evaluation setup as before.Table 2 shows that training on our LLM-generated  COPLAN dataset, consistently transfers better to human-written dataset, ProScript across all dimensions.Training on the mix of both datasets, however, achieves the best performance.
770M 3B 11B 175B</p>
<p>CONSTRAINED AND COUNTERFACTUAL (RE)PLANNING</p>
<p>Here, we seek to benchmark language models' planning abilities under constrained (contextually grounded) situations.This task goes beyond the original planning task, requiring models to produce novel linguistic alternatives to unseen situations.</p>
<p>Evaluation Set.We created the test set of COPLAN by generating conditions and counterfactual plans for the human-written (goal, plan) in the ProScript.Additionally, instead of using trained critic to filter out low-quality samples, we used human annotators to verify them.We only used human-verified tuples of (goal, plan, condition, cf.plan) as the test set of COPLAN.</p>
<p>Setup.We compare 3B and 11B student models with GPT-3 Curie and text-davinci-003, the 175B teacher, in zero/few-shot settings.During inference, we use our verifier-guided step-wise decoding with α = 0.75 to outweigh student model's probability over the verifier validity score.7</p>
<p>Metric.We conduct human evaluation on the AMT.We generate (counterfactual) plans for 300 randomly sampled examples using each model.We ask 3 workers to rate if each generated plan contains the necessary steps to make the goal achievable while satisfying the condition.We provide 3 answer options: A: The plan contains all the necessary steps to meet the requirements of the condition on the goal, B: The plan addresses the condition, but it is trivial and lacks thoughtfulness8 , and C:</p>
<p>The plan does NOT address the condition or does so very poorly.We take the majority vote for the final results.Details on crowd-sourcing human evaluation can be found in Appendix Figure 12.</p>
<p>Results. Figure 4 depicts the results.Large students perform better on both tasks.In constrained planning, our 11B PLASMA-Mul+ demonstrates a 93.33% success rate in producing high-quality plans while adhering to the given condition, which is comparable to the performance of the 175B parameter Davinci model in a zero-shot setting.Furthermore, our model generates slightly fewer low-quality plans, only 7 as opposed to 12 by Davinci.While multi-tasking seems to be somewhat helpful in constrained planning, this is not always the case for replanning.We hypothesize that the reason for this could be that the original and constrained planning tasks, which do not involve modifying an existing plan, may negatively impact the replanning task.The best performance for the counterfactual replanning is achieved by Davinci (90%) followed by PLASMA+ (86.33%).9Nonetheless, statistical T -test of our best models for constrained and counterfactual (re)planning tasks indicate that they are statistically on par with the much larger Davinci GPT-3.5 (175B We provide qualitative examples of model generations across all three tasks in Table 4.More examples of (good and bad) generations according to human annotators are provided in Appendix Tables 9, 10.As an extrinsic evaluation, we investigate the application of PLASMA in a domain with hard executability conditions.We evaluate PLASMA on the task of planning in the VirtualHome (Puig et al., 2018) environment.In this environment, agents can perform household activities, e.g."paint ceiling", through programs, in the form of supported actions (42 in total) and arguments.For evaluation, we use their test set consisting of 88 goals (and corresponding gold programs).We compare our best student PLASMA-Mul (11B) with the best-performing model on VirtualHome environment according to Huang et al. (2022).Specifically, we compare with Planner, a 1-shot GPT-3 (175B) model with several inference-time strategies designed to ensure executability in embodied environments.Following their setup, we translate generated steps from natural language to steps executable in the environment.To apply our model to VirtualHome, we finetune PLASMA-Mul on ∼ 4K human labeled examples and also finetune the verifier on the same data using the method described in Section 2.3.This human-labeled data, obtained from previous work (Huang et al., 2022), consists of pairs of ⟨task, natural language plan⟩.The same data was used to finetune supervised models including GPT-3 13B, resulting in performance inferior to that of Planner (Huang et al., 2022).</p>
<p>APPLICATION TO EMBODIED AGENTS</p>
<p>We evaluate models on: (i) Executability: measures whether a generated action is executable within the environment, (ii) Correctness: measures whether the generated actions accomplish the task, and (iii) Longest common subsequence (LCS): measures the action-level similarity between a generated program and a human-annotated one.We show, in Table 3, that PLASMA generates steps that are significantly more executable (according to automatic metric) and also more correct/complete (according to human judges).This suggests successful application of PLASMA in embodied setting.More experimental details can be found in Appendix E.  (Chambers &amp; Jurafsky, 2008), or, more recently, methods that utilize task-specific fine-tuned LLMs (Sakaguchi et al., 2021) and pipeline-based approaches (Sancheti &amp; Rudinger, 2022).In addition, there is a line of procedural planning that involves planning with executable actions that can be executed by robots in real-life environments (Huang et al., 2022;Ahn et al., 2022;Wu et al., 2022;Jansen, 2020;Guan et al., 2023).Recent approaches view planning as a conditional text generation problem using LLMs (Madaan et al., 2022;Huang et al., 2022;Ahn et al., 2022;Lu et al., 2023).Despite showing strong performance, their success heavily relies on scale.</p>
<p>Symbolic Knowledge Distillation Crowd-sourcing human-written datasets at scale is both challenging and costly, leading to a growing interest in using LLM-generated data to train smaller models which falls under the conceptual framework of symbolic knowledge distillation (West et al., 2022).In a concurrent work, Yuan et al. (Yuan et al., 2023) proposed a similar approach to distill script knowledge from LLMs for constrained planning task.However unlike our conditions which allows nuanced and free-form format, their constraints are limited to specific types by extending an original goal with a modifier.Relatedly, Collins et al. (2022) benchmarked LLMs' planning abilities (Valmeekam et al., 2023) under 28 manually constructed constrained goals.We instead investigate a broader range of constraints in a larger-scale COPLAN and distill this knowledge into smaller models.</p>
<p>Decoding-time Algorithm Decoding-time algorithm is an emerging approach for adapting language models' output for task-specific characteristics.Works in this line often focus on incorporating explicit lexical constraints (Lu et al., 2021;2022a;Hokamp &amp; Liu, 2017;Pascual et al., 2020).Besides discrete lexical constraints, applying continuous optimization functions, e.g.KL loss, has been found to be effective (Qin et al., 2020;2022;Kumar et al., 2021;Hoang et al., 2017).Perhaps our approach is most similar to function-guided decoding methods.Krause et al. (Krause et al., 2021) and Yang et al. (Yang &amp; Klein, 2021) fuse next-token probability with desired attributes' probabilities at inference using a discriminator model.These and related token-level beam search variants assume access to per-token logits and gradient updates.Our decoding method however only relies on model log-probabilities and a verifier to facilitate semantic and temporal constraints at a step level.</p>
<p>CONCLUSIONS AND FUTURE WORK</p>
<p>In this paper, we focus on procedural planning, a challenging task that involves decomposing highlevel goals into ordered steps.We introduce PLASMA as an effective approach that uses smaller and more accessible models.By leveraging symbolic procedural knowledge distillation and an inference-time algorithm, we have endowed smaller models with enhanced procedural knowledge and planning capabilities.Furthermore, we introduced the task of Counterfactual Planning, which involves generating/revising plans to accommodate realistic counterfactual scenarios.Our results demonstrate that significantly smaller models can effectively compete with and often outperform their larger teacher models in both original and counterfactual settings.We hope our work sheds light on new directions towards developing smaller yet powerful multi-modal models for (counterfactual) procedural planning and reasoning.</p>
<p>ETHICS STATEMENT IRB AND ANNOTATION ETHICS</p>
<p>We obtained IRB exemption for our data collection and evaluation from our institution's internal review board.In full compliance to the exemption clauses as published in the code of federal regulations (45 CFR 46.104(d)(2,3)), we did not collect any deanomyzing information, and we do not publish our dataset with worker specific information such as the MTurk's worker id.Based on our exempted status, according to our internal regulations, does not require for us to use consent forms with our crowdsourcing.</p>
<p>Additionally, our data collection and evaluation efforts only involve human judgments about world knowledge relating to general real-world goals and plans.We have no reason to believe that our crowdsourcing posed harm or discomfort beyond the minimal risk as defined by 45 CFR 46.102(i).</p>
<p>LIMITATIONS</p>
<p>One potential limitation of our work is that the verbalization component of our framework involves open text generation from large-scale language models (GPTs).Works such as Bender et al. (Bender et al., 2021) have argued that generations from LLMs can be prone to harmful biases stemming from the massive language data they are trained on.In the process of constructing the dataset, we have not directly observed levels of biases to cause us alarm.We believe harmful and discriminatory generations are largely mitigated by the very nature of the goals and scripts we obtain: our data is primarily composed of low-level everyday situations such as education, self-care, and mundane chores like vacuuming the floor or cooking a meal (see §A.1, A.2).This said, we acknowledge that prejudices like gender roles, for example, do also surface in the most mundane scenarios.</p>
<p>A related limitation is that LLMs have been trained on primarily English pretraining data, likely sourced from texts that reflect North American or European culture or norms.Consequently, we note that the goals in COPLAN may reflect the goals that are most culturally expected or appropriate to the cultures of English-speaking countries.This is also expected of the plans that may include culturally limited processes and procedures.This should be a consideration that any follow-up studies using our data and model should attend to.Extending our study to include more socio-culturally inclusive goals and plans is a compelling direction for our future research.</p>
<p>BROADER IMPACTS</p>
<p>Related to the concerns discussed in the Limitations section above, it is important for any downstream application to be aware that our data may have a limited representation of the goals and procedures of dominant cultures of English-speaking countries.</p>
<p>REPRODUCIBILITY STATEMENT</p>
<p>We include all experimental details for reproducing the distillation and decoding algorithm in the beginning of §3  Next, using the seven categories, we manually annotate 200 most frequent verb unigrams, 300 most frequent noun unigrams, and 300 most frequent nominal (nouns + adjectives) bigrams extracted from the goals statement.Only when the unigram (e.g."make") or the bigram (e.g."new word") indicates one of the seven categories (e.g., "close friend" for relationship or "college university" for education) the instance is annotated with the category.Otherwise, it is annotated with an eight category, other.</p>
<p>For each goal in COPLAN, each (verb, noun) unigram or (nominal) bigram casts a category as a vote if found in the annotated data.If not found, then it casts other as vote.Majority vote is taken as the category of the larger goal statement.</p>
<p>Figure 5 shows the distribution of the activity types in COPLAN.Education is the largest category ("join an online course to learn a new language") followed by self-improvement ("develop my creative writing skills").Service ("cooking meals for a homeless shelter"), career ("get interview for a new job"), and financial ("upgrade to a new car") are the next largest categories.The other category includes miscellaneous activies like chores and events like "vaccuum the livingroom floor".</p>
<p>A.2 CONDITION DIVERSITY</p>
<p>We assess the diversity of the conditions in COPLAN by analyzing the verbal use and nominal trigrams employed in the statements.</p>
<p>We manually analyze 20 most frequent verbs and phrasal verbs (e.g., "have access") appearing in the condition statements.The verbs are grouped into 5 semantic categories: (1) want (to want, to desire, etc); ( 2) possess (to have, to possess, etc); (3) access (to obtain, to get, to procure etc); ( 4) able (to be able to, be capable of, etc); and ( 5) trust (to be safe, to rely, etc).Note that each of these categories include conditions of both polarity; for example, for possess, it includes both the condition imposed by having ("have enough money") and by lacking ("not have enough money").A sixth category, other, was included for the verbs not included in the above categories.For each condition in COPLAN, the first trigram made up of verbs, adjectives, and nouns appearing after the main verb (e.g., "If you want to [apply to an online program]" -&gt; main verb: want, trigram: apply online program) were extracted.Trigrams were then associated with each of the 5 semantic categories based on the main verb.</p>
<p>Figure 6 shows the most frequent unique trigrams in each category.The graph includes the 20 most frequent trigrams for each category.The displayed trigrams were manually clustered when appropriate for readability purposes (e.g., "take course online" clustered with "take online course").</p>
<p>We find a wide variety of real-world constraints that pose varying levels of restriction such as preference and desire ("want to take an online course") and hindrances posed by the state of having or not having something ("not having enough money" or "having a disability").</p>
<p>B ADDITIONAL EXPERIMENTAL DETAILS B.1 CRITIC MODELS: COLLECTING HUMAN ANNOTATIONS</p>
<p>We gather human annotations of valid vs. invalid teacher generations.Annotations are crowdsourced through the Amazon Mechanical Turk (AMT) platform.We qualify 263 best performing workers through a paid qualification round.Additionally, we chose annotators among those who were located in US, GB and CA, and had 98% approval rate for at least 10,000 previous annotations.Crowdworker compensation for qualification and annotation HITs is maintained at an average of $15 per hour.</p>
<p>Plans.For plans, the crowdworkers were presented with randomly-sampled 13K generated (goal, plan) pairs, and were asked to evaluate the plans along three dimensions: topicality-the topic of the plan is relevant and appropriate for the goal, ordering-the steps in the plan are appropriately ordered, and completeness-the plan provides complete and informative steps to achieve the goal.We asked the workers to evaluate the goal's achievability as a separate (fourth) dimension.Each dimension was rated on a 5-point likert scale with three valid labels (Definitely, Mostly, and Somewhat; numeric value 1) and two invalid labels (Hardly, Not at all; numeric value 0).Each (goal, plan) pairs were annotated by three crowdworkers.The template used is shown in Figure 10.</p>
<p>We determine the validity of a (goal, plan) pair in the following manner.We then calculate the mean score (over the three annotator responses) for each of the dimensions.A (goal, plan) pair is considered valid only if: (1) it receives a score greater than 0.25 for each of the achievablility, topicality, or ordering dimensions, and (2) receives a scores greater or equal to 0.65 on the completeness dimension.Failing that, a pair is considered invalid.</p>
<p>Conditions.For conditions, we collect human judgements on whether the condition makes the goal more specific or harder to achieve (but not impossible) on a randomly-sampled set of 6100 generated tuples of (goal, plan, condition).We include screenshot of our annotation template in Figure 11.Counterfactual Plans.And finally, for counterfactual plans, we collect 10.5K human judgements on whether the modified plan contain all the necessary steps to make the goal achievable while adhering to the condition.We include screenshot of our annotation template in Figure 12.</p>
<p>B.2 CRITIC MODELS: TRAINING DETAILS</p>
<p>We train 3 binary classifiers (critics) for filtering out low quality teacher generations in §2.1 using pre-trained RoBERTa-Large Liu et al. (2019a).We conduct a small grid search on validation loss for batch size bs = {16, 32, 64} and learning rate lr = {1e − 4, 1e − 5, 1e − 6, 5e − 6}.We report the effective hyper-parameters for each critic in Table 5.We use early stopping on validation loss.</p>
<p>B.3 TRAINING THE VERIFIER</p>
<p>Constructing Pseudo-negative Examples.For training the step verifier, we use the human-written plans Sakaguchi et al. (2021) to construct positive examples of (plan-so-far, next-step) pairs and devise three main perturbation strategies to automatically construct negative examples as explained below:</p>
<p>• Reordered Steps: Conflicting logical order results from inaccurate causal or temporal dependencies in a plan.Thus, we apply both near and distant reordering by randomly reordering two consecutive and two distant steps.• Repetitive Steps: Degeneration i.e., generating repetitive text is commonly observed in language models.Similarly, we include both near and distant repetition by repeating the immediate previous step and distant previous step as a pseudo-negative next-step.• Missing Steps: Another common mistake made by language models is missing necessary steps, leading to incoherent plans.To simulate this behaviour, we randomly select a non-immediate step as a pseudo-negative next-step.</p>
<p>We collect a training set of 47k positive and negative pairs of (plan-so-far, next-step) using only 3k human-written plans.</p>
<p>Training Details.We fine-tune RoBERTa Large Liu et al. (2019a) as a binary classifier identifying the validity of a candidate next-step.We train for 10 epochs with early stopping on validation accuracy using batch size of 32 and learning rate of 1e − 5.  GPT-3 (from (Collins et al., 2022)) 36</p>
<p>GPT-3 zero shot 64</p>
<p>Table 12: Percent of generated counterfactual plans which have been rated as good by annotators.</p>
<p>one of which involved constrained planning.For a given goal and one or more conditions, the task is to generate a plan.We evaluate PLASMA on the 28 constrained goals provided by the paper.We compare our generations to the GPT-generated plans provided by the paper and text-davinci-002 prompted in a zero shot manner.</p>
<p>To evaluate the generations we perform a human evaluation, as described in §D.3.</p>
<p>The human evaluation results in Table 12 show that PLASMA outperforms the other baselines in this out-ofdomain subset of counterfactual planning task.</p>
<p>D EVALUATION DETAILS D.1 AUTOMATIC EVALUATION</p>
<p>We report automatic evaluation of models for the original planning task in Table 7.Note that humanwritten plans are not the only possible plans, hence these automatic metrics may not provide an Table 7: Automatic Evaluation Results for the Planning task.Note that the human-written plans are not the only possible plans, hence these automatic metrics may not provide an informative measure of performance.</p>
<p>informative measure of performance.To further verify this, we computed the correlation between the most commonly used BLEU score and human scores.We find that BLEU has very weak correlations to human scores of coverage, ordering an overall quality, with a Pearson correlation of 7.7%, 5.9%, and 5.6%.</p>
<p>D.2 CONFIDENCE INTERVALS</p>
<p>We provide the 95% confidence intervals for our main results on goal-based (Table 13) and constrained and counterfactual (re)planning (Figure 9).</p>
<p>D.3 HUMAN EVALUATION ON AMT</p>
<p>All human evaluations were conducted on the Amazon Mechanical Turk (AMT).We sourced our annotators from the same pool of qualified workers (see B.1).Throughout the entirety project, we maintained an average of $15/hour pay rate based on our estimation of time needed to complete the task.Each examples were annotated by 3 workers and majority vote was taken for the reported results.The layout templates for evaluating plans and counterfactual plans are shown in Figures 10  and 12, respectively.</p>
<p>E EXPERIMENTAL DETAILS OF VIRTUALHOME EVALUATION</p>
<p>We follow the same experimental setup and metrics for evaluation as Planner Huang et al. (2022).</p>
<p>The test set consists of 88 high-level goals.To translate a generated natural language step into an executable step, we follow Huang et al. (2022) and find an executable action closest in embedding space to the generated step.To compute these embeddings, we use the stsb-roberta-large model.Executability and LCS are computed identical to Huang et al. (2022).Due to challenges with reproducibility of GPT-3 outputs, evaluation results of GPT-3 do not exactly match between our works.</p>
<p>Note that the previous method (Huang et al., 2022) involves extracting the most relevant (in-domain) human-annotated examples by matching goals (Make breakfast ⟨-⟩ Make toast) as well as sampling LLMs several times for each step and ranking them.</p>
<p>Model Plan</p>
<p>Goal: put coffee in coffee machine</p>
<p>Curie (Teacher)</p>
<p>Step 1: find coffee machine</p>
<p>F COMPARISON WITH GPT-4</p>
<p>It is noteworthy to mention that the planning subset of COPLAN is collected from the smaller GPT model (as teacher), i.e., text-curie-001 which is significantly less powerful that the most recent GPT-4 model.Nonetheless, we conduct a comparison of our best goal-based PLASMA model (11B PLASMA-Mul+) with its teacher, GPT-312 and GPT-4 in few-shot setting on 50 instances (total of 200).Results are shown in Table 14.As we observe, the trend remains the same as in Table 1, with GPT-4 slightly surpassing its predecessor (text-davinci-003) only in the ordering dimension.</p>
<p>Published as a conference paper at ICLR 2024 Type Conditional Plan good Goal: eat ice cream if you have an ice cream maker</p>
<p>Step 1: Decide to eat ice cream</p>
<p>Step 2: Locate the ice cream maker</p>
<p>Step 3: Turn on the ice cream maker</p>
<p>Step 4: Add ingredients to the ice cream maker</p>
<p>Step 5: Follow the instructions to churn the ice cream</p>
<p>Step 6: Remove the ice cream from the ice cream maker</p>
<p>Step 7: Put the ice cream in a bowl</p>
<p>Step 8: Eat ice cream good Goal: brush all teeth if you are out of toothpaste</p>
<p>Step 1: Decided to brush all teeth</p>
<p>Step 2: Locate a store that sells toothpaste</p>
<p>Step 3: Purchase toothpaste</p>
<p>Step 4: Drive to the store</p>
<p>Step 5: Purchase toothpaste</p>
<p>Step 6: Drive back home</p>
<p>Step 7: Unpack the toothpaste</p>
<p>Step 8: Open the toothpaste</p>
<p>Step 9: Brush all teeth bad Goal: write names on the cards if you have a shaky hand</p>
<p>Step 1: find a pen or pencil with a large tip</p>
<p>Step 2: hold the pen or pencil in one hand</p>
<p>Step 3: hold the pen or pencil in the other hand</p>
<p>Step 4: use a pen or pencil to write the names on the cards</p>
<p>Step 5: once the names are on the cards, place them in a drawer or file</p>
<p>Step 6: close the drawer or file</p>
<p>Step 7: write names on the cards bad Goal: walk into town if you have a disability that limits your mobility</p>
<p>Step 1: Decide to walk into town</p>
<p>Step 2: Put on shoes</p>
<p>Step 3: Get a cane or other mobility aid if necessary</p>
<p>Step 4: Put the cane or other mobility aid in a backpack</p>
<p>Step 5: Put the backpack on</p>
<p>Step 6: Leave the house</p>
<p>Step 7: Walk to the bus stop</p>
<p>Step 8: Take the bus into town</p>
<p>Step 9: Walk into town</p>
<p>G COMPLEXITY AND DIVERSITY ANALYSIS OF STUDIED DATASETS</p>
<p>We analyze the complexity of proScript and CoPlan from several dimensions:</p>
<p>• Lexical diversity: We use generally accepted measures (Gehrmann et al., 2021) to analyze the diversity of datasets.We compute 1/2/3-gram entropy and the mean segmented token type ratio (MSTTR).To establish a comparison, we compute these values for three other datasets: XSUM (extreme summarization of news articles), DialogSum (real-life scenario dialogue summarization), and TinyStories.These have been specifically picked as they are stylistically different from our goal and script setup, and they often contain longer more natural sentences.In the characteristics of news and more formal text.We also note that the machine-generated CoPlan exhibits slightly higher lexical diversity than the human-written proScript.• Perplexity of an LM: We also report the perplexity of an off-the-shelf language model which measures the degree of uncertainty (surprise) of an LM when it generates the next tokens.The higher the perplexity, the more surprised the LM is.As we see from the last column, with the exception of XSUM, the remaining datasets exhibit comparable perplexity scores.The higher perplexity in the case of XSUM is, again, attributed to its association with the news domain, a distinct characteristic compared to the other datasets, which predominantly encompass everyday scenarios.Also note that, LMs generally have lower perplexity scores on machine-generated data (as seen for CoPlan vs proScript).</p>
<p>Overlapping of the plans.We additionally analyze the amount of overlap between the steps in the train and test set.To this end, we identify the direct noun object of a given goal (e.g., "Carry [a plate] to the kitchen") and remove it from the goal (i.e., "Carry to the kitchen") as well as all the steps in the corresponding plan (e.g., "Pick up the plate" -&gt; "Pick up".We then concatenate each goal with individual steps (i.e., "Carry to the kitchen.Pick up.") and measure the maximum longest subsequence match of goal+step in the test set over all goal+step in the train set.</p>
<p>In the ProScript dataset, we find that only 4.3% of steps in the test set have exact overlap with steps in the train set.If we relax the overlap to 90% and 80% (as opposed to an exact 100% overlap), this number increases to 5.5% and 10%, respectively.If the same is computed for plan overlap (as opposed to the step level; i.e., the direct object removed goal and plan-not individual steps-are concatenated), we observe 0% overlap.</p>
<p>In the COPLAN dataset, commuting overlap w.r.t full train set is still in progress (due to its large scale).However, on a randomly sampled 10K instances from the train set, the numbers are 1.8%, 2%, 3.3% for exact, 90% and 80% overlap, respectively.And 0% for plan overlap.</p>
<p>This suggests that differences in the object taken by the verb do not necessarily mean minimal changes to the plan.Intuitively speaking, this is sensical: changes in the direct object, in the real world, should affect the way we resolve a goal.For example, what extra steps we take (e.g., stack plates, but not mugs), the final goal location of the item (e.g., kitchen sink for plates, but the fridge for apples), or the manner of carrying (e.g., glasses vs. boxes) will affect the steps we take in a plan even if the goal is constant (i.e."Carry X to the kitchen").This is even more pronounced in CoPlan as it contains a broad set of everyday human goals (see Appendix A) which can lead to vastly distinct plans even when the event (verb) itself is the same.While learning is learning, the differences between the path taken to "Learn to play a violin" vs. "Learn to play Monopoly" vs. "Learn to speak Spanish fluently" are non-trivially different.</p>
<p>H DISCUSSION</p>
<p>On the importance of Distillation.Finetuning LLMs requires updating models' parameters which is not only costly but often inaccessible for the broader community.Reducing the scale and cost of strong models via teacher distillation is the key to developing open-sourced LMs that are accessible to all, facilitating fine-tuning and seamless adaptation to various domains and custom use cases.Given the large-scale training dataset used for PlaSma, we hope it can serve as a foundation model that  can be quickly adapted to specific domains with minimal additional annotation (like we demonstrate by adapting Plasma to VirtualHome).Moreover, we could not augment most of the LLMs with our decoding-time algorithm due to limited access to the model's log probabilities.</p>
<p>Example Template:</p>
<p>Given a goal write down a list of steps to achieve the goal:</p>
<p>Goal: take a nap on the bed</p>
<p>Step 1: sit on the bed for a little</p>
<p>Step 2: pull back the blanket</p>
<p>Step 3: pull back the sheet</p>
<p>Step 4: fluff up the pillow</p>
<p>Step 5: lay down on the bed</p>
<p>Step 6: fall asleep on the bed</p>
<p>Step 7: take a nap on the bed ...</p>
<p>Goal: hire a dog walker</p>
<p>Step 1:</p>
<p>Prompt Prefix Generator: def generate_prompt_prefix(): w1_list = ["For a given goal", "Given a goal"] w2_list = ["write down", "break down into", "put down" "jot down"] w3_list = ["steps", "subgoals", "a list of steps", "several steps", "several subgoals", " some steps", "some small steps"] w4_list = ["to achieve the goal", "for achieving the goal", "to attain the goal"]  What is a specification that might affect the plan above?</p>
<p>If you want to use compost for soil.</p>
<p>… x 3</p>
<p>You want to print the report.How do you do this in 7 steps?</p>
<p>step 1: type the edited draft; step 2: save the edited draft;</p>
<p>step 3: open the file menu in the word processor; step 4: select print from the file menu; step 5: select printer settings;</p>
<p>step 6: send document to the printer; step 7: print the report What is the hindrance that might affect the plan above?</p>
<p>Prompt Template (Counterfactual Plan)</p>
<p>You want to learn how to swim.How can you do this in 7</p>
<p>Steps?</p>
<p>Step</p>
<p>Figure 1: Symbolic Procedural Knowledge Distillation.</p>
<p>Figure 2 :
2
Figure 2: Verifier-guided Step-wise Beam Search.For brevity, we only showcase with N = 5 and K = 2 for the first step and N = 4 and K = 2 for the second step.The scores are for illustration.</p>
<p>Figure 3 :
3
Figure 3: Bridging the scale gap in goal-based planning.Smaller models are able to achieve comparable performance and sometimes surpass larger models via multi-tasking and guided decoding.</p>
<p>Figure 5 :
5
Figure 5: Goal diversity in COPLAN Figure 6: Condition diversity in COPLAN</p>
<p>Step 2: unlock coffee machine Step 3: put coffee in coffee machine Step 4: close coffee machine Step 5: wait a few minutes Step 6: coffee should be ready Step 1: get coffee Step 2: put coffee in coffee machine Step 3: turn on coffee machineStep 4: wait for coffee to brew Step 5: drink coffee PLASMA-Mul+ (11B) Step 1: buy coffee beans Step 2: grind the coffee beans Step 3: put the ground coffee into the coffee filter Step 4: put the filter into the machine Step 5: turn the machine on Step 6: wait for the coffee to brew Step 7: enjoy your coffee Goal: put on baseball jersey Curie (Teacher) Step 1: get baseball jersey Step 2: put baseball jersey on Step 3: take baseball jersey off PLASMA (11B) Step 1: find a baseball jersey Step 2: put on baseball jersey Step 3: take off baseball jersey Step 4: put on another baseball jersey Step 5: take off second baseball jersey Step 6: put on third baseball jersey Step 7: put on fourth baseball jersey PLASMA+ (11B) Step 1: walk to closet Step 2: open closet Step 3: look for baseball jersey Step 4: find baseball jersey Step 5: take baseball jersey out of closet Step 6: put on baseball jersey Goal: sit at the</p>
<p>get in the car Step 2: drive to the dental office Step 3: park the car Step 4: go inside the office Step 5: pay the bill Step 6: get a receipt Step 7: brush all teeth Step 8: leave office PLASMA (770M) Step 1: Get toothbrush Step 2: Get toothpaste Step 3: Get toothbrush Step 4: Get toothbrush Step 5: Get toothbrush Step 6: Get toothbrush Step 7: Brush all teeth PLASMA+ (770M) Step 1: Get toothbrush Step 2: Get toothpaste Step 3: Put toothpaste on toothbrush Step 4: Grab toothbrush Step 5: Hold toothbrush up to mouth Step 6: Brush all teeth</p>
<p>that sells videogames &gt; Go to the store &gt; Find the videogame you want to buy &gt; Buy the videogame &gt; Take the videogame home &gt; Play the videogame If the game store is too far away Decide to buy a new videogame &gt; Research online game stores &gt; Compare prices and reviews &gt; Select the game to buy &gt; Purchase the game online &gt; Wait for the game to be delivered &gt; Buy a new videogame Decided to buy a new videogame &gt; Decide on game &gt; Get into car &gt; Drive to game store &gt; Walk into game store &gt; Find the desired game &gt; Buy a new videogame Decided to buy a new videogame &gt; Decide on game &gt; Search for the game online &gt; Compare prices online &gt; Purchase the game online &gt; Wait for the game to be delivered &gt; Unbox the game &gt; Play the game &gt; Enjoy the game Eat some ice cream from an ice cream shop Find ice cream shop &gt; Enter ice cream shop &gt; Find ice cream &gt; Choose ice cream &gt; Eat ice cream If you have allergies to dairy products Decide to eat some ice cream from an ice cream shop &gt; Find an ice cream shop &gt; Walk into ice cream shop &gt; Ask for a dairy-free ice cream &gt; Pick out ice cream &gt; Pay for ice cream &gt; Eat some ice cream from an ice cream shop Decided to eat some ice cream from an ice cream shop &gt; Decide to eat ice cream &gt; Gather the family &gt; Drive to ice cram parlor &gt; Get family out and lock car &gt; Walk in ice cream shop and sit &gt; Eat some ice cream from an ice cream shop Decide to eat some ice cream from an ice cream shop &gt; Research ice cream shops in your area that offer dairy-free options &gt; Gather the family &gt; Drive to ice cream parlor &gt; Get family out and lock car &gt; Walk in ice cream shop and sit &gt; Ask the staff about their dairy-free options &gt; Select a dairy-free option &gt; Eat some ice cream from an ice cream shop get extra exercise Set a goal for how many hours a week you want to exercise &gt; Research different types of exercise &gt; Choose one type of exercise to start with &gt; Make a plan to follow the exercise plan &gt; Start exercising &gt; Keep exercising If the fitness activity presents a risk of injury Decide what type of exercise you would like to do &gt; Research the activity to make sure you understand the risks and benefits &gt; Consult with a medical professional to ensure the activity is safe for you &gt; Find a place to do the activity &gt; Set a goal for how often you would like to do the activity &gt; Start doing the activity &gt; Monitor your progress and adjust the activity as needed &gt; Get extra exercise Decided to get extra exercise &gt; Open the calendar &gt; Identify open time slots during the week &gt; Schedule a fitness activity during free time &gt; Set reminder for activity on phone &gt; Attend weekly fitness activity &gt; Get extra exercise Decide to get extra exercise &gt; Open the calendar &gt; Identify open time slots during the week &gt; Research and select a fitness activity that presents a low risk of injury &gt; Schedule the fitness activity during free time &gt; Set reminder for activity on phone &gt; Attend weekly fitness activity &gt; Get extra exercise chop the wood Get a chopping block &gt; Get a chopping knife &gt; Chop the wood &gt; Clean the chopping block &gt; Put the chopping block away If you have a chainsaw Pick up the wood &gt; Place the wood on the ground &gt; Set up the chainsaw &gt; Sharpen the chainsaw &gt; Start the chainsaw &gt; Cut the wood &gt; Chop the wood Pick up axe &gt; Pick up a piece of wood &gt; Check the condition of wood &gt; Make sure wood is dry enough &gt; Set the wood upright &gt; Swing the axe at wood &gt; Chop the wood Pick up the chainsaw &gt; Pick up a piece of wood &gt; Check the condition of wood &gt; Make sure wood is dry enough &gt; Set the wood upright &gt; Start the chainsaw &gt; Guide the chainsaw along the wood &gt; Chop the wood</p>
<p>w1 = random.sample(w1_list,1)[0] w2 = random.sample(w2_list,1)[0] w3 = random.sample(w3_list,1)[0] w4 = random.sample(w4_list,1)[0] prompt_prefix = f"{w1}, {w2} {w3} {w4}.\n\n"return prompt_prefix</p>
<p>Figure 7 :
7
Figure 7: Randomize prompt template for eliciting plans.</p>
<p>1: Decided to learn how to swim; Step 2: Find swimming instructor; Step 3: Travel to pool; Step4: Meet swimming teacher; Step 5: Practice swimming during classes; Step 6: Review mistakes with teacher until right; Step 7: Learn how to swim.You want to learn how to swim.How can you do this in several steps if you forget your swimsuit?Step 1: Decided to learn how to swim; Step 2: Find swimming instructor; Step 3: Travel to pool; Step4: Meet swimming teacher; Step 5: If you have forgotten your swimsuit, ask the instructor if it is possible to borrow one or if there is a place where you can purchase one; Step 6: Practice swimming during classes; Step 7: Review mistakes with teacher until right; Step 8: Learn how to swim … x 3You want to pick up pen.How can you do this in 6 steps?step 1: look for a pen; step 2: find a pen; step 3: walk over to pen; step 4: extend hand out to pen; step 5: reach for pen; step 6: pick up pen You want to pick up pen.How can you do this in several steps if you want to pick up the pen from a high shelf?</p>
<p>Figure 8 :
8
Figure 8: Prompt templates for acquiring Conditions and Counterfactual Plans.</p>
<p>Figure 9 :
9
Figure9: Human evaluation of constrained and counterfactual (re)planning tasks.We report the proportion of plans labeled as "Good" by annotators along with 95% confidence intervals.Applying statistical tests (t-test) indicates a significant difference between all PLASMA variants and Curie (p &lt; 0.01) as well as a significant difference between students of different sizes (p &lt; 0.05).No statistical significance was found between variants w/ or wo/ multitasking as well as between our best PLASMA and ×16 larger text-davinci-003.</p>
<p>Figure 11 :
11
Figure 11: AMT template for assessing validity of conditions for critic model training.</p>
<p>Figure 12 :
12
Figure 12: AMT human evaluation template for counterfactual re-planning.We use a similar layout for counterfactual planning task only removing the initial plan.</p>
<p>Table 1 :
1
Averaged 5-point Likert scale human evaluation for the goal-based planning.Small students paired with our decoding algorithm consistently outperform their teacher (text-curie-001) and are competitive with order of magnitude larger models in zero/few-shot settings.
ModelsizeCoverage OrderOverall QualityPLASMA3.183.643.17Distilled 770MPLASMA+4.254.554.28PLASMA-Mul2.843.362.85PLASMA-Mul+4.164.484.23PLASMA3.784.073.83Distilled 3BPLASMA+4.384.604.35PLASMA-Mul3.964.354.03PLASMA-Mul+4.294.624.33PLASMA4.014.334.03Distilled 11BPLASMA+4.334.604.39PLASMA-Mul4.244.594.28PLASMA-Mul+4.534.774.58Curie (Teacher)few-shot (5)3.754.273.75Davinci (175B)zero-shot few-shot (5)4.83 4.884.87 4.904.84 4.90COCOGEN (175B) few-shot (16)4.484.704.55Human4.564.614.57
(Madaan et al., 2022)., 2022)is a 16-shot baseline using code LLM.</p>
<p>Table 2 :
2
Effect of symbolic knowledge distillation.The model trained on our COPLAN dataset transfers better to other dataset, ProScript.
Test on →ProScriptCOPLANOverallOverallTrain on ↓ Coverage OrderCoverage OrderQualityQualityProScript4.474.684.514.514.814.58COPLAN4.584.784.734.724.864.73Mix4.824.834.834.774.884.78</p>
<p>Table 3 :
3modelExecutabilityLCSCorrectness(%)(%)(%)Planner (175B) (Huang et al., 2022)77.1719.1018.33PLASMA-Mul F T (11B)76.3828.3641.38PLASMA-Mul+ F T (11B)94.1831.9343.68Human100N/A66.66
(Puig et al., 2018)rectness along with (automatic) executability and Longest-common subsequence (LCS) scores on VirtualHome(Puig et al., 2018).Steps generated by our model are more executable and correct for accomplishing the task.</p>
<p>Table 4 :
4
(Wanzare et al., 2016)5a)nstrained planning and Counterfactual replanning tasks.More examples are provided in Appendix Table15.Procedural Planning The problem of planning to accomplish a goal via sub-steps is widely studied in two contexts.One is script knowledge generation, which is a long-standing NLP problem(Schank &amp; Abelson, 1975a).Collecting script knowledge requires either human annotation(Wanzare et al., 2016), unsupervised feature-based extraction
GoalConditionInitial PlanGenerated (Counterfactual) PlanEmpty lint filterFind lint filter &gt; Remove lint filter &gt; Clean lint filter &gt;Replace lint filterIf the lint trap isUnplug dryer &gt; Open dryer &gt; Locate lint trap &gt; Use heat-too hot to touchresistant glove or mitt to pick up lint trap &gt; Pull lint trapout of dryer &gt; Empty lint trapLoad clothes into dryer &gt; Locate lint trap &gt; MoveLoad clothes into dryer &gt; Locate lint trap &gt; Use glovedhand towards lint trap &gt; Grip lint trap with fin-hand to move hand toward lint trap &gt; Grip lint trap withgers &gt; Pull lint trap out of dryer &gt; Use other handfingers &gt; Use other hand to lift lint from lint trap &gt; Removeto lift lint from lint trap &gt; Empty lint filterlint trap from dryer4 RELATED WORKS</p>
<p>, Appendix B, and E. Additionally, instruction for collecting COPLAN and human evaluations are provided in §2.1 and Appendix D.3.Kevin Yang and Dan Klein.FUDGE: Controlled text generation with future discriminators.In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.Association for Computational Linguistics, 2021.doi: 10.18653/v1/2021.naacl-main.276.URL https://doi.org/10.18653.
SUPPLEMENTARY MATERIALA COPLAN ANALYSIS DETAILSSiyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Jankowski, Yanghua A.1 GOAL DIVERSITYXiao, and Deqing Yang. Distilling script knowledge from large language models for constrainedlanguage planning. In Proceedings of the 61st Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pp. 4303-4325, Toronto, Canada, July 2023. Association for FitnessComputational Linguistics. URL https://aclanthology.org/2023.acl-long.236. 3%Social5%Financial Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evaluating Education 21%text generation with BERT. In 8th International Conference on Learning Representations, ICLR 8%2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id=SkeHuCVFDr. Career9%Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge forlarge-scale task planning, 2023.OtherService20%14%Self-Improvement20%</p>
<p>Table 5 :
5
Hyper-parameter values for training different critic models.</p>
<p>Table 6 :
6
Examples for different categories of conditions in COPLAN dataset.
Model% goodPLASMA71
Collins et al. (2022)ATIONCollins et al. (2022)proposed two out-of-distribution reasoning tasks to evaluate LLMs,</p>
<p>table with dinner date Curie (Teacher) Step 1: text or call the person to let them know that you will be late Step 2: arrive at the restaurant on time Step 3: take a seat at the table Step 4: wait for the other person to arrive Step 5: eat dinner Step 6: say goodbye and thank you</p>
<p>PLASMA (3B)Step 1: find dinner date Step 2: go to dinner date's house Step 3: sit at the table Step 4: talk to dinner date Step 5: eat dinner Step 6: leave dinner date's house PLASMA+ (3B) Step 1: choose a restaurant Step 2: make a reservation Step 3: drive to the restaurant Step 4: park the car Step 5: enter the restaurant Step 6: find a seat Step 7: sit at the table with dinner date</p>
<p>Table 8 :
8
Qualitative examples generated by different models for the goal-based planning task.</p>
<p>Table 9 :
9
Qualitative examples of the constrained planning task.
TypeOriginal PlanCounterfactual PlangoodGoal: empty lint filter Step 1: load clothes into dryer Step 2: locate lint trap Step 3: move hand towards lint trap Step 4: grip lint trap with fingers Step 5: pull lint trap out of dryer Step 6: use other hand to lift lint from lint trap Step 7: empty lint filterGoal: empty lint filter if the lint trap is too hot to touch Step 1: Load clothes into dryer Step 2: Locate lint trap Step 3: Move hand towards lint trap Step 4: Use a heat-resistant glove to grip lint trap with fingers Step 5: Pull lint trap out of dryer Step 6: Use other hand to lift lint from lint trap Step 7: Empty lint filterGoal: take a shower after work if you want toGoal: take a shower after worktake a shower at the gymStep 1: decided to take a shower after workStep 1: Decide to take a shower after workStep 2: drive home from workStep 2: Drive to gymgoodStep 3: go to bath room Step 4: take off clothesStep 3: Go to locker room Step 4: Remove clothesStep 5: start water to get heatStep 5: Enter shower roomStep 6: take hot showerStep 6: Start water to get heatStep 7: take a shower after workStep 7: Take hot showerStep 8: Take a shower after workGoal: empty old left overs from the fridgeif you have difficulty bending downGoal: empty old left overs from the fridgeStep 1: go through the houseStep 1: go through the houseStep 2: walk into the kitchenStep 2: walk into the kitchenStep 3: locate the refridgeratorbadStep 3: locate the refridgerator Step 4: walk to the refridgeratorStep 4: walk to the refridgerator Step 5: grab a chair or stoolStep 5: grab the door handleStep 6: place the chair or stool in frontStep 6: open the refrigerator doorof the refrigeratorStep 7: empty old left overs from the fridgeStep 7: use the chair or stool to openthe refrigerator doorStep 8: empty old left overs from the fridgebadGoal: buy a new watch Step 1: decided to buy a new watch Step 2: search the internet for watch retailers Step 3: pick a reliable retailer Step 4: search the retailer site for watches Step 5: add watch to cart Step 6: click check out Step 7: add payment information Step 8: add address information Step 9: buy a new watchGoal: buy a new watch if your payment information is compromised Step 1: decide to buy a new watch Step 2: search the internet for watch retailers Step 3: pick a reliable retailer Step 4: search the retailer site for watches Step 5: add watch to cart Step 6: click check out Step 7: add payment information Step 8: verify payment information Step 9: buy a new watch</p>
<p>Table 10 :
10
Qualitative examples of the counterfactual re-planning task.
Constrained PlanningCounterfactual ReplanningError TypeEdits RequiredMissing stepsUnnecessary stepsEdits RequiredMissing stepsUnnecessary stepsPlasma+ (3B)4.668.333.6613.3319.336.00Plasma-Mul+ (3B)4.337.663.6610.6614.664.33Plasma+ (11B)3.665.003.334.6610.003.33Plasma-Mul+ (11B)3.003.333.666.0011.664.66curie-001 zero-shot7.0027.006.6626.0049.3313.66curie-001 few-shot6.0025.335.0030.0048.0013.33davinci-003 zero-shot1.336.330.665.337.332.66davinci-003 few-shot1.333.000.664.338.662.66</p>
<p>Table 11 :
11
Percent of generated (counterfactual) plans with each error type."Missing Steps" is the most common error types across all models.
ModelsizeOverall Quality 95% CIDistilled 770M</p>
<p>Table 13 :
13
Averaged 5-point human 'quality ratings' for original planning along with 95% Confidence Intervals.</p>
<p>Table 16, we observe that even though the goals and steps in our dataset are shorter, the overall lexical diversity of proScript and Coplan are comparable with other datasets.XSUM displays a higher MSTTR score, but this is likely attributed to
Coverage OrderOverallQualityPLASMA-Mul+ (11B)4.314.684.23Curie (teacher)3.534.373.58GPT-3.5 (Davinci-003)4.784.844.81GPT-44.785.004.81Table 14: Comparison of our best goal-based PLASMA model with its teacher, GPT-3.5 and GPT-4 infewshot setting.</p>
<p>Table 15 :
15
Additional PLASMA generations for constrained planning and counterfactual replanning tasks.</p>
<p>These values are for plan, condition and counterfactual plans, respectively.
In total, we automatically create 47K +/-pairs of (plan-so-far, next-step) using 3K human-written plans.
In our preliminary experiment, we found text-davinci-003 (the strongest GPT-3 version at the time) to be helpful for the more challenging counterfactual data collection.
Pairwise annotator agreements (i.e., how often do two annotators agree on the answer) are 0.78, 0.84, and 0.80 for coverage, order and overall quality, respectively.
We performed a hyperparameter search over α = {0.5, 0.75, 0.8}.
Example: addressing the condition "you have no money" with adding a step "find money" in the plan.
Pairwise annotator agreements are 0.96 and 0.94 for constrained and counterfactual (re)planning.
Results with 95% confidence intervals are reported in the Appendix Table13 and Figure 9.
https://www.bls.gov/news.release/atus.t12.htm defines 11 categories to cover common everyday civilian activities. We cluster these categories into five.
 text-davinci-003 <br />
ACKNOWLEDGEMENTSThis work was funded in part by the DARPA MCS program through NIWC Pacific (N66001-19-2-4031), and the Allen Institute for AI.We thank the Beaker Team at the Allen Institute for AI for helping with the compute infrastructure, OpenAI for providing access to the GPT-3 API, and the anonymous reviewers for the helpful discussions."Symbolic" AI vs. "Symbolic" Knowledge Distillation.We would like to draw attention to the evolving use of the term "symbolic" within the contemporary AI community, particularly in the context of natural language.It is important to note that the term "symbolic" has acquired multiple connotations, and its modern usage may differ from its original application in symbolic AI(Kambhampati et al., 2021).In our case, "Symbolic" (in symbolic knowledge distillation) refers to human-readable textual formats(West et al., 2022)rather than the transfer of obscure/soft model weights as in standard distillation(Hinton et al., 2015).I EXTENDED RELATED WORKSBuilding Smaller Models.There is a recent line of work on building general-purpose small models for reasoning tasks such as Orca(Mukherjee et al., 2023).While our work shares a similar spirit with Orca, we find the key distinction in (1) our goal is to develop a specialized small model for procedural/counterfactual planning and replanning with potential application to an embodied domain, and (2) Orca is focused on learning from GPT-4 explanations (Chain of Thought) to improve models capabilities.Nonetheless, building specialized models on top of them can be explored in future works as we only worked on models that were accessible at the time of submission.Published as a conference paper at ICLR 2024 Figure10: AMT human evaluation template for the original planning task.For validation round we substituted goal achievability (is the goal achievable with appropriate steps?) for overall question (is the plan overall good?).
Anthony Michael Ahn, Noah Brohan, Yevgen Brown, Omar Chebotar, Byron Cortes, Chelsea David, Chuyuan Finn, Keerthana Fu, Karol Gopalakrishnan, Alex Hausman, Daniel Herzog, Jasmine Ho, Julian Hsu, Brian Ibarz, Alex Ichter, Eric Irpan, Rosario Jang, Kyle Jauregui Ruano, Sally Jeffrey, Nikhil Jesmonth, Ryan Joshi, Dmitry Julian, Yuheng Kalashnikov, Kuang-Huei Kuang, Sergey Lee, Yao Levine, Linda Lu, Carolina Luu, Peter Parada, Jornell Pastor, Kanishka Quiambao, Jarek Rao, Diego Rettinghouse, Pierre Reyes, Nicolas Sermanet, Clayton Sievers, Alexander Tan, Vincent Toshev, Fei Vanhoucke, Ted Xia, Peng Xiao, Sichun Xu, Mengyuan Xu, Andy Yan, Zeng, arXivpreprintarXiv:2204.01691Do as i can and not as i say: Grounding language in robotic affordances. 2022</p>
<p>On the dangers of stochastic parrots: Can language models be too big?. Emily M Bender, Timnit Gebru, Angelina Mcmillan-Major, Shmargaret Shmitchell, 10.1145/3442188.3445922Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21. the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21New York, NY, USAAssociation for Computing Machinery2021</p>
<p>I2d2: Inductive knowledge distillation with neurologic and self-imitation. Chandra Bhagavatula, Jena D Hwang, Doug Downey, Ronan Le Bras, Ximing Lu, Lianhui Qin, Keisuke Sakaguchi, Swabha Swayamdipta, Peter West, Yejin Choi, 2023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mccandlish, Alec Radford, Ilya Sutskever, Dario Amodei, Advances in Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M F Balcan, H Lin, Curran Associates, Inc202033</p>
<p>Unsupervised learning of narrative event chains. Nathanael Chambers, Dan Jurafsky, Proceedings of ACL-08: HLT. ACL-08: HLTColumbus, OhioAssociation for Computational LinguisticsJune 2008</p>
<p>Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks. Katherine M Collins, Catherine Wong, Jiahai Feng, Megan Wei, Josh Tenenbaum, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science Society202244</p>
<p>The GEM benchmark: Natural language generation, its evaluation and metrics. Sebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan Sasanka Ammanamanchi, Anuoluwapo Aremu, Antoine Bosselut, Raghavi Khyathi, Miruna-Adriana Chandu, Dipanjan Clinciu, Kaustubh Das, Wanyu Dhole, Esin Du, Ondřej Durmus, Chris Dušek, Varun Chinenye Emezue, Cristina Gangal, Tatsunori Garbacea, Yufang Hashimoto, Yacine Hou, Harsh Jernite, Yangfeng Jhamtani, Shailza Ji, Mihir Jolly, Dhruv Kale, Faisal Kumar, Aman Ladhak, Mounica Madaan, Khyati Maddela, Saad Mahajan, Mahamood, Prasad Bodhisattwa, Pedro Henrique Majumder, Angelina Martins, Simon Mcmillan-Major, Mille, Moin Emiel Van Miltenburg, Shashi Nadeem, Vitaly Narayan, Andre Nikolaev, Salomey Niyongabo Rubungo, Ankur Osei, Laura Parikh, Niranjan Perez-Beltrachini, Ramesh Rao, Vikas Raunak, Juan Diego Rodriguez, Sashank Santhanam, João Sedoc, Thibault Sellam, Samira Shaikh, Anastasia Shimorina, Marco Antonio Sobrevilla, Hendrik Cabezudo, Nishant Strobelt, Wei Subramani, Diyi Xu, Akhila Yang, Jiawei Yerukola, Zhou, 10.18653/v1/2021.gem-1.10Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021). Antoine Bosselut, Esin Durmus, Prashant Varun, Sebastian Gangal, Yacine Gehrmann, Laura Jernite, Samira Perez-Beltrachini, Wei Shaikh, Xu, the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)Association for Computational LinguisticsAugust 2021</p>
<p>Leveraging pretrained large language models to construct and utilize world models for model-based task planning. Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati, ArXiv, abs/1503.025312023. Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. 2015</p>
<p>Towards decoding as continuous optimisation in neural machine translation. Cong Duy, Vu Hoang, Gholamreza Haffari, Trevor Cohn, 10.18653/v1/D17-1014Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsSeptember 2017</p>
<p>Lexically constrained decoding for sequence generation using grid beam search. Chris Hokamp, Qun Liu, 10.18653/v1/P17-1141Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171</p>
<p>Language models as zeroshot planners: Extracting actionable knowledge for embodied agents. Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch, International Conference on Machine Learning, ICML 2022. Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, Sivan Sabato, Baltimore, Maryland, USAPMLRJuly 2022. 2022162of Proceedings of Machine Learning Research</p>
<p>Visually-grounded planning without vision: Language models infer detailed plans from high-level instructions. Peter Jansen, 10.18653/v1/2020.findings-emnlp.395Findings of the Association for Computational Linguistics: EMNLP 2020. OnlineNovember 2020Association for Computational Linguistics</p>
<p>Symbols as a lingua franca for bridging human-ai chasm for explainable and advisable ai systems. Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, Lin Guan, 2021</p>
<p>GeDi: Generative discriminator guided sequence generation. Ben Krause, Akhilesh Deepak Gotmare, Bryan Mccann, Nitish Shirish Keskar, Shafiq Joty, Richard Socher, Nazneen Fatema, Rajani , 10.18653/v1/2021.findings-emnlp.424Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational LinguisticsNovember 2021</p>
<p>Controlled text generation as continuous optimization with multiple constraints. Sachin Kumar, Eric Malmi, Aliaksei Severyn, Yulia Tsvetkov, Neural Information Processing Systems. Barcelona, SpainAssociation for Computational Linguistics2021. July 2004Text Summarization Branches Out</p>
<p>Roberta: A robustly optimized bert pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, ArXiv, abs/1907.116922019a</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019barXiv preprint</p>
<p>NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints. Ximing Lu, Peter West, Rowan Zellers, Le Ronan, Chandra Bras, Yejin Bhagavatula, Choi, 10.18653/v1/2021.naacl-main.339Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational LinguisticsJune 2021</p>
<p>NeuroLogic a*esque decoding: Constrained text generation with lookahead heuristics. Ximing Lu, Sean Welleck, Peter West, Liwei Jiang, Jungo Kasai, Daniel Khashabi, Le Ronan, Lianhui Bras, Youngjae Qin, Rowan Yu, Noah A Zellers, Yejin Smith, Choi, 10.18653/v1/2022.naacl-main.57Proceedings of the 2022 Conference of the North American Chapter. the 2022 Conference of the North American ChapterSeattle, United StatesAssociation for Computational LinguisticsJuly 2022a</p>
<p>Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp, 10.18653/v1/2022.acl-long.556Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational LinguisticsMay 2022b1</p>
<p>Neuro-symbolic procedural planning with commonsense prompting. Yujie Lu, Weixi Feng, Wanrong Zhu, Wenda Xu, Xin , Eric Wang, Miguel Eckstein, William Yang, Wang , The Eleventh International Conference on Learning Representations. 2023</p>
<p>Language models of code are few-shot commonsense learners. Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, Graham Neubig, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>Orca: Progressive learning from complex explanation traces of gpt-4. Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, Ahmed Awadallah, 2023</p>
<p>Openai api pricing. Openai, 2023</p>
<p>Bleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, 10.3115/1073083.1073135Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. the 40th Annual Meeting of the Association for Computational LinguisticsPhiladelphia, Pennsylvania, USAAssociation for Computational LinguisticsJuly 2002</p>
<p>Directed beam search: Plugand-play lexically constrained language generation. Damian Pascual, Béni Egressy, Florian Bolli, Roger Wattenhofer, ArXiv, abs/2012.154162020</p>
<p>Incremental learning of procedural planning knowledge in challenging environments. Douglas Pearson, John Laird, 10.1111/j.1467-8640.2005.00280.xComputational Intelligence. 212005</p>
<p>True few-shot learning with language models. Ethan Perez, Douwe Kiela, Kyunghyun Cho, NeurIPS. 2021</p>
<p>Virtualhome: Simulating household activities via programs. Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, Antonio Torralba, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2018</p>
<p>Back to the future: Unsupervised backprop-based decoding for counterfactual and abductive commonsense reasoning. Lianhui Qin, Vered Shwartz, Peter West, Chandra Bhagavatula, Jena D Hwang, Le Ronan, Antoine Bras, Yejin Bosselut, Choi, 10.18653/v1/2020.emnlp-main.58Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsNovember 2020</p>
<p>Cold decoding: Energy-based constrained text generation with langevin dynamics. Lianhui Qin, Sean Welleck, Daniel Khashabi, Yejin Choi, Advances in Neural Information Processing Systems. 2022</p>
<p>Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 211402020</p>
<p>proScript: Partially ordered scripts generation. Keisuke Sakaguchi, Chandra Bhagavatula, Le Ronan, Niket Bras, Peter Tandon, Yejin Clark, Choi, 10.18653/v1/2021.findings-emnlp.184Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational LinguisticsNovember 2021</p>
<p>What do large language models learn about scripts?. Abhilasha Sancheti, Rachel Rudinger, 10.18653/v1/2022.starsem-1.1Proceedings of the 11th Joint Conference on Lexical and Computational Semantics. the 11th Joint Conference on Lexical and Computational SemanticsSeattle, WashingtonAssociation for Computational LinguisticsJuly 2022</p>
<p>Scripts, plans and knowledge. Roger C Schank, Robert P Abelson, International Joint Conference on Artificial Intelligence. 1975a</p>
<p>Scripts, plans and knowledge. Roger C Schank, Robert P Abelson, Thinking: Readings in Cognitive Science, Proceedings of the Fourth International Joint Conference on Artificial Intelligence. Johnson-Laird Pn, Wason, Tbilisi, USSR1975b</p>
<p>Large language models still can't plan (a benchmark for llms on planning and reasoning about change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, 2023</p>
<p>A crowdsourced database of event sequence descriptions for the acquisition of high-quality script knowledge. D A Lilian, Alessandra Wanzare, Stefan Zarcone, Manfred Thater, Pinkal, Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16). the Tenth International Conference on Language Resources and Evaluation (LREC'16)Portorož, SloveniaEuropean Language Resources Association (ELRAMay 2016</p>
<p>Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, Quoc V Le, International Conference on Learning Representations. 2022</p>
<p>Symbolic knowledge distillation: from general language models to commonsense models. Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, Yejin Choi, 10.18653/v1/2022.naacl-main.341Proceedings of the 2022 Conference of the North American Chapter. the 2022 Conference of the North American ChapterSeattle, United StatesAssociation for Computational LinguisticsJuly 2022</p>
<p>Transformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Le Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest, Rush, 10.18653/v1/2020.emnlp-demos.6Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsAssociation for Computational LinguisticsOctober 2020</p>
<p>Understanding multimodal procedural knowledge by sequencing multimodal instructional manuals. Te-Lin Wu, Alex Spangher, Pegah Alipoormolabashi, Marjorie Freedman, Ralph Weischedel, Nanyun Peng, 10.18653/v1/2022.acl-long.310Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational LinguisticsMay 20221PLASMA 3.17 [2.94; 3.41</p>
<p>. Davinci, 175B) zero-shot 4.84 [4.77; 4.92] few-shot (5) 4.90 [4.85; 4.95</p>
<p>. Cocogen, 175B) few-shot (16) 4.55 [4.43; 4.68</p>            </div>
        </div>

    </div>
</body>
</html>