<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1937 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1937</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1937</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-43.html">extraction-schema-43</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experiments or studies that measure bloat, diversity, and executability (or related metrics like validity, correctness, or fitness) in genetic programming or evolutionary computation systems, particularly focusing on how these metrics interact and trade off against each other.</div>
                <p><strong>Paper ID:</strong> paper-278815677</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2508.20871v1.pdf" target="_blank">Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics</a></p>
                <p><strong>Paper Abstract:</strong> Optimal path planning involves finding a feasible state sequence between a start and a goal that optimizes an objective. This process relies on heuristic functions to guide the search direction. While a robust function can improve search efficiency and solution quality, current methods often overlook available environmental data and simplify the function structure due to the complexity of information relationships. This study introduces Genetic Informed Trees (GIT*), which improves upon Effort Informed Trees (EIT*) by integrating a wider array of environmental data, such as repulsive forces from obstacles and the dynamic importance of vertices, to refine heuristic functions for better guidance. Furthermore, we integrated reinforced genetic programming (RGP), which combines genetic programming with reward system feedback to mutate genotype-generative heuristic functions for GIT*. RGP leverages a multitude of data types, thereby improving computational efficiency and solution quality within a set timeframe. Comparative analyses demonstrate that GIT* surpasses existing single-query, sampling-based planners in problems ranging from R^4 to R^16 and was tested on a real-world mobile manipulation task. A video showcasing our experimental results is available at https://youtu.be/URjXbc_BiYg</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1937.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1937.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experiments or studies that measure bloat, diversity, and executability (or related metrics like validity, correctness, or fitness) in genetic programming or evolutionary computation systems, particularly focusing on how these metrics interact and trade off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RGP (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforced Genetic Programming (RGP) used to evolve G-heuristics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-based genetic programming system (symbolic regression) that evolves expression-tree heuristics for sampling-based path planners; individuals (œà) are evaluated via a reward-based fitness that measures planner performance on a benchmark and includes parsimony and variance penalties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Reinforced Genetic Programming (RGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Tree-based genetic programming (expression trees) applied to symbolic regression / heuristic discovery; individuals represent heuristic functions (G-heuristics) which are compiled into a planner variant GIT* and evaluated by running the planner on benchmark planning problems (unlabeled data).</td>
                        </tr>
                        <tr>
                            <td><strong>bloat_metric</strong></td>
                            <td>Program size |œà| (tree size / number of nodes) used as a complexity measure; also a maximum tree depth limit (max depth = 4) enforced during evolution; parsimony pressure applied via additive penalty c2 * |œà| in fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>bloat_measurements</strong></td>
                            <td>No empirical time-series measuring 'bloat' (growth of program size) is reported. The paper reports design choices intended to limit bloat: max tree depth = 4, and an explicit parsimony penalty term c2 * |œà| in the fitness function; no numeric growth (e.g., nodes/gen) is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Qualitative diversity notion: population diversity is referred to in terms of population size and variation across individuals; tournament selection size (5) and large population (1500) are used to influence diversity. No formal numeric diversity metric (e.g., genotypic uniqueness or edit distance) is defined.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_measurements</strong></td>
                            <td>No explicit numeric diversity measurements are reported. The paper states qualitatively that a high population size 'enhances diversity but raises computational cost' and shows fitness variation across generations (Fig.5) but does not report per-generation uniqueness/diversity statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Indirect 'executability' / functional fitness is measured as planner performance when using an individual's heuristic: a composite reward score built from multiple planner metrics (time to initial solution, initial solution cost, final solution cost within time limit, success rate, etc.). The final individual fitness œÅ_œà = s_total + c1 * variance(s_total) + c2 * |œà|, where s_total is a weighted sum of per-metric base scores and bonuses comparing GIT*_œà to the EIT* baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_measurements</strong></td>
                            <td>The paper reports example fitness values and planner performance metrics used in the reward: example fitness values shown in figures/text (e.g., œÅ_œà1* ‚âà 800.7, œÅ_œà2* ‚âà 735.9, œÅ_œà3* ‚âà 480.3, œÅ_œàn* ‚âà 780.6) and extensive planner experiment outputs (success rates and median costs) for GIT* vs SOTA planners. However, there are no per-generation measurements of 'percentage of syntactically valid programs' or similar executability-of-code statistics; executability here = planner success rate / solution cost used inside the fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_rate</strong></td>
                            <td>0.8</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_rate</strong></td>
                            <td>0.1</td>
                        </tr>
                        <tr>
                            <td><strong>selection_method</strong></td>
                            <td>Tournament selection (tournament size = 5)</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>1500</td>
                        </tr>
                        <tr>
                            <td><strong>special_operators</strong></td>
                            <td>No special semantic-aware operators reported; controls that affect trade-offs include: parsimony pressure via c2*|œà|, maximum tree depth = 4 (size limit), and the reinforced reward function (fitness based on planner performance vs EIT* baseline) which is a domain-aware evaluator.</td>
                        </tr>
                        <tr>
                            <td><strong>observed_tradeoffs</strong></td>
                            <td>Explicit empirical tradeoffs between bloat, diversity, and executability are not quantitatively reported. The paper discusses qualitatively: (1) larger population size increases diversity but raises computational cost; (2) parsimony penalty (c2*|œà|) and tree depth limit are used to avoid overfitting/complex individuals (bloat) while preserving planner performance; (3) the reinforced fitness trades off multiple planner performance metrics (including success rate), variance across benchmarks, and program size. No numeric tradeoff curves (e.g., increasing crossover increases diversity but reduces executability by X%) are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_dynamics</strong></td>
                            <td>Temporal dynamics are not reported quantitatively for bloat/diversity/executability triad. The paper shows fitness evolution across generations (Fig.5) ‚Äî average fitness and min/max per generation ‚Äî but does not report time-series of program size, genotype uniqueness, or percent-validity across generations. The only temporal parameters given: 100 generations (training), and discussion that training can early-exit poorly-performing individuals across benchmark segments.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_triangle_constraint</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_to_triangle</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_explanation</strong></td>
                            <td>Mechanisms described that influence relationships: (1) parsimony pressure (additive c2*|œà|) intended to penalize complexity and avoid overfitting (reduce bloat); (2) maximum tree depth prevents runaway growth; (3) large population size and tournament selection balance exploration/diversity vs selection pressure; (4) reinforced evaluator (reward function comparing to EIT*) biases evolution toward heuristics that improve planner executability; collectively these are presented as design choices to balance complexity (bloat), diversity, and functional performance (executability), but no formal proof or measured causal relationships among the three are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>Symbolic regression for heuristic discovery (applied domain: sampling-based path planning / motion planning).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>Tree-based Genetic Programming (expression trees), strongly conventional GP representation (Koza-style trees) with depth limit.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Reinforced genetic programming <em>(Rating: 2)</em></li>
                <li>Genetic Programming: On the Programming of Computers by Means of Natural Selection <em>(Rating: 2)</em></li>
                <li>Foundations of genetic programming <em>(Rating: 2)</em></li>
                <li>Convergence analysis of canonical genetic algorithms <em>(Rating: 1)</em></li>
                <li>Symbolic regression is NP-hard <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1937",
    "paper_id": "paper-278815677",
    "extraction_schema_id": "extraction-schema-43",
    "extracted_data": [
        {
            "name_short": "RGP (this work)",
            "name_full": "Reinforced Genetic Programming (RGP) used to evolve G-heuristics",
            "brief_description": "A tree-based genetic programming system (symbolic regression) that evolves expression-tree heuristics for sampling-based path planners; individuals (œà) are evaluated via a reward-based fitness that measures planner performance on a benchmark and includes parsimony and variance penalties.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Reinforced Genetic Programming (RGP)",
            "system_description": "Tree-based genetic programming (expression trees) applied to symbolic regression / heuristic discovery; individuals represent heuristic functions (G-heuristics) which are compiled into a planner variant GIT* and evaluated by running the planner on benchmark planning problems (unlabeled data).",
            "bloat_metric": "Program size |œà| (tree size / number of nodes) used as a complexity measure; also a maximum tree depth limit (max depth = 4) enforced during evolution; parsimony pressure applied via additive penalty c2 * |œà| in fitness.",
            "bloat_measurements": "No empirical time-series measuring 'bloat' (growth of program size) is reported. The paper reports design choices intended to limit bloat: max tree depth = 4, and an explicit parsimony penalty term c2 * |œà| in the fitness function; no numeric growth (e.g., nodes/gen) is provided.",
            "diversity_metric": "Qualitative diversity notion: population diversity is referred to in terms of population size and variation across individuals; tournament selection size (5) and large population (1500) are used to influence diversity. No formal numeric diversity metric (e.g., genotypic uniqueness or edit distance) is defined.",
            "diversity_measurements": "No explicit numeric diversity measurements are reported. The paper states qualitatively that a high population size 'enhances diversity but raises computational cost' and shows fitness variation across generations (Fig.5) but does not report per-generation uniqueness/diversity statistics.",
            "executability_metric": "Indirect 'executability' / functional fitness is measured as planner performance when using an individual's heuristic: a composite reward score built from multiple planner metrics (time to initial solution, initial solution cost, final solution cost within time limit, success rate, etc.). The final individual fitness œÅ_œà = s_total + c1 * variance(s_total) + c2 * |œà|, where s_total is a weighted sum of per-metric base scores and bonuses comparing GIT*_œà to the EIT* baseline.",
            "executability_measurements": "The paper reports example fitness values and planner performance metrics used in the reward: example fitness values shown in figures/text (e.g., œÅ_œà1* ‚âà 800.7, œÅ_œà2* ‚âà 735.9, œÅ_œà3* ‚âà 480.3, œÅ_œàn* ‚âà 780.6) and extensive planner experiment outputs (success rates and median costs) for GIT* vs SOTA planners. However, there are no per-generation measurements of 'percentage of syntactically valid programs' or similar executability-of-code statistics; executability here = planner success rate / solution cost used inside the fitness.",
            "crossover_rate": "0.8",
            "mutation_rate": "0.1",
            "selection_method": "Tournament selection (tournament size = 5)",
            "population_size": "1500",
            "special_operators": "No special semantic-aware operators reported; controls that affect trade-offs include: parsimony pressure via c2*|œà|, maximum tree depth = 4 (size limit), and the reinforced reward function (fitness based on planner performance vs EIT* baseline) which is a domain-aware evaluator.",
            "observed_tradeoffs": "Explicit empirical tradeoffs between bloat, diversity, and executability are not quantitatively reported. The paper discusses qualitatively: (1) larger population size increases diversity but raises computational cost; (2) parsimony penalty (c2*|œà|) and tree depth limit are used to avoid overfitting/complex individuals (bloat) while preserving planner performance; (3) the reinforced fitness trades off multiple planner performance metrics (including success rate), variance across benchmarks, and program size. No numeric tradeoff curves (e.g., increasing crossover increases diversity but reduces executability by X%) are provided.",
            "temporal_dynamics": "Temporal dynamics are not reported quantitatively for bloat/diversity/executability triad. The paper shows fitness evolution across generations (Fig.5) ‚Äî average fitness and min/max per generation ‚Äî but does not report time-series of program size, genotype uniqueness, or percent-validity across generations. The only temporal parameters given: 100 generations (training), and discussion that training can early-exit poorly-performing individuals across benchmark segments.",
            "supports_triangle_constraint": null,
            "counterexample_to_triangle": null,
            "mechanism_explanation": "Mechanisms described that influence relationships: (1) parsimony pressure (additive c2*|œà|) intended to penalize complexity and avoid overfitting (reduce bloat); (2) maximum tree depth prevents runaway growth; (3) large population size and tournament selection balance exploration/diversity vs selection pressure; (4) reinforced evaluator (reward function comparing to EIT*) biases evolution toward heuristics that improve planner executability; collectively these are presented as design choices to balance complexity (bloat), diversity, and functional performance (executability), but no formal proof or measured causal relationships among the three are provided.",
            "domain_type": "Symbolic regression for heuristic discovery (applied domain: sampling-based path planning / motion planning).",
            "representation_type": "Tree-based Genetic Programming (expression trees), strongly conventional GP representation (Koza-style trees) with depth limit.",
            "uuid": "e1937.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Reinforced genetic programming",
            "rating": 2
        },
        {
            "paper_title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
            "rating": 2
        },
        {
            "paper_title": "Foundations of genetic programming",
            "rating": 2
        },
        {
            "paper_title": "Convergence analysis of canonical genetic algorithms",
            "rating": 1
        },
        {
            "paper_title": "Symbolic regression is NP-hard",
            "rating": 1
        }
    ],
    "cost": 0.00985875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics</p>
<p>Liding Zhang 
Kuanqi Cai 
Zhenshan Bing 
Chaoqun Wang 
Alois Knoll 
Genetic Informed Trees (GIT<em>): Path Planning via Reinforced Genetic Programming Heuristics
76AC76A53EFDA43E2AD173EC1C05F784Genetic algorithmreinforced genetic programminggenerative heuristicsoptimal path planning
Optimal path planning involves finding a feasible state sequence between a start and a goal that optimizes an objective.This process relies on heuristic functions to guide the search direction.While a robust function can improve search efficiency and solution quality, current methods often overlook available environmental data and simplify the function structure due to the complexity of information relationships.This study introduces Genetic Informed Trees (GIT</em>), which improves upon Effort Informed Trees (EIT<em>) by integrating a wider array of environmental data, such as repulsive forces from obstacles and the dynamic importance of vertices, to refine heuristic functions for better guidance.Furthermore, we integrated reinforced genetic programming (RGP), which combines genetic programming with reward system feedback to mutate genotype-generative heuristic functions for GIT</em>.RGP leverages a multitude of data types, thereby improving computational efficiency and solution quality within a set timeframe.Comparative analyses demonstrate that GIT* surpasses existing single-query, sampling-based planners in problems ranging from R 4 to R 16 and was tested on a real-world mobile manipulation task.A video showcasing our experimental results is available at https://youtu.be/URjXbc BiYg.</p>
<p>I. INTRODUCTION</p>
<p>P ATH planning is a fundamental challenge in robotic automation, involving the determination of a sequence of valid states that guide a robot from a starting point to a desired goal while avoiding obstacles [1].Many algorithms have been proposed to address this problem, such as the A<em> algorithm [2], Artificial Potential Field (APF) algorithm [3], and samplingbased algorithms [4].The A</em> algorithm's performance declines with higher dimensionality, while the APF algorithm often converges to local minima.Sampling-based algorithms have gained popularity due to their efficient exploration of the state space [5].However, they often require significant time to find the optimal solution.In multi-dimensional environments, such as autonomous vehicles and robot manipulators, it is essential to compute an efficient path to conserve power [6].</p>
<p>The motivation for this paper is to improve the convergence rate and find successful solutions faster with lower initial solution costs based on the genetic-based generation of heuristics.Sampling-based algorithms like Rapidly-exploring Random Trees (RRT) [7], Probabilistic Roadmaps (PRM) [8], and variant algorithms of RRTs [9] have been widely used for recent path planning work and have demonstrated effectiveness in practical applications.However, these algorithms' performance fluctuates greatly in different environments.On the other hand, in optimization algorithm research, a combined method known as Reinforced Genetic Programming (RGP) [10] is proposed.We introduced genotype-generative heuristic (G-heuristic) functions based on RGP for optimal edge evaluation, incorporating a fitness reward function to facilitate autonomous learning and adjustment of exploration strategies based on environmental feedback.This approach integrates the Genetic Algorithm (GA) [11] to assess bioinspired chromosome behavior (e.g., crossover, mutation, reproduction) for integration with sampling-based planners.However, the G-heuristic cannot be directly applied to robot path planning because it does not consider environmental constraints (e.g., obstacle avoidance) or robustness across various scenarios.Therefore, the G-heuristic must be trained across different benchmarking datasets using reward feedback for robustness.</p>
<p>Inspired by RGP technology, this paper presents the Genetic Informed Trees (GIT<em>) algorithm, which generates a heuristic function using problem-specific information via RGP.This heuristic enhances efficiency by minimizing expanded vertices.GIT</em> uses invalid samples within obstacles and start/goal points to create an APF, incorporating obstacle shapes and locations, and tracks sample visit frequency to account for the dynamic importance of states.The G-heuristics represent a symbolic regression problem tackled by RGP.It involves evolving nonlinear expressions to refine the heuristic.As shown in Fig. 2, G-heuristic enables GIT<em> to find the initial solution quickly and then expand.GIT</em> incorporates additional graph search techniques, such as truncation and inflation, to balance exploitation and exploration, dynamically modified using RGP.GIT* has shown improvements over state-of-theart (SOTA) methods in time to find the initial solution, initial solution quality, and final solution quality in both generalized simulation benchmarks and real-world experiments.The contributions of this paper are summarized as follows:</p>
<p>1) An efficient optimal genotype-generative heuristic function based on reinforced genetic programming, trained with a dataset from the random problem domain.2) A novel sampling-based path planning algorithm, GIT<em>, integrates the trained genotype-generative heuristic function to rapidly obtain high-quality solutions.3) Demonstrating the effectiveness of GIT</em> across various dimensional environments and optimization objectives.</p>
<p>II. RELATED WORK</p>
<p>Heuristic functions optimize path planning by estimating goal-state costs, which is crucial across multiple dimensions.Informed planners with heuristics outperform their uninformed counterparts [12].Effective heuristics should be accurate and efficient, yet balancing these traits can be challenging [13].</p>
<p>RRT-Connect [14] extends the RRT framework by growing two trees: one from the start state and the other from the goal, using heuristic-guided planning to accelerate path convergence.However, RRT-Connect lacks asymptotic optimality and does not improve solution quality with more computation time [15].Cost heuristics in tree growth are demonstrated by Heuristically-guided RRT (hRRT) [16] and Generalized Bidirectional RRT (GBRRT) [17].hRRT uses a priori heuristics for exploration within RRT's Voronoi regions, while GBRRT, a bidirectional RRT variant, employs reverse tree-computed heuristics to guide the forward tree.However, these algorithms do not provide bounds on solution quality [18].</p>
<p>To overcome this limitation, some planners combine graphbased and sampling-based approaches.Batch Informed Trees (BIT<em>) [19] uses A</em> on a random geometric graph (RGG) formed by random samples, improving approximation as samples increase.While BIT<em> efficiently refines its search, it still has limitations in using problem-specific information.Advanced BIT</em> (ABIT<em>) [20] enhances BIT</em> by introducing inflated and truncated factors, balancing the exploration and exploitation.Adaptively Informed Trees (AIT<em>) [13] and Effort Informed Trees (EIT</em>) [13] further enhance efficiency with bidirectional search strategies.EIT<em> uses adaptive sparse collision checks, reducing expensive collision detections.The forward and reverse trees inform each other, sharing complementary information to optimize the search [9].However, EIT</em> did not leverage the information from the invalid sample/nearest neighbor in the planning domain.GIT* integrates APF and dynamic importance for further guidance.</p>
<p>A. Genetic-based Path Planning Method</p>
<p>Genetic sampling-based algorithms utilize genetic operations like crossover and mutation to generate candidate solutions in the problem space.Hybridizing-RRT [21] uses a hybrid path generation scheme that combines RRT with an island parallel genetic algorithms (GA) to efficiently find G 3 -continuous Œ∑ 3 -spline paths that optimize path length and curvature.This approach leverages RRT injections to maintain genetic diversity and prevent premature convergence in complex map scenarios.Genetic-RRT [22] uses GA to optimize paths planned by RRTs.This approach retains multiple optimal solutions, increasing the likelihood of finding an asymptotically optimal path with more iterations.However, genetic-based algorithms typically use GA to optimize path length objectives, often overlooking edge evaluation during exploration, resulting in a challenging achievement of rapid convergence of the initial solution.Our method enhances search efficiency by employing RGP to create G-heuristics.</p>
<p>B. Applications of Symbolic Regression</p>
<p>Symbolic regression, a popular application of genetic algorithms (GA) [23], discovers mathematical expressions that accurately represent datasets without presupposing a specific mathematical form.Unlike traditional regression models that require predefined functional relationships, symbolic regression explores all possible expressions, uncovering complex data relationships, nonlinear interactions, and dynamic patterns [24].Inspired by symbolic regression, our work incorporates genetic programming to generate heuristic functions within the GIT<em> algorithm for path planning.This integration allows GIT</em> to leverage a broader range of data, improving computational efficiency and solution quality.</p>
<p>The Open Motion Planning Library (OMPL) [25] is commonly used in benchmarking motion planning algorithms.It provides a comprehensive framework and tools for researchers to evaluate algorithms.Genetic Informed Trees (GIT*) is integrated into the OMPL framework, the Planner-Arena benchmark database [26], and Planner Developer Tools (PDT) [27].</p>
<p>III. PROBLEM FORMULATION</p>
<p>We define the optimal planning problem according to the definition provided in [4] and consider the symbolic regression problem defined in [28] as a tool to address optimal planning.</p>
<p>Problem Definition 1 (Optimal Planning): Consider a path planning problem with the n-th dimensional state space X ‚äÜ R n .Let X obs ‚äÇ X represent states in collision with obstacles, and X free = cl(X \ X obs ) denote the resulting permissible states, where cl(‚Ä¢) represents the closure of a set.The initial/start state is denoted by x start ‚àà X free , and the set of desired final/goal states is X goal ‚äÇ X free .A sequence of states œÉ : [0, 1] ‚Üí X forms a continuous map (i.e., a collision-free, feasible path), and Œ£ represents the set of all nontrivial paths.</p>
<p>The optimal solution, represented as the queue vector œÉ * , corresponds to the path that minimizes a selected scalar cost function s : Œ£ ‚Üí R ‚â•0 .This path connects the initial state x start to any goal state x goal ‚àà X goal through the free space:
œÉ * = arg min œÉ‚ààŒ£ {s(œÉ) | œÉ(0) = x start , œÉ(1) ‚àà X goal , ‚àÄt ‚àà [0, 1], œÉ(t) ‚àà X free } ,(1)
where R ‚â•0 denotes non-negative real numbers.The cost of the optimal path is s * , and t is the timestep of the exploration.</p>
<p>Considering a discrete set of states, X samples ‚äÇ X, as a graph where edges are determined algorithmically by a transition function, we can describe its properties using a probabilistic model implicit dense RGGs when these states are randomly sampled, i.e., X samples = {x ‚àº U(X)}, as discussed in [29].</p>
<p>The characteristics of the anytime almost-surely samplingbased planner with the definition are provided in [12].</p>
<p>Problem Definition 2 (Symbolic Regression): Symbolic regression aims to find a mathematical expression that best fits a given dataset.The process involves searching the space of mathematical expressions to identify the one that minimizes the error between the predicted output ≈∑ and the actual output y over a dataset D [30].This can be formulated as an optimization problem where the objective is to minimize the sum of squared errors, represented by the fitness function.</p>
<p>The fitness function, Fitness(‚Ä¢), quantifies the error between the predicted and actual outputs.It is defined as:
Fitness(œà) = (œÅ œà ,y)‚ààD (y ‚àí ≈∑(œÅ œà , œà)) 2 ,(2)
where œà represents the symbolic expression, œÅ œà denotes the input fitness value, ≈∑(œÅ œà , œà) is the predicted output generated by the symbolic expression œà, and y is the actual output in the dataset D. The goal is to find the expression œà * that minimizes Fitness(œà), thus minimizing the sum of squared errors over the dataset.This optimization problem can be expressed as:
œà * = arg min œà Fitness(œà).(3)
In this context, the fitness function measures how well a given symbolic expression œà fits the dataset D. By minimizing the fitness function, we aim to find the symbolic expression that best fits the data, as discussed in [28].</p>
<p>IV. ALGORITHM</p>
<p>This section explains how to use the RGP to learn heuristic functions from the benchmark dataset.Then, the learned Gheuristics are then applied in the GIT<em> to achieve fast and highquality path planning.Finally, we prove that GIT</em> guarantees probabilistic completeness and asymptotic optimality.</p>
<p>A. Notation</p>
<p>The state space of the planning problem is denoted by X ‚äÜ R n , where n ‚àà N. The start point is represented by x start ‚àà X, and the goals are denoted by X goal ‚äÇ X.The sampled states are denoted by X sampled .The forward and reverse search trees are represented by T F = (V F , E F ) and T R = (V R , E R ), respectively.The vertices in these trees, denoted by V F and V R , correspond to valid states.The edges in the forward tree, E F ‚äÜ V F √ó V F , represent valid connections between states, while the edges in the reverse tree, E R ‚äÜ V R √ó V R , may traverse invalid regions of the problem domain.An edge comprises a source state, x s , and a target state, x t , denoted as (x s , x t ).The true connection cost between two states in configuration space (C-space) is represented by the function c : X √ó X ‚Üí [0, ‚àû).</p>
<p>Let A be a set and let B, C be subsets of A. The notation
B + ‚Üê C is used to denote B ‚Üê B ‚à™ C and B ‚àí ‚Üê C is used to denote B ‚Üê B \ C.
GIT*-specific Notation: Let Œò be the space of all path planning problems and Œû be the space of all path planning algorithms.The dataset consisting of k path planning problems is represented as
D k benchmark = {Œ∏ 1 , Œ∏ 2 , . . . , Œ∏ k }. The function Œ¶ : Œû √ó Œò ‚Üí {(m 1 , v 1 ), (m 2 , v 2 ), . . . , (m k , v k )}
quantifies the expected performance of running an algorithm Œæ ‚àà Œû on a path planning problem Œ∏ ‚àà Œò one hundred times, with the performance measured by k distinct indicators.The elements (m i , v i ) belong to a set M √ó V, where M is the set of all possible metrics and V is the set of all possible values.</p>
<p>In the genetic programming process, an individual is denoted as œà ‚àà E. The individual corresponding to the heuristic function of EIT<em> is defined as œà EIT * .The individuals generated in the same iteration form a population P, with size denoted as O.The probabilities of mutation and crossover, the two types of genetic operations, are denoted as p m and p c respectively.We define the fitness loss function œï : E ‚Üí [0, ‚àû), which quantitatively evaluates the performance of individuals on the dataset D k benchmark .The evaluated fitness value of an individual is denoted as œÅ œà := œï(œà).The algorithm obtained by substituting the heuristic function in EIT</em> with the individual œà i is denoted by GIT * œài .The reward function to assess the improvement of algorithm performance is denoted as œá :
M √ó V ‚Üí [0, ‚àû). The function U : X ‚Üí [0, ‚àû)
provides the magnitude of potential energy of a state in APF.</p>
<p>B. Reinforced Genetic Programming (RGP)</p>
<p>This subsection introduces RGP and its adaptation to improve the heuristic function in sampling-based path planning.RGP uses a reward function to evaluate candidate models on unlabeled data, enabling model evolution.</p>
<p>As shown in Fig. 3, RGP continues the traditional genetic programming's (GP) iterative evolutionary process.Initially, a primitive set is established to generate individuals and populations in the evolutionary cycle.This set includes essential components for individual generations.An algorithm outlines the rules for assembling individuals from these components.Multiple individuals created using the primitive set form a population of candidate solutions.Each individual œà i represents a heuristic function and corresponds to a new algorithm GIT * œài .The performance of this new algorithm is assessed using a Reinforced Fitness Evaluation Function, which compares the fitness of GIT * œài with the baseline (EIT<em>) algorithm.Based on fitness values, exceptional individuals from the previous generation are chosen for the next, preserving superior genetic segments and removing inferior ones.This iterative process involves selecting parents, performing crossover and mutation to introduce new genetic segments, and evaluating the new population's fitness.Crossover mixes genetic material between parents, creating offspring with diverse traits, while mutation introduces random changes for unique variations.The process continues iteratively until a termination condition, such as a specific number of generations or satisfactory fitness, is met.The best-performing individual œà * is then selected as the genotype-generative heuristic function for GIT</em>.The pseudocode for this process is illustrated in Alg. 1.</p>
<p>Unlike traditional GP, RGP employs a reward function to assess the fitness of individuals, known as the Reinforced Fitness Evaluation Function.In traditional GP, the dataset D comprises input data x i ‚àà X and corresponding label data l i ‚àà L. The objective is for each individual's model, œà i , to simulate the mapping from inputs to labels, œï : X ‚Üí L, minimizing the discrepancy between predicted outputs and actual labels to optimize model performance.</p>
<p>However, in our path planning problem, only the environment and problem description are provided as input data without any labels.We adopted an incentive-based approach to evaluate an individual's fitness using our unlabeled dataset D benchmark .The objective is to identify an individual œà * from the set E to replace the heuristic of EIT<em> and maximize the performance improvement over the EIT</em> baseline, as measured by the loss function œï.This is intended to optimize the
ùê∫ùêºùëá ùúì 2 * ùê∫ùêºùëá ùúì 1 * ùê∫ùêºùëá ùúì 3 * ùê∫ùêºùëá ùúì ùëõ * ùúå ùúì 1 * = 800.7
  2 * = 735.9
ùúå ùúì 3 * = 480.3 ùúå ùúì ùëõ * = 780.6
Reward Function for Fitness Tunning</p>
<p>Fitness
ùê∑ ùêµùëíùëõùëê ‚Ñéùëöùëéùëüùëò ùëò = {ùúÉ 1 , ùúÉ 2 , ‚Ä¶ ùúÉ ùëò } Initial Population ùëÖùëÖ [ùúÉ1] ùëÖùëÖ [ùúÉ2] ùëÖùëÖ [ùúÉùëò ]
Candidate Path Planners Best
œà * = arg min œài‚ààE œï(œà i , D benchmark ),(4)œï(œà i , D benchmark ) = œá(Œ¶(œà i , D benchmark ), Œ¶(œà EIT<em> , D benchmark )).(5)
For problem description input Œ∏ i , we use the existing algorithm EIT</em> performance as a control group, assessed over a set number of trials.We then compare this with the performance of a new algorithm GIT * œài , generated by replacing EIT<em>'s heuristic function with individual œà i , tested under identical conditions.If GIT * œài outperforms EIT</em> on any performance metric, the reward function œá decreases the fitness score proportionally to the degree of improvement.Conversely, if GIT * œài performs worse than EIT<em> on any metric, œá increases the fitness score accordingly.This method ensures that a lower fitness score indicates the superior performance of an individual compared to EIT</em> within the dataset D benchmark .</p>
<p>To illustrate how the fitness of an individual œÅ œài is assessed, consider the following example.Table I presents the performance results of EIT* and GIT * œài .These two algorithms were tested 100 times on the Random Rectangle problems across different dimensions, with time limits for each run (unsuccessful runs were considered as infinite costs).Ten critical metrics were evaluated, reflecting the algorithm's performance in terms of time to find the initial solution, the cost of the initial solution, the cost of the optimal solution within the time limit, and the final success rate over 100 runs of finding solutions.</p>
<p>When assessing the fitness œÅ of an individual œà i , these metrics must be taken into consideration, and the corresponding weights for each metric should be set according to the specific application context.Below, we present the reward function system and rules used in our subsequent experiments:</p>
<p>1) Initial score: The initial score for an individual is 800, ensuring the final computed fitness is greater than 0.</p>
<p>2) Weights of metrics:</p>
<p>To determine the specific weights w[m i ] for each metric m i , the weighting depends on the specific application scenario and requirements.The weights for the metrics are provided in the weights row of Table I.</p>
<p>3) Base score for each metric: For each metric m i , a base score s base is assigned based on whether GIT * œài outperforms EIT * and the magnitude of the difference.First, it is assessed whether
GIT * œài 's value v i GIT * œà i outperforms EIT * 's value v i EIT * . If GIT *
œài is superior, a fixed score Œ¥ is subtracted; otherwise, it is added.To quantify the degree of superiority, this score is multiplied by a coefficient Œ±, calculated as the
Œ± = v i GIT * œà i ‚àí v i EIT * v i EIT * ,(6)
The base score for the metric m i is then:
s base [m i ] = Œ¥ + Œ¥ √ó Œ±,(7)
4) Handling infinity as a special case: Some metrics may be infinite if solutions are not found in time.If both EIT* and GIT * œài record infinity for a metric, s base is set to 0. If only one does, s base is 2 √ó Œ¥.</p>
<p>5) Bonus for significant success rate enhancement: Given the importance of the success rate, substantial differences between GIT * œài and EIT* in this metric should impact the overall fitness evaluation.If the difference v success
GIT * œà i ‚àí v success EIT * exceeds 5% but is less than 15%, a bonus s bonus [m success ] = Œ¥ is applied. For differences exceeding 15%, s bonus [m success ] = 2 √ó Œ¥.
6) Calculation of total score: The total score run on path planning problem Œ∏ is equal to the sum of all metrics' basic scores and bonuses, each multiplied by their respective weights.The total scure is expressed as:
s Œ∏ total = n i=1 (s base [m i ] + s bonus [m i ]) ‚Ä¢ w[m i ],(8)
The above rules evaluate an individual's total score within a specific problem context.To measure generalizability, we use randomly generated problem descriptions as a dataset D benchmark .The average total scores within this dataset are included in the fitness calculation.To ensure stability across problems, we include the variance of total scores.Lastly, we consider the number of nodes as a complexity measure to avoid overfitting from complex expressions.The final fitness calculation formula is as follows:
œÅ œà = s total + c 1 œÉ 2 stotal + c 2 |œà|. (9)
where œà denotes the individual.s total represents the mean of the total scores across each problem definition in the benchmark.œÉ 2 stotal is the variance of the total scores, multiplied by the coefficient c 1 .|œà| signifies the size of the individual œà, multiplied by the coefficient c 2 .</p>
<p>During practical training, techniques can reduce unnecessary computations.A segmented system can evaluate an individual without testing the complete benchmark.The benchmark's scenarios are divided into segments with increasing difficulty.If the fitness in the first i segments is significantly lower than a baseline, it indicates the algorithm performs worse than the expected ideal threshold (EIT*).Consequently, the fitness score can be directly assessed and recorded as L œà
Output: Feasible path T F 1 X sampled ‚Üê {x goal }, E F ‚Üê ‚àÖ, T F = (V F , E F ) 2 key GIT * R ‚Üê bestKey(œà * ) 3 while not terminateCondition() do 4 X sampled + ‚Üê sample() 5 T R ‚Üê reverseSearch(key GIT * R , Œµ * infl , Œµ * trunc ) 6 while couldImproveForwardSearch(T R ) do 7 E F ‚Üê forwardSearch(T R , Œµ * trunc ) 8 if pathFound(E F ) then 9 T F ‚Üê T R 10 else 11 updateReverseSearch()12
prune(T F )</p>
<p>13 return T F Algorithm 3: GIT*: Potential Energy
1 U [x] ‚Üê ‚àÖ 2 U attr [x] ‚Üê calcAttractiveEnergy(x start , x) // Equation 16 3 foreach x invalid ‚àà X invalid do 4 U rep [x] += calcRepulsiveEnergy(x invalid , x) // Equation 14 5 U [x] ‚Üê U rep [x] + U attr [x] 6 return U [x]
without testing the entire benchmark, as such an individual is likely to be quickly eliminated in the evolutionary process.</p>
<p>C. Genetic Informed Trees (GIT*)</p>
<p>In Section IV-B, we use the RGP to evaluate the best individual œà * of the generated population.In this subsection, the evaluated best individual œà * is utilized in the GIT* to guide robot path planning, allowing the robot to rapidly converge on the initial solution while maintaining path quality.</p>
<p>Problem-specific information falls into three categories: search tree information g(x), heuristic information ƒ•(x), and environmental information (e.g., dimensionality D(Œ∏) and obstacle details).GIT<em> uses the RGP to generate evolving individuals that combine these information types into complex expressions.These expressions are integrated into the EIT</em> heuristic function to form new algorithms, GIT * œà , with the optimal GIT<em> algorithm being selected based on performance:
œà * := arg min œài œÅ œài ,(10)GIT * := GIT * œà * ,(11)
When GIT</em> trains its heuristic function using RGP, information is stored in the primitive set to generate individuals.The search tree-related information includes g(x s ), while prior heuristic information includes ƒ•(x t ) and ƒâ(x s , x t ).ƒì(x s ) estimates the effort to find and validate a path from x s to the goal, whereas ƒì(x s , x t ) estimates the computational effort required to find and validate a path between states, while d(x t ) estimates the effort from x t to the start.Environmental information comprises not only D(Œ∏) but also two variables that record information about obstacles and the dynamic importance of states.According to the GA model, after natural selection, the winner G-heuristic function generated by RGP can be equivalently represented by key GIT * R , which extracts the next edge from the reverse queue:
key GIT * R (x s , x t ) := ( g (x t ) ‚àí œÄ) √ó log(1+|U [xt]‚àíU [xs]|) 1+w dyn [xt] , ƒì(x s ) + ƒì(x s , x t ) √ó log( d(x t )).(12)
where U [x t ] refers to the potential energy of the current state in an artificial potential field, and w dym refers to dynamic importance, represented by the number of times the current state has been visited.The following will detail how these variables are obtained.</p>
<p>1) Potential field variable U [x t ]: Understanding obstacle characteristics like shapes, numbers, and locations is crucial for guiding the search tree to either circumvent obstacles for quicker solutions or approach them to reduce costs.However, these characteristics are often unknown beforehand.</p>
<p>GIT<em> approximates the environment by sampling points in the C-space to acquire information about obstacles, denoted as X obs .Those randomly sampled points undergo a validity check (e.g., collision detection) to determine if they are inside obstacles.Invalid points, denoted as x invalid , indicate locations within obstacles, gradually outlining their shapes and locations as sampling increases.GIT</em> also employs the APF method to conceptualize the navigation space as a force field where obstacles generate repulsive forces, and targets generate attractive forces (Alg.3, line 2).x invalid and x goal generate repulsive and attractive forces with target state x t , respectively, and the potential field is dynamically adjusted based on the obstacle data.The calculated data is then utilized in the primitive set as candidates for RGP to generate G-heuristic individuals.</p>
<p>‚Ä¢ Repulsive force: Generated around invalid samples, these forces prevent entry into these areas.The magnitude of the repulsive force is:
F rep (q) := ‚àí kr‚Ä¢q‚Ä¢qobs r 2 if r ‚â§ œÅ 0 0 otherwise ,(13)
where k r is a proportionality constant, q is the charge equivalent of the path planner, q obs is the charge equivalent of the obstacle, r is the distance between the path Algorithm 4: GIT<em>: Dynamic Importance
1 w dyn [x t ] ‚Üê ‚àÖ 2 foreach x neighbor ‚àà neighbors(x t ) do 3 if inReverseTree(x neighbor , x t ) 4 w dyn [x t ] ‚Üê w dyn [x t ] + 1 5 return w dyn [x t ]
Algorithm 5: GIT</em>: Nearest Neighbors
1 X neighbors ‚Üê nearest(x t ) 2 X neighbors + ‚Üê {parent(x t ) ‚à™ children(x t ) \ X neighbors } 3 X neighbors ‚àí ‚Üê {x s ‚àà X neighbors |(x s , x t ) ‚àà E invalid } 4 return X neighbors
planner and the obstacle, and œÅ 0 is the threshold distance beyond which the force is not exerted.</p>
<p>‚Ä¢ Repulsive potential energy: The potential energy is:
U rep (q) := ‚àí kr‚Ä¢q‚Ä¢qobs r if r ‚â§ œÅ 0 0 otherwise ,(14)
‚Ä¢ Attractive force: Produced by the target, these forces guide the path planner towards the target, navigating around repulsive regions.The magnitude of the attractive force is:
F attr (q) := k a ‚Ä¢ q ‚Ä¢ q goal r 2 ,(15)
where k a is another proportionality constant, q is the charge equivalent of the path planner, q goal is the charge equivalent of the target, and r is the distance between the path planner and the target.‚Ä¢ Attractive potential energy: The potential energy is:
U attr (q) := k a ‚Ä¢ q ‚Ä¢ q goal r .(16)
The potential energy in the APF can be calculated using these formulae, recording information about obstacles and incorporating it into the primitive set to construct the heuristic function.As potential energy increases, indicating proximity to obstacles, the heuristic function's value increases, reducing the likelihood of state selection.When U [x t ] is high, indicating frequent visits, the heuristic function's value decreases, increasing the likelihood of exploration.As g (x t ) increases, indicating greater distance from the start, the heuristic function's value increases, making the node less likely to be searched.</p>
<p>2) Dynamic importance variable w dyn [x t ]: In incremental asymptotically sampling-based planners like GIT<em>, certain sample points in C-space are frequently visited, often in nearest neighbor areas (e.g., path rewire) of path planning.These samples may lie along essential routes between start and end states, serve as conduits connecting regions, and could be located in narrow corridor areas.Thus, frequently visited samples in the free space prior to neighboring areas guide the search into explore-worthy regions, which improves search efficiency.GIT</em> tracks the number of visits to each sample point, capturing its dynamic importance (Alg.4 and 5), and navigates to higher importance states.These strategies help GIT* search more efficiently during the path optimization phase.Similar to the APF discussed in Section IV-C1, the number of visits (i.e., dynamic importance) to a state is included in RGP's primitive set to generate G-heuristics.</p>
<p>Formally, the dynamic importance of a state x t , denoted as w dyn [x t ], is calculated as follows: (17) where I(‚Ä¢) is the indicator function that equals 1 if the condition is true and 0 otherwise.
w dyn [x t ] := xneighbor‚ààXneighbors(xt) I(x neighbor ‚àà T R (X neighbors (x t ))),
Each time a sample point appears in the nearest neighbors of the reverse tree queue, the dynamic importance of the corresponding state is incremented by 1, emphasizing frequently visited states for path optimization.Furthermore, the inflation factor speeds up the search by biasing the goal, resulting in rapid initial solutions.The truncation factor optimizes the search by stopping it when the solution quality is satisfied.</p>
<p>3) Inflation and truncation factor function: The traditional inflation and truncation factor update strategy is a useradjustable parameter that can be tailored to specific application scenarios and requirements.However, this strategy lacks flexibility as it requires manual adjustments in each scenario to achieve optimal performance.The updated function for the inflation factor derived from this training session is:
Œµ * infl = 1.0 + log(D(Œ∏)) + D(Œ∏) N samples + log(N samples ) + 1 ,(18)
where D(Œ∏) is the dimensionality of the path planning problem Œ∏, and N samples is the current number of samples taken.</p>
<p>As the problem's dimensionality increases, this expression's value also increases, biasing the search towards rapidly finding feasible solutions based on heuristics rather than ensuring the lowest cost solution.In higher-dimensional spaces, fewer obstacles relative to the overall space decrease the probability of blocking the path, enhancing the success rate and reducing the time to find initial solutions.As the number of samples increases, the value decreases, leading GIT* to focus on lowcost solutions after several sampling batches, aligning with practical requirements.</p>
<p>The updated function for the truncation factor is:
Œµ * trunc = 1.0 + 3œÄ N samples , (19)
where N samples represents the current number of samples taken.</p>
<p>As N samples increases, the value decreases, indicating a tendency to exploit the current approximation rather than explore new ones.This is suitable for the later stages of the search when N samples is large.</p>
<p>V. ANALYSIS</p>
<p>In this section, firstly, we provide the convergency analysis and asymptotical time to prove the feasibility of the proposed algorithm.In addition, we explain the reason that GIT* consumes less time complexity, and we also verify the advantage of reinforced genetic programming (RGP) from mathematics.</p>
<p>A. Reinforced Genetic Programming Training Analysis</p>
<p>Due to the randomness of the RGP algorithm and variability in training parameters, results from each RGP instance are unique.Practical applications need to consider specific objectives, use cases, datasets, and time constraints for parameter settings.Table II details the chosen parameters: high population size enhances diversity but raises computational cost, 1500 size was chosen for optimal performance with our equipment; 100 generations provide a balance between solution quality and overfitting; a crossover rate of 0.8 promotes exploration without excessive disruption; a mutation rate of 0.1 maintains diversity and prevents premature convergence; a maximum tree depth of 4 avoids overfitting and underfitting; and a tournament size of 5 balances selection pressure and diversity.The fitness variation across generations is shown in Fig. 5.</p>
<p>B. Proof of Convergence in Genetic Programming</p>
<p>Research has explored the convergence properties of genetic programming (GP) for symbolic regression [31].The global optimum in symbolic regression problem refers to the best possible individual that achieves the minimum or maximum fitness of the objective function across the entire state space [32].Convergence to the global optimum implies generating solutions where the global optimum emerges as a limit.This study adopts a probabilistic interpretation.Rudolph [23] modeled genetic programming using a Markov Chain framework and demonstrated convergence when the population retains the best solution.The natural selection, crossover, and mutation processes in GP mimic biological evolution.</p>
<p>Let P(t) be the population at time t, and œà * be the global optimum.GP maintains a diverse population P(t) over generations to escape local optima:
P(t + 1) := select(crossover(mutate(P(t)))),(20)
This helps GP escape local optima, unlike greedy search methods, which may converge quickly to local optima.Let Z t denote a sequence of random variables representing the best fitness within a population at step t.The convergence property of genetic programming, which preserves the best solution in the population, can then be formalized as:
lim t‚Üí‚àû P(Z t = œà * ) := 1, (21)
where œà * represents the global optimum.This expression indicates that the probability of the best fitness Z t equating to the global optimum œà * approaches unity as the number of iterations steps t approaches infinity.Through mutation and crossover, GP maintains diversity and explores the search space effectively.Selection mechanisms favor individuals with higher fitness, leading to gradual improvement.Consequently, the probability of finding the global optimum œà * increases with each iteration.</p>
<p>C. Probabilistic Completeness and Asymptotic Optimality</p>
<p>Most informed tree-based path planning algorithms have been proven to be probabilistically complete and asymptotically optimal, and GIT<em> can also guarantee these two properties.GIT</em> utilizes uniform sampling strategies.As the number of iterations n approaches infinity, the entire state space will be explored, satisfying the following equation:
lim n‚Üí‚àû P({V F ‚à™ V R } ‚à© X goal ) Ã∏ = ‚àÖ) = 1,(22)
which means that if there is a feasible path, it must be found by the GIT*.Therefore, the probabilistic completeness of the optimal path planner is guaranteed.</p>
<p>The GIT<em> implements the same Choose Parent and Rewire strategies as the EIT</em>.It means that if the rewiring radius r(q) in Choose Parent and Rewire processes satisfies:
r(q) &gt; Œ∑ 2 1 + 1 d Œª(X f ) Œ∂ d log(q) q 1 d ,(23)
here, q denotes the number of sampled states in the informed set, Œ∑ &gt; 1 is a tuning parameter, Œª(‚Ä¢) denotes the Lebesgue measure, and d is the dimensionality of the workspace, Œª(X f )) is the Lebesgue measure of informed set X f and Œ∂ d is the volume of unit ball in current workspace.In reference to Lemma 56, 71 and 72 in [4], the following equation holds: The state space, denoted as X ‚äÇ R n , is constrained within a hypercube with one width for both problem instances.Specifically, we conducted ten distinct instantiations of the random rectangles experiment and the outcomes are showcased in Fig. 7.
P(lim sup q‚Üí‚àû min œÉ‚ààŒ£q {c(œÉ)} = c * ) = 1,(24)
where q is the number of samples, Œ£ q ‚äÇ Œ£ is the set of valid paths from the start to the goal found by the planner from those samples, c : Œ£ ‚Üí [0, ‚àû) is the cost function, and c * is the optimal solution cost.It indicates that the GIT* can find an optimal path, if it exists, as the number of iterations go to infinity.Therefore, the asymptotic optimality is guaranteed.</p>
<p>VI. EXPERIMENTS</p>
<p>In this paper, we utilize the Planner Developer Tools (PDT) [27] and MoveIt [33] to benchmark motion planner behaviors.GIT<em> was tested against SOTA algorithms in both simulated random scenarios (Fig. 6) and real-world manipulation problems (Fig. 8).The comparison involved several versions of RRT-Connect, Informed RRT</em>, BIT<em>, AIT</em>, ABIT<em>, and EIT</em> sourced from the Open Motion Planning Library (OMPL) [25].The evaluations were conducted on a computer with an Intel i7 3.90 GHz processor and 32GB of LPDDR3 3200 MHz memory.These comparisons were carried out in simulated environments of dimensions R 4 and R 8 .The primary objective for the planners was to minimize path length (cost).The RGG constant Œ∑ was uniformly set to 1.001, and the rewire factor was set to 1.2 for all planners.</p>
<p>In the case of RRT-based algorithms, a goal bias of 5% was employed, and the maximum edge lengths were determined based on the dimensionality of the space.All batched algorithms utilized a batch size of 100.BIT<em>, AIT</em>, ABIT<em>, and EIT</em> maintained a linear combination heuristic function</p>
<p>Overview</p>
<p>This report was automatically generated using Planner Developer Tools (PDT).It presents the results for the 2024-05-31_15-35-32_defaultWallGap8D experiment, which executed 100 runs of RRT-Connect, Informed RRT<em>, BIT</em>, AIT<em>, ABIT</em>, EIT<em>, and GIT</em> on the defaultWallGap8D planning context.See appendix A.1 for more information about the experiment setup.   of Euclidean distance and effort, respectively.GIT* utilized optimal G-heuristic (Eq.12) to extract the next edge from the reverse queue, which was selected based on the fitness of RGP.</p>
<p>Results Summary</p>
<p>A. Simulation Experimental Tasks</p>
<p>The planners were tested across three distinct benchmarks in two domains: R 4 and R 8 .In the first scenario, a constrained environment resembling a dividing wall with several narrow gaps was simulated, allowing valid paths in multiple general directions for non-intersecting solutions (Fig. 6a).Each planner underwent 100 runs, with computation time for each anytime asymptotically optimal planner shown in the labels, using varying random seeds.The overall success rates and median path lengths for all planners are depicted in Fig. 7a and  7b.It can be seen that GIT<em> quickly finds the initial solution in both dimensions with minimal time, whereas EIT</em> requires more time to find the initial solution.</p>
<p>In the second test scenario, random widths were assigned to axis-aligned hyperrectangles, generated arbitrarily within the C-space (Fig. 6b).Random rectangle problems were created for each dimension of the C-space, with each planner undergoing 100 runs for every instance.Fig. 7c and 7d illustrate the proposed method has the highest success rates and lowest median path costs within the computation time compared with other planners.This indicates that GIT<em> can recognize promising regions via environmental information (e.g., APF) where feasible paths likely lie, thereby biasing the sampling process toward these regions.As a result, GIT</em> outperformed and can quickly find an initial solution.</p>
<p>The last test problem consisted of a hollow, axis-aligned hyperrectangle enclosing the goal state, configured such that even in higher dimensions, the goal can only be reached through the face of the hyperrectangle farthest from the start state (Fig. 6c).This problem is challenging for GIT<em> because there are many invalid edges close to the root of the reverse search tree, often requiring large parts to be repaired (Figs.7ef).From the figure, the GIT</em> achieves the best performance in finding the initial solution and converging to the optimal solution compared with the SOTA planner.</p>
<p>As observed in Table III, there's a median initial time Overall, Table III highlights the advantages of GIT* in achieving lower initial median times compared to SOTA, thereby enhancing the efficiency of path planning algorithms.</p>
<p>B. Real-world Path Planning Tasks</p>
<p>To evaluate the algorithm's performance in real-world scenarios, three numerical experiments are conducted on a singlearm manipulator and mobile manipulator (DARKO) to demonstrate the efficiency and extensibility of GIT<em> compared with three SOTA path planning algorithms: Batch Informed Trees (BIT</em>) [19], Adaptively Informed Trees (AIT<em>) [13], and Effort Informed Trees (EIT</em>) [13].</p>
<p>We compare GIT<em> with AIT</em> and EIT<em> in single-arm manipulator environments to evaluate their performance in converging to the optimal solution cost and success rate over 30 runs.The first environment (Beer Barrel) consists of simple cup holder obstacles.The second and third environments (Shelf and Kitchen) are confined to the DARKO robot and cluttered with narrow spaces.A collision-free path connecting the start state to the goal region is required.GIT</em> demonstrated its effective G-heuristic during multiple experimental tasks (Fig. 8).The detailed behavior of real-world experiments can be viewed in the accompanying video.</p>
<p>1) Beer Barrel Cup Placement Task: Fig. 8a showcases the start and goal configuration of the cup placement task.In this task, we utilize a single robotic manipulator to grab a beer cup and place it under the beer tap of the beer barrel keg while avoiding obstacles.The following graph illustrates the performance of AIT<em>, EIT</em>, and GIT<em> in terms of solution cost and success rate.All planners were given 1.0 seconds to address the beer barrel cup placement problem.Over the course of 30 trials, GIT</em> achieved a 100% success rate with a median solution cost of 13.8972.EIT<em> had a success rate of 96.67% with a median solution cost of 15.1332.AIT</em> was 93.33% successful, with a median solution cost of 19.2183.</p>
<p>2) Industry Shelf Container Rearrangement Task: The initial and final configurations for the shelf task are depicted in Fig. 8b.This task involves extracting an industry-standard container from a position between two other boxes on the lower bottom layer and repositioning it on the third layer of the shelf, again between two containers.Due to component standardization, the challenge lies in the precise insertion of industry containers into narrow spaces.The task aims to place the industry-standard container between two larger containers on the shelf, with a tolerance scope of ‚â§5mm, making the planning of a collision-free feasible path particularly difficult.Each planner was allocated 5.0 seconds to solve this confined, limited space pull-out and insertion problem.Across 30 trials, GIT<em> achieved an 86.67% success rate with a median solution cost of 15.9745.EIT</em> had a 76.67% success rate with a median solution cost of 19.1045.AIT* managed a 56.67% success rate with a median solution cost of 18.2672.</p>
<p>3) Kitchen Model Pan Cooking Task: For the third task, we utilized the DARKO robot positioned in front of a kitchen model.The start and goal configurations are illustrated in Fig. 8c.This task is particularly challenging as the manipulator must navigate the geometric shape of the pan within a cluttered oven while also avoiding collisions between the base robot and the kitchen shelves.The complexity is further heightened by the need for precise movements in a confined space.Each planner was allotted 10.0 seconds to solve this kitchen pan reallocation problem.Over the course of 30 trials, GIT<em> achieved a 30% success rate with a median solution cost of 15.8860.EIT</em> had a success rate of 26.67% with a median solution cost of 19.2746.AIT* managed a 16.67% success rate with a median solution cost of 20.9824.</p>
<p>In short, compared with the AIT<em> and the EIT</em>, the GIT* achieves the best performance on finding the initial solution and converging to the optimal solution.</p>
<p>C. Discussion</p>
<p>1) Comparison With SOTA Planner: To showcase the advantages of GIT<em>, we compared its performance with AIT</em> and EIT* using success rate and solution cost metrics in three real-world tasks (Fig. 8): placing cups on beer barrel faucets, rearranging industrial containers on shelves, and cooking pans in a kitchen model, and six simulation tasks (Fig. 6) across multi-dimensions with randomly generated seeds.</p>
<p>From the experiment results, we observe that EIT<em> performs much better than AIT</em> in both simulation environments (Table III) and real-world scenarios.However, GIT<em> outperforms From the discussion, one may conclude that using RGP to train an optimal G-heuristic across all benchmarks can improve the initial convergence rate and initial path length.Furthermore, GIT</em> can utilize environmental information to search via more promising regions (i.e., APF and dynamic importance), which accelerates the path-planning initial finding process.GIT* achieved the highest success rate and lowest solution cost among tested SOTA planners, emphasizing its potential for real-world applications.</p>
<p>2) Limitations and Future Work: While GIT<em> demonstrates superior performance, it has limitations.The current implementation is tailored for specific tasks with predefined start and goal configurations, limiting its adaptability to variable environments and tasks.Future work could enhance GIT</em>'s generalization capabilities by integrating neural network-driven approaches to learn from diverse human demonstrations, improving its extension ability across different environments.This aligns with advancements in neural network-based path planning and promises to enhance GIT*'s robustness and versatility.Furthermore, future designs will consider human acceptability and comfort when planning trajectories.</p>
<p>VII. CONCLUSION</p>
<p>In this paper, we introduced the Genetic Informed Trees (GIT<em>) algorithm, a novel path planning approach that leverages Reinforced Genetic Programming (RGP) to refine heuristic functions for enhanced guidance.By incorporating additional environmental data, such as repulsive forces from obstacles and the dynamic importance of vertices, GIT</em> improves search efficiency and solution quality.The integration of RGP allows GIT<em> to mutate genotype-generative heuristic functions (G-heuristic), adapting to various problem domains.Our comparative analyses demonstrate that GIT</em> consistently outperforms existing single-query, sampling-based planners across different scenarios, including simulation benchmarks and real-world robot manipulation tasks.Optimal G-heuristic exhibits notable improvements over SOTA methods in terms of both success rate and solution cost, showcasing its robustness and adaptability, particularly in handling complex, cluttered environments with high precision and efficiency.</p>
<p>In conclusion, GIT<em> enhances rapid initial pathfinding and reduces solution costs.GIT</em> shows promising potential for future research and applications in motion planning.</p>
<p>Fig. 1 .
1
Fig.1.GIT<em> utilizes a population of G-heuristics (i.e., œà 1 , œà 2 ...) with chromosome behaviors.The example of G-heuristics is illustrated above, which are trained using a reward function over multiple generations through RGP.The best G-heuristic is employed for pathfinding guidance.GIT</em>'s performance is evaluated in beer barrel, shelf, and kitchen model scenarios.</p>
<p>Fig. 2 .
2
Fig. 2. Four snapshots show EIT<em> and GIT</em> exploration strategies in reverse search.GIT<em> employs G-heuristics, while EIT</em> maintains a linear combination heuristic.Yellow points indicate valid samples in obstacle-free areas.The blue line represents the reverse tree at time tn, the pink line represents it at time t n+1 , and the dashed red lines are optimized reverse edges.</p>
<p>Fig. 3 .
3
Fig.3.Overview of the Reinforced Genetic Programming (RGP) process for path planning.The process initiates with the collection of path planning scenarios as benchmark data, followed by the generation of expression trees acting as G-heuristics.These trees represent individuals' heuristics in the genetic process, undergoing various genetic operations such as mutation, crossover, and reproduction to evolve a new population of heuristic candidates.The cycle concludes with the evaluation and replacement of individuals, continuously iterating to enhance algorithmic performance.</p>
<p>Fig. 4 . 4 P 7 œà 12 P ‚Üê P new 13 œà
4471213
Fig. 4. llustration of the evaluation and fitness assignment process for individuals in the RGP.Each individual œà i represents an expression that serves as a heuristic to guide the search, forming a new planner GIT * œà i .These planners are benchmarked across multi-dimensional and multi-scenario problems.They are scored based on a designed reward function, and the resulting score is the fitness value of the individual.Algorithm 1: Reinforced Genetic Programming (RGP) Input : Population size O, mutation rate p m , crossover rate p c Output: Best found individual œà * 1 P ‚Üê initializePopulation(O) 2 while not terminateCondition do 3</p>
<p>Algorithm 2 :
2
Genetic Informed Trees (GIT*) Input : Start point x start , goal region X goal , best individual œà * , optimal inflation/truncation factors Œµ * infl , Œµ * trunc</p>
<p>Fig. 5 .
5
Fig. 5. Evolution of fitness over generations during genetic programming training.The light purple error bar represents the maximum/minimum fitness value within each generation, while the light orange line depicts the average fitness value across individuals within each generation.The horizontal axis represents the generations, and the vertical axis represents the fitness values.</p>
<p>Fig. 6 .
6
Fig.6.The 2D representation of the simulated planning problems in Section VI.The state space, denoted as X ‚äÇ R n , is constrained within a hypercube with one width for both problem instances.Specifically, we conducted ten distinct instantiations of the random rectangles experiment and the outcomes are showcased in Fig.7.</p>
<p>Figure 1 :
1
Figure 1: Top: Percentage of runs that found a solution at any given time with a Clopper-Pearson (nonparametric) 99% confidence interval.Bottom: Median cost evolution and median of initial solution with nonparametric 99% confidence intervals.</p>
<p>1 (Fig. 7 .
17
Fig. 7. Detailed experimental results from Section VI-A are presented above.MaxTime is the planner's maximum allotted planning time.Fig.(a) and (b) depict test benchmark dividing walls outcomes in R4 and R 8 , respectively.Panel (c) showcases random rectangle experiments in R 4 , while panels (d) demonstrate in R 8 .Panel (e) and (f) present goal enclosure experiments in R 4 and R 8 .In the cost plots, boxes represent solution cost and time, with lines showing cost progression for optimal planners (unsuccessful runs have infinite cost).Error bars provide nonparametric 99% confidence intervals for solution cost and time.</p>
<p>Fig. 8 .
8
Fig. 8. Detailed experimental results from Section VI-B are summarized above.Fig. 8a illustrates the beer barrel ENV, highlighting the start and goal configurations along with the solution cost and success rate.Fig. 8b depicts the industry shelf ENV, showing initial and final positions for extracting and placing an industry-standard container.Fig. 8c presents the kitchen ENV, focusing on the DARKO robot's performance.In the cost box plots, boxes indicate the solution cost per planner, while lines represent the mean cost progression for an optimal planner (unsuccessful runs are assigned an infinite cost).SOTA planners due to its use of problem-specific environmental information via RGP and the integration of the G-heuristic.As shown in Fig.7(a, c, and e), In low-dimensional problem domains, the initial solution finding time and cost show minimal improvement.In high-dimensional domains, the linear combination heuristic struggles to guide the search efficiently, as shown in Fig.7(b, d, and f).Furthermore, In the first realworld environment, GIT<em> outperformed EIT</em> by 3.33% in success rate and reduced the solution cost by approximately 8.17%.Compared to AIT<em>, GIT</em> improved the success rate by 6.67% and reduced the solution cost by approximately 27.68%, as shown in Fig.8(a).In the second real-world experiment, the benchmark results show that the G-heuristic can enhance solving cluttered tasks, achieving the highest success rate and the lowest solution cost among the evaluated planners.GIT<em> outperformed EIT</em> by 13.04% in success rate and reduced the solution cost by approximately 16.38%.Compared to AIT<em>, GIT</em> improved the success rate by 52.94% and reduced the solution cost by approximately 12.56%, as shown in Fig.8(b).In the third real-world experiment, GIT<em> outperformed EIT</em> by 12.5% in success rate and reduced solution cost by about 17.58%.Compared to AIT<em>, GIT</em> improved success rate by 80% and reduced solution cost by approximately 24.32%, as shown in Fig.8(c).These results highlight the effectiveness of the G-heuristic in narrow environments to prevent obstacle avoidance in the kitchen model.From the discussion, one may conclude that using RGP to train an optimal G-heuristic across all benchmarks can improve the initial convergence rate and initial path length.Furthermore, GIT<em> can utilize environmental information to search via more promising regions (i.e., APF and dynamic importance), which accelerates the path-planning initial finding process.GIT</em> achieved the highest success rate and lowest solution cost among tested SOTA planners, emphasizing its potential for real-world applications.2) Limitations and Future Work: While GIT* demonstrates superior performance, it has limitations.The current implementation is tailored for specific tasks with predefined start and</p>
<p>TABLE I EXAMPLE
I
PERFORMANCE RESULTS FOR RANDOMLY GENERATED ENVIRONMENT
t min initt med initt max initc min initc med initc max initc min finalc med finalc max finalSuccessWeights w[m i ]1.03.50.51.02.51.01.02.51.03.0EIT*0.19‚àû‚àû2.5‚àû‚àû2.5‚àû‚àû0.48GIT  *  œà i0.160.39‚àû2.345.05‚àû2.333.53‚àû0.72ratio of the difference between v i GIT  *  œà iand v i EIT
* :</p>
<p>This trend is consistent across other scenarios, such as RR ‚àí R 4 and GE ‚àí R4, where GIT<em> consistently shows reduced initial median times.In the GE ‚àí R 8 scenario, GIT</em> demonstrates an initial median time of 0.0512s, compared to 0.0941 for EIT<em> and 0.3834s for AIT</em>.This indicates an improvement in initial convergence time of approximately 45.59% compared to EIT<em>.
TABLE IIIBENCHMARKS EVALUATION COMPARISON (FIG. 7)Adaptively Informed Trees t med init c med init c med finalEffort Informed Trees t med init c med init c med finalGenetic Informed Trees t med init c med init c med finalt med init ‚áë‚áë (%)DW ‚àí R 40.1299 1.9571 1.7151 0.0252 2.4051 1.3693 0.0201 2.0619 1.363484.53 / 20.23DW ‚àí R 80.1947 3.1492 2.6388 0.0357 4.0910 2.2892 0.0279 3.3791 2.310985.67 / 21.84RR ‚àí R 40.0853 1.7570 1.5282 0.0587 1.8392 1.4715 0.0472 1.6874 1.459544.67 / 19.59RR ‚àí R 81.1843 4.4697 4.3599 0.1889 4.6789 2.8588 0.1429 4.1716 2.845087.93 / 24.35GE ‚àí R 40.0191 1.2457 0.9900 0.0082 1.2909 0.9126 0.0064 1.2678 0.908366.49 / 21.95GE ‚àí R 80.3834 1.7854 1.6605 0.0941 1.4970 1.4086 0.0512 1.6634 1.363686.64 / 45.59improvement across varied benchmark scenarios, correlatingwith dimensionality. For instance, in the DW ‚àí R 4 scenario,GIT</em> exhibits a lower initial median time (i.e., median valueover 100 trials) of 0.0201s compared to 0.0252s for EIT<em>and 0.1299s for AIT</em>.
L. Zhang, K. Cai, Z. Bing, and A. Knoll are with the Department of Informatics, Technical University of Munich, Germany.liding.zhang@tum.de
2 C. Wang is with the School of Control Science and Engineering, Shandong University, Shandong, China. (Corresponding authors: Zhenshan Bing; Kuanqi Cai.)</p>
<p>Motion planning for robotics: A review for samplingbased planners. L Zhang, K Cai, Z Sun, Z Bing, C Wang, L Figueredo, S Haddadin, A Knoll, Biomimetic Intelligence and Robotics. 511002072025</p>
<p>A formal basis for the heuristic determination of minimum cost paths. P E Hart, N J Nilsson, B Raphael, IEEE transactions on Systems Science and Cybernetics. 421968</p>
<p>Real-time obstacle avoidance for manipulators and mobile robots. O Khatib, The International Journal of Robotics Research. 511986</p>
<p>Sampling-based algorithms for optimal motion planning. S Karaman, E Frazzoli, The international journal of robotics research. 3072011</p>
<p>Samplingbased path planning in highly dynamic and crowded pedestrian flow. K Cai, W Chen, D Dugas, R Siegwart, J J Chung, IEEE Transactions on Intelligent Transportation Systems. 24122023</p>
<p>APT*: Asymptotically optimal motion planning via adaptively prolated elliptical r-nearest neighbors. L Zhang, S Wang, K Cai, Z Bing, F Wu, C Wang, S Haddadin, A Knoll, IEEE Robotics and Automation Letters. 10102025</p>
<p>Randomized kinodynamic planning. S M Lavalle, J J KuffnerJr, The international journal of robotics research. 2052001</p>
<p>Probabilistic roadmaps for path planning in high-dimensional configuration spaces. L E Kavraki, P Svestka, J.-C Latombe, M H Overmars, IEEE transactions on Robotics and Automation. 1241996</p>
<p>Elliptical k-nearest neighbors: Path optimization via coulomb's law and invalid vertices in c-space obstacles. L Zhang, Z Bing, Y Zhang, K Cai, L Chen, F Wu, S Haddadin, A Knoll, pp. 12 032-12 0392024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2024</p>
<p>Reinforced genetic programming. K L Downing, Genetic Programming and Evolvable Machines. 20012</p>
<p>Genetic algorithms. K Sastry, D Goldberg, G Kendall, Search Methodologies, E. K. Burke and G. Kendall2005SpringerBoston, MA</p>
<p>Informed sampling for asymptotically optimal path planning. J D Gammell, T D Barfoot, S S Srinivasa, IEEE Transactions on Robotics. 3442018</p>
<p>Adaptively informed trees (ait<em>) and effort informed trees (eit</em>): Asymmetric bidirectional sampling-based path planning. M P Strub, J D Gammell, The International Journal of Robotics Research. 4142022</p>
<p>Rrt-connect: An efficient approach to single-query path planning. J J Kuffner, S M Lavalle, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No. 00CH37065). 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia (Cat. No. 00CH37065)IEEE20002</p>
<p>Treebased grafting approach for bidirectional motion planning with local subsets optimization. L Zhang, Y Ling, Z Bing, F Wu, S Haddadin, A Knoll, IEEE Robotics and Automation Letters. 1062025</p>
<p>Approaches for heuristically biasing rrt growth. C Urmson, R Simmons, Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003. Cat. No. 03CH37453. 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003IEEE20032</p>
<p>Bidirectional sampling-based motion planning without two-point boundary value solution. S Nayak, M W Otte, IEEE Transactions on Robotics. 3862022</p>
<p>Estimated informed anytime search for sampling-based planning via adaptive sampler. L Zhang, K Cai, Y Zhang, Z Bing, C Wang, F Wu, S Haddadin, A Knoll, IEEE Transactions on Automation Science and Engineering. 222025</p>
<p>Batch informed trees (bit*): Informed asymptotically optimal anytime search. J D Gammell, T D Barfoot, S S Srinivasa, The International Journal of Robotics Research. 3952020</p>
<p>Advanced bit<em>(abit</em>): Samplingbased planning with advanced graph-search techniques. M P Strub, J D Gammell, 2020 IEEE International Conference on Robotics and Automation (ICRA). IEEE2020</p>
<p>Hybridizing rrt and variable-length genetic algorithm for smooth path generation. C.-H Wei, J.-S Liu, 2011 IEEE International Conference on Robotics and Biomimetics. 2011</p>
<p>Genetic rrt: Asymptotically optimal sampling-based path planning via optimization of genetic algorithm. X Wang, Highlights in Science Engineering and Technology. 432023</p>
<p>Convergence analysis of canonical genetic algorithms. G Rudolph, 19945</p>
<p>Convergence properties of evolutionary algorithms. G Rudolph, 1997Verlag Dr. Kovaƒç</p>
<p>The open motion planning library. I A Sucan, M Moll, L E Kavraki, IEEE Robotics &amp; Automation Magazine. 1942012</p>
<p>Benchmarking motion planning algorithms: An extensible infrastructure for analysis and visualization. M Moll, I A Sucan, L E Kavraki, IEEE Robotics &amp; Automation Magazine. 2232015</p>
<p>Planner developer tools (pdt): Reproducible experiments and statistical analysis for developing and testing motion planners. J D Gammell, M P Strub, V N Hartmann, Proceedings of the Workshop on Evaluating Motion Planning Performance (EMPP), IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). the Workshop on Evaluating Motion Planning Performance (EMPP), IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)2022</p>
<p>Symbolic regression is NP-hard. M Virgolin, S P Pissis, Transactions on Machine Learning Research. 2022</p>
<p>Random geometric graphs. M Penrose, OUP Oxford. 52003</p>
<p>Genetic Programming: On the Programming of Computers by Means of Natural Selection. J R Koza, 1992MIT press</p>
<p>Foundations of genetic programming. W B Langdon, R Poli, 2013Springer Science &amp; Business Media</p>
<p>R Horst, H Tuy, Global Optimization: Deterministic Approaches. Springer1996</p>
<p>Moveit! task constructor for task-level motion planning. M G√∂rner, R Haschke, H Ritter, J Zhang, IEEE International Conference on Robotics and Automation (ICRA). 2019</p>            </div>
        </div>

    </div>
</body>
</html>