<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1185 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1185</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1185</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-242246703</p>
                <p><strong>Paper Title:</strong> <a href="https://engrxiv.org/preprint/download/732/4351/3292" target="_blank">Artificial General Intelligence: A New Perspective, with Application to Scientific Discovery</a></p>
                <p><strong>Paper Abstract:</strong> The dream of building general intelligence machines has inspired scientists for decades. Remarkable advances have been made recently; however, we are still far from achieving this goal. In this paper, we review different machine learning techniques used in scientific discovery with their limitations. We survey and discuss the main principles driving the scientific discovery process. These principles are used in different fields and by different scientists to solve problems and discover new knowledge. We provide many examples of the use of these principles in different fields such as physics, mathematics, and biology. We also review AI systems that attempt to implement some of these principles. We argue that building general intelligence machines should be guided by these principles as an alternative to the dominant approach of current AI systems that focuses on narrow objectives. Building machines that fully incorporate these principles in an automated way might open the doors for many advancements.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1185.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1185.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Feynman (Udrescu & Tegmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A physics-inspired symbolic regression algorithm that combines neural network fitting with physics-inspired techniques to recover closed-form equations from data; applied to benchmark sets of physics equations and reported large improvements over prior methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Feynman</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A hybrid symbolic regression system combining neural-network-based function fitting with a suite of physics-inspired transformations and search heuristics to discover analytic expressions that fit data. Emphasizes exploiting separability, dimensional analysis and other structure to reduce search complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / Symbolic regression / Mathematical law discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Applied to datasets derived from equations in the Feynman Lectures on Physics, the system recovered closed-form physical equations from data (100-equation benchmark). Also applied to a more difficult test set where it substantially improved discovery rates versus prior state-of-the-art.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation on benchmark datasets of known physics equations (100-equation Feynman benchmark and a harder test set); measurement of whether the algorithm exactly recovers the known closed-form equations; comparison of percent of equations discovered to prior state-of-the-art.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation by exact matching to known ground-truth equations from the benchmark (i.e., comparing discovered symbolic expressions to the known equations). Comparisons against previous algorithms' outputs on the same benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by the ability to recover more ground-truth equations than prior methods on established benchmarks (recovering all 100 equations vs prior 71 on one benchmark, and boosting success rate on a harder set from 15% to 90%).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Primary metrics reported in the paper: percent of benchmark equations exactly discovered (100/100 for one benchmark; improvement from 15% to 90% on a harder set). Also compared to prior SOTA which discovered 71 equations on the same 100-equation benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>Compared quantitatively to prior automated/state-of-the-art symbolic regression algorithms (numerical success rates), not to human discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>On the 100-equation Feynman benchmark: 100% recovery (100/100) as reported; prior state-of-the-art: 71/100. On a more difficult test set: prior state-of-the-art success rate 15% improved to 90% with AI Feynman.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The paper notes general limitations of such approaches: difficulty transforming learned representations into interpretable properties without prior knowledge, and broader concerns about representation and search complexity in automated discovery systems.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1185.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI Feynman 2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Feynman 2.0 (Pareto-optimal symbolic regression exploiting graph modularity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An improved version of AI Feynman that uses Pareto-optimal symbolic regression and graph modularity to exploit structure and produce compact analytic expressions from data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI Feynman 2.0</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An evolution of the AI Feynman approach that incorporates Pareto-optimal tradeoffs and graph/modularity heuristics to guide symbolic regression toward simpler, modular expressions that balance complexity and fit.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Symbolic regression / Physics / Mathematical law discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>An algorithmic improvement intended to more efficiently discover compact analytic laws from data by exploiting modular graph structure and Pareto-optimal selection of candidate expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Referenced as an advancement in symbolic regression; evaluation implied to use Pareto-front metrics (tradeoff between expression complexity and fit) and benchmark comparisons, though specific datasets and numbers are not given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Implied validation via benchmark performance and demonstration of Pareto-optimal solutions; exact validation details are not provided in this review paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Presented as an incremental algorithmic improvement over prior symbolic regression methods by exploiting modularity and Pareto-optimal selection.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>No specific evaluation limitations detailed in this paper beyond general challenges of symbolic regression and interpretability noted for the class of approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1185.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa / Schmidt & Lipson</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distilling free-form natural laws from experimental data (Schmidt & Lipson) / Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early symbolic-regression system (often referred to as Eureqa) that searches for compact analytic expressions explaining experimental data, notable for recovering physical laws directly from measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distilling free-form natural laws from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eureqa (Schmidt & Lipson)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A symbolic regression framework that searches the space of mathematical expressions (using genetic programming and fitness metrics) to find simple analytic forms that fit empirical data, used to rediscover classical physics laws from time-series and other experimental measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / Data-driven law discovery / Symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Known for rediscovering canonical laws of motion and other physical relationships from raw experimental data by finding concise symbolic formulas that match measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluated by successful recovery of known physical laws from experimental datasets; judged by simplicity (compactness) and fit to data (error metrics) although the review paper does not provide detailed numeric evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation by comparison of discovered expressions to known ground-truth laws and by measuring fit to held-out data; reproducibility demonstrated via case studies in the original work but specifics are not given in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Assessed as a notable early demonstration that automated methods can recover human-discovered physical laws from data; novelty arises from directly producing interpretable closed-form expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>General limitations include dependence on quality/coverage of data and search scalability; the review notes symbolic-regression approaches face representational and search-cost challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1185.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The Ramanujan Machine: automatically generated conjectures on fundamental constants</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated conjecture-generation system that proposes closed-form conjectures (often continued fraction representations) relating mathematical constants, producing novel conjectures for human mathematicians to consider.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The ramanujan machine: automatically generated conjectures on fundamental constants</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ramanujan Machine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that searches for conjectural closed-form relationships (e.g., continued-fraction or series representations) involving fundamental mathematical constants, producing conjectures algorithmically rather than proving them.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics (number theory / constants)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automatically generated conjectures about relationships among fundamental constants; produces candidate formulas and conjectures that can be later verified or proven by mathematicians.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation consists of producing conjectures; the paper mentions the system in the context of automated conjecture generation but does not detail evaluation metrics within this review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation of outcomes typically requires subsequent mathematical proof or numerical verification by humans; the review does not supply validation details.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is in automated generation of mathematically interesting conjectures; assessed by the production of previously unknown candidate formulas for fundamental constants.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The system generates conjectures but does not (in itself) provide proofs; thus validation and establishing significance remains dependent on human mathematicians. The review notes automation of conjecture generation but not transformative proof automation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1185.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientists</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientists for autonomous scientific discovery (Sparkes et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Laboratory automation platforms that integrate hypothesis generation, experiment planning, robotic execution, and analysis to perform autonomous cycles of discovery in domains like biology and chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards Robot Scientists for autonomous scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot Scientists</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrated experimental automation systems that combine hypothesis generation, automated experimental execution (robotics), data acquisition, and analysis to close the loop on autonomous discovery workflows, typically applied in laboratory sciences.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Biology / Laboratory sciences / Experimental discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>These systems have been used to autonomously carry out experiments and generate candidate discoveries within constrained laboratory domains (for example, hypothesis-driven experiments in molecular biology), automating parts of the scientific workflow.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluations typically involve case studies showing autonomous execution of hypothesis-driven experiments and successful identification of expected outcomes or novel observations; this review cites the work but does not give numeric evaluation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation done via experimental replication, comparison to expected/known biological results, and demonstration of autonomous closed-loop operation; specifics are not detailed in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty assessed by ability to automate experimental cycles and generate results with reduced human intervention; considered an early step toward automated scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include automating complex domains, building rich representations/models of the world, and scaling robotic experimentation; review emphasizes theoretical/computational framework gaps for full automation.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1185.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zenil et al.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal deconvolution by algorithmic generative models (Zenil et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised, parameter-free approach using algorithmic probability to decompose observations into likely algorithmic generative models, demonstrated to deconvolve interacting mechanisms across different data types.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal deconvolution by algorithmic generative models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Algorithmic-probability deconvolution (Zenil et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A universal, unsupervised, parameter-free model-oriented method grounded in algorithmic probability to decompose observations into likely generative programs; applied across bit strings, images, and networks.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Computational science / Causal inference / Complex systems</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Demonstrated ability to deconvolve interacting generative mechanisms from observed data, identifying underlying algorithmic generative models that could explain emergent structures in diverse modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluated by case studies demonstrating deconvolution across data types (bit strings, images, networks); judged by ability to recover plausible generative mechanisms irrespective of data modality.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation through demonstration on controlled examples and showing deconvolution success across modalities; details in original cited work rather than in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty lies in applying algorithmic probability to a universal, modality-agnostic deconvolution problem and demonstrating generative-model recovery across different data types.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The review highlights general challenges of building representations and models of the world; for this approach, scaling and practical application details are subject to the limitations of algorithmic-probability approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1185.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous Chemistry (Coley et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous discovery in the chemical sciences (Coley, Eyke, Jensen)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of methods and platforms integrating machine learning, automation, and experiment planning to accelerate materials and molecular discovery, discussed as progress and outlook in autonomous chemical discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous discovery in the chemical sciences part I: Progress</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Autonomous chemical discovery platforms</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Integrated systems combining ML-guided experiment planning, automated synthesis/characterization, and closed-loop optimization to propose and test candidate molecules/materials with reduced human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry / Materials science / Molecular discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Applied to accelerate molecule and materials discovery through closed-loop design-make-test cycles; the review notes significant progress and presents the research landscape rather than a single system's new discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation methods in the cited literature typically include metrics like discovery throughput, hit rates of desirable properties, and autonomous cycle efficiency; the review references the work but does not present specific quantitative metrics here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation commonly entails experimental synthesis/characterization of predicted candidates and comparison to baseline discovery processes; details are in the cited primary literature.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty judged by degree of autonomy achieved (closed-loop experiments, ML-guided decisions) and successful application to real discovery tasks in chemistry and materials science.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include experimental cost, scaling of laboratory automation, and the need for principled frameworks that encapsulate scientific discovery principles (representation, hypothesis space reduction).</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1185.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1185.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AM / EURISKO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AM and EURISKO (Lenat)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Historical AI systems for discovery and heuristic learning: AM focused on heuristic search for mathematical discovery; EURISKO learned heuristics and domain concepts to generate novel solutions and heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AM and EURISKO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Early heuristic-based discovery systems: AM performed search-based discovery in mathematics; EURISKO extended the idea to learn new heuristics and domain concepts, enabling exploration and invention within constrained domains.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Mathematics / Heuristic discovery / Early AI</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Demonstrated automated heuristic search to generate novel conjectures, heuristics, and domain concepts in mathematical/problem-solving domains; historically influential as examples of machine-led discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluated historically via qualitative case studies and examples of generated heuristics/concepts; this review references them as influential prior work without quantitative metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation historically performed by human inspection of generated concepts/heuristics and by their subsequent usefulness in problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novel at the time for demonstrating automated concept invention and heuristic learning; assessed historically by the novelty/usefulness of generated heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Noted limitations include brittleness, shallow-level operation without deep world models, and dependence on well-formed input knowledge; the review highlights representational limitations for concept-combination systems.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AI Feynman: a Physics-Inspired Method for Symbolic Regression <em>(Rating: 2)</em></li>
                <li>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity <em>(Rating: 2)</em></li>
                <li>Distilling free-form natural laws from experimental data <em>(Rating: 2)</em></li>
                <li>The ramanujan machine: automatically generated conjectures on fundamental constants <em>(Rating: 2)</em></li>
                <li>Towards Robot Scientists for autonomous scientific discovery <em>(Rating: 2)</em></li>
                <li>Causal deconvolution by algorithmic generative models <em>(Rating: 2)</em></li>
                <li>Autonomous discovery in the chemical sciences part I: Progress <em>(Rating: 2)</em></li>
                <li>AM: An artificial intelligence approach to discovery in mathematics as heuristic search <em>(Rating: 1)</em></li>
                <li>EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1185",
    "paper_id": "paper-242246703",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "AI Feynman",
            "name_full": "AI Feynman (Udrescu & Tegmark)",
            "brief_description": "A physics-inspired symbolic regression algorithm that combines neural network fitting with physics-inspired techniques to recover closed-form equations from data; applied to benchmark sets of physics equations and reported large improvements over prior methods.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "AI Feynman",
            "system_description": "A hybrid symbolic regression system combining neural-network-based function fitting with a suite of physics-inspired transformations and search heuristics to discover analytic expressions that fit data. Emphasizes exploiting separability, dimensional analysis and other structure to reduce search complexity.",
            "discovery_domain": "Physics / Symbolic regression / Mathematical law discovery",
            "discovery_description": "Applied to datasets derived from equations in the Feynman Lectures on Physics, the system recovered closed-form physical equations from data (100-equation benchmark). Also applied to a more difficult test set where it substantially improved discovery rates versus prior state-of-the-art.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluation on benchmark datasets of known physics equations (100-equation Feynman benchmark and a harder test set); measurement of whether the algorithm exactly recovers the known closed-form equations; comparison of percent of equations discovered to prior state-of-the-art.",
            "validation_approaches": "Validation by exact matching to known ground-truth equations from the benchmark (i.e., comparing discovered symbolic expressions to the known equations). Comparisons against previous algorithms' outputs on the same benchmarks.",
            "novelty_assessment": "Novelty assessed by the ability to recover more ground-truth equations than prior methods on established benchmarks (recovering all 100 equations vs prior 71 on one benchmark, and boosting success rate on a harder set from 15% to 90%).",
            "impact_metrics": "Primary metrics reported in the paper: percent of benchmark equations exactly discovered (100/100 for one benchmark; improvement from 15% to 90% on a harder set). Also compared to prior SOTA which discovered 71 equations on the same 100-equation benchmark.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "Compared quantitatively to prior automated/state-of-the-art symbolic regression algorithms (numerical success rates), not to human discoveries.",
            "success_rate": "On the 100-equation Feynman benchmark: 100% recovery (100/100) as reported; prior state-of-the-art: 71/100. On a more difficult test set: prior state-of-the-art success rate 15% improved to 90% with AI Feynman.",
            "challenges_limitations": "The paper notes general limitations of such approaches: difficulty transforming learned representations into interpretable properties without prior knowledge, and broader concerns about representation and search complexity in automated discovery systems.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.0"
        },
        {
            "name_short": "AI Feynman 2.0",
            "name_full": "AI Feynman 2.0 (Pareto-optimal symbolic regression exploiting graph modularity)",
            "brief_description": "An improved version of AI Feynman that uses Pareto-optimal symbolic regression and graph modularity to exploit structure and produce compact analytic expressions from data.",
            "citation_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",
            "mention_or_use": "mention",
            "system_name": "AI Feynman 2.0",
            "system_description": "An evolution of the AI Feynman approach that incorporates Pareto-optimal tradeoffs and graph/modularity heuristics to guide symbolic regression toward simpler, modular expressions that balance complexity and fit.",
            "discovery_domain": "Symbolic regression / Physics / Mathematical law discovery",
            "discovery_description": "An algorithmic improvement intended to more efficiently discover compact analytic laws from data by exploiting modular graph structure and Pareto-optimal selection of candidate expressions.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Referenced as an advancement in symbolic regression; evaluation implied to use Pareto-front metrics (tradeoff between expression complexity and fit) and benchmark comparisons, though specific datasets and numbers are not given in this paper.",
            "validation_approaches": "Implied validation via benchmark performance and demonstration of Pareto-optimal solutions; exact validation details are not provided in this review paper.",
            "novelty_assessment": "Presented as an incremental algorithmic improvement over prior symbolic regression methods by exploiting modularity and Pareto-optimal selection.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "No specific evaluation limitations detailed in this paper beyond general challenges of symbolic regression and interpretability noted for the class of approaches.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.1"
        },
        {
            "name_short": "Eureqa / Schmidt & Lipson",
            "name_full": "Distilling free-form natural laws from experimental data (Schmidt & Lipson) / Eureqa",
            "brief_description": "An early symbolic-regression system (often referred to as Eureqa) that searches for compact analytic expressions explaining experimental data, notable for recovering physical laws directly from measurements.",
            "citation_title": "Distilling free-form natural laws from experimental data",
            "mention_or_use": "mention",
            "system_name": "Eureqa (Schmidt & Lipson)",
            "system_description": "A symbolic regression framework that searches the space of mathematical expressions (using genetic programming and fitness metrics) to find simple analytic forms that fit empirical data, used to rediscover classical physics laws from time-series and other experimental measurements.",
            "discovery_domain": "Physics / Data-driven law discovery / Symbolic regression",
            "discovery_description": "Known for rediscovering canonical laws of motion and other physical relationships from raw experimental data by finding concise symbolic formulas that match measurements.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluated by successful recovery of known physical laws from experimental datasets; judged by simplicity (compactness) and fit to data (error metrics) although the review paper does not provide detailed numeric evaluations.",
            "validation_approaches": "Validation by comparison of discovered expressions to known ground-truth laws and by measuring fit to held-out data; reproducibility demonstrated via case studies in the original work but specifics are not given in this review.",
            "novelty_assessment": "Assessed as a notable early demonstration that automated methods can recover human-discovered physical laws from data; novelty arises from directly producing interpretable closed-form expressions.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "General limitations include dependence on quality/coverage of data and search scalability; the review notes symbolic-regression approaches face representational and search-cost challenges.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.2"
        },
        {
            "name_short": "Ramanujan Machine",
            "name_full": "The Ramanujan Machine: automatically generated conjectures on fundamental constants",
            "brief_description": "An automated conjecture-generation system that proposes closed-form conjectures (often continued fraction representations) relating mathematical constants, producing novel conjectures for human mathematicians to consider.",
            "citation_title": "The ramanujan machine: automatically generated conjectures on fundamental constants",
            "mention_or_use": "mention",
            "system_name": "Ramanujan Machine",
            "system_description": "A system that searches for conjectural closed-form relationships (e.g., continued-fraction or series representations) involving fundamental mathematical constants, producing conjectures algorithmically rather than proving them.",
            "discovery_domain": "Mathematics (number theory / constants)",
            "discovery_description": "Automatically generated conjectures about relationships among fundamental constants; produces candidate formulas and conjectures that can be later verified or proven by mathematicians.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluation consists of producing conjectures; the paper mentions the system in the context of automated conjecture generation but does not detail evaluation metrics within this review.",
            "validation_approaches": "Validation of outcomes typically requires subsequent mathematical proof or numerical verification by humans; the review does not supply validation details.",
            "novelty_assessment": "Novelty is in automated generation of mathematically interesting conjectures; assessed by the production of previously unknown candidate formulas for fundamental constants.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "The system generates conjectures but does not (in itself) provide proofs; thus validation and establishing significance remains dependent on human mathematicians. The review notes automation of conjecture generation but not transformative proof automation.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.3"
        },
        {
            "name_short": "Robot Scientists",
            "name_full": "Robot Scientists for autonomous scientific discovery (Sparkes et al.)",
            "brief_description": "Laboratory automation platforms that integrate hypothesis generation, experiment planning, robotic execution, and analysis to perform autonomous cycles of discovery in domains like biology and chemistry.",
            "citation_title": "Towards Robot Scientists for autonomous scientific discovery",
            "mention_or_use": "mention",
            "system_name": "Robot Scientists",
            "system_description": "Integrated experimental automation systems that combine hypothesis generation, automated experimental execution (robotics), data acquisition, and analysis to close the loop on autonomous discovery workflows, typically applied in laboratory sciences.",
            "discovery_domain": "Biology / Laboratory sciences / Experimental discovery",
            "discovery_description": "These systems have been used to autonomously carry out experiments and generate candidate discoveries within constrained laboratory domains (for example, hypothesis-driven experiments in molecular biology), automating parts of the scientific workflow.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluations typically involve case studies showing autonomous execution of hypothesis-driven experiments and successful identification of expected outcomes or novel observations; this review cites the work but does not give numeric evaluation metrics.",
            "validation_approaches": "Validation done via experimental replication, comparison to expected/known biological results, and demonstration of autonomous closed-loop operation; specifics are not detailed in this review.",
            "novelty_assessment": "Novelty assessed by ability to automate experimental cycles and generate results with reduced human intervention; considered an early step toward automated scientific discovery.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "Challenges include automating complex domains, building rich representations/models of the world, and scaling robotic experimentation; review emphasizes theoretical/computational framework gaps for full automation.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.4"
        },
        {
            "name_short": "Zenil et al.",
            "name_full": "Causal deconvolution by algorithmic generative models (Zenil et al.)",
            "brief_description": "An unsupervised, parameter-free approach using algorithmic probability to decompose observations into likely algorithmic generative models, demonstrated to deconvolve interacting mechanisms across different data types.",
            "citation_title": "Causal deconvolution by algorithmic generative models",
            "mention_or_use": "mention",
            "system_name": "Algorithmic-probability deconvolution (Zenil et al.)",
            "system_description": "A universal, unsupervised, parameter-free model-oriented method grounded in algorithmic probability to decompose observations into likely generative programs; applied across bit strings, images, and networks.",
            "discovery_domain": "Computational science / Causal inference / Complex systems",
            "discovery_description": "Demonstrated ability to deconvolve interacting generative mechanisms from observed data, identifying underlying algorithmic generative models that could explain emergent structures in diverse modalities.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluated by case studies demonstrating deconvolution across data types (bit strings, images, networks); judged by ability to recover plausible generative mechanisms irrespective of data modality.",
            "validation_approaches": "Validation through demonstration on controlled examples and showing deconvolution success across modalities; details in original cited work rather than in this review.",
            "novelty_assessment": "Novelty lies in applying algorithmic probability to a universal, modality-agnostic deconvolution problem and demonstrating generative-model recovery across different data types.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "The review highlights general challenges of building representations and models of the world; for this approach, scaling and practical application details are subject to the limitations of algorithmic-probability approximations.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.5"
        },
        {
            "name_short": "Autonomous Chemistry (Coley et al.)",
            "name_full": "Autonomous discovery in the chemical sciences (Coley, Eyke, Jensen)",
            "brief_description": "A set of methods and platforms integrating machine learning, automation, and experiment planning to accelerate materials and molecular discovery, discussed as progress and outlook in autonomous chemical discovery.",
            "citation_title": "Autonomous discovery in the chemical sciences part I: Progress",
            "mention_or_use": "mention",
            "system_name": "Autonomous chemical discovery platforms",
            "system_description": "Integrated systems combining ML-guided experiment planning, automated synthesis/characterization, and closed-loop optimization to propose and test candidate molecules/materials with reduced human intervention.",
            "discovery_domain": "Chemistry / Materials science / Molecular discovery",
            "discovery_description": "Applied to accelerate molecule and materials discovery through closed-loop design-make-test cycles; the review notes significant progress and presents the research landscape rather than a single system's new discoveries.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluation methods in the cited literature typically include metrics like discovery throughput, hit rates of desirable properties, and autonomous cycle efficiency; the review references the work but does not present specific quantitative metrics here.",
            "validation_approaches": "Validation commonly entails experimental synthesis/characterization of predicted candidates and comparison to baseline discovery processes; details are in the cited primary literature.",
            "novelty_assessment": "Novelty judged by degree of autonomy achieved (closed-loop experiments, ML-guided decisions) and successful application to real discovery tasks in chemistry and materials science.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "Challenges include experimental cost, scaling of laboratory automation, and the need for principled frameworks that encapsulate scientific discovery principles (representation, hypothesis space reduction).",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.6"
        },
        {
            "name_short": "AM / EURISKO",
            "name_full": "AM and EURISKO (Lenat)",
            "brief_description": "Historical AI systems for discovery and heuristic learning: AM focused on heuristic search for mathematical discovery; EURISKO learned heuristics and domain concepts to generate novel solutions and heuristics.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "AM and EURISKO",
            "system_description": "Early heuristic-based discovery systems: AM performed search-based discovery in mathematics; EURISKO extended the idea to learn new heuristics and domain concepts, enabling exploration and invention within constrained domains.",
            "discovery_domain": "Mathematics / Heuristic discovery / Early AI",
            "discovery_description": "Demonstrated automated heuristic search to generate novel conjectures, heuristics, and domain concepts in mathematical/problem-solving domains; historically influential as examples of machine-led discovery.",
            "discovery_type": "",
            "discovery_type_justification": "",
            "evaluation_methods": "Evaluated historically via qualitative case studies and examples of generated heuristics/concepts; this review references them as influential prior work without quantitative metrics.",
            "validation_approaches": "Validation historically performed by human inspection of generated concepts/heuristics and by their subsequent usefulness in problem solving.",
            "novelty_assessment": "Novel at the time for demonstrating automated concept invention and heuristic learning; assessed historically by the novelty/usefulness of generated heuristics.",
            "impact_metrics": "",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "",
            "challenges_limitations": "Noted limitations include brittleness, shallow-level operation without deep world models, and dependence on well-formed input knowledge; the review highlights representational limitations for concept-combination systems.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1185.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AI Feynman: a Physics-Inspired Method for Symbolic Regression",
            "rating": 2,
            "sanitized_title": "ai_feynman_a_physicsinspired_method_for_symbolic_regression"
        },
        {
            "paper_title": "AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity",
            "rating": 2,
            "sanitized_title": "ai_feynman_20_paretooptimal_symbolic_regression_exploiting_graph_modularity"
        },
        {
            "paper_title": "Distilling free-form natural laws from experimental data",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "The ramanujan machine: automatically generated conjectures on fundamental constants",
            "rating": 2,
            "sanitized_title": "the_ramanujan_machine_automatically_generated_conjectures_on_fundamental_constants"
        },
        {
            "paper_title": "Towards Robot Scientists for autonomous scientific discovery",
            "rating": 2,
            "sanitized_title": "towards_robot_scientists_for_autonomous_scientific_discovery"
        },
        {
            "paper_title": "Causal deconvolution by algorithmic generative models",
            "rating": 2,
            "sanitized_title": "causal_deconvolution_by_algorithmic_generative_models"
        },
        {
            "paper_title": "Autonomous discovery in the chemical sciences part I: Progress",
            "rating": 2,
            "sanitized_title": "autonomous_discovery_in_the_chemical_sciences_part_i_progress"
        },
        {
            "paper_title": "AM: An artificial intelligence approach to discovery in mathematics as heuristic search",
            "rating": 1,
            "sanitized_title": "am_an_artificial_intelligence_approach_to_discovery_in_mathematics_as_heuristic_search"
        },
        {
            "paper_title": "EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results",
            "rating": 1,
            "sanitized_title": "eurisko_a_program_that_learns_new_heuristics_and_domain_concepts_the_nature_of_heuristics_iii_program_design_and_results"
        }
    ],
    "cost": 0.013951999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Artificial General Intelligence: A New Perspective, with Application to Scientific Discovery</p>
<p>A M Khalili a.m.khalili@outlook.com 
Artificial General Intelligence: A New Perspective, with Application to Scientific Discovery
917CAD163A7A98CEDDF3BEE23EE66E6AAIArtificial IntelligenceMachine LearningScience AutomationScientific Discovery
The dream of building general intelligence machines has inspired scientists for decades.Remarkable advances have been made recently; however, we are still far from achieving this goal.In this paper, we review different machine learning techniques used in scientific discovery with their limitations.We survey and discuss the main principles driving the scientific discovery process.These principles are used in different fields and by different scientists to solve problems and discover new knowledge.We provide many examples of the use of these principles in different fields such as physics, mathematics, and biology.We also review AI systems that attempt to implement some of these principles.We argue that building general intelligence machines should be guided by these principles as an alternative to the dominant approach of current AI systems that focuses on narrow objectives.Building machines that fully incorporate these principles in an automated way might open the doors for many advancements.</p>
<p>Introduction</p>
<p>In [1][2] Penrose talked about the existence of three different worlds: the mental world, the physical world, and the mathematical world.The physical world is governed by laws that reside in the world of mathematics, our minds emerge from the physical world, and those minds are able to access the mathematical world by discovering mathematics, which is within the scope of reason.</p>
<p>In the mathematical world, Bourbaki [5] likened mathematics to a city, where the outlying districts expand on the surrounding country.Plato believed that ideas or forms exist in some ideal world outside the physical world, which became later known as the 'Platonic world of forms' [3].If Plato's realm exists, it is very unlikely that different parts of such realm are disconnected and do not have links with each other, they would be beautifully connected and one can navigate between different parts of that realm, and discover new hidden structures.</p>
<p>Although on rare occasions, the intellect might break through into those worlds and get a limited glimpse of those realms as described by Penrose [1], and illustrated through many examples by Hadamard [6], still in most times we follow certain procedures and principles to reconstruct those realms.Similar to the mathematical and physical worlds, a curtail aspect of the mental world and hence Artificial General Intelligence (AGI) is to build the maps that represent other realms by using a set of principles to reconstruct these original worlds and discover new knowledge.Today these principles represent the major driving force of the scientific discovery process.We argue that these principles should be used as guiding principles for building science discovery machines.The landscape of AGI is extremely vast, in this paper we will focus on the scientific discovery process [6-8, 33-37, 41-42, 54-55, 77, 81, 85, 87-91, 116-123, 149].problems, this approach has key limitations in its generalization ability as discussed in earlier sections.The evolution-inspired path [83,[126][127] could provide an alternative way to build more general AI systems.However, the extremely large search space and the existence of many complex interacting parts still represent a major obstacle.In this study, we argue that the building of these systems should be guided by a set of principles as an alternative of narrow objectives or open-ended evolution.The use of these principles is backed by many historical examples of how different scientists made their discovery.Most scientific discoveries could be understood as instances of the use of one or more of these principles.They are the main approach used by scientists to solve problems and discover new knowledge.The use of these principles provides a way for machine learning systems to improve their generalization ability and to cut down the large search space of hypotheses by approaching the given problem using these principles in template ways as an alternative of the expensive random search..In addition to logic, which plays an important role in the scientific discovery process, in reality, logic alone is not enough, we usually use more sophisticated principles and structures.In the literature, there is a focus on two main principles, concepts combination and analogies.However, other principles should be taken into account to build a comprehensive framework.Different problems in science can be solved using one or more of these principles by using these principles in template ways.For instance, some problems require finding the equation that fits the experimental data, some problems require finding the optimization criteria that give rise to the observed phenomenon, other problems require finding the rules or the program that gives rise to the observed phenomenon, many problems require combining different ideas, unifying ideas or finding analogy with other ideas, and so on.Each scientific problem comes with an objective to meet, the problem could be approached by these principles to find which principle best satisfy the objective.These principles should seek to expand the knowledge base by discovering new knowledge, they should also reveal new connections that link different concepts.Proposing theoretical and computational frameworks that encapsulate these principles is beyond the scope of this paper.These principles can be summarized as follow</p>
<p>Mathematization</p>
<p>Mathematics is a very powerful tool to describe the natural world [30][31][32].Mathematics today is very effective in studying fields as diverse as physics, computer science, finance, and biology.Mathematics is not only able to describe the natural world, but this description on many occasions led us to predict and discover new aspects of the studied phenomena.On many occasions, testing the mathematical description in new extreme conditions led to new insights and sometimes to new theories.In 1915 for instance, General Relativity (GR) was at the frontier of the map of physics, many physicists used mathematics to derive new knowledge from the GR equation, they were able to predict gravitational waves, and black holes as solutions to the GR equation, both of these phenomena were confirmed experimentally in the few recent years.</p>
<p>In AI, there are many attempts to build symbolic regression algorithms, which are automated tools to find the mathematical equation that fits the experimental data [33].Udrescu and Tegmark [34,148] developed an algorithm that combines neural network fitting with a set of physics-inspired techniques.They applied it to 100 equations from the Feynman lectures on physics.It was able to discover all of them; the state of the art algorithm was only able to discover 71.For a more difficult test set, the state of the art success rate was improved from 15% to 90%.Many researchers recently [35][36][37] started to use recent advances in deep learning such as generative adversarial networks to discover physical concepts from experimental data without being provided with any additional prior knowledge and then use the discovered representation to answer questions about the physical system.The main limitation of these approaches is that it is difficult to transform the learned representations into interpretable properties unless prior knowledge is available.The main purpose of the algorithm that encapsulates the mathematization principle would be to find the equations that describe the experimental data.</p>
<p>Optimization</p>
<p>Optimization is one of the most powerful and most used principles from the least action principle in physics, survival of the fittest in biology, and utility maximization in economics, see [134][135] for a long list of examples from different disciplines.Optimization is one of the most used principles in everyday life, we constantly try to minimize energy, cost, distance, time, etc.Some other notable uses of this principle in science include minimizing the energy and time that are required to distribute fuels to the cells, gives rise to the circulatory system networks [27].Optimizing the balance between the input and output energy gives rise to bird migration patterns [28].Increasing entropy drives matter to acquire life-like physical properties [29].The main purpose of the algorithm that encapsulates the optimization principle would be to find the optimization criteria and constraints that describe the studied problem.</p>
<p>Analogies</p>
<p>Many prominent cognitive scientists [38] consider analogy to be one of the main building blocks of human cognition.There are many examples where analogy has played a crucial role in scientific discovery.Polya [39] observed that analogy has played a role in most mathematical discoveries.He provided many historical examples where analogy played the main role.See [40] for a long list of the use of analogy in scientific discovery.Nersessian [41][42] also gave a list of examples such as Newton's analogy between projectiles and the moon which gave rise to universal gravitation, Darwin's analogy between selective breeding and reproduction in nature which gave rise to natural selection, and the Rutherford-Bohr analogy between the structure of the solar system and the configuration of subatomic particles.Many algorithms in computer science have been inspired from biology to solve different problems such as the traveling salesman problem [43], [44].They took inspirations from ants, which are capable of finding the shortest path from the nest to a food source [45], [46], by using a chemical substance called pheromone.Other notable examples include genetic algorithms, see [47][48][49] for a list of bio-inspired algorithms.</p>
<p>Two of the most remarkable approaches to this principle are the High-Level Perception (HLP) theory of analogy [94] and the Structure Mapping Theory (SMT) [22,25], however; building representations and models of the world still represents a major obstacle for these approaches.Hill et al. [93] investigated the use of neural networks to solve analogical problems, they also took inspiration from both SMT and HLP, where they encouraged the models to compare inputs at the more abstract level of relations rather than the less abstract level of attributes.Zhang et al. [26] also took inspiration from the field of psychology and education where teaching new concepts by comparing with noisy examples is shown to be effective.They build a model that sets the new state-of-the-art on two major Raven's Progressive Matrices datasets.One key limitation of the deep learning approach is the lack of transparency where the biases in many of the used datasets often lead to finding shortcuts instead of finding the real analogy [115,[132][133].See [22,25,[93][94][95][96]115] for different theoretical and computational frameworks for the analogy principle.The main purpose of the algorithm that encapsulates the analogy principle would be to find matching between the studied problem and similar problems.</p>
<p>Concepts Combination</p>
<p>Concepts combination is a fundamental cognitive principle [50][51][52].Many scientific discoveries are based on conceptual combination, where new concepts arise by combining old ones [53][54][55].Concepts combination is also one of the main used themes in theoretical physics.In 1973 for instance, both general relativity and quantum mechanics were at the frontier of the map of physics, by combining ideas from these two fields, Hawking proposed that black holes emit thermal radiation.Moreover, by combining ideas from quantum mechanics and statistical mechanics, Bekenstein and Hawking proposed the formula that describes the black hole entropy, which later led to the holographic principle.</p>
<p>Some of the most notable approaches include conceptual blending [50], amalgamation [23], and compositional adaptation [24].These techniques combine input concepts from a knowledge base and output novel concepts.See [23, 24, 50, 56-57, 113, 114] for different theoretical and computational frameworks.One major limitation of these techniques is that they require well-formed knowledge as input.Furthermore, without deeper representations and models of the world these approaches and other AI systems will keep operating at a very shallow level.</p>
<p>Emergence</p>
<p>Emergence is a powerful approach to explain complex behaviors by simple underlying rules.One notable example is birds flocking, some birds fly in coordinated flocks that show remarkable synchronization in movements.Heppner [60] showed that the coordinated movements could be the result of simple movement rules followed by each bird individually.Another example is the Game of Life [61], a two-dimensional cellular automaton with rules that avoid the formation of structures that grow freely or quickly disappear.Remarkable behaviors have been observed such as the glider, a small group of cells that moves like an independent emergent entity.Graph neural networks could be more suitable than other techniques to model complex systems with multiple interacting parts.The main purpose of the algorithm that encapsulates the emergence principle would be to find the set of rules that gives rise to the emergent behavior.</p>
<p>Computability</p>
<p>Computation is a new paradigm that has revolutionized science and engineering [63,82], it has derived many advancements in science and changed the way it is done.Many biologists would agree that biology is information science.One of the most notable examples is the DNA, which gives rise to the whole biological system.A growing number of physicists would also agree that the interactions between physical systems are information processing [64][65].Zenil et al. [81] proposed a universal unsupervised and parameter-free model-oriented approach based on the concept of algorithmic probability to decompose an observation into its most likely algorithmic generative models.They demonstrated the ability of the approach to deconvolve interacting mechanisms regardless of whether the resulted objects are bit strings, images, or networks.A related topic is using machine learning for code generation (see [98] for a recent survey).The main purpose of the algorithm that encapsulates the computability principle would be to find the program that gives rise to the observed phenomenon.</p>
<p>Beauty</p>
<p>Aesthetic judgments play a guiding role in scientific discovery [66][67][68][69].Scientists often evaluate models and theories based on their aesthetic appeal.Many scientists have even suggested that the goal of science is to find beauty in nature.</p>
<p>The role of beauty in science has found some skepticism because we still do not have a satisfactory theory that can exactly test the claims made by scientists about the beauty of a theory [71].Recent works on empirical aesthetics [111] show that there is a general agreement on what is considered beautiful, despite the subjectivity of beauty appreciation.A recent interesting study about the nature of aesthetic in science by Zeki et al. [72] demonstrated that the aesthetic appreciation of mathematical equations corresponds to the same brain activity that corresponds to the appreciation of music and art.Zee [73], Thuan [74], and Dirac [70] also argued that beauty's attributes such as simplicity, symmetry, and elegance have universal values and that they should not be subject to revision in science.</p>
<p>Recent approaches for beauty assessments of visual contents [130][131] could shed new lights on how to assess different scientific models.Deep learning could be particularly interesting where promising results were reported.The main purpose of the algorithm that encapsulates the beauty principle would be to find a metric that evaluates the scientific model describing the observed phenomenon.</p>
<p>Universality</p>
<p>Universality means that a similar mathematical formulation can describe different phenomena across multiple fields.The spectral measurements of composite materials, such as sea ice and human bones, the time between the buses' arrival in the city of Cuernavaca in Mexico, the zeros of the Riemann zeta function, and many other phenomena have shown to have the same statistical distribution [58].Power laws are another example of universal laws that have been observed in a wide range of phenomena in fields as diverse as physics, biology, and computer science [59].Recently, Mocanu et al. [144] were able to significantly reduce the number of parameters of deep learning models with no decrease in performance by enforcing a power law distribution.</p>
<p>Unification</p>
<p>Unification [150][151] has played a key role in physics since Newton who unified celestial and terrestrial mechanics, Maxwell who unified electricity and magnetism, then the unification of the weak and the electromagnetic forces, and most recently the attempts to unify all the four fundamental forces.Unification has also played an important role in biology [140][141].In addition to several attempts to unify different machine learning approaches such as neuro-symbolic [15,92], neuro-evolution [143], and many others [10,14].</p>
<p>Symmetry</p>
<p>Symmetry has played an important role in science [75,[136][137][138][139] from Newton's laws to Maxwell's equations, and general relativity.Symmetry has also played a fundamental role in the development of quantum mechanics.Today, it is one of the most used principles in searching for the fundamental laws of physics and further unification.Convolutional neural networks represent an early use of the symmetry principle in deep learning.</p>
<p>Recently, more advanced symmetry was used to significantly reduce the number of examples required to train deep learning models [142].</p>
<p>Many of these principles could operate at different levels, for instance, the circulatory system example in the optimization principle.By studying the literatures, one can find that the energy and time should be minimized; here the optimization principle is operating at the conceptual level.Then the principle could operate at the mathematical level by using a mathematical description of the optimization process.Similar reasoning could be applied for other principles such as concepts combination where the ideas are firstly combined at the conceptual level and then at the mathematical level.</p>
<p>Discussion and Conclusion</p>
<p>This paper has presented a review of different machine learning techniques used in scientific discovery with their limitations.It discussed and reviewed the main principles used by scientists to solve problems and discover new knowledge.We argue that a key step to improve the generalization ability of AI systems is to build systems guided by these principles rather than focusing on solving specific and narrow problems, or searching the extremely large space of the evolution-inspired approaches.The main challenge to build science discovery machines and automate the scientific discovery process is to build the theoretical and computational frameworks that encapsulate these principles.Although some principles are harder to automate where the challenge of building representation and models of the world is more dominant such as concepts combination and analogy.However, a lot of progress can be made in working on other principles such as mathematization, emergence, etc. Deep learning could be a very effective tool to implement some of these principles, it has shown promising results for the mathematization principle.However, it might be limited for other principles.In the literature, there is a focus on few principles, we believe that there are rooms for many interesting future contributions by working on the rest of the principles by building different theoretical and computational frameworks or by investigating the use of some existing AI techniques.Incorporating these principles fully in an automated scientific discovery framework might open the doors for many advancements.Pursuing this research direction holds a great promise to help scientist in their research and to speed up the scientific discovery process.</p>
<p>The emperor's new mind: Concerning computers, minds, and the laws of physics. R Penrose, N D Mermin, 1990</p>
<p>The road to reality: A complete guide to the physical universe. R Penrose, 2004Jonathan Cape</p>
<p>Plato's theory of ideas. D Ross, 1953</p>
<p>M Aigner, G M Ziegler, K H Hofmann, P Erdos, Proofs from the Book. BerlinSpringer2010274</p>
<p>The architecture of mathematics. N Bourbaki, The American Mathematical Monthly. 5741950</p>
<p>The mathematician's mind: The psychology of invention in the mathematical field. J Hadamard, 1996</p>
<p>Scientific thinking and reasoning. The Cambridge handbook of thinking and reasoning. K Dunbar, J Fugelsang, 2005</p>
<p>Towards Robot Scientists for autonomous scientific discovery. A Sparkes, W Aubrey, E Byrne, A Clare, M N Khan, M Liakata, . . Young, M , Automated Experimentation. 2112010</p>
<p>Future progress in artificial intelligence: A survey of expert opinion. V C Mller, N Bostrom, Fundamental issues of artificial intelligence. ChamSpringer2016</p>
<p>The master algorithm: How the quest for the ultimate learning machine will remake our world. P Domingos, 2015Basic Books</p>
<p>The limitations of deep learning in adversarial settings. N Papernot, P Mcdaniel, S Jha, M Fredrikson, Z B Celik, A Swami, 2016 IEEE European Symposium on Security and Privacy (EuroS&amp;P). IEEE2016, March</p>
<p>Adversarial examples: Attacks and defenses for deep learning. X Yuan, P He, Q Zhu, X Li, 2019</p>
<p>One pixel attack for fooling deep neural networks. J Su, D V Vargas, K Sakurai, IEEE Transactions on Evolutionary Computation. 2019</p>
<p>Unifying logical and statistical AI with Markov logic. P Domingos, D Lowd, Communications of the ACM. 6272019</p>
<p>&amp; de Penning, L. T R Besold, A D A Garcez, S Bader, H Bowman, P Domingos, P Hitzler, arXiv:1711.03902Neural-symbolic learning and reasoning: A survey and interpretation. 2017arXiv preprint</p>
<p>Mapping the landscape of human-level artificial general intelligence. S Adams, I Arel, J Bach, R Coop, R Furlan, B Goertzel, . . Shapiro, S C , AI magazine. 3312012</p>
<p>Artificial general intelligence: concept, state of the art, and future prospects. B Goertzel, Journal of Artificial General Intelligence. 512014</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and brain sciences. 402017</p>
<p>AM: An artificial intelligence approach to discovery in mathematics as heuristic search (No. STAN-CS-76-570). D B Lenat, STANFORD UNIV CA DEPT OF COMPUTER SCIENCE1976</p>
<p>EURISKO: a program that learns new heuristics and domain concepts: the nature of heuristics III: program design and results. D B Lenat, Artificial intelligence. 211-21983</p>
<p>Why AM and EURISKO appear to work. D B Lenat, J S Brown, Artificial intelligence. 2331984</p>
<p>The structure-mapping engine: Algorithm and examples. B Falkenhainer, K D Forbus, D Gentner, Artificial intelligence. 4111989</p>
<p>Amalgams: A formal approach for combining multiple case solutions. S Ontan, E Plaza, International Conference on Case-Based Reasoning. Berlin, HeidelbergSpringer2010, July</p>
<p>Techniques and knowledge used for adaptation during case-based problem solving. W Wilke, R Bergmann, International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems. Berlin, HeidelbergSpringer1998. June</p>
<p>Structure-mapping: A theoretical framework for analogy. D Gentner, Cognitive science. 721983</p>
<p>Learning perceptual inference by contrasting. C Zhang, B Jia, F Gao, Y Zhu, H Lu, S C Zhu, Advances in Neural Information Processing Systems. 2019</p>
<p>Toward a metabolic theory of ecology. J H Brown, J F Gillooly, A P Allen, V M Savage, G B West, Ecology. 8572004</p>
<p>Energy efficiency drives the global seasonal distribution of birds. M Somveille, A S Rodrigues, A Manica, Nature ecology &amp; evolution. 269622018</p>
<p>Statistical physics of self-replication. J L England, The Journal of chemical physics. 139122013</p>
<p>The unreasonable effectiveness of mathematics in the natural sciences. E P Wigner, Mathematics and Science. 1990</p>
<p>Is God a mathematician?. M Livio, 2010Simon and Schuster</p>
<p>Our mathematical universe: My quest for the ultimate nature of reality. M Tegmark, 2014Vintage</p>
<p>Distilling free-form natural laws from experimental data. science. M Schmidt, H Lipson, 2009324</p>
<p>S M Udrescu, M Tegmark, arXiv:1905.11481AI Feynman: a Physics-Inspired Method for Symbolic Regression. 2019arXiv preprint</p>
<p>Unsupervised learning of latent physical properties using perception-prediction networks. D Zheng, V Luo, J Wu, J B Tenenbaum, arXiv:1807.092442018arXiv preprint</p>
<p>R Iten, T Metger, H Wilming, L Del Rio, R Renner, arXiv:1807.10300Discovering physical concepts with neural networks. 2018arXiv preprint</p>
<p>Exploring galaxy evolution with generative models. K Schawinski, M D Turp, C Zhang, arXiv:1812.011142018arXiv preprint</p>
<p>Analogical problem solving. M L Gick, K J Holyoak, Cognitive psychology. 1231980</p>
<p>Mathematics and plausible reasoning volume 1, Induction and analogy in mathematics. G Polya, 1954Princeton University Press</p>
<p>Mental leaps: Analogy in creative thought. K J Holyoak, P Thagard, 1995MIT PressBradford BooksCambridge, MA</p>
<p>N J Nersessian, Creating Scientific Concepts. Cambridge, MAMIT Press2008</p>
<p>How do scientists think? Capturing the dynamics of conceptual change in science. Cognitive models of science. N J Nersessian, 199215</p>
<p>Ant colony optimization. M Dorigo, M Birattari, 2010Springer US</p>
<p>Distributed optimization by ant colonies. A Colorni, M Dorigo, V Maniezzo, Proceedings of the first European conference on artificial life. the first European conference on artificial life1992, December142</p>
<p>Self-organized shortcuts in the Argentine ant. S Goss, S Aron, J L Deneubourg, J M Pasteels, Naturwissenschaften. 76121989</p>
<p>Trail and U-turns in the Selection of the Shortest Path by the Ants. R Beckers, J L Deneubourg, S Gross, J. of Theoretical Biology. 1591992</p>
<p>A survey of bio inspired optimization algorithms. S Binitha, S S Sathya, International journal of soft computing and engineering. 222012</p>
<p>Nature-inspired optimization algorithms. X S Yang, 2014Elsevier</p>
<p>Handbook of bioinspired algorithms and applications. S Olariu, A Y Zomaya, 2005Chapman and Hall/CRC</p>
<p>The Way We Think. G Fauconnier, M Turner, 2003</p>
<p>The act of creation. A Koestler, 1967DellNew York</p>
<p>M Boden, The creative mind: Myths and mechanisms. LondonRoutledge20042nd ed.</p>
<p>The associate basis of the creative process. S A Mednick, Psychological Review. 691962</p>
<p>Computational philosophy of science. P Thagard, 1988MIT PressCambridge, MA</p>
<p>The AHA! experience: Creativity through emergent binding in neural networks. P Thagard, T C Stewart, Cognitive science. 3512011</p>
<p>Algorithmic aspects of theory blending. M Martinez, U Krumnack, A Smaill, T R Besold, A M Abdel-Fattah, M Schmidt, A Pease, International Conference on Artificial Intelligence and Symbolic Computation. ChamSpringer2014, December</p>
<p>R Confalonieri, A Pease, M Schorlemmer, T R Besold, O Kutz, E Maclean, Concept invention: Foundations, implementation, social aspects and applications. M Kaliakatsos-Papakostas, Springer2018</p>
<p>Universality for mathematical and physical systems. P Deift, math-ph/06030382006arXiv preprint</p>
<p>Power laws, Pareto distributions and Zipf's law. M E Newman, Contemporary physics. 4652005</p>
<p>A stochastic nonlinear model for coordinated bird flocks. The ubiquity of chaos. F Heppner, U Grenander, 1990238</p>
<p>The game of life. J Conway, Scientific American. 223441970</p>
<p>A new kind of science. S Wolfram, 2002Wolfram mediaChampaign, IL</p>
<p>Computational thinking in science. P J Denning, 2017</p>
<p>Programming the universe: a quantum computer scientist takes on the cosmos. S Lloyd, 2006Vintage</p>
<p>K Zuse, Rechnender raum. Springer-Verlag2013</p>
<p>Why is beauty a road to the truth?. P Thagard, Cognitive structures in scientific inquiry. RodopiBrill2005</p>
<p>Beauty, a Road to The Truth. T Kuipers, 2002131</p>
<p>A conceptual overview of the role of beauty and aesthetics in science and science education. M Girod, 2007</p>
<p>Aesthetic values in science. M Ivanova, Philosophy Compass. 1210e124332017</p>
<p>Paul Dirac. Obituary Notice, American Philosophical Society Yearbook for. F J Dyson, 1987. 1986</p>
<p>Beauty and Revolution in Science. Mcallister, 1996Cornell University PressIthaca, NY</p>
<p>The Experience of Mathamtical beauty and its Neural Correlates. S Zeki, J P Romaya, D M T Benincasa, M F Atiyah, Frontiers in Human Neuroscience. 82014</p>
<p>A Zee, Fearful Symmetry: the Search for Beauty in Modern Physics. PrincetonPrinceton University Press1999</p>
<p>Chaos and Harmony: Perspectives on Scientific Revolutions of the Twentieth Century. T Thuan, 2001Oxford University PressNew York</p>
<p>The role of symmetry in fundamental physics. D J Gross, Proceedings of the National Academy of Sciences. 93251996</p>
<p>K Xu, J Li, M Zhang, S S Du, K I Kawarabayashi, S Jegelka, arXiv:1905.13211What Can Neural Networks Reason About. 2019arXiv preprint</p>
<p>D Saxton, E Grefenstette, F Hill, P Kohli, arXiv:1904.01557Analysing mathematical reasoning abilities of neural models. 2019arXiv preprint</p>
<p>Raven: A dataset for relational and analogical visual reasoning. C Zhang, F Gao, B Jia, Y Zhu, S C Zhu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2019</p>
<p>D G Barrett, F Hill, A Santoro, A S Morcos, T Lillicrap, arXiv:1807.04225Measuring abstract reasoning in neural networks. 2018arXiv preprint</p>
<p>Rebooting AI: building artificial intelligence we can trust. E Davis, G Marcus, 2019Knopf Doubleday Publishing Group</p>
<p>Causal deconvolution by algorithmic generative models. H Zenil, N A Kiani, A A Zea, J Tegnr, Nature Machine Intelligence. 11582019</p>
<p>H Zenil, arXiv:1904.10258Compression is Comprehension, and the Unreasonable Effectiveness of Digital Computation in the Natural World. 2019arXiv preprint</p>
<p>G Marcus, arXiv:1801.00631Deep learning: A critical appraisal. 2018arXiv preprint</p>
<p>Toward an AI physicist for unsupervised learning. T Wu, M Tegmark, arXiv:1810.105252018arXiv preprint</p>
<p>AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence. J Clune, arXiv:1905.109852019arXiv preprint</p>
<p>Artificial Intelligence: A Guide for Thinking Humans. M Mitchell, 2019Farrar, Straus and Giroux</p>
<p>R Roscher, B Bohn, M F Duarte, J Garcke, arXiv:1905.08883Explainable Machine Learning for Scientific Insights and Discoveries. 2019arXiv preprint</p>
<p>Artificial intelligence and scientific creativity. S Colton, G Steel, Artificial Intelligence and the Study of Behaviour Quarterly. 1021999</p>
<p>Towards an explanatory and computational theory of scientific discovery. C Chen, Y Chen, M Horowitz, H Hou, Z Liu, D Pellegrino, Journal of Informetrics. 332009</p>
<p>How Artificial Intelligence Can Help Us Understand Human Creativity. F Gobet, G Sala, Frontiers in Psychology. 1014012019</p>
<p>Computational scientific discovery. P D Sozou, P C Lane, M Addis, F Gobet, Springer Handbook of Model-Based Science. ChamSpringer2017</p>
<p>A D A Garcez, M Gori, L C Lamb, L Serafini, M Spranger, S N Tran, arXiv:1905.06088Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning. 2019arXiv preprint</p>
<p>F Hill, A Santoro, D G Barrett, A S Morcos, T Lillicrap, arXiv:1902.00120Learning to make analogies by contrasting abstract relational structure. 2019arXiv preprint</p>
<p>High-level perception, representation, and analogy: A critique of artificial intelligence methodology. D J Chalmers, R M French, D R Hofstadter, Journal of Experimental &amp; Theoretical Artificial Intelligence. 431992</p>
<p>Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought. D R Hofstadter, 1995Basic books</p>
<p>Analogy-making as perception: A computer model. M Mitchell, 1993Mit Press</p>
<p>S Hu, Y Ma, X Liu, Y Wei, S Bai, arXiv:2002.06838Hierarchical Rule Induction Network for Abstract Visual Reasoning. 2020arXiv preprint</p>
<p>Automated Coding: The Quest to Develop Programs That Write Programs. M Campbell, Computer. 5322020</p>
<p>M Raghu, E Schmidt, arXiv:2003.11755A Survey of Deep Learning for Scientific Discovery. 2020arXiv preprint</p>
<p>. F Bacon, Novum Organum [Trans. and Ed.: P. Urbach, J. Gibson1620. 1994Court, Chicago and La Salle</p>
<p>Conjectures and refutations: The growth of scientific knowledge. K Popper, 1963routledge</p>
<p>Scientific discovery: Computational explorations of the creative processes. P Langley, H A Simon, G L Bradshaw, J M Zytkow, 1987MIT press</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, Nature. 55977152018</p>
<p>Machine learning and the physical sciences. G Carleo, I Cirac, K Cranmer, L Daudet, M Schuld, N Tishby, . . Zdeborov, L , Reviews of Modern Physics. 914450022019</p>
<p>Opportunities and obstacles for deep learning in biology and medicine. T Ching, D S Himmelstein, B K Beaulieu-Jones, A A Kalinin, B T Do, G P Way, . . Xie, W , Journal of The Royal Society Interface. 151412018. 20170387</p>
<p>From genotype to phenotype: Augmenting deep learning with networks and systems biology. Current opinion in systems biology. V H Gazestani, N E Lewis, 2019</p>
<p>Deep learning and process understanding for data-driven Earth system science. M Reichstein, G Camps-Valls, B Stevens, M Jung, J Denzler, N Carvalhais, Nature. 56677432019</p>
<p>Hume's aesthetics. T Gracyk, 2011Stanford encyclopedia of Philosophy</p>
<p>The German aesthetic tradition. K Hammermeister, 2002Cambridge University Press</p>
<p>Kant's aesthetics. Internet encyclopedia of philosophy. D Burnham, 2001</p>
<p>Beauty and the beholder: Highly individual taste for abstract, but not real-world images. E A Vessel, N Rubin, Journal of vision. 1022010</p>
<p>Dynamic Switching Networks. A M Khalili, Complex Systems. 1282019</p>
<p>Blend City, BlendVille. J Gonalves, P Martins, A Cardoso, ICCC. 2017</p>
<p>F C Pereira, Creativity and artificial intelligence: a conceptual blending approach. Walter de Gruyter20074</p>
<p>Abstraction and Analogy-Making in Artificial Intelligence. M Mitchell, arXiv:2102.107172021arXiv preprint</p>
<p>Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery. H Kitano, AI magazine. 3712016</p>
<p>Autonomous discovery in the chemical sciences part I: Progress. C W Coley, N S Eyke, K F Jensen, Angewandte Chemie International Edition. 59512020</p>
<p>Autonomous discovery in the chemical sciences part II: outlook. C W Coley, N S Eyke, K F Jensen, Angewandte Chemie International Edition. 59522020</p>
<p>Automating sciences: Philosophical and social dimensions. R D King, V S Costa, C Mellingwood, L N Soldatova, IEEE Technology and Society Magazine. 3712018</p>
<p>Towards a humanmachine scientific partnership based on semantically rich research objects. J M Gomez-Perez, R Palma, A Garcia-Silva, 2017 IEEE 13th International Conference on e-Science (e-Science. IEEE2017, October</p>
<p>Robot-scientists will lead tomorrow's biomaterials discovery. A Vasilevich, J De Boer, Current Opinion in Biomedical Engineering. 62018</p>
<p>Artificial intelligence and machine learning in science. R D King, S Roberts, 2018</p>
<p>2100 AI: Reflections on the mechanisation of scientific discovery. A Mannocci, A A Salatino, F Osborne, E Motta, 2017</p>
<p>The book of why: the new science of cause and effect. J Pearl, D Mackenzie, 2018Basic books</p>
<p>Self-Organizing Intelligent Matter: A blueprint for an AI generating algorithm. K Gregor, F Besse, arXiv-21012021arXiv e-prints</p>
<p>Abandoning objectives: Evolution through the search for novelty alone. J Lehman, K O Stanley, Evolutionary computation. 1922011</p>
<p>Why open-endedness matters. K O Stanley, Artificial life. 2532019</p>
<p>A B Arrieta, N Daz-Rodrguez, J Del Ser, A Bennetot, S Tabik, A Barbado, . . Herrera, F , Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion. 202058</p>
<p>G Vilone, L Longo, arXiv:2006.00093Explainable artificial intelligence: a systematic review. 2020arXiv preprint</p>
<p>A deep learning perspective on beauty, sentiment, and remembrance of art. E Cetinic, T Lipic, S Grgic, IEEE Access. 72019</p>
<p>An Information Theory Approach to Aesthetic Assessment of Visual Patterns. A Khalili, H Bouchachia, Entropy. 2321532021</p>
<p>Shortcut learning in deep neural networks. R Geirhos, J H Jacobsen, C Michaelis, R Zemel, W Brendel, M Bethge, F A Wichmann, Nature Machine Intelligence. 2112020</p>
<p>Five Points to Check when Comparing Visual Perception in Humans and Machines. C M Funke, J Borowski, K Stosio, W Brendel, T S A Wallis, M Bethge, ArXiv:2004.094062020arXiv preprintCs, q-Bio, Stat</p>
<p>The quest for optimality: A positive heuristic of science?. P J Schoemaker, Behavioral and Brain Sciences. 1421991</p>
<p>A central principle of science: Optimization. R F Bordley, Behavioral Science. 2811983</p>
<p>Symmetry at the Foundation of Science and. J Rosen, Nature. Symmetry. 112009</p>
<p>Symmetry as a Superprinciple of Science and Art. A V Voloshinov, 1996Leonardo</p>
<p>J P Elliott, P G Dawber, Symmetry in Physics. Macmillan19791</p>
<p>Symmetry. H Weyl, 2015Princeton University Press104</p>
<p>In the beat of a heart: life, energy, and the unity of nature. J Whitfield, 1922National Academies Press</p>
<p>Unifying biology: The evolutionary synthesis and evolutionary biology. V B Smocovitis, Journal of the History of Biology. 2511992</p>
<p>M Winkels, T S Cohen, arXiv:1804.046563D G-CNNs for pulmonary nodule detection. 2018arXiv preprint</p>
<p>Designing neural networks through neuroevolution. K O Stanley, J Clune, J Lehman, R Miikkulainen, Nature Machine Intelligence. 112019</p>
<p>Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. D C Mocanu, E Mocanu, P Stone, P H Nguyen, M Gibescu, A Liotta, Nature communications. 912018</p>
<p>G Raayoni, S Gottlieb, G Pisha, Y Harris, Y Manor, U Mendlovic, . . Kaminer, I , arXiv:1907.00205The ramanujan machine: automatically generated conjectures on fundamental constants. 2019arXiv preprint</p>
<p>Universal artificial intelligence: Sequential decisions based on algorithmic probability. M Hutter, 2004Springer Science &amp; Business Media</p>
<p>B Goertzel, arXiv:2103.15100The General Theory of General Intelligence: A Pragmatic Patternist Perspective. 2021arXiv preprint</p>
<p>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. S M Udrescu, A Tan, J Feng, O Neto, T Wu, M Tegmark, Advances in Neural Information Processing Systems. 202033</p>
<p>Thoughtful artificial intelligence: Forging a new partnership for data science and scientific discovery. Y Gil, Data Science. 11-22017</p>
<p>Two uses of unification. E Sober, The Vienna Circle and Logical Empiricism -Vienna Circle Institute Yearbook. F Stadler, Dordrecht Kluwer, 2003. 2002</p>
<p>Explanatory unification and the causal structure of the world. P Kitcher, Scientific Explanation. P Kitcher, W Salmon, MinneapolisUniversity of Min-nesota Press1989</p>            </div>
        </div>

    </div>
</body>
</html>