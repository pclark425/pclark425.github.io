<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2516 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2516</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2516</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-250264138</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2207.00902v1.pdf" target="_blank">Complementary artificial intelligence designed to augment human discovery</a></p>
                <p><strong>Paper Abstract:</strong> Neither artificial intelligence designed to play Turing's imitation game, nor augmented intelligence built to maximize the human manipulation of information are tuned to accelerate innovation and improve humanity's collective advance against its greatest challenges. We reconceptualize and pilot beneficial AI to radically augment human understanding by complementing rather than competing with human cognitive capacity. Our approach to complementary intelligence builds on insights underlying the wisdom of crowds, which hinges on the independence and diversity of crowd members' information and approach. By programmatically incorporating information on the evolving distribution of scientific expertise from research papers, our approach follows the distribution of content in the literature while avoiding the scientific crowd and the hypotheses cognitively available to it. We use this approach to generate valuable predictions for what materials possess valuable energy-related properties (e.g., thermoelectricity), and what compounds possess valuable medical properties (e.g., asthma) that complement the human scientific crowd. We demonstrate that our complementary predictions, if identified by human scientists and inventors at all, are only discovered years further into the future. When we evaluate the promise of our predictions with first-principles equations, we demonstrate that increased complementarity of our predictions does not decrease and in some cases increases the probability that the predictions possess the targeted properties. In summary, by tuning AI to avoid the crowd, we can generate hypotheses unlikely to be imagined or pursued until the distant future and promise to punctuate scientific advance. By identifying and correcting for collective human bias, these models also suggest opportunities to improve human prediction by reformulating science education for discovery.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2516.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2516.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Complementary discovery predictor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Complementary discovery prediction algorithm (human‑aware discovery predictor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid AI system that generates scientific hypotheses by combining a knowledge‑graph measure of cognitive 'alienness' (shortest‑path distances in a literature hypergraph) with an embedding‑based plausibility score (cosine similarity of word embeddings), controlled by a mixing coefficient to tune complementarity vs. human‑mimicry.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Complementary discovery prediction algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a mixed hypergraph where papers are hyperedges connecting authors, materials (or compounds) and properties; computes cognitive unavailability ('alienness') as shortest‑path distances (SPD) between property and material nodes in the hypergraph; trains unsupervised skip‑gram word2vec embeddings over prior literature and measures plausibility by cosine similarity between material and property embedding vectors; standardizes both signals using a Van der Waerden transform followed by Z‑scoring; combines standardized scores with a linear weighted average using a mixing coefficient (α) in [-1,1] to prioritize either human‑familiar (α<0) or human‑alien (α>0) hypotheses; ranks candidate materials by final score and outputs top N hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>hybrid knowledge-graph + embedding-based</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science (thermoelectrics, ferroelectrics, photovoltaics) and biomedicine/drug repurposing (COVID-19 and other human diseases)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Candidate materials/drugs are extracted from literature (pymatgen + rule-based extraction or drug lists). For each material-property pair the system computes: (1) SPD-based alienness on the mixed hypergraph; (2) embedding cosine plausibility from skip‑gram word2vec trained on the pre‑prediction corpus. After normalization, scores are linearly combined by mixing coefficient α and top-ranked pairs are proposed as hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Novelty (human‑complementarity) is quantified by SPD distances on the author-material-property hypergraph: larger shortest‑path distances indicate lower cognitive availability and higher novelty/alienness; the mixing coefficient α increases weight on this signal to force novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is assessed by cosine similarity of unsupervised word embedding vectors (skip‑gram word2vec) trained on literature prior to the prediction year; additionally, separate first‑principles or domain models (DFT power factor for thermoelectrics, spontaneous polarization estimates for ferroelectrics, protein‑protein interaction proximity for diseases) are used as conservative external plausibility/validation scores.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>A single mixing coefficient α ∈ [-1,1] controls the tradeoff: α<0 emphasizes plausibility and human‑familiar predictions, α=0 uses plausibility only (traditional methods), and α>0 increases novelty/alienness. Extremes α=±1 ignore one of the signals; intermediate α (empirically ~0.2–0.3) provides the best joint plausibility/undiscoverability balance.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision (overlap percentage of predicted pairs with later published discoveries), average theoretical scores per hypothesis (e.g., DFT power factor, spontaneous polarization, protein‑protein similarity), average discovery waiting time (years/months until human discovery), and the expectation gap metric (difference between E[plausible|α] and E[discoverable|α]).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational validation: (1) compare predictions to later human publications to compute precision and discovery wait time; (2) compute domain‑specific theoretical scores for candidates using first‑principles simulations or curated databases (DFT power factor, ferroelectric polarization estimates, PPI proximity) and compare average scores across α; (3) probabilistic modeling of P(undiscoverable, plausible | α) and expectation gap analysis. No novel wet‑lab experiments were reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Use of established, citable corpora (Tshitoyan et al. inorganic materials corpus, MEDLINE), explicit extraction pipelines (pymatgen for materials, rule‑based string processing for candidates), DOI retrieval via Scopus API, author disambiguation via PubMed Knowledge Graph, and reliance on prior published databases (CTD, PPI datasets); algorithmic steps (embedding training, SPD computation, Van der Waerden + Z‑score normalization, linear combination) are described and code/data provenance is cited though no repository release is explicitly claimed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Probabilistic modeling of conditional distributions over α, including conversion of theoretical scores to probabilities and weighted maximum likelihood estimation of ℙ(α=0 | plausible); computation of joint probability ℙ(undiscoverable, plausible | α) and the expectation gap (difference between ℙ(plausible|α) and ℙ(discoverable|α)) to quantify uncertainty about whether a prediction is both plausible and beyond current human scope.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Inorganic materials corpus from Tshitoyan et al. (~1.5M articles), MEDLINE (~28M articles) for biomedical domain, Comparative Toxicogenomics Database (CTD) for drug‑disease ground truth, PubMed Knowledge Graph / Author‑ity / Semantic Scholar for author disambiguation, curated DFT/ferroelectric databases (Ricci et al., Smidt et al.) and PPI datasets referenced in Gysi et al.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include: precision (overlap of predicted material/property pairs with later published discoveries) which decreases monotonically as α increases; average theoretical scores for predicted hypotheses (DFT power factor, spontaneous polarization, PPI similarity) which decline more slowly and in many cases increase for intermediate positive α before decaying near α≈0.4; discovery wait time which increases with α (predictions at higher α are discovered later if at all). The paper identifies α≈0.2–0.3 as a consistently promising operating range. Exact numeric rate values are reported in figures for individual properties but not enumerated as single summary numbers in text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Baseline is plausibility‑only prediction (α=0) equivalent to traditional literature‑based discovery methods; compared to baseline, positive α yields predictions that are substantially less discoverable (lower precision and longer wait times) yet maintain or sometimes exceed baseline theoretical scores, producing a positive 'expectation gap'.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>The system produced hypotheses that in many cases were only discovered (published) years later by human scientists; for a subset of properties (thermoelectrics, some diseases) predicted candidates had higher theoretical scores than average actual published discoveries, indicating potential novel, high‑quality leads—however, no new wet‑lab experimental validations were reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>At extreme α values plausibility collapses and the algorithm can produce scientifically irrelevant proposals; reliance on published literature and metadata means the approach reflects existing publication biases and the quality of corpora; theoretical validation scores are conservative and may be available to human scientists (so some predictions could have been discoverable if examined); the paper does not present explicit methods for hallucination detection/prevention or formal statistical hypothesis tests for many comparisons.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2516.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hypergraph SPD alienness</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hypergraph shortest‑path distance (SPD) cognitive alienness metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that quantifies how cognitively available a material-property relationship is to human scientists by computing shortest‑path distances between nodes in a mixed hypergraph of authors, materials and concepts; larger SPD implies lower cognitive availability (higher novelty).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hypergraph shortest‑path alienness metric</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Represent literature as a hypergraph where each paper is a hyperedge connecting author nodes and concept/material/property nodes; compute shortest path distances between a target property node and candidate material nodes across this mixed hypergraph to measure how many intermediate conceptual/author links separate them; treat SPD as an unbounded ordinal 'alienness' score for novelty assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph-based (hypergraph)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>applied to materials science and biomedical literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Used as the novelty component: high SPD candidates are prioritized when α>0 to generate hypotheses that are less cognitively available to the scientific crowd.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>SPD directly operationalizes novelty/alienness; the distribution of experts around nodes (authors linked to concepts) informs cognitive availability.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Combined linearly with embedding‑based plausibility after normalization; higher α increases weight for SPD.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical validation via correlations between SPD and discovery wait times/precision: hypotheses with larger SPD were less likely to be discovered and had longer waits.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Hypergraph construction from DOIs and author disambiguation sources (Scopus / PKG) described; SPD is a standard graph metric.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Hypergraphs built from the Tshitoyan inorganic corpus and MEDLINE with author metadata from Scopus and PubMed Knowledge Graph.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Qualitatively, SPD correlates negatively with discoverability (precision) and positively with discovery wait time; distributions of published discoveries concentrate at low SPD values.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>SPD is sensitive to the coverage and quality of the underlying publication and author metadata; long SPD can indicate legitimate novelty or simply data sparsity; SPD as an ordinal metric requires normalization when combined with plausibility scores.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2516.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Word2Vec plausibility</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unsupervised skip‑gram word2vec embedding plausibility scorer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An embedding‑based plausibility assessment that uses cosine similarity between word2vec embedding vectors (trained on prior literature) for material and property mentions to estimate how plausible a material is to have a target property.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Unsupervised skip‑gram word2vec plausibility model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Train skip‑gram word2vec models on the corpus of publications prior to the prediction year (inorganic corpus or MEDLINE). Represent materials and properties by their learned embedding vectors and compute cosine similarity between material and property vectors as a continuous plausibility score indicating semantic/latent association strength.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>embedding-based (unsupervised)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science and biomedical literature</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Plausibility scores from embeddings are one branch of the scoring pipeline and feed into the final combined score used to rank hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Cosine similarity of embedding vectors; higher cosine similarity indicates higher literature‑based plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Balances novelty SPD signal through linear combination regulated by α after statistical standardization.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Compared embedding plausibility distributions across α and against external theoretical scores; embedding‑based plausibility alone corresponds to α=0 baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embeddings trained on publicly described corpora (Tshitoyan dataset, MEDLINE) using standard skip‑gram word2vec procedures; prior work (Tshitoyan et al.) and shared data/code cited.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Tshitoyan et al. inorganic materials literature corpus and MEDLINE abstracts prior to the prediction year.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Embedding plausibility scores provide a Gaussian‑like continuous signal used to rank candidates; used as baseline (α=0) and shown to decay more slowly across α than discoverability.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Embedding similarity reflects patterns in published text and therefore inherits literature biases; semantic similarity does not guarantee physical or biological efficacy—necessitating domain‑specific theoretical validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2516.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixing coefficient (α)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixing coefficient α for novelty–plausibility tradeoff</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scalar parameter (α ∈ [-1,1]) that linearly combines standardized plausibility and alienness scores to tune the algorithm between human‑mimicking and human‑complementary hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Mixing coefficient α</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>After Van der Waerden transformation and Z‑score normalization of the plausibility and alienness signals, α determines the weighted average: negative α emphasizes human‑familiar plausible predictions, α=0 uses plausibility only, positive α increases weight on alienness to produce novel, complementary predictions; extremes α=±1 isolate one signal.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>parameterized hybrid scoring</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials and biomedical sciences</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Controls selection bias toward either high plausibility (exploitation) or high alienness (exploration) when ranking candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>Directly increases or decreases weight of SPD novelty signal in final score.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Directly increases or decreases weight of embedding plausibility signal in final score.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Explicit single‑parameter tradeoff; authors identify α≈0.2–0.3 as a generally promising range balancing undiscoverability and plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirically evaluated by sweeping α and measuring precision, theoretical score trends, discovery wait times, expectation gap and joint probability ℙ(undiscoverable, plausible | α).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>α is a simple tunable scalar—experiments report predictions at multiple α values (e.g., -0.8 to 0.8) and compare outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Identified operating interval α≈0.2–0.3 as consistently promising across properties; precision declines and theoretical scores remain acceptable across this intermediate positive α range.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Single scalar may be insufficient to capture more complex tradeoffs across domains; extreme α values yield poor plausibility or trivial human‑like predictions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2516.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expectation gap</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expectation gap metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novel metric defined in this paper as the difference between the expected probability a prediction is theoretically plausible and the expected probability it is discoverable by humans, used to quantify whether increasing complementarity preserves scientific promise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Expectation gap</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Compute two conditional distributions over α: ℙ(predictable is plausible | α) estimated by converting theoretical scores to probabilities, and ℙ(predictable is discoverable | α) estimated empirically from later publications; the expectation gap = E[plausible|α] − E[discoverable|α]. Positive gap indicates that raising α maintains or increases theoretical promise while making predictions more complementary (less discoverable).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic metric</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science and biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Relies on conversion of first‑principles theoretical scores to probabilities (see Supplementary Information) to estimate ℙ(plausible | α).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Used to identify regions of α where novelty (undiscoverability) increases faster than loss of plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computed across multiple properties; authors report that the majority of considered properties yield substantially positive expectation gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Definition and computation steps described, including score conversion and weighted MLE; applied only to properties with reliable theoretical scores (~45% of properties).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Expectation gap itself is a probabilistic quantity comparing two estimated distributions; estimation involves weighted maximum likelihood and conversion of continuous theoretical scores into probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Authors report 'substantial and significantly positive' expectation gaps for the majority of properties with theoretical scores (thermoelectricity, ferroelectricity, COVID‑19, and many diseases); no single numerical aggregate is given beyond examples and figures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires reliable theoretical scores to estimate plausibility probabilities; only applied to ~45% of properties in the study; statistical uncertainty around converted probabilities depends on the conversion method.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2516.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Joint plausibility/undiscoverability model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Joint probability model P(undiscoverable, plausible | α)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic model that computes the joint probability a predicted hypothesis is both plausible (by theoretical score) and beyond current scientists' scope (undiscoverable), used to identify optimal α operating points.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Joint plausibility-undiscoverability probabilistic model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Models the joint event that a randomly selected prediction is plausible and undiscoverable as a function of α by estimating ℙ(plausible | α) (from converted theoretical scores) and ℙ(discoverable | α) (empirically from later publication overlaps), then computing ℙ(undiscoverable, plausible | α) = ℙ(plausible | α) × (1 − ℙ(discoverable | α)) possibly accounting for dependence structures (details in Supplementary Information). The distribution is used to screen optimal α values per property.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic modeling</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science and biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Produces an empirical objective to maximize when choosing α to balance novelty and plausibility; identifies α≈0.2–0.3 as broadly effective across properties.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Used to empirically evaluate α sweeps and produce per‑property optimal operating ranges.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Methodological description provided; depends on availability of empirical discovery labels and theoretical score conversions.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Probability estimates and joint distribution provide a measure of uncertainty about dual desiderata (plausibility and undiscoverability).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used to identify per‑property optimal α; authors highlight a consistent promising range 0.2–0.3 across many properties.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Accuracy depends on quality of theoretical score→probability conversions and completeness of discovery labels; potential dependence between plausibility and discoverability may complicate joint probability estimation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2516.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DFT / first-principles validators</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>First‑principles and data‑driven validation modules (DFT power factor, ferroelectric polarization, PPI proximity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Domain‑specific computational validators used to score candidate hypotheses: DFT‑computed thermoelectric power factor for thermoelectricity, symmetry‑based spontaneous polarization estimates for ferroelectricity, and protein‑protein interaction proximity metrics for disease therapeutics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>First-principles / data-driven validation modules</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Independent computational scoring functions: (i) compute power factor (PF) via density functional theory (DFT) and transport calculations to estimate thermoelectric promise; (ii) estimate spontaneous polarization via symmetry analysis and theoretical relations for ferroelectricity; (iii) compute network‑based proximity measures in protein‑protein interaction networks to estimate drug‑disease engagement likelihood. These produce real‑valued scores used as conservative plausibility measures and for expectation gap calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>domain-specific simulation/analysis (physics-based + network medicine)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science (thermoelectrics, ferroelectrics) and network medicine (drug‑disease interactions)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Provide theory‑driven numerical scores for candidate hypotheses independent of literature embeddings; used to evaluate and rank undiscovered predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Used as offline, conservative validation of hypotheses that have not been experimentally tested; scores compared across α regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Relies on established computational methods and curated databases (DFT databases, ferroelectric databases, PPI resources); references supplied for datasets and methods.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>DFT transport database (Ricci et al.), ferroelectric database (Smidt et al.), network medicine PPI resources (Gysi et al.), CTD for drug‑disease ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used to show that average theoretical scores for predicted hypotheses often decline more slowly than discoverability and in some cases exceed average scores of published discoveries before eventual decay; no single numerical aggregate is provided in text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>These theoretical scores are conservative and derived from established models; they may be available to scientists and therefore do not guarantee the hypotheses were inaccessible to humans; computational validators are imperfect proxies for experimental validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2516.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2516.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Discoverability / precision metric</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discoverability measured by precision (overlap with later publications) and discovery wait time</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical metrics that quantify whether a generated hypothesis was later published by human scientists (precision/overlap) and the elapsed time until such discovery (discovery wait time).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Precision and discovery wait time metrics</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Discoverability: compute the precision as the percentage overlap between predicted material/property pairs and actual discoveries (co‑occurrence in literature or curated CTD associations) after the prediction year. Discovery wait time: measure the elapsed time from prediction date to the first human publication/discovery event for predicted pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>evaluation metrics (empirical)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>applied to materials and biomedical domains</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Precision (overlap percentage), mean/median discovery waiting time (years/months), Pearson correlation between α and precision/wait time shown in figures.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Used empirically to show that higher α predictions are less likely to be discovered by humans and, when discovered, are discovered later.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Uses curated discovery labels from literature co‑occurrence methodology and CTD with documented earliest publication dates; prediction experiments use fixed prediction years (e.g., 2001 and 2020 for COVID‑19).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Tshitoyan corpus, MEDLINE, CTD, ClinicalTrials.gov (for COVID‑19 trials), Scopus DOI retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision declines strongly as α increases; discovery wait times increase with α across most targeted properties (figures show per‑property curves).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Discoverability depends on the completeness and timeliness of publication databases and curated associations; co‑occurrence in text is an imperfect proxy for genuine experimental validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unsupervised word embeddings capture latent knowledge from materials science literature <em>(Rating: 2)</em></li>
                <li>Fish oil, Raynaud's syndrome, and undiscovered public knowledge <em>(Rating: 1)</em></li>
                <li>A hypergraph model for representing scientific output <em>(Rating: 1)</em></li>
                <li>Network Medicine Framework for Identifying Drug Repurposing Opportunities for COVID-19 <em>(Rating: 2)</em></li>
                <li>Prediction of robust scientific facts from literature <em>(Rating: 1)</em></li>
                <li>Accelerating science with human versus alien artificial intelligences <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2516",
    "paper_id": "paper-250264138",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "Complementary discovery predictor",
            "name_full": "Complementary discovery prediction algorithm (human‑aware discovery predictor)",
            "brief_description": "A hybrid AI system that generates scientific hypotheses by combining a knowledge‑graph measure of cognitive 'alienness' (shortest‑path distances in a literature hypergraph) with an embedding‑based plausibility score (cosine similarity of word embeddings), controlled by a mixing coefficient to tune complementarity vs. human‑mimicry.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Complementary discovery prediction algorithm",
            "system_description": "Constructs a mixed hypergraph where papers are hyperedges connecting authors, materials (or compounds) and properties; computes cognitive unavailability ('alienness') as shortest‑path distances (SPD) between property and material nodes in the hypergraph; trains unsupervised skip‑gram word2vec embeddings over prior literature and measures plausibility by cosine similarity between material and property embedding vectors; standardizes both signals using a Van der Waerden transform followed by Z‑scoring; combines standardized scores with a linear weighted average using a mixing coefficient (α) in [-1,1] to prioritize either human‑familiar (α&lt;0) or human‑alien (α&gt;0) hypotheses; ranks candidate materials by final score and outputs top N hypotheses.",
            "system_type": "hybrid knowledge-graph + embedding-based",
            "scientific_domain": "materials science (thermoelectrics, ferroelectrics, photovoltaics) and biomedicine/drug repurposing (COVID-19 and other human diseases)",
            "hypothesis_generation_method": "Candidate materials/drugs are extracted from literature (pymatgen + rule-based extraction or drug lists). For each material-property pair the system computes: (1) SPD-based alienness on the mixed hypergraph; (2) embedding cosine plausibility from skip‑gram word2vec trained on the pre‑prediction corpus. After normalization, scores are linearly combined by mixing coefficient α and top-ranked pairs are proposed as hypotheses.",
            "novelty_assessment_method": "Novelty (human‑complementarity) is quantified by SPD distances on the author-material-property hypergraph: larger shortest‑path distances indicate lower cognitive availability and higher novelty/alienness; the mixing coefficient α increases weight on this signal to force novelty.",
            "plausibility_assessment_method": "Plausibility is assessed by cosine similarity of unsupervised word embedding vectors (skip‑gram word2vec) trained on literature prior to the prediction year; additionally, separate first‑principles or domain models (DFT power factor for thermoelectrics, spontaneous polarization estimates for ferroelectrics, protein‑protein interaction proximity for diseases) are used as conservative external plausibility/validation scores.",
            "novelty_plausibility_balance": "A single mixing coefficient α ∈ [-1,1] controls the tradeoff: α&lt;0 emphasizes plausibility and human‑familiar predictions, α=0 uses plausibility only (traditional methods), and α&gt;0 increases novelty/alienness. Extremes α=±1 ignore one of the signals; intermediate α (empirically ~0.2–0.3) provides the best joint plausibility/undiscoverability balance.",
            "hypothesis_quality_metrics": "Precision (overlap percentage of predicted pairs with later published discoveries), average theoretical scores per hypothesis (e.g., DFT power factor, spontaneous polarization, protein‑protein similarity), average discovery waiting time (years/months until human discovery), and the expectation gap metric (difference between E[plausible|α] and E[discoverable|α]).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational validation: (1) compare predictions to later human publications to compute precision and discovery wait time; (2) compute domain‑specific theoretical scores for candidates using first‑principles simulations or curated databases (DFT power factor, ferroelectric polarization estimates, PPI proximity) and compare average scores across α; (3) probabilistic modeling of P(undiscoverable, plausible | α) and expectation gap analysis. No novel wet‑lab experiments were reported in this paper.",
            "reproducibility_measures": "Use of established, citable corpora (Tshitoyan et al. inorganic materials corpus, MEDLINE), explicit extraction pipelines (pymatgen for materials, rule‑based string processing for candidates), DOI retrieval via Scopus API, author disambiguation via PubMed Knowledge Graph, and reliance on prior published databases (CTD, PPI datasets); algorithmic steps (embedding training, SPD computation, Van der Waerden + Z‑score normalization, linear combination) are described and code/data provenance is cited though no repository release is explicitly claimed in the paper.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Probabilistic modeling of conditional distributions over α, including conversion of theoretical scores to probabilities and weighted maximum likelihood estimation of ℙ(α=0 | plausible); computation of joint probability ℙ(undiscoverable, plausible | α) and the expectation gap (difference between ℙ(plausible|α) and ℙ(discoverable|α)) to quantify uncertainty about whether a prediction is both plausible and beyond current human scope.",
            "benchmark_dataset": "Inorganic materials corpus from Tshitoyan et al. (~1.5M articles), MEDLINE (~28M articles) for biomedical domain, Comparative Toxicogenomics Database (CTD) for drug‑disease ground truth, PubMed Knowledge Graph / Author‑ity / Semantic Scholar for author disambiguation, curated DFT/ferroelectric databases (Ricci et al., Smidt et al.) and PPI datasets referenced in Gysi et al.",
            "performance_metrics": "Reported metrics include: precision (overlap of predicted material/property pairs with later published discoveries) which decreases monotonically as α increases; average theoretical scores for predicted hypotheses (DFT power factor, spontaneous polarization, PPI similarity) which decline more slowly and in many cases increase for intermediate positive α before decaying near α≈0.4; discovery wait time which increases with α (predictions at higher α are discovered later if at all). The paper identifies α≈0.2–0.3 as a consistently promising operating range. Exact numeric rate values are reported in figures for individual properties but not enumerated as single summary numbers in text.",
            "comparison_with_baseline": "Baseline is plausibility‑only prediction (α=0) equivalent to traditional literature‑based discovery methods; compared to baseline, positive α yields predictions that are substantially less discoverable (lower precision and longer wait times) yet maintain or sometimes exceed baseline theoretical scores, producing a positive 'expectation gap'.",
            "validated_on_real_science": true,
            "novel_discoveries": "The system produced hypotheses that in many cases were only discovered (published) years later by human scientists; for a subset of properties (thermoelectrics, some diseases) predicted candidates had higher theoretical scores than average actual published discoveries, indicating potential novel, high‑quality leads—however, no new wet‑lab experimental validations were reported in this paper.",
            "limitations": "At extreme α values plausibility collapses and the algorithm can produce scientifically irrelevant proposals; reliance on published literature and metadata means the approach reflects existing publication biases and the quality of corpora; theoretical validation scores are conservative and may be available to human scientists (so some predictions could have been discoverable if examined); the paper does not present explicit methods for hallucination detection/prevention or formal statistical hypothesis tests for many comparisons.",
            "uuid": "e2516.0"
        },
        {
            "name_short": "Hypergraph SPD alienness",
            "name_full": "Hypergraph shortest‑path distance (SPD) cognitive alienness metric",
            "brief_description": "A method that quantifies how cognitively available a material-property relationship is to human scientists by computing shortest‑path distances between nodes in a mixed hypergraph of authors, materials and concepts; larger SPD implies lower cognitive availability (higher novelty).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Hypergraph shortest‑path alienness metric",
            "system_description": "Represent literature as a hypergraph where each paper is a hyperedge connecting author nodes and concept/material/property nodes; compute shortest path distances between a target property node and candidate material nodes across this mixed hypergraph to measure how many intermediate conceptual/author links separate them; treat SPD as an unbounded ordinal 'alienness' score for novelty assessment.",
            "system_type": "knowledge graph-based (hypergraph)",
            "scientific_domain": "applied to materials science and biomedical literature",
            "hypothesis_generation_method": "Used as the novelty component: high SPD candidates are prioritized when α&gt;0 to generate hypotheses that are less cognitively available to the scientific crowd.",
            "novelty_assessment_method": "SPD directly operationalizes novelty/alienness; the distribution of experts around nodes (authors linked to concepts) informs cognitive availability.",
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": "Combined linearly with embedding‑based plausibility after normalization; higher α increases weight for SPD.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirical validation via correlations between SPD and discovery wait times/precision: hypotheses with larger SPD were less likely to be discovered and had longer waits.",
            "reproducibility_measures": "Hypergraph construction from DOIs and author disambiguation sources (Scopus / PKG) described; SPD is a standard graph metric.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Hypergraphs built from the Tshitoyan inorganic corpus and MEDLINE with author metadata from Scopus and PubMed Knowledge Graph.",
            "performance_metrics": "Qualitatively, SPD correlates negatively with discoverability (precision) and positively with discovery wait time; distributions of published discoveries concentrate at low SPD values.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "SPD is sensitive to the coverage and quality of the underlying publication and author metadata; long SPD can indicate legitimate novelty or simply data sparsity; SPD as an ordinal metric requires normalization when combined with plausibility scores.",
            "uuid": "e2516.1"
        },
        {
            "name_short": "Word2Vec plausibility",
            "name_full": "Unsupervised skip‑gram word2vec embedding plausibility scorer",
            "brief_description": "An embedding‑based plausibility assessment that uses cosine similarity between word2vec embedding vectors (trained on prior literature) for material and property mentions to estimate how plausible a material is to have a target property.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Unsupervised skip‑gram word2vec plausibility model",
            "system_description": "Train skip‑gram word2vec models on the corpus of publications prior to the prediction year (inorganic corpus or MEDLINE). Represent materials and properties by their learned embedding vectors and compute cosine similarity between material and property vectors as a continuous plausibility score indicating semantic/latent association strength.",
            "system_type": "embedding-based (unsupervised)",
            "scientific_domain": "materials science and biomedical literature",
            "hypothesis_generation_method": "Plausibility scores from embeddings are one branch of the scoring pipeline and feed into the final combined score used to rank hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Cosine similarity of embedding vectors; higher cosine similarity indicates higher literature‑based plausibility.",
            "novelty_plausibility_balance": "Balances novelty SPD signal through linear combination regulated by α after statistical standardization.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Compared embedding plausibility distributions across α and against external theoretical scores; embedding‑based plausibility alone corresponds to α=0 baseline.",
            "reproducibility_measures": "Embeddings trained on publicly described corpora (Tshitoyan dataset, MEDLINE) using standard skip‑gram word2vec procedures; prior work (Tshitoyan et al.) and shared data/code cited.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Tshitoyan et al. inorganic materials literature corpus and MEDLINE abstracts prior to the prediction year.",
            "performance_metrics": "Embedding plausibility scores provide a Gaussian‑like continuous signal used to rank candidates; used as baseline (α=0) and shown to decay more slowly across α than discoverability.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Embedding similarity reflects patterns in published text and therefore inherits literature biases; semantic similarity does not guarantee physical or biological efficacy—necessitating domain‑specific theoretical validation.",
            "uuid": "e2516.2"
        },
        {
            "name_short": "Mixing coefficient (α)",
            "name_full": "Mixing coefficient α for novelty–plausibility tradeoff",
            "brief_description": "A scalar parameter (α ∈ [-1,1]) that linearly combines standardized plausibility and alienness scores to tune the algorithm between human‑mimicking and human‑complementary hypothesis generation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Mixing coefficient α",
            "system_description": "After Van der Waerden transformation and Z‑score normalization of the plausibility and alienness signals, α determines the weighted average: negative α emphasizes human‑familiar plausible predictions, α=0 uses plausibility only, positive α increases weight on alienness to produce novel, complementary predictions; extremes α=±1 isolate one signal.",
            "system_type": "parameterized hybrid scoring",
            "scientific_domain": "materials and biomedical sciences",
            "hypothesis_generation_method": "Controls selection bias toward either high plausibility (exploitation) or high alienness (exploration) when ranking candidate hypotheses.",
            "novelty_assessment_method": "Directly increases or decreases weight of SPD novelty signal in final score.",
            "plausibility_assessment_method": "Directly increases or decreases weight of embedding plausibility signal in final score.",
            "novelty_plausibility_balance": "Explicit single‑parameter tradeoff; authors identify α≈0.2–0.3 as a generally promising range balancing undiscoverability and plausibility.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirically evaluated by sweeping α and measuring precision, theoretical score trends, discovery wait times, expectation gap and joint probability ℙ(undiscoverable, plausible | α).",
            "reproducibility_measures": "α is a simple tunable scalar—experiments report predictions at multiple α values (e.g., -0.8 to 0.8) and compare outcomes.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": "Identified operating interval α≈0.2–0.3 as consistently promising across properties; precision declines and theoretical scores remain acceptable across this intermediate positive α range.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Single scalar may be insufficient to capture more complex tradeoffs across domains; extreme α values yield poor plausibility or trivial human‑like predictions.",
            "uuid": "e2516.3"
        },
        {
            "name_short": "Expectation gap",
            "name_full": "Expectation gap metric",
            "brief_description": "A novel metric defined in this paper as the difference between the expected probability a prediction is theoretically plausible and the expected probability it is discoverable by humans, used to quantify whether increasing complementarity preserves scientific promise.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Expectation gap",
            "system_description": "Compute two conditional distributions over α: ℙ(predictable is plausible | α) estimated by converting theoretical scores to probabilities, and ℙ(predictable is discoverable | α) estimated empirically from later publications; the expectation gap = E[plausible|α] − E[discoverable|α]. Positive gap indicates that raising α maintains or increases theoretical promise while making predictions more complementary (less discoverable).",
            "system_type": "probabilistic metric",
            "scientific_domain": "materials science and biomedicine",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Relies on conversion of first‑principles theoretical scores to probabilities (see Supplementary Information) to estimate ℙ(plausible | α).",
            "novelty_plausibility_balance": "Used to identify regions of α where novelty (undiscoverability) increases faster than loss of plausibility.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computed across multiple properties; authors report that the majority of considered properties yield substantially positive expectation gaps.",
            "reproducibility_measures": "Definition and computation steps described, including score conversion and weighted MLE; applied only to properties with reliable theoretical scores (~45% of properties).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Expectation gap itself is a probabilistic quantity comparing two estimated distributions; estimation involves weighted maximum likelihood and conversion of continuous theoretical scores into probabilities.",
            "benchmark_dataset": null,
            "performance_metrics": "Authors report 'substantial and significantly positive' expectation gaps for the majority of properties with theoretical scores (thermoelectricity, ferroelectricity, COVID‑19, and many diseases); no single numerical aggregate is given beyond examples and figures.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Requires reliable theoretical scores to estimate plausibility probabilities; only applied to ~45% of properties in the study; statistical uncertainty around converted probabilities depends on the conversion method.",
            "uuid": "e2516.4"
        },
        {
            "name_short": "Joint plausibility/undiscoverability model",
            "name_full": "Joint probability model P(undiscoverable, plausible | α)",
            "brief_description": "A probabilistic model that computes the joint probability a predicted hypothesis is both plausible (by theoretical score) and beyond current scientists' scope (undiscoverable), used to identify optimal α operating points.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Joint plausibility-undiscoverability probabilistic model",
            "system_description": "Models the joint event that a randomly selected prediction is plausible and undiscoverable as a function of α by estimating ℙ(plausible | α) (from converted theoretical scores) and ℙ(discoverable | α) (empirically from later publication overlaps), then computing ℙ(undiscoverable, plausible | α) = ℙ(plausible | α) × (1 − ℙ(discoverable | α)) possibly accounting for dependence structures (details in Supplementary Information). The distribution is used to screen optimal α values per property.",
            "system_type": "probabilistic modeling",
            "scientific_domain": "materials science and biomedicine",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": "Produces an empirical objective to maximize when choosing α to balance novelty and plausibility; identifies α≈0.2–0.3 as broadly effective across properties.",
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Used to empirically evaluate α sweeps and produce per‑property optimal operating ranges.",
            "reproducibility_measures": "Methodological description provided; depends on availability of empirical discovery labels and theoretical score conversions.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Probability estimates and joint distribution provide a measure of uncertainty about dual desiderata (plausibility and undiscoverability).",
            "benchmark_dataset": null,
            "performance_metrics": "Used to identify per‑property optimal α; authors highlight a consistent promising range 0.2–0.3 across many properties.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Accuracy depends on quality of theoretical score→probability conversions and completeness of discovery labels; potential dependence between plausibility and discoverability may complicate joint probability estimation.",
            "uuid": "e2516.5"
        },
        {
            "name_short": "DFT / first-principles validators",
            "name_full": "First‑principles and data‑driven validation modules (DFT power factor, ferroelectric polarization, PPI proximity)",
            "brief_description": "Domain‑specific computational validators used to score candidate hypotheses: DFT‑computed thermoelectric power factor for thermoelectricity, symmetry‑based spontaneous polarization estimates for ferroelectricity, and protein‑protein interaction proximity metrics for disease therapeutics.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "First-principles / data-driven validation modules",
            "system_description": "Independent computational scoring functions: (i) compute power factor (PF) via density functional theory (DFT) and transport calculations to estimate thermoelectric promise; (ii) estimate spontaneous polarization via symmetry analysis and theoretical relations for ferroelectricity; (iii) compute network‑based proximity measures in protein‑protein interaction networks to estimate drug‑disease engagement likelihood. These produce real‑valued scores used as conservative plausibility measures and for expectation gap calculations.",
            "system_type": "domain-specific simulation/analysis (physics-based + network medicine)",
            "scientific_domain": "materials science (thermoelectrics, ferroelectrics) and network medicine (drug‑disease interactions)",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Provide theory‑driven numerical scores for candidate hypotheses independent of literature embeddings; used to evaluate and rank undiscovered predictions.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Used as offline, conservative validation of hypotheses that have not been experimentally tested; scores compared across α regimes.",
            "reproducibility_measures": "Relies on established computational methods and curated databases (DFT databases, ferroelectric databases, PPI resources); references supplied for datasets and methods.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "DFT transport database (Ricci et al.), ferroelectric database (Smidt et al.), network medicine PPI resources (Gysi et al.), CTD for drug‑disease ground truth.",
            "performance_metrics": "Used to show that average theoretical scores for predicted hypotheses often decline more slowly than discoverability and in some cases exceed average scores of published discoveries before eventual decay; no single numerical aggregate is provided in text.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "These theoretical scores are conservative and derived from established models; they may be available to scientists and therefore do not guarantee the hypotheses were inaccessible to humans; computational validators are imperfect proxies for experimental validation.",
            "uuid": "e2516.6"
        },
        {
            "name_short": "Discoverability / precision metric",
            "name_full": "Discoverability measured by precision (overlap with later publications) and discovery wait time",
            "brief_description": "Empirical metrics that quantify whether a generated hypothesis was later published by human scientists (precision/overlap) and the elapsed time until such discovery (discovery wait time).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Precision and discovery wait time metrics",
            "system_description": "Discoverability: compute the precision as the percentage overlap between predicted material/property pairs and actual discoveries (co‑occurrence in literature or curated CTD associations) after the prediction year. Discovery wait time: measure the elapsed time from prediction date to the first human publication/discovery event for predicted pairs.",
            "system_type": "evaluation metrics (empirical)",
            "scientific_domain": "applied to materials and biomedical domains",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Precision (overlap percentage), mean/median discovery waiting time (years/months), Pearson correlation between α and precision/wait time shown in figures.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Used empirically to show that higher α predictions are less likely to be discovered by humans and, when discovered, are discovered later.",
            "reproducibility_measures": "Uses curated discovery labels from literature co‑occurrence methodology and CTD with documented earliest publication dates; prediction experiments use fixed prediction years (e.g., 2001 and 2020 for COVID‑19).",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Tshitoyan corpus, MEDLINE, CTD, ClinicalTrials.gov (for COVID‑19 trials), Scopus DOI retrieval",
            "performance_metrics": "Precision declines strongly as α increases; discovery wait times increase with α across most targeted properties (figures show per‑property curves).",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Discoverability depends on the completeness and timeliness of publication databases and curated associations; co‑occurrence in text is an imperfect proxy for genuine experimental validation.",
            "uuid": "e2516.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unsupervised word embeddings capture latent knowledge from materials science literature",
            "rating": 2,
            "sanitized_title": "unsupervised_word_embeddings_capture_latent_knowledge_from_materials_science_literature"
        },
        {
            "paper_title": "Fish oil, Raynaud's syndrome, and undiscovered public knowledge",
            "rating": 1,
            "sanitized_title": "fish_oil_raynauds_syndrome_and_undiscovered_public_knowledge"
        },
        {
            "paper_title": "A hypergraph model for representing scientific output",
            "rating": 1,
            "sanitized_title": "a_hypergraph_model_for_representing_scientific_output"
        },
        {
            "paper_title": "Network Medicine Framework for Identifying Drug Repurposing Opportunities for COVID-19",
            "rating": 2,
            "sanitized_title": "network_medicine_framework_for_identifying_drug_repurposing_opportunities_for_covid19"
        },
        {
            "paper_title": "Prediction of robust scientific facts from literature",
            "rating": 1,
            "sanitized_title": "prediction_of_robust_scientific_facts_from_literature"
        },
        {
            "paper_title": "Accelerating science with human versus alien artificial intelligences",
            "rating": 2,
            "sanitized_title": "accelerating_science_with_human_versus_alien_artificial_intelligences"
        }
    ],
    "cost": 0.0200195,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Complementary artificial intelligence designed to augment human discovery</p>
<p>Jamshid Sourati 
University of Chicago
1155 S. 60th Street Chicago60637IL</p>
<p>James Evans 
University of Chicago
1155 S. 60th Street Chicago60637IL</p>
<p>Santa Fe Institute
1399 Hyde Park Road Santa Fe87501NM</p>
<p>Complementary artificial intelligence designed to augment human discovery
* Correspondence to jevans@uchicago.edu 1
Neither artificial intelligence designed to play Turing's imitation game, nor augmented intelligence built to maximize the human manipulation of information are tuned to accelerate innovation and improve humanity's collective advance against its greatest challenges. We reconceptualize and pilot beneficial AI to radically augment human understanding by complementing rather than competing with human cognitive capacity. Our approach to complementary intelligence builds on insights underlying the wisdom of crowds, which hinges on the independence and diversity of crowd members' information and approach. By programmatically incorporating information on the evolving distribution of scientific expertise from research papers, our approach follows the distribution of content in the literature while avoiding the scientific crowd and the hypotheses cognitively available to it. We use this approach to generate valuable predictions for what materials possess valuable energy-related properties (e.g., thermoelectricity), and what compounds possess valuable medical properties (e.g., asthma) that complement the human scientific crowd. We demonstrate that our complementary predictions, if identified by human scientists and inventors at all, are only discovered years further into the future. When we evaluate the promise of our predictions with first-principles or data-driven simulations of those properties, we demonstrate an "expectation gap" such that increased complementarity of our predictions do not decrease and in some cases increase the probability of these properties above those discovered and published by human scientists. In summary, by tuning AI to avoid the crowd, we can generate hypotheses unlikely to be imagined or pursued without intervention until the distant future that promise to punctuate scientific advance. By identifying and correcting for collective human bias, these models also suggest opportunities to improve human prediction by reformulating science education for discovery.</p>
<p>Two competing visions for computational intelligence have dominated designs over the past half-century, but neither are tuned to accelerate humanity's advance against its greatest challenges, such as advancing science and technology for human benefit. Artificial Intelligence, coined by McCarthy in 1955, fixes humans as the standard of intelligence, following Turing's "imitation game" 1 . This influential approach became more tightly tethered to human intelligence with Samuel's work to build "machine learning" algorithms in the late 1950s 2 that not only produce human-like outcomes, but train on human moves. The Turing test vision of AI contrasted with a contemporary program to directly "Augment" Intelligence by reducing frictions in the conveyance and manipulation of information by Ashby 3 , Englebart 4 , Licklider 5 and others. If humanoid robots embody artificial intelligence; human-computer interfaces (e.g., screens, mice, EEG helmets, brain implants) realize augmented intelligence, but both visions feel inert to assist with science and technology design challenges, as in biomedicine and material science, on which millions of human scientists and engineers have collaborated and competed for centuries. Moreover, with millions of active scientists and engineers around the world and stagnating growth in labor productivity, halving to 1.3% for all but one OECD country since the 1990s 6 , is the production of computational intelligence that mimics human capacity our most strategic or ethical investment? Here we reconceptualize and pilot beneficial AI that radically complements human understanding by thinking differently, complementing human cognitive capacity rather than competing with or directly extending it.</p>
<p>Our approach to complementary intelligence builds on insights underlying the wisdom of crowds 7 , which hinges on the independence and diversity of crowd members' information 8 and approach 9 . In machine learning contexts like the Netflix Prize and Kaggle, ensemble models have always won 10 . In scientific crowds, findings established by more distinct methods and researchers are much more likely to replicate 11,12 . If we model discovery as establishing novel links among otherwise disconnected concepts 13 , discovery cannot occur until discoverers arise with viewpoints that bridge the fields required to imagine those conceptual connections (Fig. 1a). This diversity of scientific viewpoints was implicitly drawn upon by pioneering information scientist Swanson in a heuristic approach to knowledge generation. For example, he hypothesized that if Raynaud's disorder was linked to blood viscosity in one literature, and fish oil was known to decrease that viscosity in another, then fish oil might lessen the symptoms of Raynaud's disorder, but would unlikely be arrived at within the field because no scientist was available to infer it [14][15][16] , one of several hypotheses later experimentally demonstrated [17][18][19] . Expansive opportunities for discovery persist as researchers crowd around past discoveries 20 , refusing to explore regions of knowledge cognitively distant from recent findings 21 (Extended Data Fig. 1). Our approach in this article scales and makes Swanson's heuristic continuous, combining it with explicit measurement of the scientific expertise distribution that draw upon advances in unsupervised manifold learning 22 . Recent efforts to generate scientific hypotheses rely heavily on scientific literature, but ignore equally available publication meta-data. By programmatically incorporating information on the evolving distribution of scientific expertise, our approach targets the exploration of areas far from past discoveries, avoiding the scientific crowd. As such, the suggestions that result complement collective intelligence and enable us to punctuate advance by identifying promising experiments unlikely to be pursued by scientists in the near future without intervention.</p>
<p>In order to avoid the scientific crowd, our approach must first identify those topics at the focus of collective attention in the scientific system. Metadata about the distribution of research experts across topics and time represents a critical social fact that can stably improve our inference about whether scientific relationships will receive scientific attention or remain unimagined and unexplored 13,23 . We build expert awareness into our approach to identify and validate the scientific and technological benefit of pursuing complementary research avenues unlikely to be considered by unassisted human experts. The proposed framework provides opportunities for intellectual arbitrage between isolated communities through complementary intelligences unconstrained by the human incentive to flock together within fields.</p>
<p>Avoiding Cognitive Availability</p>
<p>We model the cognitive availability of a hypothesis to human scientists by measuring the distribution of experts exposed to its underlying concepts, linked by previous discoveries that intermediate them and which could guide human intuition from one to the other (Fig. 1a). The distribution of relevant experts in science can be estimated from a sufficient corpus of research articles, where papers inscribe the mixed network of publishing scientists and concepts they investigate. We represent these complex connectivities with a hypergraph, where published articles are hyperedges connecting authors and mentioned concepts. Hypergraphs are effective at representing complex social interaction [24][25][26] and proximity between concepts across them quantifies their cognitive availability to scientist teams, which effectively forecasts human discovery and publication 27 . Scientific entities further apart in the hypergraph will be less likely conceived together, or seen as relevant by scientists, dramatically reducing their chance for consideration and discovery. We can measure node proximities with any graph distance metric that varies with expert density, such as unsupervised neural embeddings, Markov transition probabilities, or self-avoiding walks from Schramm-Loewner evolutions. Here we use shortest-path distances (SPD) between conceptual nodes, as interlinked by authors in our mixed hypergraph. In the remainder of our paper, we divide concepts into materials such as chemical compounds and the valuable scientific properties that may be attributed them, like conductivity, treatment potential, regulation of a disease-related gene, etc. The hypotheses we explore involve material and biomedical relationships between materials and their properties.</p>
<p>In order to avoid selecting hypotheses without scientific promise, cognitive availability must couple with a signal of hypothesis plausibility. Such a signal could be provided by the published research literature and quantified with unsupervised knowledge embedding models 28 . Alternatively, a signal of plausibility could be derived from theory-driven models of material properties. Here we use unsupervised knowledge embeddings for our algorithm, reserving theory-driven model simulations to evaluate the value and human complementarity of our predictions. Specifically, we measure the scientific merit of any given hypothesis using the cosine similarity between embedding vectors of material and property nodes that comprise each hypothesis. Figure 1b provides a general overview of our algorithm for inferring materials with a target property. Initialized once a pool of candidate materials has been extracted from literature, we perform parallel operations to generate hypotheses that are both scientifically plausible and human-complementary. We train an unsupervised word embedding model over prior publications and measure scientific relevance as cosine distance in the embedding. In parallel, we indicate cognitive availability by structuring the hypergraph such that each author and material or property node from a paper is encased within a hyperedge and shortest path distances between the property and all materials are computed across the graph. We transform signals of plausibility and cognitive availability into a unified scale and linearly combine them with a mixing coefficient (see details in Methods and Supplementary Information). With its expert awareness, our algorithm can symmetrically generate either the most or least-human hypotheses-those likely to compete versus complement collective human capacity-based on the sign of the mixing coefficient. Negative values lead to predictions that mimic human experts in discovery, while positive values produce hypotheses least similar to those human experts could infer, straddling socially but not scientifically disconnected fields. At extremes, =-1 and 1 yield algorithms that generate predictions very familiar or very alien to human experts, regardless of scientific merit. Setting =0 implies exclusive emphasis on scientific plausibility, blind to the distribution of experts. This mode is equivalent to traditional discovery prediction methods exclusively based on previously published content. Intermediate positive s balance exploitation of relevant materials with exploration of areas unlikely considered or connected by human experts. Materials with the highest resulting scores are reported as the algorithm's predictions.</p>
<p>In the following sections, we evaluate the complementarity of our inferences for human science by verifying (1) their distinctness from contemporary investigations and (2) their scientific promise. We anticipate that both features will simultaneously increase in ranges of higher than those that characterize published science. Scientific merit will naturally reduce at the extremes of our interval [-1,1], however, where the algorithm ignores an inferred hypothesis' literature-based plausibility.</p>
<p>Evaluating Discovered Predictions</p>
<p>As we increase , the algorithm avoids inferences that lie within regions of high expert density and focuses on candidate materials and properties that span disciplinary divides and evade human attention. As a result, we expect that generated hypotheses with large will diverge from those pursued by the scientific community, will less likely become published, and if published, will be discovered further into the future, after science has reorganized itself to consider them. In order to verify these hypotheses, we first assess the discoverability of hypotheses inferred from different values by computing the precision between our inferences and published discoveries. Results strongly confirm our expectation that materials inferred at higher values are less discoverable by human scientists (Extended Data Fig. 2). Materials distant from a given property in the hypergraph remain cognitively unavailable to scientists in the property's proximity (Fig. 1c). It takes longer for researchers in the field to broach knowledge gaps separating unfamiliar materials from valued properties. Among the inferences eventually discovered, we measure the discovery waiting time and expect to observe an increasing trend in wait times as we move from negative (human-competitive) to positive (human-complementary) values in our predictions. Generating 50 hypotheses per value and evaluating the resulting predictions indicates that for the majority of targeted properties the average discovery wait times climb markedly when increasing (Fig. 2) for energy-related chemical properties (Fig. 2a-2c), COVID-19 (Fig. 2d) and 70% of the other human diseases (Fig.  2e). Averaging wait times across all human diseases manifests a clear increasing trend. For some cases such as COVID-19 (Fig. 2d), none of the complementary predictions made with positive values come to be discovered by humans within the time frame we examine.</p>
<p>Evaluating Undiscovered Predictions</p>
<p>To evaluate the scientific merit of our algorithm's undiscovered hypotheses requires data beyond the extant literature. Such hypotheses necessarily grow to comprise the vast majority of cases for large values of . If science was an efficient market and experts optimally pursued scientific quality, then in human-avoiding high hypotheses, we would observe a proportional decline in their scientific promise and efficacy. On the other hand, if scientists crowd together along the frontier of scientific possibility and their continued efforts yield diminishing marginal returns, we might observe an increase in promise as we move beyond them.</p>
<p>To evaluate the merit of scientific inferences, we utilize first-principles or data-driven models derived uniquely for each property based on well-established theoretical principles within the field. Such models assign real-valued scores to candidate materials as a measure of their potential for possessing the targeted properties. These computations may be carried out without regard for whether materials have yet been discovered, making them a suitable, if conservative, scoring function for evaluating undiscovered hypotheses. We produced such scores for approximately 45% of the properties we considered above using first-principle equations or based on databases curated through high-throughput protein screens. To evaluate thermoelectric promise, we used power factor (PF) as an important component of the overall thermoelectric figure of merit, zT, calculated using density functional theory for candidate materials as a strong indication of thermoelectricity 29,30 . To evaluate ferroelectricity, estimates of spontaneous polarization obtained through symmetry analysis and relevant theoretical equations serve as a reliable metric for this property 31 . For human diseases including COVID-19, proximity between disease agents (e.g., SARS-CoV-2) and candidate compounds in protein-protein interaction networks suggests the likelihood a material will recognize and engage with the disease agent 32 (for more details on how these theoretical scores are derived see the Supplementary Information). We note that scores based on first-principles equations or simulations represent conservative estimates of scientific merit as they are based on widely-accepted, scientist-crafted and theory-inspired models. Because these scores are potentially available to scientists in the area, they may be considered when guiding investigation, such that experiments on these unevaluated hypotheses are very often promising. Nevertheless, in what follows we show that intermediate positive s manifest continuation or improvement on even this conservative measure of quality.</p>
<p>We expect the average theoretical scores of hypotheses to decay significantly at the extremes of the range [-1,1], as at those points the algorithm ignores the merit signal putting it at higher risk of generating scientifically irrelevant (or absurd) proposals. We expect, however, that this decay will occur more slowly than the decrease in hypothesis discovery and publication, which implies a interval where proposals are not discoverable but highly promising-an ideal operating region for the generation of hypotheses that complement those from the human scientific crowd. In order to verify this, we contrasted changes in average theoretical scores with the discoverability of generated hypotheses for various values, which we quantify with precision-the overlap between predictions and published discoveries. As illustrated in Fig. 3 (first row), discoverability decreases near the transition of from negative to positive values, but its decay is much sharper than average theoretical scores, which do not collapse until nearly =0.4. This holds for electrochemical properties and the majority of diseases. Results for certain individual diseases can be seen in the second row of Fig. 3 (for the full set of results see Extended Data Fig. 3 and Supplementary Information). Moreover, note that for the cases investigated, average theoretical scores for inferred hypotheses grow higher than average scores for actual, published discoveries before eventual decay at high values. For certain properties like thermoelectricity or therapeutic efficacy against the disease Alopecia, theoretical merit of our inferences exhibit striking and dramatic growth from negative (scientist-mimicking) to positive (scientist-avoiding) hypotheses, suggesting strong diminishing returns to following these scientific crowds, whose overharvested fields have become barren for new discoveries.</p>
<p>In order to compare the decay rate of discoverability and theoretical scores, we define and compute the expectation gap to measure the distance between expected values for two conditional distributions over . A randomly selected prediction is (1) identified as promising based on its corresponding first-principle score, and (2) discoverable, i.e., studied and published by a scientist following prediction year (for details see Methods and Supplementary Information). A positive expectation gap indicates that increasing will preserve the quality of predictions while making them more complementary to human hypotheses. As shown in Fig. 4a, the vast majority of properties considered in this section yield substantial and significantly positive expectation gaps. Building on this, we use a probabilistic model to assess the complementarity of our algorithm's prediction with those of the scientific community for any value of . This is done by computing the joint probability that a randomly selected prediction is plausible in terms of the desired property and beyond current scientists' scope of research (see Supplementary Information). These probabilities specify the optimal to balance exploitation and exploration in augmenting collective human prediction. Results in Fig. 4b indicates the optimal point varies for different properties, but one can distinguish the range 0.2-0.3 as the most consistently promising interval.</p>
<p>Discussion</p>
<p>Here we explore the potential for building AI algorithms to radically augment the scientific community. Building on insights about independence underlying the wisdom of crowds, we seek to complement the clustering driven by interactions and institutions of the scientific community. By tuning our algorithm to avoid the crowd, we generate promising hypotheses unlikely to be imagined, pursued or published without machine recommendation for years into the future. By identifying and correcting for collective patterns of human attention, formed by field boundaries and institutionalized education, these models complement the contemporary scientific community. A further class of complementary predictions could be tuned to compensate not only for emergent collective bias, but universal cognitive constraints, such as limits on the human capacity to conceive or search through complex combinations (e.g., high-order therapeutic cocktails 33 ). Disorienting hypotheses from such a system will not be beautiful, but being inconceivable, they break fresh ground and sidestep the path-dependent "burden of knowledge" where scientific institutions require new advances built upon the old for ratification and support 34,35 .</p>
<p>Our approach can also be used to identify individual and collective biases that limit productive exploration and suggest opportunities to improve human prediction by reformulating science education for discovery. Insofar as research experiences and relationships condition the questions scientists investigate, education tuned to discovery would conceive of each student as a new experiment, recombining knowledge and opportunity in novel ways. Our investigation underscores the power of incorporating human and social factors to produce artificial intelligence that complements rather than substitutes for human expertise. By making AI hypothesis generation aware of human expertise, it can race with rather than against the scientific community to expand the scope of human imagination and discovery. Dashed lines represent paths of more or less cognitive availability between topics ("triangle", "diamond" and "square"). (b) Overview of our complementary discovery prediction algorithm. Beginning with a scientific corpus and a targeted property, candidate materials are extracted from the corpus and used along with property mentions and authors to form the hypergraph. The algorithm follows two branches to compute plausibility from word embedding semantic similarities and "alienness" or human inaccessibility from hypergraph shortest-path distances. These two signals are combined after proper normalization and standardization through the mixing coefficient to generate a prediction more or less complementary to the flow of human discovery. Candidate materials are sorted based on resulting scores and those with highest rank are reported as proposed discoveries. (c) Discovery wait times for relations between "triangle"-"diamond" and "triangle"-"square". The time one needs to wait for a relationship to be discovered is proportional to the path length of cognitive availability between the two relevant topics. The denser presence of experts around the pair "triangle"-"diamond" implies greater cognitive availability leading to earlier discovery and publication versus "triangle"-"square" where the connection requires a longer path.   </p>
<p>Methods</p>
<p>Experiments and Data Collection</p>
<p>We used two distinct datasets in our experiments. For energy-related properties, i.e., thermoelectricity, ferroelectricity and photovoltaic materials, we used a pre-curated dataset of approximately 1.5M articles whose topics are relevant to inorganic materials. These articles have been selected and pre-processed by Tshitoyan et. al (2019) 28 , who also made their DOIs publicly available. We downloaded abstracts of these DOIs through the Scopus API provided by Elsevier (https://dev.elsevier.com/) and extracted 106K candidate inorganic materials from the downloaded abstracts using Python Materials Genomics 36 and direct rule-based string processing. For COVID-19 and other human diseases, we used the MEDLINE database which includes more than 28M articles published on a wide range of topics. In this dataset, we identified around 7,800 approved candidate drugs, from which we selected approximately 4,000 drugs with simple names (excluding names with multiple numerical subparts). We use Comparative Toxicogenomics Database (CTD) 37 to extract ground-truth associations between our drug pool and 400 human diseases (besides COVID-19), selected such that they represent the largest number of associations. Note that in order to form our hypergraph, we need to know who authored the articles. The Scopus API distinguishes distinct authors and assigns unique codes to them. However, this is not the case with MEDLINE, where authors are not identified other than by name. We use the set of disambiguated authors shared through PubMed Knowledge Graph (PKG) package 38 , which were obtained by combining results from the Author-ity disambiguation of PubMed 39 and the more recent semantic scholar database 40 .</p>
<p>Our discovery prediction experiment begins by setting a date of prediction (e.g., the beginning of January 2001). We then form our hypergraph using literature prior to that date and let our algorithm make predictions from materials unstudied in relation to a given property at that point. Many of our evaluation criteria are based on human discovery. For energy-related properties, we model human discovery as first-time co-occurrence of materials with the targeted property, following methodology of the team that curated the dataset 28 . For all diseases except COVID-19, human discoveries were identified through drug-disease associations indicated in CTD. We set the date for each drug-disease discovery to the earliest publication reported by the CTD for curated associations. For COVID-19, discovered drugs are identified based on their involvement in COVID-related studies reported by ClinicalTrials.org that began after breakout of the disease in the US in the beginning of 2020. Discovery date for each association is set to the date the corresponding study was first posted, and if the drug was involved in multiple trials we considered the earliest. There were 6,280 trials posted as of August 5th, 2021 (ignoring 37 trials dated before 2020), which included 279 drugs from our pool (~7%) within their designs.</p>
<p>Prediction Algorithm</p>
<p>Our predictor consists of two scoring functions. The first measures the cognitive unavailability ("alienness") of candidate materials via Shortest-Path distance (SPD) between the nodes corresponding to the targeted property and candidates. The second measures scientific plausibility through the semantic cosine similarities of their corresponding keywords. For this purpose, we train skipgram word2vec embedding models over the literature (literature collected on inorganic materials for energy-related properties and MEDLINE for the diseases) produced prior to the prediction year. The prediction year is set to the beginning of 2001 for all the considered properties except for COVID-19 for which the prediction year is set to the beginning of 2020. We combine the alienness and plausability scores with a mixing coefficient, denoted by , adjusting their contributions to obtain a final score for the candidate. The plausibility component yields continuous scores distributed close to Gaussian, whereas the alienness component offers unbounded ordinal SPD values. Simple normalization methods are insufficient to combine scores with such distinct characteristics. As a result, we first standardize the two scores to a unified scale by applying the Van der Waerden transformation 41 , followed by a Z-score normalization. The final step includes taking the weighted average of the resulting Z-scores with weights depending on (see Supplementary Information for more details).</p>
<p>We want our predictor to infer undiscoverable yet promising hypotheses. Setting to a more positive value makes predictions less familiar and more alien, i.e., less discoverable. Moreover, increasing to the positive extreme (i.e., +1) excludes scientific merit from the algorithm's objective in materials selection. Hence, growing causes both discoverability and plausibility of predictions to decay. What matters to us is that plausibility decreases more slowly than discoverability, suggesting that the predictor achieves a close-to-ideal state where predictions are simultaneously alien and promising. In order to verify this with a single number, we define the expectation gap criterion, computed as the difference between expected values of the following two distributions over : ℙ( |plausible) and ℙ( |discoverable). The terms "plausible" and "discoverable" on the conditional sides could be substituted by the precise statements "a randomly selected inferred hypothesis is theoretically plausible" and "a randomly selected inferred hypothesis is discoverable"-it will be published by scientists, respectively. While we know both of these distributions reduce as approaches +1, the expectation gap measures any positive shift in the mass of ℙ( |plausible) against ℙ( |discoverable). The likelihood of discovery ℙ( |discoverable) can be estimated through an empirical distribution of predictions discovered and published. Scientific plausibility can be estimated by leveraging properties' theoretical scores obtained from prior knowledge and first-principles equations and data from relevant fields. We estimate ℙ( = 0 | plausible) in two steps: (1) converting theoretical scores to probabilities, and (2) computing weighted maximum likelihood estimates of ℙ( = 0 |plausible) given a set of predictions generated by our algorithm operated with 0 (see Supplementary Information for details). We restrict experiments in this section to only those properties for which we could obtain a reliable source of theoretical scores (see Supplementary Information for details of the scores): thermoelectricity, ferroelectricity, COVID-19 and 175 other human diseases (178 out of 404 total properties). Finally, note that expectation gaps and average discovery dates (described above) say nothing about the interval most likely to lead to complementarity and plausibility. We introduce an additional probabilistic criterion for this purpose, which jointly models these two features and computes their likelihood for various values, ℙ(undiscoverable, plausible | ). One can use this distribution to screen the best operating point for complementary artificial intelligence (see Supplementary Information).</p>
<p>11 Extended Data Fig. 1. Illustration of localized discoveries made by scientists regarding thermoelectric materials (a) and repurposing materials for treating gout (b), asthma (c) and malaria (d). Red bars indicate fractions of discoveries occurring at various levels of proximity (measured through shortest path distances (SPD) in a literature-based hypergraph) to a particular targeted property. Note how these distributions concentrate around low proximites. Blue bars indicate average scores representing plausibility that candidate materials have the targeted property in theory. For thermoelectricity (a), we defined Power Factor (PF) as the plausibility score, and for the three human diseases shown here (b-d), scores are obtained through similarities between protein profiles of the candidate materials and the targeted diseases. Fig. 3. Discoverability and scientific merit for predictions made with varying values in the research case repurposing drugs for treating human diseases. (a) Precision values for predictions generated with eight levels of and computed for all 400 human diseases we considered (except COVID-19). Diseases are sorted in terms of the number of relevant drugs. (b) Average theoretical scores measured through protein-protein similarity between diseases and candidate drugs for predictions generated with the same values. We compute such protein-based theoretical scores for 176 diseases out of 400 total cases (44%). In both subfigures, horizontal lines show average values across all diseases.</p>
<p>Extended Data</p>
<p>Fig. 1 .
1(a) Distribution and overlap of experts investigating (and publishing on) topics represented by yellow geometric shapes.</p>
<p>Fig. 2 .
2Wait time for published discoveries associated with distinct properties and different values. (a-d) Average annual/monthly discovery wait times are shown as thick gray arcs, where thickness represents the percentage of materials discovered in the corresponding year/month. Each orbit is associated with a particular value with larger (more red) orbits representing larger values. The values we consider here vary between -0.8 (the smallest, bluest orbit) and 0.8 (the largest, reddest orbit). The plot in the upper right quarter of the orbits reveals the total average of discovery wait times including all years/months for the considered values. (f) Total average for wait times across all the human diseases (except COVID-19) in our experiments.</p>
<p>Fig. 3 .
3Overlapping percentage and average theoretical scores calculated for predictions. (a-b) Green bars show overlapping percentages and curves indicate (a) average PF for thermoelectricity and (b) spontaneous polarization for ferroelectricity. (c) Overlapping and average theoretical scores (i.e., protein-protein interaction similarity scores) of the therapeutic predictions. Dashed lines in all cases show average theoretical scores computed for actual discoveries following prediction year. (d) Overlapping versus average protein-protein similarity scores for nine human disease examples. The y-axis indicates overlapping percentage and color gradient represents average theoretical scores for predictions.</p>
<p>Fig. 4 .
4(a) Expectation gap calculated for properties with theoretical first-principle scores. We plot the conditional distributions ℙ( |plausible) and ℙ( |discoverable) separately for Thermoelectricity, Ferroelectricity and COVID-19, whereas for the remainder of human diseases included in our experiments we simply show the normalized histogram (first row) and individual (second row) gaps. (b) The joint probability of simultaneous undiscoverability and plausibility for different values.9
AcknowledgementsThe authors wish to thank our funders for their generous support: National Science Foundation #1829366; Air Force Office of Scientific Research #FA9550-19-1-0354, #FA9550-15-1-0162; DARPA #HR00111820006. We thank Laszlo Barabasi and Deisy Morselli Gysi for helpful data related to their network-based forecast of COVID-19 drugs and vaccines with protein-protein interactions32, and Anubhav Jain, Vahe Tshitoyan and Alex Dunn for sharing data and code to help replicate their work on unsupervised word embeddings and latent knowledge about material science28. We also thank participants of the Santa Fe Institute workshop "Foundations of Intelligence in Natural and Artificial Systems", the University of Wisconsin at Madison's HAMLET workshop, and colleagues at the Knowledge Lab for helpful comments.
. A M Turing, I.-COMPUTING MACHINERY AND INTELLIGENCE. Mind. 433460Turing, A. M. I.-COMPUTING MACHINERY AND INTELLIGENCE. Mind vol. LIX 433-460 (1950).</p>
<p>Some Studies in Machine Learning Using the Game of Checkers. A L Samuel, IBM Journal of Research and Development. 3Samuel, A. L. Some Studies in Machine Learning Using the Game of Checkers. IBM Journal of Research and Development vol. 3 210-229 (1959).</p>
<p>An introduction to cybernetics. W R Ashby, 10.5962/bhl.title.5851Ashby, W. R. An introduction to cybernetics. (1956) doi:10.5962/bhl.title.5851.</p>
<p>Augmenting human intellect: A conceptual framework. D C Engelbart, Menlo Park, CAEngelbart, D. C. Augmenting human intellect: A conceptual framework. Menlo Park, CA (1962).</p>
<p>. J C R Licklider, Man-Computer Symbiosis. IRE Transactions on Human Factors in Electronics HFE. 1Licklider, J. C. R. Man-Computer Symbiosis. IRE Transactions on Human Factors in Electronics HFE-1, 4-11 (1960).</p>
<p>Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics. E Brynjolfsson, D Rock, C Syverson, 10.3386/w24001Brynjolfsson, E., Rock, D. &amp; Syverson, C. Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics. https://www.nber.org/papers/w24001 (2017) doi:10.3386/w24001.</p>
<p>Vox populi (the wisdom of crowds). F Galton, Nature. 75Galton, F. Vox populi (the wisdom of crowds). Nature 75, 450-451 (1907).</p>
<p>The wisdom of crowds: Why the many are smarter than the few and how collective wisdom shapes business. J Surowiecki, Economies, Societies and Nations. 296Surowiecki, J. The wisdom of crowds: Why the many are smarter than the few and how collective wisdom shapes business. Economies, Societies and Nations 296, (2004).</p>
<p>The Diversity Bonus: How Great Teams Pay Off in the Knowledge Economy. S E Page, Princeton University PressPage, S. E. The Diversity Bonus: How Great Teams Pay Off in the Knowledge Economy. (Princeton University Press, 2019).</p>
<p>Y Freund, R E Schapire, Others, Experiments with a new boosting algorithm. in icml. Citeseer96Freund, Y., Schapire, R. E. &amp; Others. Experiments with a new boosting algorithm. in icml vol. 96 148-156 (Citeseer, 1996).</p>
<p>Centralized scientific communities are less likely to generate replicable results. V Danchev, A Rzhetsky, J A Evans, Elife. 8Danchev, V., Rzhetsky, A. &amp; Evans, J. A. Centralized scientific communities are less likely to generate replicable results. Elife 8, (2019).</p>
<p>Prediction of robust scientific facts from literature. A V Belikov, A Rzhetsky, J Evans, Nature Machine Intelligence. 110Belikov, A. V., Rzhetsky, A. &amp; Evans, J. Prediction of robust scientific facts from literature. Nature Machine Intelligence 1-10 (2022).</p>
<p>Choosing experiments to accelerate collective discovery. A Rzhetsky, J G Foster, I T Foster, J A Evans, Proc. Natl. Acad. Sci. U. S. A. 112Rzhetsky, A., Foster, J. G., Foster, I. T. &amp; Evans, J. A. Choosing experiments to accelerate collective discovery. Proc. Natl. Acad. Sci. U. S. A. 112, 14569-14574 (2015).</p>
<p>Fish oil, Raynaud's syndrome, and undiscovered public knowledge. D R Swanson, Perspect. Biol. Med. 30Swanson, D. R. Fish oil, Raynaud's syndrome, and undiscovered public knowledge. Perspect. Biol. Med. 30, 7-18 (1986).</p>
<p>Medical literature as a potential source of new knowledge. D R Swanson, Bull. Med. Libr. Assoc. 78Swanson, D. R. Medical literature as a potential source of new knowledge. Bull. Med. Libr. Assoc. 78, 29-37 (1990).</p>
<p>Using concepts in literature-based discovery: Simulating Swanson's Raynaud--fish oil and migraine--magnesium discoveries. M Weeber, H Klein, De Jong-Van Den, L T W Berg, R Vos, J. Am. Soc. Inf. Sci. Technol. 52Weeber, M., Klein, H., de Jong-van den Berg, L. T. W. &amp; Vos, R. Using concepts in literature-based discovery: Simulating Swanson's Raynaud--fish oil and migraine--magnesium discoveries. J. Am. Soc. Inf. Sci. Technol. 52, 548-557 (2001).</p>
<p>. J Evans, A Rzhetsky, Science, Science. 329Evans, J. &amp; Rzhetsky, A. Machine Science. Science 329, 399-400 (2010).</p>
<p>Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study. R A Digiacomo, J M Kremer, D M Shah, The American Journal of Medicine. 86Digiacomo, R. A., Kremer, J. M. &amp; Shah, D. M. Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study. The American Journal of Medicine vol. 86 158-164 (1989).</p>
<p>Effects of Intravenous and Oral Magnesium on Reducing Migraine: A Meta-analysis of Randomized Controlled Trials. H.-Y Chiu, T.-H Yeh, Y.-C Huang, P.-Y Chen, Pain Physician. 19Chiu, H.-Y., Yeh, T.-H., Huang, Y.-C. &amp; Chen, P.-Y. Effects of Intravenous and Oral Magnesium on Reducing Migraine: A Meta-analysis of Randomized Controlled Trials. Pain Physician 19, E97-112 (2016).</p>
<p>On Biases Of Attention In Scientific Discovery. U Singer, K Radinsky, E Horvitz, 10.1093/bioinformatics/btaa1036Bioinformatics. Singer, U., Radinsky, K. &amp; Horvitz, E. On Biases Of Attention In Scientific Discovery. Bioinformatics (2020) doi:10.1093/bioinformatics/btaa1036.</p>
<p>Slowed canonical progress in large fields of science. J S G Chu, J A Evans, Proc. Natl. Acad. Sci. U. S. A. 118Chu, J. S. G. &amp; Evans, J. A. Slowed canonical progress in large fields of science. Proc. Natl. Acad. Sci. U. S. A. 118, (2021).</p>
<p>Linguistic regularities in continuous space word representations. T Mikolov, W Yih, G Zweig, hlt-Naacl. Mikolov, T., Yih, W. &amp; Zweig, G. Linguistic regularities in continuous space word representations. hlt-Naacl (2013).</p>
<p>Data on how science is made can make science better. J Sourati, A Belikov, J Evans, Sourati, J., Belikov, A. &amp; Evans, J. Data on how science is made can make science better. (2022).</p>
<p>Weaving the fabric of science: Dynamic network models of science's unfolding structure. F Shi, J G Foster, J A Evans, Soc. Networks. 43Shi, F., Foster, J. G. &amp; Evans, J. A. Weaving the fabric of science: Dynamic network models of science's unfolding structure. Soc. Networks 43, 73-85 (2015).</p>
<p>A hypergraph model for representing scientific output. R I Lung, N Gaskó, M A Suciu, Scientometrics. 117Lung, R. I., Gaskó, N. &amp; Suciu, M. A. A hypergraph model for representing scientific output. Scientometrics 117, 1361-1379 (2018).</p>
<p>Social Influence Maximization in Hypergraphs. A Antelmi, G Cordasco, C Spagnuolo, P Szufel, Entropy. 23Antelmi, A., Cordasco, G., Spagnuolo, C. &amp; Szufel, P. Social Influence Maximization in Hypergraphs. Entropy 23, (2021).</p>
<p>Accelerating science with human versus alien artificial intelligences. J Sourati, J Evans, arXiv [cs.AISourati, J. &amp; Evans, J. Accelerating science with human versus alien artificial intelligences. arXiv [cs.AI] (2021).</p>
<p>Unsupervised word embeddings capture latent knowledge from materials science literature. V Tshitoyan, Nature. 571Tshitoyan, V. et al. Unsupervised word embeddings capture latent knowledge from materials science literature. Nature 571, 95-98 (2019).</p>
<p>Thermoelectric power factor: Enhancement mechanisms and strategies for higher performance thermoelectric materials. A Mehdizadeh Dehkordi, M Zebarjadi, J He, T M Tritt, Mater. Sci. Eng. R Rep. 97Mehdizadeh Dehkordi, A., Zebarjadi, M., He, J. &amp; Tritt, T. M. Thermoelectric power factor: Enhancement mechanisms and strategies for higher performance thermoelectric materials. Mater. Sci. Eng. R Rep. 97, 1-22 (2015).</p>
<p>An ab initio electronic transport database for inorganic materials. F Ricci, Sci Data. 4170085Ricci, F. et al. An ab initio electronic transport database for inorganic materials. Sci Data 4, 170085 (2017).</p>
<p>An automatically curated first-principles database of ferroelectrics. T E Smidt, S A Mack, S E Reyes-Lillo, A Jain, J B Neaton, Sci Data. 772Smidt, T. E., Mack, S. A., Reyes-Lillo, S. E., Jain, A. &amp; Neaton, J. B. An automatically curated first-principles database of ferroelectrics. Sci Data 7, 72 (2020).</p>
<p>Network Medicine Framework for Identifying Drug Repurposing Opportunities for COVID-19. D M Gysi, ArXiv. Gysi, D. M. et al. Network Medicine Framework for Identifying Drug Repurposing Opportunities for COVID-19. ArXiv (2020).</p>
<p>Promise and challenges in drug discovery and development of hybrid anticancer drugs. L K Gediya, V C Njar, Expert Opin. Drug Discov. 4Gediya, L. K. &amp; Njar, V. C. Promise and challenges in drug discovery and development of hybrid anticancer drugs. Expert Opin. Drug Discov. 4, 1099-1111 (2009).</p>
<p>The Burden of Knowledge and the 'Death of the Renaissance Man': Is Innovation Getting Harder?. B F Jones, Rev. Econ. Stud. 76Jones, B. F. The Burden of Knowledge and the 'Death of the Renaissance Man': Is Innovation Getting Harder? Rev. Econ. Stud. 76, 283-317 (2009).</p>
<p>A Nobel opportunity for interdisciplinarity. M Szell, Y Ma, R Sinatra, Nat. Phys. 14Szell, M., Ma, Y. &amp; Sinatra, R. A Nobel opportunity for interdisciplinarity. Nat. Phys. 14, 1075-1078 (2018).</p>
<p>A robust, open-source python library for materials analysis. S P Ong, Python Materials Genomics. 68Comput. Mater. Sci.Ong, S. P. et al. Python Materials Genomics (pymatgen): A robust, open-source python library for materials analysis. Comput. Mater. Sci. 68, 314-319 (2013).</p>
<p>The Comparative Toxicogenomics Database: update 2019. A P Davis, Nucleic Acids Res. 47Davis, A. P. et al. The Comparative Toxicogenomics Database: update 2019. Nucleic Acids Res. 47, D948-D954 (2019).</p>
<p>Building a PubMed knowledge graph. J Xu, Sci Data. 7205Xu, J. et al. Building a PubMed knowledge graph. Sci Data 7, 205 (2020).</p>
<p>Author Name Disambiguation in MEDLINE. V I Torvik, N R Smalheiser, ACM Trans. Knowl. Discov. Data. 3Torvik, V. I. &amp; Smalheiser, N. R. Author Name Disambiguation in MEDLINE. ACM Trans. Knowl. Discov. Data 3, (2009).</p>
<p>Construction of the Literature Graph in Semantic Scholar. W Ammar, arXiv [cs.CL]Ammar, W. et al. Construction of the Literature Graph in Semantic Scholar. arXiv [cs.CL] (2018).</p>
<p>C W Coakley, Practical Nonparametric Statistics. 953323rd ed.Coakley, C. W. Practical Nonparametric Statistics (3rd ed.). J. Am. Stat. Assoc. 95, 332 (2000).</p>
<p>Discoverability of predictions is measured through computing the precision metric, i.e., their overlapping percentage with respect to actual discoveries made after prediction year. Decreasing precision curves and their highly negative Pearson correlation coefficients are shown for (a) thermoelectricity, (b) ferroelectricity, (c) photovoltaics and (d) COVID-19. We visualize these statistics for the remaining human diseases with a scatterplot of. Extended Data Fig. 2. Illustration of decaying discoverability for predictions as increases. their Pearson correlation coefficients (e)Extended Data Fig. 2. Illustration of decaying discoverability for predictions as increases. Discoverability of predictions is measured through computing the precision metric, i.e., their overlapping percentage with respect to actual discoveries made after prediction year. Decreasing precision curves and their highly negative Pearson correlation coefficients are shown for (a) thermoelectricity, (b) ferroelectricity, (c) photovoltaics and (d) COVID-19. We visualize these statistics for the remaining human diseases with a scatterplot of their Pearson correlation coefficients (e).</p>            </div>
        </div>

    </div>
</body>
</html>