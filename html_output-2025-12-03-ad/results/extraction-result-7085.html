<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7085 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7085</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7085</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-57651d65078818821234d13544ac1f29858dcd67</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/57651d65078818821234d13544ac1f29858dcd67" target="_blank">Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> This work constructs a paired dataset of molecules and their corresponding text descriptions, which it uses to learn an aligned common semantic embedding space for retrieval and extends this to create a cross-modal attention-based model for explainability and reranking by interpreting the attentions as association rules.</p>
                <p><strong>Paper Abstract:</strong> We propose a new task, Text2Mol, to retrieve molecules using natural language descriptions as queries. Natural language and molecules encode information in very different ways, which leads to the exciting but challenging problem of integrating these two very different modalities. Although some work has been done on text-based retrieval and structure-based retrieval, this new task requires integrating molecules and natural language more directly. Moreover, this can be viewed as an especially challenging cross-lingual retrieval problem by considering the molecules as a language with a very unique grammar. We construct a paired dataset of molecules and their corresponding text descriptions, which we use to learn an aligned common semantic embedding space for retrieval. We extend this to create a cross-modal attention-based model for explainability and reranking by interpreting the attentions as association rules. We also employ an ensemble approach to integrate our different architectures, which significantly improves results from 0.372 to 0.499 MRR. This new multimodal approach opens a new perspective on solving problems in chemistry literature understanding and molecular machine learning.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7085",
    "paper_id": "paper-57651d65078818821234d13544ac1f29858dcd67",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00528775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries</h1>
<p>Carl Edwards, ChengXiang Zhai, Heng Ji<br>University of Illinois Urbana-Champaign<br>{cne2, czhai, hengji}@illinois.edu</p>
<h4>Abstract</h4>
<p>We propose a new task, Text2Mol, to retrieve molecules using natural language descriptions as queries. Natural language and molecules encode information in very different ways, which leads to the exciting but challenging problem of integrating these two very different modalities. Although some work has been done on text-based retrieval and structurebased retrieval, this new task requires integrating molecules and natural language more directly. Moreover, this can be viewed as an especially challenging cross-lingual retrieval problem by considering the molecules as a language with a very unique grammar. We construct a paired dataset of molecules and their corresponding text descriptions, which we use to learn an aligned common semantic embedding space for retrieval. We extend this to create a cross-modal attention-based model for explainability and reranking by interpreting the attentions as association rules. We also employ an ensemble approach to integrate our different architectures, which significantly improves results from 0.372 to 0.499 MRR. This new multimodal approach opens a new perspective on solving problems in chemistry literature understanding and molecular machine learning. ${ }^{1}$</p>
<h2>1 Introduction</h2>
<p>Discovering new properties and applications of different molecules is critical for accelerating discovery in medicine and science. Existing databases contain tens of millions of molecules; PubChem (Kim et al., 2016, 2019) alone has 110 million compounds. Many information retrieval (IR) tools for chemistry rely on queries based on natural language descriptions of the molecules and existing chemical reactions. Hundreds of millions of possible molecules cannot all possibly undergo laboratory</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Water is an oxygen hydride consisting of an oxygen atom that is covalently bonded to two hydrogen atoms.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Given a natural language description of water, we want to rank the corresponding molecule $\mathrm{H}_{2} \mathrm{O}$ first among all the possible molecules.
experimentation and be given attention by experts in order to create a description. To address this issue, it is critical to retrieve molecules directly from natural language descriptions. This approach allows newly discovered molecules to be easily integrated into the proposed IR framework. Our framework also allows for semantic-level search between natural language descriptions and molecules as well as for query expansion within traditional chemistry information retrieval systems.</p>
<p>Over the past several years, chemists have begun to rely increasingly on computational techniques for cataloging molecules and predicting chemical reactions, products, and properties, such as yield, toxicity, and water solubility (Wu et al., 2018; Glavatskikh et al., 2019; Coley et al., 2017; Ahneman et al., 2018; Fooshee et al., 2018). However, natural language and molecules are very different modalities of data, which makes integrating them together a challenging task. We argue that these two modalities are complementary and should be considered together.</p>
<p>Much current work focuses on images and language (Mogadala et al., 2020), but it is beneficial for the community to consider modalities beyond traditional ones, increasing their work's impact and efficacy. For example, integrating NLP and</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Molecule</th>
<th style="text-align: center;">An electrically neutral group of atoms bonded together.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Compound</td>
<td style="text-align: center;">Two or more elements held together by chemical bonds.</td>
</tr>
<tr>
<td style="text-align: center;">Chemical fingerprint</td>
<td style="text-align: center;">Represents a molecule or substructure using a bitstring. This allows for <br> efficient substructure search and similarity calculation.</td>
</tr>
<tr>
<td style="text-align: center;">Morgan fingerprint</td>
<td style="text-align: center;">A specific type of chemical fingerprint also known as ECFP.</td>
</tr>
<tr>
<td style="text-align: center;">SMILES string</td>
<td style="text-align: center;">A character-based sequence representation of a molecule. <br> (for example, $\mathrm{C} 1=\mathrm{CC}=\mathrm{CC}=\mathrm{C} 1$ is the SMILES string for benzene)</td>
</tr>
<tr>
<td style="text-align: center;">Canonical SMILES</td>
<td style="text-align: center;">A unique SMILES string for a molecule.</td>
</tr>
</tbody>
</table>
<p>Table 1: Relevant Terminology
molecules could improve drug discovery and design.</p>
<p>In pursuit of this goal, we propose a multimodal embedding approach for constructing an aligned semantic space between these two types of data to allow for cross-modal retrieval. No previous work has studied this retrieval problem. The closest is (Zhou et al., 2010), which uses a hybrid approach to document retrieval by replacing chemicals in text with canonical keywords in order to standardize different chemical synonyms. However, this does not take the semantic information of the molecule (properties beyond the atoms and graph structure, such as being a pollutant or hydrophobic) into account.</p>
<p>Additionally, incorporating cross-modal attention can lead to insights on the relations between molecule substructures and text keywords. For example, we find that given "pollutant," the model focuses on the substructure $\mathrm{F}-\mathrm{C}$. This contributes to higher-level explainability between molecules and their descriptions.</p>
<p>Our molecular encoder is based on the Mol2vec (Jaeger et al., 2018) algorithm, which creates "sentences" of substructure identifiers from molecules; we frame Text2Mol as a new, particularly challenging type of cross-lingual information retrieval (CLIR). This problem is much more challenging than traditional CLIR since the gap between the query and target is much larger. It also provides a useful benchmark for extending CLIR to incorporate multiple data modalities. Molecules are essentially a different language with a uniquely challenging grammar. In fact, several techniques apply models developed for natural language processing to SMILES strings-machine-readable characterbased representations for molecules (Weininger, 1988; Weininger et al., 1989).</p>
<p>The major novel contributions of this paper are:</p>
<ul>
<li>A new task Text2Mol: Cross-modal Text-</li>
</ul>
<p>Molecule Information Retrieval directly from natural language descriptions to molecules.</p>
<ul>
<li>Cross-modal attention-based association rules between molecules and text are used to improve results and for explainability.</li>
<li>A new benchmark dataset with 33,010 text-compound pairs for cross-modal textmolecule IR which can be used for crosslingual, multimodal, and explainable IR.</li>
</ul>
<h2>2 Task Definition</h2>
<p>To push the boundaries of multimodal models, we present a new IR task: Text2Mol.</p>
<p>Given a text query and list of molecules without any reference textual information (represented, for example, as SMILES strings, graphs, or other equivalent representations) retrieve the molecule corresponding to the query. Figure 1 shows an example of this task. From a text description of a molecule, the model must incorporate the information in the description into a semantic representation which can be used to directly retrieve the molecule.</p>
<p>This requires the integration of two very different types of information: the structured knowledge represented by text and the chemical properties present in molecular graphs. We assume there is only one correct (relevant) molecule for each description, so we consider two measures for this task: Hits@1 and mean reciprocal rank (MRR).</p>
<h2>3 Related Work</h2>
<h3>3.1 Multimedia Representation</h3>
<p>Much recent work in this area has fallen into the category of vision-language models which leverage transformers (Chen et al., 2019; Su et al., 2020; Lu et al., 2019). There are also more fine-grained</p>
<p>multimedia embedding approaches, such as integrating events from images and their descriptions (Li et al., 2020) or multimodal pattern mining ( Li et al., 2016). CLIP (Radford et al., 2021) uses natural language to train a zero-shot image classifier which can be easily applied to different datasets. Specifically, their loss function, which follows Sohn (2016), serves as a very efficient version of binary cross-entropy loss by comparing all samples in a mini-batch with each other. To our knowledge, we are the first to apply this technique to molecules and text, and we also extend this loss function to incorporate negative samples to allow for crossmodal attention between the two encoders.</p>
<h3>3.2 Molecule Representation</h3>
<p>One critical problem in the field of molecular machine learning is molecule representation. Fingerprinting methods have long been employed in cheminformatics to featurize molecule structural representations (Cereto-Massagué et al., 2015; Sandfort et al., 2020). However, this approach does not allow these representations to be learned from the data. Other representations include techniques such as kernel PCA using Tanimoto similarity (Rensi and Altman, 2017; Mallory et al.). Recent advances in machine learning have begun to be applied to this problem. Jaeger et al. (2018) use the Morgan fingerprinting algorithm to convert each molecule into a 'sentence' of its substructures. A dataset of molecules can be interpreted as a corpus, and Mol2vec then applies Word2vec (Mikolov et al., 2013a,b) to create molecule representations. Additionally, other recent advances such as BERT (Devlin et al., 2019) have been applied to the domain such as MolBERT (Fabian et al., 2020) and ChemBERTa (Chithrananda et al., 2020), which use SMILES strings (Weininger et al., 1989) as inputs to pretrain a BERT-esque model.</p>
<h3>3.3 Substructure or Description Retrieval</h3>
<p>Although the biomedical domain has been more popular than chemistry (Zheng et al., 2014; Li et al., 2019; Li and Ji, 2019; Islamaj Doğan et al., 2019; Zhang et al., 2021; Lai et al., 2021), information retrieval in chemistry has long been studied and is summarized by Krallinger et al. (2017). Most work has focused on only a single modality: text or molecules. Text-based retrieval includes tasks such as finding relevant papers for a chemical or reaction and chemical entity recognition. Much work has also been done in graph and molecule-
based retrieval (Hagadone, 1992; Barnard, 1993; Yan et al., 2005; Kratochvíl et al., 2018; Qu et al., 2019; Kratochvíl, 2019; Goyal et al., 2020). Hybrid approaches have also been attempted; Zhou et al. (2010) replace chemical entities in text with a unique canonical key (thus standardizing synonyms). This also allows them to perform query expansion by including similar molecules from their database. In contrast to this, we perform direct semantic cross-modal retrieval task in our approach, as opposed to just augmenting queries. Work in chemical entity recognition has also incorporated hybrid approaches, mostly as chemical name to structure converters such as ChemSpot (Rocktäschel et al., 2013) and OPSIN (Lowe et al., 2011).</p>
<h3>3.4 Cross-Lingual Retrieval</h3>
<p>Cross-lingual information retrieval (CLIR) is a technique to retrieve documents from a target language given a query in a different source language. Two common strategies are either translating the query into the target language or translating the document corpus into the source language (Zhang and Zhao, 2020). Further, work exists combining these approaches using interlingual semantics, such as via bilingual word embeddings (Vulic and Moens, 2015) or word embeddings and a dictionary (Bhattacharya et al., 2016).</p>
<p>Our problem, cross-modal molecule retrieval from text, can be considered as a CLIR task which we approach using an interlingual semantic approach. The model is trained on a parallel corpus of molecules and descriptions.</p>
<h2>4 Methodology</h2>
<h3>4.1 Model</h3>
<p>To accomplish this retrieval task, we need to connect text to molecules. To do so, we build an aligned semantic embedding space. Our approach consists of two distinct submodels: a text encoder and a molecule encoder. Both submodels create an embedding in the aligned space, and cosine similarity is used to rank the embeddings. A description embedding can be compared against a database of existing molecule embeddings, and this process scales easily using an approximate nearest neighbor search algorithm such as (Johnson et al., 2017). For the text encoder, we use SciBERT (Beltagy et al., 2019) and a linear projection to the embedding space followed by layer normalization (Ba</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Example of Morgan Fingerprinting from (Rogers and Hahn, 2010) for Butyramide. The algorithm updates the identifiers from radius $r=0$ to $r=1$, as shown by the green circles.
et al., 2016). For the molecule encoder, we consider two architectures. First, we use a multi-layer perceptron (MLP) that takes Mol2vec embeddings as input. Second, we integrate a graph convolutional network (GCN) (Kipf and Welling, 2017) into Mol2vec.</p>
<p>Mol2vec (Jaeger et al., 2018) converts molecule graph structures into "sentences" of substructures. These substructures are created using Morgan fingerprinting (Rogers and Hahn, 2010), which is a type of topological fingerprint, which were historically used for quick substructure lookup. Morgan fingerprints incorporate a number of molecular properties based on the Daylight atomic invariants rule (Weininger et al., 1989). Atomic invariants such as the number of connections, number of nonhydrogen bonds, and atomic number are used to create the initial identifier for an atom. By using a circular hashing technique, they are able to create a unique identifier for a molecular substructure of some radius $r$ centered around a central atom, as shown in Figure 2. The algorithm starts with a radius of zero which is iteratively increased until the desired substructure size is obtained. In Mol2vec, these fingerprints are used as tokens for each atom. In this work, we use a default value of $r=1$, which gives two tokens for each atom ( $r=0$ and $r=1$ ). This set of tokens is canonicalized in the same way as the canonical SMILES representation (Weininger et al., 1989). This list of tokens can be interpreted as a "sentence", and Mol2vec builds a
corpus of such sentences. It then uses the Word2vec skip-gram (Mikolov et al., 2013a,b) algorithm to create "word" embeddings, which it averages together to create molecule representations. We use a two-layer MLP followed by a linear projection and layer normalization to create a trainable representation from the Mol2vec embedding, followed by layer normalization.</p>
<p>While the Morgan fingerprints (substructure tokens) incorporate some implicit graph information, we explicitly introduce the molecule graph structure using a GCN that takes a molecular graph as input with Mol2vec token embeddings as features. For example, rings are very important substructures in molecules. If the description mentions "aromatic ring" or "phenyl group," we want to be able to match this substructure in the molecule. We could potentially do so by increasing the maximum radius of the Morgan fingerprinting algorithm, but then there might not be enough examples of the resulting large-radius tokens to create a good representation given our corpus size. Particularly for large molecules, to capture the global structural information, we might need a very large radius which will create a lot of rare tokens (that get replaced by the UNK token). Instead, we explicitly incorporate the graph structure by using a GCN.</p>
<p>The Mol2vec token features are input to a threelayer GCN to create node representations for each atom in the molecule. These representations are combined using global mean pooling, and passed through two more hidden layers to produce a molecule representation. Since Mol2vec produces multiple tokens based on Morgan fingerprints of different radii, we select the corresponding token with the largest radius.</p>
<h3>4.2 Cross-Modal Attention Model</h3>
<p>To improve the explainability of our approach, we introduce a model with cross-modal attention by modifying the base model to use a transformer decoder (Vaswani et al., 2017). This decoder uses the SciBERT output as a source sequence and the node representations from the Mol2vec GCN model as a target sequence, and the attentions can be used to learn multimodal association rules. The architecture is shown in Figure 3.</p>
<h3>4.3 Loss</h3>
<p>To optimize the models, we base our loss on the symmetric contrastive loss presented by Radford et al. (2021). The loss takes the output embed-</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Model architecture for the cross-modal attention extension and association rules.
dings of both submodels, multiplies by the exponent of a learned temperature parameter, $\tau$, and then takes the outer product of the mini-batch. The identity matrix $I$ is used as labels. Categorical cross-entropy ( $C C E$ ) is then applied along both axes, and the two losses are summed. This improves efficiency by allowing all the other samples in a mini-batch to serve as negatives. It corresponds to cosine similarity because the normalized dot product is minimized or maximized, for positives and negatives respectively. For batch embedding $m$ and $t$ of length $n$,
$L(m, t)=C C E\left(e^{\tau} m t^{T}, I_{n}\right)+C C E\left(e^{\tau} t m^{T}, I_{n}\right)$
We find this loss to be ineffective for training the cross-modal attention model because it encourages the model to ignore the textual information-i.e. information can leak from one encoder to the other. To remedy this problem, we modify this loss function to incorporate a matching task by introducing negative samples. We randomly sample new descriptions and replace their respective ones in the diagonal of the identity matrix with zeros, creating a binary classification task-does the description match the molecule? Since the rows with all zeros are no longer probability distributions, we instead use binary cross-entropy loss. This modified loss provides more signal than a pure matching task since it also receives signal from the other negatives, and it enforces the constraint that the model consider both the molecule and text description.</p>
<h3>4.4 Cross-Modal Reranking</h3>
<p>We want to better understand how the base networks work, so we introduce a modified model with cross-modal attention, which we also use to rerank the output of the base models. Given a training set of molecule-text pairs, $P$, we first train the
cross-modal matching model. We collect the attention weights of the final layer for each of these pairs. Next, the attention weights for molecule token, $m$, and text token, $t$, are aggregated to create association rules. We define the support for a rule $r$ from $t$ to $m$ as the sum of all attentions,</p>
<p>$$
\operatorname{supp}(r)=\sum_{p \in P} \sum_{\substack{t^{\prime} \in p_{t} \ m^{\prime} \in p_{m}}} \mathbb{1}<em t_prime="t^{\prime">{\substack{t=t^{\prime} \ m=m^{\prime}}} a</em>
$$}, m^{\prime}</p>
<p>where $a_{i, j}$ is the attention weight between tokens $i$ and $j$ and $p_{t}$ and $p_{m}$ are the multisets of text and molecule tokens in $p$, respectively.</p>
<p>This produces association rules from every text token $t$ to every molecule token $m$. We calculate the confidence for each of these rules by taking the support of the rule and dividing by the support of all the rules using $t$,</p>
<p>$$
\operatorname{conf}(t \Longrightarrow m)=\frac{\operatorname{supp}(t, m)}{\sum_{t^{\prime} \in T} \operatorname{supp}\left(t^{\prime}, m\right)}
$$</p>
<p>where $T$ is the set of all text tokens.
Following this, given a molecule and text pair, we consider all association rules that can produce it, and we take the average of the top $k$ confidence values. For association-rule based reranking, Bharadwaj et al. (2014) takes the average of all confidence values. However, they have a comparatively smaller number of confidence rules. On the other hand, AnyBURL (Meilicke et al., 2019, 2020) finds maximum aggregation to be most effective. It also shows rule-based approaches can be very efficient (Ott et al., 2021). For our approach, we want to consider multiple one-to-one rules because we only use rules from one text token to one molecule token since the computational costs scale significantly due to the combinatorial number of many-to-many rules. By taking an average of only the top confidence values, we incorporate multiple one-to-one rules but ignore unimportant rules. This combines the two approaches to reranking while keeping in mind efficiency. We calculate a score by interpolating between the cosine similarities with association rule-based scores $(A R)$ linearly,</p>
<p>$$
S(a, b)=\alpha \cos (a, b)+(1-\alpha) A R(a, b)
$$</p>
<p>where $\alpha \in[0,1]$ is selected on the validation set.</p>
<h3>4.5 Ensemble Approach</h3>
<p>Upon investigation of the baseline models, we found that the correct molecule was very frequently found in the top molecules. However, many of the molecules ranked above the correct molecule did not occur in the top results of the same model trained with different parameter initialization. We found that by taking an average of these rankings, the correct molecule's average rank would stay roughly the same, but the average rank of false positives increases. When these average ranks are used to reorder the results, the order of the incorrect and correct molecule switches. We find this method to be surprisingly effective, and we connect this to committee of neural networks (Drucker et al., 1994) in ensemble learning (Polikar, 2012). Additionally, we draw comparisons to Mixture of Experts-based models (Masoudnia and Ebrahimpour, 2014) such as Fan et al. (2006) and the Switch Transformer which contains 1.6 trillion parameters (Fedus et al., 2021). We compute the score, $S$, as a weighted average,</p>
<p>$$
S(m)=\sum_{i} w_{i} R_{i}(m) \quad \text { s.t. } \sum_{i} w_{i}=1
$$</p>
<p>for some molecule $m$ where $R_{i}$ is the rank assigned to that molecule by model $i$ and $w_{i}$ is the model weight. A lower score is more desirable.</p>
<h2>5 Experiments</h2>
<h3>5.1 Data and Evaluation</h3>
<p>For our task, we create a dataset using PubChem (Kim et al., 2016, 2019) and Chemical Entities of Biological Interest (ChEBI) (Hastings et al., 2016). We collect ChEBI annotations of compounds scraped from PubChem, which consists of 102,980 compound-description pairs. Using this data, we create a dataset consisting of 33,010 pairs, which we call ChEBI-20, that contains descriptions of more than 20 words. We find that longer descriptions tend to be less noisy and more informative. We remove compounds which cannot be processed by RDKit (Landrum, 2021).</p>
<p>We separate these datasets into $80 \% / 10 \% / 10 \%$ train-validation-test splits. The alignment models are trained on the training data, and the results are evaluated by searching all molecules in the dataset. The molecules in the training set are processed by Mol2vec using default parameters: a radius of 1 , a
threshold for unknown tokens of 3, an embedding dimension of 300, and a window size of 10.</p>
<h3>5.2 Results</h3>
<p>To train the models, we use Adam optimizer (Kingma and Ba, 2015) and two different learning rates. The SciBERT model uses a finetuning learning rate of 3e-5, as used by Devlin et al. (2019). The rest of the model uses 1e-4 as used by Vaswani et al. (2017). We use a linear annealing rate for the learning rate with 1,000 steps of warmup. We train for 40 epochs with a batch size of 32 . We also use a temperature value of 0.07 as suggested by Radford et al. (2021). We use the first 256 text tokens for the text encoder.</p>
<h3>5.2.1 Baseline Models</h3>
<p>The MLP and GCN encoder models both show similar performance. Three results for both are shown in Table 2. We believe the performance similarity between MLP and GCN is because the description is a bottleneck. However, they appear to be effective at different tasks. In the test set, the mean rank is significantly lower for the MLP models than the GCN models; however, the MRR values are fairly similar. This indicates that these two architectures have different strengths. Further, the difference in mean rank is much smaller in the validation set; the validation mean rank is 30.60 and 28.89 for the MLP and GCN ensembles respectively. This indicates that the GCN architecture is more effective for retrieving the most difficult examples in the validation set (since there are not outlier ranks to increase the mean), but the MLP is more effective at difficult examples in the test set. We further examine this in Section 5.4.</p>
<h3>5.2.2 Ensemble</h3>
<p>We find that the ensemble method shows significant performance improvements. The ensemble of the three GCN models increases Test Hits@1 by roughly $8 \%$ from the baseline models. It is notable that the hyperparameters for these models are exactly the same, and the models are learning different ways of ranking which are complementary. To combine the different models, we find the heuristic of using uniform weights to be very effective.</p>
<p>A further advantage of the ensemble approach is that it can incorporate different encoder architectures and retrieval schemes, which may have different understandings of how to solve the problem. We find that combining both architectures is</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Training</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Test</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Model</td>
<td style="text-align: center;">Mean Rank</td>
<td style="text-align: center;">MRR</td>
<td style="text-align: center;">Hits@1</td>
<td style="text-align: center;">Hits@10</td>
<td style="text-align: center;">Mean Rank</td>
<td style="text-align: center;">MRR</td>
<td style="text-align: center;">Hits@1</td>
<td style="text-align: center;">Hits@10</td>
</tr>
<tr>
<td style="text-align: center;">MLP1</td>
<td style="text-align: center;">9.55</td>
<td style="text-align: center;">0.428</td>
<td style="text-align: center;">$26.5 \%$</td>
<td style="text-align: center;">$77.5 \%$</td>
<td style="text-align: center;">30.38</td>
<td style="text-align: center;">0.372</td>
<td style="text-align: center;">$22.4 \%$</td>
<td style="text-align: center;">$68.6 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP2</td>
<td style="text-align: center;">9.82</td>
<td style="text-align: center;">0.425</td>
<td style="text-align: center;">$26.4 \%$</td>
<td style="text-align: center;">$77.1 \%$</td>
<td style="text-align: center;">30.72</td>
<td style="text-align: center;">0.369</td>
<td style="text-align: center;">$22.3 \%$</td>
<td style="text-align: center;">$68.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP3</td>
<td style="text-align: center;">9.53</td>
<td style="text-align: center;">0.431</td>
<td style="text-align: center;">$26.9 \%$</td>
<td style="text-align: center;">$77.8 \%$</td>
<td style="text-align: center;">36.30</td>
<td style="text-align: center;">0.372</td>
<td style="text-align: center;">$22.3 \%$</td>
<td style="text-align: center;">$67.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN1</td>
<td style="text-align: center;">10.22</td>
<td style="text-align: center;">0.432</td>
<td style="text-align: center;">$27.2 \%$</td>
<td style="text-align: center;">$76.5 \%$</td>
<td style="text-align: center;">42.28</td>
<td style="text-align: center;">0.366</td>
<td style="text-align: center;">$21.7 \%$</td>
<td style="text-align: center;">$68.2 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN2</td>
<td style="text-align: center;">9.67</td>
<td style="text-align: center;">0.423</td>
<td style="text-align: center;">$26.7 \%$</td>
<td style="text-align: center;">$77.4 \%$</td>
<td style="text-align: center;">41.90</td>
<td style="text-align: center;">0.371</td>
<td style="text-align: center;">$22.3 \%$</td>
<td style="text-align: center;">$68.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN3</td>
<td style="text-align: center;">10.12</td>
<td style="text-align: center;">0.420</td>
<td style="text-align: center;">$25.8 \%$</td>
<td style="text-align: center;">$76.7 \%$</td>
<td style="text-align: center;">39.11</td>
<td style="text-align: center;">0.366</td>
<td style="text-align: center;">$22.3 \%$</td>
<td style="text-align: center;">$67.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP-Ensemble</td>
<td style="text-align: center;">5.81</td>
<td style="text-align: center;">0.520</td>
<td style="text-align: center;">$35.1 \%$</td>
<td style="text-align: center;">$86.4 \%$</td>
<td style="text-align: center;">20.78</td>
<td style="text-align: center;">0.452</td>
<td style="text-align: center;">$29.4 \%$</td>
<td style="text-align: center;">$77.6 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN-Ensemble</td>
<td style="text-align: center;">6.09</td>
<td style="text-align: center;">0.516</td>
<td style="text-align: center;">$35.0 \%$</td>
<td style="text-align: center;">$86.1 \%$</td>
<td style="text-align: center;">28.77</td>
<td style="text-align: center;">0.447</td>
<td style="text-align: center;">$29.4 \%$</td>
<td style="text-align: center;">$77.1 \%$</td>
</tr>
<tr>
<td style="text-align: center;">All-Ensemble</td>
<td style="text-align: center;">4.67</td>
<td style="text-align: center;">0.568</td>
<td style="text-align: center;">40.2\%</td>
<td style="text-align: center;">89.8\%</td>
<td style="text-align: center;">20.21</td>
<td style="text-align: center;">0.499</td>
<td style="text-align: center;">34.4\%</td>
<td style="text-align: center;">81.1\%</td>
</tr>
<tr>
<td style="text-align: center;">MLP1+Attn</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">30.37</td>
<td style="text-align: center;">0.375</td>
<td style="text-align: center;">$22.8 \%$</td>
<td style="text-align: center;">$68.7 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP1+FPGrowth</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">30.37</td>
<td style="text-align: center;">0.374</td>
<td style="text-align: center;">$22.6 \%$</td>
<td style="text-align: center;">$68.6 \%$</td>
</tr>
</tbody>
</table>
<p>Table 2: Results. FPGrowth is the frequent pattern growth algorithm (Han and Pei, 2000). Models 1, 2, and 3 only differ in initial parameter initialization.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Validation MRR values for different combinations of architectures. The axes indicate the number of each architecture used. Ensembles with both architectures are more effective.
more effective than either alone; this is shown in Figure 4. Ensembles that only incorporate one architecture are consistently outperformed by models that incorporate both. For example, using 3 MLP models has an MRR of 0.442 but using 2 MLP and 1 GCN model has an MRR of 0.449 .</p>
<h3>5.3 Cross-Modal Attention and Reranking</h3>
<p>To better understand the behavior of the model, we apply cross-modal attention using a transformer decoder with 3 layers, and we rerank the top 10 of MLP1 using the 10 most confident association rules. We find cross-modal reranking to slightly improve our baseline model and to outperform traditional association rule mining, which can be accomplished by the FPGrowth algorithm (Han and Pei, 2000). Hits@1 for the baseline MLP model is</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Token</th>
<th style="text-align: center;">Substructure</th>
<th style="text-align: center;">Supp</th>
<th style="text-align: center;">Conf</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Titanium</td>
<td style="text-align: center;">$\mathrm{Ti}=\mathrm{O}$</td>
<td style="text-align: center;">1.29</td>
<td style="text-align: center;">0.65</td>
</tr>
<tr>
<td style="text-align: center;">Aluminium</td>
<td style="text-align: center;">$\mathrm{Al}^{3+}$</td>
<td style="text-align: center;">4.31</td>
<td style="text-align: center;">0.23</td>
</tr>
<tr>
<td style="text-align: center;">Manganese</td>
<td style="text-align: center;">$\mathrm{Mn}^{2+}$</td>
<td style="text-align: center;">10.08</td>
<td style="text-align: center;">0.30</td>
</tr>
<tr>
<td style="text-align: center;">Toluene</td>
<td style="text-align: center;">$\mathrm{C}-\mathrm{C}=\mathrm{C}$</td>
<td style="text-align: center;">12.93</td>
<td style="text-align: center;">0.231</td>
</tr>
<tr>
<td style="text-align: center;">Toluene</td>
<td style="text-align: center;">$\mathrm{C}<em 8="8">{7} \mathrm{H}</em>$</td>
<td style="text-align: center;">23.79</td>
<td style="text-align: center;">0.425</td>
</tr>
<tr>
<td style="text-align: center;">##chloro</td>
<td style="text-align: center;">$\mathrm{Cl}-\mathrm{C}$</td>
<td style="text-align: center;">18.81</td>
<td style="text-align: center;">0.207</td>
</tr>
<tr>
<td style="text-align: center;">pollutant</td>
<td style="text-align: center;">$\mathrm{F}-\mathrm{C}$</td>
<td style="text-align: center;">3.097</td>
<td style="text-align: center;">0.208</td>
</tr>
<tr>
<td style="text-align: center;">chromatography</td>
<td style="text-align: center;">$\mathrm{C}-\mathrm{Si}$</td>
<td style="text-align: center;">2.976</td>
<td style="text-align: center;">0.271</td>
</tr>
<tr>
<td style="text-align: center;">acid</td>
<td style="text-align: center;">$\mathrm{C}-\mathrm{O}-\mathrm{H}$</td>
<td style="text-align: center;">2398.7</td>
<td style="text-align: center;">0.078</td>
</tr>
<tr>
<td style="text-align: center;">crown</td>
<td style="text-align: center;">$\mathrm{C}-\mathrm{C}-\mathrm{O}$</td>
<td style="text-align: center;">4.18</td>
<td style="text-align: center;">0.325</td>
</tr>
</tbody>
</table>
<p>Table 3: Examples of interesting learned association rules from token to substructure. $\mathrm{C}<em 8="8">{7} \mathrm{H}</em>$ is the chemical formula of toluene.
increased by about $0.4 \%$, but normal association rules only improve it by $0.2 \%$.</p>
<p>Mining these rules using attention also allows us to understand the connections the model is making. Examples of these rules are shown in Table 3. We primarily examine one-to-one rules; however, these one-to-one rules will often "split" the confidence among themselves. For example, toluene is a ring containing different substructures, so there will be multiple one-to-one rules required to capture the substructure. The rule from toluene to the three common substructure tokens in toluene has an increased confidence and support. Since we average the confidence values of all applicable rules, this is accounted for in reranking.</p>
<p>One interesting phenomenon we find is that the model is very interested in O-H structures (hydroxyl groups). It is also interested in positively charged metal ions in salts. The token "acid" has many different rules; however, the most confident</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Inositol: Myo-inositol is an inositol having myoconfiguration. It has a role as a member of compatible osmolytes, a nutrient, an EC 3.1.4.11 (phosphoinositide phospholipase C) inhibitor, a human metabolite, a Daphnia magna metabolite, $[\ldots]$
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Cannabidiolate is a dihydroxybenzoate that is the conjugate base of cannabidiolic acid, obtained by deprotonation of the carboxy group. It derives from an olivetolate. It is a conjugate base of a cannabidiolic acid.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5: Example queries that are predicted correctly by All-Ensemble.
is a hydroxyl ( -OH$)$ group, which matches basic chemical properties of acids. Rules involving rare tokens can result in high confidence values. For example, the rule "crown" implies $\mathrm{C}-\mathrm{C}-\mathrm{O}$ has a confidence of 0.325 . This is because the dataset contains two "crown ether" molecules which have multiple occurrences of $\mathrm{C}-\mathrm{C}-\mathrm{O}$.</p>
<h3>5.4 Qualitative Analysis</h3>
<p>Our technique is capable of retrieving large, complicated molecules as well as small ones. For example, it successfully retrieves both Argyssfrywff $\left(\mathrm{C}<em 99="99">{79} \mathrm{H}</em>} \mathrm{~N<em 17="17">{19} \mathrm{O}</em>}\right)$ and Inositol $\left(\mathrm{C<em 12="12">{6} \mathrm{H}</em>\right)$, shown in Figure 5. Argyssfrywff shows that the model is capable of composing molecules from constituent parts mentioned in the description.} \mathrm{O}_{6</p>
<p>The MLP and GCN models capture different aspects of the molecules leading to different rankings. For example, MLP-ensemble ranks an alphamycolic acid $\left(\mathrm{C}<em 26="26">{15} \mathrm{H}</em>\right)$ at 43 ; GCN-ensemble ranks it 3. The compound contains cyclopropyl} \mathrm{O}_{3</p>
<p>Fura red is a 1-benzofuran substituted at position 2 by a (5-oxo-2-thioxoimidazolidin-4ylidene)methyl group, and at C-5 and C-6 by heavily substituted oxygen and nitrogen functionalities [...]
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Clondronate(2-) is the dianion resulting from the removal of two protons from clondronic acid. It is a conjugate base of a clodronic acid.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>An alpha-mycolic acid is a class of mycolic acids characterized by the presence of two cis cyclopropyl groups in the meromycolic chain. It is an organic molecular entity and a mycolic acid. [...]</p>
<p>Figure 6: Example queries that are ranked incorrectly by All-Ensemble.
groups (the triangles), shown in Figure 6, which the GCN captures. On the other hand, Clondronate(2-) $\left(\mathrm{CH}<em 2="2">{2} \mathrm{Cl}</em>} \mathrm{O<em 2="2">{6} \mathrm{P}</em>}^{-2}\right)$ is ranked 4,915 by the GCN but 61 by the MLP, showing large differences exist between the architectures. The models are also mutually beneficial; 2-Methylideneglutaric acid $\left(\mathrm{C<em 8="8">{6} \mathrm{H}</em>} \mathrm{O<em 27="27">{4}\right)$ is ranked 2nd by MLP and 3rd by GCN, but it is ranked 1st by All-Ensemble. Individual models trained identically (but with different initial parameters) also show this phenomenon. GCN 1, 2, and 3 rank Pierreione $\mathrm{C}\left(\mathrm{C}</em>} \mathrm{H<em 6="6">{28} \mathrm{O}</em>\right)$ 2nd. GCN1 ranks Aspernidine A 1st, but it is ranked 49 and 64 by GCN 2 and 3, respectively. The average rank of Aspernidine A becomes 38, so GCN-Ensemble ranks Pierreione C 1st.</p>
<p>The model is able to ignore irrelevant description information. For example, MLP achieves rank 1 for Rostratin $\mathrm{D}\left(\mathrm{C}<em 20="20">{18} \mathrm{H}</em>} \mathrm{~N<em 6="6">{2} \mathrm{O}</em>\right)$, whose description includes the unique and likely unuseful section "isolated from the whole broth of the marinederived fungus Exserohilum rostratum." Instead, the model successfully identifies it from the following attributes: "bridged compound, a cyclic ketone, a lactam, an organic disulfide, an organic heterohexacyclic compound, a secondary alcohol, a dithiol and a diol."} \mathrm{~S}_{4</p>
<p>There are some very challenging queries where multiple molecules are very similar. For example, Pro-Arg and Arg-Pro share the same chemical formula $\mathrm{C}<em 21="21">{11} \mathrm{H}</em>} \mathrm{~N<em 3="3">{5} \mathrm{O}</em>}$. Fura red $\left(\mathrm{C<em 44="44">{41} \mathrm{H}</em>} \mathrm{~N<em 20="20">{4} \mathrm{O}</em>\right)$ is the most challenging query for the model; it is ranked at 8,320 by All-Ensemble. Its entire description is based off of 1-benzofuran, but the substitutions are each larger than the original molecule and poorly defined.} \mathrm{~S</p>
<h3>5.5 Remaining Challenges</h3>
<p>One further challenge is integrating external domain knowledge. Many current errors can be eliminated by applying this information, such as assuming "oxide" means the molecule should contain an oxygen. Although our association rule approach learns some of these, external knowledge can provide stronger rules. We observe that descriptions appear to be the limiting factor in this model, which is consistent with the similar performance of the GCN and MLP encoders. Comprehensive techniques for extracting information from external knowledge could lead to significant improvements, which we leave for future work.</p>
<h2>6 Conclusions and Future Work</h2>
<p>In this work, we present Text2Mol: a novel and challenging cross-modal information retrieval task to retrieve molecules using natural language descriptions. To tackle this problem, we apply contrastive representation learning to a BERTbased text encoder and both MLP and GCN-based molecule encoders. We show that these models are complementary and that an ensemble approach combines them very effectively. We also show that the ensemble approach is effective for combining identically trained neural networks (with different parameter initialization), and we consider attentionbased association rules. Improved encoder architectures will likely yield improvements, and further investigation of how model architectural choices affect these rules and their interactions for reranking may be interesting as well. In the future, we plan to further improve results by integrating external knowledge as constraints. It should also be noted that this task is possible in the reverse direction, from molecules to descriptions. This has many possible applications, such as finding relevant descriptions for newly discovered molecules.</p>
<h2>Acknowledgements</h2>
<p>This research is based upon work supported by the Molecule Maker Lab Institute: An AI Research Institutes program supported by NSF under Award No. 2019897 and NSF No. 2034562. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.</p>
<h2>References</h2>
<p>Derek T. Ahneman, Jesús G. Estrada, Shishi Lin, Spencer D. Dreher, and Abigail G. Doyle. 2018. Predicting reaction performance in c-n cross-coupling using machine learning. Science, 360(6385):186190.</p>
<p>Jimmy Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450.</p>
<p>John M. Barnard. 1993. Substructure searching methods: Old and new. Journal of chemical information and computer sciences, 33(4):532-538.</p>
<p>Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 36153620, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Samarth Bharadwaj, Mayank Vatsa, and Richa Singh. 2014. Aiding face recognition with social context association rule based re-ranking. In IEEE International Joint Conference on Biometrics, pages 1-8. IEEE.</p>
<p>Paheli Bhattacharya, Pawan Goyal, and Sudeshna Sarkar. 2016. Using word embeddings for query translation for hindi to english cross language information retrieval. Computación y Sistemas, 20(3):435-447.</p>
<p>Adrià Cereto-Massagué, María J. Ojeda, Cristina Valls, Miquel Mulero, Santiago Garcia-Vallvé, and Gerard Pujadas. 2015. Molecular fingerprint similarity search in virtual screening. Methods, 71:58-63.</p>
<p>Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, and Jingjing Liu. 2019. Uniter: Learning universal image-text representations.</p>
<p>Seyone Chithrananda, Gabe Grand, and Bharath Ramsundar. 2020. Chemberta: Large-scale selfsupervised pretraining for molecular property prediction. arXiv preprint arXiv:2010.09885.</p>
<p>Connor W. Coley, Regina Barzilay, Tommi S. Jaakkola, William H. Green, and Klavs F. Jensen. 2017. Prediction of organic reaction outcomes using machine learning. ACS central science, 3(5):434-443.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Harris Drucker, Corinna Cortes, Lawrence D. Jackel, Yann LeCun, and Vladimir Vapnik. 1994. Boosting and other ensemble methods. Neural Computation, 6(6):1289-1301.</p>
<p>Benedek Fabian, Thomas Edlich, Héléna Gaspar, Marwin Segler, Joshua Meyers, Marco Fiscato, and Mohamed Ahmed. 2020. Molecular representation learning with language models and domain-relevant auxiliary tasks. arXiv preprint arXiv:2011.13230.</p>
<p>Weiguo Fan, Michael Gordon, and Praveen Pathak. 2006. On linear mixture of expert approaches to information retrieval. Decision Support Systems, 42(2):975-987.</p>
<p>William Fedus, Barret Zoph, and Noam Shazeer. 2021. Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. arXiv preprint arXiv:2101.03961.</p>
<p>David Fooshee, Aaron Mood, Eugene Gutman, Mohammadamin Tavakoli, Gregor Urban, Frances Liu, Nancy Huynh, David Van Vranken, and Pierre Baldi. 2018. Deep learning for chemical reaction prediction. Molecular Systems Design \&amp; Engineering, 3(3):442-452.</p>
<p>Marta Glavatskikh, Jules Leguy, Gilles Hunault, Thomas Cauchy, and Benoit Da Mota. 2019. Dataset's chemical diversity limits the generalizability of machine learning predictions. Journal of Cheminformatics, 11(1):1-15.</p>
<p>Kunal Goyal, Utkarsh Gupta, Abir De, and Soumen Chakrabarti. 2020. Deep neural matching models for graph retrieval. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020, pages 17011704. ACM.</p>
<p>Thomas R. Hagadone. 1992. Molecular substructure similarity searching: efficient retrieval in twodimensional structure databases. Journal of chemical information and computer sciences, 32(5):515521 .</p>
<p>Jiawei Han and Jian Pei. 2000. Mining frequent patterns by pattern-growth: methodology and implications. ACM SIGKDD explorations newsletter, 2(2):14-20.</p>
<p>Janna Hastings, Gareth Owen, Adriano Dekker, Marcus Ennis, Namrata Kale, Venkatesh Muthukrishnan, Steve Turner, Neil Swainston, Pedro Mendes, and Christoph Steinbeck. 2016. Chebi in 2016: Improved services and an expanding collection of metabolites. Nucleic acids research, 44(D1):D1214-D1219.</p>
<p>Rezarta Islamaj Doğan, Sun Kim, Andrew ChatrAryamontri, Chih-Hsuan Wei, Donald C. Comeau, Rui Antunes, Sérgio Matos, Qingyu Chen, Aparna Elangovan, Nagesh C. Panyam, et al. 2019. Overview of the biocreative vi precision medicine track: mining protein interactions and mutations for precision medicine. Database, 2019.</p>
<p>Sabrina Jaeger, Simone Fulle, and Samo Turk. 2018. Mol2vec: unsupervised machine learning approach with chemical intuition. Journal of chemical information and modeling, 58(1):27-35.</p>
<p>Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2017. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734.</p>
<p>Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A. Shoemaker, Paul A. Thiessen, Bo Yu, et al. 2019. Pubchem 2019 update: improved access to chemical data. Nucleic acids research, 47(D1):D1102D1109.</p>
<p>Sunghwan Kim, Paul A. Thiessen, Evan E. Bolton, Jie Chen, Gang Fu, Asta Gindulyte, Lianyi Han, Jane He, Siqian He, Benjamin A. Shoemaker, et al. 2016. Pubchem substance and compound databases. Nucleic acids research, 44(D1):D1202-D1213.</p>
<p>Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.</p>
<p>Thomas N. Kipf and Max Welling. 2017. Semisupervised classification with graph convolutional networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.</p>
<p>Martin Krallinger, Obdulia Rabal, Analia Lourenco, Julen Oyarzabal, and Alfonso Valencia. 2017. Information retrieval and text mining technologies for chemistry. Chemical reviews, 117(12):7673-7761.</p>
<p>Miroslav Kratochvíl, Jiří Vondrášek, and Jakub Galgonek. 2018. Sachem: a chemical cartridge for highperformance substructure search. Journal of cheminformatics, 10(1):1-11.</p>
<p>Miroslav Kratochvíl. 2019. Accelerating structure search in small-molecule databases. Master's thesis.</p>
<p>Tuan Lai, Heng Ji, ChengXiang Zhai, and Quan H. Tran. 2021. Joint biomedical entity and relation extraction with knowledge-enhanced collective inference. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6248-6260, Online. Association for Computational Linguistics.</p>
<p>Greg Landrum. 2021. Rdkit: Open-source cheminformatics software.</p>
<p>Diya Li, Lifu Huang, Heng Ji, and Jiawei Han. 2019. Biomedical event extraction based on knowledgedriven tree-LSTM. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1421-1430, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Diya Li and Heng Ji. 2019. Syntax-aware multi-task graph convolutional networks for biomedical relation extraction. In Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 28-33, Hong Kong. Association for Computational Linguistics.</p>
<p>Hongzhi Li, Joseph G. Ellis, Heng Ji, and Shih-Fu Chang. 2016. Event specific multimodal pattern mining for knowledge base construction. In Proceedings of the 2016 ACM Conference on Multimedia Conference, MM 2016, Amsterdam, The Netherlands, October 15-19, 2016, pages 821-830.</p>
<p>Manling Li, Alireza Zareian, Qi Zeng, Spencer Whitehead, Di Lu, Heng Ji, and Shih-Fu Chang. 2020. Cross-media structured common space for multimedia event extraction. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2557-2568, Online. Association for Computational Linguistics.</p>
<p>Daniel M. Lowe, Peter T. Corbett, Peter Murray-Rust, and Robert C. Glen. 2011. Chemical name to structure: Opsin, an open source solution. Journal of Chemical Information and Modeling, 51(3):739753. PMID: 21384929.</p>
<p>Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages $13-23$.</p>
<p>Emily K. Mallory, Ambika Acharya, Stefano E. Rensi, Peter J. Turnbaugh, Roselie A. Bright, and Russ B.</p>
<p>Altman. Chemical reaction vector embeddings: towards predicting drug metabolism in the human gut microbiome. In Biocomputing 2018, pages 56-67.</p>
<p>Saeed Masoudnia and Reza Ebrahimpour. 2014. Mixture of experts: a literature survey. Artificial Intelligence Review, 42(2):275-293.</p>
<p>Christian Meilicke, Melisachew W. Chekol, Manuel Fink, and Heiner Stuckenschmidt. 2020. Reinforced anytime bottom up rule learning for knowledge graph completion. arXiv preprint arXiv:2004.04412.</p>
<p>Christian Meilicke, Melisachew W. Chekol, Daniel Ruffinelli, and Heiner Stuckenschmidt. 2019. Anytime bottom-up rule learning for knowledge graph completion. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, pages 3137-3143. ijcai.org.</p>
<p>Tomás Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient estimation of word representations in vector space. In 1st International Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona, USA, May 2-4, 2013, Workshop Track Proceedings.</p>
<p>Tomás Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013b. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States, pages 31113119.</p>
<p>Aditya Mogadala, Marimuthu Kalimuthu, and Dietrich Klakow. 2020. Trends in integration of vision and language research: A survey of tasks, datasets, and methods. arXiv preprint arXiv:1907.09358.</p>
<p>Simon Ott, Christian Meilicke, and Matthias Samwald. 2021. SAFRAN: An interpretable, rule-based link prediction method outperforming embedding models. In 3rd Conference on Automated Knowledge Base Construction.</p>
<p>Robi Polikar. 2012. Ensemble learning. In Ensemble machine learning, pages 1-34. Springer.</p>
<p>Jingwei Qu, Penghui Sun, Xin Li, Bei Wang, Xiaoqing Lu, Zhi Tang, and Chengcui Zhang. 2019. A retrieval system of medicine molecules based on graph similarity. IEEE MultiMedia, 26(4):17-27.</p>
<p>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning transferable visual models from natural language supervision. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of</p>
<p>Proceedings of Machine Learning Research, pages 8748-8763. PMLR.</p>
<p>Stefano Rensi and Russ B. Altman. 2017. Flexible analog search with kernel pca embedded molecule vectors. Computational and structural biotechnology journal, 15:320-327.</p>
<p>Tim Rocktäschel, Torsten Huber, Michael Weidlich, and Ulf Leser. 2013. WBI-NER: The impact of domain-specific features on the performance of identifying and classifying mentions of drugs. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 356-363, Atlanta, Georgia, USA. Association for Computational Linguistics.</p>
<p>David Rogers and Mathew Hahn. 2010. Extendedconnectivity fingerprints. Journal of chemical information and modeling, 50(5):742-754.</p>
<p>Frederik Sandfort, Felix Strieth-Kalthoff, Marius Kühnemund, Christian Beecks, and Frank Glorius. 2020. A structure-based platform for predicting chemical reactivity. Chem, 6(6):1379-1390.</p>
<p>Kihyuk Sohn. 2016. Improved deep metric learning with multi-class n-pair loss objective. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 1849-1857.</p>
<p>Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai. 2020. VL-BERT: pretraining of generic visual-linguistic representations. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 49, 2017, Long Beach, CA, USA, pages 5998-6008.</p>
<p>Ivan Vulic and Marie-Francine Moens. 2015. Monolingual and cross-lingual information retrieval models based on (bilingual) word embeddings. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, Santiago, Chile, August 9-13, 2015, pages 363-372. ACM.</p>
<p>David Weininger. 1988. Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules. Journal of chemical information and computer sciences, 28(1):31-36.</p>
<p>David Weininger, Arthur Weininger, and Joseph L. Weininger. 1989. Smiles. 2. algorithm for generation of unique smiles notation. Journal of chemical information and computer sciences, 29(2):97-101.</p>
<p>Zhenqin Wu, Bharath Ramsundar, Evan N. Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S. Pappu, Karl Leswing, and Vijay Pande. 2018. Moleculenet: a benchmark for molecular machine learning. Chemical science, 9(2):513-530.</p>
<p>Xifeng Yan, Philip S. Yu, and Jiawei Han. 2005. Substructure similarity search in graph databases. In Proceedings of the 2005 ACM SIGMOD international conference on Management of data, pages 766-777.</p>
<p>Liang Zhang and Xiaobing Zhao. 2020. An overview of cross-language information retrieval. In International Conference on Artificial Intelligence and Security, pages 26-37. Springer.</p>
<p>Zixuan Zhang, Nikolaus Parulian, Heng Ji, Ahmed Elsayed, Skatje Myers, and Martha Palmer. 2021. Fine-grained information extraction from biomedical literature based on knowledge-enriched Abstract Meaning Representation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6261-6270, Online. Association for Computational Linguistics.</p>
<p>Jin Guang Zheng, Daniel Howsmon, Boliang Zhang, Juergen Hahn, Deborah McGuinness, James Hendler, and Heng Ji. 2014. Entity linking for biomedical literature. In BMC Medical Informatics and Decision Making.</p>
<p>Yingyao Zhou, Bin Zhou, Shumei Jiang, and Frederick J. King. 2010. Chemical- text hybrid search engines. Journal of chemical information and modeling, 50(1):47-54.</p>
<h2>A Supporting Figures</h2>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 7: This figure shows the ensemble validation MRR from different weighted averages of the three GCN models. GCN3_weight $=1-$ GCN1_weight GCN2_weight. The MRR is clearly lower in the corners, where only rankings from one model are used because the others have zero weight. This figure illustrates that using uniform weights is an effective heuristic.</p>
<h2>B Reproducibility</h2>
<p>The MLP and GCN models were each run three times. The GCN and MLP use 600 hidden units. The mol2vec input and the model outputs are 300-dimensional. GCN uses the substructure representations with the largest radius. MLP contains 110,871,865 parameters. GCN contains 111,953,665 parameters. The cross-modal attention model contains 128,978,441 parameters and attends the first 512 molecule substructures. It achieves about $97 \%$ classification accuracy for the matching task from the negative samples. The number of one-to-one association rules with confidence greater than 0.1 and support greater than 2 is 1,835 . The MLP and GCN take approximately 7 hours on a NVIDIA V100 and the cross-modal attention model takes approximately 9 hours. We find that early stopping is not useful and that layer normalization increases training speed. The value of $\alpha$ for reranking was selected by grid search for high validation MRR. For the metrics, given a list of rankings $R$,</p>
<p>$$
\begin{gathered}
\text { MeanRank }=\frac{1}{n} \sum_{i=1}^{n} R_{i} \
MRR=\frac{1}{n} \sum_{i=1}^{n} \frac{1}{R_{i}}
\end{gathered}
$$</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Validation</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Model</td>
<td style="text-align: center;">Mean Rank</td>
<td style="text-align: center;">MRR</td>
<td style="text-align: center;">Hits@1</td>
<td style="text-align: center;">Hits@10</td>
</tr>
<tr>
<td style="text-align: center;">MLP1</td>
<td style="text-align: center;">43.66</td>
<td style="text-align: center;">0.374</td>
<td style="text-align: center;">$22.5 \%$</td>
<td style="text-align: center;">$68.8 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP2</td>
<td style="text-align: center;">47.42</td>
<td style="text-align: center;">0.360</td>
<td style="text-align: center;">$22.1 \%$</td>
<td style="text-align: center;">$68.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP3</td>
<td style="text-align: center;">41.15</td>
<td style="text-align: center;">0.376</td>
<td style="text-align: center;">$21.2 \%$</td>
<td style="text-align: center;">$68.2 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN1</td>
<td style="text-align: center;">41.78</td>
<td style="text-align: center;">0.367</td>
<td style="text-align: center;">$22.2 \%$</td>
<td style="text-align: center;">$68.4 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN2</td>
<td style="text-align: center;">41.23</td>
<td style="text-align: center;">0.367</td>
<td style="text-align: center;">$22.1 \%$</td>
<td style="text-align: center;">$68.9 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN3</td>
<td style="text-align: center;">42.19</td>
<td style="text-align: center;">0.360</td>
<td style="text-align: center;">$21.2 \%$</td>
<td style="text-align: center;">$68.2 \%$</td>
</tr>
<tr>
<td style="text-align: center;">MLP-Ensemble</td>
<td style="text-align: center;">30.60</td>
<td style="text-align: center;">0.442</td>
<td style="text-align: center;">$28.7 \%$</td>
<td style="text-align: center;">$76.5 \%$</td>
</tr>
<tr>
<td style="text-align: center;">GCN-Ensemble</td>
<td style="text-align: center;">28.89</td>
<td style="text-align: center;">0.435</td>
<td style="text-align: center;">$27.7 \%$</td>
<td style="text-align: center;">$76.6 \%$</td>
</tr>
<tr>
<td style="text-align: center;">All-Ensemble</td>
<td style="text-align: center;">24.95</td>
<td style="text-align: center;">0.479</td>
<td style="text-align: center;">31.7\%</td>
<td style="text-align: center;">80.2\%</td>
</tr>
</tbody>
</table>
<p>Table 4: Reproducibility results for the validation set.</p>
<p>$$
\text { Hits@m }=\frac{1}{n} \sum_{i=1}^{n} \mathbb{1}<em i="i">{R</em>
$$} \leq m</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ The programs and data are publicly available at github.com/cnedwards/text2mol for research purposes.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>