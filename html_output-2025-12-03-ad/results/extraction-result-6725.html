<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6725 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6725</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6725</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-119601712acbe6ee133a1744f0970190c4195519</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/119601712acbe6ee133a1744f0970190c4195519" target="_blank">Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Think-on-Graph (ToG) is presented, a novel framework that leverages knowledge graphs to enhance LLMs’ ability for deep and responsible reasoning and outperforms existing methods, effectively addressing the aforementioned limitations of LLMs without incurring additional training costs.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6725.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6725.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToG-GPT4-GrailQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Think-on-Graph (ToG) with GPT-4 on GrailQA</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ToG is a tight LLM-KG coupling that uses an LLM as an agent to perform beam-search graph traversal on a knowledge graph, producing top-N multi-hop reasoning paths which the LLM then evaluates to answer KBQA queries; evaluated here using GPT-4 on GrailQA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Think-on-Graph (ToG)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>beam-search graph traversal (tight LLM–KG coupling)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GrailQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering (KBQA)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>81.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Prior fine-tuned SOTA (75.4)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>ToG uses beam search to maintain top-N reasoning paths (diverse multi-hop paths) and then asks the LLM to evaluate whether the current paths suffice to answer; authors attribute large gains to deeper, explicit multi-hop evidence and tight LLM–KG interaction enabling knowledge-traceability and reduced hallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6725.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToG-R-GPT4-CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relation-based Think-on-Graph (ToG-R) with GPT-4 on CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ToG-R is a relation-chain variant of ToG that searches relation sequences starting from topic entities and uses random pruning for entities to reduce LLM calls; evaluated with GPT-4 on CWQ.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Relation-based Think-on-Graph (ToG-R)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>beam-search over relation chains (graph traversal, relation-first)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Complex WebQuestions (CWQ)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>69.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Prior fine-tuned SOTA (70.4)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-0.9</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>ToG-R emphasizes relation literal information and uses random beam prune for entities (reduces LLM prune cost but can increase relation diversity); authors report ToG-R is slightly less accurate than triple-based ToG on most datasets but faster/cheaper.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6725.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToG-ChatGPT-CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Think-on-Graph (ToG) with ChatGPT (GPT-3.5-turbo) on CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application of ToG using ChatGPT as the backbone LLM to run beam-search graph reasoning for CWQ KBQA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (GPT-3.5 family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Think-on-Graph (ToG)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>beam-search graph traversal (tight LLM–KG coupling)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Complex WebQuestions (CWQ)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>57.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Chain-of-Thought prompting (CoT) w/ ChatGPT (38.8)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>18.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Authors report ToG substantially outperforms standard prompting/CoT (same backbone) by exploring multiple KG paths as supporting evidence; maintaining top-N diverse paths reduces calibration accumulation and hallucination relative to naive single-path beam search.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6725.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-ChatGPT-CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting (CoT) with ChatGPT on CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard Chain-of-Thought prompting applied to CWQ using ChatGPT, producing step-by-step textual reasoning chains without explicit KG traversal.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (GPT-3.5 family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT) prompting</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential (chain-of-thought)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Complex WebQuestions (CWQ)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>38.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ToG w/ ChatGPT (57.1)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-18.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT relies solely on the LLM's internal knowledge and sequential chain generation; authors observe CoT performance degrades with greater reasoning depth whereas ToG mitigates depth-related drops by using KG evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6725.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SC-ChatGPT-CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (SC) with ChatGPT on CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Self-Consistency ensembles multiple CoT-style reasoning chains from the LLM and votes/aggregates results; evaluated with ChatGPT on CWQ.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary (GPT-3.5 family)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (SC)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble (aggregation of multiple CoT traces)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>ensemble of similar style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Complex WebQuestions (CWQ)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>45.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Chain-of-Thought w/ ChatGPT (38.8)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SC improves over single CoT by aggregating multiple chain-of-thought outputs, but still lags behind KG-augmented ToG; authors note SC reduces some CoT variance but does not provide explicit, editable evidence like KG-paths.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6725.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToG+SentenceBERT-WebQSP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ToG with Sentence-BERT used for pruning (hybrid) on WebQSP</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An efficiency-oriented variant where the expensive LLM-based prune step is replaced by Sentence-BERT (or BM25) for candidate scoring, reducing LLM calls but impacting accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT (GPT-3.5-turbo) + Sentence-BERT (pruning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>proprietary +  SBERT (lightweight)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>ToG with lightweight pruning (Sentence-BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>beam-search graph traversal with lightweight prune (hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>reduced diversity (weaker semantic pruning)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>WebQSP</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>66.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ToG w/ ChatGPT (76.2)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-9.9</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Replacing LLM-based pruning with Sentence-BERT or BM25 reduces LLM calls from O(ND) to O(D) but causes substantial accuracy drops (authors report average drops ~8.4% on CWQ and ~15.1% on WebQSP); they suggest increasing beam width to partially recover accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6725.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6725.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NaiveBeam-CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Naive top-1 beam search on KG (single-path) evaluated on CWQ</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline that selects the single most plausible path at each search step (naive top-1 beam) instead of keeping top-N paths as ToG does; evaluated on CWQ.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM used in experiment (unspecified for this baseline run)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Naive top-1 beam search on KG</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>single-path beam search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style (homogeneous)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Complex WebQuestions (CWQ)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-hop knowledge-base question answering</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Hits@1 (Exact match)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>30.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ToG (CWQ) (58.8 reported in Table 6)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-28.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Authors show naive single-path beam search accumulates calibration error along depth and is much less stable; ToG keeps top-N paths to mitigate this and substantially improves EM on CWQ.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>ReAct: Synergizing reasoning and acting in language models <em>(Rating: 1)</em></li>
                <li>BeamQA: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search <em>(Rating: 2)</em></li>
                <li>StructGPT: A general framework for large language model to reason over structured data <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6725",
    "paper_id": "paper-119601712acbe6ee133a1744f0970190c4195519",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "ToG-GPT4-GrailQA",
            "name_full": "Think-on-Graph (ToG) with GPT-4 on GrailQA",
            "brief_description": "ToG is a tight LLM-KG coupling that uses an LLM as an agent to perform beam-search graph traversal on a knowledge graph, producing top-N multi-hop reasoning paths which the LLM then evaluates to answer KBQA queries; evaluated here using GPT-4 on GrailQA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": "proprietary (GPT-4)",
            "reasoning_method_name": "Think-on-Graph (ToG)",
            "reasoning_method_type": "beam-search graph traversal (tight LLM–KG coupling)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GrailQA",
            "task_description": "Multi-hop knowledge-base question answering (KBQA)",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 81.4,
            "comparison_target_method": "Prior fine-tuned SOTA (75.4)",
            "performance_difference": 6.0,
            "statistical_significance": false,
            "analysis_notes": "ToG uses beam search to maintain top-N reasoning paths (diverse multi-hop paths) and then asks the LLM to evaluate whether the current paths suffice to answer; authors attribute large gains to deeper, explicit multi-hop evidence and tight LLM–KG interaction enabling knowledge-traceability and reduced hallucination.",
            "ablation_study_present": true,
            "uuid": "e6725.0"
        },
        {
            "name_short": "ToG-R-GPT4-CWQ",
            "name_full": "Relation-based Think-on-Graph (ToG-R) with GPT-4 on CWQ",
            "brief_description": "ToG-R is a relation-chain variant of ToG that searches relation sequences starting from topic entities and uses random pruning for entities to reduce LLM calls; evaluated with GPT-4 on CWQ.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_size": "proprietary (GPT-4)",
            "reasoning_method_name": "Relation-based Think-on-Graph (ToG-R)",
            "reasoning_method_type": "beam-search over relation chains (graph traversal, relation-first)",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Complex WebQuestions (CWQ)",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 69.5,
            "comparison_target_method": "Prior fine-tuned SOTA (70.4)",
            "performance_difference": -0.9,
            "statistical_significance": false,
            "analysis_notes": "ToG-R emphasizes relation literal information and uses random beam prune for entities (reduces LLM prune cost but can increase relation diversity); authors report ToG-R is slightly less accurate than triple-based ToG on most datasets but faster/cheaper.",
            "ablation_study_present": true,
            "uuid": "e6725.1"
        },
        {
            "name_short": "ToG-ChatGPT-CWQ",
            "name_full": "Think-on-Graph (ToG) with ChatGPT (GPT-3.5-turbo) on CWQ",
            "brief_description": "Application of ToG using ChatGPT as the backbone LLM to run beam-search graph reasoning for CWQ KBQA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5-turbo)",
            "model_size": "proprietary (GPT-3.5 family)",
            "reasoning_method_name": "Think-on-Graph (ToG)",
            "reasoning_method_type": "beam-search graph traversal (tight LLM–KG coupling)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Complex WebQuestions (CWQ)",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 57.1,
            "comparison_target_method": "Chain-of-Thought prompting (CoT) w/ ChatGPT (38.8)",
            "performance_difference": 18.3,
            "statistical_significance": false,
            "analysis_notes": "Authors report ToG substantially outperforms standard prompting/CoT (same backbone) by exploring multiple KG paths as supporting evidence; maintaining top-N diverse paths reduces calibration accumulation and hallucination relative to naive single-path beam search.",
            "ablation_study_present": true,
            "uuid": "e6725.2"
        },
        {
            "name_short": "CoT-ChatGPT-CWQ",
            "name_full": "Chain-of-Thought prompting (CoT) with ChatGPT on CWQ",
            "brief_description": "Standard Chain-of-Thought prompting applied to CWQ using ChatGPT, producing step-by-step textual reasoning chains without explicit KG traversal.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5-turbo)",
            "model_size": "proprietary (GPT-3.5 family)",
            "reasoning_method_name": "Chain-of-Thought (CoT) prompting",
            "reasoning_method_type": "sequential (chain-of-thought)",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "Complex WebQuestions (CWQ)",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 38.8,
            "comparison_target_method": "ToG w/ ChatGPT (57.1)",
            "performance_difference": -18.3,
            "statistical_significance": false,
            "analysis_notes": "CoT relies solely on the LLM's internal knowledge and sequential chain generation; authors observe CoT performance degrades with greater reasoning depth whereas ToG mitigates depth-related drops by using KG evidence.",
            "ablation_study_present": true,
            "uuid": "e6725.3"
        },
        {
            "name_short": "SC-ChatGPT-CWQ",
            "name_full": "Self-Consistency (SC) with ChatGPT on CWQ",
            "brief_description": "Self-Consistency ensembles multiple CoT-style reasoning chains from the LLM and votes/aggregates results; evaluated with ChatGPT on CWQ.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5-turbo)",
            "model_size": "proprietary (GPT-3.5 family)",
            "reasoning_method_name": "Self-Consistency (SC)",
            "reasoning_method_type": "ensemble (aggregation of multiple CoT traces)",
            "reasoning_style_diversity": "ensemble of similar style",
            "benchmark_name": "Complex WebQuestions (CWQ)",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 45.4,
            "comparison_target_method": "Chain-of-Thought w/ ChatGPT (38.8)",
            "performance_difference": 6.6,
            "statistical_significance": false,
            "analysis_notes": "SC improves over single CoT by aggregating multiple chain-of-thought outputs, but still lags behind KG-augmented ToG; authors note SC reduces some CoT variance but does not provide explicit, editable evidence like KG-paths.",
            "ablation_study_present": true,
            "uuid": "e6725.4"
        },
        {
            "name_short": "ToG+SentenceBERT-WebQSP",
            "name_full": "ToG with Sentence-BERT used for pruning (hybrid) on WebQSP",
            "brief_description": "An efficiency-oriented variant where the expensive LLM-based prune step is replaced by Sentence-BERT (or BM25) for candidate scoring, reducing LLM calls but impacting accuracy.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGPT (GPT-3.5-turbo) + Sentence-BERT (pruning)",
            "model_size": "proprietary +  SBERT (lightweight)",
            "reasoning_method_name": "ToG with lightweight pruning (Sentence-BERT)",
            "reasoning_method_type": "beam-search graph traversal with lightweight prune (hybrid)",
            "reasoning_style_diversity": "reduced diversity (weaker semantic pruning)",
            "benchmark_name": "WebQSP",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 66.3,
            "comparison_target_method": "ToG w/ ChatGPT (76.2)",
            "performance_difference": -9.9,
            "statistical_significance": false,
            "analysis_notes": "Replacing LLM-based pruning with Sentence-BERT or BM25 reduces LLM calls from O(ND) to O(D) but causes substantial accuracy drops (authors report average drops ~8.4% on CWQ and ~15.1% on WebQSP); they suggest increasing beam width to partially recover accuracy.",
            "ablation_study_present": true,
            "uuid": "e6725.5"
        },
        {
            "name_short": "NaiveBeam-CWQ",
            "name_full": "Naive top-1 beam search on KG (single-path) evaluated on CWQ",
            "brief_description": "A baseline that selects the single most plausible path at each search step (naive top-1 beam) instead of keeping top-N paths as ToG does; evaluated on CWQ.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLM used in experiment (unspecified for this baseline run)",
            "model_size": "variable",
            "reasoning_method_name": "Naive top-1 beam search on KG",
            "reasoning_method_type": "single-path beam search",
            "reasoning_style_diversity": "single style (homogeneous)",
            "benchmark_name": "Complex WebQuestions (CWQ)",
            "task_description": "Multi-hop knowledge-base question answering",
            "performance_metric": "Hits@1 (Exact match)",
            "performance_value": 30.1,
            "comparison_target_method": "ToG (CWQ) (58.8 reported in Table 6)",
            "performance_difference": -28.7,
            "statistical_significance": false,
            "analysis_notes": "Authors show naive single-path beam search accumulates calibration error along depth and is much less stable; ToG keeps top-N paths to mitigate this and substantially improves EM on CWQ.",
            "ablation_study_present": true,
            "uuid": "e6725.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2
        },
        {
            "paper_title": "ReAct: Synergizing reasoning and acting in language models",
            "rating": 1
        },
        {
            "paper_title": "BeamQA: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search",
            "rating": 2
        },
        {
            "paper_title": "StructGPT: A general framework for large language model to reason over structured data",
            "rating": 1
        }
    ],
    "cost": 0.017479249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>THINK-ON-GRAPH: DEEP AND RESPONSIBLE REASONING OF LARGE LANGUAGE MODEL ON KNOWLEDGE GRAPH</h1>
<p>Jiashuo Sun ${ }^{21 \text { a }}$ Chengjin Xu ${ }^{1 *}$ Lumingyuan Tang ${ }^{31 \text { a }}$ Saizhuo Wang ${ }^{41 \text { a }}$ Chen Lin ${ }^{2}$ Yeyun Gong ${ }^{6}$ Lionel M. Ni ${ }^{5}$ Heung-Yeung Shum ${ }^{14}$ Jian Guo ${ }^{15 \ddagger}$<br>${ }^{1}$ IDEA Research, International Digital Economy Academy<br>${ }^{2}$ Xiamen University<br>${ }^{3}$ University of Southern California<br>${ }^{4}$ The Hong Kong University of Science and Technology<br>${ }^{5}$ The Hong Kong University of Science and Technology (Guangzhou)<br>${ }^{6}$ Microsoft Research Asia</p>
<h4>Abstract</h4>
<p>Although large language models (LLMs) have achieved significant success in various tasks, they often struggle with hallucination problems, especially in scenarios requiring deep and responsible reasoning. These issues could be partially addressed by introducing external knowledge graphs (KG) in LLM reasoning. In this paper, we propose a new LLM-KG integrating paradigm "LLM $\otimes \mathrm{KG}$ " which treats the LLM as an agent to interactively explore related entities and relations on KGs and perform reasoning based on the retrieved knowledge. We further implement this paradigm by introducing a new approach called Think-on-Graph (ToG), in which the LLM agent iteratively executes beam search on KG, discovers the most promising reasoning paths, and returns the most likely reasoning results. We use a number of well-designed experiments to examine and illustrate the following advantages of ToG: 1) compared with LLMs, ToG has better deep reasoning power; 2) ToG has the ability of knowledge traceability and knowledge correctability by leveraging LLMs reasoning and expert feedback; 3) ToG provides a flexible plug-and-play framework for different LLMs, KGs and prompting strategies without any additional training cost; 4) the performance of ToG with small LLM models could exceed large LLM such as GPT-4 in certain scenarios and this reduces the cost of LLM deployment and application. As a training-free method with lower computational cost and better generality, ToG achieves overall SOTA in 6 out of 9 datasets where most previous SOTAs rely on additional training. Our code is publicly available at https://github.com/IDEA-FinAI/ToG.</p>
<h2>1 INTRODUCTION</h2>
<p>Large language models (LLMs) (Ouyang et al., 2022; OpenAI, 2023; Thoppilan et al., 2022; Brown et al., 2020a; Chowdhery et al., 2022; Touvron et al., 2023) have demonstrated remarkable performance across various natural language processing tasks. These models capitalize on pre-training techniques applied to vast text corpora to generate responses that are coherent and contextually appropriate. Despite their impressive performance, LLMs have substantial limitations when facing complex knowledge reasoning tasks (Petroni et al., 2021; Talmor et al., 2019; Talmor \&amp; Berant, 2018; Zhang et al., 2023) that require deep and responsible reasoning. Firstly, LLMs usually fail to provide accurate answers to questions requiring specialized knowledge beyond what was included in the pre-training phase (out-of-date knowledge in Figure 1a), or to questions requiring long logic chain and multi-hop knowledge reasoning. Secondly, LLMs lack responsibility, explainability and transparency,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Representative workflow of three LLM reasoning paradigms: (a) LLM-only (e.g., Chain-ofThought prompting), (b) LLM $\oplus$ KG (e.g., KBQA via LLM-generated SPARQL query), (c) LLM $\otimes$ KG (e.g., Think-on-Graph).
raising concerns about the risk of hallucinations or toxic texts. Thirdly, the training process for LLMs is often expensive and time-consuming, making it challenging to keep their knowledge up to date.</p>
<p>Recognizing these challenges, a natural and promising solution is to incorporate external knowledge such as knowledge graphs (KGs) to help improve LLM reasoning. KGs offer structured, explicit, and editable representations of knowledge, presenting a complementary strategy to mitigate the limitations of LLMs (Pan et al., 2023). Researchers (Li et al., 2023c; Xie et al., 2022; Baek et al., 2023b; Yang et al., 2023; Wang et al., 2023a; Jiang et al., 2023) have explored the usage of KGs as external knowledge sources to mitigate hallucination in LLMs. These approaches follow a routine: retrieve information from KGs, augment the prompt accordingly, and feed the increased prompt into LLMs (as illustrated in Figure 1b). In this paper, we refer to this paradigm as "LLM $\otimes$ KG". Although aiming to integrate the power of LLM and KG, in this paradigm, LLM plays the role of translator which transfers input questions to machine-understandable command for KG searching and reasoning, but it does not participate in the graph reasoning process directly. Unfortunately, the loose-coupling LLM $\oplus$ KG paradigm has its own limitations, and its success depends heavily on the completeness and high quality of KG. In Figure 1b, for example, although LLM successfully identified necessary relation types required to answer the question, the absence of the relation "majority party" leads to a failure in retrieving the correct answer.</p>
<p>Building upon these considerations, we propose a new tight-coupling "LLM $\otimes$ KG" paradigm where KGs and LLMs work in tandem, complementing each other's capabilities in each step of graph reasoning. Figure 1c provides an example illustrating the advantage of LLM $\otimes$ KG. In this example, the missing relation "majority party" resulting in the failure in Figure 1b can be complemented by a reference triple {Australia, prime minister, Anthony Albanese} discovered by the LLM agent with dynamic reasoning ability (Yao et al., 2022), as well as the political party membership of Anthony Albanese coming from LLM's inherent knowledge. In this way, the LLM succeeds in generating the correct answer with reliable knowledge retrieved from KGs. As an implementation of this paradigm, we propose an algorithmic framework "Think-on-Graph" (meaning: LLMs "Think" along the reasoning paths "on" knowledge "graph" step-by-step, abbreviated as ToG below), for deep, responsible, and efficient LLM reasoning. Using the beam search algorithm (Jurafsky \&amp; Martin, 2009) in KG/LLM reasoning (Atif et al., 2023; Sun et al., 2023a; Xie et al., 2023; Liu et al., 2024), ToG allows LLM to dynamically explore a number of reasoning paths in KG and make decisions accordingly. Given an input question, ToG first identifies initial entities and then iteratively calls the LLM to retrieve relevant triples from KGs through exploration (looking for relevant triples in KG via "on graph" step) and reasoning (deciding on the most relevant triples via "think" step) until adequate</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: An example workflow of ToG. The glowing entities are the central entities where the search starts at each iteration (depth), and the entities with boldface are the selected central entities for the next iteration after pruning. At each pruning step, the darkness of the edges represents the ranking score given by LLM, and the dashed lines indicate relations that have been pruned due to low evaluation scores.
information through the top-N reasoning paths in beam search is gathered to answer the question (judged by LLMs in "Think" step) or the predefined maximum search depth is reached.</p>
<p>The advantage of ToG can be abbreviated as (1) Deep reasoning: ToG extracts diverse and multihop reasoning paths from KGs as the basis for LLM reasoning, enhancing LLMs' deep reasoning capabilities for knowledge-intensive tasks. (2) Responsible reasoning: Explicit, editable reasoning paths improve the explainability of the reasoning process of LLMs, and enable the tracing and correction of the provenances of models' outputs. (3) Flexibility and efficiency: a) ToG is a plug-and-play framework that can be applied to a variety of LLMs and KGs seamlessly. b) Under ToG framework, knowledge can be updated frequently via KG instead of LLM whose knowledge-update is expensive and slow. c) ToG enhances the reasoning ability of small LLMs (e.g., LLAMA2-70B) to be competitive with big LLMs (e.g., GPT-4).</p>
<h1>2 MEthods</h1>
<p>ToG implements the "LLM $\otimes \mathrm{KG}$ " paradigm by asking LLM to perform beam search on knowledge graph. Specifically, it prompts the LLM to iteratively explore multiple possible reasoning paths on KGs until the LLM determines that the question can be answered based on the current reasoning paths. ToG constantly updates and maintains top- $N$ reasoning paths $P=\left{p_{1}, p_{2}, \ldots, p_{N}\right}$ for the question $x$ after each iteration, where $N$ denotes the width of beam search. The entire inference process of ToG contains the following 3 phases: initialization, exploration, and reasoning.</p>
<h3>2.1 THINK-ON-GRAPH</h3>
<h3>2.1.1 Initialization of Graph Search</h3>
<p>Given a question, ToG leverages the underlying LLM to localize the initial entity of the reasoning paths on knowledge graph. This phase can be regarded as the initialization of the top- $N$ reasoning paths $P$. ToG first prompts LLMs to automatically extract the topic entities in question and gets the</p>
<p>top- $N$ topic entities $E^{0}=\left{e_{1}^{0}, e_{2}^{0}, \ldots, e_{N}^{0}\right}$ to the question. Note that the number of topic entities might possibly be less than $N$.</p>
<h1>2.1.2 EXPLORATION</h1>
<p>At the beginning of the $D$-th iteration, each path $p_{n}$ consists of $D-1$ triples, i.e., $p_{n}=$ $\left{\left(e_{s, n}^{d}, r_{j, n}^{d}, e_{o, n}^{d}\right)\right}<em n="n" s_="s,">{d=1}^{D-1}$, where $e</em>\right}$, respectively.
The exploration phase in the $D$-th iteration aims to exploit the LLM to identify the most relevant top- $N$ entities $E^{D}$ from the neighboring entities of the current top- $N$ entity set $E^{D-1}$ based on the question $x$ and extend the top- $N$ reasoning paths $P$ with $E^{D}$. To address the complexity of handling numerous neighboring entities with the LLM, we implement a two-step exploration strategy: first, exploring significant relations, and then using selected relations to guide entity exploration.}^{d}$ and $e_{o, n}^{d}$ denote subject and object entities, $r_{j, n}^{d}$ is a specific relation between them, $\left(e_{s, n}^{d}, r_{j, n}^{d}, e_{o, n}^{d}\right)$ and $\left(e_{s, n}^{d+1}, r_{j, n}^{d+1}, e_{o, n}^{d+1}\right)$ are connected to each other. The sets of the tail entities and relations in $P$ are denoted as $E^{D-1}=\left{e_{1}^{D-1}, e_{2}^{D-1}, \ldots, e_{N}^{D-1}\right}$ and $R^{D-1}=\left{r_{1}^{D-1}, r_{2}^{D-1}, \ldots, r_{N}^{D-1</p>
<p>Relation Exploration Relation exploration is a beam search process with the depth of 1 and the width of $N$ from $E^{D-1}$ to $R^{D}$. The whole process can be decomposed into two steps: Search and Prune. The LLM serves as an agent to automatically complete this process.</p>
<ul>
<li>Search At the beginning of the $D$-th iteration, the relation exploration phase first searches out relations $R_{\text {cand }, n}^{D}$ linked to the tail entity $e_{n}^{D-1}$ for each reasoning path $p_{n}$. These relations are aggregated into $R_{\text {cand }}^{D}$. In the case of Figure 2, $E^{1}={$ Canberra $}$ and $R_{\text {cand }}^{1}$ denotes the set of all relations linked to Canberra inwards or outwards. Notably, the Search procedure can be easily completed by executing two simple pre-defined formal queries shown in Appendix E.1 and E.2, which makes ToG adapt well to different KGs without any training cost.</li>
<li>Prune Once we have obtained the candidate relation sets $R_{\text {cand }}^{D}$ and the expanded candidate reasoning paths $P_{\text {cand }}$ from the relation search, we can utilize the LLM to select out new top- $N$ reasoning paths $P$ ending with the tail relations $R^{D}$ from $P_{\text {cand }}$ based on the literal information of the question $x$ and the candidate relations $R_{\text {cand }}^{D}$. The prompt used here can be found in Appendix E.3.1. As shown in Figure 2, the LLM selects top-3 relations ${$ capital of, country, territory $}$ out from all relations linked to the entity Canberra in the first iteration. Since Canberra is the only topic entity, the top-3 candidate reasoning paths are updated as ${($ Canberra, capital of), (Canberra, country), (Canberra, territory) $}$.</li>
</ul>
<p>Entity Exploration Similar to relationship exploration, entity exploration is also a beam search process performed by the LLM from $R^{D}$ to $E^{D}$, and consists of two steps, Search and Prune.</p>
<ul>
<li>Search Once we have obtained new top- $N$ reasoning paths $P$ and the set of new tail relations $R^{D}$ from relation exploration, for each relation path $p_{n} \in P$, we can explore a candidate entity set $E_{\text {cand }, n}^{D}$ by querying $\left(e_{n}^{D-1}, r_{n}^{D}, ?\right)$ or $\left(?, r_{n}^{D}, e_{n}^{D-1}\right)$, where $e_{n}^{D-1}, r_{n}$ denote the tail entity and relation of $p_{n}$. We can aggregate $\left{E_{\text {cand }, 1}^{D}, E_{\text {cand }, 2}^{D}, \ldots, E_{\text {cand }, N}^{D}\right}$ into $E_{\text {cand }}^{D}$ and expand top- $N$ reasoning paths $P$ to $P_{\text {cand }}$ with the tail entities $E_{\text {cand }}^{D}$. For the shown case, $E_{\text {cand }}^{1}$ can be represented as ${$ Australia, Australia, Australian Capital Territory $}$.</li>
<li>Prune Since the entities in each candidate set $E_{\text {cand }}^{D}$ is expressed in natural language, we can leverage the LLM to select new top- $N$ reasoning paths $P$ ending with the tail entities $E^{D}$ out from $P_{\text {cand }}$. The prompt used here can be found in Appendix E.3.2. As shown in Figure 2, Australia and Australian Capital Territory are scored as 1 since the relations capital of, country and territory are only linked to one tail entity respectively, and the current reasoning paths $p$ are updated as ${($ Canberra, capital of, Australia $),($ Canberra, country, Australia $)$, (Canberra, territory, Australian Capital Territory) $}$.</li>
</ul>
<p>After executing the two explorations described above, we reconstruct new top- $N$ reasoning paths $P$ where the length of each path increases by 1 . Each prune step requires at most $N$ LLM calls.</p>
<h1>2.1.3 REASONING</h1>
<p>Upon obtaining the current reasoning path $P$ through the exploration process, we prompt the LLM to evaluate whether the current reasoning paths are adequate for generating the answer. If the evaluation yields a positive result, we prompt the LLM to generate the answer using the reasoning paths with the query as inputs as illustrated in Figure 2. The prompt used for evaluation and generation can be found in Appendix E.3.3 and E.3.4. Conversely, if the evaluation yields a negative result, we repeat the Exploration and Reasoning steps until the evaluation is positive or reaches the maximum search depth $D_{\text {max }}$. If the algorithm has not yet concluded, it signifies that even upon reaching the $D_{\text {max }}$, ToG remains unable to explore the reasoning paths to resolve the question. In such a scenario, ToG generates the answer exclusively based on the inherent knowledge in the LLM. The whole inference process of ToG contains $D$ exploration phases and $D$ evaluation steps as well as a generation step, which needs at most $2 N D+D+1$ calls to the LLM.</p>
<h3>2.2 Relation-based Think-on-Graph</h3>
<p>Previous KBQA methods, particularly based on semantic parsing, have predominantly relied on relation information in questions to generate formal queries (Lan et al., 2022). Inspired by this, we propose relation-based ToG (ToG-R) that explores the top- $N$ relation chains $\left{p_{n}=\left(e_{n}^{0}, r_{n}^{1}, r_{n}^{2}, \ldots, r_{n}^{D}\right)\right}<em n="n">{n=1}^{N}$ starting with the topic entities $\left{e</em>\right}}^{0<em _cand="{cand" _text="\text">{n=1}^{N}$ instead of triple-based reasoning paths. ToG-R sequentially performs relation search, relation prune and entity search in each iteration, which is the same as ToG. Then ToG-R performs the reasoning step based on all candidate reasoning paths ending with $E</em>$ might have little impact on the following relation exploration. Thus, we use the random beam search instead of the LLM-constrained beam search in ToG for entity prune, referred to as random prune. Algorithm 1 and 2 show the implementation details of the ToG and ToG-R. ToG-R needs at most $N D+D+1$ calls to the LLM.}}^{D}$ obtained by entity search. If the LLM determines that the retrieved candidate reasoning paths do not contain enough information for the LLM to answer the question, we randomly sample N entities from the candidate entities $E_{\text {cand }}^{D}$ and continue to the next iteration. Assuming that entities in each entity set $E_{\text {cand }, n}^{D}$ probably belong to the same entity class and have similar neighboring relations, the results of pruning the entity set $\left{E_{\text {cand }, n}^{D}\right}_{n=1}^{N</p>
<p>Compared to ToG, ToG-R offers two key benefits: 1) It eliminates the need for the process of pruning entities using the LLM, thereby reducing the overall cost and reasoning time. 2) ToG-R primarily emphasizes the literal information of relations, mitigating the risk of misguided reasoning when the literal information of intermediate entities is missing or unfamiliar to the LLM.</p>
<h2>3 EXPERIMENTS</h2>
<h3>3.1 EXPERIMENTAL DESIGN</h3>
<h3>3.1.1 Datasets and Evaluation Metrics</h3>
<p>In order to test ToG's ability on multi-hop knowledge-intensive reasoning tasks, we evaluate ToG on five KBQA datasets (4 Multi-hop and 1 Single-hop): CWQ (Talmor \&amp; Berant, 2018), WebQSP (Yih et al., 2016), GrailQA (Gu et al., 2021), QALD10-en (Perevalov et al., 2022), Simple Questions (Bordes et al., 2015). Moreover, in order to examine ToG on more generic tasks, we also prepare one open-domain QA dataset: WebQuestions (Berant et al., 2013); two slot filling datasets: T-REx (ElSahar et al., 2018) and Zero-Shot RE (Petroni et al., 2021); and one fact-checking dataset: Creak (Onoe et al., 2021). Note that, for two big datasets GrailQA and Simple Questions, we only randomly selected 1,000 samples each for testing in order to save computational cost. For all datasets, exact match accuracy (Hits@1) is used as our evaluation metric following previous works (Li et al., 2023c; Baek et al., 2023b; Jiang et al., 2023; Li et al., 2023a).</p>
<h3>3.1.2 Methods Selected for Comparison</h3>
<p>We compare with standard prompting (IO prompt) (Brown et al., 2020b), Chain-of-Thought prompting (CoT prompt) (Wei et al., 2022), and Self-Consistency (Wang et al., 2023c) with 6 in-context exemplars and "step-by-step" reasoning chains. Moreover, for each dataset, we pick previous state-of-the-art (SOTA) works for comparison. We notice that fine-tuning methods trained specifically on</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Multi-Hop KBQA</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Single-Hop KBQA</th>
<th style="text-align: center;">Open-Domain QA</th>
<th style="text-align: center;">Slot Filling</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Fact Checking</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">CWQ</td>
<td style="text-align: center;">WebQSP</td>
<td style="text-align: center;">GrailQA</td>
<td style="text-align: center;">QALD10-en</td>
<td style="text-align: center;">Simple Questions</td>
<td style="text-align: center;">WebQuestions</td>
<td style="text-align: center;">T-REx</td>
<td style="text-align: center;">Zero-Shot RE</td>
</tr>
<tr>
<td style="text-align: center;">Without external knowledge</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">IO prompt w/ChatGPT</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">29.4</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">27.7</td>
</tr>
<tr>
<td style="text-align: center;">CoT w/ChatGPT</td>
<td style="text-align: center;">38.8</td>
<td style="text-align: center;">62.2</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">42.9</td>
<td style="text-align: center;">20.3</td>
<td style="text-align: center;">48.5</td>
<td style="text-align: center;">32.0</td>
<td style="text-align: center;">28.8</td>
</tr>
<tr>
<td style="text-align: center;">SC w/ChatGPT</td>
<td style="text-align: center;">45.4</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">29.6</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">18.9</td>
<td style="text-align: center;">50.3</td>
<td style="text-align: center;">41.8</td>
<td style="text-align: center;">45.4</td>
</tr>
<tr>
<td style="text-align: center;">With external knowledge</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Prior FT SOTA</td>
<td style="text-align: center;">$70.4^{\circ}$</td>
<td style="text-align: center;">$82.1^{\mathrm{d}}$</td>
<td style="text-align: center;">$75.4^{\circ}$</td>
<td style="text-align: center;">$45.4^{\mathrm{d}}$</td>
<td style="text-align: center;">$85.8^{\circ}$</td>
<td style="text-align: center;">$56.3^{\mathrm{d}}$</td>
<td style="text-align: center;">$87.7^{\mathrm{a}}$</td>
<td style="text-align: center;">$74.6^{\mathrm{d}}$</td>
</tr>
<tr>
<td style="text-align: center;">Prior Prompting SOTA</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$74.4^{\circ}$</td>
<td style="text-align: center;">$53.2^{\circ}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">ToG-R (Ours) w/ChatGPT</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">56.4</td>
<td style="text-align: center;">48.6</td>
<td style="text-align: center;">45.4</td>
<td style="text-align: center;">53.2</td>
<td style="text-align: center;">75.3</td>
<td style="text-align: center;">86.5</td>
</tr>
<tr>
<td style="text-align: center;">ToG (Ours) w/ChatGPT</td>
<td style="text-align: center;">57.1</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;">50.2</td>
<td style="text-align: center;">53.6</td>
<td style="text-align: center;">54.5</td>
<td style="text-align: center;">76.8</td>
<td style="text-align: center;">88.0</td>
</tr>
<tr>
<td style="text-align: center;">ToG-R (Ours) w/GPT-4</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">57.1</td>
<td style="text-align: center;">75.5</td>
<td style="text-align: center;">86.9</td>
</tr>
<tr>
<td style="text-align: center;">ToG (Ours) w/GPT-4</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">53.8</td>
<td style="text-align: center;">66.7</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">77.1</td>
<td style="text-align: center;">88.3</td>
</tr>
</tbody>
</table>
<p>Table 1: The ToG results for different datasets. The prior FT (Fine-tuned) and prompting SOTA include the best-known results: $\alpha$ : Das et al. (2021); $\beta$ : Yu et al. (2023); $\gamma$ : Gu et al. (2023); $\delta$ : Santana et al. (2022); $\epsilon$ : Baek et al. (2023a); $\zeta$ : Kedia et al. (2022); $\eta$ : Glass et al. (2022); $\theta$ : Petroni et al. (2021); $\iota$ : Yu et al. (2022); $\kappa$ : Li et al. (2023a).
evaluated datasets usually have an advantage by nature over methods based on prompting without training, but sacrificing the flexibility and generalization on other data. For a fair play, therefore, we compare with previous SOTA among all prompting-based methods and previous SOTA among all methods respectively. Note that the paper Tan et al. (2023) is not involved in comparison because its results are not based on standard exact match and thus incomparable.</p>
<h1>3.1.3 EXPERIMENT DETAILS</h1>
<p>Given the plug-and-play convenience of ToG, we try three LLMs in experiments: ChatGPT, GPT-4 and Llama-2. We use OpenAI API to call ChatGPT (GPT-3.5-turbo) and GPT-4 ${ }^{1}$. Llama-2-70B-Chat (Touvron et al., 2023) runs with 8 A100-40G without quantization, where the temperature parameter is set to 0.4 for exploration process (increasing diversity) and set to 0 for reasoning process (guaranteeing reproducibility). The maximum token length for the generation is set to 256. In all experiments, we set both width $N$ and depth $D_{\max }$ to 3 for beam search. Freebase (Bollacker et al., 2008) is used as KG for CWQ, WebQSP, GrailQA, Simple Questions, and Webquestions, and Wikidata (Vrandečić \&amp; Krötzsch, 2014) is used as KG for QALD10-en, T-REx, Zero-Shot RE and Creak. We use 5 shots in ToG-reasoning prompts for all the datasets.</p>
<h3>3.2 MAIN RESULTS</h3>
<h3>3.2.1 COMPARISON TO OTHER METHODS</h3>
<p>Since CoT uses external KG to enhance LLM, we first compare it with those methods leveraging external knowledge as well. As we can see in Figure 1, even if ToG is a training-free prompting-based method and has natural disadvantage in comparison with those fine-tuning methods trained with data for evaluation, ToG with GPT-4 still achieves new SOTA performance in 6 out of 9 datasets, including WebQSP, GrailQA,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 2: Performances of ToG using different backbone models on CWQ and WebQSP.</p>
<p>QALD10-en, WebQuestions, Zero-Shot RE and Creak. Even for some dataset without SOTA, e.g., CWQ, the performance of CoT has already been close to SOTA ( $69.5 \%$ v.s. $70.4 \%$ ). If comparing with all promoting-based methods, both ToG with GPT-4 and its weaker version ToG with ChatGPT can win the competition in all datasets. In particular, the improvement of $1.6 \%$ on open-domain QA dataset WebQuestions demonstrates the ToG's generality on open-domain QA tasks. We also notice that the performance of ToG on single-hop KBQA dataset is not as good as its performance on other datasets. These results indicate that ToG is more effective on multi-hop datasets in general, which supports our argument that ToG enhances the deep reasoning capability of LLMs.</p>
<p>We also see from Figure 1 that, compared with those methods without leveraging external knowledge (e.g, IO, CoT and SC prompting methods), the advantage of ToG is more significant. For example, the performance improves $51.8 \%$ and $42.9 \%$ on GrailQA and Zero-Shot RE, respectively. It turns out that benefits from external KG can not be ignored in reasoning.</p>
<p>ToG outperforms ToG-R on most datasets since the triple-based reasoning paths provide additional intermediate entity information compared to the relation chains retrieved by ToG-R. More detailed analysis of the answers generated by ToG can be checked in Appendix B.2. And the results of previous methods on each dataset are reported in Appendix C for better comparison,</p>
<h1>3.2.2 Performances with Different Backbone Models</h1>
<p>Given ToG's flexibility of plug-and-play, we evaluate how different backbone models affect its performance on two datasets CWQ and WebQSP. Table 2 shows that, as we expected, the performance of CoT improves with the size (also reflecting partially the reasoning ability) of backbone models (GPT-4 &gt; ChatGPT &gt; Llama-2). Furthermore, we see that, the larger the backbone model, the larger the gap between CoT and ToG (the gain increases from $18.5 \%$ for Llama-2 to $23.5 \%$ for GPT-4 on CWQ, and from $11.5 \%$ for Llama-2 to $15.3 \%$ for GPT-4 on WebQSP), and this indicates more potential of KG can be mined using a more powerful LLM.</p>
<p>In addition, even if using the smallest model Llama-2 (70B parameters), ToG outperforms CoT with GPT-4. This implies a much cheaper technical route for LLM deployment and application, i.e., TOG with cheap small LLM may be a candidate for substituting expensive big LLM, especially in vertical scenarios that external KGs can cover.</p>
<h3>3.2.3 Ablation Study</h3>
<p>We perform various ablation studies to understand the importance of different factors in ToG. We conduct our ablation studies on two subsets of the test sets of CWQ and WebQSP, each of which contains 1,000 randomly sampled questions.</p>
<p>Do search depth and width matter for ToG? To explore the influence of the search depth $D_{\max }$ and the beam width $N$ on ToG's performance, we conduct experiments under settings with depths ranging from 1 to 4 and widths from 1 to 4 . As shown in Figure 3, ToG's performance improves with the search depth and width. This also implies that ToG's performance could potentially be improved with the increment of the exploration depth and breadth. However, considering the computational cost (which increases linearly with the depth), we set both the depth and width to 3 as the default experimental setting. On the other hand, the performance growth diminishes when the depth exceeds 3 . This is mainly because only a small part of questions have the reasoning depths (based on the number of relations in SPARQL, as seen in Figure 12 in the Appendix) of greater than 3.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">CWQ</th>
<th style="text-align: center;">WebQSP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">CoT</td>
<td style="text-align: center;">37.6</td>
<td style="text-align: center;">62.0</td>
</tr>
<tr>
<td style="text-align: left;">ToG</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">w/ Freebase</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">76.2</td>
</tr>
<tr>
<td style="text-align: left;">w/ WikiData</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">68.6</td>
</tr>
<tr>
<td style="text-align: left;">ToG-R</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">w/ Freebase</td>
<td style="text-align: center;">59.2</td>
<td style="text-align: center;">75.1</td>
</tr>
<tr>
<td style="text-align: left;">w/ WikiData</td>
<td style="text-align: center;">51.9</td>
<td style="text-align: center;">66.7</td>
</tr>
</tbody>
</table>
<p>Table 3: Performances of ToG using different source KGs on CWQ and WebQSP.</p>
<p>Do different KGs affect ToG's performance? One of the main advantages of ToG is its plug-andplay capabilities. As shown in Table 3, ToG achieves significant improvements with different source KGs on CWQ and WebQSP, compared to CoT. On the other hand, different source KGs might have</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Performances of ToG with different search depths and widths.
different effects on the performance of ToG. Notably, Freebase brings more significant improvements on CWQ and WebQSP than Wikidata, since both datasets are constructed upon Freebase. Moreover, in a very large KG like Wikidata, the searching and pruning processes are relatively challenging.</p>
<p>How do different prompt designs affect ToG? We perform additional experiments to determine which types of prompt representations can work well for our approach. The results are presented in Table 4. "Triples" denotes using triple formats as prompts to represent multiple paths, such as "(Canberra, capital of, Australia), (Australia, prime minister, Anthony Albanese)". "Sequences" refers to the utilization of a sequence format, as illustrated in Figure 2. "Sentences" involves converting the triples into natural language sentences. For example, "(Canberra, capital of, Australia)" can be converted to "The capital of Canberra is Australia." The result shows that the utilization of triplebased representations for the reasoning paths yields the highest degree of efficiency and superior performance. Conversely, when considering ToG-R, each reasoning path is a relation chain starting from a topic entity, rendering it incompatible with the triple-based prompt representation. Consequently, the transformation of ToG-R into the natural language form results in excessively lengthy prompts, thereby leading to a notable deterioration in performance.</p>
<p>Comparing the affects from different pruning tools. Other than the LLM, lightweight models that can measure text similarity like BM25 and SentenceBERT, can be employed as pruning tools in the exploration phase. We can select top- $N$ entities and relations based on their literal similarities with the question. We investigate the impacts of different pruning tools on the performance of the ToG, as demonstrated in Table 5. The replacement of the LLM with either BM25 or SentenceBERT results in the significant performance degradation of our approach. Concretely, the results on CWQ drop on average by $8.4 \%$, and the results on WebQSP drop on average by $15.1 \%$. The results show that the LLMs perform best as a pruning tool in terms of effectiveness. On the other hand, after utilizing the BM25 or SentenceBERT, we only need $D+1$ calls to the LLM instead of $2 N D+D+1$ as we discuss in Section 2.1.3, which enhances the efficiency of ToG.</p>
<p>We conduct additional ablation studies on the effect of the number of seed exemplars and the difference between ToG and naive beam search on the KG, which can be seen in Appendix B.1.</p>
<h1>3.3 Knowledge Traceability and Correctability in ToG</h1>
<p>The quality of KG is very important for correct reasoning by ToG. An interesting feature of ToG is knowledge traceability and knowledge correctability during LLM reasoning, and it provides a way to improve KG's quality using ToG itself and reduce the cost of KG construction and correction. As illustrated in Figure 4, the explicit reasoning paths of the ToGs can be displayed to users. If potential</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The illustration of knowledge traceability and correctability of ToG.
errors or uncertainties in ToG answers are discovered by human users/experts or other LLMs, ToG has the ability to trace back and examine the reasoning path, find suspicious triples with errors, and correct them.</p>
<p>Take the case in Figure 4 as an example. Given the input question "What is mascot Phillie Phanatic's team's spring training stadium?", ToG outputs the wrong answer "Bright House Field" in the first round. Then ToG traces back all reasoning paths, localizes the cause of the error may come from the second reasoning path (Phillie Phanatic $\xrightarrow{\text { Team }}$ Philadelphia Phillies $\xrightarrow{\text { Arena Stadium }}$ Bright House Field), and analyzes that the error comes from the old name "Spectrum Field" of "Bright House Field" in the outdated triple (Philadelphia Phillies, Arena Stadium, Bright House Field). According to the hints from ToG, user can ask LLM to correct this error and answer the same question with correct information. This example reveals that ToG not only enhances LLM with KG, but also improves the quality of KG with LLM, known as knowledge infusion (Moiseev et al., 2022).</p>
<h1>4 Related Work</h1>
<p>Reasoning with LLM Prompting Chain-of-Thought (CoT) (Wei et al., 2022) has been shown to be effective in enhancing LLM reasoning. It creates a series of prompt instances according to reasoning logic under a few-shot learning paradigm in order to improve LLM's performance on complex tasks. The thought of CoT has been improved along different dimensions, including Auto-CoT (Zhang et al., 2022), Complex-CoT (Fu et al., 2023), Self-Consistency (Wang et al., 2023c), Zero-Shot-CoT (Kojima et al., 2022), Iter-CoT (Sun et al., 2023b), ToT (Yao et al., 2023), GoT (Besta et al., 2023) and so on. Given the limitation that all these works only use the knowledge in training data, recent efforts such as ReAct (Yao et al., 2022) attempt to utilize the information from external sources such as Wiki documents to further improve the reasoning performance.</p>
<p>KG-enhanced LLM KG has advantages in dynamic, explicit, and structured knowledge representation (Pan et al., 2023) and techniques combining LLMs with KGs have been studied. Early studies (Peters et al., 2019; Huang et al., 2024; Luo et al., 2024; Zhang et al., 2021; Li et al., 2023b; Liu et al., 2020) embed structured knowledge from KGs into the underlying neural networks during the pretraining or fine-tuning process. However, KG embedded in LLM sacrifices its own nature of explainability in knowledge reasoning and efficiency in knowledge updating (Hu et al., 2023).
Recent works instead combine LLMs with KGs by translating relevant structured knowledge from KGs to textual prompts for LLMs. All the methods follow a fixed pipeline that retrieves extra information from KGs to augment the LLM prompt and they belong to the LLM $\otimes \mathrm{KG}$ paradigm we defined in the introduction section. On the other hand, Jiang et al. (2023) asks LLM to explore KG and so it can be regarded as a special case of ToG, which belongs to the LLM $\otimes \mathrm{KG}$ paradigms.</p>
<h1>5 CONCLUSION</h1>
<p>We introduce the LLM $\oslash \mathrm{KG}$ paradigm for integrating LLMs and KGs in a tight-coupling manner, and propose the Think-on-Graph (ToG) algorithmic framework which leverages LLM as a agent participating in KG reasoning for better decision-making. Experimental results demonstrate that ToG outperforms existing fine-tuning-based methods and prompting-based methods without additional training cost and mitigates the hallucination issue of LLMs.</p>
<h2>6 ACKNOWLEDGEMENT</h2>
<p>We express our sincere gratitude to the esteemed reviewers for their invaluable feedback and constructive comments, which significantly contributed to the improvement and refinement of this paper. Their insightful suggestions and meticulous attention to detail have played a pivotal role in enhancing the quality and clarity of our research work.</p>
<h2>REFERENCES</h2>
<p>Farah Atif, Ola El Khatib, and Djellel Eddine Difallah. Beamqa: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search. In Hsin-Hsi Chen, Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete (eds.), Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023, pp. 781-790. ACM, 2023. doi: 10.1145/3539618.3591698. URL https://doi.org/10.1145/3539618.3591698.</p>
<p>Jinheon Baek, Alham Fikri Aji, Jens Lehmann, and Sung Ju Hwang. Direct fact retrieval from knowledge graphs without entity linking. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 1003810055. Association for Computational Linguistics, 2023a. doi: 10.18653/v1/2023.acl-long.558. URL https://doi.org/10.18653/v1/2023.acl-long.558.</p>
<p>Jinheon Baek, Alham Fikri Aji, and Amir Saffari. Knowledge-augmented language model prompting for zero-shot knowledge graph question answering, 2023b.</p>
<p>Debayan Banerjee, Pranav Ajit Nair, Ricardo Usbeck, and Chris Biemann. Gett-qa: Graph embedding based t2t transformer for knowledge graph question answering, 2023.</p>
<p>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pp. 1533-1544. ACL, 2013. URL https://aclanthology.org/D13-1160/.</p>
<p>Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. Graph of thoughts: Solving elaborate problems with large language models, 2023.</p>
<p>Kurt D. Bollacker, Colin Evans, Praveen K. Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD Conference, 2008.</p>
<p>Antoine Bordes, Nicolas Usunier, Sumit Chopra, and Jason Weston. Large-scale simple question answering with memory networks. CoRR, abs/1506.02075, 2015. URL http://arxiv.org/ abs/1506.02075.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler,</p>
<p>Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020a. URL https://proceedings.neurips.cc/paper/2020/hash/ 1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020b. URL https://proceedings.neurips.cc/paper/2020/hash/ 1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html.</p>
<p>Shulin Cao, Jiaxin Shi, Zijun Yao, Xin Lv, Jifan Yu, Lei Hou, Juanzi Li, Zhiyuan Liu, and Jinghui Xiao. Program transfer for answering complex questions over knowledge bases. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pp. 8128-8140. Association for Computational Linguistics, 2022. doi: 10.18653/ v1/2022.acl-long.559. URL https://doi.org/10.18653/v1/2022.acl-long.559.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.</p>
<p>Rajarshi Das, Manzil Zaheer, Dung Thai, Ameya Godbole, Ethan Perez, Jay-Yoon Lee, Lizhen Tan, Lazaros Polymenakos, and Andrew McCallum. Case-based reasoning for natural language queries over knowledge bases, 2021.</p>
<p>Michiel de Jong, Yury Zemlyanskiy, Joshua Ainslie, Nicholas FitzGerald, Sumit Sanghai, Fei Sha, and William Cohen. Fido: Fusion-in-decoder optimized for stronger performance and faster inference. arXiv preprint arXiv:2212.08153, 2022.</p>
<p>Cicero Nogueira dos Santos, Zhe Dong, Daniel Cer, John Nham, Siamak Shakeri, Jianmo Ni, and Yun hsuan Sung. Knowledge prompts: Injecting world knowledge into language models through soft prompts, 2022.</p>
<p>Hady ElSahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon S. Hare, Frédérique Laforest, and Elena Simperl. T-rex: A large scale alignment of natural language with knowledge base triples. In Nicoletta Calzolari, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Kōiti Hasida, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hélène Mazo, Asunción Moreno, Jan Odijk, Stelios Piperidis, and Takenobu Tokunaga (eds.), Proceedings of the Eleventh International Conference on Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7-12, 2018. European Language Resources Association (ELRA), 2018. URL http://www. lrec-conf.org/proceedings/lrec2018/summaries/632.html.</p>
<p>Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting for multi-step reasoning. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview. net/pdf?id=yflicZHC-19.</p>
<p>Michael Glass, Gaetano Rossiello, Md Faisal Mahbub Chowdhury, Ankita Naik, Pengshan Cai, and Alfio Gliozzo. Re2G: Retrieve, rerank, generate. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2701-2715, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.194. URL https://aclanthology.org/ 2022.naacl-main. 194</p>
<p>Yu Gu, Sue Kase, Michelle Vanni, Brian M. Sadler, Percy Liang, Xifeng Yan, and Yu Su. Beyond I.I.D.: three levels of generalization for question answering on knowledge bases. In Jure Leskovec, Marko Grobelnik, Marc Najork, Jie Tang, and Leila Zia (eds.), WWW '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, pp. 3477-3488. ACM / IW3C2, 2021. doi: 10.1145/3442381.3449992. URL https://doi.org/10.1145/3442381.3449992.</p>
<p>Yu Gu, Xiang Deng, and Yu Su. Don't generate, discriminate: A proposal for grounding language models to real-world environments, 2023.</p>
<p>Gaole He, Yunshi Lan, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. Improving multi-hop knowledge base question answering by learning intermediate supervision signals. In Liane LewinEytan, David Carmel, Elad Yom-Tov, Eugene Agichtein, and Evgeniy Gabrilovich (eds.), WSDM '21, The Fourteenth ACM International Conference on Web Search and Data Mining, Virtual Event, Israel, March 8-12, 2021, pp. 553-561. ACM, 2021. doi: 10.1145/3437963.3441753. URL https://doi.org/10.1145/3437963.3441753.</p>
<p>Linmei Hu, Zeyi Liu, Ziwang Zhao, Lei Hou, Liqiang Nie, and Juanzi Li. A survey of knowledge enhanced pre-trained language models. IEEE Transactions on Knowledge and Data Engineering, 2023.</p>
<p>Rikui Huang, Wei Wei, Xiaoye Qu, Wenfeng Xie, Xianling Mao, and Dangyang Chen. Joint multifacts reasoning network for complex temporal question answering over knowledge graph. arXiv preprint arXiv:2401.02212, 2024.</p>
<p>Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-Rong Wen. Structgpt: A general framework for large language model to reason over structured data, 2023.</p>
<p>Dan Jurafsky and James H. Martin. Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition, 2nd Edition. Prentice Hall series in artificial intelligence. Prentice Hall, Pearson Education International, 2009. ISBN 9780135041963. URL https://www.worldcat.org/oclc/315913020.</p>
<p>Akhil Kedia, Mohd Abbas Zaidi, and Haejun Lee. Fie: Building a global probability space by leveraging early fusion in encoder for open-domain question answering. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp. 4246-4260. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022. emnlp-main.285. URL https://doi.org/10.18653/v1/2022.emnlp-main. 285.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In NeurIPS, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 8bb0d29lacd4acf06ef112099c16f326-Abstract-Conference.html.</p>
<p>Yunshi Lan and Jing Jiang. Query graph generation for answering multi-hop complex questions from knowledge bases. Association for Computational Linguistics, 2020.</p>
<p>Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, and Ji-Rong Wen. Complex knowledge base question answering: A survey. IEEE Transactions on Knowledge and Data Engineering, 2022.</p>
<p>Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks, 2021.</p>
<p>Tianle Li, Xueguang Ma, Alex Zhuang, Yu Gu, Yu Su, and Wenhu Chen. Few-shot in-context learning on knowledge base question answering. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 6966-6980. Association for Computational Linguistics, 2023a. doi: 10.18653/v1/2023.acl-long.385. URL https://doi.org/10.18653/v1/2023.acl-long.385.</p>
<p>Wendi Li, Wei Wei, Xiaoye Qu, Xian-Ling Mao, Ye Yuan, Wenfeng Xie, and Dangyang Chen. Trea: Tree-structure reasoning schema for conversational recommendation. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2970-2982, 2023b.</p>
<p>Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Lidong Bing, Shafiq Joty, and Soujanya Poria. Chain of knowledge: A framework for grounding large language models with structured knowledge bases, 2023c.</p>
<p>Daizong Liu, Xiaoye Qu, Jianfeng Dong, and Pan Zhou. Reasoning step-by-step: Temporal sentence localization in videos via deep rectification-modulation network. In Proceedings of the 28th International Conference on Computational Linguistics, pp. 1841-1851, 2020.</p>
<p>Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, and Junxian He. What makes good data for alignment? a comprehensive study of automatic data selection in instruction tuning. In The Twelfth International Conference on Learning Representations, 2024. URL https://openreview. net/forum?id=BTKAeLqLMw.</p>
<p>Ye Liu, Semih Yavuz, Rui Meng, Dragomir Radev, Caiming Xiong, and Yingbo Zhou. Uni-parser: Unified semantic parser for question answering on knowledge base and database. arXiv preprint arXiv:2211.05165, 2022.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019.</p>
<p>Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. Reasoning on graphs: Faithful and interpretable large language model reasoning. In International Conference on Learning Representations, 2024.</p>
<p>Fedor Moiseev, Zhe Dong, Enrique Alfonseca, and Martin Jaggi. SKILL: structured knowledge infusion for large language models. In Marine Carpuat, Marie-Catherine de Marneffe, and Iván Vladimir Meza Ruíz (eds.), Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022, pp. 1581-1588. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.naacl-main.113. URL https://doi.org/10. 18653/v1/2022.naacl-main.113.</p>
<p>Yasumasa Onoe, Michael J. Q. Zhang, Eunsol Choi, and Greg Durrett. CREAK: A dataset for commonsense reasoning over entity knowledge. In Joaquin Vanschoren and Sai-Kit Yeung (eds.), Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual, 2021. URL https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/ hash/5737c6ec2e0716f3d8a7a5c4e0de0d9a-Abstract-round2.html.</p>
<p>OpenAI. Gpt-4 technical report, 2023.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. arXiv Preprint, 2022. doi: 10.48550/arXiv.2203.02155. URL https://doi.org/10.48550/ arXiv.2203.02155.</p>
<p>Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. arXiv preprint arXiv:2306.08302, 2023.
A. Perevalov, D. Diefenbach, R. Usbeck, and A. Both. Qald-9-plus: A multilingual dataset for question answering over dbpedia and wikidata translated by native speakers. In 2022 IEEE 16th International Conference on Semantic Computing (ICSC), pp. 229-234, Los Alamitos, CA, USA, jan 2022. IEEE Computer Society. doi: 10.1109/ICSC52841.2022.00045. URL https://doi.ieeecomputersociety.org/10.1109/ICSC52841.2022.00045.</p>
<p>Matthew E. Peters, Mark Neumann, Robert Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, and Noah A. Smith. Knowledge enhanced contextual word representations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 43-54, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1005. URL https://aclanthology.org/D19-1005.</p>
<p>Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rocktäschel, and Sebastian Riedel. Kilt: a benchmark for knowledge intensive language tasks, 2021.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485-5551, 2020.</p>
<p>Manuel Alejandro Borroto Santana, Bernardo Cuteri, Francesco Ricca, and Vito Barbara. SPARQLQA enters the QALD challenge. In Xi Yan, Meriem Beloucif, and Ricardo Usbeck (eds.), Proceedings of the 7th Natural Language Interfaces for the Web of Data (NLIWoD) co-located with the 19th European Semantic Web Conference (ESWC 2022), Hersonissos, Greece, May 29th, 2022, volume 3196 of CEUR Workshop Proceedings, pp. 25-31. CEUR-WS.org, 2022. URL https://ceur-ws.org/Vol-3196/paper3.pdf.</p>
<p>Yiheng Shu, Zhiwei Yu, Yuhan Li, Börje Karlsson, Tingting Ma, Yuzhong Qu, and Chin-Yew Lin. TIARA: Multi-grained retrieval for robust question answering over large knowledge base. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 8108-8121, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.555. URL https://aclanthology.org/ 2022.emnlp-main. 555 .</p>
<p>Haitian Sun, Tania Bedrax-Weiss, and William W. Cohen. Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text, 2019.</p>
<p>Hao Sun, Xiao Liu, Yeyun Gong, Anlei Dong, Jingwen Lu, Yan Zhang, Daxin Jiang, Linjun Yang, Rangan Majumder, and Nan Duan. Beamsearchqa: Large language models are strong zero-shot QA solver. CoRR, abs/2305.14766, 2023a. doi: 10.48550/arXiv.2305.14766. URL https://doi.org/10.48550/arXiv.2305.14766.</p>
<p>Jiashuo Sun, Yi Luo, Yeyun Gong, Chen Lin, Yelong Shen, Jian Guo, and Nan Duan. Enhancing chain-of-thoughts prompting with iterative bootstrapping in large language models, 2023b.</p>
<p>Alon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex questions. In Marilyn A. Walker, Heng Ji, and Amanda Stent (eds.), Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), pp. 641-651. Association for Computational Linguistics, 2018. doi: 10.18653/v1/ n18-1059. URL https://doi.org/10.18653/v1/n18-1059.</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pp. 4149-4158, 2019. doi: 10.18653/v1/n19-1421. URL https://doi.org/10.18653/v1/n19-1421.</p>
<p>Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, and Guilin Qi. Evaluation of chatgpt as a question answering system for answering complex questions. arXiv preprint arXiv:2303.07992, 2023.</p>
<p>Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Agüera y Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. Lamda: Language models for dialog applications. CoRR, 2022. URL https://arxiv.org/abs/2201.08239.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023.</p>
<p>Denny Vrandečić and Markus Krötzsch. Wikidata: A free collaborative knowledgebase. Commun. ACM, 57(10):78-85, sep 2014. ISSN 0001-0782. doi: 10.1145/2629489. URL https://doi . org/10.1145/2629489.</p>
<p>Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and Ming Gao. Boosting language models reasoning with chain-of-knowledge prompting, 2023a.</p>
<p>Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge Rong, and Zhang Xiong. Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering, 2023b.</p>
<p>Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023c. URL https://openreview.net/ pdf?id=1PL1NIMMrw.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv Preprint, 2022. URL https://arxiv.org/abs/2201.11903.</p>
<p>Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, ChienSheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. UnifiedSKG: Unifying and multitasking structured knowledge grounding with text-to-text language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 602-631, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.emnlp-main. 39.</p>
<p>Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, and Qizhe Xie. Decomposition enhances reasoning via self-evaluation guided decoding, 2023.</p>
<p>Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, and Xindong Wu. Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling, 2023.</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.</p>
<p>Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models, 2023.</p>
<p>Wen-tau Yih, Matthew Richardson, Christopher Meek, Ming-Wei Chang, and Jina Suh. The value of semantic parse labeling for knowledge base question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 2: Short Papers. The Association for Computer Linguistics, 2016. doi: 10.18653/v1/p16-2033. URL https://doi.org/10.18653/v1/p16-2033.</p>
<p>Donghan Yu, Sheng Zhang, Patrick Ng, Henghui Zhu, Alexander Hanbo Li, Jun Wang, Yiqun Hu, William Wang, Zhiguo Wang, and Bing Xiang. Decaf: Joint decoding of answers and logical forms for question answering over knowledge bases, 2023.</p>
<p>Wenhao Yu, Chenguang Zhu, Zhihan Zhang, Shuohang Wang, Zhuosheng Zhang, Yuwei Fang, and Meng Jiang. Retrieval augmentation for commonsense reasoning: A unified approach. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 4364-4377, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.294. URL https://aclanthology.org/ 2022.emnlp-main. 294.</p>
<p>Hang Zhang, Yeyun Gong, Yelong Shen, Weisheng Li, Jiancheng Lv, Nan Duan, and Weizhu Chen. Poolingformer: Long document modeling with pooling attention. In International Conference on Machine Learning, pp. 12437-12446. PMLR, 2021.</p>
<p>Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu, Daya Guo, Jiancheng Lv, and Jian Guo. Noisy pair corrector for dense retrieval. arXiv preprint arXiv:2311.03798, 2023.</p>
<p>Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting in large language models. arXiv Preprint, 2022. doi: 10.48550/arXiv.2210.03493. URL https: //doi.org/10.48550/arXiv.2210.03493.</p>
<h1>A Algorithm for ToG</h1>
<p>We summarize the comprehensive algorithmic procedure of ToG and ToG-R, as shown in Figure Algorithm 1 and 2.</p>
<div class="codehilite"><pre><span></span><code>Algorithm 1 ToG
    Algorithm 2 ToG-R
Require: Input \(x\), LLM \(\pi\), depth limit \(D_{\max}\) sam-Require: Input \(x\), LLM \(\pi\), depth limit \(D_{\max}\) sam-
    ple limit \(N\).
Initialize \(E^{0} \leftarrow\) Extract entities on \(x, P \leftarrow[]\).
$M \leftarrow 0$.
while \(D \leq D_{\max}\) do
    \(R_{\text {cand }}^{D}, P_{\text {cand }} \leftarrow \operatorname{Search}\left(x, E^{D-1}, P\right)\)
    \(R^{D}, P \leftarrow \operatorname{Prune}\left(\pi, x, R_{\text {cand }}^{D}, P_{\text {cand }}\right)\)
    \(E_{\text {cand }}^{D}, P_{\text {cand }} \leftarrow \operatorname{Search}\left(x, E^{D-1}, R^{D}, P\right)\)
    \(E^{D}, P \leftarrow \operatorname{Prune}\left(\pi, x, E_{\text {cand }}^{D}, P_{\text {cand }}\right)\)
    if Reasoning \((\pi, x, P)\) then
        Generate \((\pi, x, P)\)
        break
    end if
    Increment \(D\) by 1 .
end while
if \(D&gt;D_{\max}\) then
    Generate \((\pi, x)\)
end if
ple limit \(N\).
Initialize \(E^{0} \leftarrow\) Extract entities on \(x, P \leftarrow[]\).
$M \leftarrow 0$.
while \(D \leq D_{\max}\) do
    \(R_{\text {cand }}^{D}, P_{\text {cand }} \leftarrow \operatorname{Search}\left(x, E^{D-1}, P\right)\)
    \(R^{D}, P \leftarrow \operatorname{Prune}\left(\pi, x, R_{\text {cand }}^{D}, P_{\text {cand }}\right)\)
    \(E_{\text {cand }}^{D}, P_{\text {cand }} \leftarrow \operatorname{Search}\left(x, E^{D-1}, R^{D}, P\right)\)
    if Reasoning \(\left(\pi, x, P, E_{\text {cand }}^{D}\right)\) then
        Generate \(\left(\pi, x, P, E_{\text {cand }}^{D}\right)\)
        break
    end if
    \(E^{D}, P \leftarrow \operatorname{Random} \_\operatorname{Prune}\left(E_{\text {cand }}^{D}, P_{\text {cand }}\right)\)
    Increment \(D\) by 1 .
end while
if \(D&gt;D_{\max}\) then
    Generate \((\pi, x)\)
end if
</code></pre></div>

<h2>B Additional Ablation Study and Experiment Analysis</h2>
<p>In this section, we conduct more experiments for ablation study in addition to Section 3.2.3, and analyze experimental results of ToG in detail.</p>
<h2>B. 1 Additional Ablation Study</h2>
<p>Sensitivity to the Number of Seed Examplars To better understand how sensitive ToG is sensitivity to the number of seed exemplars, we employ sensitivity analysis shown in Figure 5. We conduct zero-shot experiment and select 1-6 examples from the training set as few-shot setting. In the fewshot tests, we randomly chose $M$ of ${1,2,3,4,6}$ exemplars as demonstrations and replicated the experiments three times. As the number of examples in the demonstrations increases, the overall performance also generally improves. However, the performance peaks for ToG and ToG-R differ (with the best performance for ToG at 5-shot and for ToG-R at 4-shot). Moreover, ToG's zero-shot performance outpaces ToG-R. This can be attributed to ToG having fully completely explored paths, ensuring commendable performance even in zero-shot. In contrast, ToG-R omits entities in the path, but its average performance with demonstrations is superior to ToG.</p>
<p>Difference with Naive Beam Search ToG is slightly different from the beam search. ToG uses the top- $N$ reasoning paths as evidence while the naive beam search chooses the most plausible path as the only reasoning path. We conduct naive top1-beam search methods for ToG on CWQ and WebQSP. For each depth of the ToG, we choose the reasoning path with the highest plausibility, to evaluate if the current reasoning path is sufficient to answer the questions. The experiment results are shown in Table 6. In naive beam search, the calibration error accumulates along</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Search Algorithm</th>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">EM</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Naive Beam Search</td>
<td style="text-align: left;">CWQ</td>
<td style="text-align: left;">30.1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">WebQSP</td>
<td style="text-align: left;">46.1</td>
</tr>
<tr>
<td style="text-align: left;">TOG-R</td>
<td style="text-align: left;">CWQ</td>
<td style="text-align: left;">59.2</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">WebQSP</td>
<td style="text-align: left;">75.1</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">CWQ</td>
<td style="text-align: left;">58.8</td>
</tr>
<tr>
<td style="text-align: left;">TOG</td>
<td style="text-align: left;">WebQSP</td>
<td style="text-align: left;">76.2</td>
</tr>
</tbody>
</table>
<p>Table 6: The results of Naive Beam Search, ToG methods on CWQ and WebQSP.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Exemplar sensitivity analysis for CWQ and WebQSP for ToG, where "0" denotes zero-shot and "k" denotes k-shot.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: The erroneous instances and categories in the CWQ, WebQSP, and GrailQA of IO, CoT, and ToG.
the inference, leading to the instability of the final result.
We believe that ToG can partially alleviate this issue by considering the top- $N$ reasoning paths.</p>
<h1>B. 2 Result Analysis</h1>
<p>We conduct a detailed analysis on the answers generated by ToG and ToG-R.
Error Analysis We considered three types of errors: (1) Hallucination error, (2) Refuse error ${ }^{2}$, and (3) Format error. The distribution is shown in Figure 6. Our approach has significantly reduced the hallucination and refusal to answer error types in IO and CoT. For GrailQA, ToG even reduces these types of errors by $50 \%$ and $60 \%$, respectively. Moreover, in ToG's error samples, there are still many instances of hallucination and refusal to answer errors. This is because the current search depth and width are both set to 3 . By increasing the search depth and width, these error instances will further decrease (refer to Section 3.2.3). Furthermore, we currently generalize incorrect answers as hallucinations, but there are various categories within hallucinations, which we won't discuss in this paper. Additionally, after applying ToG, there's a slight increase in samples with format errors. This result shows that the explored paths lead to a noticeable increase in the tokens, sometimes even exceeding the maximum output limit. However, the error rate from this issue is negligible (less than $3 \%)$.</p>
<p>Evidence of Answers We conducted an analysis of the correctly answered samples in three datasets to investigate the evidence for LLM in generating answers as shown in Figure 7. Evidently, a significant portion of the answers are derived from the paths explored by ToG, while roughly $20 \%$ rely exclusively on the intrinsic knowledge embedded within LLM's parameters for generating responses. It is worth noting that around $7 \%$ of the correctly answered samples require a combination</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>of knowledge from both the explored paths and LLM’s inherent knowledge (as elaborated in Appendix Table 21). This distinction sets our approach apart from traditional graph-based search methods, as it does not necessitate the path to encompass the node containing the correct answer entirely. Instead, the explored paths supplement and reference LLM’s inherent knowledge. The distribution of answer types for ToG-R is almost indistinguishable from that of ToG, proving the robustness of our approach.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: The proportions of ToG’s evidence of answers on CWQ, WebQSP, and GrailQA datasets.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: The explored path overlap ratio of ToG-R on CWQ, WebQSP, and GrailQA datasets.</p>
<p>The Overlap Ratio between the Explored Paths and Ground-truth Paths We also conduct an analysis of the correctly answered samples in three datasets to investigate the ratio of overlap between the paths explored by ToG and the ground-truth path in SPARQL. The definition of overlap ratio is the ratio of overlapping paths to the total number of relations in ground-truth SPARQL:</p>
<p>$$
\frac{\text{Count}(\text{Rel}(\text{Paths}) \cap \text{Rel}(\text{SPARQL}))}{\text{Count}(\text{Rel}(\text{SPARQL}))}
$$</p>
<p>where Rel(<em>) denotes all the unduplicated relations in the "</em>" and Count(<em>) denotes the number of "</em>"3. Figure 9 is a path schematic which takes the case shown in Table 22 for example. It can be observed from Figure 10 that the paths explored by ToG are identical to the golden paths of an average of 30% correct samples, while the paths of an average of 21% correct samples are completely different from the golden path. This indicates that ToG has successfully explored a completely and approximately new path in the knowledge graph space to reach the final answer entity. For ToG-R, the disparity between the two is primarily evident in the CWQ dataset, where the percentage of intervals [25,50] in ToG results is quite significant (nearly 40%), whereas ToG-R results tend to be more evenly distributed as shown in Figure 11. We contend that this discrepancy arises from the disregard of entity, thereby enhancing the diversity of explored relations. This represents a significant application of knowledge graph reasoning in academic research.</p>
<p>The Reasoning Depth of Questions We calculate the reasoning depth of testing questions based on the number of relations within their ground-truth SPARQL queries on CWQ and WebQSP. The counts</p>
<p><sup>3</sup>We approximately calculate the length of a path by counting the number of relations in the ground-truth SPARQL.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Path schematic to calculate overlap.
<img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: The explored path overlap ratio of ToG on CWQ, WebQSP, and GrailQA datasets.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 11: The path overlap ratio of ToG-R on CWQ, WebQSP, and GrailQA datasets.
<img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 12: The lengths of the ground-truth SPARQL queries within the CWQ and WebQSP datasets, computed based on relation numbers.</p>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 13: ToG, ToG-R and CoT's performance among CWQ and WebQSP dataset.
of questions with different reasoning depths are shown in Figure 12. We analyze the performances of ToG, ToG-R, and CoT on testing questions of both datasets with different reasoning depths. As illustrated in Figure 13, the performances of CoT show roughly decreasing trends on both datasets, with the reasoning depth of testing questions increasing. Conversely, ToG and ToG-R can partially counteract the performance degradation caused by the increment of reasoning depths of questions, especially on CWQ. Generally, the performance difference between ToG and CoT becomes more significant on deeper questions.</p>
<h1>B.2.1 Efficiency of ToG</h1>
<p>There are many solutions to improve efficiency and reduce the computational complexity (proportional to the number of calling LLMs) of ToG from the original $O(N D)$ to $O(D)$, where $D$ is the depth (or equivalently length) of the reasoning path, and $N$ is the width of the beam-search (how many paths are remained in the pool in each iteration).</p>
<p>Solution 1 Reducing computational complexity from $O(N D)$ to $O(D)$ by using lightweight model in pruning. The bottleneck of computation is the pruning step, which contributes to $N * D$ times calling, and it is important to optimize it for computational efficiency. A technical route is to replace LLM with small models such as BM25 and Sentence-BERT in the pruning step since the small models are much faster than LLM calling. In this way, we can reduce the number of LLM calling from $2 N D+D+1$ to $D+1$. When $D=3$, for example, there are only 4 times LLM calling. However, this optimization sacrifices the accuracy due to the weaker scoring model in pruning. For instance, as shown in Table 5 of the manuscript, the performance of ToG on WebQSP drops from 76.2\% to $66.3 \%$ after replacing ChatGPT with SentenceBERT for pruning. To alleviate the issue of the performance degradation, we can appropriately increase the search width to compensate the loss because increasing search width can improve the chance of the optimal path to be selected in the pool and it doesn't affect the number of LLM calling. To empirically verify this, we increase the search width from 3 to 5 and reevaluate ToG with SentenceBERT as the pruning model on WebQSP. The accuracy rises to from $66.3 \%$ to $68.5 \%$ and could be further improved with a greater width since the greater width would not cause an increase in the number of LLM calls.</p>
<p>Solution 2 Reducing computational complexity from $O(N D)$ to $O(D)$ by unifying the prompts in the same pruning step. Another solution on speeding up the pruning step is to employ the LLM at once to score all components of N candidate sets for obtaining top-N candidates, instead of calling the LLM N times to score N candidate sets separately. Through this solution, either entity pruning step or relation pruning step only need 1 LLM call for each iteration. Thus, the maximum number of LLM calls per question needed for ToG and ToG-R would drop to $2 D+D+1$ and $D+D+1$.</p>
<p>Solution 3 Optimizing pruning step to make the actual calls of LLMs much less than the previously estimated $2 N D+D+1$ and closer to some common prompting methods such as CoT-SC. For ToG and other LLM-based methods, the computational time (cost or complexity) in the inference phase mainly depends on how many times calling LLM. For each question, ToG needs at most $2 N D+D+1$ times. Meanwhile, ToG-R needs at most $N D+D+1$ times as mentioned in Section 2.</p>
<p>Given the beam search width $N$ and maximal reasoning depth $D$, ToG's initialize the search from the entity mostly aligning with the keyword in question. In each iterative step of the reasoning path,</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ LLM will refuse to answer due to lack of information.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>