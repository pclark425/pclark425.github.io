<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6888 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6888</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6888</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-258866103</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.14356v1.pdf" target="_blank">Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</a></p>
                <p><strong>Paper Abstract:</strong> There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6888.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6888.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype Theory of Concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory that conceptual categories are organized around central tendency exemplars (prototypes) defined by characteristic features, with category membership graded by similarity to the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Prototype Theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented functionally as a set of characteristic features (a prototype or central tendency); membership and inference depend on similarity of an item to that feature vector or prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for typicality gradients and graded category membership; supports induction and hierarchical structure; explains many similarity-based categorization effects.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral literature review</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>category learning and categorization tasks, typicality/induction phenomena (literature-reported paradigms)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Literature review finds phenomena (hierarchical structure, knowledge effects, induction) better explained by prototype-style feature representations than by exemplar recall.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>The paper notes there is also robust evidence that salient exemplars influence categorization judgments, indicating exemplar effects coexist with prototype-like behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Murphy, 2016</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6888.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar Theory of Concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory that conceptual categories are represented by memory of specific encountered instances (exemplars), and categorization arises from similarity to stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is There an Exemplar Theory of Concepts?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Exemplar Theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>instance-based memory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as a set of stored individual exemplars; new items are categorized by similarity comparisons to these instances rather than to an abstract prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains effects of salient exemplars on categorization and some context-dependent categorization phenomena; predicts exemplar similarity will predict reaction times and choices.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral literature review</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>category learning and similarity-based categorization tasks (reported in literature reviews)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Review finds strong evidence that salient exemplars influence categorization, but little direct evidence that people recall specific exemplars to make broader conceptual inferences; exemplar models appear limited to category learning rather than general concept representation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Murphy (2016) argues exemplar models fail to account for hierarchical structure, knowledge effects, and induction that characterize conceptual reasoning, suggesting exemplar theory does not generalize to full concept representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Murphy, 2016</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6888.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Implicosphere / Concept Clouds</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Implicospheres (concepts as vague clouds with control knobs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hofstadter's philosophical model describing concepts as vague, high-dimensional 'clouds' of possibilities with context-dependent 'control knobs' that can be varied and intersected to yield novel ideas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>METAMAGICAL THEMAS.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Implicosphere / Concept-as-Cloud</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional space (vague continuous conceptual cloud)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are functionally represented as continuous, context-sensitive regions ('clouds') in a possibility space with many latent parameters ('control knobs'); intersections of clouds produce blended/novel concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how subtle contextual shifts reveal different concept dimensions, enables blending/intersection to produce novel variations, and provides a substrate for subconscious creative recombination.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>philosophical proposal (augmented by later formalizations cited)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>not experimental in original proposal; motivates formal and computational work</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Original proposal is philosophical/anecdotal; later works in the paper formalize and operationalize the idea (e.g., geometric representational proposals and neural simulations consistent with concept intersections).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Hofstadter provided no direct empirical evidence; the review notes this as a philosophical proposal requiring formalization and empirical testing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Hofstadter, 1982</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6888.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Knowledge Geometry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Geometry (three-plane implicosphere projection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formal spatial knowledge representation projecting the implicosphere onto three planes (real, conceptual, symbolic) with a cultural/contextual filter translating real phenomena into conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge Geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Knowledge Geometry / Conceptual Spaces (three-plane model)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional spatial/geometric representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functionally represents knowledge in geometric form by mapping phenomena across real, conceptual, and symbolic planes; person-dependent cultural filters modulate mappings to yield individualized conceptual variations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains reification, intuition, formalization, interpretation, and deduction; models how context and individual differences shape concept instantiation and variation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical formalization (mathematical/modeling paper)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>formal modeling and conceptual analysis (no direct behavioral/neural experiment reported in the review)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Provides an operational geometric formalization of implicospheres that can account for several cognitive processes associated with mental models and prototype-like concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Formal model aligns conceptually with empirical findings but lacks direct neural or behavioral experiments in the cited work demonstrating brain-level implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>de Mello & de Carvalho, 2015</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6888.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mental Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mental Models in Conceptual Development</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model-based account that people build and manipulate internal mental models (structured, often spatial or causal representations) to reason and generate explanations, shown in developmental studies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mental Models in Conceptual Development.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Mental Models (model-based reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational/structural simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as structured internal models (often spatial or causal) that can be simulated and manipulated to answer generative questions and revise beliefs.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how people use and revise dynamic internal models to generate explanations, integrate explicit knowledge, and produce novel reasoning (including misconceptions); supports creative revision in response to inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral developmental studies / interviews</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>generative questioning, drawings and interviews about conceptual structures (e.g., children's models of the Earth)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Children and adults manipulate internal models in response to generative questions; explicit knowledge integrates with conceptual models to produce novel explanations and conceptual change over time.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Findings show that revisions of mental models can lead to persistent misconceptions, indicating model manipulation is fallible and not always normatively correct.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Vosniadou, 2002</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6888.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Emergent Binding (AHA! model)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The AHA! Experience: Emergent Binding in Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational neural-network model where high-dimensional distributed neural activity patterns representing concepts are convolved to produce emergent combined patterns associated with creative insight and the emotional 'Aha!' moment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The AHA! Experience: Creativity through Emergent Binding in Neural Networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Emergent Binding / Convolutional Combination of Neural Vectors</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional distributed neural vectors (neural simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are functionally represented as high-dimensional neural activity vectors; combining concepts is modeled by convolution/operations on these vectors producing new emergent activity patterns that correspond to novel ideas and the affective experience of discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for fluid creative combination, emergence of novel representations without symbolic manipulation, and explains affective components of insight (e.g., 'aha' responses) as emergent network dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>simulated neural activity experiments with multi-dimensional vectors and convolutional combination operations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Simulations successfully convolved simulated neural representations into novel patterns, some corresponding to heightened emotional states associated with discovery; supports the plausibility of neural collision/intersection producing creative insight.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Simulations are based on modeled neural activity rather than direct neural recordings; not all generated combinations are judged 'creative' and emotional labeling is simulated rather than measured in brains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Thagard & Stewart, 2010</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6888.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixed-Initiative Co-Creativity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixed-Initiative Co-Creativity (MI-CC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A paradigm where human and computer agents proactively collaborate on creative tasks, effectively externalizing and combining their concept spaces to explore possibility spaces and foster novel output.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mixed-initiative co- creativity.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Mixed-Initiative Co-Creativity (extended/externalized concept spaces)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hybrid externalized conceptual space / interactive symbolic & latent representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functionally models conceptual knowledge as partly externalized into interactive interfaces where human and AI concept spaces can intersect, reframe possibilities, and suggest perturbations that expand exploration of concept variations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Externalizing the mind into interfaces and allowing collision between human and AI concept spaces increases exploration of possibility spaces, leading to more novel and valuable creative output and guiding human creative paths.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>human-subject co-creative system study</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>mixed-initiative tool usage (Sentient Sketchbook) with analysis of user interactions and creative outcomes</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>User study with a co-creative level design tool showed MI-CC is useful to human users and strongly guides the creative paths they take, supporting the effectiveness of externalized/intersecting concept spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>This evidence concerns engineered external systems rather than direct neural representational evidence; effectiveness may depend on interface design and task domain.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Yannakakis et al., 2014</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6888.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6888.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Plug-and-Blend / Control Knobs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Plug-and-Blend: Plug-and-Play Controllable Story Generation with Sketches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A controllable generation framework that allows human users to steer large language model outputs via 'sketch' control knobs, enabling blending of topics and stepwise guidance of story generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Control-Knob / Controllable Latent Space Model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>parameterized latent feature space (controllable generative model)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual content is functionally represented within a generative model's latent/parameter space, where explicit control knobs (sketches) manipulate which topics or features are emphasized, enabling blending and guided generation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Provides human-interpretable controls over generative concept space enabling blending fluency and control fidelity; supports co-creative workflows and effective exploration of variations around concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational analysis and human-subject preference study</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>controllable story generation with sketches; computational metrics for blending/control plus user preference evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Computational analysis found blending fluency and control fidelity effective; a human subject study confirmed user preference for generations from the controllable system, demonstrating practical utility of control-knob representations.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Engineered demonstration shows effectiveness for story generation but does not directly demonstrate that human conceptual representations in the brain use the same controllable latent format.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Lin & Riedl, 2021</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>METAMAGICAL THEMAS. <em>(Rating: 2)</em></li>
                <li>Is There an Exemplar Theory of Concepts? <em>(Rating: 2)</em></li>
                <li>Knowledge Geometry. <em>(Rating: 2)</em></li>
                <li>The AHA! Experience: Creativity through Emergent Binding in Neural Networks. <em>(Rating: 2)</em></li>
                <li>Mental Models in Conceptual Development. <em>(Rating: 2)</em></li>
                <li>Mixed-initiative co- creativity. <em>(Rating: 2)</em></li>
                <li>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6888",
    "paper_id": "paper-258866103",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Prototype Theory",
            "name_full": "Prototype Theory of Concepts",
            "brief_description": "A theory that conceptual categories are organized around central tendency exemplars (prototypes) defined by characteristic features, with category membership graded by similarity to the prototype.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_name": "Prototype Theory",
            "theory_type": "feature-based vector",
            "theory_description": "Concepts are represented functionally as a set of characteristic features (a prototype or central tendency); membership and inference depend on similarity of an item to that feature vector or prototype.",
            "functional_claims": "Accounts for typicality gradients and graded category membership; supports induction and hierarchical structure; explains many similarity-based categorization effects.",
            "evidence_source": "behavioral literature review",
            "experimental_paradigm": "category learning and categorization tasks, typicality/induction phenomena (literature-reported paradigms)",
            "key_result": "Literature review finds phenomena (hierarchical structure, knowledge effects, induction) better explained by prototype-style feature representations than by exemplar recall.",
            "supports_theory": true,
            "counter_evidence": "The paper notes there is also robust evidence that salient exemplars influence categorization judgments, indicating exemplar effects coexist with prototype-like behavior.",
            "citation": "Murphy, 2016",
            "uuid": "e6888.0"
        },
        {
            "name_short": "Exemplar Theory",
            "name_full": "Exemplar Theory of Concepts",
            "brief_description": "A theory that conceptual categories are represented by memory of specific encountered instances (exemplars), and categorization arises from similarity to stored exemplars.",
            "citation_title": "Is There an Exemplar Theory of Concepts?",
            "mention_or_use": "mention",
            "theory_name": "Exemplar Theory",
            "theory_type": "instance-based memory",
            "theory_description": "Conceptual knowledge is functionally represented as a set of stored individual exemplars; new items are categorized by similarity comparisons to these instances rather than to an abstract prototype.",
            "functional_claims": "Explains effects of salient exemplars on categorization and some context-dependent categorization phenomena; predicts exemplar similarity will predict reaction times and choices.",
            "evidence_source": "behavioral literature review",
            "experimental_paradigm": "category learning and similarity-based categorization tasks (reported in literature reviews)",
            "key_result": "Review finds strong evidence that salient exemplars influence categorization, but little direct evidence that people recall specific exemplars to make broader conceptual inferences; exemplar models appear limited to category learning rather than general concept representation.",
            "supports_theory": false,
            "counter_evidence": "Murphy (2016) argues exemplar models fail to account for hierarchical structure, knowledge effects, and induction that characterize conceptual reasoning, suggesting exemplar theory does not generalize to full concept representations.",
            "citation": "Murphy, 2016",
            "uuid": "e6888.1"
        },
        {
            "name_short": "Implicosphere / Concept Clouds",
            "name_full": "Implicospheres (concepts as vague clouds with control knobs)",
            "brief_description": "Hofstadter's philosophical model describing concepts as vague, high-dimensional 'clouds' of possibilities with context-dependent 'control knobs' that can be varied and intersected to yield novel ideas.",
            "citation_title": "METAMAGICAL THEMAS.",
            "mention_or_use": "mention",
            "theory_name": "Implicosphere / Concept-as-Cloud",
            "theory_type": "high-dimensional space (vague continuous conceptual cloud)",
            "theory_description": "Concepts are functionally represented as continuous, context-sensitive regions ('clouds') in a possibility space with many latent parameters ('control knobs'); intersections of clouds produce blended/novel concepts.",
            "functional_claims": "Explains how subtle contextual shifts reveal different concept dimensions, enables blending/intersection to produce novel variations, and provides a substrate for subconscious creative recombination.",
            "evidence_source": "philosophical proposal (augmented by later formalizations cited)",
            "experimental_paradigm": "not experimental in original proposal; motivates formal and computational work",
            "key_result": "Original proposal is philosophical/anecdotal; later works in the paper formalize and operationalize the idea (e.g., geometric representational proposals and neural simulations consistent with concept intersections).",
            "supports_theory": null,
            "counter_evidence": "Hofstadter provided no direct empirical evidence; the review notes this as a philosophical proposal requiring formalization and empirical testing.",
            "citation": "Hofstadter, 1982",
            "uuid": "e6888.2"
        },
        {
            "name_short": "Knowledge Geometry",
            "name_full": "Knowledge Geometry (three-plane implicosphere projection)",
            "brief_description": "A formal spatial knowledge representation projecting the implicosphere onto three planes (real, conceptual, symbolic) with a cultural/contextual filter translating real phenomena into conceptual representations.",
            "citation_title": "Knowledge Geometry.",
            "mention_or_use": "mention",
            "theory_name": "Knowledge Geometry / Conceptual Spaces (three-plane model)",
            "theory_type": "high-dimensional spatial/geometric representation",
            "theory_description": "Functionally represents knowledge in geometric form by mapping phenomena across real, conceptual, and symbolic planes; person-dependent cultural filters modulate mappings to yield individualized conceptual variations.",
            "functional_claims": "Explains reification, intuition, formalization, interpretation, and deduction; models how context and individual differences shape concept instantiation and variation.",
            "evidence_source": "theoretical formalization (mathematical/modeling paper)",
            "experimental_paradigm": "formal modeling and conceptual analysis (no direct behavioral/neural experiment reported in the review)",
            "key_result": "Provides an operational geometric formalization of implicospheres that can account for several cognitive processes associated with mental models and prototype-like concepts.",
            "supports_theory": true,
            "counter_evidence": "Formal model aligns conceptually with empirical findings but lacks direct neural or behavioral experiments in the cited work demonstrating brain-level implementation.",
            "citation": "de Mello & de Carvalho, 2015",
            "uuid": "e6888.3"
        },
        {
            "name_short": "Mental Models",
            "name_full": "Mental Models in Conceptual Development",
            "brief_description": "A model-based account that people build and manipulate internal mental models (structured, often spatial or causal representations) to reason and generate explanations, shown in developmental studies.",
            "citation_title": "Mental Models in Conceptual Development.",
            "mention_or_use": "mention",
            "theory_name": "Mental Models (model-based reasoning)",
            "theory_type": "relational/structural simulation",
            "theory_description": "Conceptual knowledge is represented as structured internal models (often spatial or causal) that can be simulated and manipulated to answer generative questions and revise beliefs.",
            "functional_claims": "Explains how people use and revise dynamic internal models to generate explanations, integrate explicit knowledge, and produce novel reasoning (including misconceptions); supports creative revision in response to inconsistencies.",
            "evidence_source": "behavioral developmental studies / interviews",
            "experimental_paradigm": "generative questioning, drawings and interviews about conceptual structures (e.g., children's models of the Earth)",
            "key_result": "Children and adults manipulate internal models in response to generative questions; explicit knowledge integrates with conceptual models to produce novel explanations and conceptual change over time.",
            "supports_theory": true,
            "counter_evidence": "Findings show that revisions of mental models can lead to persistent misconceptions, indicating model manipulation is fallible and not always normatively correct.",
            "citation": "Vosniadou, 2002",
            "uuid": "e6888.4"
        },
        {
            "name_short": "Emergent Binding (AHA! model)",
            "name_full": "The AHA! Experience: Emergent Binding in Neural Networks",
            "brief_description": "A computational neural-network model where high-dimensional distributed neural activity patterns representing concepts are convolved to produce emergent combined patterns associated with creative insight and the emotional 'Aha!' moment.",
            "citation_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks.",
            "mention_or_use": "mention",
            "theory_name": "Emergent Binding / Convolutional Combination of Neural Vectors",
            "theory_type": "high-dimensional distributed neural vectors (neural simulation)",
            "theory_description": "Concepts are functionally represented as high-dimensional neural activity vectors; combining concepts is modeled by convolution/operations on these vectors producing new emergent activity patterns that correspond to novel ideas and the affective experience of discovery.",
            "functional_claims": "Accounts for fluid creative combination, emergence of novel representations without symbolic manipulation, and explains affective components of insight (e.g., 'aha' responses) as emergent network dynamics.",
            "evidence_source": "computational simulation",
            "experimental_paradigm": "simulated neural activity experiments with multi-dimensional vectors and convolutional combination operations",
            "key_result": "Simulations successfully convolved simulated neural representations into novel patterns, some corresponding to heightened emotional states associated with discovery; supports the plausibility of neural collision/intersection producing creative insight.",
            "supports_theory": true,
            "counter_evidence": "Simulations are based on modeled neural activity rather than direct neural recordings; not all generated combinations are judged 'creative' and emotional labeling is simulated rather than measured in brains.",
            "citation": "Thagard & Stewart, 2010",
            "uuid": "e6888.5"
        },
        {
            "name_short": "Mixed-Initiative Co-Creativity",
            "name_full": "Mixed-Initiative Co-Creativity (MI-CC)",
            "brief_description": "A paradigm where human and computer agents proactively collaborate on creative tasks, effectively externalizing and combining their concept spaces to explore possibility spaces and foster novel output.",
            "citation_title": "Mixed-initiative co- creativity.",
            "mention_or_use": "mention",
            "theory_name": "Mixed-Initiative Co-Creativity (extended/externalized concept spaces)",
            "theory_type": "hybrid externalized conceptual space / interactive symbolic & latent representations",
            "theory_description": "Functionally models conceptual knowledge as partly externalized into interactive interfaces where human and AI concept spaces can intersect, reframe possibilities, and suggest perturbations that expand exploration of concept variations.",
            "functional_claims": "Externalizing the mind into interfaces and allowing collision between human and AI concept spaces increases exploration of possibility spaces, leading to more novel and valuable creative output and guiding human creative paths.",
            "evidence_source": "human-subject co-creative system study",
            "experimental_paradigm": "mixed-initiative tool usage (Sentient Sketchbook) with analysis of user interactions and creative outcomes",
            "key_result": "User study with a co-creative level design tool showed MI-CC is useful to human users and strongly guides the creative paths they take, supporting the effectiveness of externalized/intersecting concept spaces.",
            "supports_theory": true,
            "counter_evidence": "This evidence concerns engineered external systems rather than direct neural representational evidence; effectiveness may depend on interface design and task domain.",
            "citation": "Yannakakis et al., 2014",
            "uuid": "e6888.6"
        },
        {
            "name_short": "Plug-and-Blend / Control Knobs",
            "name_full": "Plug-and-Blend: Plug-and-Play Controllable Story Generation with Sketches",
            "brief_description": "A controllable generation framework that allows human users to steer large language model outputs via 'sketch' control knobs, enabling blending of topics and stepwise guidance of story generation.",
            "citation_title": "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.",
            "mention_or_use": "mention",
            "theory_name": "Control-Knob / Controllable Latent Space Model",
            "theory_type": "parameterized latent feature space (controllable generative model)",
            "theory_description": "Conceptual content is functionally represented within a generative model's latent/parameter space, where explicit control knobs (sketches) manipulate which topics or features are emphasized, enabling blending and guided generation.",
            "functional_claims": "Provides human-interpretable controls over generative concept space enabling blending fluency and control fidelity; supports co-creative workflows and effective exploration of variations around concepts.",
            "evidence_source": "computational analysis and human-subject preference study",
            "experimental_paradigm": "controllable story generation with sketches; computational metrics for blending/control plus user preference evaluation",
            "key_result": "Computational analysis found blending fluency and control fidelity effective; a human subject study confirmed user preference for generations from the controllable system, demonstrating practical utility of control-knob representations.",
            "supports_theory": true,
            "counter_evidence": "Engineered demonstration shows effectiveness for story generation but does not directly demonstrate that human conceptual representations in the brain use the same controllable latent format.",
            "citation": "Lin & Riedl, 2021",
            "uuid": "e6888.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "METAMAGICAL THEMAS.",
            "rating": 2,
            "sanitized_title": "metamagical_themas"
        },
        {
            "paper_title": "Is There an Exemplar Theory of Concepts?",
            "rating": 2,
            "sanitized_title": "is_there_an_exemplar_theory_of_concepts"
        },
        {
            "paper_title": "Knowledge Geometry.",
            "rating": 2,
            "sanitized_title": "knowledge_geometry"
        },
        {
            "paper_title": "The AHA! Experience: Creativity through Emergent Binding in Neural Networks.",
            "rating": 2,
            "sanitized_title": "the_aha_experience_creativity_through_emergent_binding_in_neural_networks"
        },
        {
            "paper_title": "Mental Models in Conceptual Development.",
            "rating": 2,
            "sanitized_title": "mental_models_in_conceptual_development"
        },
        {
            "paper_title": "Mixed-initiative co- creativity.",
            "rating": 2,
            "sanitized_title": "mixedinitiative_co_creativity"
        },
        {
            "paper_title": "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches.",
            "rating": 2,
            "sanitized_title": "plugandblend_a_framework_for_plugandplay_controllable_story_generation_with_sketches"
        }
    ],
    "cost": 0.01080275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>Rohan Agarwal roaga@gatech.edu 
Georgia Institute of Technology</p>
<p>Creativity as Variations on a Theme: Formalizations, Evidence, and Engineered Applications</p>
<p>There are many philosophies and theories on what creativity is and how it works, but one popular idea is that of variations on a theme and intersection of concepts. This literature review explores philosophical proposals of how creativity emerges from variations on a theme, and how formalizations of these proposals in human subject studies and computational methods result in creativity. Specifically, the philosophical idea of intangible clouds of concepts is analyzed with empirical studies of concept representation and mental model formation, and mathematical formalizations of such ideas. Empirical findings on emergent neural activity from neural network combinations are also examined for evidence of novel, emergent ideas from the collision of existing ones. Finally, work on human-AI co-creativity is used as a lens for concept collision and the effectiveness of this model of creativity. This paper also proposes directions for further research in studying creativity as variations on a theme.</p>
<p>Introduction</p>
<p>Creativity is often said to be one of the hallmarks that make us human, and it is a trait that serves us every day, from art and music to innovative technology and problem-solving. However, it is not well understood how it works; how does the human brain be creative so effectively?</p>
<p>There are many philosophical ideas on how creativity should be modeled cognitively, but this paper examines the popular proposal that creativity results from variations on a theme. Rather than effortful creation, this model imagines existing concepts subconsciously colliding and overlapping into new, creative ones that give us the creativity we see. There is plenty of anecdotal and philosophical reasoning that supports this idea, as Hofstadter (1982) originally presented. It also serves as a valuable and unique way to think about creativity, originality, and innovation.</p>
<p>However, more formalization and empirical evidence are needed to accept it as a model of creative cognition. To do so, this paper first examines the components of this model and how it imagines mental concepts being represented and how they interact. Then, empirical studies, from both computational and psychological approaches, that examine this form of mental concept representation are reviewed. While these studies formalize concept representation, insight into concept collision is still needed. A study using simulated neural network activity is reviewed to provide evidence for this idea. The field of human-AI co-creativity is also explored as an example and potentially useful application of concept collision, and more generally, this model of creativity. It is crucial to understand how this philosophical perspective on creativity can function and benefit us in a more concrete way. Engineered co-creative applications shed light on the empirical effectiveness of this model and its translation to real-world creativity, not just its correctness with respect to human cognition. Hofstadter (1982) set out to answer the fundamental question of how humans can imagine ideas that do not already exist (i.e., to be creative and original), which are notably often sensible and valuable (like an invention, scientific theory, or a piece of a music). He claimed that creativity stems from variations on existing themes and concepts in the creator's mind. He then justified his claim through a series of thought experiments and anecdotes, which while convincing, underscore the need for scientific evidence to support this model of creativity. First, acknowledging that he lacked a scientific model for what a concept is, he imagined a concept as a box with control knobs used to vary different attributes of the concept. By imagining the consequences of that metaphor for musical compositions and n-dimensional Rubik's Cubes, he concluded that a concept has an infinite number of knobs which reveal themselves depending on the concepts in the mind of the person. He noted how one person can vary a theme to create an idea, but others can still take that idea and vary it infinitely further (Hofstadter, 1982).</p>
<p>Review</p>
<p>Philosophical Proposal</p>
<p>Hofstadter then proposed subconscious slipping and blending between concepts as the source of these variations, changing the mental context and revealing different sets of knobs to the mind. He modeled concepts as vague clouds representing the possible set of variations and slipping as the intersection of multiple clouds. It is also notable that he advocated for using computers to help humans explore these possibility spaces, which he termed "implicospheres" (Hofstadter, 1982). In summary, the model of creativity proposed here is that of subconscious possibility spaces around concepts, built through manipulatable, context-dependent parameters, that intersect to yield new variations and concepts. Hofstadter, however, provides no scientific basis for this representation of concepts or their blending, so formal studies are now presented. Vosniadou (2002) investigated mental models in concept development and reasoning in children, arguing they are a core part of human cognition. She first analyzed their construction by having children draw and answer generative questions about their model of the Earth. Through further generative questioning (e.g., where would you end up if you walked forever?), the children were manipulating their models with imaginary scenarios to answer the questions. It was found that explicit knowledge can integrate with the conceptual model to create novel explanations and further conceptual knowledge. In fact, this is done over time as new information creates new theories in the mind and lets mental models be tweaked and revised.</p>
<p>Scientific Basis for Variations on a Theme as Creativity</p>
<p>Vosniadou also presented other interviews with adults that highlight how when faced with inconsistencies in their mental model, people creatively revise their model to solve the problem (often leading to misconceptions). The existing mental model in mind determines how new information is interpreted and conceptualized (Vosniadou, 2002). These findings support the idea of iteratively tweaking and growing concepts, and the power of concepts in generating novel creative ideas, especially when trying to integrate new information.</p>
<p>However, this does not answer how mental models are represented in the brain. Two main theories of concepts are the prototype theory, where categories are defined based on sets of characteristic features, and the exemplar theory, where categories are defined by encountered instances of the category (Murphy, 2016). Murphy (2016) conducted a literature review on both theories and psychological findings surrounding concepts. While there is strong evidence for salient exemplars influencing categorization, he found lackluster evidence on recalling specific exemplars to decide categorization. Murphy (2016) highlights several phenomena that have prototype explanations but no exemplar explanation, such as hierarchical structure of concepts, knowledge effects, and induction. In fact, since exemplar models in the literature seemed to only apply to category learning, and not concepts (i.e., mental models that can be used for learning, communication, and reasoning, as Vosniadou (2002) demonstrated), he argued that there is no exemplar theory of concepts at all (Murphy, 2016). If the prototype theory, or representing concepts through their features, is more accurate to human cognition, then that aligns well with the proposal of variations on a theme. It implies that concepts really are built around a central set of attributes that, if adjusted, can yield new variations of a concept and even new concepts entirely.</p>
<p>Such a model can also be mathematically formalized. Based on the idea of the implicosphere (Hofstadter, 1982), researchers designed a spatial knowledge representation based on projecting the implicosphere onto three planes: the real, the conceptual, and the symbolic (de Mello and de Carvalho, 2015). A cultural filter, or person-dependent context as Hofstadter (1982) described it, was used to transfer real-world phenomena to the conceptual plane, creating different variations of concepts for different people. The authors also demonstrated how this three-plane model can be used to explain reification (imagining new ideas from abstracted concepts), intuition, formalization, interpretation, and deduction of concepts (de Mello and de Carvalho, 2015). This work formalizes the idea of variations on a theme and demonstrates its usefulness for modeling many creative and cognitive tasks, which include key abilities found to apply to mental models (Vosniadou, 2002) and the prototype theory of concepts (Murphy, 2016).</p>
<p>This formalization shows that this model of creativity can align effectively with empirical findings on the subject.</p>
<p>More than just concept representation, though, how concepts collide to cause creative output is important to this theory of creativity. While concept combination has been successfully shown with symbolic representations in the past, Thagard and Stewart (2010) demonstrated its more generalizable potential with neural activity-in particular, by using convolution to combine vectors represented neural activity patterns. Their neural representations, more than symbolic/verbal ones, facilitated the fluid creative thinking Hofstadter described (Thagard and Stewart, 2010). The authors first devised a multi-dimensional vector representation of neural activity by multiplying the number of neurons to handle their stochasticity. Then they successfully convolved multiple representations of simulated neural activity into new ones, including patterns that correspond to the heightened emotions upon a creative discovery (e.g., an "aha!" or "eureka!" moment). These simulations provided evidence for the intersection of multimodal concepts in the brain leading to original ideas and a sense of creative discovery. The authors also stated that not every combination will be considered "creative," as Hofstadter (1982) also pointed out for the collision of implicospheres. However, the ones accompanied by the emotional experience of discovery likely are what we consider creative (Thagard and Stewart, 2010). This study directly supports the proposal that the collision of concepts in the brain is the source of creativity, not only in the outputted ideas, but also in the sense in which humans emotionally experience it.</p>
<p>Co-Creativity as a Lens</p>
<p>While all these studies provide great insight into the plausibility of this model of creativity, it is also valuable to consider concrete examples of how it enables creativity. Yannakakis et. al. (2014) introduced the paradigm of mixed-initiative co-creativity (MI-CC):</p>
<p>when a human and a computer both proactively collaborate on a creative work, like a story or a video game level. Reframing parts of the possibility space and introducing random stimulus are found to foster the creative process and creative output. The user of a co-creative system often has a diagram or user interface that serves as an extension of their mind, and facilitates creative, lateral thinking (Yannakakis, 2014). Effectively, the AI agent's concept space and the user's concept space collide and interact on this diagram; later works even outline multiple dimensions for such interactions, as if in 3D space, and modularize the different parts of this extended mind (Lin et. al, 2022). Yannakakis et. al. (2014) argued that this interaction (usually suggestions and iterative co-creation) facilitates greater exploration of the possibility space, leading to more novel and valuable creative output. Using a human subject study with a co-creative level design tool called Sentient Sketchbook, analysis of usage of the tool led to the conclusion that MI-CC is useful to human users and strongly guides the creative paths they take (Yannakakis, 2014). While this study is not about creative within the human mind, it demonstrates that when the human mind is effectively extended onto an external diagram, introducing new context, suggesting new ideas and concepts, and exploring the possibility space or variations around a concept lead to superior creative process and output. It is an engineered example that shows that the variations on a theme model is in fact an effective and valuable source of creativity.</p>
<p>In addition, MI-CC takes great advantage of "control knobs" similar to Hofstadter's (1982) metaphor for varying the features on a concept. For example, Lin and Riedl (2021) introduced a control knob system for guiding the story generation of a large language model. By providing a "sketch," a human user can guide the topics of a generated story, sentence by sentence. Not only does this framework allow for control knobs, but also blending of topics and concepts in the generation. Blending fluency and control fidelity were found to be effective through computational analysis, and a human subject study confirmed preference for the generations from this system. The authors envisioned their system being used for co-creative applications, as it was in Lin et. al. (2022). The system is remarkably similar to Hofstadter's (1982) metaphor of control knobs on a black box and blending of concepts to generate creative output. The study proves the possibility and effectiveness of a system based on these proposals.</p>
<p>Discussion</p>
<p>Summary</p>
<p>Variations on a theme as the source of creativity is a common model of how human creativity works, but without empirical evidence, it remained an anecdotal and philosophical one.</p>
<p>This paper presented studies that do provide substantial support for this theory, as originally proposed by Hofstadter (1982). Research into how we form and use mental models (Vosniadou, 2002) showed how they can grow, be manipulated, and used to produce novel, creative ideas in response to new context. Further literature review lent support to the prototype theory of concepts (Murphy, 2016), meaning we form concepts around characteristic features which can vary, similar to Hofstadter's idea of implicospheres (Hofstadter, 1982). While Hofstadter's (1982) theory may seem vague and unscientific, implicospheres and changing context can be used as a basis for geometric knowledge representations that explain core creative processes (de Mello and de Carvalho, 2015).</p>
<p>With evidence for variable features forming concepts and leading to creativity, there is also evidence for the intersection of concepts and its benefits for creativity. Thagard and Stewart (2010) demonstrated that multiple neural activity patterns, representing concepts, can be fluidly interweaved into novel activity and lead to the emotional "aha!" moment we often get upon a creative discovery. The field of mixed-initiative co-creativity also lends great support to the creative usefulness of this idea. Yannakakis et. al. (2014) demonstrated that when humans and AI proactively collaborate on creative tasks, effectively extending the mind of the human and introducing new context, the possible variations are better explored, and creativity is fostered.</p>
<p>This paradigm also makes extensive use of control knobs and blending concepts like what Hofstadter (1982) proposed, as shown by Lin and Riedl's (2021) controllable story generation model. Overall, there is evidence in diverse areas of scientific literature for variations on a theme being the source of human creativity, and an effective method for achieving creativity in engineered applications, including creative AI.</p>
<p>Limitations and Future Research</p>
<p>While there is substantial support, the question of the nature of human creativity is not settled. All the literature reviewed has only been able to answer that question through indirect observation, because it is near impossible to parse the inner workings of the brain otherwise.</p>
<p>There is still no clear-cut answer to how creativity works, and other theories could also be supported with the same studies. Additionally, all the studies that involve creative output-whether learning how the Earth works, new (but illegible) neural patterns, or video game levels-are very small examples of creativity compared to the most grand and valuable examples of scientific discovery, artistry, or innovation. In case creative cognition changes depending on the quality or scale of creative output, future work should aim to produce more valuable creative works or capture insights from those who do (perhaps through a longitudinal study). Some people are also more creative personality-wise, more successfully creative, or have different creative processes and styles. Further investigation is also needed in identifying how cognition varies between people-can one theory apply to everyone and everything we consider creative?</p>
<p>Knowledge Geometry. Flvio De Mello, Roberto Lins De Luis, Carvalho, 10.1142/s0219649215500288Journal of Information &amp; Knowledge Management. 14041550028de Mello, Flvio Luis, and Roberto Lins de Carvalho. "Knowledge Geometry." Journal of Information &amp; Knowledge Management 14, no. 04 (2015): 1550028. https://doi.org/10.1142/s0219649215500288.</p>
<p>. Douglas R &quot; Hofstadter, Metamagical Themas, Scientific American. 2474Hofstadter, Douglas R. "METAMAGICAL THEMAS." Scientific American 247, no. 4 (1982): 20-31. http://www.jstor.org/stable/24966697.</p>
<p>Plug-and-blend: a framework for plug-and-play controllable story generation with sketches. Zhiyu Lin, Mark O Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment17Lin, Zhiyu, and Mark O. Riedl. "Plug-and-blend: a framework for plug-and-play controllable story generation with sketches." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 17, no. 1, pp. 58-65. 2021.</p>
<p>Creative Wand: A System to Study Effects of Communications in Co-creative Settings. Zhiyu Lin, Rohan Agarwal, Mark Riedl, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment18Lin, Zhiyu, Rohan Agarwal, and Mark Riedl. "Creative Wand: A System to Study Effects of Communications in Co-creative Settings." In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, vol. 18, no. 1, pp. 45-52. 2022.</p>
<p>Is There an Exemplar Theory of Concepts?. Gregory L Murphy, 10.3758/s13423-015-0834-3Psychonomic Bulletin &amp; Review. 234Murphy, Gregory L. "Is There an Exemplar Theory of Concepts?" Psychonomic Bulletin &amp; Review 23, no. 4 (2016): 1035-42. https://doi.org/10.3758/s13423-015-0834-3.</p>
<p>The AHA! Experience: Creativity through Emergent Binding in Neural Networks. Paul Thagard, Terrence C Stewart, 10.1111/j.1551-6709.2010.01142.xCognitive Science. 351Thagard, Paul, and Terrence C. Stewart. "The AHA! Experience: Creativity through Emergent Binding in Neural Networks." Cognitive Science 35, no. 1 (2010): 1-33. https://doi.org/10.1111/j.1551-6709.2010.01142.x.</p>
<p>Mental Models in Conceptual Development. Stella Vosniadou, 10.1007/978-1-4615-0605-8_20Model-Based ReasoningVosniadou, Stella. "Mental Models in Conceptual Development." Model-Based Reasoning, 2002, 353-68. https://doi.org/10.1007/978-1-4615-0605-8_20.</p>
<p>Mixed-initiative cocreativity. Georgios N Yannakakis, Antonios Liapis, Constantine Alexopoulos, Yannakakis, Georgios N., Antonios Liapis, and Constantine Alexopoulos. "Mixed-initiative co- creativity." (2014).</p>            </div>
        </div>

    </div>
</body>
</html>