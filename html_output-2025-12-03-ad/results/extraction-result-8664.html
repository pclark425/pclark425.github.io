<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8664 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8664</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8664</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-155.html">extraction-schema-155</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-281526344</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.15141v2.pdf" target="_blank">Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation</a></p>
                <p><strong>Paper Abstract:</strong> Identifying reaction conditions that are broadly applicable across diverse substrates is a longstanding challenge in chemical and pharmaceutical research. While many methods are available to generate conditions with acceptable performance, a universal approach for reliably discovering effective conditions during reaction exploration is rare. Consequently, current reaction optimization processes are often labor-intensive, time-consuming, and costly, relying heavily on trial-and-error experimentation. Nowadays, large language models (LLMs) are capable of tackling chemistry-related problems, such as molecule design and chemical reasoning tasks. Here, we report the design, implementation and application of Chemma-RC, a text-augmented multimodal LLM to identify effective conditions through task-specific dialogue and condition generation. Chemma-RC learns a unified representation of chemical reactions by aligning multiple modalities-including text corpus, reaction SMILES, and reaction graphs-within a shared embedding module. Performance benchmarking on datasets showed high precision in identifying optimal conditions, with up to 17% improvement over the current state-of-the-art methods. A palladium-catalysed imidazole C-H arylation reaction was investigated experimentally to evaluate the functionalities of the Chemma-RC in practice. Our findings suggest that Chemma-RC holds significant potential to accelerate high-throughput condition screening in chemical synthesis.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8664.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8664.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chemma-RC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chemma-RC (Text-Augmented Multimodal LLM for Chemical Reaction Condition Prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multimodal autoregressive large language model that jointly learns representations from reaction SMILES, reaction graphs, and text corpus to generate reaction conditions (solvents, reagents, catalysts) as SMILES/tokens and rank condition candidates for high-yield outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Chemma-RC</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>multimodal transformer-based LLM (text decoder + modality alignment via Perceiver modules)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>LLLaMA-2-7b backbone (7B total params); ~0.3B trainable LoRA parameters during fine-tuning (reported)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on USPTO-Condition and USPTO_500MT_Condition reaction datasets augmented with retrieved textual corpus (per-reaction paragraphs), reaction SMILES and reaction graphs; post-fine-tuned with HTE (high-throughput experimentation) ligand-yield data for ranking enhancement.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Chemical synthesis: reaction condition prediction and high-throughput ligand selection (catalysis), aimed at accelerating condition screening in organic synthesis and HTE workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Autoregressive generation of condition tokens/SMILES within an LLM decoder (LLaMA-2) after modality alignment; uses multimodal supervised fine-tuning (SFT) with text-augmented instruction prompts and a second-stage Ranking Enhancement with Feedback (REF) using HTE yield-ranked candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not framed as de novo molecular discovery; model generates reagents/solvents/ligands as SMILES or from candidate spaces. No explicit novelty metrics (e.g., fraction novel vs training set, Tanimoto similarity) are reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Specificity is achieved by (i) conditioning on the joint multimodal reaction representation (SMILES + graph + retrieved corpus) and task-specific instruction prompts; and (ii) REF post-fine-tuning trained on HTE datasets so the model ranks/generates conditions optimized for high experimental yields.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-k exact-match accuracy (top-1/top-3/top-10/top-15), partial-match accuracy (component-level), precision, recall; HTE-specific ligand selection accuracy (top-1 and top-50% metrics), and out-of-distribution partial-match accuracy in cross-dataset evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Chemma-RC outperforms baselines on reaction condition prediction: e.g., on USPTO-Condition it yields improvements over TextReact (~+7% overall) with top-1 accuracies such as catalyst 92.7% and solvent1 54.6%. On USPTO_500MT_Condition zero-shot top-1 = 25.9% (vs ChemDFM 2.0%). In a Pd-catalysed imidazole C–H arylation HTE ligand selection task, Chemma-RC achieved 93.7% top-1 ligand selection accuracy vs a comparison model at 38.1%. Ablations show benefit from combining SMILES + corpus and modest additional gains from graphs especially for very large/complex substrates.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Directly compared to rxnfp LSTM, Parrot, TextReact, Reagent Transformer, Reaction GCNN, ChemDFM and general LLMs (GPT-4o, DeepSeek-V2, LLaMA3-70B). Chemma-RC shows higher top-k and partial accuracies across datasets and stronger OOD generalization, attributed to multimodal alignment and ranking enhancement.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Paper-reported limitations include: increased computational cost when including graph modality with limited aggregated gains for common tasks; data sparsity and long-tail distributions (many rare reagents/solvents) that limit generalization; the intrinsic 'one-to-many' nature of reactions complicates identification of single optimal conditions; safety and feasibility concerns when deploying generated conditions in autonomous platforms; trade-offs between computational efficiency and predictive performance. No explicit measures of chemical synthesizability or novelty were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8664.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2-7b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2 (7B parameter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7-billion-parameter autoregressive transformer LLM used in this work as the text-decoder backbone that generates condition text and SMILES tokens after multimodal alignment and fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>autoregressive transformer LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7 billion parameters (backbone reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper (pretrained LLaMA-2 weights used as backbone); fine-tuned with multimodal SFT and LoRA on chemical instruction datasets derived from USPTO corpora and retrieved textual paragraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used as the decoder to generate chemical condition tokens/SMILES for reaction condition prediction and ligand selection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompted/instruction-conditioned autoregressive generation of tokens; learned to accept modality-aligned latent tokens representing SMILES and graphs and produce condition outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported; used as a generative backend to produce condition tokens rather than to optimize for molecular novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Specialized toward condition generation via multimodal fine-tuning (alignment + SFT) and REF ranking; task-specific instruction prompts were used.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Part of the Chemma-RC evaluation pipeline; metrics reported at system level (top-k, partial accuracy, HTE ligand selection) reflect LLaMA-2's fine-tuned generation performance within Chemma-RC.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>As the backbone for Chemma-RC, LLaMA-2-7b enables the model to generate condition SMILES and textual answers; LoRA parameter-efficient fine-tuning of ~0.3B parameters was used to avoid full model fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Paper notes that sequence-based LLMs pretrained/fine-tuned only on text struggle on SMILES/reaction tasks relative to domain-specific graph/SMILES models unless integrated with modality-specific encoders and alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Pretrained text LLMs have difficulty with SMILES and graph-structured chemical data without dedicated alignment/encoders; purely sequence LLMs underperform on detailed molecular-design tasks unless multimodalized.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8664.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (used for prompt generation & related work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art general-purpose generative LLM referenced in the paper and used by the authors to generate diverse question templates/prompts for constructing multimodal instruction datasets; also cited in related work for autonomous experimental agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>autoregressive transformer LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not reported in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used to generate diverse instruction-style question prompts for dataset augmentation; cited in related work as enabling agents that plan/perform experiments or assist chemical workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt generation for dataset construction (GPT-4 produced question templates and prompt variants used in SFT data).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not applicable in this paper (GPT-4 used for prompt/text generation rather than chemical structure generation).</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Induced diversity of instruction prompts to help the multimodal LLM (Chemma-RC) generalize to varied Q&A styles; not used to directly design molecules in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>No direct evaluation reported for prompts produced by GPT-4; system-level metrics reflect downstream model performance after training with GPT-4-generated prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT-4 was used to expand the variety of instruction prompts for multimodal supervised fine-tuning; the paper reports that using varied prompts contributed to training but does not quantify prompt-generation performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>General-purpose LLMs such as GPT-4 are powerful text generators but, per the paper, lack deep SMILES/graph understanding and thus underperform on raw molecular tasks unless augmented with domain-specific encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>When used alone (text-only), general LLMs show lower performance on SMILES/reaction tasks; they need multimodal augmentation or external chemistry tools to be effective for molecular design/prediction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8664.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemDFM (chemical domain foundation model / LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large chemistry-focused LLM trained on extensive chemical literature and textbooks and fine-tuned with chemical instructions; used in this paper as a baseline to evaluate zero-/few-shot condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer-based large language model specialized for chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Training reported on ~34B tokens (chemical literature/text); parameter count not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pretrained on chemical literature and textbooks (34B tokens) and fine-tuned on ~2.7M instructions (as reported in the paper's description of ChemDFM).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General chemical language tasks and instruction-following in chemistry; evaluated here for reaction condition generation (zero-/one-/few-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Instruction-tuned autoregressive generation (zero/one/few-shot prompting evaluated).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported here; evaluation focused on condition-prediction accuracy rather than novelty or de novo molecule generation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Designed to be a general-purpose chemistry LLM via large-scale chemical text pretraining and instruction tuning; in this study, evaluated on condition generation but performed poorly in zero-shot settings on structured SMILES/condition generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact-match accuracy and partial accuracy on USPTO_500MT_Condition (zero-/one-/five-shot settings) as reported in the paper's baseline table.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>ChemDFM scored low on USPTO_500MT_Condition zero-shot top-1 exact accuracy (reported as 2.0% in the paper's baseline comparisons), substantially lower than Chemma-RC's zero-shot performance (25.9%) in the same dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Despite large-scale chemical-text pretraining, ChemDFM underperforms specialized multimodal models like Chemma-RC on structured reaction condition generation, highlighting limits of text-only pretraining for SMILES/graph-structured chemistry tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Text-only pretraining at scale does not guarantee strong performance on SMILES- and graph-centric chemistry generation tasks; lacks integrated modality-specific encoders and contrastive alignment used by Chemma-RC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8664.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boiko et al. GPT-4 agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4-driven scientific agent system for autonomous experimentation (Boiko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned related work describing a GPT-4-driven agent that plans and performs complex experiments to accelerate reaction condition screening and experimental automation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4-driven scientific agent (as reported by Boiko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM-driven agentic system (transformer LLM paired with experimental tools/workflow automation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not detailed in this paper (referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Autonomous experimental planning and execution for chemistry; reaction condition screening and experimental automation.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM-driven planning and instruction-generation, integrated with experimental tools to design and execute steps in lab workflows (as summarized in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported here; referenced as a system to accelerate screening rather than de novo molecule discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Targets practical experimental workflows and condition optimization across chemical reactions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not provided in this paper; consult the referenced Boiko et al. work for details.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited as an example of LLMs being applied to accelerate reaction condition screening and automation; this paper positions Chemma-RC as complementary (focused on predictive condition generation rather than experiment execution).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Referenced to illustrate use of general LLMs in experimental agents; no direct comparison within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Cited generally; the authors emphasize that LLM-driven agents still face challenges in precise SMILES/graph understanding and ensuring safety/feasibility in autonomous execution.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8664.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow (LLM augmented with chemistry tools)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned related work that augments large language models with chemistry-specific expert-designed tools to improve chemical task performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting large language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemCrow (LLM + tool augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Tool-augmented LLM system (transformer LLM + domain tools)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Chemical assistance tasks (planning, information retrieval, possibly molecule-related tasks) when combined with domain tools.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Augmentation: LLM calls out to chemistry tools designed by experts to perform tasks beyond plain text generation.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Designed to improve LLM performance on chemistry tasks via tool usage.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Referenced as an approach to overcome limitations of pure LLMs on chemistry tasks; no direct experimental comparison in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Mentioned alongside other works that seek to improve LLM chemical capabilities (e.g., tool augmentation vs multimodal alignment).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Paper notes that tool-augmentation is one strategy; Chemma-RC instead pursues multimodal representation alignment to better handle SMILES/graph data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8664.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8664.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>General-purpose LLM baselines (DeepSeek-V2, GPT-4o, LLaMA3-70B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepSeek-V2 / GPT-4o / LLaMA3-70B (general LLM baselines evaluated for condition generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Several general-purpose LLMs evaluated in zero/one/few-shot settings as baselines for reaction condition generation; they perform substantially worse than Chemma-RC on structured SMILES/condition tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepSeek-V2, GPT-4o, LLaMA3-70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Large transformer-based LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Varies (LLaMA3-70B = 70B parameters; others not specified in-paper)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper (pretrained general corpora for each model).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Evaluated for chemical condition generation under zero-/one-/few-shot prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-based generation (zero/one/few-shot) producing condition strings/SMILES via API/inference.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported; primary evaluation was accuracy of reproducing known conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>General LLMs not specialized for SMILES/graph chemical representations; authors report poor performance on structured condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact-match accuracy, partial accuracy, recall, precision as reported in baseline tables.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Reported low top-1 exact-match accuracies (e.g., many near-zero or single-digit percentages) on USPTO_500MT_Condition in zero-shot/one-shot settings; highlight need for domain adaptation/multimodality.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Underperformed domain-specialized multimodal methods such as Chemma-RC and SMILES/graph-augmented models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>General LLMs struggle with formatting and correctness of SMILES and structured concatenated condition strings without domain-specific encoders or alignment; few-shot prompting gives limited gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Augmenting large language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>Developing ChemDFM as a large language foundation model for chemistry <em>(Rating: 2)</em></li>
                <li>Predictive Chemistry Augmented with Text Retrieval <em>(Rating: 2)</em></li>
                <li>Parrot: (as cited by Wang et al.) (attention-based reaction encoder) <em>(Rating: 1)</em></li>
                <li>What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8664",
    "paper_id": "paper-281526344",
    "extraction_schema_id": "extraction-schema-155",
    "extracted_data": [
        {
            "name_short": "Chemma-RC",
            "name_full": "Chemma-RC (Text-Augmented Multimodal LLM for Chemical Reaction Condition Prediction)",
            "brief_description": "A multimodal autoregressive large language model that jointly learns representations from reaction SMILES, reaction graphs, and text corpus to generate reaction conditions (solvents, reagents, catalysts) as SMILES/tokens and rank condition candidates for high-yield outcomes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Chemma-RC",
            "model_type": "multimodal transformer-based LLM (text decoder + modality alignment via Perceiver modules)",
            "model_size": "LLLaMA-2-7b backbone (7B total params); ~0.3B trainable LoRA parameters during fine-tuning (reported)",
            "training_data": "Fine-tuned on USPTO-Condition and USPTO_500MT_Condition reaction datasets augmented with retrieved textual corpus (per-reaction paragraphs), reaction SMILES and reaction graphs; post-fine-tuned with HTE (high-throughput experimentation) ligand-yield data for ranking enhancement.",
            "application_domain": "Chemical synthesis: reaction condition prediction and high-throughput ligand selection (catalysis), aimed at accelerating condition screening in organic synthesis and HTE workflows.",
            "generation_method": "Autoregressive generation of condition tokens/SMILES within an LLM decoder (LLaMA-2) after modality alignment; uses multimodal supervised fine-tuning (SFT) with text-augmented instruction prompts and a second-stage Ranking Enhancement with Feedback (REF) using HTE yield-ranked candidates.",
            "novelty_of_chemicals": "Not framed as de novo molecular discovery; model generates reagents/solvents/ligands as SMILES or from candidate spaces. No explicit novelty metrics (e.g., fraction novel vs training set, Tanimoto similarity) are reported in the paper.",
            "application_specificity": "Specificity is achieved by (i) conditioning on the joint multimodal reaction representation (SMILES + graph + retrieved corpus) and task-specific instruction prompts; and (ii) REF post-fine-tuning trained on HTE datasets so the model ranks/generates conditions optimized for high experimental yields.",
            "evaluation_metrics": "Top-k exact-match accuracy (top-1/top-3/top-10/top-15), partial-match accuracy (component-level), precision, recall; HTE-specific ligand selection accuracy (top-1 and top-50% metrics), and out-of-distribution partial-match accuracy in cross-dataset evaluations.",
            "results_summary": "Chemma-RC outperforms baselines on reaction condition prediction: e.g., on USPTO-Condition it yields improvements over TextReact (~+7% overall) with top-1 accuracies such as catalyst 92.7% and solvent1 54.6%. On USPTO_500MT_Condition zero-shot top-1 = 25.9% (vs ChemDFM 2.0%). In a Pd-catalysed imidazole C–H arylation HTE ligand selection task, Chemma-RC achieved 93.7% top-1 ligand selection accuracy vs a comparison model at 38.1%. Ablations show benefit from combining SMILES + corpus and modest additional gains from graphs especially for very large/complex substrates.",
            "comparison_to_other_methods": "Directly compared to rxnfp LSTM, Parrot, TextReact, Reagent Transformer, Reaction GCNN, ChemDFM and general LLMs (GPT-4o, DeepSeek-V2, LLaMA3-70B). Chemma-RC shows higher top-k and partial accuracies across datasets and stronger OOD generalization, attributed to multimodal alignment and ranking enhancement.",
            "limitations_and_challenges": "Paper-reported limitations include: increased computational cost when including graph modality with limited aggregated gains for common tasks; data sparsity and long-tail distributions (many rare reagents/solvents) that limit generalization; the intrinsic 'one-to-many' nature of reactions complicates identification of single optimal conditions; safety and feasibility concerns when deploying generated conditions in autonomous platforms; trade-offs between computational efficiency and predictive performance. No explicit measures of chemical synthesizability or novelty were reported.",
            "uuid": "e8664.0",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "LLaMA-2-7b",
            "name_full": "LLaMA-2 (7B parameter)",
            "brief_description": "A 7-billion-parameter autoregressive transformer LLM used in this work as the text-decoder backbone that generates condition text and SMILES tokens after multimodal alignment and fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7b",
            "model_type": "autoregressive transformer LLM",
            "model_size": "7 billion parameters (backbone reported in paper)",
            "training_data": "Not specified in this paper (pretrained LLaMA-2 weights used as backbone); fine-tuned with multimodal SFT and LoRA on chemical instruction datasets derived from USPTO corpora and retrieved textual paragraphs.",
            "application_domain": "Used as the decoder to generate chemical condition tokens/SMILES for reaction condition prediction and ligand selection tasks.",
            "generation_method": "Prompted/instruction-conditioned autoregressive generation of tokens; learned to accept modality-aligned latent tokens representing SMILES and graphs and produce condition outputs.",
            "novelty_of_chemicals": "Not reported; used as a generative backend to produce condition tokens rather than to optimize for molecular novelty.",
            "application_specificity": "Specialized toward condition generation via multimodal fine-tuning (alignment + SFT) and REF ranking; task-specific instruction prompts were used.",
            "evaluation_metrics": "Part of the Chemma-RC evaluation pipeline; metrics reported at system level (top-k, partial accuracy, HTE ligand selection) reflect LLaMA-2's fine-tuned generation performance within Chemma-RC.",
            "results_summary": "As the backbone for Chemma-RC, LLaMA-2-7b enables the model to generate condition SMILES and textual answers; LoRA parameter-efficient fine-tuning of ~0.3B parameters was used to avoid full model fine-tuning.",
            "comparison_to_other_methods": "Paper notes that sequence-based LLMs pretrained/fine-tuned only on text struggle on SMILES/reaction tasks relative to domain-specific graph/SMILES models unless integrated with modality-specific encoders and alignment.",
            "limitations_and_challenges": "Pretrained text LLMs have difficulty with SMILES and graph-structured chemical data without dedicated alignment/encoders; purely sequence LLMs underperform on detailed molecular-design tasks unless multimodalized.",
            "uuid": "e8664.1",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-4 (used for prompt generation & related work)",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A state-of-the-art general-purpose generative LLM referenced in the paper and used by the authors to generate diverse question templates/prompts for constructing multimodal instruction datasets; also cited in related work for autonomous experimental agents.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_type": "autoregressive transformer LLM",
            "model_size": "Not reported in this paper",
            "training_data": "Not specified in this paper",
            "application_domain": "Used to generate diverse instruction-style question prompts for dataset augmentation; cited in related work as enabling agents that plan/perform experiments or assist chemical workflows.",
            "generation_method": "Prompt generation for dataset construction (GPT-4 produced question templates and prompt variants used in SFT data).",
            "novelty_of_chemicals": "Not applicable in this paper (GPT-4 used for prompt/text generation rather than chemical structure generation).",
            "application_specificity": "Induced diversity of instruction prompts to help the multimodal LLM (Chemma-RC) generalize to varied Q&A styles; not used to directly design molecules in this work.",
            "evaluation_metrics": "No direct evaluation reported for prompts produced by GPT-4; system-level metrics reflect downstream model performance after training with GPT-4-generated prompts.",
            "results_summary": "GPT-4 was used to expand the variety of instruction prompts for multimodal supervised fine-tuning; the paper reports that using varied prompts contributed to training but does not quantify prompt-generation performance.",
            "comparison_to_other_methods": "General-purpose LLMs such as GPT-4 are powerful text generators but, per the paper, lack deep SMILES/graph understanding and thus underperform on raw molecular tasks unless augmented with domain-specific encoders.",
            "limitations_and_challenges": "When used alone (text-only), general LLMs show lower performance on SMILES/reaction tasks; they need multimodal augmentation or external chemistry tools to be effective for molecular design/prediction tasks.",
            "uuid": "e8664.2",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "ChemDFM",
            "name_full": "ChemDFM (chemical domain foundation model / LLM)",
            "brief_description": "A large chemistry-focused LLM trained on extensive chemical literature and textbooks and fine-tuned with chemical instructions; used in this paper as a baseline to evaluate zero-/few-shot condition generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChemDFM",
            "model_type": "transformer-based large language model specialized for chemistry",
            "model_size": "Training reported on ~34B tokens (chemical literature/text); parameter count not specified in this paper",
            "training_data": "Pretrained on chemical literature and textbooks (34B tokens) and fine-tuned on ~2.7M instructions (as reported in the paper's description of ChemDFM).",
            "application_domain": "General chemical language tasks and instruction-following in chemistry; evaluated here for reaction condition generation (zero-/one-/few-shot).",
            "generation_method": "Instruction-tuned autoregressive generation (zero/one/few-shot prompting evaluated).",
            "novelty_of_chemicals": "Not reported here; evaluation focused on condition-prediction accuracy rather than novelty or de novo molecule generation.",
            "application_specificity": "Designed to be a general-purpose chemistry LLM via large-scale chemical text pretraining and instruction tuning; in this study, evaluated on condition generation but performed poorly in zero-shot settings on structured SMILES/condition generation tasks.",
            "evaluation_metrics": "Top-1 exact-match accuracy and partial accuracy on USPTO_500MT_Condition (zero-/one-/five-shot settings) as reported in the paper's baseline table.",
            "results_summary": "ChemDFM scored low on USPTO_500MT_Condition zero-shot top-1 exact accuracy (reported as 2.0% in the paper's baseline comparisons), substantially lower than Chemma-RC's zero-shot performance (25.9%) in the same dataset.",
            "comparison_to_other_methods": "Despite large-scale chemical-text pretraining, ChemDFM underperforms specialized multimodal models like Chemma-RC on structured reaction condition generation, highlighting limits of text-only pretraining for SMILES/graph-structured chemistry tasks.",
            "limitations_and_challenges": "Text-only pretraining at scale does not guarantee strong performance on SMILES- and graph-centric chemistry generation tasks; lacks integrated modality-specific encoders and contrastive alignment used by Chemma-RC.",
            "uuid": "e8664.3",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Boiko et al. GPT-4 agent",
            "name_full": "GPT-4-driven scientific agent system for autonomous experimentation (Boiko et al.)",
            "brief_description": "Mentioned related work describing a GPT-4-driven agent that plans and performs complex experiments to accelerate reaction condition screening and experimental automation.",
            "citation_title": "Autonomous chemical research with large language models",
            "mention_or_use": "mention",
            "model_name": "GPT-4-driven scientific agent (as reported by Boiko et al.)",
            "model_type": "LLM-driven agentic system (transformer LLM paired with experimental tools/workflow automation)",
            "model_size": null,
            "training_data": "Not detailed in this paper (referenced work)",
            "application_domain": "Autonomous experimental planning and execution for chemistry; reaction condition screening and experimental automation.",
            "generation_method": "LLM-driven planning and instruction-generation, integrated with experimental tools to design and execute steps in lab workflows (as summarized in related work).",
            "novelty_of_chemicals": "Not reported here; referenced as a system to accelerate screening rather than de novo molecule discovery.",
            "application_specificity": "Targets practical experimental workflows and condition optimization across chemical reactions.",
            "evaluation_metrics": "Not provided in this paper; consult the referenced Boiko et al. work for details.",
            "results_summary": "Cited as an example of LLMs being applied to accelerate reaction condition screening and automation; this paper positions Chemma-RC as complementary (focused on predictive condition generation rather than experiment execution).",
            "comparison_to_other_methods": "Referenced to illustrate use of general LLMs in experimental agents; no direct comparison within this paper.",
            "limitations_and_challenges": "Cited generally; the authors emphasize that LLM-driven agents still face challenges in precise SMILES/graph understanding and ensuring safety/feasibility in autonomous execution.",
            "uuid": "e8664.4",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow (LLM augmented with chemistry tools)",
            "brief_description": "Mentioned related work that augments large language models with chemistry-specific expert-designed tools to improve chemical task performance.",
            "citation_title": "Augmenting large language models with chemistry tools",
            "mention_or_use": "mention",
            "model_name": "ChemCrow (LLM + tool augmentation)",
            "model_type": "Tool-augmented LLM system (transformer LLM + domain tools)",
            "model_size": null,
            "training_data": null,
            "application_domain": "Chemical assistance tasks (planning, information retrieval, possibly molecule-related tasks) when combined with domain tools.",
            "generation_method": "Augmentation: LLM calls out to chemistry tools designed by experts to perform tasks beyond plain text generation.",
            "novelty_of_chemicals": "Not reported here.",
            "application_specificity": "Designed to improve LLM performance on chemistry tasks via tool usage.",
            "evaluation_metrics": "Not provided in this paper.",
            "results_summary": "Referenced as an approach to overcome limitations of pure LLMs on chemistry tasks; no direct experimental comparison in this work.",
            "comparison_to_other_methods": "Mentioned alongside other works that seek to improve LLM chemical capabilities (e.g., tool augmentation vs multimodal alignment).",
            "limitations_and_challenges": "Paper notes that tool-augmentation is one strategy; Chemma-RC instead pursues multimodal representation alignment to better handle SMILES/graph data.",
            "uuid": "e8664.5",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "General-purpose LLM baselines (DeepSeek-V2, GPT-4o, LLaMA3-70B)",
            "name_full": "DeepSeek-V2 / GPT-4o / LLaMA3-70B (general LLM baselines evaluated for condition generation)",
            "brief_description": "Several general-purpose LLMs evaluated in zero/one/few-shot settings as baselines for reaction condition generation; they perform substantially worse than Chemma-RC on structured SMILES/condition tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "DeepSeek-V2, GPT-4o, LLaMA3-70B",
            "model_type": "Large transformer-based LLMs",
            "model_size": "Varies (LLaMA3-70B = 70B parameters; others not specified in-paper)",
            "training_data": "Not specified in this paper (pretrained general corpora for each model).",
            "application_domain": "Evaluated for chemical condition generation under zero-/one-/few-shot prompting.",
            "generation_method": "Prompt-based generation (zero/one/few-shot) producing condition strings/SMILES via API/inference.",
            "novelty_of_chemicals": "Not reported; primary evaluation was accuracy of reproducing known conditions.",
            "application_specificity": "General LLMs not specialized for SMILES/graph chemical representations; authors report poor performance on structured condition generation.",
            "evaluation_metrics": "Top-1 exact-match accuracy, partial accuracy, recall, precision as reported in baseline tables.",
            "results_summary": "Reported low top-1 exact-match accuracies (e.g., many near-zero or single-digit percentages) on USPTO_500MT_Condition in zero-shot/one-shot settings; highlight need for domain adaptation/multimodality.",
            "comparison_to_other_methods": "Underperformed domain-specialized multimodal methods such as Chemma-RC and SMILES/graph-augmented models.",
            "limitations_and_challenges": "General LLMs struggle with formatting and correctness of SMILES and structured concatenated condition strings without domain-specific encoders or alignment; few-shot prompting gives limited gains.",
            "uuid": "e8664.6",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Augmenting large language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "augmenting_large_language_models_with_chemistry_tools"
        },
        {
            "paper_title": "Developing ChemDFM as a large language foundation model for chemistry",
            "rating": 2,
            "sanitized_title": "developing_chemdfm_as_a_large_language_foundation_model_for_chemistry"
        },
        {
            "paper_title": "Predictive Chemistry Augmented with Text Retrieval",
            "rating": 2,
            "sanitized_title": "predictive_chemistry_augmented_with_text_retrieval"
        },
        {
            "paper_title": "Parrot: (as cited by Wang et al.) (attention-based reaction encoder)",
            "rating": 1,
            "sanitized_title": "parrot_as_cited_by_wang_et_al_attentionbased_reaction_encoder"
        },
        {
            "paper_title": "What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks",
            "rating": 1,
            "sanitized_title": "what_can_large_language_models_do_in_chemistry_a_comprehensive_benchmark_on_eight_tasks"
        }
    ],
    "cost": 0.018302,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Text-Augmented Multimodal LLMs for Chemical Reaction Condition Prediction
25 Sep 2025</p>
<p>Yu Zhang 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Ruijie Yu 
Kaipeng Zeng 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Ding Li 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Feng Zhu 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Frontiers Science Center for Transformative Molecules (FSCTM)
Shanghai Jiao Tong University</p>
<p>Xiaokang Yang 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Yaohui Jin 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Yanyan Xu yanyanxu@sjtu.edu.cn 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Text-Augmented Multimodal LLMs for Chemical Reaction Condition Prediction
25 Sep 202523F06603C638B0484C4E157E4D564C84arXiv:2407.15141v2[cs.AI]Text-augmentedMultimodal LLMChemical reaction condition prediction
Identifying reaction conditions that are broadly applicable across diverse substrates is a longstanding challenge in chemical and pharmaceutical research.While many methods are available to generate conditions with acceptable performance, a universal approach for reliably discovering effective conditions during reaction exploration is rare.Consequently, current reaction optimization processes are often labor-intensive, time-consuming, and costly, relying heavily on trial-and-error experimentation.Nowadays, large language models (LLMs) are capable of tackling chemistry-related problems, such as molecule design and chemical reasoning tasks.Here, we report the design, implementation and application of Chemma-RC, a text-augmented multimodal LLM to identify effective conditions through task-specific dialogue and condition generation.Chemma-RC learns a unified representation of chemical reactions by aligning multiple modalities-including text corpus, reaction SMILES, and reaction graphs-within a shared embedding module.Performance benchmarking on datasets showed high precision in identifying optimal conditions, with up to 17% improvement over the current state-of-the-art methods.A palladium-catalysed imidazole C-H arylation reaction was investigated experimentally to evaluate the functionalities of the Chemma-RC in practice.Our findings suggest that Chemma-RC holds significant potential to accelerate highthroughput condition screening in chemical synthesis.CCS Concepts• Applied computing → Chemistry; • Computing methodologies → Artificial intelligence.</p>
<p>Introduction</p>
<p>Chemical synthesis is a crucial step for the discovery of transformative molecules in multiple fields, including drug design, materials, renewable energy, etc.In chemical synthesis, reaction conditions are usually optimized to maximize the yield of each target molecule and to be applicable to a wide variety of substrates [37,38].Despite synthetic methods have achieved significant advancements over the past few decades, discovering effective reaction conditions from the vast substrates still relies on the trial-and-error experimental efforts [4].While automated platforms have increased the efficiency of reaction optimization and reduced exploration costs, challenges in exploring reaction conditions still hinder the adoption of new methodologies in synthetic chemistry.Additionally, optimization is often necessary for different target substrates, and pharmaceutically relevant molecules with high structural complexity may not be compatible with existing conditions.Recently, chemists have focused on designing reliable computer-aided synthesis planning (CASP) tools to facilitate condition screening [11,28,36].Transformer-based models built upon SMILES or reaction graphs have demonstrated strong effectiveness in addressing various chemical tasks [3,14,35].However, practical prediction for reaction conditions is more complex than what can be achieved by using graph methods alone.Therefore, a universal approach to discover effective conditions is still rare [27,32].In summary, to realize efficient synthesis in chemistry, there is an urgent need to facilitate high-efficiency reaction condition prediction.</p>
<p>Nowadays, the emergence of generative large language models (LLMs) or large multimodal models (LMMs), typified by GPT-4 and GPT-4o [1], has sparked significant interest in the field of AI for chemistry [2,6,7,16,25].The prediction and design of reaction conditions necessitate LLMs to be controllable for generating molecular structures that satisfy the substrates and synthesizability requirements.These requirements can be articulated as questions for LLM input, as illustrated in Figure 1A.Answering these questions demands a comprehensive understanding of chemical reactions and the relationship between substrates and conditions.However, sequence-based LLMs struggle with this because they are pre-trained or fine-tuned solely on texts.Notably, even in comparatively easier tasks related to molecules, such as captioning and understanding, the best LLMs perform worse than the domain-specific model, like GraphQA, an effective graph-based method in the design of molecules [15].As we investigate that there are various types of data in the field of chemistry, including simplified molecular-input line-entry system (SMILES) [44], reaction graphs, and a textual corpus of reaction [33], which encompasses the descriptions of reaction processes and reaction mechanisms.Among several data modalities, chemical large multimodal models (LMMs) are essential, with LLMs handling text generation and domain-specific models managing reaction representations [22].However, under the paradigm of LMMs, there are still two important challenges in chemical reaction prediction.First, the inherently 'one-to-many' nature of chemical reactions, where a single substrate may correspond to multiple valid reaction conditions, makes it difficult for LMMs to identify optimal reaction conditions.Second, multiple scales of different modalities of data, from atom-level structures to high-level corpora texts [30], render conventional cross-modal alignment methods ineffective.Addressing these challenges is essential for building chemical LMMs capable of advancing reaction prediction and optimization.Thus, we propose the multimodal LLM, Chemma-RC, for reaction condition prediction.As shown in Figure 1, Chemma-RC integrates LLMs and the other chemical domain-specific models within a multi-modal auto-regressive framework.It predicts the next token across both word and chemical space, enabling the direct generation of reaction conditions.In summary, we think Chemma-RC can be a potential solution due to the following advantages: (i) foundational LLMs can learn relationships between molecules and reactions, thereby acquiring chemical knowledge akin to the learning process of chemists; (ii) via learning the joint representation of chemical reactions from different modalities-graphs, reaction SMILES, and corpus, LLMs might be better equipped to capture the underlying chemical semantics of reactions, thereby improving the accuracy of reaction condition prediction.</p>
<p>The contributions of this work are summarized as follows:</p>
<p>(1) we first design a multimodal LLM, Chemma-RC, to jointly learn a unified reaction representation from SMILES, graphs, and corpus for condition prediction; (2) We design a post-fine-tuning strategy that integrates a ranking enhancement with feedback module to facilitate the generation of optimal conditions; (3) We design a cross-modality contrastive learning strategy to achieve unified and semantically representations across different modalities.</p>
<p>Through evaluation on benchmark datasets, Chemma-RC exhibits strong generalization capabilities on out-of-domain (OOD) and high-throughput experimentation (HTE) datasets.</p>
<p>Related Work</p>
<p>Since the emergence of DeepSeek [21], GPT-4 series [1], LLMs have become foundational models in addressing text-based challenges.The influence of these models is increasingly evident in the fields of chemistry [17], biology, and materials science, where they are being applied to complex molecular studies [13].In the field of chemistry,  [45,46].Further, in the study of organic synthesis, reaction conditions are usually designed and optimized to maximize the yield of each target molecule or minimize the cost of the reaction process [37,38].High-throughput condition screening, as an important tool in synthesizing molecules, exerts an important influence on chemical synthesis.For decades, chemists have focused on building reliable and convenient computer-aided synthesis planning (CASP) tools to facilitate chemical synthesis [28].[12,35], which were applied in forward prediction and reaction condition prediction tasks [3,35].Wang et al. reported the application of reinforcement learning models to identify generally applicable conditions [41].Chemical reaction condition prediction tasks aim to identify catalysts, reagents, solvents, or other conditions for a specific reaction.The exploration of a suitable condition is crucial in synthetic chemistry, as it dictates the expected outcomes, including reaction yields and rates [34].Gao et al. developed a neural network model to predict the chemical context as well as the temperature for any particular organic reaction [14]; Maser et al. proposed a machine-learned ranking model to predict the set of conditions used in a reaction as a binary vector [26]; Wang et al. proposed Parrot, a powerful and interpretable transformer-based model for the prediction of reaction condition [42]; In the meantime, in order to enhance the representation of reactions, Qian et al. [30] designed TextReact, which introduced relevant corpus retrieved from literature to enhance the molecular representation of the reaction based on SMILES.Nevertheless, these methods rely on manual feature selection by experts' knowledge and lack a general prediction model with powerful reaction representation.</p>
<p>Nowadays, the emergence of generative pre-trained transformerbased large language models (LLMs), typified by GPT-4, has triggered keen interest in leveraging such techniques to tackle chemistry challenges [2,6].Several works focus on chemical agents for the exploration of chemical conditions.Boiko et al. [7] proposed a GPT-4 driven scientific agent system to plan and perform complex experiments, which accelerates reaction condition screening and experimental automation in chemistry; Bran et al. developed ChemCrow, which augmented LLMs with chem-expert-designed tools [25]; However, for tasks demanding a precise understanding of molecular SMILES representation, such as reaction prediction, and retrosynthesis, LLMs exhibited a less competitive performance than traditional machine learning baselines [16].Partially, the reason is that, without an in-depth understanding of the SMILES strings and the reaction process that transforms reactants into products, it will be difficult for LLMs to generate accurate responses.</p>
<p>Methods</p>
<p>Problem Setup</p>
<p>For a task of reaction condition prediction, we define these symbols for following clarification: (1) reaction SMILES input , reaction SMILES representation encoded by encoder   , and reaction tokens  ; (2) graph representation of a reaction   and graph tokens ; (3) text corpus of similar reactions  , and text tokens  ; (4) reaction conditions  , which includes the catalyst, solvent, and reagent.We define F as a condition prediction function, then we obtain:
𝑌 = F (𝑋, 𝐺,𝑇 )(1)</p>
<p>Model Structure</p>
<p>An overview of Chemma-RC is illustrated in Figure 1.Chemma-RC responds to task-specific questions constructed by instruction prompts such as "which solvents would you recommend?", and generate answers as reaction conditions prediction.Firstly, it learns a unified reaction representation from SMILES, graphs, and corpus.Subsequently, the tunable modality alignment transforms the graph and SMILES embeddings into language tokens compatible with the  LLM space.Finally, Chemma-RC generates the SMILES of reagents, solvents, and catalysts as predicted results.</p>
<p>To formalize this, let  = { 1 ,  2 , . . .,   } be a sequence of word tokens (denoted as <Corpus> in Figure 2) of length  from the vocabulary W, reaction tokens <Reaction>  = { 1 ,  2 , . . .,   } of length , and graph tokens <Graph>  = { 1 ,  2 , . . .,   } of length , LLMs parameterized by  decompose the joint distribution as   ( ) =  =1   (  |  &lt; ), where  &lt; represents the tokens preceding the -th position.These learnable reaction and graph tokens, along with text tokens, are then input into the LLM to predict chemical reaction conditions, as shown in the equation 2:
L LM = ∑︁ 𝑖 − log 𝑝 𝜃 (𝑤 𝑖 | 𝑊 &lt;𝑖 , 𝑋, 𝐺)(2)</p>
<p>Modality Alignment</p>
<p>In Figure 1B, we introduce an alignment module designed to facilitate cross-modal representation learning among three distinct modalities.This module leverages latent tokens derived from graph and SMILES embeddings, aligning them with corresponding textbased tokens.To achieve this alignment, we utilize two transformerbased Perceiver modules [19], which project the graph and SMILES representations into a shared semantic space compatible with LLMs.Although these Perceiver modules share an identical architecture, they are parameterized independently.The pseudo-code for the modality projection process is detailed in Appendix C.</p>
<p>To optimize this alignment, we adopt a contrastive learning loss approach.Specifically, an InfoNCE loss, described in equation 3, is designed to minimize the embedding distance between the textual modality and its corresponding graph and SMILES representations for the same reaction (L text-graph and L text-SMILES ).Simultaneously, it maximizes the distance between graph and SMILES representations of different reactions (L graph-SMILES ).This dual application of the InfoNCE loss effectively aligns text-graph and text-SMILES pairs from the same reaction while contrasting graph-SMILES pairs from different reactions.
L text-graph = − 1 2 E x𝑔,x𝑡 log exp 𝐸 (x 𝑔 , x 𝑡 ) exp 𝐸 (x 𝑔 , x 𝑡 ) + x 𝑡 ′ ≠x𝑡 exp 𝐸 (x 𝑔 , x 𝑡 ′ ) + log exp 𝐸 (x 𝑔 , x 𝑡 ) exp 𝐸 (x 𝑔 , x 𝑡 ) + x 𝑔 ′ ≠x𝑔 exp 𝐸 (x 𝑔 ′ , x 𝑡 )(3)
where x t and x g form the text-graph pair for each reaction, and x  ′ and x  ′ are the negative samples randomly sampled from the noise distribution, which we use the empirical data distribution. (•) is the dot product function on the jointly learned space, that is,  x g , x t =  g •  g x g ,  t •  t (x t ) , where • is the function composition.</p>
<p>The final alignment loss for the module can be computed as a weighted sum of all contrastive pairs presented in Equation 4, with each term calculated using the InfoNCE loss presented in Equation 3.
L align = 1 3 L text-graph + L text-SMILES + L graph-SMILES(4)
We propose a two-stage training strategy for Chemma-RC, consisting of supervised fine-tuning (SFT) followed by post fine-tuning, as detailed in Section 3.5.Therefore, for the first training stage, the final loss for training Chemma-RC is the integration of next token prediction loss (L LM ) and alignment loss (L align ), which is illustrated in equation 5:
L final = L LM + L align (5)
3.4 Ranking Enhancement with Feedback (REF)</p>
<p>Given our focus on the practical applications in synthetic chemistry, we also want to underscore the significance of accurately identifying reaction conditions that lead to high-yield outcomes.</p>
<p>Large chemical models such as ChemDFM [46] commonly use top 50% accuracy to evaluate ligand prediction performance.This metric is well-suited for high-throughput experimentation (HTE) datasets, where the top-ranked half of ligands generally correspond to satisfactory reaction outcomes.However, when models trained under this paradigm are transferred to literature-based datasets for one-shot condition prediction, they often fail to generate suitable reaction conditions that lead to high yields.</p>
<p>To address this, as depicted in Figure 1C, we design the ranking enhancement module with feedback.This component is the second stage phase of training, as the detailed training process is discussed in Section 3.5.It learns the preferences among condition candidates, thereby enabling the model to predict conditions that are optimized for each specific target substrate.Specifically, it provides a prediction score not only for the ground truth preference condition but also for a set of candidates.During post-fine-tuning, we utilize High-Throughput Experimentation (HTE) data for training, which are predefined and sorted according to their yields of reaction outcomes.The objective of this fine-tuning is to learn a ranking function that assigns higher prediction scores to condition candidates of higher performance.We employ a ranking loss that penalizes the model when it fails to rank high-yield candidates above lower-yield ones.The ranking loss is defined as follows:
L Ranking = 𝑛−1 ∑︁ 𝑖=1 max (0, Δ 𝑖 − score (𝐶 𝑖 ) + score (𝐶 𝑖+1 ))(6)
where L Ranking is the ranking loss,  is the number of candidates, Δ  is the allowed margin between the scores of the -th candidate   and the ( + 1)-th candidate  +1 , and score(  ) is the model's prediction score for the -th candidate.The loss function encourages the model to learn that the score of the -th candidate should be at least Δ  higher than the score of the ( + 1)-th candidate.If the predictions do not meet this criterion, the loss is non-zero and the model is penalized.</p>
<p>End-to-End Model Fine-tuning</p>
<p>Supervised Fine-Tuning (SFT): we employ multimodal SFT to integrate the base LLM with other modules in Chemma-RC.In this process, we freeze the parameters of the reaction and graph encoders depicted in Figure 1A, and focus on fine-tuning the parameters of the LLM, denoted as  in Equation 2, as well as the projection layers for the query tokens  and .The projection layers for the graph and reaction encoders are designed to share the same architecture, although they are parameterized independently.The optimization can be performed end-to-end using Equation 2. This fine-tuning stage aligns the LLM with domain-specific models.</p>
<p>To preserve the generality of the base LLM, and improve training efficiency, we utilize parameter-efficient LoRA for SFT.</p>
<p>Ranking Enhancement with Feedback (REF):</p>
<p>The REF stage is the second phase of training, following the initial SFT stage.In this phase, we focus exclusively on optimizing the ranking loss, while keeping the parameters fine-tuned during SFT frozen.This approach allows the ranking enhancement module to learn preferences among different reaction condition candidates, improving the model's ability to predict high-yield outcomes for specific target substrates.</p>
<p>Construction of Multimodal Instruction Datasets</p>
<p>Instruction prompt datasets refer to format structured or unstructured data as natural language instructions so that LLMs can respond properly [31,43].Here, we introduce a tailored format of instruction-style prompts to facilitate multimodal SFT, shown in  To be specific, given a reaction, we retrieve a relevant corpus-a paragraph containing contextual information that closely resembles the reaction-and populate the <Corpus> placeholder with this data.Next, the reaction is converted into its corresponding SMILES format, and inserted into the specific token placeholder <Reaction SMILES>.Finally, we introduce two additional token placeholders, <Reaction> and <Graph>, for reaction SMILES and graph representations, respectively.To enhance the diversity of the dataset, we further leverage GPT-4 to generate a wide range of question prompts.These prompts are based on predefined templates, examples of which are provided in Table 8.</p>
<p>Experiments and Results</p>
<p>Data</p>
<p>We evaluate on two benchmark datasets, USPTO-Condition and USPTO_500MT_Condition, respectively.The details of data description are presented in Appendix A and Table 6.The visualization of data distribution is depicted in Figure 5.As shown in Table 6, the reaction conditions in the USPTO-Condition dataset are divided into five distinct categories, such as solvent 1, reagent 1, etc, and presented in a fixed order, which results in a more structured prediction task.In contrast, all reaction conditions in USPTO_500MT_Condition dataset are a single dot-concatenated string, posing a greater challenge due to the need to generate an unstructured sequence with correct formatting and semantics.</p>
<p>Experiment Setup</p>
<p>In our work, the reaction encoder is implemented based on Wang et al. [42].A pre-trained graph model proposed by [33] encodes the molecules in the reaction.We utilize LLaMA-2 [39] as a text decoder.Each reaction has a corresponding similar corpus, a paragraph describing a chemical reaction with an average length of 190 tokens.During the training process, we freeze the weight parameters of GCN and the reaction encoder.The modality alignment and part layers of LLaMA-2 are trainable.We utilize parameter-efficient LoRA for SFT, and the trainable parameters constitute approximately 0.3 billion out of the total 7 billion parameters.The multimodal SFT process is conducted with a batch size of 16 for fewer than 6 epochs over 48 hours, utilizing a GPU configuration of 2 × 48 GB NVIDIA A6000 GPUs.Inference is performed on a single 80 GB NVIDIA A800 GPU.Detailed training configuration is shown in Appendix B.</p>
<p>Performance Comparison</p>
<p>We conduct a systematic evaluation to demonstrate Chemma-RC's superior performance for reaction condition prediction.Compared baseline methods include rxnfp LSTM [14], Reaction GCNN [26], TextReact [30], and Reagent Transformer [3].The detailed introduction of these methods is presented in Appendix D.</p>
<p>For the USPTO-Condition dataset, we calculate top- accuracy with a strict matching policy.All SMILES from the prediction results are canonicalized to ensure consistent comparison.As depicted in Table 1, TextReact  refers that we utilize similar text [30] paired with the corresponding reaction for training.To avoid label leak issues, we do not use gold text mentioned in his work for training or testing.Thanks to the work of Qian et al., we retrieve the most semantically relevant corpus entries from literature or patents for each reaction.These retrieved corpus are integrated with reactions to construct Q&amp;A instruction datasets for multimodal SFT.</p>
<p>The overall performance is summarized in the Table 1.From the results, we can see that Chemma-RC consistently outperforms the baselines across all categories and accuracy levels, yielding a significant improvement of 7% over TextReact.Specifically, Chemma-RC achieves superior performance compared to other methods, attaining top-1 accuracy of 54.6% for solvent 1 and 81.8% for solvent 2 prediction, respectively.We also observe that the observed performance disparity across condition types-such as the significantly higher accuracy for catalyst prediction (92.7%) compared to solvent 1 prediction (54.6%).It can be attributed to the inherent distributional differences within the dataset.Specifically, the statistical results in Table 7 illustrate that the number of distinct catalyst types present in the training data is relatively limited, which leads to the highly consistent usage across reactions.In contrast, the solvent category, particularly solvent 1, exhibits much greater chemical diversity, with a larger number of unique solvents and more varied usage contexts.This increased diversity results in a more challenging prediction task, leading to lower model performance in this category.</p>
<p>For the USPTO_500MT_Condition dataset, all reaction conditions are a single dot-concatenated string, annotated as reagents.All reaction conditions must be generated in a single inference pass and then canonicalized to ensure consistency for evaluation and comparison.In Table 2, we report two metrics, including top-1 accuracy and partial accuracy.Different from the complete match accuracy that requires an exact match between the predicted and ground-truth conditions, the partial match accuracy focuses more on evaluating whether individual components (e.g., solvent, reagent, or catalyst) are correctly predicted, even if the full sequence is not perfectly matched.Relative enhanced performance is visualized in Appendix Figure 9. Notably, Chemma-RC significantly outperforms other LLMs and domain-specific chemical models [3,22] in Table 2.In the zero-shot setting, Chemma-RC achieves a top-1 accuracy of 25.9%, which is significantly higher than the best-performing general-purpose model, ChemDFM [45], at 2.0%.Further, we investigate the distribution of condition numbers combinations in test set, and report both top-1 exact match accuracy and partial accuracy in Table 11.We find that exact match accuracy, as well as precision and recall, increases with the frequency of specific condition number combinations in the dataset, irrespective of the type or quantity of reagents involved.Specifically, for three-condition combinations, which occur 3,258 times in the test set, Chemma-RC achieves a higher partial accuracy of 85.6%, compared to 56.91% in the onecondition scenario with 1,622 occurrences.Furthermore, we select several challenging reactions for detailed discussion, with results presented in Table 10.Our model, Chemma-RC, demonstrates robust performance in predicting complex chemical reactions, such as ring cleavage, achieving an exact match accuracy of 66.13% across six different condition combinations.In summary, despite singlecondition samples being simpler in structure, the limited occurrence provides fewer learning signals, which can negatively impact generalization.Conversely, frequent multi-condition examples offer richer and more consistent patterns, leading to better model performance, especially in partial accuracy.</p>
<p>Ablation Study</p>
<p>4.4.1 Model structure.Here, we conduct an ablation study to examine the inherent effect of different modalities on the performance of Chemma-RC.Specifically, we evaluate the performance under the different combinations of mono-domain, including SMILES, graph, and corpus, on the USPTO-Condition dataset.The results are reported in Table 3, and the heatmap visualization illustrating the relative performance improvements contributed by different modalities is presented in Figure 3.The results clearly indicate that different mono-domain inputs contribute unevenly to overall performance.For the prediction of solvent 1, which emerges as the most challenging condition type (in Table 1), the model enhanced with SMILES modality (first row) outperforms the models trained solely on graph-based modality (second row) and corpus data (third row), achieving 21.8% and 23.0% higher top-1 accuracy, respectively.</p>
<p>Subsequently, we investigate how chemical mono-domain data combination affects model performance compared to individual types of data (fourth row to sixth row).By incorporating a corpus   into the model already trained with SMILES representations, we achieve a 16.9% improvement in solvent 1 top-1 prediction accuracy.However, integrating graph representations into the SMILES-based model results in a 5.0% improvement in solvent 1 top-1 accuracy.The limited performance gain observed in this setting can be attributed to the inherent similarity between the graph modality and the SMILES representation.Since both modalities encode comparable structural information about the molecule, the removal of one does not significantly impact the model's overall performance.In contrast, the incorporation of textual modality, which introduces complementary semantic and contextual information, has a more substantial effect on representation quality and prediction accuracy.Although the advantages of incorporating graph modality may not be immediately apparent from aggregated performance metrics, we assert its critical importance for this task.In the context of challenging reactions with substrates comprising over 100 atoms, the integration of graph modality has been observed to significantly enhance condition prediction performance, which can be seen in Figure 7.</p>
<p>We hypothesize that this improvement arises because the graph modality enables the model to discern subtle differences between complex substrates-nuances that are not adequately captured by SMILES representations alone-thereby facilitating a more accurate prediction of reaction conditions.Therefore, the integration of graph modalities into predictive models will become essential for the actual applications of organic chemistry.</p>
<p>Out-of-distribution evaluation.</p>
<p>Here, we evaluate the generalization performance of Chemma-RC.We conduct two out-ofdistribution (OOD) experiments for evaluation.Firstly, inspired by the work proposed by Qian et al., [30], we also evaluate the out-ofdistribution (OOD) performance of Chemma-RC across different dataset splitting strategies on the USPTO-Condition dataset.Secondly, we employ Chemma-RC trained on the USPTO_500MT _Condition to test on the USPTO-Condition.Results are presented in Table 9 and Table 4.We consider both random split (RS) and time-based split (TS) to further assess the model's robustness and generalization ability.Random split (RS) setup follows the original data split of the USPTO-Condition dataset.The second setup-time split is more challenging [9,14], where the dataset is partitioned based on the publication year of patents.We train the model with historical data from older patents and test its performance on the data from newer patents.This temporal division introduces a substantial domain shift, as the difference between reactions in new patents and previous ones.</p>
<p>In Table 4, we calculate the average accuracy of all different types of conditions, and report average top-1, top-3, top-10, and top-15 accuracy metrics.TextReact (gr) refers to the TextReact model without retrieving gold texts for testing.The results demonstrate that while baseline method such as ChemBERTa [8] achieves moderate success, they fall short in capturing the full complexity of condition prediction.In contrast, Chemma-RC significantly outperforms all baseline methods across both RS and TS settings.Notably, despite being trained only on historical data, Chemma-RC achieves a top-1 (TS) accuracy of 69.6%.Further, the results of cross-dataset evaluation are presented in Appendix D.1 Table 9.This substantial improvement highlights Chemma-RC's superior ability to leverage multi-modal information and its robustness across different data distributions.As we discussed before, we designed a ranking function that assigns higher scores to condition candidates associated with better experimental performance.</p>
<p>C-H arylation reaction</p>
<p>Here, we curate a Pd-catalysed imidazole C-H arylation [37] HTE reaction data from ORD [9] to evaluate the effectiveness of this module.The objective is to identify ligands that maximize reaction yield, under the constraint that all other conditions, including bases and solvents, remain fixed within a predefined reaction space.</p>
<p>Compared with the top-50% metric proposed in [16], we aim to predict the ligands with the highest yields.In Figure 4, the box plot illustrates the yield distribution under different base-solventligand combination of conditions; the box marked in green is the ligand generated by our proposed Chemma-RC.For example, in the left top panel, under the combination of CsOAc and DMAc, Chemma-RC identifies the XPhos ligand.We further evaluate the model proposed by Zhao et al.'s work [45], which yields a top-1 accuracy of 38.1% for ligand selection.In comparison, Chemma-RC achieves a significantly higher accuracy of 93.7%, representing an improvement of 58.7%.All results are presented in Appendix Figure 10.In summary, Chemma-RC is capable of generating optimal conditions due to post-fine-tuning by the ranking enhancement module.We hope this technology has the potential to accelerate high-throughput reaction condition screening in the future.</p>
<p>Modality alignment.</p>
<p>In Chemma-RC, the modality alignment module utilizes the Perceiver projection module [19] to extract latent tokens from both graph and SMILES representations and subsequently aligns these tokens into a text-related language space, as illustrated in Figure 1.Here, we investigate the impact of different projection modules on modality alignment, a component that plays a crucial role in the performance of LMMs.Specifically, we introduce three projection methods for modality alignment, including Perceiver [19], Reprogramming [20], and MLP for comparison.</p>
<p>As depicted in Table 5, the Perceiver module achieves significant gains in the prediction of all condition categories.Compared to reprogramming, it achieves the highest accuracy in all predicted condition categories with an average performance gain of 7.1%.Specifically, for the solvent 1 prediction, a challenging task, the Perceiver module achieves a top-1 accuracy of 54.6%, clearly outperforming both MLP (51.1%) and Reprogramming (52.8%).This performance demonstrates the Perceiver's robustness and effectiveness in capturing complex cross-modal relationships, making it a strong candidate for accurate and reliable reaction condition prediction.</p>
<p>Conclusion and Limitations</p>
<p>In this paper, we present a multimodal LLM, a.k.a.Chemma-RC, for chemical reaction condition prediction.Trained with Q&amp;A instruction datasets along with text-augmented corpus, graph, and SMILES representation, Chemma-RC effectively answers questions about reaction conditions.Even though the integration of the graph modality increases computational cost while offering limited performance gains in the current task, we believe it holds promise for more complex reaction scenarios.We plan to further explore crossmodal alignments, where graph-based contributions are expected to play a more significant role.In the future, ensuring the safety and feasibility of generated reaction conditions is critical, especially when deploying the model in autonomous synthesis platforms.Second, the trade-off between computational efficiency and predictive performance warrants further investigation, particularly for scaling the model to broader chemical domains or real-time applications.To obtain a comprehensive understanding of data distribution, we perform an in-depth data analysis on the USPTO-Condition and USPTO_500MT_Condition datasets.</p>
<p>First, we calculate the non-empty count and non-empty proportion of each condition type.On the USPTO-Condition dataset, catalyst, reagent 2 and solvent 2 condition types exhibit a high extent of sparsity, with non-empty entries occurring in less than 30% of reactions, as shown in Table 7.It indicates that some reactions do not require multiple reagents and solvents, and the corresponding condition labels are therefore assigned as None.On the USPTO_500MT_Condition dataset, since reaction conditions are represented as a single dot-concatenated string, all reactions are associated with non-empty condition labels.Second, we explore the inner distribution characteristics across the two dataset, as illustrated in Figure 6.Reaction conditions exhibit a high degree of diversity and imbalance in both datasets.In Figure 6(F), we confirm that the occurrence frequency of reagents in the datasets follow a power-law distribution.The power-law distributions demonstrate the long-tail characteristics and a small number of categories account for the majority of the whole dataset.Such phenomenon is in light with the distribution of words in natural language, indicating that there is potential for tackling chemical tasks with natural language models.Table 8: Question templates generated by GPT-4.</p>
<p>Task Description</p>
<p>Solvent prediction</p>
<p>Could you suggest potential solvents that could have been used in the given chemical reaction, taking into consideration their polarity and compatibility with the reactants?</p>
<p>Reagent prediction</p>
<p>Please suggest some possible reagents that could have been used in the following chemical reaction.</p>
<p>Catalyst prediction</p>
<p>Considering the chemical reaction in question, which catalysts could be effective?</p>
<p>Condition prediction (all) Given the current chemical reaction, what would be the appropriate conditions to consider?</p>
<p>B Training Settings</p>
<p>Within the model framework, Chemma-RC takes the 32-layer LLaMA-2-7b as the LLM backbone.For the reaction representation, we introduce Parrot [42] to encode the reaction SMILES.For the graphbased reaction representation, we leverage R-GCN [33].For the text-based reaction representation, we retrieve the corresponding similar corpus and utilize LLaMA-2 as a text decoder.During the training process, the weight parameters of the graph and reaction encoders are frozen, while the modality alignment and part layers of LLaMA-2 are trainable.We utilize parameter-efficient LoRA for SFT, and the trainable parameters constitute approximately 0.3 billion out of the total 7 billion parameters.The multimodal SFT process is conducted with a batch size of 16 for fewer than 6 epochs over 48 hours, utilizing a GPU configuration of 2 × 48 GB NVIDIA A6000 GPUs.Inference is performed on a single 80 GB NVIDIA A800 GPU.</p>
<p>C Details of Modality Alignment</p>
<p>For the reaction condition prediction task, the representation of the reaction is extracted by encoders, and the text representation is tokenized by LLMs.However, fusing two types of representation introduces inductive biases issues [5,19].To effectively fuse representations from multiple modalities, we propose the use of a projection module, the Perceiver [19], for modality alignment (Figure 1).This module employs latent queries to align graph and SMILES tokens with text-related tokens, such as question prompts and a text-augmented corpus.We show the pseudo-code for modality projection in Algorithm.1.</p>
<p>D Model Performance</p>
<p>A chemical reaction can be represented as the transformation of a sequence of characters (reactants, conditions) into another sequence (products), with compounds connected by special characters, such as '&gt;&gt;'.This structure makes sequence-to-sequence models, such as the Transformer, well-suited for predictive modeling of reaction representation [18,35].However, existing SMILES-based Transformer models for reaction representation encounter limitations in various aspects, particularly with respect to atom permutations and the interpretability of reaction mechanisms.Consequently, our proposed Chemma-RC fuses data from diverse sources including corpus, SMILES and graphs of molecules to present a comprehensive view of the reaction.We assess the performance of our proposed Chemma-RC and the aforementioned baseline methods for reaction condition prediction.The top- reaction condition prediction accuracy on USPTO-Condition and USPTO_500MT_Condition datasets are presented in Table 1 and Table 2, respectively.We introduce several comparative baseline methods.</p>
<p>(1) rxnfp LSTM [14].This method introduces a reaction representation based on Morgan fingerprints, defined as the difference between the fingerprint vectors of the products and the reactants.We report reproduced results from Wang et al. [42] in Table 1, and results from Qian et al. [30] in Table 4. (2) Parrot [42].This method leverages a powerful attentionbased model architecture to encode the reaction.We report (5) ChemDFM [46].It is a pioneering LLM for chemistry trained on 34B tokens from chemical literature and textbooks, and fine-tuned using 2.7M instructions.We download the opensourced ChemDFM weights and evaluate model performance under zero-shot, one-shot and five-shot settings.We report our evaluation result in Table 2. (6) Reagent Transformer [3].This method leverages Molecular Transformer [35] to tackle the task of reagent prediction.We reproduce the model with the training settings reported in the paper and evaluate model performance on the USPTO_500MT_Condition dataset in Table 2. (7) Reaction GCNN [26].This method proposes a machine-learned ranking model to predict the condition set.We reproduce the model with the training settings reported in the paper and evaluate model performance in the USPTO_500MT_Condition dataset on in Table 2. (8) nach0 [22].This method is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge.In Table 2, we report evaluation results from the paper.</p>
<p>(9) TextReact [30] variants: rxnfp retrieval, Transformer, Chem-BERTa, TextReact(gr).rxnfp retrieval takes the conditions of the most similar reactions in the training set as the prediction.Transformer uses the same architecture as the Tex-tReact predictor.ChemBERTa is same as the Transformer baseline except that the encoder is pretrained on external SMILES data.TextReact(gr) removes the gold corpus in the evaluation process.In Table 4, we report model performance from Qian et al. [30].</p>
<p>D.1 Generalization Performance</p>
<p>In order to validate the out-of-domain performance of Chemma-RC, we employ Chemma-RC trained on the USPTO_500MT_Condition to test on the USPTO-Condition.The evaluation strategy includes three specific training conditions: reagents, catalysts, and solvents.We adopt a metric of partial matched accuracy to illustrate the generalization capability of Chemma-RC.Different from the complete matched accuracy that requires perfect matching between predictions and labels, the partial matched accuracy is more suitable to test the generalization capacity, which focuses more on whether the predicted results match a substitutable part of the ground truth.Chemma-RC can successfully distinguish reagents from the combination of all conditions in a reaction.Additionally, training Chemma-RC on USPTO-Condition, a larger chemical reaction dataset, further enhances its ability to akin chemical knowledge.</p>
<p>D.2 Case Study</p>
<p>In this section, we select four cross-coupling reactions from USPO-Condition datasets for performance validation.We visualize the predicted results in Figure 7.As depicted in Figure 7, the reaction centers and leaving groups are highlighted in different colors.For C-N cross-coupling reactions (the first and the third row), Chemma-RC can predict all conditions precisely.For C-C bond formation and Formylation reactions (the second and the fourth row), Chemma-RC fails to predict Ethyl Acetate (the second case) and THF (the fourth case).The reason why Chemma-RC is less effective for these reactions is that the data volume of C-C bond formation reactions in the USPTO-Condition dataset is only 5%, as shown in Figure 5.This limited representation constrains the model's ability to learn the patterns associated with C-C bond formation reactions.Consequently, Chemma-RC lacks sufficient training examples to capture and generalize the underlying reaction mechanisms accurately.The scarcity of diverse and representative data hampers its effectiveness, leading to a lower precision in predicting these types of reactions.</p>
<p>Further, we visualize the predicted results on OOD datasets in Figure 8.We select two reaction cases for analysis.In case 1, Toluene is not predicted by Chemma-RC.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide are predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p>E Reproducibility Statement</p>
<p>To ensure the reproducibility of our work, we have used datasets which have been published in [24,42], and the data links are as follows: USPTO_500MT_Condition and USPTO-Condition.Additionally, the code base for Chemma-RC is available as an anonymous repository for continuous development: https://anonymous.4open.science/r/Chemma-RC-submission-5600/.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide were predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p><Graph>, <Reaction>, <Corpus>, considering the characteristics of this chemical reaction, which solvents would you advise as e ective?Reaction-graph contrastive loss (d) Reaction-text and graph-text constrative loss Ranking enhancement with feedback</p>
<p>Figure 1 :
1
Figure 1: Architecture of Chemma-RC.It processes task-specific questions and generates answers via a two-stage training framework: multimodal supervised fine-tuning followed by post-fine-tuning.</p>
<p>Figure 2 .
2
In contrast to standard prompts used in common SFT in Figure 2(a), we incorporate additional textual indicators and modalityspecific tokens (Figure 2(b)) to represent multimodal chemical data.CC(C)O.O=C(n1ccnc1)nccnc1&gt;&gt;CC(C)OC(=O)n1ccnc1 predict the the reagent for this reaction, reaction SMILES is as follows: <Reaction SMILES>.(b) Multimodal instruction Q&amp;A Text Human: Given a reaction text description: <Corpus>, reaction embedding <Reaction>, graph embedding: <Graph>, and the reaction SMILES: <Reaction SMILES>.Please predict the reagent for this reaction.)O.O=C(n1ccnc1)nccnc1&gt;&gt;CC(C)OC(=O)n1ccnc1</p>
<p>Figure 2 :
2
Figure 2: Construction of multimodal instruction datasets.(a) Traditional instruction prompts for supervised fine-tuning; (b) Our proposed text-augmented multimodal instruction Q&amp;A datasets.</p>
<p>Figure 3 :
3
Figure 3: Heatmap visualization of performance enhancements of Chemma-RC on the USPTO-Condition dataset.</p>
<p>Figure 4 :
4
Figure 4: Performance evaluation for identifying optimal ligand on C-H arylation reaction.</p>
<p>Algorithm 1
1
Pseudo code for modality projection.# B: batch size; C: channel size; n: content shape # M: query length; N: shape of flatten reaction tokens; # text_q: text query in shape (B, M, C) # react_embed: reaction embedding in shape (B, N, C) # word_embed: word embedding in shape (B, vocab_size, C) # Key part 1: map transformer-based reaction feature word_embed = self.word_proj(word_embed)word_embed = word_embed.repeat(react_embed.size()[0], 1, 1) react_embed = torch.cat([react_embed,word_embed], dim=1) smiles_react_tokens = linear_layer(react_embed) # to make 128 tokens # Key part 2: map graph-based reaction features graph_embed = self.word_proj(graph_embed)graph_react_tokens = linear_layer(graph_embed) # to make 3 tokens # Key part 3: reaction_tokens = torch.cat([smiles_react_tokens,graph_react_tokens], dim=1) # Key part 4: modality projection reaction_tokens_from_smiles = self.perceiver_proj_smiles(smiles_react_tokens) reaction_tokens_from_graphs = self.perceiver_proj_graphs(graph_react_tokens) # concat token final_token = torch.cat([reaction_tokens_from_smiles,reaction_tokens_from_graphs, text_q], dim=1)</p>
<p>EthylFirstFigure 7 :
7
Figure7: Visualization of generated conditions on four reactions.We select four Suzuki-Miyaura cross-coupling reactions to present the performance of condition prediction.The reaction centers and leaving groups are highlighted in different colors.</p>
<p>1 Sulfonylation 11 Conference' 17 , 1 -Figure 8 :
1111718
Figure8: Visualization of recommended conditions on two reactions.In case 1, Toluene was not predicted by Chemma-RC.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide were predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p>Figure 9 :
9
Figure 9: The visualization of relative performance enhancement.(A) relative performance enhancement on the USPTO-Condition dataset.(B) Performance evaluation for three baseline methods: Parrot (red), TextReact (green), and Chemma-RC (blue) on USPTO_500MT_Condition datasets.</p>
<p>Figure 10 :
10
Figure 10: Performance evaluation of ligand generation.</p>
<p>Table 1 :
1
Accuracy results for reaction condition prediction on USPTO-Condition dataset.The best performance is in bold.
Top-𝑘 Accuracy (%)ModelCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135rxnfp LSTM92.2 92.2 92.250.2 66.4 70.681.3 83.7 84.649.7 66.0 74.076.2 84.1 86.6Parrot92.4 92.4 92.449.3 67.7 72.380.7 84.2 85.149.6 67.3 75.776.5 84.1 87.2TextReact 𝑠92.4 95.3 96.351.7 65.5 71.779.8 87.7 89.851.9 68.7 75.175.8 86.7 89.7Chemma-RC92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2</p>
<p>Table 2 :
2
Comparison of model performance on USPTO_500MT_Condition dataset between general-purpose LLMs and domainspecific chemical models, respectively.General-purpose LLMs are tested under three settings: zero-shot, one-shot, and five-shot.Error analysis is reported, and the best results are in bold font.
MethodTop-1 exact acc. (%)Partial acc. (%)Recall (%)Precision (%)General-purpose LLMs, 100 examples are randomly sampled for evaluationZero-shot performanceDeepSeek-V20.0 ± 0.01915.1 ± 0.01817.4 ± 0.01817.9 ± 0.034GPT-4o1.0 ± 0.01213.0 ± 0.0107.6 ± 0.03412.1 ± 0.038LLaMA3-70B0.0 ± 0.0007.0 ± 0.01011.4 ± 0.0249.1 ± 0.024ChemDFM3.0 ± 0.02938.0 ± 0.02419.6 ± 0.01226.5 ± 0.028One-shot performanceDeepSeek-V20.0 ± 0.01915.1 ± 0.01817.4 ± 0.01817.9 ± 0.034GPT-4o1.0 ± 0.01213.0 ± 0.0107.6 ± 0.03412.1 ± 0.038LLaMA3-70B0.0 ± 0.0007.0 ± 0.01011.4 ± 0.0249.1 ± 0.024ChemDFM3.0 ± 0.02938.0 ± 0.02419.6 ± 0.01226.5 ± 0.028Five-shot performanceDeepSeek-V21.3 ± 0.01415.8 ± 0.05917.2 ± 0.01825.3 ± 0.050GPT-4o0.0 ± 0.03915.3 ± 0.0796.2 ± 0.0369.8 ± 0.020LLaMA3-70B1.0 ± 0.01028.0 ± 0.01314.1 ± 0.02411.9 ± 0.024ChemDFM1.0 ± 0.01721.0 ± 0.07011.1 ± 0.03814.4 ± 0.073Domain-specific chemical models, all samples in test sets are selected for evaluationReagent Transformer17.527.531.635.6Reaction GCNN16.127.533.040.2Parrot13.825.331.437.9nach013.1---Chemma-RC (zero-shot)25.969.767.979.3</p>
<p>Table 3 :
3
Performance evaluation of Chemma-RC under different combinations of mono-domain data on the USPTO-Condition Dataset.
Top-𝑘 Accuracy (%)SMILES Graph CorpusCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135✓✗✗90.3 97.5 98.737.1 64.5 75.780.8 92.9 96.837.1 63.5 74.773.7 89.9 94.1✗✓✗87.1 93.3 95.515.3 40.5 58.280.7 91.9 95.534.6 56.8 67.575.4 86.6 90.6✗✗✓87.1 87.4 87.814.1 26.1 44.980.7 88.19226.0 32.1 37.375.1 76.6 77.9✓✗✓92.6 98.5 99.354.0 76.0 84.481.8 94.7 97.652.8 75.4 83.378.6 93.1 96.1✓✓✗91.3 98.1 99.142.1 68.8 79.480.1 93.5 97.145.2 70.4 79.976.7 91.4 95.1✓✓✓92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2</p>
<p>Table 4 :
4
Evaluation performance under different data split strategies for reaction condition prediction.RS: random split; TS: time split.
Random splitTime splitTop-1 Top-3 Top-10 Top-15Top-1 Top-3 Top-10 Top-15rxnfp LSTM20.530.741.745.315.226.240.745.4rxnfp retrieval27.237.547.951.17.815.227.331.5Transformer30.043.856.760.518.731.847.652.7ChemBERTa30.344.758.062.018.731.947.652.8TextReact(gr)47.259.965.071.436.350.456.263.8Chemma-RC72.387.892.496.569.686.791.796.2</p>
<p>Table 5 :
5
Performance evaluation of Chemma-RC under different Modality alignments, the best performance are in bold.
ProjectionTop-𝑘 Accuracy (%)LayerCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135MLP90.9 97.8 98.951.1 73.3 82.281.1 93.9 97.147.4 71.0 79.977.0 91.7 95.2Reprogramming92.1 98.3 99.152.8 75.1 83.781.3 94.3 97.450.2 73.5 81.977.7 92.5 95.7Perceiver92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2
4.4.3Ranking enhancement with feedback.</p>
<p>Table 6 :
6
Data description of USPTO-Condition and USPTO_500MT_Condition datasets.
DatasetSample of conditionsPrediction type Training Validation TestingUSPTO-Condition[Zn],C1CCOC1,O,CO,[Cl-].[NH4+]classification546,72868,34168,341USPTO_500MT_ConditionCO.[Na+].CC(=O)O.[BH3-]CNgeneration88,4109,77810,828</p>
<p>Table 7 :
7
Sparsity analysis of the USPTO-Condition dataset.
Non-emptycatalystsolvent 1solvent 2reagent 1reagent 2Count89,756673,634130,326504,169170,752Density13%99%19%74%25%</p>
<p>Table 9 :
9
The top-1 partial matched accuracy of Chemma-RC under OOD setting.
Evaluation strategy (train → test)Accuracy (%)USPTO_500MT_Condition → USPTO-Condition (reagent)67.1USPTO_500MT_Condition → USPTO-Condition (catalyst)89.9USPTO_500MT_Condition → USPTO-Condition (solvent)58.1</p>
<p>Table 10 :
10
Performance evaluation of Chemma-RC on specific reaction types on USPTO-Condition dataset.
Reaction SMARTSReaction NameExact Match (%)Part Match (%)Recall (%)More complex reaction types</p>
<p>Table 11 :
11
Performance comparison across different numbers of reaction conditions on USPTO_500MT_Condition dataset.Condition numbers Frequency Exact acc (%) Partial acc (%) Recall (%) Precision (%)
1162233.1756.9156.5834.242402632.6678.7160.1054.713325819.0085.6056.4663.684132620.8189.2257.4370.56544020.9191.5957.8373.20615627.5691.0360.7777.25
Conference'17, July 2017, Washington, DC, USA Zhang et al.
Appendix A Data DescriptionWe introduce two large benchmark datasets, USPTO-Condition and USPTO_500MT_Condition to evaluate model performance on recommending reaction conditions.The USPTO-Condition dataset, curated by Wang et al.[42], is commonly used in previous works[30,42].It comprises about 700,000 reaction data derived from the public USPTO data[23], with heteroatom alkylation and arylation reactions accounting for the majority, as shown in Figure5(left).Each reaction entry consists of reaction reactants, products, and conditions in canonical SMILES format.As shown in Table6, the reaction conditions are categorized into five distinct types, including catalyst, solvent 1, solvent 2, reagent 1, and reagent 2, and are presented in a consistent order, which facilitates a more structured prediction task.We follow the data split strategy proposed by Wang[42], which randomly divides reactions into training, validation, and testing sets with a ratio of 8:1:1, and detailed statistics are presented in Table6.Furthermore, in section 4.4.2, for a fair comparison, we evaluate model performance under the time-based data split (TS) strategy proposed by Qian[30], where the reactions collected before 2015 are categorized as the training set, reactions from 2015 as validation, and reactions 2016 as testing.The USPTO_500MT_Condition dataset, introduced by Lu et al.[24], collects about 110,000 reactions with the top-500 common reaction types sourced from the USPTO-MIT dataset[9], and reactions with the top-100 reaction types constitute 59% of the dataset, as illustrated in Figure5(right).Each entry in the USPTO_500MT_Condition dataset comprises reactants, products, and conditions.Notably, as shown in Table6, all reaction conditions in USPTO_500MT_Condition dataset are concatenated using dots and collectively labeled as reagents, which results in an unstructured sequence generation task.We perform data cleaning on the USPTO_500MT_Condition dataset to ensure consistency and quality.Specifically, we canonicalize all molecular SMILES representations and remove reactions with more than six reagents.Following the data splitting strategy proposed by Lu[24], the dataset is randomly divided into training, validation, and test sets in an 8:1:1 ratio.Detailed statistics are reported in Table6.evaluation results from Wang et al.[42]in Table1.Further, we follow the training setting in the paper, and test Parrot's performance on the USPTO_500MT_Condition dataset in Table2. (3) TextReact[30].This method introduces relevant corpus retrieved from literature to enhance the molecular representation of the reaction based on SMILES.For a fair comparison, we exclude the gold texts paired with each chemical input during both training and evaluation.Our reproduced results are reported in Table1, where we referred as TextReact_s.(4) DeepSeek-V2[21], GPT-4o[1], LLaMA3-70B[39].They are general-purpose generative large language models pretrained on massive corpora of diverse text data, which sparked significant interest in the field of AI for chemistry.In Table2, we utilize Ollama and OpenAI API to evaluate model performance under three settings: zero-shot, one-shot and fiveshot.USPTO-Condition
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. 2023arXiv preprint</p>
<p>. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, arXiv:2303.087742023. 2023arXiv preprint</p>
<p>Reagent prediction with a molecular transformer improves reaction data quality. Mikhail Andronov, Varvara Voinarovska, Natalia Andronova, Michael Wand, Djork-Arné Clevert, Jürgen Schmidhuber, Chemical Science. 142023. 2023</p>
<p>Closed-loop optimization of general reaction conditions for heteroaryl Suzuki-Miyaura coupling. Vandana Nicholas H Angello, Wiktor Rathore, Agnieszka Beker, Wołos, Rafał Edward R Jira, Tony C Roszak, Charles M Wu, Alán Schroeder, Bartosz A Aspuru-Guzik, Grzybowski, Science. 3782022. 2022</p>
<p>Tadas Baltrušaitis, Chaitanya Ahuja, Louis-Philippe Morency, Multimodal Machine Learning: A Survey and Taxonomy. IEEE transactions on pattern analysis and machine intelligence. 2018. 201841</p>
<p>Artificial Intelligence in Chemistry: Current Trends and Future Directions. Zachary J Baum, Xiang Yu, Philippe Y Ayala, Yanan Zhao, Steven P Watkins, Qiongqiong Zhou, Journal of Chemical Information and Modeling. 612021. 2021</p>
<p>Autonomous chemical research with large language models. Robert Daniil A Boiko, Ben Macknight, Gabe Kline, Gomes, Nature. 6242023. 2023</p>
<p>ChemBERTa: large-scale self-supervised pretraining for molecular property prediction. Seyone Chithrananda, Gabriel Grand, Bharath Ramsundar, arXiv:2010.098852020. 2020arXiv preprint</p>
<p>Prediction of Organic Reaction Outcomes Using Machine Learning. Regina Connor W Coley, Tommi S Barzilay, William H Jaakkola, Green, Klavs, Jensen, ACS central science. 32017. 2017</p>
<p>A graphconvolutional neural network model for the prediction of chemical reactivity. Wengong Connor W Coley, Luke Jin, Timothy F Rogers, Tommi S Jamison, William H Jaakkola, Regina Green, Klavs F Barzilay, Jensen, Chemical science. 102019. 2019</p>
<p>Computer-Assisted Design of Complex Organic Syntheses: Pathways for molecular synthesis can be devised with a computer and equipment for graphical communication. Elias James, Corey , W Todd Wipke, Science. 1661969. 1969</p>
<p>Exploring Chemical Reaction Space with Machine Learning Models: Representation and Feature Perspective. Yuheng Ding, Bo Qiang, Qixuan Chen, Yiqiao Liu, Liangren Zhang, Zhenming Liu, Journal of Chemical Information and Modeling. 2024. 2024</p>
<p>Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen, ICLR. OpenReview.net. 2024</p>
<p>Using Machine Learning To Predict Suitable Conditions for Organic Reactions. Hanyu Gao, Thomas J Struble, Connor W Coley, Yuran Wang, William H Green, Klavs, Jensen, ACS central science. 42018. 2018</p>
<p>Sample efficiency matters: a benchmark for practical molecular optimization. Wenhao Gao, Tianfan Fu, Jimeng Sun, Connor Coley, Advances in neural information processing systems. 352022. 2022</p>
<p>What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks. Taicheng Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh Chawla, Olaf Wiest, Xiangliang Zhang, Advances in Neural Information Processing Systems. 362023. 2023</p>
<p>Chemeval: a comprehensive multi-level chemical evaluation for large language models. Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, arXiv:2409.139892024. 2024arXiv preprint</p>
<p>Chemformer: a pre-trained transformer for computational chemistry. Ross Irwin, Spyridon Dimitriadis, Jiazhen He, Esben Jannik Bjerrum, Machine Learning: Science and Technology. 3150222022. 2022</p>
<p>Perceiver: General Perception with Iterative Attention. Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, Joao Carreira, International conference on machine learning. PMLR2021</p>
<p>Time-LLM: Time Series Forecasting by Reprogramming Large Language Models. Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, Qingsong Wen, International Conference on Learning Representations (ICLR). 2024</p>
<p>Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, arXiv:2412.19437Deepseek-v3 technical report. 2024. 2024arXiv preprint</p>
<p>Alán Aspuru-Guzik, et al. 2024. nach0: Multimodal natural and chemical languages foundation model. Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, Anthony Costa, Alex Aliper, Chemical Science. 152024</p>
<p>Extraction of chemical structures and reactions from the literature. Daniel Mark, Lowe , </p>
<p>Unified Deep Learning Model for Multitask Reaction Predictions with Explanation. Jieyu Lu, Yingkai Zhang, Journal of chemical information and modeling. 622022. 2022</p>
<p>Augmenting large language models with chemistry tools. Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller, Nature Machine Intelligence. 2024. 2024</p>
<p>Multi-Label Classification Models for the Prediction of Cross-Coupling Reaction Conditions. Alexander Y Michael R Maser, Serim Cui, Travis J Ryou, Yisong Delano, Sarah E Yue, Reisman, Journal of Chemical Information and Modeling. 612021. 2021</p>
<p>A universal system for digitization and automatic execution of the chemical synthesis literature. M Hessam, Matthew Mehr, Artem I Craven, Graham Leonov, Leroy Keenan, Cronin, Science. 3702020. 2020</p>
<p>Computational planning of the synthesis of complex natural products. Barbara Mikulak-Klucznik, Patrycja Gołębiowska, Alison A Bayly, Oskar Popik, Tomasz Klucznik, Sara Szymkuć, Ewa P Gajewska, Piotr Dittwald, Olga Staszewska-Krajewska, Wiktor Beker, Nature. 5882020. 2020</p>
<p>Linking the Neural Machine Translation and the Prediction of Organic Chemistry Reactions. Juno Nam, Jurae Kim, arXiv:1612.095292016. 2016arXiv preprint</p>
<p>Predictive Chemistry Augmented with Text Retrieval. Yujie Qian, Zhening Li, Zhengkai Tu, Connor Coley, Regina Barzilay, 10.18653/v1/2023.emnlp-main.784Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Houda Bouamor, Juan Pino, Kalika Bali, the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. Laria Reynolds, Kyle Mcdonell, Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021</p>
<p>Digitization and validation of a chemical synthesis literature database in the ChemPU. Simon Rohrbach, Mindaugas Šiaučiulis, Greig Chisholm, Petrisor-Alin Pirvan, Michael Saleeb, S Hessam M Mehr, Ekaterina Trushina, I Artem, Graham Leonov, Aamir Keenan, Khan, Science. 3772022. 2022</p>
<p>Modeling relational data with graph convolutional networks. Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den, Ivan Berg, Max Titov, Welling, The semantic web: 15th international conference. Heraklion, Crete, GreeceSpringer2018. 2018. June 3-7, 2018</p>
<p>Tobias Schnitzer, Martin Schnurr, Andrew F Zahrt, Nader Sakhaee, Scott E Denmark, Helma Wennemers, Machine Learning to Develop Peptide Catalysts-Successes, Limitations, and Opportunities. ACS Central Science2024. 2024</p>
<p>Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction. Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas Bekas, Alpha A Lee, ACS central science. 52019. 2019</p>
<p>Mapping the Space of Chemical Reactions Using Attention-Based Neural Networks. Philippe Schwaller, Daniel Probst, Alain C Vaucher, H Vishnu, David Nair, Teodoro Kreutter, Jean-Louis Laino, Reymond, Nature machine intelligence. 32021. 2021</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. J Benjamin, Jason Shields, Jun Stevens, Marvin Li, Farhan Parasram, Jesus I Martinez Damani, Jacob M Alvarado, Ryan P Janey, Abigail G Adams, Doyle, Nature. 5902021. 2021</p>
<p>A Brief Introduction to Chemical Reaction Optimization. Alexander Connor J Taylor, Pomberger, Rachel Kobi C Felton, Magda Grainger, Thomas W Barecka, Richard A Chamberlain, Christopher N Bourne, Alexei A Johnson, Lapkin, Chemical Reviews. 1232023. 2023</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, arXiv:2307.09288Shruti Bhosale, et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. 2023arXiv preprint</p>
<p>Attention Is All You Need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 2017. 201730</p>
<p>Identifying general reaction conditions by bandit optimization. Jason Y Wang, Jason M Stevens, Stavros K Kariofillis, Mai-Jan Tom, Dung L Golden, Jun Li, Jose E Tabora, Marvin Parasram, Benjamin J Shields, David N Primer, Nature. 6262024. 2024</p>
<p>Generic Interpretable Reaction Condition Predictions with Open Reaction Condition Datasets and Unsupervised Learning of Reaction Center. Xiaorui Wang, Chang-Yu Hsieh, Xiaodan Yin, Jike Wang, Yuquan Li, Yafeng Deng, Dejun Jiang, Zhenxing Wu, Hongyan Du, Hongming Chen, Research. 62312023. 2023</p>
<p>Self-Instruct: Aligning Language Models with Self-Generated Instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, 10.18653/v1/2023.acl-long.754Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231</p>
<p>SMILES. 2. Algorithm for generation of unique SMILES notation. David Weininger, Arthur Weininger, Joseph L Weininger, Journal of chemical information and computer sciences. 291989. 1989</p>
<p>Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Yansi Li, Zhongyang Dai, ChemDFM-X: towards large multimodal model for chemistry. 2024. 202467220109</p>
<p>Developing ChemDFM as a large language foundation model for chemistry. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, Hongshen Xu, Zichen Zhu, Su Zhu, Cell Reports Physical Science. 642025. 2025</p>            </div>
        </div>

    </div>
</body>
</html>