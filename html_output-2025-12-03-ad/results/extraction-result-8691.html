<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8691 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8691</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8691</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-18949530</p>
                <p><strong>Paper Title:</strong> Compositional Reasoning in Early Childhood</p>
                <p><strong>Paper Abstract:</strong> Compositional “language of thought” models have recently been proposed to account for a wide range of children’s conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5–4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8691.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8691.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format in which concepts are represented by an idealized or average 'prototype' carrying typical feature values; membership and similarity to the prototype determine category judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally represented as prototypes — single summary exemplars (feature vectors or distributions of features) that encode the typical values of a category; conceptual judgments are made by comparing items to prototype representations (similarity computations).</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>feature-based / exemplar-summary (symbolic-ish but non-compositional)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Mentioned in relation to categorization and conceptual structure (family resemblances, typicality effects).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper only references prototype theory in the literature review as one of several proposed representational formats; no direct empirical tests in this experiment. The authors note prototype accounts as candidates for how concepts might be structured but do not test them.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted in the introduction with compositional / language-like (LOT) approaches; the paper poses the question whether compositionality is built 'on top' of prototype-like formats or intrinsic to core representations. The experimental results are described as more directly indicative of compositional/function-based representations than simple prototype accounts, but not definitive against prototype models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>No direct experimental evidence here against prototypes; the authors observe that prototype approaches must specify how combination/compositionality is achieved and that LOT-style accounts more naturally encode compositional combination of primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Prototype theory is presented as an alternative to compositional accounts; the paper implies that if children spontaneously compose functions, models that rely purely on prototype summaries would need an extra mechanism to explain combinatorial operations observed in the experiment.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8691.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory / exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where categories are stored as collections of individual exemplars; classification is based on similarity to remembered exemplars rather than abstract prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, concepts are represented as sets of remembered instances (feature vectors); judgments are computed by measuring similarity/aggregate similarity across stored exemplars rather than by composing primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>instance-based / feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Referenced with respect to categorization and how conceptual combination could be modeled (typicality, classification).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper only cites exemplar models as part of the landscape of conceptual-format proposals and does not present empirical tests specific to exemplar models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Mentioned alongside prototype theory and contrasted with compositional / language-like approaches; exemplar models would require mechanisms to generate novel composed concepts, whereas LOT/compositional accounts directly represent composition.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>No direct counter-evidence presented here; authors argue that their findings (children composing novel functions after learning primitives) are more naturally accounted for by systems that represent compositional operations, posing a challenge for pure exemplar-only accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Suggests exemplar approaches must explain how novel compositions are produced without explicit composition mechanisms; the experiment's success at composing novel operations favors models that can represent operations/functions rather than only stored instances.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8691.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Language of Thought (LOT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language of Thought (LOT) / symbolic compositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic, structured representational format positing that concepts are built compositionally from primitive functions and symbols (a 'mental language'); supports systematicity and productivity via function composition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Language of Thought (LOT) / symbolic compositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are represented as structured symbolic expressions built from primitive functions and combinatory operators (e.g., logical quantifiers, predicates, function composition f2(f1(x))). Functional-level behavior arises by composing these primitives into larger expressions that explicitly denote operations on entities or sets.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / compositional</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>This paper uses a novel behavioral task (car-with-iconic-screens single-screen training and two-screen composition test) designed to test children’s ability to represent functions and compose them predictively; referenced tasks include Boolean concept learning and adjective/noun compositionality in prior literature.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Children aged 3.5–4.5 performed significantly above chance on two-screen trials (chance 25%); overall intercept in mixed-effect logistic regression was significantly greater than chance (intercept β = −0.19 compared to logit(0.25), p < 0.001). Performance on two-screen compositions was comparable to single-screen performance (single-screen ~50%). Children succeeded especially on cross-dimension change pairs (CH-Color then CH-Pattern and vice versa: ~50–55% accuracy, p = 0.003 and p = 0.002 respectively), indicating ability to apply two operations in sequence without feedback. These results are presented as empirical support for LOT-style compositional representations (representation and composition of functions).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Paper frames LOT as a natural explanation for systematic compositional behavior and contrasts it with prototype/exemplar and non-compositional accounts; results are taken as 'consistent with' LOT models because children represent functions and combine them without explicit instruction, but the authors note that some non-compositional (constraint-based) models might also be constructed to explain the data and thus results are suggestive but not definitive.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Performance breakdown for two sequential changes within the same feature dimension (CH-Color then CH-Color or CH-Pattern then CH-Pattern) where children were at chance; this challenges a 'pure' unconstrained compositional account since composition should work regardless of feature dimension. The study cannot distinguish whether children form explicit symbolic compositions (f2∘f1) or only perform successive application f2(f1(x)).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors claim the data provide evidence that children can represent functions and compose them, supporting the plausibility of LOT-based learning models; they argue compositionality could be a core computational primitive that allows construction of arbitrarily complex concepts from few primitives (invoking lambda calculus/combinatory logic and Turing-completeness), and that compositional representations may underlie children's capacity for rich conceptual learning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8691.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boolean / Formal logic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Boolean/formal logical representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representational format that encodes concepts using formal logical primitives (e.g., AND, OR, NOT, quantifiers) to produce compositional structured representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Boolean / formal logical representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally described as logical formulas built from primitive logical operators; composition corresponds to applying logical operators to predicates to form more complex expressions (e.g., ∀x.sailboat(x) → heavy(x)).</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / logical</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Referenced historically and as a theoretical instantiation of compositionality (e.g., Boole, Frege); related to Boolean concept learning tasks in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper cites prior work (e.g., Feldman) using Boolean compositional systems to explain patterns in human concept learning, but provides no new empirical tests of pure Boolean formulations in this experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Presented as an exemplar of LOT-style symbolic compositional systems; compared conceptually to prototype/exemplar approaches which lack native logical composition mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>No direct experimental refutation in this study, but the same-dimension CH/CH breakdown raises the question of whether simple logical composition (which should be blind to feature-dimension interference) alone can explain children's failures without additional memory/processing constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Used to motivate the idea that symbolic composition can in principle construct arbitrarily complex concepts; the authors point out that the ability to compose functions is necessary for these logical systems to be behaviorally plausible in child cognition.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8691.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Functions-as-first-class-objects</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Functional representations / functions-as-first-class-objects</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where operations (functions) themselves are represented as mental entities that can be stored, manipulated, and composed to produce higher-order operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Functions-as-first-class-objects (functional representations)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>At a functional level, mental representations treat transformations as entities: each operation (e.g., 'change color to blue') is represented and can be applied to object representations; these function-objects can be composed (f2(f1(x))) or potentially chunked into composite functions (f2∘f1).</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / higher-order functional</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Directly tested by the car-and-screens task: learning single-screen operations (functions) and then predicting outcomes of two-screen sequences without feedback tests whether children represent functions and can compose them.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Children learned individual screen operations (single-screen accuracy ~50%, above chance 25%) and on two-screen trials were able to predict composed outcomes above chance overall (intercept greater than chance, p < 0.001). Specific evidence that children represent functions: they correctly applied combinations of two change operations across different dimensions (CH-Color/CH-Pattern and CH-Pattern/CH-Color) at ~50–55% accuracy, significantly above chance (p = 0.003 and p = 0.002). Error analyses show incorrect responses tended to correctly reflect the second screen more often than the first (β = 1.15, z = 4.946, p < 0.001), consistent with representations of individual functions and sequential application.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>The data are presented as supporting functional representations (and their composition) over non-functional formats that cannot naturally represent operations as manipulable entities; authors concede that some constraint-based or connectionist accounts might be formulated to mimic this behavior but would need to represent or implement function-like transformations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>The critical within-dimension CH-CH conditions (two rapid updates to the same variable) produced chance performance, indicating limitations in how functions are encoded/applied or in working-memory/processing when functions affect the same feature; also unresolved whether children form explicit composite function symbols (strong composition) or only run successive updates (weak composition).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors argue that representing functions as manipulable entities is a basic cognitive capacity in preschoolers and that such a capacity (together with composition) can underwrite complex learning using few primitives; functional representations may be the crucial mechanism that LOT-style theories assume for building higher-level cognition.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8691.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constraint-based (non-compositional) models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constraint-based / constraints-combination models (non-compositional explanations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Accounts that explain outcome predictions by combining constraints on possible outcomes rather than by explicit syntactic composition of functions; composition is achieved by intersecting or combining constraints imposed by each source of information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Constraint-based (non-compositional) representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, each cue or 'screen' provides a constraint on the possible resulting states (e.g., 'color must be blue or unchanged'); the predicted outcome is obtained by combining constraints (e.g., intersection of feasible outcomes) rather than by applying stored functions sequentially.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid / constraint-satisfaction (non-symbolic composition)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Offered as an alternative explanatory framework for the same car-with-screens task: children might combine constraints provided by each screen to infer outcomes without representing operations as composable functions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Authors note that constraint-based models could in principle capture the observed above-chance composition in many cases, but argue such models would struggle to naturally explain the within-dimension CH/CH breakdown and the detailed error patterns (e.g., second-screen bias) without ad-hoc mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Compared as an alternative to LOT/functional accounts; paper emphasizes that while constraint models might be constructed to fit overall performance, they may be less natural explanations of sequential application and of compositional chunking, and they must articulate combination rules that may look functionally equivalent to composition.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>The CH/CH within-dimension chance performance and the error bias favoring the second screen are presented as challenging for simple constraint-intersection accounts unless additional assumptions are introduced; authors state results are suggestive but not decisive against constraint-based models.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors suggest constraint-based accounts need to specify combination operations explicitly and that such specifications often become equivalent to function composition; whether constraint models can explain compositional generalization without presupposing compositional mechanisms is an open question raised by the paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8691.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8691.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Connectionist / PDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / parallel distributed processing (PDP) approaches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Distributed representation frameworks that encode concepts as patterns over units in a network and perform transformations via learned weights and activation dynamics rather than explicit symbolic composition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Connectionist / parallel distributed processing (PDP)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, knowledge is encoded in distributed activation patterns across units; transformations and 'composition' arise from network dynamics and weight-mediated interactions rather than explicit symbolic function objects; generalization emerges from learning mappings in hidden layers.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / sub-symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Discussed in the discussion as an important alternative research program; the authors ask whether connectionist systems can learn separate functions and generalize compositionally without additional training on compositions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>No empirical tests in this experiment; authors point out a theoretical challenge for connectionist models: to explain spontaneous composition of novel operations (two-screen trials without feedback) requires architectures that can combine learned transformations without being explicitly trained on the combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrast drawn between connectionist and LOT/symbolic approaches: LOT naturally encodes composition; the question for PDP is whether it can capture compositional generalization without implicitly assuming symbolic compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Paper does not present direct counter-evidence to PDP models but highlights conceptual difficulties in reproducing the observed behavior (spontaneous composition) in standard connectionist frameworks without additional mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors propose that if compositionality is fundamental, it may need to be built into models (as in LOT) or else connectionist architectures must demonstrate ways to implement compositional combination of independently learned functions; this represents an empirical and theoretical challenge for PDP.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The language of thought <em>(Rating: 2)</em></li>
                <li>Minimization of Boolean complexity in human concept learning <em>(Rating: 2)</em></li>
                <li>Bootstrapping in a language of thought: a formal model of numerical concept learning <em>(Rating: 2)</em></li>
                <li>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings <em>(Rating: 1)</em></li>
                <li>Parallel distributed processing <em>(Rating: 2)</em></li>
                <li>A Rational Analysis of Rule-Based Concept Learning <em>(Rating: 2)</em></li>
                <li>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings <em>(Rating: 1)</em></li>
                <li>Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8691",
    "paper_id": "paper-18949530",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory",
            "brief_description": "A representational format in which concepts are represented by an idealized or average 'prototype' carrying typical feature values; membership and similarity to the prototype determine category judgments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Prototype theory",
            "representational_format_description": "Concepts are functionally represented as prototypes — single summary exemplars (feature vectors or distributions of features) that encode the typical values of a category; conceptual judgments are made by comparing items to prototype representations (similarity computations).",
            "format_type": "feature-based / exemplar-summary (symbolic-ish but non-compositional)",
            "cognitive_task_or_phenomenon": "Mentioned in relation to categorization and conceptual structure (family resemblances, typicality effects).",
            "key_findings": "Paper only references prototype theory in the literature review as one of several proposed representational formats; no direct empirical tests in this experiment. The authors note prototype accounts as candidates for how concepts might be structured but do not test them.",
            "comparison_with_other_formats": "Contrasted in the introduction with compositional / language-like (LOT) approaches; the paper poses the question whether compositionality is built 'on top' of prototype-like formats or intrinsic to core representations. The experimental results are described as more directly indicative of compositional/function-based representations than simple prototype accounts, but not definitive against prototype models.",
            "limitations_or_counter_evidence": "No direct experimental evidence here against prototypes; the authors observe that prototype approaches must specify how combination/compositionality is achieved and that LOT-style accounts more naturally encode compositional combination of primitives.",
            "theoretical_claims_or_implications": "Prototype theory is presented as an alternative to compositional accounts; the paper implies that if children spontaneously compose functions, models that rely purely on prototype summaries would need an extra mechanism to explain combinatorial operations observed in the experiment.",
            "uuid": "e8691.0"
        },
        {
            "name_short": "Exemplar model",
            "name_full": "Exemplar theory / exemplar model",
            "brief_description": "A representational format where categories are stored as collections of individual exemplars; classification is based on similarity to remembered exemplars rather than abstract prototypes.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Exemplar model",
            "representational_format_description": "Functionally, concepts are represented as sets of remembered instances (feature vectors); judgments are computed by measuring similarity/aggregate similarity across stored exemplars rather than by composing primitives.",
            "format_type": "instance-based / feature-based",
            "cognitive_task_or_phenomenon": "Referenced with respect to categorization and how conceptual combination could be modeled (typicality, classification).",
            "key_findings": "The paper only cites exemplar models as part of the landscape of conceptual-format proposals and does not present empirical tests specific to exemplar models.",
            "comparison_with_other_formats": "Mentioned alongside prototype theory and contrasted with compositional / language-like approaches; exemplar models would require mechanisms to generate novel composed concepts, whereas LOT/compositional accounts directly represent composition.",
            "limitations_or_counter_evidence": "No direct counter-evidence presented here; authors argue that their findings (children composing novel functions after learning primitives) are more naturally accounted for by systems that represent compositional operations, posing a challenge for pure exemplar-only accounts.",
            "theoretical_claims_or_implications": "Suggests exemplar approaches must explain how novel compositions are produced without explicit composition mechanisms; the experiment's success at composing novel operations favors models that can represent operations/functions rather than only stored instances.",
            "uuid": "e8691.1"
        },
        {
            "name_short": "Language of Thought (LOT)",
            "name_full": "Language of Thought (LOT) / symbolic compositional representation",
            "brief_description": "A symbolic, structured representational format positing that concepts are built compositionally from primitive functions and symbols (a 'mental language'); supports systematicity and productivity via function composition.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Language of Thought (LOT) / symbolic compositional representation",
            "representational_format_description": "Concepts are represented as structured symbolic expressions built from primitive functions and combinatory operators (e.g., logical quantifiers, predicates, function composition f2(f1(x))). Functional-level behavior arises by composing these primitives into larger expressions that explicitly denote operations on entities or sets.",
            "format_type": "symbolic / compositional",
            "cognitive_task_or_phenomenon": "This paper uses a novel behavioral task (car-with-iconic-screens single-screen training and two-screen composition test) designed to test children’s ability to represent functions and compose them predictively; referenced tasks include Boolean concept learning and adjective/noun compositionality in prior literature.",
            "key_findings": "Children aged 3.5–4.5 performed significantly above chance on two-screen trials (chance 25%); overall intercept in mixed-effect logistic regression was significantly greater than chance (intercept β = −0.19 compared to logit(0.25), p &lt; 0.001). Performance on two-screen compositions was comparable to single-screen performance (single-screen ~50%). Children succeeded especially on cross-dimension change pairs (CH-Color then CH-Pattern and vice versa: ~50–55% accuracy, p = 0.003 and p = 0.002 respectively), indicating ability to apply two operations in sequence without feedback. These results are presented as empirical support for LOT-style compositional representations (representation and composition of functions).",
            "comparison_with_other_formats": "Paper frames LOT as a natural explanation for systematic compositional behavior and contrasts it with prototype/exemplar and non-compositional accounts; results are taken as 'consistent with' LOT models because children represent functions and combine them without explicit instruction, but the authors note that some non-compositional (constraint-based) models might also be constructed to explain the data and thus results are suggestive but not definitive.",
            "limitations_or_counter_evidence": "Performance breakdown for two sequential changes within the same feature dimension (CH-Color then CH-Color or CH-Pattern then CH-Pattern) where children were at chance; this challenges a 'pure' unconstrained compositional account since composition should work regardless of feature dimension. The study cannot distinguish whether children form explicit symbolic compositions (f2∘f1) or only perform successive application f2(f1(x)).",
            "theoretical_claims_or_implications": "Authors claim the data provide evidence that children can represent functions and compose them, supporting the plausibility of LOT-based learning models; they argue compositionality could be a core computational primitive that allows construction of arbitrarily complex concepts from few primitives (invoking lambda calculus/combinatory logic and Turing-completeness), and that compositional representations may underlie children's capacity for rich conceptual learning.",
            "uuid": "e8691.2"
        },
        {
            "name_short": "Boolean / Formal logic",
            "name_full": "Boolean/formal logical representations",
            "brief_description": "Representational format that encodes concepts using formal logical primitives (e.g., AND, OR, NOT, quantifiers) to produce compositional structured representations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Boolean / formal logical representation",
            "representational_format_description": "Concepts are functionally described as logical formulas built from primitive logical operators; composition corresponds to applying logical operators to predicates to form more complex expressions (e.g., ∀x.sailboat(x) → heavy(x)).",
            "format_type": "symbolic / logical",
            "cognitive_task_or_phenomenon": "Referenced historically and as a theoretical instantiation of compositionality (e.g., Boole, Frege); related to Boolean concept learning tasks in the literature.",
            "key_findings": "Paper cites prior work (e.g., Feldman) using Boolean compositional systems to explain patterns in human concept learning, but provides no new empirical tests of pure Boolean formulations in this experiment.",
            "comparison_with_other_formats": "Presented as an exemplar of LOT-style symbolic compositional systems; compared conceptually to prototype/exemplar approaches which lack native logical composition mechanisms.",
            "limitations_or_counter_evidence": "No direct experimental refutation in this study, but the same-dimension CH/CH breakdown raises the question of whether simple logical composition (which should be blind to feature-dimension interference) alone can explain children's failures without additional memory/processing constraints.",
            "theoretical_claims_or_implications": "Used to motivate the idea that symbolic composition can in principle construct arbitrarily complex concepts; the authors point out that the ability to compose functions is necessary for these logical systems to be behaviorally plausible in child cognition.",
            "uuid": "e8691.3"
        },
        {
            "name_short": "Functions-as-first-class-objects",
            "name_full": "Functional representations / functions-as-first-class-objects",
            "brief_description": "A representational format where operations (functions) themselves are represented as mental entities that can be stored, manipulated, and composed to produce higher-order operations.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Functions-as-first-class-objects (functional representations)",
            "representational_format_description": "At a functional level, mental representations treat transformations as entities: each operation (e.g., 'change color to blue') is represented and can be applied to object representations; these function-objects can be composed (f2(f1(x))) or potentially chunked into composite functions (f2∘f1).",
            "format_type": "symbolic / higher-order functional",
            "cognitive_task_or_phenomenon": "Directly tested by the car-and-screens task: learning single-screen operations (functions) and then predicting outcomes of two-screen sequences without feedback tests whether children represent functions and can compose them.",
            "key_findings": "Children learned individual screen operations (single-screen accuracy ~50%, above chance 25%) and on two-screen trials were able to predict composed outcomes above chance overall (intercept greater than chance, p &lt; 0.001). Specific evidence that children represent functions: they correctly applied combinations of two change operations across different dimensions (CH-Color/CH-Pattern and CH-Pattern/CH-Color) at ~50–55% accuracy, significantly above chance (p = 0.003 and p = 0.002). Error analyses show incorrect responses tended to correctly reflect the second screen more often than the first (β = 1.15, z = 4.946, p &lt; 0.001), consistent with representations of individual functions and sequential application.",
            "comparison_with_other_formats": "The data are presented as supporting functional representations (and their composition) over non-functional formats that cannot naturally represent operations as manipulable entities; authors concede that some constraint-based or connectionist accounts might be formulated to mimic this behavior but would need to represent or implement function-like transformations.",
            "limitations_or_counter_evidence": "The critical within-dimension CH-CH conditions (two rapid updates to the same variable) produced chance performance, indicating limitations in how functions are encoded/applied or in working-memory/processing when functions affect the same feature; also unresolved whether children form explicit composite function symbols (strong composition) or only run successive updates (weak composition).",
            "theoretical_claims_or_implications": "Authors argue that representing functions as manipulable entities is a basic cognitive capacity in preschoolers and that such a capacity (together with composition) can underwrite complex learning using few primitives; functional representations may be the crucial mechanism that LOT-style theories assume for building higher-level cognition.",
            "uuid": "e8691.4"
        },
        {
            "name_short": "Constraint-based (non-compositional) models",
            "name_full": "Constraint-based / constraints-combination models (non-compositional explanations)",
            "brief_description": "Accounts that explain outcome predictions by combining constraints on possible outcomes rather than by explicit syntactic composition of functions; composition is achieved by intersecting or combining constraints imposed by each source of information.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Constraint-based (non-compositional) representations",
            "representational_format_description": "Functionally, each cue or 'screen' provides a constraint on the possible resulting states (e.g., 'color must be blue or unchanged'); the predicted outcome is obtained by combining constraints (e.g., intersection of feasible outcomes) rather than by applying stored functions sequentially.",
            "format_type": "hybrid / constraint-satisfaction (non-symbolic composition)",
            "cognitive_task_or_phenomenon": "Offered as an alternative explanatory framework for the same car-with-screens task: children might combine constraints provided by each screen to infer outcomes without representing operations as composable functions.",
            "key_findings": "Authors note that constraint-based models could in principle capture the observed above-chance composition in many cases, but argue such models would struggle to naturally explain the within-dimension CH/CH breakdown and the detailed error patterns (e.g., second-screen bias) without ad-hoc mechanisms.",
            "comparison_with_other_formats": "Compared as an alternative to LOT/functional accounts; paper emphasizes that while constraint models might be constructed to fit overall performance, they may be less natural explanations of sequential application and of compositional chunking, and they must articulate combination rules that may look functionally equivalent to composition.",
            "limitations_or_counter_evidence": "The CH/CH within-dimension chance performance and the error bias favoring the second screen are presented as challenging for simple constraint-intersection accounts unless additional assumptions are introduced; authors state results are suggestive but not decisive against constraint-based models.",
            "theoretical_claims_or_implications": "Authors suggest constraint-based accounts need to specify combination operations explicitly and that such specifications often become equivalent to function composition; whether constraint models can explain compositional generalization without presupposing compositional mechanisms is an open question raised by the paper.",
            "uuid": "e8691.5"
        },
        {
            "name_short": "Connectionist / PDP",
            "name_full": "Connectionist / parallel distributed processing (PDP) approaches",
            "brief_description": "Distributed representation frameworks that encode concepts as patterns over units in a network and perform transformations via learned weights and activation dynamics rather than explicit symbolic composition.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Connectionist / parallel distributed processing (PDP)",
            "representational_format_description": "Functionally, knowledge is encoded in distributed activation patterns across units; transformations and 'composition' arise from network dynamics and weight-mediated interactions rather than explicit symbolic function objects; generalization emerges from learning mappings in hidden layers.",
            "format_type": "distributed / sub-symbolic",
            "cognitive_task_or_phenomenon": "Discussed in the discussion as an important alternative research program; the authors ask whether connectionist systems can learn separate functions and generalize compositionally without additional training on compositions.",
            "key_findings": "No empirical tests in this experiment; authors point out a theoretical challenge for connectionist models: to explain spontaneous composition of novel operations (two-screen trials without feedback) requires architectures that can combine learned transformations without being explicitly trained on the combinations.",
            "comparison_with_other_formats": "Contrast drawn between connectionist and LOT/symbolic approaches: LOT naturally encodes composition; the question for PDP is whether it can capture compositional generalization without implicitly assuming symbolic compositionality.",
            "limitations_or_counter_evidence": "Paper does not present direct counter-evidence to PDP models but highlights conceptual difficulties in reproducing the observed behavior (spontaneous composition) in standard connectionist frameworks without additional mechanisms.",
            "theoretical_claims_or_implications": "Authors propose that if compositionality is fundamental, it may need to be built into models (as in LOT) or else connectionist architectures must demonstrate ways to implement compositional combination of independently learned functions; this represents an empirical and theoretical challenge for PDP.",
            "uuid": "e8691.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The language of thought",
            "rating": 2,
            "sanitized_title": "the_language_of_thought"
        },
        {
            "paper_title": "Minimization of Boolean complexity in human concept learning",
            "rating": 2,
            "sanitized_title": "minimization_of_boolean_complexity_in_human_concept_learning"
        },
        {
            "paper_title": "Bootstrapping in a language of thought: a formal model of numerical concept learning",
            "rating": 2,
            "sanitized_title": "bootstrapping_in_a_language_of_thought_a_formal_model_of_numerical_concept_learning"
        },
        {
            "paper_title": "A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings",
            "rating": 1,
            "sanitized_title": "a_computational_study_of_crosssituational_techniques_for_learning_wordtomeaning_mappings"
        },
        {
            "paper_title": "Parallel distributed processing",
            "rating": 2,
            "sanitized_title": "parallel_distributed_processing"
        },
        {
            "paper_title": "A Rational Analysis of Rule-Based Concept Learning",
            "rating": 2,
            "sanitized_title": "a_rational_analysis_of_rulebased_concept_learning"
        },
        {
            "paper_title": "A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings",
            "rating": 1,
            "sanitized_title": "a_computational_study_of_crosssituational_techniques_for_learning_wordtomeaning_mappings"
        },
        {
            "paper_title": "Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue.",
            "rating": 1,
            "sanitized_title": "connectionism_and_cognitive_architecture_a_critical_analysis_connections_and_symbols_a_cognition_special_issue"
        }
    ],
    "cost": 0.013278499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Compositional Reasoning in Early Childhood</p>
<p>Steven Piantadosi *spiantado@gmail.com 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Richard Aslin 
Department of Brain and Cognitive Sciences
University of Rochester
RochesterNYUnited States of America</p>
<p>Compositional Reasoning in Early Childhood
RESEARCH ARTICLE
Compositional "language of thought" models have recently been proposed to account for a wide range of children's conceptual and linguistic learning. The present work aims to evaluate one of the most basic assumptions of these models: children should have an ability to represent and compose functions. We show that 3.5-4.5 year olds are able to predictively compose two novel functions at significantly above chance levels, even without any explicit training or feedback on the composition itself. We take this as evidence that children at this age possess some capacity for compositionality, consistent with models that make this ability explicit, and providing an empirical challenge to those that do not.</p>
<p>Introduction</p>
<p>One of the basic goals of cognitive science is to understand the nature of conceptual representations. Proposals for the format and structure of concepts range through theories based on prototypes [1], exemplars [2,3], language-like representations [4], and others [5]. A central issue for all approaches is that of compositionality-how to handle the combination of individual concepts into more complex representations (e.g. "beautiful" composed with "accordions" yields a composite concept, "beautiful accordions") [6][7][8][9]. This ability may be built "on top" of a representational format like prototypes [10] or it may be intrinsically a part of the core conceptual representation itself, as is hypothesized in language of thought (LOT) theories. According to LOT theories, the formation of a complex thought like "all sailboats are heavy" occurs when thinkers construct the corresponding compositional structure built out of simpler operations. For instance, such a conceptual format may be similar to standard logic: 8x.sailboat(x)! heavy(x). Here, 8, sailboat and heavy are functions that are composed in one particular way to express the composite idea "all sailboats are heavy." These functions may themselves be built out of simpler operations, but in LOT theories eventually this process grounds out in primitive functions from which all other thoughts and representations are derived.</p>
<p>LOT theories are motivated in part by the rich structure human concepts appear to easily represent, as well as by factors like the systematicity, productivity, and compositionality of cognition [11]. Indeed, the LOT has a rich history in cognitive science, dating back at least to Boole [12] and later Frege [13]. Boole sought to characterize the "laws of thought" and did so by postulating the formal logical system of Boolean logic, which builds logical representations (formulas) out of the logical primitives and, or, and not. More recent incarnations of LOT theories have argued specifically for compositional, symbolic representations as fuller cognitive theories encompassing a wider range of semantic and logical operations [4]. A structured LOT has also been argued to explain developmental change in concept and language learning [14][15][16][17][18][19][20][21], providing a convenient formalism to express both what learners bring to learning tasks (primitive functions), and what exactly they acquire (compositions of those functions to explain observed data). For instance, Piantadosi et al. [21] suggest that children may know about simple functions on sets (e.g. union, intersection, etc.) and build more complex representations of cardinality and counting by appropriately composing these operations. This type of general approach builds on work of Feldman [22] who used a compositional system to explain patterns in Boolean concept learning, and Siskind [14] who first developed a compositional account of learning semantics. Following Goodman et al. [16], many recent theories posit rational (Bayesian) statistical models as the core inductive mechanism that decides between possible combinations of primitives in the face of data. In all cases-dating back to Boole-the core claim is that composition of simple primitive functions is what allows for the creation of complex cognitive representations.</p>
<p>While learning studies and modeling work have established LOT-based models as plausible in principle, no experimental work has examined LOT models' most basic assumptions: learners should be able to represent functions and combine them through composition. This ability should be present without any explicit instruction on either the fact that functions can be composed, or what happens when they are composed. This ability is not trivial. Functions may perform many kinds of operations and in principle function combination can be used to express arbitrary computation [23][24][25].</p>
<p>To be clear, we focus here on conceptual compositionality (combinations of concepts), not linguistic compositionality (combinations of words in sentences), which has been studied previously [26][27][28][29]. The reason for this is that acquisition models have so far focused on learning either individual word meanings by composing simpler conceptual elements [14] or using compositional LOT systems to learn non-linguistic systems of concepts like magnetism [19]. In these cases, the learning models therefore make the strong prediction that children should be able to compose operations outside of the domain of language. Note that an ability to compose linguistic expressions does not establish that children will be able to compose conceptual operations; the compositionality of linguistics may or may not be encapsulated within language processing. The present work takes a first step towards investigating non-linguistic conceptual combination in children.</p>
<p>Of course, it is important to note that many tasks can be interpreted as compositional, depending on how they are formalized. Even, for instance, Sally-Ann [30] or simple numerical tasks with infants [31] require multiple updates to a representation, and therefore can be phrased as compositions of functions. Here, however, we approach compositionality from a more directed stance, constructing an experiment that is difficult to interpret in any way but compositional. The general logic of our experiment is to teach children that certain "screens" (occluders) cause specific feature changes (color or pattern) to an occluded object. The critical test conditions occur when two such screens are adjacent and children observe an object go behind both screens but they do not observe it between screens. Prediction of the correct outcome in this case requires them to apply both object transformations. Children receive no feedback on their responses to the compositional (two-screen) trials, meaning that success is indicative of automatic compositional reasoning without instruction or encouragement.</p>
<p>This experiment tests whether children can compute a composition of functions like f 2 (f 1 (x)), where f 2 is the second screen and f 1 is the first. However, there is a stronger sense in which learners might "know" compositionality: they might be able to form an explicit symbol h = f 2 (f 1 (x)) for the composition itself. Creating such a symbol is not a necessary ability for success on our task. In a linguistic analogy, the strong form of compositionality is tantamount to knowing that the term (symbol) "pit stop" refers to "refueling" and "changing tires." The weaker form corresponds to being able to refuel and then change tires, without knowing that there is a term or symbol that refers to the combination of both operations. Because we are just beginning to explore the type of compositional reasoning in a non-linguistic task, we start by investigating the developmental origins of the weaker sense: can preschoolers predictively compose novel operations? Or, do they show catastrophic failures when attempting to combine multiple functions, perhaps reminiscent of younger children's limitations with multiple updates to representations of objects or numerosity [32][33][34]?</p>
<p>Methods</p>
<p>In the experiment, preschoolers were shown displays on a touchscreen monitor in which a car with a colored pattern appeared. Cars had one of two patterns (dots/stars) occurring in one of two colors (red/blue). A car with one choice of these features drove on-screen and children were required to select which pattern it matched from a menu with all four possible options (Fig 1a). This ensured that they attended to the features of the cars and knew them at the start of each trial. For this response, children were required to respond until they answered correctly, with incorrect responses penalized by a buzzing noise and correct responses rewarded by a trumpet sound. The car then drove behind a single screen, making its pattern (but not wheels) occluded (Fig 1b). It jiggled behind the screen to indicate that a transformation was taking place. Children then responded with what they expected the car to look like when the screen lifted.</p>
<p>The experiment began with 6 explicit training trials in which children were provided with verbal feedback and instruction on the operation provided by each of the screens. Participants then entered an second training phase in which they received no verbal feedback from the experimenter, but were required to answer single-screen trials until correct, at which time the screen lifted to reveal the correct outcome (Fig 1c). Presentation of operations in this phase was in blocks of 6 single operations (red, blue, dots, stars, and two with no changes, in random order).</p>
<p>Children stayed in the training phase until they answered 5 out of 6 correct in a block. After meeting this criterion, the experiment progressed to a test phase. Here, children were shown blocks containing 2 single screen displays with feedback, and 4 two-screen displays without feedback (Fig 1d). In these critical trials, children observed the car pass behind one screen, then the next, without seeing it in between. As in training, they were required to answer correctly to the first question on the car's initial pattern, but crucially received no feedback on their selected outcome after the car had passed behind both screens. The screens never lifted to reveal the car after selection and the experiment simply progressed to the next trial.</p>
<p>Screens were chosen to be iconic of the color and pattern transformations because we are primarily interested in how children combine these operations when they know them, not how hard it is for children to learn each individual function. However, sometimes the screen would not cause a change-for instance, if a car with blue dots drove behind a blue screen. These trials were included in order to ensure that children really paid attention to the pattern on the screens and did not just "flip" the relevant dimension. We refer to transformations in which a feature changed (e.g. red car behind blue screen) as change (CH) screens, and transformations which did not change a feature (e.g. blue car behind blue screen) as identity (ID) screens.</p>
<p>Children were run in the experiment for a maximum of approximately 30 minutes, and were shown a short "reward" animation every three responses in order to keep the experiment interesting. Stimuli were presented using Kelpy, the Kid Experimental Library in Python, which is available under the GNU Public License from the first author [35]. This study was approved by the University of Rochester Research Subjects Review Board. Written informed consent was gathered from parents/guardians of the children involved.</p>
<p>Participants</p>
<p>Twenty-one children (10 females and 11 males) aged approximately 3.5-4.5 years (mean: 50.9 months; range: 42.9 to 53.9 months) were recruited to the Rochester Baby Lab. In order to assess overall levels of performance, all subjects were included in the following analysis, although two did not progress out of training.  subject intercepts and slopes by function type [36]. This type of analysis is well-suited to unbalanced designs where children have been run for varying amounts of test and training items. The red line corresponds to a chance rate of 25%, for guessing at random from the four possible choices. This figure shows that in each condition children are substantially above chance on single screen displays. They thus learned the operations performed by each iconic screen. However, children are not very good at this task-their overall accuracy is near 50%. This likely results from the fact that the task is somewhat complex, requiring tracking of multiple values of multiple dimensions.</p>
<p>Results</p>
<p>Critical two-screen test trials are shown in Fig 3. Again, error bars were computed via a mixed effect logistic regression with subject intercepts by function type (a model with random slopes did not converge). First, this figure shows that the overall mean response (teal bar) is substantially higher than the chance rate of 25%. The overall accuracy is also only slightly worse than the overall accuracy on single screen displays, meaning that knowledge of compositions is available to learners after training on single screens despite the fact that feedback was never provided on these two-screen trials. The other bars in this plot show performance broken down by the type of function performed by each of the two screens. Despite above chance performance overall, children are at chance in conditions involving feature changes within the same dimension (e.g. CH-Color/ CH-Color). In such a condition, a red circle car would go behind a blue screen (changing its color) and then behind a red screen (changing its color again). This requires keeping track of several different values within the same dimension, and-because the features are binary-realizing that a feature changes and then reverts back to its original value. Note that children are not just having difficulty in this condition in tracking the order in which the functions applied: that would predict 50% performance in these conditions (since children would have the other dimension right). Instead, it appears that children's performance breaks down completely in this case, not unlike total breakdowns seen in object tracking [32][33][34].</p>
<p>These detailed patterns of responses also rule out several other hypotheses about children's performance. First, it is clear that children are not above chance by merely applying one of the two screens. Such a tactic would predict 0% accuracy on conditions with two changes (e.g. CH-Color-CH-Pattern and CH-Pattern-CH-Shape) since application of only one screen would always give the wrong answer. Instead, children performed particularly well in these two conditions, with a mean accuracy of nearly 50%, trending above even the overall experiment mean. Responses in these conditions are each individually significantly above the 25% chance level (CH-Color-CH-Pattern accuracy is 50%, p = 0.003 when compared to chance; CH-Pattern-  CH-Color is 55%, p = 0.002 when compared to chance). Children's success in these conditions provides strong evidence that they do not simply choose one box to apply.</p>
<p>Moreover, children's performance surpasses their expected performance based on their ability to apply single screens. The blue dots in Fig 3 show the performance that would be expected if children's accuracy was determined by independent application of each function, with individual function accuracies determined by the performance on single boxes. Thus, the blue dot for CH-Color/CH-Pattern corresponds to the probability of success on a CH-Color operation followed by the probability of success on a CH-Pattern operation, according to Fig 2. Because the accuracies in Fig 2 are near 50% for each function type, application of two of these correctly is near 25%(= 0.5 Á 0.5). Across nearly all function types other than changes within the same dimension, children are substantially above this performance level. This suggests that their failures are not due to independent failures on each screen. This pattern could occur if, for instance, children's low accuracy in Fig 2 was driven by not paying attention on all trials, rather than not knowing the right answer.</p>
<p>Responses were also analyzed using a mixed-effect logistic regression [36] with intercepts by subject (a model with random slopes did not converge). This analysis lets us simultaneously evaluate the influence of multiple factors of children's response accuracies, and determine their mean accuracy while controlling these factors. Fig 4 shows estimated coefficients and standard errors. The coefficients here correspond to whether the first function is an identity function (Identity F1), the second is an identity (Identity F2; this is computed as whether the second function is an identity function on the output of the first function), the first change is a color dimension (IsColor F1), the second is the same feature dimension as the first (SameDimension), children's age, whether the child is male, the child's training accuracy, the number of items it took the child to progress on to testing, and the number of test items seen so far. The binary predictors here (Identity F1, Identity F2, IsColor F1, SameDimension, IsMale) are all negative sum coded and the continuous predictors are all standardized, meaning that the intercept can be interpreted as the mean response accuracy across all predictors. In this figure, coefficients far from the zero line indicate significant influences on response accuracy. This shows that there are three significant predictors: children are substantially worse when both boxes operate on the same dimension (SameDimension) (β = −0.50,z = −4.23,p &lt; 0.001). This means that when the first box changes a color, children are worse when the second box also changes a color, and analogously when both boxes change pattern. Children are worse when they take longer to reach testing (β = −0.25, z = 2.14, p = 0.03). Children with better training accuracy also perform better on testing (β = 0.54, z = 4.40, p &lt; 0.001). Importantly, the intercept here represents the mean accuracy controlling for all other effects. This shows that the intercept (β = −0.19) is significantly higher than the chance rate logit(0.25) shown by the red dot in the graph (p &lt; 0.001), indicating that children are substantially above the chance guessing rate. They are not, however, significantly different from 50% accuracy (p = 0.15). These results revealed no significant effect of age, indicating that we have no evidence older children are better at this task. This might suggest that such compositional reasoning is attained earlier than about 3.5 years of age so that children in the range 3.5 * 4.5 are not differentially capable of dealing with composition.</p>
<p>We additionally analyzed the pattern of errors children made in their responses. To do this, we looked only at incorrect responses and tried to predict which components of an incorrect response children were likely to get correct. In a mixed effect regression, we found that these responses were substantially more likely to provide a response with the second screen correctly applied rather than the first (β = 1.15, z = 4.946, p &lt; 0.001). This effect was independent of whether the first and second screens were colors or not (|β|&lt;0.1, z &lt; 0.5, p &gt; 0.65). This suggests that children's difficulty with composition may be in tracking or encoding the features of the car and the first screen while focusing on the second, temporally more recent, screen.</p>
<p>Discussion</p>
<p>These results provide evidence that preschoolers spontaneously infer the outcome of combinations of function applications after receiving training on only the individual pieces. Their performance on two screen displays-though not perfect-is comparable to their performance on single screen displays. These results suggest that knowledge of composition does not require training for preschoolers beyond learning the individual pieces: children at this age have already learned how to predictively combine operations. This does not mean that children have never required instruction (or data) for learning about composition, but it does mean that whatever they have learned before the experiment began is abstract enough to apply to novel functions.</p>
<p>It is worth noting that while our experiments were motivated by compositionality, there are likely non-compositional models that could capture these results. For instance, children may learn that each screen constrains the possible outcomes, and combine constraints in order to predict the outcome. The challenge for these theories would be to state combination in a way that cannot be viewed (or perhaps cannot be viewed naturally) as function composition. There are also challenging data points for such theories even in this simple experiment: for instance, they would have a difficult time explaining why children are below 50% on within-dimension CH/CH trials, a fact that almost certainly depends on the details of how constraints may be combined. Stronger results could likely be provided by displays with more features and operations in order to fully probe the extent of children's ability and distinguish alternative models. We therefore take our results as a first step that provides suggestive-not definitive-evidence for compositionality.</p>
<p>Our analysis revealed some subtle facts about which compositions are easy and difficult for young learners. Changes within the same feature dimension are difficult, but two changes across dimensions are as easy as one. The limitation within dimensions presents a challenge to the purest form of compositional theories: what type of mechanism could correctly compose, but only when the composed functions operate on separate feature dimensions? One theory is that setting a feature value in memory is slow. Thus, when the value of two features change rapidly, children may get confused about what the resulting value is. On the other hand, if one feature changes and then a different feature changes, both "write" processes can occur in parallel and not interfere with each other. Difficulties dealing with rapidly sequential updates to a variable are common in parallel programming in computer science, (resulting in a so-called race condition). This view is consistent with the pattern of children's errors, where it appears that the transformation of the first screen is most likely to get overwritten or lost.</p>
<p>Interestingly, however, children's performance is also below 50%, indicating that their failure is perhaps more than a problem with remembering both screens. It is more likely to be a complete breakdown, because forgetting a single screen would still give 50% performance in the two-screen trials (since half the time, one will be an identity screen). This may indicate that memory mechanisms are fundamentally incapable of tracking multiple updates to the same feature dimension, perhaps because two rapid updates interfere in a particularly destructive way.</p>
<p>In the introduction, we discussed two forms of compositionality corresponding to whether learners explicitly represent a combination of functions f 2 ⚬ f 1 or whether they merely have the capacity to successively apply them to a representation f 2 (f 1 (x)). The present experiment does not strongly distinguish between these possibilities; it is possible that children only track the object moving behind the screens, successively updating its visual features (corresponding to f 2 (f 1 (x))). It is also possible that children could explicitly know that two screens together can be chunked into a single unit, the function f 2 ⚬ f 1 . These possibilities might be disentangled by future work where children's ability to treat compositional functions as single units (e.g. in other compositions) could be evaluated.</p>
<p>In addition to demonstrating compositional ability, these results also suggest that children aged 3.5 * 4.5 are able to represent functions, not itself a trivial capacity. In particular, to perform above chance children must be able to represent the fact that each of four screens performs a particular change to an object's features, and that that change occurs even if the outcome is not directly observed. Such an ability to represent functions themselves might be viewed as an even more basic ability than compositionality. However, fluency with functions can only yield more complex computations if those functions can be combined to form novel combinations-which our results indicate preschoolers are likely able to do.</p>
<p>We consider this capacity for representing functions themselves as potentially a basic fact about the organization of cognitive computation. In modern computer systems, encapsulated functions play a critical role by allowing complex computations to efficiently and easily be built from simpler components. For instance, programs are constructed only out of simpler elementary operations (e.g. +, −, Á, /, for, if, etc.) which are eventually directly interpretable by the computer's hardware. Using only these kinds of primitive functions, one can create a structure implementing a more complex computation, like f(x) = x Á x Á x+x − (x+1)/x. The capacity to combine such elementary operations in arbitrary ways is extremely powerful, and an ability to manipulate functions themselves potentially allows a huge range of computations to be executed using very little "built in" knowledge (ie. few primitives). Indeed, the simplest computational systems like lambda calculus [23,25] and combinatory logic [24,37] "build in" almost nothing, essentially only the rules of function composition. A striking result in formal logic holds that arbitrary (ie. Turing-complete) computational processes can then be built out of nothing more than this capacity for composition [23]. This means that the ability of children to represent, manipulate, and compose functions may point to how they are able to acquire operations of substantial computational complexity, while requiring only very simple cognitive machinery. In this sense, compositionality may be the key component of LOT theories that allows arbitrarily complex computations to be represented by learners.</p>
<p>Our study was in large part motivated by LOT learning models, but it is also interesting to consider how to interpret these results in the context of larger theoretical divides in cognitive science. It may be productive, for example, to determine how such learning might be captured in connectionist or parallel distribution processing [38] approaches: how might one capture learning of separate functions which can be composed, without requiring any additional training on composition? Is it possible to set up such a system in a way that cannot be interpreted as presupposing compositionality itself? Or, it may be that compositionality is basic enough that, as in LOT theories, it should be assumed as a core computational primitive.</p>
<p>Conclusion</p>
<p>These results are an early step in linking contemporary structured learning models with infant and early childhood experimental studies. An ability to combine novel functions appears to be robustly present by three or four years of age, with children requiring no explicit training on combination once they have learned individual functions. This suggests that learning theories based around assuming compositionality are behaviorally plausible and that a capacity for combining mental operations may be one of the mechanisms that supports children's creation of rich conceptual systems.</p>
<p>Fig 2
2shows mean first response accuracies to single screen trials, broken down by each type of function: change (CH) color, change pattern, identity (ID) color, identity pattern. Means and standard errors were computed using a mixed effect logistic regression, taking into account</p>
<p>Fig 1 .
1The four phases of the experiment. First, a truck is observed (a) and children are required to touch which pattern of the four possible patterns in the box matches the car. The response of the first pattern on the car stays on the screen (right box in (b)) and the car moves behind a screen with an iconic representation of its operation. Children are then asked to predict the outcome with a new set of four choices on the left (b). In training trials (b), children answer until they are correct and then see the screen lift to reveal the car with the new pattern (c). The critical response in test trials is shown in (d), with the car occluded after passing behind two screens. No feedback is provided on these trials. doi:10.1371/journal.pone.0147734.g001</p>
<p>Fig 2 .
2Mean response accuracies to single screens which performed change (CH) or identity (ID) operations. A chance rate of 25% is shown by the dotted red line. doi:10.1371/journal.pone.0147734.g002</p>
<p>Fig 3 .
3Mean response accuracies to double screens, each of which performed change (CH) or identity (ID) operations. Error bars show confidence intervals. A chance rate of 25% is shown by the dotted red line. The blue dots correspond to the accuracy predicted under independent application of the single function accuracies in Fig 2.</p>
<p>doi:10.1371/journal.pone.0147734.g003</p>
<p>Fig 4 .
4Coefficients in a mixed-effect logistic regression predicting accuracy on test (two-screen) trials from a number of predictors. There intercept here, representing the mean accuracy, should be compared to the chance rate of 1/4 (red dot, at logit(0.25) on this scale), the overall chance guessing rate for 4 options. All other coefficients should be compared to the x = 0 line, showing whether they had a statistically significant influence on response accuracy. Effects significant at p &lt; 0.05) are shown with gray bars. doi:10.1371/journal.pone.0147734.g004
PLOS ONE | DOI:10.1371/journal.pone.0147734 September 2, 2016
AcknowledgmentsThis work benefited greatly from discussions with Roman Feiman, Celeste Kidd, Noah Goodman, and members of AKlab. Children were run with the help of Holly Palmeri and the Rochester Babylab RAs. Research reported in this publication was supported by the Eunice Kennedy Shriver National Institute Of Child Health &amp; Human Development of the National Institutes of Health under Award Number F32HD070544 and an NIH research grant to R. Aslin and E. Newport (HD-037082). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.
Family resemblances: Studies in the internal structure of categories. E Rosch, C B Mervis, 10.1016/0010-0285(75)90024-9Cognitive psychology. 74Rosch E, Mervis CB. Family resemblances: Studies in the internal structure of categories. Cognitive psychology. 1975; 7(4):573-605. doi: 10.1016/0010-0285(75)90024-9</p>
<p>Context theory of classification learning. D L Medin, M M Schaffer, 10.1037/0033-295X.85.3.207Psychological review. 853Medin DL, Schaffer MM. Context theory of classification learning. Psychological review. 1978; 85 (3):207-238. doi: 10.1037/0033-295X.85.3.207</p>
<p>The exemplar view. Foundations of cognitive psychology: Core readings. E E Smith, D L Medin, Smith EE, Medin DL. The exemplar view. Foundations of cognitive psychology: Core readings. 2002; p. 277-292.</p>
<p>The language of thought. J A Fodor, Harvard University PressCambridge, MAFodor JA. The language of thought. Cambridge, MA: Harvard University Press; 1975.</p>
<p>Concepts: Core Readings. E Margolis, S Laurence, The MIT PressCambridge, MAMargolis E., Laurence S. Concepts: Core Readings. Cambridge, MA: The MIT Press; 1999.</p>
<p>On the adequacy of prototype theory as a theory of concepts. D N Osherson, E E Smith, 10.1016/0010-0277(81)90013-5Cognition. 91Osherson DN, Smith EE. On the adequacy of prototype theory as a theory of concepts. Cognition. 1981; 9(1):35-58. doi: 10.1016/0010-0277(81)90013-5 PMID: 7196818</p>
<p>Conceptual combination with prototype concepts. E E Smith, D N Osherson, 10.1207/s15516709cog0804_2Cognitive Science. 84Smith EE, Osherson DN. Conceptual combination with prototype concepts. Cognitive Science. 1984; 8 (4):337-361. doi: 10.1207/s15516709cog0804_2</p>
<p>Prototype theory and compositionality. H Kamp, B Partee, 10.1016/0010-0277(94)00659-98556840Cognition. 572Kamp H, Partee B. Prototype theory and compositionality. Cognition. 1995; 57(2):129-191. doi: 10. 1016/0010-0277(94)00659-9 PMID: 8556840</p>
<p>The red herring and the pet fish: Why concepts still can't be prototypes. J Fodor, E Lepore, 10.1016/0010-0277(95)00694-XCognition. 582Fodor J, Lepore E. The red herring and the pet fish: Why concepts still can't be prototypes. Cognition. 1996; 58(2):253-270. doi: 10.1016/0010-0277(95)00694-X PMID: 8820389</p>
<p>Combining prototypes: A selective modification model. Cognitive Science. E E Smith, D N Osherson, L Rips, M Keane, 10.1207/s15516709cog1204_112Smith EE, Osherson DN, Rips L, Keane M. Combining prototypes: A selective modification model. Cog- nitive Science. 1988; 12(4):485-527. doi: 10.1207/s15516709cog1204_1</p>
<p>Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue. J Fodor, Z W Pylyshyn, Pinker S and Mehler JFodor J, Pylyshyn ZW. Connectionism and cognitive architecture: a critical analysis, Connections and symbols. A Cognition Special Issue, Pinker S and Mehler J (eds). 1988; p. 3-71.</p>
<p>An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. G Boole, Walton and MaberlyLondon, UKBoole G. An investigation of the laws of thought: on which are founded the mathematical theories of logic and probabilities. London, UK: Walton and Maberly; 1854.</p>
<p>Über sinn und bedeutung. G Frege, Wittgenstein Studien. 18921Frege G. Über sinn und bedeutung. Wittgenstein Studien. 1892; 1(1).</p>
<p>A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. J M Siskind, 10.1016/S0010-0277(96)00728-7Cognition. 61Siskind JM. A Computational Study of Cross-Situational Techniques for Learning Word-to-Meaning Mappings. Cognition. 1996; 61:31-91. doi: 10.1016/S0010-0277(96)00728-7</p>
<p>Modeling semantic cognition as logical dimensionality reduction. Y Katz, N D Goodman, K Kersting, C Kemp, J B Tenenbaum, Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society. Thirtieth Annual Meeting of the Cognitive Science SocietyKatz Y, Goodman ND, Kersting K, Kemp C, Tenenbaum JB. Modeling semantic cognition as logical dimensionality reduction. In: Proceedings of Thirtieth Annual Meeting of the Cognitive Science Society; 2008.</p>
<p>A Rational Analysis of Rule-Based Concept Learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, 10.1080/0364021070180207121635333Cognitive Science. 321Goodman ND, Tenenbaum JB, Feldman J, Griffiths TL. A Rational Analysis of Rule-Based Concept Learning. Cognitive Science. 2008; 32(1):108-154. doi: 10.1080/03640210701802071 PMID: 21635333</p>
<p>Advances in neural information processing systems. C Kemp, N D Goodman, J B Tenenbaum, 20Learning and using relational theoriesKemp C, Goodman ND, Tenenbaum JB. Learning and using relational theories. Advances in neural information processing systems. 2008; 20:753-760.</p>
<p>Learning a theory of causality. N D Goodman, T D Ullman, J B Tenenbaum, Proceedings of the 31st annual conference of the cognitive science society. the 31st annual conference of the cognitive science societyGoodman ND, Ullman TD, Tenenbaum JB. Learning a theory of causality. In: Proceedings of the 31st annual conference of the cognitive science society; 2009. p. 2188-2193.</p>
<p>Theory Acquisition as Stochastic Search. T D Ullman, N D Goodman, J B Tenenbaum, Proceedings of thirty second annual meeting of the cognitive science society. thirty second annual meeting of the cognitive science societyUllman TD, Goodman ND, Tenenbaum JB. Theory Acquisition as Stochastic Search. In: Proceedings of thirty second annual meeting of the cognitive science society; 2010.</p>
<p>Learning and the language of thought. MIT. S T Piantadosi, Piantadosi ST. Learning and the language of thought. MIT; 2011. Available from: http://colala.bcs. rochester.edu/papers/piantadosi_thesis.pdf.</p>
<p>Bootstrapping in a language of thought: a formal model of numerical concept learning. S T Piantadosi, J B Tenenbaum, N D Goodman, 10.1016/j.cognition.2011.11.00522284806Cognition. 123Piantadosi ST, Tenenbaum JB, Goodman ND. Bootstrapping in a language of thought: a formal model of numerical concept learning. Cognition. 2012; 123:199-217. doi: 10.1016/j.cognition.2011.11.005 PMID: 22284806</p>
<p>Minimization of Boolean complexity in human concept learning. J Feldman, 10.1038/3503658611034211Nature. 4076804Feldman J. Minimization of Boolean complexity in human concept learning. Nature. 2000; 407 (6804):630-633. doi: 10.1038/35036586 PMID: 11034211</p>
<p>An unsolvable problem of elementary number theory. A Church, 10.2307/2371045American journal of mathematics. 582Church A. An unsolvable problem of elementary number theory. American journal of mathematics. 1936; 58(2):345-363. doi: 10.2307/2371045</p>
<p>On the building blocks of mathematical logic. From Frege to Gödel. M Schönfinkel, Schönfinkel M. On the building blocks of mathematical logic. From Frege to Gödel. 1967; p. 355-366.</p>
<p>Introduction to Combinators and λ-calculus. J R Hindley, J P Seldin, Cambridge, UKPress Syndicate of the University of CambridgeHindley JR, Seldin JP. Introduction to Combinators and λ-calculus. Cambridge, UK: Press Syndicate of the University of Cambridge; 1986.</p>
<p>The acquisition of prenominal modifier sequences. E H Matthei, 10.1016/0010-0277(82)90018-XCognition. 113Matthei EH. The acquisition of prenominal modifier sequences. Cognition. 1982; 11(3):301-332. doi: 10.1016/0010-0277(82)90018-X PMID: 7199414</p>
<p>Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. D Barner, J Snedeker, 10.1111/j.1467-8624.2008.01145.x1848941579Barner D, Snedeker J. Compositionality and Statistics in Adjective Acquisition: 4-Year-Olds Interpret Tall and Short Based on the Size Distributions of Novel Noun Referents. Child development. 2008; 79 (3):594-608. doi: 10.1111/j.1467-8624.2008.01145.x PMID: 18489415</p>
<p>Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. A Fernald, K Thorpe, V A Marchman, 10.1016/j.cogpsych.2009.12.00220189552Cognitive psychology. 603Fernald A, Thorpe K, Marchman VA. Blue car, red car: Developing efficiency in online interpretation of adjective-noun phrases. Cognitive psychology. 2010; 60(3):190-217. doi: 10.1016/j.cogpsych.2009. 12.002 PMID: 20189552</p>
<p>30-month-olds use the distribution and meaning of adverbs to interpret novel adjectives. K Syrett, J Lidz, 10.1080/15475440903507905Language Learning and Development. 64Syrett K, Lidz J. 30-month-olds use the distribution and meaning of adverbs to interpret novel adjec- tives. Language Learning and Development. 2010; 6(4):258-282. doi: 10.1080/15475440903507905</p>
<p>Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. H Wimmer, J Perner, 10.1016/0010-0277(83)90004-56681741Cognition. 131Wimmer H, Perner J. Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. Cognition. 1983; 13(1):103-128. doi: 10.1016/0010-0277 (83)90004-5 PMID: 6681741</p>
<p>Addition and subtraction by human infants. K Wynn, 10.1038/358749a01508269Nature. 3586389Wynn K. Addition and subtraction by human infants. Nature. 1992; 358(6389):749-750. doi: 10.1038/ 358749a0 PMID: 1508269</p>
<p>Ten-month-old infants' intuitions about addition. Unpublished manuscript. R Baillargeon, K Miller, J Constantino, Urbana, Champaign, IL.University of Illinois atBaillargeon R, Miller K, Constantino J. Ten-month-old infants' intuitions about addition. Unpublished manuscript, University of Illinois at Urbana, Champaign, IL. 1994;.</p>
<p>On the limits of infants' quantification of small object arrays. L Feigenson, S Carey, 10.1016/j.cognition.2004.09.01016260263Cognition. 973Feigenson L, Carey S. On the limits of infants' quantification of small object arrays. Cognition. 2005; 97 (3):295-313. doi: 10.1016/j.cognition.2004.09.010 PMID: 16260263</p>
<p>Seven-month old infants chunk items in working memory. M Moher, A S Tuerk, L Feigenson, 10.1016/j.jecp.2012.03.00722575845Journal of Experimental Child Psychology. 112Moher M, Tuerk AS, Feigenson L. Seven-month old infants chunk items in working memory. Journal of Experimental Child Psychology. 2012; 112:361-377. doi: 10.1016/j.jecp.2012.03.007 PMID: 22575845</p>
<p>Kelpy: a free library for child experimentation in python. S T Piantadosi, Piantadosi ST. Kelpy: a free library for child experimentation in python; 2012. available from https:// github.com/piantado/kelpy/.</p>
<p>Data Analysis Using Regression and Multilevel/Hierarchical Models. A Gelman, J Hill, Cambridge University PressCambridge, UKGelman A, Hill J. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge, UK: Cambridge University Press; 2007.</p>
<p>To Mock a Mockingbird: and other logic puzzles including an amazing adventure in combinatory logic. R M Smullyan, Oxford University PressSmullyan RM. To Mock a Mockingbird: and other logic puzzles including an amazing adventure in com- binatory logic. Oxford University Press; 1985.</p>
<p>Parallel distributed processing. D E Rumelhart, J L Mcclelland, MIT PressCambridge, MARumelhart DE, McClelland JL. Parallel distributed processing. Cambridge, MA: MIT Press; 1986.</p>            </div>
        </div>

    </div>
</body>
</html>