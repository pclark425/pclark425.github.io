<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9219 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9219</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9219</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-279306303</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.09368v1.pdf" target="_blank">Anomaly Detection and Generation with Diffusion Models: A Survey</a></p>
                <p><strong>Paper Abstract:</strong> Anomaly detection (AD) plays a pivotal role across diverse domains, including cybersecurity, finance, healthcare, and industrial manufacturing, by identifying unexpected patterns that deviate from established norms in real-world data. Recent advancements in deep learning, specifically diffusion models (DMs), have sparked significant interest due to their ability to learn complex data distributions and generate high-fidelity samples, offering a robust framework for unsupervised AD. In this survey, we comprehensively review anomaly detection and generation with diffusion models (ADGDM), presenting a tutorial-style analysis of the theoretical foundations and practical implementations and spanning images, videos, time series, tabular, and multimodal data. Crucially, unlike existing surveys that often treat anomaly detection and generation as separate problems, we highlight their inherent synergistic relationship. We reveal how DMs enable a reinforcing cycle where generation techniques directly address the fundamental challenge of anomaly data scarcity, while detection methods provide critical feedback to improve generation fidelity and relevance, advancing both capabilities beyond their individual potential. A detailed taxonomy categorizes ADGDM methods based on anomaly scoring mechanisms, conditioning strategies, and architectural designs, analyzing their strengths and limitations. We final discuss key challenges including scalability and computational efficiency, and outline promising future directions such as efficient architectures, conditioning strategies, and integration with foundation models (e.g., visual-language models and large language models). By synthesizing recent advances and outlining open research questions, this survey aims to guide researchers and practitioners in leveraging DMs for innovative AD solutions across diverse applications.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9219.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9219.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>High-capacity pretrained transformer language models referenced as potential partners to diffusion-based anomaly detection frameworks for explanation, hypothesis generation, multimodal reasoning, and guidance in anomaly generation and monitoring.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>large language models (LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multimodal (text+image), time series, tabular (sequences/lists)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>medical diagnosis, cybersecurity, industrial monitoring, finance, general multimodal domains</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>rare events, outliers, anomalous temporal patterns, semantic anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Survey mentions integrating LLMs with diffusion-model-based AD to (1) provide interpretable explanations for flagged anomalies, (2) analyze multimodal inputs and complex temporal patterns, (3) propose hypotheses/repairs, and (4) assist synthetic anomaly generation and adaptive monitoring; described at a conceptual level (e.g., embedding expert knowledge as tokens for LLMs).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper does not report empirical limitations for LLM-based AD; it notes integration is an open opportunity and does not provide experimental evaluations or failure analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>The survey argues LLMs can add interpretability and high-level reasoning to diffusion-based AD pipelines — e.g., explain anomalies, mine complex temporal patterns in time series, and help generate targeted synthetic anomalies to address class imbalance — but this is presented as a future research direction rather than validated results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection and Generation with Diffusion Models: A Survey', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9219.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9219.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VadCLIP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VadCLIP (adapting vision-language models for weakly supervised video anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced approach that adapts vision-language (CLIP-like) models for weakly supervised video anomaly detection, demonstrating that vision-language architectures can be effective for detecting anomalous events in video sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Vadclip: Adapting vision-language models for weakly supervised video anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>vision-language model (CLIP-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (multimodal/vision-language)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>video frame sequences (temporal sequence data)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>surveillance and video anomaly detection (e.g., XD-Violence, UCF-Crime)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>anomalous events/actions in video (open-vocabulary/weakly-supervised anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Adaptation/prompting of vision-language models to VAD tasks under weak supervision (e.g., open-vocabulary or text-guided anomaly detection), using model's joint image-text representations to localize or flag anomalous sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Traditional VAD methods such as autoencoders, GANs, and DM-based VAD methods (survey references these as contemporaneous baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Standard VAD metrics (AUROC/AUC, AUC@PR, F1), dataset-specific AUC reported in referenced works (not reproduced in survey).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Survey notes VadCLIP (and ReFLIP-VAD) show strong performance on certain video anomaly benchmarks but are discussed as separate (non-diffusion) baselines; no direct head-to-head numbers versus diffusion methods are reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey highlights challenges adapting complex vision-language architectures to video analysis (e.g., temporal modeling, computational cost, and inconsistent protocols across studies) but does not detail empirical failure cases for VadCLIP specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Vision-language models can enable open-vocabulary and weakly-supervised VAD, offering complementary strengths to diffusion-based approaches (e.g., semantic guidance), yet integrating them with diffusion pipelines and maintaining temporal coherence remains an open challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection and Generation with Diffusion Models: A Survey', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9219.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9219.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ReFLIP-VAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ReFLIP-VAD (reusable feature/prompt-based VAD leveraging vision-language foundations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced vision-language–informed VAD variant (ReFLIP-VAD) that demonstrates leveraging vision-language foundation models for video anomaly detection, used in the survey to illustrate non-diffusion baselines with strong performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>vision-language foundation models (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (multimodal)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>video sequences (temporal data)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>surveillance video anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>event-level anomalous actions/behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Survey references ReFLIP-VAD as an approach that adapts vision-language foundation capabilities for VAD (e.g., reusing pretrained representations and prompt-based adaptation) to improve detection under weak supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Conventional VAD networks (autoencoders, GANs, diffusion-based VAD) as contextual baselines mentioned in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Typical VAD metrics (AUC/AUROC) referenced in the survey; specific ReFLIP-VAD numbers not provided in this survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Survey states such vision-language approaches achieve strong performance on large benchmarks but does not provide direct quantitative comparisons versus diffusion approaches within the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey notes the adaptation of complex vision-language models to video (temporal) tasks is nontrivial, with issues like temporal modeling, modality alignment, and computation/resource costs.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Survey highlights that vision-language foundation models represent a promising direction for VAD (weak supervision, open vocabulary), and their success points to potential fruitful integration with diffusion-based AD pipelines for richer semantic conditioning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection and Generation with Diffusion Models: A Survey', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9219.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9219.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Myriad (LLM tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Myriad model (Expert Perception module embedding prior knowledge as tokens for LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced multimodal industrial anomaly detection model that embeds expert knowledge as tokens consumable by language models (LLMs) to generate granular anomaly descriptions and support industrial defect detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs (used as downstream reasoning/explanation module)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (multimodal / LLM integration)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>multimodal (images with textual expert tokens), tabular/inspection metadata</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>industrial inspection / Industry 5.0</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>visual defects, semantic anomaly descriptions (color, shape, category)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Survey describes Myriad's Expert Perception module that turns prior domain knowledge into tokens interpretable by LLMs to produce granular, human-interpretable anomaly descriptions and to close a human-in-the-loop feedback loop.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Survey presents Myriad as a promising direction but provides no empirical evaluation details or failure modes within this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Embedding expert knowledge as LLM-consumable tokens can enable neuro-symbolic interactions where LLMs produce interpretable anomaly descriptions, improving decision support in industrial anomaly detection; survey frames this as an opportunity rather than validated evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection and Generation with Diffusion Models: A Survey', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Vadclip: Adapting vision-language models for weakly supervised video anomaly detection <em>(Rating: 2)</em></li>
                <li>Plovad: Prompting visionlanguage models for open vocabulary video anomaly detection <em>(Rating: 2)</em></li>
                <li>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection <em>(Rating: 2)</em></li>
                <li>Improving vision anomaly detection with the guidance of language modality <em>(Rating: 2)</em></li>
                <li>LLMs understand glass-box models, discover surprises, and suggest repairs <em>(Rating: 1)</em></li>
                <li>Large language models for spatial trajectory patterns mining <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9219",
    "paper_id": "paper-279306303",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "LLMs",
            "name_full": "Large Language Models",
            "brief_description": "High-capacity pretrained transformer language models referenced as potential partners to diffusion-based anomaly detection frameworks for explanation, hypothesis generation, multimodal reasoning, and guidance in anomaly generation and monitoring.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "large language models (LLMs)",
            "model_type": "transformer (generic)",
            "model_size": null,
            "data_type": "multimodal (text+image), time series, tabular (sequences/lists)",
            "data_domain": "medical diagnosis, cybersecurity, industrial monitoring, finance, general multimodal domains",
            "anomaly_type": "rare events, outliers, anomalous temporal patterns, semantic anomalies",
            "method_description": "Survey mentions integrating LLMs with diffusion-model-based AD to (1) provide interpretable explanations for flagged anomalies, (2) analyze multimodal inputs and complex temporal patterns, (3) propose hypotheses/repairs, and (4) assist synthetic anomaly generation and adaptive monitoring; described at a conceptual level (e.g., embedding expert knowledge as tokens for LLMs).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Paper does not report empirical limitations for LLM-based AD; it notes integration is an open opportunity and does not provide experimental evaluations or failure analyses.",
            "unique_insights": "The survey argues LLMs can add interpretability and high-level reasoning to diffusion-based AD pipelines — e.g., explain anomalies, mine complex temporal patterns in time series, and help generate targeted synthetic anomalies to address class imbalance — but this is presented as a future research direction rather than validated results.",
            "uuid": "e9219.0",
            "source_info": {
                "paper_title": "Anomaly Detection and Generation with Diffusion Models: A Survey",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "VadCLIP",
            "name_full": "VadCLIP (adapting vision-language models for weakly supervised video anomaly detection)",
            "brief_description": "A referenced approach that adapts vision-language (CLIP-like) models for weakly supervised video anomaly detection, demonstrating that vision-language architectures can be effective for detecting anomalous events in video sequences.",
            "citation_title": "Vadclip: Adapting vision-language models for weakly supervised video anomaly detection",
            "mention_or_use": "mention",
            "model_name": "vision-language model (CLIP-based)",
            "model_type": "transformer (multimodal/vision-language)",
            "model_size": null,
            "data_type": "video frame sequences (temporal sequence data)",
            "data_domain": "surveillance and video anomaly detection (e.g., XD-Violence, UCF-Crime)",
            "anomaly_type": "anomalous events/actions in video (open-vocabulary/weakly-supervised anomalies)",
            "method_description": "Adaptation/prompting of vision-language models to VAD tasks under weak supervision (e.g., open-vocabulary or text-guided anomaly detection), using model's joint image-text representations to localize or flag anomalous sequences.",
            "baseline_methods": "Traditional VAD methods such as autoencoders, GANs, and DM-based VAD methods (survey references these as contemporaneous baselines).",
            "performance_metrics": "Standard VAD metrics (AUROC/AUC, AUC@PR, F1), dataset-specific AUC reported in referenced works (not reproduced in survey).",
            "performance_results": null,
            "comparison_to_baseline": "Survey notes VadCLIP (and ReFLIP-VAD) show strong performance on certain video anomaly benchmarks but are discussed as separate (non-diffusion) baselines; no direct head-to-head numbers versus diffusion methods are reported in the survey.",
            "limitations_or_failure_cases": "Survey highlights challenges adapting complex vision-language architectures to video analysis (e.g., temporal modeling, computational cost, and inconsistent protocols across studies) but does not detail empirical failure cases for VadCLIP specifically.",
            "unique_insights": "Vision-language models can enable open-vocabulary and weakly-supervised VAD, offering complementary strengths to diffusion-based approaches (e.g., semantic guidance), yet integrating them with diffusion pipelines and maintaining temporal coherence remains an open challenge.",
            "uuid": "e9219.1",
            "source_info": {
                "paper_title": "Anomaly Detection and Generation with Diffusion Models: A Survey",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "ReFLIP-VAD",
            "name_full": "ReFLIP-VAD (reusable feature/prompt-based VAD leveraging vision-language foundations)",
            "brief_description": "A referenced vision-language–informed VAD variant (ReFLIP-VAD) that demonstrates leveraging vision-language foundation models for video anomaly detection, used in the survey to illustrate non-diffusion baselines with strong performance.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "vision-language foundation models (unspecified)",
            "model_type": "transformer (multimodal)",
            "model_size": null,
            "data_type": "video sequences (temporal data)",
            "data_domain": "surveillance video anomaly detection",
            "anomaly_type": "event-level anomalous actions/behaviors",
            "method_description": "Survey references ReFLIP-VAD as an approach that adapts vision-language foundation capabilities for VAD (e.g., reusing pretrained representations and prompt-based adaptation) to improve detection under weak supervision.",
            "baseline_methods": "Conventional VAD networks (autoencoders, GANs, diffusion-based VAD) as contextual baselines mentioned in the survey.",
            "performance_metrics": "Typical VAD metrics (AUC/AUROC) referenced in the survey; specific ReFLIP-VAD numbers not provided in this survey text.",
            "performance_results": null,
            "comparison_to_baseline": "Survey states such vision-language approaches achieve strong performance on large benchmarks but does not provide direct quantitative comparisons versus diffusion approaches within the survey.",
            "limitations_or_failure_cases": "Survey notes the adaptation of complex vision-language models to video (temporal) tasks is nontrivial, with issues like temporal modeling, modality alignment, and computation/resource costs.",
            "unique_insights": "Survey highlights that vision-language foundation models represent a promising direction for VAD (weak supervision, open vocabulary), and their success points to potential fruitful integration with diffusion-based AD pipelines for richer semantic conditioning.",
            "uuid": "e9219.2",
            "source_info": {
                "paper_title": "Anomaly Detection and Generation with Diffusion Models: A Survey",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Myriad (LLM tokens)",
            "name_full": "Myriad model (Expert Perception module embedding prior knowledge as tokens for LLMs)",
            "brief_description": "Referenced multimodal industrial anomaly detection model that embeds expert knowledge as tokens consumable by language models (LLMs) to generate granular anomaly descriptions and support industrial defect detection.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LLMs (used as downstream reasoning/explanation module)",
            "model_type": "transformer (multimodal / LLM integration)",
            "model_size": null,
            "data_type": "multimodal (images with textual expert tokens), tabular/inspection metadata",
            "data_domain": "industrial inspection / Industry 5.0",
            "anomaly_type": "visual defects, semantic anomaly descriptions (color, shape, category)",
            "method_description": "Survey describes Myriad's Expert Perception module that turns prior domain knowledge into tokens interpretable by LLMs to produce granular, human-interpretable anomaly descriptions and to close a human-in-the-loop feedback loop.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Survey presents Myriad as a promising direction but provides no empirical evaluation details or failure modes within this survey.",
            "unique_insights": "Embedding expert knowledge as LLM-consumable tokens can enable neuro-symbolic interactions where LLMs produce interpretable anomaly descriptions, improving decision support in industrial anomaly detection; survey frames this as an opportunity rather than validated evidence.",
            "uuid": "e9219.3",
            "source_info": {
                "paper_title": "Anomaly Detection and Generation with Diffusion Models: A Survey",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Vadclip: Adapting vision-language models for weakly supervised video anomaly detection",
            "rating": 2,
            "sanitized_title": "vadclip_adapting_visionlanguage_models_for_weakly_supervised_video_anomaly_detection"
        },
        {
            "paper_title": "Plovad: Prompting visionlanguage models for open vocabulary video anomaly detection",
            "rating": 2,
            "sanitized_title": "plovad_prompting_visionlanguage_models_for_open_vocabulary_video_anomaly_detection"
        },
        {
            "paper_title": "Myriad: Large multimodal model by applying vision experts for industrial anomaly detection",
            "rating": 2,
            "sanitized_title": "myriad_large_multimodal_model_by_applying_vision_experts_for_industrial_anomaly_detection"
        },
        {
            "paper_title": "Improving vision anomaly detection with the guidance of language modality",
            "rating": 2,
            "sanitized_title": "improving_vision_anomaly_detection_with_the_guidance_of_language_modality"
        },
        {
            "paper_title": "LLMs understand glass-box models, discover surprises, and suggest repairs",
            "rating": 1,
            "sanitized_title": "llms_understand_glassbox_models_discover_surprises_and_suggest_repairs"
        },
        {
            "paper_title": "Large language models for spatial trajectory patterns mining",
            "rating": 1,
            "sanitized_title": "large_language_models_for_spatial_trajectory_patterns_mining"
        }
    ],
    "cost": 0.01567425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Anomaly Detection and Generation with Diffusion Models: A Survey
11 Jun 2025</p>
<p>Yang Liu 0000-0002-1312-0146
Member, IEEEJing Li 0000-0002-2819-0200
Rui Xi 0000-0003-0626-494X
Wenchao Li 0009-0001-4010-3536
Liang Cao 0000-0002-2880-3097
Jin Wang 0000-0003-0766-9906
Fellow, IEEELaurence T Yang 0000-0001-6663-7643
Fellow, IEEEJunsong Yuan 0000-0002-7901-8793
Senior Member, IEEEWei Zhou 0000-0003-3641-1429
Anomaly Detection and Generation with Diffusion Models: A Survey
11 Jun 20259A44BCD5747B48CE6B3DF60C386D09CCarXiv:2506.09368v1[cs.LG]Anomaly DetectionAnomaly GenerationDiffusion ModelsGenerative AIUnsupervised LearningSurvey
Anomaly detection (AD) plays a pivotal role across diverse domains, including cybersecurity, finance, healthcare, and industrial manufacturing, by identifying unexpected patterns that deviate from established norms in real-world data.Recent advancements in deep learning, specifically diffusion models (DMs), have sparked significant interest due to their ability to learn complex data distributions and generate high-fidelity samples, offering a robust framework for unsupervised AD.In this survey, we comprehensively review anomaly detection and generation with diffusion models (ADGDM), presenting a tutorial-style analysis of the theoretical foundations and practical implementations and spanning images, videos, time series, tabular, and multimodal data.Crucially, unlike existing surveys that often treat anomaly detection and generation as separate problems, we highlight their inherent synergistic relationship.We reveal how DMs enable a reinforcing cycle where generation techniques directly address the fundamental challenge of anomaly data scarcity, while detection methods provide critical feedback to improve generation fidelity and relevance, advancing both capabilities beyond their individual potential.A detailed taxonomy categorizes ADGDM methods based on anomaly scoring mechanisms, conditioning strategies, and architectural designs, analyzing their strengths and limitations.We final discuss key challenges including scalability and computational efficiency, and outline promising future directions such as efficient architectures, conditioning strategies, and integration with foundation models (e.g., visual-language models and large language models).By synthesizing recent advances and outlining open research questions, this survey ( ADGDM) aims to guide researchers and practitioners in leveraging DMs for innovative AD solutions across diverse applications.</p>
<p>INTRODUCTION</p>
<p>A Nomaly detection (AD) is a crucial task in various domains, from cybersecurity [1] and finance [2] to healthcare [3] and industrial manufacturing [4], aiming to identify instances deviating significantly from established</p>
<p>• Detailed biographical information for all authors is provided in the supplementary material "Author Biographies".normal patterns [5].However, the unsupervised nature of AD presents substantial challenges, particularly the lack of labeled anomalous data, which makes defining precise boundaries between normal and abnormal behavior difficult [6].Traditional AD methods, often relying on predefined thresholds or assuming specific data distributions, are sensitive to noise and struggle to adapt to complex real-world scenarios [7].The increasing complexity and dimensionality of data in modern applications further compound these challenges, demanding more robust and adaptable techniques [8].Consequently, innovative approaches are needed to learn from the inherent structure of normal data and effectively identify deviations without explicit supervision [9].The scarcity of labeled anomalies coupled with data heterogeneity complicates the development of effective unsupervised AD methods [10].In addition, the need for interpretability in anomaly detection adds another layer of complexity, as understanding the reasons for flagged anomalies is crucial for effective decision-making [11].</p>
<p>Recent years have witnessed the emergence of DMs as a powerful class of generative models that have rapidly gained prominence across various computer vision tasks [12], [13].At their core, DMs operate through a distinctive two-stage process: forward diffusion and reverse denoising.During forward diffusion, Gaussian noise progressively corrupts input data across multiple steps, transforming complex data distributions into simple isotropic Gaussian structures [14].The neural network-parameterized reverse denoising process then learns to iteratively remove the added noise, reconstructing original data from noisy samples while capturing intricate data dependencies [15].Compared to traditional generative approaches such as generative adversarial networks (GANs) and variational autoencoders (VAEs), DMs offer significant advantages in training stability by avoiding mode collapse and vanishing gradient challenges [16].With superior sample quality and improved mode coverage, DMs generate diverse, high-fidelity samples that accurately represent underlying data distributions, positioning them at the forefront of generative modeling research for applications including anomaly detection [17].Ongoing research addresses computational limitations through techniques like patching, which employs ViT-style transformations to reduce sampling time and memory requirements, while flexibility in the forward process enables multi-scale training that enhances overall performance [1].</p>
<p>Considering the inherent challenges of anomaly scarcity and data distribution complexity, identifying instances that deviate significantly from expected behavior poses particular challenges in unsupervised settings with limited labeled anomalies [18], [19], where DMs provide a promising solution by learning complex data distributions and generating highfidelity samples for effective reconstruction-based anomaly scoring [20], [21].Specifically, a DM trained on normal data learns to progressively add and then reverse noise, effectively reconstructing data from a noise distribution [22].Consequently, when presented with an anomalous input, the DM attempts to reconstruct a "normal" version, and the discrepancy between the input and its reconstruction, quantified as the reconstruction error, serves as an anomaly score [23], [24].A larger reconstruction error thus implies a higher likelihood of an anomaly, allowing DMs to capture subtle deviations, particularly in high-dimensional image data [25], [26].As shown in Fig. 1, research interest in anomaly detection and diffusion models has grown substantially from 2021 to 2025, with both publication counts and citation metrics exhibiting steep upward trajectories.Time series anomaly detection (TSAD) currently dominates the research landscape, accounting for 41% of all the AD publications, followed by video anomaly detection (VAD, 29%) and image anomaly detection (IAD, 22%).Such a distribution reflects both the versatility of diffusion models across different data modalities and the particularly challenging nature of detecting anomalies in sequential data [27]- [29].Related Surveys.Despite the growing interest in anomaly detection research, existing surveys typically focus on specific modalities or methodological aspects rather than offering a unified perspective across different data types and genera-tive approaches.For example, Cook et al. [30] concentrate solely on IoT time-series data anomaly detection without addressing generative approaches, while Pang et al. [31] provide a general overview of deep learning for anomaly detection but omit specific coverage of diffusion models.In the medical domain, Fernando et al. [32] thoroughly examine anomaly detection techniques but predominantly focus on discriminative rather than generative approaches.Regarding VAD, Ramachandra et al. [7] and Chandrakala et al. [33] offer valuable insights into single-scene surveillance applications but lack exploration of generative approaches such as diffusion models.Furthermore, while Liu et al. [36] establish a comprehensive taxonomy for VAD and Liu et al. [37] investigate networking systems for VAD, neither addresses the potential of DMs.Similarly, Ma et al. [34] extensively explore graph anomaly detection with deep learning but without investigating diffusion-based approaches.More recently, Jin et al. [6] and Zamanzadeh Darban et al. [8] have advanced TSAD research, yet their coverage of DMs remains limited.A detailed comparison between our survey and existing works is presented in Table 1, which demonstrates our unique contribution in comprehensively addressing both anomaly detection and generation across multiple modalities through the lens of diffusion models.Scope and Contributions.In this survey 1 , we provide a comprehensive and up-to-date examination of anomaly detection and generation with diffusion models (ADGDM), spanning multiple data modalities including images, videos, time series, and tabular data.A distinctive aspect is our integrated view of detection and generation as complementary processes, wherein DMs enable controllable generation of synthetic anomalies to address data scarcity, while detection insights guide targeted generation.Consequently, a synergistic feedback loop emerges, transforming the fundamental limitation of anomaly data scarcity into an opportunity for continuous improvement.As DMs continue to demonstrate remarkable capabilities in generative AI tasks across various domains, their application to anomaly detection represents a rapidly evolving frontier with significant potential.The key contributions of our survey are summarized as follows:</p>
<p>• To the best of our knowledge, this is the first comprehensive survey specifically dedicated to examining the intersection of diffusion models with anomaly detection and generation across diverse data modalities including images, videos, time series, and tabular data.Our integrative perspective reveals common principles and modality-specific challenges, fostering knowledge transfer between previously siloed research areas.2, the organization reflects the multifaceted nature of ADGDM research, highlighting both the core theoretical underpinnings and their practical applications across diverse domains.The remainder of this survey is structured as follows.Sec. 2 establishes the foundations of ADGDM, covering diffusion models, anomaly scoring mechanisms, and conditioning strategies.Sec. 3 and Sec. 4 examine image and video AD respectively, addressing modality-specific challenges and methodological advances.Sec. 5 and Sec.6 explore anomaly detection in time series and tabular data, respectively, while Sec.7 investigates multimodal anomaly detection.Sec. 8 investigates anomaly generation with diffusion models.Sec. 9 details evaluation metrics and benchmark datasets across different modalities.Sec. 10 discusses open challenges and future research directions, and Sec.11 concludes this survey.</p>
<p>FOUNDATIONS</p>
<p>DMs Primer</p>
<p>DMs constitute a powerful class of generative models capable of synthesizing high-quality data across various modalities [38].The underlying principle of DMs involves a twostage process: a forward diffusion process that gradually corrupts data by adding noise, and a reverse denoising process that learns to recover the original data from this noisy version.The forward process can be mathematically formulated as a stochastic differential equation (SDE) dx = f (x, t)dt+g(t)dw [39] or its discrete-time counterpart, where Gaussian noise is iteratively added to an initial data sample x 0 according to a predefined schedule β t [40].In the discretetime formulation, the forward process transforms x 0 through a series of steps q(x
t |x t−1 ) = N (x t ; √ 1 − β t x t−1 , β t I),</p>
<p>Methodologies</p>
<p>Sec. 2: Foundations</p>
<p>Anomaly Detection and Generation with Diffusion Models Fig. 2: Organization outline of this survey, which illustrates the article structure, covering basic concepts (Sec.2), methodologies for AD in different modalities (including image (Sec.3), video (Sec.4), time series (Sec.5), tabular (Sec.6), and multimodal data (Sec.7)) and anomaly generation (Sec.8), evaluation (Sec.9), and future research outlook (Sec.10).eventually approximating a standard Gaussian distribution N .Sampling from DMs can be viewed as solving the corresponding SDEs or ordinary differential equations (ODEs) [40], and recent work such as DynGMA [41] explores robustly learning SDEs from data, potentially enhancing the forward process.In the reverse process, a neural network, typically a U-Net [14], is trained to predict either the noise ϵ θ (x t , t) or estimate the score function ∇ xt log p(x t ) at each time step, effectively reversing the noise addition.The network learns to predict either the original data or the added noise, guided by maximizing a variational lower bound on the data likelihood [38].Several DM variants exist, including denoising diffusion probabilistic models (DDPMs) [42] which employ a Markov chain, denoising diffusion implicit models (DDIMs) [40] which offer a non-Markovian formulation for faster sampling, and SDE-based models [39], [43] for a more flexible framework.Additionally, alternative frameworks based on phase space dynamics [44] and methods using neural operators for accelerated sampling [45] have been proposed.A mathematical analysis of singularities in DMs provides further insights into the challenges associated with learning complex data distributions, particularly when data lies on lower-dimensional manifolds [46].</p>
<p>Anomaly Scoring Mechanisms with DMs</p>
<p>Anomaly scoring with DMs leverages their learned understanding of data distributions to identify deviations from normality.As illustrated in Fig. 3, DMs provide three primary paradigms for anomaly scoring.</p>
<p>Reconstruction-Based Scoring</p>
<p>Leveraging the reconstruction capability inherent in diffusion models, anomaly scoring can quantify the discrepancy between an input x and its reconstructed version x.The underlying principle posits that a larger reconstruction error signifies a higher likelihood of x being anomalous, stemming from the model's training predominantly on normal data which hinders accurate reconstruction of out-of-distribution samples [47].As depicted in Fig. 3(a), the process involves passing x through the reverse process to produce x, then comparing them.The reconstruction error can be formally expressed as A(x) = d(x, x), where common distance metrics d include the L 1 norm, L 2 norm, or perceptual loss [48].Perceptual loss uniquely compares high-level features extracted via pre-trained networks, capturing perceptual similarity rather than pixel-wise differences.Further refinements involve utilizing intermediate diffusion states x t for scoring rather than just the final reconstruction.To refine scoring, intermediate diffusion states x t are utilized, capturing diverse data characteristics at varying noise levels [49].</p>
<p>A generalized multi-step scoring approach aggregates errors over different timesteps as S(x) = t = 1 T w t L(x, xt ), where weights w t prioritize contributions from specific steps [16].Additionally, methods like dynamic denoising and latent space projections aim to improve reconstruction fidelity, particularly for anomalies of varying scales [25].</p>
<p>Density-Based Scoring</p>
<p>Density-based ADGDM exploits the model's capacity to learn the probability density function of the training data, operating under the premise that anomalies reside in lowdensity regions.Specifically, an anomaly score is assigned based on the negative log-likelihood: A(x) = − log p(x), where A(x) represents the anomaly score and p(x) is the estimated probability density of x [50].A primary advantage of this approach is its interpretability, as the score directly corresponds to the probability density [51].However, accurately estimating this density, especially in high-dimensional spaces, poses a considerable challenge due to the curse of dimensionality, which necessitates a large number of samples for accurate estimation [52].In addition, diffusion models often operate in a transformed space, and the estimated density in this space may not accurately reflect the original data space density.Another key challenge stems from the fact that diffusion models primarily learn the score function (the gradient of the log density) rather than the density itself [53].Estimating the density from the score function can be computationally intensive and error-prone, particularly in high dimensions.Several studies have explored methods to address these challenges, including joint dimensionality reduction and density estimation using low-rank tensor models [54], analyzing score approximation and distribution recovery in low-dimensional data [55], estimating the data manifold dimension [56], and improving density estimation through maximum likelihood training [57].</p>
<p>Score-Based Scoring</p>
<p>Score-based anomaly detection utilizes the learned score function, ∇ x log p(x), representing the gradient of the logprobability density.∇ x log p(x) provides crucial information about the local geometry of the probability density in data space [24].Importantly, a higher score magnitude indicates steeper probability density change rather than directly indicating the probability value itself.The anomaly score is defined as A(x) = ||∇ x log p(x)|| 2 .The effectiveness stems from geometric properties of normal data manifolds, which typically form regions with smooth probability transitions, while anomalies often lie where density functions exhibit sharp changes.This occurs when: (1) data points fall between normal clusters, causing gradients to point strongly toward nearby modes, or (2) out-of-distribution samples prompt stronger "pulling" toward the learned manifold.</p>
<p>During training, the model estimates scores at different noise levels [58] through score matching.At each reverse diffusion step, the score function s θ (x t , t) guides denoising as x t−1 = x t − ϵs θ (x t , t) + √ 2ϵz, pulling samples toward higher density regions [59].In AD, this represents restoring potentially anomalous inputs toward normality [22], where persistent high score magnitudes signal anomalous behavior.Empirical studies confirm that while score magnitude and probability density aren't strictly monotonically related, score-based methods effectively identify anomalies through gradient field behavior near anomalous regions.</p>
<p>Conditioning Strategies</p>
<p>Conditioning strategies are crucial for adapting diffusion models to anomaly detection by shaping the learned distribution and influencing reconstruction behavior.We first examine unconditional diffusion models (UDMs), noting their simplicity but acknowledging potential limitations with complex data.Subsequently, we explore conditional diffusion models (CDMs), investigating how incorporating additional information, such as class labels, image content, or textual descriptions, improves anomaly detection and enables controllable anomaly generation.</p>
<p>Unconditional DMs</p>
<p>UDMs learn the underlying data distribution without external labels, simplifying training and making them readily applicable to anomaly detection [26].Specifically, an unconditional DM learns a generative process mapping a standard Gaussian distribution N (0, I) to the complex data distribution p(x), where x represents a data sample.The forward diffusion process gradually adds noise to the data according to a schedule parameterized by β t , which can be formulated as a Markov chain:
q(x t |x t−1 ) = N (x t ; √ 1 − β t x t−1 , β t I)
, where x t is the data sample at time step t.Conversely, the reverse process, also a Markov chain, learns the denoising process as p θ (x t−1 |x t ) = N (x t−1 ; µ θ (x t , t), Σ θ (x t , t)), where µ θ and Σ θ , parameterized by neural networks with parameters θ, are trained to reverse this noise addition, effectively reconstructing data from noise.</p>
<p>For anomaly detection, unconditional DMs leverage this reconstruction capability [25].Given a test sample, the model reconstructs its "normal" counterpart by reversing the diffusion process, and the reconstruction error, often measured using L 1 or L 2 norms, serves as the anomaly score.A high reconstruction error indicates a potential anomaly, suggesting the input deviates significantly from the learned distribution of normal data.However, this approach has limitations in capturing complex data structures with intricate dependencies or multimodal distributions [60].The assumption of a single, unified distribution for normal data may not accurately represent real-world dataset diversity, potentially reducing anomaly detection performance, especially with subtle deviations from normality within specific sub-populations.Additionally, reliance on a global distribution can lead to the "identity shortcut" problem, where the model simply reconstructs the input, even if anomalous, leading to false negatives [22].Despite these limitations, the simplicity of unconditional DMs makes them a valuable starting point, particularly for scenarios with relatively homogeneous normal data [61].</p>
<p>Conditional DMs</p>
<p>CDMs incorporate external information, denoted as y, to guide the denoising and thus control generated samples.The core modification lies in the reverse process, where the neural network parameterizing the denoising process takes both the noisy input x t and the conditioning signal y as inputs, specifically p θ (x t−1 |x t , y) = N (x t−1 ; µ θ (x t , t, y), Σ θ (x t , t, y)), where µ θ and Σ θ represent the learned mean and covariance, respectively.The conditioning signal y can represent various data types depending on the application.For example, Zhan et al. [62] use class labels as the conditioning signal for multi-class anomaly detection, allowing the model to learn class-specific distributions.Similarly, for image restoration, Mousakhan et al. [63] condition the denoising process on the input image itself to reconstruct a defect-free version.In another approach, Tebbe and Tayyub [25] utilize an initial anomaly prediction as a conditioning signal to guide the dynamic addition of noise during the forward diffusion process.Additionally, Singh et al. [64] explore conditioning on crafted input noise artifacts for controlled image generation with semantic attributes.For controllable anomaly generation, text-conditioned diffusion models, as explored by Sadat et al. [65], leverage textual descriptions to improve the diversity of generated samples.In the context of time series analysis, Pintilie et al. [26] investigate the use of diffusion models for anomaly detection, while Tebbe and Tayyub [22] explore conditioning strategies for improved anomaly localization.</p>
<p>IMAGE ANOMALY DETECTION</p>
<p>Considerations</p>
<p>Applying diffusion models to IAD presents key challenges, particularly the "identity shortcut" problem and substantial computational costs.As illustrated in Fig. 4, the identity shortcut phenomenon occurs when diffusion models trained for high-fidelity reconstruction inadvertently reconstruct anomalous regions in the input, thus masking the very anomalies they should detect.Additionally, the high computational cost, especially during inference due to the iterative nature of the reverse diffusion process, necessitates mitigation strategies such as conditional approaches and multi-stage designs for practical deployment.</p>
<p>The "identity shortcut" in ADGDM manifests when models reconstruct anomalous regions during high-fidelity training, obscuring anomalies and yielding low reconstruction errors despite their presence [23].Such behavior risks false negatives in anomaly detection.To address this, masked reconstruction leverages learned normal data distributions to enhance sensitivity to deviations [66].Alternatively, feature editing manipulates latent space representations to reconstruct normal counterparts of anomalous inputs [49].Adversarial training further strengthens robustness against perturbations, potentially improving anomaly differentiation [67].Nevertheless, these methods face challenges: masked reconstruction demands precise masking strategies, feature editing requires latent space expertise, and adversarial training incurs high computational costs.</p>
<p>High computational demands hinder DM deployment in real-time anomaly detection, driven by iterative reverse diffusion requiring extensive neural network evaluations [17].For example, processing high-resolution medical images (2048×2048 pixels) necessitates 50-1000 denoising steps, consuming 15-30 seconds per image on advanced GPUs.</p>
<p>Acceleration strategies address this bottleneck.Progressive distillation optimizes models for faster sampling with fewer steps, balancing speed, and reconstruction quality [68].Similarly, SLAM [69] and FDM [70] employ linear ODE approximations and momentum-based techniques, respectively.Efficient ODE solvers, such as DPM-Solver [71], streamline the reverse diffusion process.Operating in lowerdimensional latent spaces, LDMs [72] reduce complexity, while LoRA [73] and SparseDM [20] enhance efficiency through model compression and sparse layers.</p>
<p>Anomaly Localization with DMs</p>
<p>Precise localization of anomalous regions is crucial for applications like industrial defect detection [16] and medical diagnosis [17].While diffusion models excel at capturing global data distributions, pinpointing anomalies requires specialized techniques, such as generating a difference map between the original and reconstructed image [74].The magnitude of this difference then serves as the anomaly likelihood measure.In addition, incorporating attention mechanisms within the diffusion model architecture offers finer-grained localization [3], where attention weights highlight anomalous regions during reconstruction.Gradientbased methods provide another strategy [75], identifying anomalous pixels by computing the gradient of the reconstruction loss with respect to the input.Specifically, methods like AnoFPDM [75] leverage the forward diffusion process for brain MRI anomaly segmentation, while D3AD [22] uses dynamic denoising and latent projections to localize multiscale anomalies, and AnoDDPM [74] employs multi-scale simplex noise diffusion for improved localization accuracy, particularly in medical images.</p>
<p>Taxonomy and Advances</p>
<p>IAD employing diffusion models can be categorized based on their scoring mechanisms, conditioning strategies, and architectural designs.As summarized in Table 2, we distinguish methods by reconstruction error, density estimation, or score function analysis, analyze trade-offs between unconditional vs. conditional diffusion models, and examine single-stage vs. multi-stage reconstruction approaches.</p>
<p>Reconstruction-based vs. Density/Score-based</p>
<p>Diffusion models for IAD employ reconstruction-based, density-based, and score-based approaches.Reconstructionbased methods, such as THOR [76] and Image-Conditioned Diffusion Models [77], leverage the model's ability to reconstruct a "normal" version of the input, and the discrepancy between the input and its reconstruction, measured by metrics like L 1 , L 2 , or perceptual loss, serves as the anomaly score.Variations include using different noise levels or intermediate reconstructions for scoring like FNDM [17], as well as masked reconstruction to address the identity shortcut problem [78].Density-based methods, in contrast, utilize the learned probability density function, identifying anomalies by their low probability under this distribution.However, accurately estimating this density in high-dimensional image spaces remains challenging.Consequently, score-based methods offer an alternative by directly using the score function, representing the gradient of the log density, to efficiently assess anomaly likelihood.In addition, methods like Cold Diffusion [79] explore deterministic degradations, while ensemble methods like Cold-Diffusion Restorations [80] combine multiple restorations for improved scoring.</p>
<p>Unconditional vs. Conditional</p>
<p>Training exclusively on normal data, UDMs [3] identify anomalies through elevated reconstruction errors or diminished likelihood estimates during inference [81].While offering streamlined training procedures and implementation frameworks, UDMs frequently encounter limitations when processing complex datasets with significant intra-class variation, potentially compromising detection sensitivity for subtle anomalous patterns [82].In contrast, CDMs incorporate additional information, such as class labels [83], image masks [78], or other modalities [84], during both training and inference [77].Consequently, CDMs can better capture normal data structure and generate more accurate reconstructions, improving anomaly detection performance [76].For example, image-conditioned models can be explicitly trained to correct synthetic anomalies, improving localization [85].Such conditioning also enables targeted anomaly generation [86].The choice between UDMs and CDMs depends on the specific dataset and application.In complex scenarios like medical imaging, where subtle anomalies are common, CDMs conditioned on image features or anatomical priors might be preferred [17], [87].Conversely, UDMs may suffice for simpler tasks with less intra-class variation.The selection of appropriate conditioning strategies [88], [89] and consideration of computational costs, especially for high-dimensional data [80], [90], are crucial for CDM effectiveness.Methods like Cold Diffusion may offer computational advantages in certain scenarios [79].</p>
<p>Single-stage vs. Multi-stage</p>
<p>Diffusion models for anomaly detection are primarily categorized into single-stage and multi-stage approaches.Singlestage methods reconstruct the input image directly through a single reverse diffusion process [3], and the resulting reconstruction error, calculated between the input and its reconstruction, serves as the anomaly score [90].While computationally efficient, such an approach may not effectively capture subtle anomalies or accurately reconstruct complex image structures [82].In contrast, multi-stage methods, incorporating multiple reconstruction stages, offer a more nuanced approach.One such approach uses patch-based processing, where the image is divided into smaller patches, each independently reconstructed [80], and the individual patch reconstruction errors are aggregated into a final anomaly score, enabling finer-grained anomaly localization [78].Another multi-stage approach utilizes hierarchical reconstruction at different scales, from coarse to fine [84], which allows the model to capture both global and local anomalies.Additionally, some methods combine different stages or incorporate steps like feature editing or adversarial training to enhance performance [76], [77], including masked reconstruction where a mask forces the model to reconstruct only masked regions [87], thus preventing the "identity shortcut" [83].Generally, multi-stage approaches achieve better performance, especially for complex anomalies, at the TABLE 2: Summary of IAD methods across various imaging domains with implementations.</p>
<p>Method Year Venue Imaging Domains DM Code</p>
<p>Latent DDPM [3] 2022 MICCAI Brain CT and MRI ✓ -LDM-OOD [81] 2023 MICCAI 3D medical data ✓ FNDM [17] 2023 MICCAI Brain MR images ✓ -Cold Diffusion [79] 2023 NeurIPS General image ✓ -Mao et al. [88] 2023 ACM MM Text-image pairs ✓ -THOR [76] 2024 MICCAI Brain MRI, Wrist X-rays ✓ DDPM-DDIM [87] 2024 IEEE TMI Brain images ✓ -mDDPM [78] 2024 MLMI Brain MRI ✓ MMCCD [84] 2024 MICCAIW Multimodal MRI ✓ -DAG [80] 2024 MICCAI Brain MRI ✓ -IgCONDA-PET [83] 2024 ArXiv Medical imaging (PET) ✓ ODEED [90] 2024 CVPRW Remote sensing ✓ -AnomalyDiffusion [85] 2024 AAAI Industrial images ✓ DualAnoDiff [86] 2024 ArXiv Industrial images ✓ -Babaei et al. [82] 2024 ArXiv Medical imaging ✓ -UNIMO-G [89] 2024 ACL Text-image pairs ✓ -ICDM [77] 2025 USMLMI Medical imaging ✓ cost of higher computational overhead compared to singlestage methods [85].The optimal choice depends on specific application requirements and the trade-off between accuracy and computational efficiency [17].</p>
<p>Performance Comparison</p>
<p>Diffusion-based approaches for IAD have demonstrated significant performance improvements on standard benchmarks in recent years.As evidenced in Table 3, methods from 2021 to 2025 show a clear upward trajectory in detection metrics across challenging datasets like MVTec AD [91] and VisA [23].</p>
<p>Early approaches such as DRAEM [92] established strong foundations through discriminatively trained reconstruction embeddings for surface anomaly detection, while PaDiM [93] advanced the field through patch distribution modeling techniques.Subsequently, PatchCore [94] achieved competitive results by leveraging memory banks of nominal patch features for efficient inference.Moving beyond traditional approaches, AnoDDPM [74] introduced partial diffusion with simplex noise to outperform Gaussian diffusion models, particularly in medical image applications.Recent innovations include AutoDDPM [95], which enhances robustness through masking and resampling techniques, and Lu et al.'s [91] anomaly removal approach that treats irregularities as noise for improved localization.Notably, GLAD [23] represents the current state-of-the-art through its global-local adaptive diffusion framework, achieving nearly perfect detection scores on the VisA [96].Throughout the evolution of these methods, evaluation metrics have remained consistent, focusing on AU-ROC, AUPR, and pixel-level metrics like Dice coefficient and IoU for comprehensive assessment.Comparative analysis across these approaches reveals inherent trade-offs between detection accuracy, localization precision, and computational demands, with certain methods excelling in image-level anomaly detection (e.g., PatchCore on MVTec AD [97]) while others demonstrate superior anomaly localization capabilities (e.g., AnoDDPM [74] on medical images).</p>
<p>VIDEO ANOMALY DETECTION</p>
<p>Considerations</p>
<p>VAD faces distinct challenges compared to image-based methods due to the inherent temporal dimension and  complex motion patterns [100]- [102].As illustrated in Fig. 5, effective VAD frameworks must process sequential frames while addressing temporal dependencies in motion, where anomalies can manifest as unusual action sequences or deviations from established patterns.The pipeline integrates spatio-temporal feature extractors with specialized diffusion models that incorporate motion information through flow vectors or transformers, enabling the detection of irregularities in both spatial appearance and temporal evolution [103].Motion's complexity, encompassing variations in speed, direction, and acceleration, requires accurate capture and representation for effective VAD, with sudden changes or unexpected trajectories potentially indicating anomalies [12].The interplay between spatial and temporal information further complicates matters, where an action considered normal in isolation might be anomalous given surrounding events.To address these challenges, diffusion models for VAD incorporate key adaptations, including explicitly modeling temporal Dependencies using spatiotemporal transformers, such as in VDT [104], to capture long-range dependencies and temporal context.Additionally, incorporating motion information directly into the diffusion process, exemplified by spectral motion alignment (SMA) [105] and MoVideo [106], refines motion dynamics and preserves temporal consistency.Conditioning on past frames or motion representations allows the model to learn expected temporal evolution and identify deviations [13].Similarly, techniques like sampling space truncation and robustness penalty in VIDM [107] improve video quality and anomaly detection robustness.</p>
<p>Taxonomy and Advances</p>
<p>As shown in  [108] 2024 IEEE MMSP F Satellite imagery, disaster detection ✓ Video LDM [109] 2023 CVPR S, M Driving simulation ✓ VidRD [110] 2023 Arxiv S Text-to-video generation ✓ FPDM [111] 2023 ICCV F Video surveillance ✓ Stable Video Diffusion [112] 2023 Arxiv S, M Text/Image-to-video generation ✓ DMAD [113] 2023 CVPR F Surveillance VAD ✗ Wang et al. [114] 2023 Neurocomput.F Video surveillance ✓ Masked Diffusion [115] 2023 Arxiv C Video procedure planning ✓ GD-VDM [116] 2023 Arxiv S Complex scene video generation ✓ AADiff [117] 2023 Arxiv C Audio-aligned video synthesis ✓ Basak et al. [118] 2024 ESWA F Video surveillance ✓ DHVAD [119] 2024 IJCAI F Security and surveillance ✓ DiffVAD [21] 2024 IJCAI F Sustainable cities management ✓ GiCiSAD [120] 2024 Arxiv M Skeleton-based VAD ✓ VADiffusion [121] 2024 Arxiv F Security surveillance ✓ Cai et al. [122] 2024 Sensors F Dust pollution monitoring ✓ FedDiff [123] 2024 IEEE TCSVT C Multi-modal remote sensing ✓</p>
<p>Notes: "Type" refers to learning paradigm: F=Frame-level, S=Sequence-level, M=Motion Modeling, C=conditioning Strategies.</p>
<p>poral dynamics, investigate motion incorporation through optical flow and spatio-temporal architectures, and analyze conditioning strategies using temporal context.</p>
<p>Frame-level Methods</p>
<p>VAD methods analyze video data at different granularities, primarily frame-level and sequence-level.Frame-level methods analyze individual frames independently, effectively treating videos as image collections and enabling direct application of image-based anomaly detection techniques using diffusion models, but consequently disregarding temporal dependencies.In contrast, sequence-level methods explicitly consider temporal relationships between frames, facilitating a more comprehensive understanding of normal behavior and the detection of anomalies evolving over time.Specifically, some approaches leverage recurrent networks [124] or spatiotemporal transformers within the diffusion model framework to capture temporal dependencies [125].Other methods reconstruct entire video sequences or segments, using the temporal coherence of the generated output as a normality measure [126].While offering improved accuracy by incorporating temporal context, sequence-level methods often incur increased computational complexity compared to framelevel approaches [26].The choice between these methods depends on the specific application and the trade-off between accuracy and computational cost [127], as well as the nature of the anomalies themselves; for example, sudden object appearances might be detectable at the frame level, while unusual motion patterns require sequence-level analysis [60].</p>
<p>Researchers have also explored the concept of a "normal gathering latent space" for enhanced anomaly detection in time series data using diffusion models and incorporated decontamination techniques within the diffusion model framework to address contaminated training data [60], [128].</p>
<p>Converting time-series data into images before applying diffusion models has also been proposed for network traffic generation and anomaly detection [129].</p>
<p>Motion Modeling</p>
<p>Motion cues are crucial for distinguishing anomalies in video data, thus integrating motion information into diffusion models is essential for robust VAD [130]- [132].Optical flow, representing the apparent motion of objects or surfaces, can condition diffusion models [133], enabling them to learn normal motion patterns and identify deviations.Similarly, motion vectors, capturing pixel displacement between frames, can be utilized for motion-aware anomaly detection.</p>
<p>Researchers have also explored spatio-temporal transformers [134], [135] to capture long-range dependencies and complex motion dynamics, leading to more nuanced representations of normal behavior.Integrating structured state space models (SSSMs) with DMs [61], [136] offers another promising approach to capturing long-term temporal dependencies.</p>
<p>In addition, incorporating collector entity ID embedding [61] can enhance pattern learning by distinguishing different collection signals, while adaptive dynamic neighbor masking mechanisms, used with transformers and denoising diffusion models [126], can mitigate information leakage during reconstruction, improving anomaly identification.</p>
<p>Conditioning Strategies</p>
<p>Conditioning strategies are crucial for adapting diffusion models to VAD, particularly for leveraging temporal context and motion information.One common approach is conditioning on past frames, which enables the model to learn temporal dependencies and predict future frames, thereby identifying deviations from expected motion patterns, as explored in TimeDiT [134].Incorporating motion representations, such as optical flow or motion vectors, can further enhance the model's sensitivity to subtle anomalies related to unusual movements.Alternatively, conditioning on semantic features extracted from the video content can provide higherlevel contextual information, helping differentiate between normal and anomalous events based on scene understanding.Hybrid conditioning strategies, combining past frames with motion representations or semantic features, leverage both low-level motion cues and high-level context.For example, ProDiffAD [137] uses inter-cloud network conditions for enhanced anomaly detection, while DDMT [126] employs an adaptive dynamic neighbor mask (ADNM) to mitigate information leakage.Approaches like NGLS-Diff [60] operate within a normal gathering latent space for improved anomaly detection in normal time series data, and TSAD-C [128] utilizes spatio-temporal graph conditional diffusion models to address contaminated training data.Similarly, SSSD [136] leverages structured state space models for improved imputation and forecasting by capturing long-term dependencies.</p>
<p>Performance Comparison</p>
<p>Emerging research in VAD increasingly leverages diffusion models to capture complex temporal dynamics and generate high-fidelity video reconstructions.As shown in Table 5, contemporary methods demonstrate varying performance across standard benchmark datasets, with approaches like DMAD [113] achieving exceptional results on UCSD Ped2 (99.7% AUC) and CUHK Avenue (92.8% AUC).Despite the promising capabilities of diffusion-based techniques, directly comparing model performance remains challenging due to inconsistent experimental protocols and reporting standards across studies.While traditional VAD research has predominantly employed autoencoders and generative adversarial networks, diffusion-based approaches like VADiffusion [121] show competitive performance by employing a dual-branch architecture that combines motion vector reconstruction with I-frame prediction guided by compressed domain information.Such integration of diffusion principles enhances  framework stability and detection accuracy, particularly when addressing both sudden and persistent anomalies.Nevertheless, computational overhead presents a significant concern for high-resolution video processing, creating an inevitable trade-off between detection accuracy and operational efficiency.Methods such as ReFLIP-VAD [138] and VadCLIP [19], though not directly via DMs, further highlight challenges in adapting complex vision-language architectures for video analysis despite their strong performance on datasets like XD-Violence [139] and UCF-Crime [140].</p>
<p>TIME SERIES ANOMALY DETECTION</p>
<p>TSAD with DMs faces distinct challenges related to the inherent temporal structure of sequential data.As shown in Fig. 6, effective TSAD frameworks must address temporal dependencies, irregular sampling rates, and longterm relationships through specialized adaptation modules incorporating recurrent networks and attention mechanisms.The figure highlights two primary approaches in diffusionbased TSAD: reconstruction-based methods that compute anomaly scores by comparing original and reconstructed series, and imputation-based methods that evaluate anomaly likelihood through the quality of imputed missing values.Both approaches utilize specialized time series-aware diffusion models that capture the complex dynamics of sequential data, enabling more nuanced anomaly detection compared to traditional methods.</p>
<p>Considerations</p>
<p>Due to inherent temporal dependencies and often irregular sampling, TSAD sometimes exhibits long-term dependencies requiring models to capture relationships across extended periods [146].While traditional methods often struggle with these characteristics, diffusion models offer a promising approach with appropriate adaptations.One key adaptation incorporates recurrent neural networks (RNNs), such as LSTMs, designed to process sequential data and capture temporal dependencies [35].Another crucial adaptation leverages attention mechanisms [3], allowing models to focus on relevant parts of the time series when reconstructing or scoring anomalies, effectively handling long-term dependencies and irregular sampling.For example, TimeDiT [134] utilizes a transformer architecture with attention and a diffusion process for generating high-quality samples.Similarly, CAT [147] employs a moment network with reinforcement learning to address irregular sampling by seeking relevant moments within the continuous timeline.Progressive learning paradigms [14] offer an additional strategy for complex time series by gradually increasing data complexity and network capacity to capture long-term trends and short-term variations.Addressing missing data, a common issue in real-world time series, is also crucial, with methods like those in [148] demonstrating the capability of handling such data without explicit structural priors.</p>
<p>Incorporating temporal priors into self-attention [149] can further enhance a model's ability to learn from the arrow of time, as exemplified by Triformer [150], which introduces a triangular attention mechanism with linear complexity for efficient processing of long sequences and capturing distinct temporal dynamics.</p>
<p>Taxonomy and Advances</p>
<p>Diffusion models for TSAD are primarily categorized into reconstruction-based and imputation-based methods, as shown in Table 6.Reconstruction-based methods exploit the generative capabilities of diffusion models to reconstruct input time series, identifying anomalies as instances with high reconstruction errors [124].For example, DDTAD [28] uses a 1-D U-Net within a DDPM framework for time series reconstruction and anomaly detection.Approaches like D 3 R [125] and NGLS-Diff [60] further enhance this paradigm; D 3 R incorporates dynamic decomposition to handle drifting time series, while NGLS-Diff operates within a learned latent space of normal temporal patterns.DDMT [126] integrates a denoising diffusion model with a Transformer architecture and an adaptive dynamic neighbor mask mechanism.</p>
<p>In contrast, imputation-based approaches use anomaly detection as a framework for the missing value imputation task [148].DiffAD [127] leverages a density ratio strategy and a conditional weight-incremental DMs for improved anomaly detection, particularly with concentrated anomalous points.Similarly, SSSD [136] combines conditional diffusion models with structured state space models for imputation and forecasting.In practical applications, Diffusion+ [151] focuses on efficient imputation for cloud failure prediction, and SaS-Dim [133] introduces a self-adaptive noise scaling diffusion model for spatial time series imputation.General-purpose diffusion transformer models like TimeDiT [134] and TSDE [135] demonstrate the versatility of diffusion models for various time series tasks, including imputation and anomaly detection.Addressing contaminated training data, TSAD-C [128] incorporates a decontamination module within a spatiotemporal graph conditional diffusion model framework.</p>
<p>Performance Comparison</p>
<p>Originally developed for image generation, DMs are increasingly being adapted for TSAD, leveraging their capability to capture complex temporal dependencies and generate high-fidelity synthetic data [152].As evidenced in Table 7, methods demonstrate significant performance improvements across challenging benchmarks such as SWaT, WADI, MSL, and SMD datasets.Early approaches like DAGMM [153] established foundational techniques using deep generative models, while subsequent methods such as OmniAnomaly [152] advanced the field through more sophisticated probabilistic modeling.Architectural adaptations addressing specific challenges of time series data have emerged, with researchers incorporating recurrent networks and attention mechanisms to handle irregular sampling and long-term dependencies [125].Various conditioning strategies have been explored, including prototype-based methods [154] that achieve notable precision-recall balance on industrial datasets, and approaches conditioning on "nominality scores" [155] that demonstrate improved performance in pointadjusted metrics.Applications span diverse domains from network monitoring [156] to industrial fault detection [50], with generative capabilities being leveraged for data augmentation and robustness enhancement [149].Recent innovations such as D 3 R [125] incorporate dynamic decomposition to handle unstable multivariate time series with data drift, while SensitiveHUE [157] represents the current state-of-theart by enhancing sensitivity to normal patterns, achieving remarkable F1 scores (91.08% on SWaT) and point-adjusted metrics (98.42% on MSL).Comparative analysis across these approaches reveals an inherent trade-off between precision and recall, with certain methods excelling in different application domains based on their specific architectural characteristics and conditioning strategies.</p>
<p>TABULAR ANOMALY DETECTION</p>
<p>Tabular data presents unique challenges for anomaly detection, primarily due to the inherent nature of mixed data types (numerical, categorical, ordinal) and the frequent presence of missing values.As illustrated in Fig. 7, effective TAD  [167] 2025 AAAI Noise evaluation AUC score ✗ CoDi [168] 2023 ICML Co-evolving diffusion Synthesis quality ✓ SimpDM [169] 2024 CIKM Self-supervised diffusion Imputation accuracy ✓ FinDiff [170] 2023 ICAIF Diffusion-based Fidelity, privacy, utility ✓ PHAD [171] 2025 IPM Hypergraph representation Detection accuracy ✓ Thimonier et al. [172] 2024 CIKM Retrieval-augmented Detection performance ✗ frameworks must process heterogeneous input data through specialized preprocessing and embedding techniques before applying tabular-adapted diffusion models, which generate reconstructions that can be compared with the original input to compute anomaly scores.The figure highlights how reconstruction or generation loss serves as the primary mechanism for anomaly detection, while addressing key challenges specific to tabular data throughout the pipeline.Consequently, researchers have developed specific data preprocessing techniques and specialized diffusion model architectures to address these issues.</p>
<p>Considerations</p>
<p>Mixed data types in tabular datasets require specialized modeling frameworks since conventional diffusion approaches poorly handle categorical variables.DiSK [158] employs Gaussian mixture modeling for simultaneous processing of text, categorical, and continuous data, while TabSynDex [159] converts diverse data types into unified latent representations.Missing values further complicate modeling, with MissDiff [160] addressing this limitation by masking denoising score matching regression loss during training.DiffImpute [161] leverages harmonization techniques for enhanced coherence between observed and imputed data.Computational efficiency constraints have led researchers toward using gradient-boosted trees for score function learning and implementing accelerated sampling methods like TimeAutoDiff's parallel generation approach [162].For imbalanced feature distributions, researchers have developed fair DMs generating balanced data while maintaining sample quality [29].Architectural adaptations include specialized denoising networks with Transformers showing superior performance [161], while latent diffusion approaches combine VAEs with diffusion models to optimize tabular data representation [163].For time series tabular data, structured state space models effectively capture temporal dependencies, complemented by appropriate preprocessing techniques tailored to domain-specific patterns [136].</p>
<p>Taxonomy and Advances</p>
<p>Modern approaches to TAD with generative models exhibit distinct methodological divisions, as illustrated in Table 8, which categorizes recent techniques across multiple dimensions including architectural paradigms and evaluation frameworks.Among reconstruction-based methods, TabADM [164] leverages diffusion principles to model normal data distributions and identify anomalies through reconstruction errors, establishing a foundational approach for diffusion-based tabular analysis.Complementary to this paradigm, generation-based techniques such as FinDiff [170] and CoDi [168] focus on synthesizing realistic tabular data, enabling broader applications spanning data augmentation and comparative anomaly detection between generated and real instances.Beyond standard diffusion approaches, self-supervised paradigms exemplified by SimpDM [169] enhance imputation accuracy and robustness handling sparse or missing values-a prevalent challenge in tabular domains.Integration with complementary techniques further diversifies the methodological landscape, with PHAD [171] merging diffusion-based augmentation with hypergraph representation learning to capture higher-order relationships, while retrieval-augmented methods [172] leverage retrieved samples for enhanced anomaly identification.Architectural innovations continue to emerge through hybrid approaches like TimeAutoDiff [162], which synergistically combines autoencoder frameworks with DMs to enhance data synthesis by capitalizing on the strengths of both paradigms.</p>
<p>Performance Comparison</p>
<p>Direct application of image-based DMs to tabular data presents challenges due to inherent structural differences, including mixed data types and missing values-obstacles that necessitate specialized adaptations and preprocessing techniques.As evidenced in Table 9, TAD approaches demonstrate considerable performance variations across 47 real-world datasets spanning healthcare, finance, and image processing domains.Earlier methods like NeuTraLAD [173] and SCAD [174] established foundational techniques with AUC scores of 71.45% and 69.15% respectively, while recent innovations including DPAD [177] and AutoUAD [178] show substantial improvements, achieving 88.05% and 92.68% AUC scores.Related work in multivariate time series demonstrates competitive performance through specialized architectures that capture complex dependencies in structured data [26].Advanced frameworks incorporating dynamic step size computation and latent space projection [25] enhance both detection accuracy and anomaly localization capabilities.Applications span diverse domains from fraud detection to intrusion monitoring, leveraging diffusion models' ability to learn complex distributions for  identifying unusual patterns in tabular structures.Notably, few-shot frameworks like AnomalySD [179] utilizing Stable Diffusion have demonstrated particular effectiveness in industrial settings, achieving high performance with minimal labeled examples.Comparative analysis across these approaches reveals the importance of domain-specific adaptations, with methods like DNN [167] achieving stateof-the-art performance (92.27%AUC) through specialized architectures tailored to tabular data characteristics.</p>
<p>MULTIMODAL ANOMALY DETECTION</p>
<p>By leveraging the complementary nature of diverse data sources, multimodal approaches significantly enhance the accuracy and robustness of anomaly detection systems.Fig. 8 illustrates how these frameworks process multiple input modalities through alignment and embedding techniques before applying fusion strategies (early, late, or dynamic) within collaborative diffusion models.The diagram demonstrates data flow while highlighting critical challenges including modal alignment, fusion techniques, and influence balancing.</p>
<p>Considerations</p>
<p>MAD introduces challenges due to diverse data sources.Modal alignment is challenging as different modalities occupy distinct feature spaces with varying scales and distributions [180].Effective fusion techniques are crucial for capturing modality interactions, as simple concatenation may not exploit their complementary nature [181].Additionally, balancing the influence of modalities is essential, as some may be more informative for specific anomaly types [182].To address these challenges, collaborative diffusion frameworks enable joint learning of representations across modalities, promoting alignment and facilitating information exchange [183].Multimodal embedding spaces provide a common ground for representing and comparing information, mitigating the alignment issue, as exemplified by AnomalyXFusion's X-embedding approach, which integrates image, text, and mask features [184].Dynamic fusion mechanisms, such as AnomalyXFusion's Dynamic Dif-Fusion module, offer adaptive weighting of modalities based on their relevance, adjusting the contribution of multimodal features during diffusion steps for context-aware generation [185].Ongoing research on cross-modal feature mapping and quality-aware fusion further enhances the robustness and accuracy of these systems [180], [182].Deep structured anomaly detection frameworks [186] and the incorporation of semantic guidance in diffusion models [187] also contribute to handling the complexities of multimodal data.</p>
<p>Taxonomy and Advances</p>
<p>Recent research in anomaly detection increasingly exploits complementary information from diverse data sources to TABLE 10: Summary of MAD methods on different datasets.</p>
<p>Method</p>
<p>Year Venue Datasets DM Code</p>
<p>Multimodal LDM [190] 2024 Ital-IA KSDD2 ✓ -Ano-cDiff [188] 2024 ESWA Brain glioma datasets ✓ Flaborea et al. [191] 2023 ICCV UBnormal, HR-UBnormal, etc., ✓ -AnomalyXFusion [183] 2024 ArXiv MVTec AD, LOCO, MVTec Caption ✓ Collaborative Diffusion [189] 2023 CVPR CelebAMask-HQ, CelebA-Dialog ✓ enhance detection accuracy and robustness.As shown in Table 10, recent multimodal approaches leverage fusion strategies tailored to specific application domains and data characteristics.Early fusion methods, exemplified by FedDiff [123], combine modalities at the input level, integrating features before model processing.In contrast, late fusion approaches like Ano-cDiff [188] process each modality independently before combining outputs, preserving modality-specific characteristics.Dynamic fusion strategies, represented by Collaborative Diffusion [189], adaptively weight modality contributions based on input characteristics, optimizing information extraction from heterogeneous sources.Multiple modality combinations have demonstrated effectiveness across application domains, with image-text pairings [190] enhancing industrial defect detection through expert knowledge integration, video-audio combinations [117], [191] improving surveillance anomaly recognition, and image-mask pairings [183] facilitating precise region localization.Notable architectural innovations include Xembeddings [183] that unify features from multiple modalities into coherent embedding spaces, and human-in-the-loop systems [190] that incorporate expert knowledge through text descriptions and region localization, substantially enhancing model performance on datasets like KSDD2.The growing availability of open-source implementations for methods like AnomalyXFusion and Ano-cDiff further accelerates progress in this rapidly evolving research area.</p>
<p>Applications</p>
<p>MAD with DMs offers substantial advancements in Industry 5.0, especially for defect detection.This approach leverages diffusion models to integrate diverse data modalities like images and text, providing a more comprehensive understanding of industrial processes and facilitating accurate anomaly identification.Approaches combining expert knowledge with visual data show particular promise.For example, multimodal LDMs incorporate text descriptions and region localization [190], enabling more targeted anomaly detection.In these models, experts provide textual descriptions and localize potential anomalies within images, guiding the model towards learning relevant and interpretable defect representations [190].Consequently, the integration of human expertise enhances the model's ability to detect subtle anomalies often missed by purely data-driven methods, and facilitates a robust feedback loop for iterative refinement and improved accuracy [190].Similarly, the Myriad model [192] uses an Expert Perception module to embed prior knowledge as tokens understandable by LLMs [193].Adopting this neuro-symbolic strategy facilitates the generation of granular anomaly descriptions encompassing attributes like color, shape, and category [192], which is crucial for effective decision-making in industrial settings.</p>
<p>Normal Sample Anomaly Sample Attention Process</p>
<p>Cross Attn.</p>
<p>Distance Map Attention Map</p>
<p>Cross Attn.</p>
<p>Decoder Encoder</p>
<p>Weight Map Anomaly Embed.</p>
<p>Noisy Image Image</p>
<p>Reweighted Map Spatial Embed.</p>
<p>Spatial Anomaly Embedding</p>
<p>Adaptive Attention Re-weighting Fig. 9: Overview of the AnomalyDiffusion framework.</p>
<p>ANOMALY GENERATION</p>
<p>Motivation</p>
<p>A key motivation for generating synthetic anomalies with DMs stems from the need to augment limited anomaly datasets.As shown in Fig. 10, AG methods typically take normal data as input seed, along with optional conditioning information (e.g., text descriptions or masks), and employ guided DMs to produce synthetic anomalies across various data modalities.The figure highlights how models like CUT [194] use latent space manipulation and controlled generation to create realistic anomalies for multiple purposes.Anomalies are inherently infrequent in real-world scenarios, resulting in imbalanced datasets that hinder the training of robust anomaly detection models.Consequently, DMs with their ability to learn complex data distributions, offer a promising avenue for generating realistic synthetic anomalies, thus addressing the scarcity of real-world examples.</p>
<p>In addition, data augmentation can improve the performance and generalization of anomaly detection models, especially in few-shot learning scenarios.Generating synthetic anomalies with varied characteristics and severities also allows researchers to stress-test anomaly detection models and identify potential vulnerabilities, such as limitations in detecting anomalies of different sizes, shapes, and locations [22], [25].As illustrated in Fig. 9, frameworks like AnomalyDiffusion [85] implement sophisticated architectures that integrate spatial anomaly embedding modules and adaptive attention re-weighting mechanisms to precisely control anomaly generation.Moreover, systematically varying generated anomalies enables researchers to assess model performance under different anomaly conditions, which can inform the development of more robust anomaly detection systems, particularly in critical applications like medical imaging [195].Finally, the generation of synthetic anomalies facilitates the development of self-supervised anomaly detection methods [16], [196] by training models on a mixture of normal data and synthetic anomalies to learn discriminative features that distinguish normal from anomalous patterns without explicit labels.</p>
<p>Taxonomy and Advances</p>
<p>Various diffusion-based approaches for anomaly generation have emerged in recent years, each addressing different aspects of the generation challenge with distinct methodological foundations.As summarized in HumanRefiner [199] 2024 ECCV Human image generation ✓ AnomalyDiffusion [85] 2024 AAAI Industrial inspection ✓ DualAnoDiff [86] 2024 ArXiv Industrial inspection ✓ AdaBLDM [197] 2024 ArXiv Industrial defect generation ✓ CUT [194] 2024 ArXiv Visual anomaly detection ✓ Rai et al. [200] 2024 CVPR Video anomaly detection ✓ -NSA [201] 2022 ECCV Manufacturing, Medical imaging ✗ CutPaste [198] 2021 CVPR Industrial inspection ✗ -PRN [202] 2023 CVPR Industrial manufacturing ✗ -Fontanella et al. [87] 2024 IEEE TMI Medical imaging (Brain) ✓ -FinDiff [170] 2023 ACM ICAIF Financial data ✓ -NetDiffus [129] 2024 COMNET Network traffic analysis ✓ directly alter the diffusion process to produce anomalous samples, while conditional generation methods leverage additional information to guide the generation toward specific anomaly types.For example, AnomalyDiffusion [85] and DualAnoDiff [86] utilize specialized conditioning strategies for industrial inspection applications, whereas CUT [194] offers a more general framework for visual anomaly detection.Latent space modification represents another significant category, where techniques modify the underlying representation space to create anomalies, contrasting with data-space approaches that operate directly on raw input.Furthermore, the integration of diffusion models with other generative or discriminative architectures has gained traction, as exemplified by AdaBLDM [197], which enhances the realism and diversity of generated anomalies.Beyond visual domains, applications have expanded to specialized fields such as financial data analysis with FinDiff [170] and network traffic analysis through NetDiffus [129], demonstrating the versatility of diffusion models for anomaly generation across diverse domains.The evolution from earlier techniques like CutPaste [198] to sophisticated diffusion-based frameworks indicates significant progression in generating increasingly realistic and controllable anomalies.</p>
<p>Performance Comparison</p>
<p>Leveraging the powerful capabilities of DMs, several frameworks have emerged as effective tools for generating synthetic anomalies with remarkable realism and diversity.As shown in Table 12, AnomalyDiffusion [85] demonstrates superior performance over traditional GAN-based methods like DefectGAN [203] and DFMGAN [204], achieving the highest Inception Score (1.8) and IC-LPIPS (0.32) on the MVTec AD dataset.Beyond AnomalyDiffusion, methods like CUT [194] further advance the field by leveraging Stable Diffusion for generating realistic anomalies without retraining, demonstrating universality across unseen data and novel anomaly types, which facilitates targeted anomaly creation for applications like data augmentation.Additionally, conditioning strategies play a crucial role in guiding the generation process.For example, SDAS in RealNet [205] employ a diffusion-based synthesis strategy specifically designed to mimic the distribution of real anomalies, creating a diverse set of synthetic examples for training robust anomaly detection models.Moreover, vision-language models [138] can effectively leverage textual descriptions to condition the generation process, enabling fine-grained control over the characteristics of generated anomalies.</p>
<p>Applications</p>
<p>Anomaly generation with DMs has found diverse applications, notably in data augmentation [85].In scenarios with limited anomaly samples, synthetically generated anomalies can augment training datasets, consequently improving the performance and robustness of AD models, which is particularly valuable in areas like industrial inspection [23] where acquiring real-world anomalies is challenging.Additionally, generating a wide range of potential anomalies facilitates model robustness testing [95] and allows researchers to evaluate detection models under diverse conditions.Such a process helps identify vulnerabilities and enhances the reliability of anomaly detection systems.Anomaly generation also enables anomaly visualization [26], aiding in understanding anomalous event characteristics and interpreting model predictions.For example, in medical imaging, visualizing generated anomalies can assist clinicians in identifying subtle abnormalities.Furthermore, some methods [22], [25] leverage dynamic noise addition during diffusion, guided by initial anomaly predictions, to improve anomaly localization, particularly for anomalies of varying scales.</p>
<p>MODEL EVALUATION</p>
<p>Evaluation Metrics</p>
<p>Effective ADGDM relies on robust evaluation metrics tailored to specific data modalities.As shown in Fig. 11, evaluation frameworks must address the distinct characteristics of each data type through specialized metrics.tasks, AUROC measures the model's ability to distinguish between normal and anomalous images [213], while Average Precision addresses class imbalance inherent in anomaly datasets [214], and F1-score balances precision and recall to reflect both correct identification and false positive avoidance [215].Metric selection depends on application requirements, with industrial defect detection prioritizing high recall through F1-score or AP, whereas medical applications favor AUROC to minimize false positives.</p>
<p>Video Anomaly Detection Metrics</p>
<p>VAD evaluation requires assessing both detection accuracy and video quality while maintaining temporal consistency [36].Detection metrics including AUROC, AUC@PR, and Equal Error Rate quantify distinguishing capabilities between normal and anomalous events [216], with AUC@PR particularly relevant given class imbalance challenges.Video quality assessment employs Fréchet Video Distance, Fréchet Inception Distance, and CLIPSIM to evaluate generated video fidelity through feature distribution comparisons and semantic similarity measures [200].Temporal coherence metrics ensure smooth frame transitions by measuring optical flow consistency and motion trajectory smoothness [103], while human evaluation provides subjective assessment for subtle or context-dependent anomalies.</p>
<p>Time Series Anomaly Detection Metrics</p>
<p>TSAD metrics encompass detection performance, error measurement, computational efficiency, and statistical fidelity [217].Detection capabilities utilize AUROC, AUPRC, F1score, precision, and recall [218], while error metrics like RMSE, MAE, and CRPS quantify prediction accuracy for forecasting-based methods [219].Computational considerations including inference time and energy consumption prove critical for deployment [105], alongside statistical fidelity metrics ensuring synthetic data reflects underlying distributions [26].Unique challenges include severe class imbalance where normal data vastly outnumbers anomalies [220], distinctions between point-wise and range-based detection requiring different evaluation approaches [221], and domain-specific requirements where financial applications prioritize false positive minimization while industrial monitoring emphasizes timely detection [222].[186] and fusion performance metrics evaluating multimodal integration benefits over single-modality approaches [224].Application-specific adaptations combine visual-textual data for industrial inspection [225] or specialized audio-visual metrics for surveillance, while addressing challenges from data heterogeneity, lack of standardized benchmarks [226], and the need for interpretable metrics capturing complementary information across modalities [227].</p>
<p>Benchmark Datasets</p>
<p>Evaluating AD requires access to well-established benchmark datasets, as summarized in Table 13, which presents key datasets categorized by modality and application domain.</p>
<p>Image Anomaly Detection Datasets</p>
<p>MVTec AD [97] serves as the de facto standard for industrial anomaly detection, encompassing 15 object categories with diverse defect types.Its extension, MVTec 3D-AD [229], incorporates depth information, facilitating research on 3D anomaly detection.Additionally, MVTec LOCO [233] focuses on logical anomalies characterized by structural or compositional irregularities.Other industrial datasets include BTAD [231], VisA [96], KSDD2 [232], MPDD [230], and PCB-Bank [47], each presenting unique characteristics for evaluating different aspects of diffusion model performance.Finally, the medical dataset BraTS [228] provides MRI scans for brain tumor segmentation, introducing challenges related to subtle anomalies and the critical need for accurate detection in medical applications.</p>
<p>Video Anomaly Detection Datasets</p>
<p>Industrial surveillance datasets including UCSD Ped2 [236] and CUHK Avenue [237] provide foundational benchmarks for non-pedestrian detection and unusual pedestrian behaviors, while comprehensive datasets ShanghaiTech [140] and UCF-Crime [140] offer diverse evaluation scenarios across 13 scenes and crime categories respectively.The most challenging benchmark, NWPU Campus [245], [246], features 43 scenes with scene-dependent anomaly definitions where identical events may be normal or abnormal based on context.Complementing surveillance data, UBnormal [241] provides densely annotated videos for pixel-level localization, while instructional datasets CrossTask [239] and COIN [240] evaluate procedural anomaly detection through deviations from standard procedures.</p>
<p>Time Series Anomaly Detection Datasets</p>
<p>Industrial monitoring drives TSAD benchmark development, with SMD [152] providing server metrics for multivariate dependency evaluation, while spacecraft datasets SMAP [235] and MSL [235] offer real-world telemetry scenarios.Moreover, industrial control contributions include SWaT [234] featuring real-world water purification testbed data with simulated attacks, specialized datasets TEP [242] with chemical process environments, Batchbenchmark [243] for manufacturing processes, and comprehensive ADBench [244] containing 57 real-world datasets across domains.The diversity in temporal characteristics and anomaly prevalence provides comprehensive evaluation settings for diffusion model performance in capturing temporal correlations essential for robust TSAD applications.</p>
<p>DISCUSSION</p>
<p>Open Challenges</p>
<p>The application of ADGDM has shown promising results, yet several critical challenges remain to be addressed to achieve robust, scalable, and generalizable solutions.Scalability.Scaling DMs to high-dimensional data, such as high-resolution images or long video sequences, remains challenging due to significant memory and computational demands [247].Iterative denoising processes exacerbate scalability issues, limiting applicability in resource-intensive settings [73].Developing efficient architectures, such as latent diffusion or optimized sampling techniques, is crucial to handlling complex multimodal inputs effectively while maintaining detection accuracy [89].Generalization.Achieving robust generalization for diffusion models across domains, e.g., from industrial to medical imaging, is hindered by domain shifts and varying anomaly types [6], [11].Models trained on specific datasets often fail to adapt to new contexts, reducing their practical utility [32], [33].Transfer learning and domain-adaptive techniques are essential to enhance cross-domain performance, ensuring DMs can handle diverse data distributions and anomaly characteristics effectively [212].Class Imbalance.Detecting rare anomalies in imbalanced datasets, where normal samples dominate, poses a significant challenge for diffusion models [210].Overfitting to normal data distributions reduces sensitivity to subtle anomalies, compromising detection accuracy [195].Techniques like anomaly augmentation or robust scoring mechanisms are needed to improve model performance on rare events, ensuring reliable detection in critical applications such as industrial monitoring [86].</p>
<p>Computational Efficiency.High computational cost of DMs during inference, driven by iterative denoising steps, hinders deployment in real-time or resource-constrained environments [248], thereby limiting their practicality for applications like industrial monitoring [93].Consequently, techniques such as model distillation, fewer-step sampling, or hardware-aware optimizations are essential to reduce inference latency while preserving AD accuracy [94].</p>
<p>Robustness.DMs are vulnerable to adversarial perturbations and noisy inputs, which can distort anomaly scoring and compromise reliability [91], particularly in domains like medical diagnostics, where robustness is paramount [17].Given these vulnerabilities, developing adversarial training strategies or noise-robust scoring mechanisms is necessary to enhance model stability, ensuring consistent performance under challenging conditions and safeguarding against malicious or erroneous inputs [67].</p>
<p>Future Opportunities</p>
<p>ADGDM presents several promising opportunities for future research and development, with prospects to enhance efficiency, integrate novel conditioning, combine with other techniques, explore new modalities, and leverage LLMs for intelligent detection, that could significantly advance the capabilities and practical applications of this field.Efficient DM architectures.High computational costs limit DM deployment in real-time anomaly detection applications, particularly for high-resolution images and videos.Dynamic step size computation [22] addresses this through initial anomaly prediction guidance, while latent space projections and quantization techniques reduce memory demands.Moreover, alternatives to full-length Markov chain diffusion [74] and multi-scale simplex noise diffusion offer pathways to scaling DMs to high-resolution imagery without compromising detection quality.New Conditioning Strategies.Enhanced conditioning strategies incorporate prior knowledge and contextual information to improve anomaly detection performance [248].Multimodal conditioning through text or audio provides complementary detection cues [249], while domain-specific knowledge integration improves detection specificity.Temporal conditioning benefits time-series and video analysis [26], while feedback loops using anomaly scores [22], [25] enhance localization accuracy.Adaptive conditioning strategies that respond to input characteristics offer promising solutions for heterogeneous datasets.DMs with Other AD techniques.Hybrid approaches combining DMs with existing methods yield superior performance through complementary strengths.Clustering integration leverages generative capabilities for representative normal data synthesis [23], while one-class classifiers benefit from DM-generated samples [241].Notable methods include ODD [18] combining similarity networks with outlier exposure, and dual conditioning frameworks for multi-class detection through category-specific reconstructions [62].New Modalities and Applications.Current ADGDM focuses primarily on images, videos, and time series, leaving opportunities in broader modalities and applications.Tabular data applications in finance and healthcare show promise despite mixed data type challenges [2].Multimodal detection [25] and extensions to audio or 3D point clouds could enable new applications, while time series advances address irregular sampling and long-term dependencies [26], combined with self-supervised learning [196].AD with LLMs.Large language models enhance diffusionbased detection through advanced pattern understanding.LLMs provide interpretable explanations for anomalies [250] while analyzing multimodal data for subtle patterns [251], [252].Complex temporal pattern identification benefits time series detection [253], while synthetic anomaly generation addresses data scarcity [254], [255].Integration enables intelligent adaptive monitoring for medical diagnosis and cybersecurity [256], [257].</p>
<p>Fig. 1 :
1
Fig. 1: Publication and citation trends in anomaly-related research topic from 2021 to 2025 (statistical time 2025/03/20).</p>
<p>Fig. 3 :
3
Fig. 3: Overview of anomaly scoring mechanisms with DMs.The diagram illustrates three primary paradigms for calculating anomaly scores: (a) Reconstruction-based scoring computes A(x) = d(x, x) between input x and its reconstruction x; (b) Density-based scoring uses negative loglikelihood A(x) = − log p(x) as the anomaly score; (c) Scorebased scoring utilizes A(x) = ∥∇ x log p(x)∥ 2 , reflecting the data manifold's geometry.</p>
<p>Fig. 4 :
4
Fig. 4: IAD with (a) reconstruction-based methods and (b) conditional/multi-stage variants.</p>
<p>Fig. 5 :
5
Fig. 5: VAD incorporating spatio-temporal features and motion modeling.</p>
<p>Fig. 6 :
6
Fig.6: TSAD with reconstruction and imputation paths.</p>
<p>Fig. 8 :
8
Fig.8: MAD with early/late/dynamic fusion strategies.</p>
<p>Jing Liu is with the College of Future Information Technology, Fudan University, Shanghai 200433, China, also with the Division of Natural and Applied Sciences, Duke Kunshan University, Suzhou 215316, China, and also with the Department of Electrical and Computer Engineering, The University of British Columbia, BC V6T 1Z4, Canada (e-mail: jing.liu@ieee.org).• Chengfang Li is with the Academy for Engineering &amp; Technology, Fudan University, Shanghai 200433, China (e-mail: cfli20@fudan.edu.cn).• Rui Xi is with the Department of Electrical and Computer Engineering, The University of British Columbia, BC V6T 1Z4, Canada (e-mail: ruix@ece.ubc.ca).• Wenchao Li is with the School of Computer Science, University of Sydney, NSW 2006, Australia (e-mail: li58843972@163.com).• Liang Cao is with the Department of Chemical Engineering, Massachusetts Institute of Technology, MA 02139, United States (e-mail: liangcao@mit.edu).• Jin Wang is with the School of Future Science and Engineering, Soochow University, Suzhou 215006, China (e-mail: wjin1985@suda.edu.cn).</p>
<p>• Yang Liu is with the Department of Computer Science, The University of Toronto, ON M5S 1A1, Canada (e-mail: yangliu@cs.toronto.edu).• • Laurence T. Yang is with School of Computer Science and Artificial Intelligence, Zhengzhou University, Zhengzhou 450001, China, and also with the Department of Computer Science, St. Francis Xavier University, Antigonish, NS B2G 2W5, Canada (e-mail: ltyang@ieee.org).• Junsong Yuan is with Department of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, NY 14260, USA (e-mail: jsyuan@buffalo.edu).• Wei Zhou is with the School of Computer Science and Informatics, Cardiff University, CF24 4AG Cardiff, U.K. (e-mail: zhouw26@cardiff.ac.uk).</p>
<dl>
<dt>TABLE 1 :</dt>
<dt>1</dt>
<dt>Summary of our survey with recently AD surveys, highlighting the main focus, domain, scope, and resources.Symbol definitions used throughout the comparison: : "Not Covered", : "Partially Covered", ⊙: "Not applicable", and : "Fully Covered".Abbreviations include image AD (IAD), video AD (VAD), time series AD (TSAD), tabular AD (TAD), multimodal AD (MAD), anomaly generation (AG), and diffusion models (DMs).</dt>
<dt>DomainScopreResources</dt>
<dt>Notes: • We identify key challenges in the field, such as computational efficiency and identity shortcut problem, and propose promising research directions including efficient architectures, novel conditioning strategies, hybrid approaches integrating traditional techniques, and LLMs with diffusion-based frameworks.This roadmap aims to accelerate progress in this rapidly evolving field.Organization.As illustrated in Fig.</dt>
<dd>
<p>Video AD Sec. 5: Time Series AD Sec. 8: Generation Sec. 9: Evaluation Sec. 10: Discussion Sec. 3: Image AD
2.1 DMs Primer2.2 Anomaly Scoring2.3 Conditioning3.13.23.33.4ConsiderationsLocalizationTaxonomyPerformanceSec. 6: Tabular AD Sec. 7: Multi-modal AD Sec. 4Basic Concepts4.1 Considerations 9.1 Evaluation Metrics 4.2 Taxonomy 9.2 Benchmark Datasets 4.3 Performance 10.1 Challenges 10.2 Opportunities Evaluation &amp; Resource Analysis &amp; Outlook sec6.. 6.1 Considerations 6.3 Performance 6.2 Taxonomy sec6.. 7.1 Considerations 7.3 Performance 7.2 Taxonomy 5.1 Considerations 5.3 Performance 5.2 Taxonomy 8.1 8.2 8.3 8.4 Motivation Taxonomy Performance Application</p>
</dd>
</dl>
<p>TABLE 3 :
3
Performance comparison of key IAD methods on VisA and BTAD datasets.
MethodYear VenueDataset (Metric)VisA (I-AUROC) BTAD (PRO)DRAEM [92]2021 ICCV88.7, 73.1-SPADE [98]2021 Arxiv82.1, 65.9-PaDiM [93]2021 ICPR89.1, 85.9-RD4AD [99]2022 CVPR96.0, 70.994.3, 77.1PatchCore [94] 2022 CVPR95.1, 91.292.7, 77.3RAN [91]2023 ICCV-93.4, 78.7Tebbe et al. [25] 2024 CVPRW96.0, 94.195.2, 83.2GLAD [47]2025 ECCV99.5, 98.6-Video Frame (Seqs)Spatio-Temporal Feature Extractor (e.g., 3D Conv, Transformer)Diffusion Model (Frame/Sequence level) (Motion Modeling: Flow, Vecs, TF)Challenges: Temporal Deps., Motion ComplexityAnomaly ScorePredicted / Recon. Frames (Temporal Consistency)Motion Info. (Seman. Flow, Vectors)</p>
<p>Table 4
4
, VAD methods employ diffusion models across surveillance to disaster detection domains, categorized by processing granularity (frame vs. sequence-level), motion modeling approaches, and conditioning mechanisms.We examine frame-level analysis treating videos as image collections versus sequence-level approaches modeling tem-</p>
<p>TABLE 4 :
4
Summary of VAD with learning paradigms.
MethodYearVenueTypeDomainDMTur et al. [103]2023 IEEE ICIPFVideo surveillance✓Awasthi et al.</p>
<p>TABLE 5 :
5
Performance (AUC) comparison of key VAD methods on UCSD Ped2, CUHK Avenue, and ShanghaiTech.
MethodYearVenueDatasetUCSD Ped2 CUHK Avenue ShanghaiTechRTFM [141]2021ICCV96.385.173DMAD [113]2023CVPR99.792.878.8LSH [142]2023 IEEE TCSVT91.387.477.6VADNet [143]2023 IEEE TCSVT-87.375.2UMIL [144]2023CVPR-88.3-UR-DMU [27]2023AAAI-88.997.92VADiffusion [121] 2024 IEEE TCSVT98.287.271.7PLOVAD [145]2025 IEEE TCSVT--97.98Input Time SeriesAdaptation ModuleDiffusion ModelImputed Series(Multivariate/Irregular)(RNN, Attention, etc.)(Time Series Aware)(Missing Values Filled)Recon. ErrorReconstructed SeriesImputation Quality (or Likelihood)Anomaly ScoreChallenges: Temporal Deps., IrregularAnomaly ScoreReconstruction-based MethodSampling, Long-term Deps.Imputation-based Method</p>
<p>TABLE 6 :
6
Summary of TSAD with learning paradigms.
MethodYearVenueLearing ParadigmDMD 3 R [125]2023 NeurIPSDecompo. and recon.✓DDMT [126]2023ArXivMask-based✓DiffAD [127]2023KDDImputation-based✓SSSD [136]2023ArXivImputation and forecasting ✓Diffusion+ [151] 2023 ESEC/FSEImputation-based✓SaSDim [133]2023ArXivNoise-scaling diffusion✓Pintilie et al. [26] 2023 ICDMWDiffusion-based✓NetDiffus [129] 2024 COMNETTime-series imaging✓NGLS-Diff [60]2024 ECML PKDDLatent space diffusion✓TimeADDM [124] 2024ICASSPDiffusion-based✓Zuo et al. [61]2024APINReconstruction-based✓TimeDiT [134]2024ICMLWFoundation model✓TSDE [135]2024ArXivSelf-supervised learning✓Chen et al. [146] 2024 IEEE TCCReinforcement learning✗ProDiffAD [137] 2024IJCNNProgressive distillation✓TSAD-C [128]2024ArXivGraph conditional diffusion ✓</p>
<p>TABLE 7 :
7
[152]rmance comparison of key TSAD methods on SWaT, WADI, MSL, and SMD datasets.,69.52,39.37,85.3354.44,26.99, 36.09,61.65 25.91, 62.86, 36.69,70.0942.59,50.46,26.85, 72.29OmniAnomaly[152]2019 ACM KDD 98.25, 64.97, 78.22, 86.61 49.47, 12.98, 22.96, 41.72 16.19, 84.66, 27.18, 89.94 20.61, 46.73, 28.20, 75.29 , 60.52, 74.16, 91.04 86.88, 15.50, 26.00, 42.04 29.06, 75.96, 42.04, 94.94 26.95, 57.36, 37.16, 76.95 D 3 R [125] 2023 NeurIPS 12.04, 99.59, 21.49, 90.55 6.23, 18.93, 11.75, 35.46 11.04, 93.01, 19.74, 87.44 23.70, 52.63, 26.12, 95.09 PUAD [154] 2023 ICML 97.94, 60.52, 74.16, 91.04 86.88, 15.50, 26.00, 42.04 29.06, 75.96, 42.04, 94.94 26.95, 57.36, 37.16, 76.95 NPSR [155] 2023 NeurIPS 93.42, 75.52, 83.52, 91.07 78.43, 50.33, 61.31, 75.22 24.03, 83.92, 37.37, 96.45 26.58, 62.36, 37.27, 76.95 [157] 2024 ACM KDD 94.68, 87.74, 91.08, 96.75 86.51, 58.73, 69.96, 92.25 33.05, 71.26, 45.16, 98.42 29.54, 60.80, 39.76, 96.33 Notes: P, R, F1, and F1 PA refer to Precision, Recall, F1-score, and Point-Adjusted F1score.
MethodYear VenueDataset (Metrics)SWaT (P, R, F1, F1 PA) WADI (P, R, F1, F1 PA) MSL (P, R, F1, F1 PA) SMD (P, R, F1, F1 PA)DAGMM [153] 27.46AnomalyTran [156] 2021 2018 ICLR ICLR 12.00, 100.00, 21.43, 94.07 5.79, 43.43, 10.21, 89.10-, -, 2.10, 93.59-, -,2.12, 92.33TranAD [149]2022 VLDB97.94</p>
<p>TABLE 8 :
8
Summary of TAD methods with type and metrics.
Tabular DataPreprocessing / Embed.Diffusion Model(Mixed Types, Missing)(Handle Mixed/Missing)(Tabular Adapted)Challenges: Mixed Types, Miss. Vals, Het. VarsAnomaly Score/ Gen. Loss (or Likelihood)Reconstructed / Generated DataFig. 7: TAD handling mixed data types.MethodYear VenueTypePerformance Metrics DMTabADM [164]2023 ArXivDiffusion-basedDetection accuracy✓MPDR [165]2023 NeurIPSEnergy-basedAUPR, AUROC✗Tritscher et al. [166] 2024 xAIGenerative inpaintingExplanation quality✓TimeAutoDiff [162] 2024 ArXivVAE + DDPM hybridFidelity and utility metrics ✓Dai et al.</p>
<p>TABLE 9 :
9
Performance comparison of key TAD models on 47 real-world tabular datasets, including domains such as healthcare, image processing, and finance.
MethodYear VenueAvg. performance on 47-datasetAUC (%) Mean Rank p-valueNeuTraLAD [173] 2021ICML71.45 ± 22.69.160SCAD [174]2022ICLR69.15 ± 15.360.0002ECOD [175]2023 IEEE TKDE 52.77 ± 11.710.120PLAD [176]2022 NeurIPS 67.42 ± 19.69.160DPAD [177]2024Arxiv88.05 ± 12.44.960.0003AutoUAD [178] 2024Arxiv92.68 ± 11.82.040.47DNN [167]2025AAAI92.27 ± 11.11.680.47</p>
<p>Table 11 ,
11
these methods can be classified according to their underlying techniques and application domains.Manipulation-based approaches Fig.10: AG techniques with guided DMs for data augmentarobustness testing, and self-supervised learning.
Normal Data(Input Seed)…Guided / Modified DM (Latent Manip., Control) (e.g., AnomalyDiffusion, CUT)Synthetic Anomalies (Image, Video, TS…)Conditioning Info(eg., Text, Mask, Loc. etc)Motivations: Data Aug., Robustness Test., Visualization, FSL, SSL</p>
<p>TABLE 11 :
11
Summary of AG methods across various domains with implementations.
MethodYearVenueDomainDM Code</p>
<p>TABLE 12 :
12
Performance comparison of key AG models on the MVTec dataset using IS and IC-LPIPS metrics.
MethodYearVenueMetricISIC-LDefectGAN [203]2021WACV1.690.15SDGAN [206]2020IEEE TASE1.710.13DiffAug [207]2020NeurIPS1.580.09Crop&amp;Paste [208]2021IEEE ICME1.510.14DFMGAN [204]2023AAAI1.720.2CDC [209]2021CVPR1.650.07AnomalyDiffusion [85]2024AAAI1.80.32</p>
<p>Time Series Anomaly Detection Metrics Multimodal Anomaly Detection Metrics Video Anomaly Detection Metrics
Image Anomaly Detection MetricsPixel-level MetricsImage-level MetricsDetection PerformanceError &amp; Efficiency• Dice Coefficient• AUROC• AUROC / AUPRC• RMSE / MAE / CRPS• Intersection over Union• Average Precision (AP)• F1-score• Inference Time• Hausdorff Distance• F1-score• Precision / Recall• Energy ConsumptionFor anomaly localizationFor anomaly classificationFor classification accuracy• Statistical FidelityApplication-Specific ConsiderationsDomain-Specific Challenges• Industrial Defect Detection: F1-score, AP (high recall)• Class Imbalance: AUPRC preferred over accuracy• Medical Imaging: AUROC (minimize false positives)• Point-wise vs. Range-based Detection• Surface Defect: Precision-Recall balance• Financial: Min. false positives, Industrial: Timely detectionEvaluationMetricsDetection MetricsMetricsModality-Specific MetricsCross-Modal &amp; Fusion• AUROC• Fréchet Video Distance• Image: Dice, IoU, AUROC• Cross-modal Consistency• AUC@PR• Fréchet Inception Distance• Time Series: RMSE, F1• Fusion Performance• Equal Error Rate (EER)• CLIPSIM• Video: FVD, Temp. Coher.• Modality AnalysisFor event classificationFor generation quality• Audio: STFT measures• Information ConvergenceConsistency &amp; Human EvaluationChallenges &amp; Domain-Specific Metrics• Temporal Coherence (optical flow, motion trajectory)• Data Heterogeneity: Complex interactions between modalities• Human Assessment (subjective quality, anomaly perception)• Industrial: Visual-textual metrics for inspection tasks• Context-dependent interpretations (esp. for surveillance)• Robustness to modality quality variations and availabilityCritical considerations across all modalities: Task-specific metrics, Domain adaptation, Class imbalance, InterpretabilityFig. 11: Comprehensive evaluation metrics for ADGDMacross different data modalities.9.1.1 Image Anomaly Detection MetricsIAD employs evaluation metrics reflecting the task's mul-tifaceted nature, categorized into pixel-level metrics foranomaly localization and image-level metrics for classifica-
[212]210].Pixel-level localization relies on the Dice coefficient and Intersection over Union (IoU) to measure overlap between predicted and ground truth anomaly masks[211], while the Hausdorff Distance quantifies maximum boundary distances, proving particularly valuable in medical imaging where precise localization is crucial[212].For classification</p>
<p>TABLE 13 :
13
Summary of benchmark datasets for IAD, TSAD, TAD, and VAD across industrial, medical, surveillance, and cybersecurity domains.
NameTask YearVenueType #Samples #SubjectsDomainSiteMVTec-AD [97]IAD 2019CVPRReal5,35415Industrial anomaly detectionBraTS [228]IAD 2020-Real 5,000+1,250+ Medical Imaging (Brain Tumor)MVTec 3D-AD [229] IAD 2021 IJCVIPAReal4,43310Industrial anomaly detectionMPDD [230]IAD 2021 ICUMTReal4,5683Metal part defect detectionBTAD [231]IAD 2021ISIEReal2,8303Industrial InspectionKSDD2 [232]IAD 2021 Comput. Ind. Real3,4201Industrial (Surface) InspectionMVTec LOCO [233]IAD 2022IJCVReal1,7725Industrial anomaly detectionVisA [96]IAD 2022ECCVReal 10,82112Visual anomaly detectionPCB-Bank [47]IAD 2024ECCVReal--Circuit board defect detectionSWaT [234]TSAD 2016CRITISReal 950,0001Industrial Control SystemsMSL [235]TSAD 2018KDDReal 73,72927Aerospace TelemetrySMAP [235]TSAD 2018KDDReal 427,61755Satellite MonitoringSMD [152]TSAD 2019KDDReal20M28AIOps Server MonitoringUCSD Ped2 [236]VAD 2010CVPRReal28-Video SurveillanceCUHK Avenue [237] VAD 2013ICCVReal 30,65216Crowd BehaviorShanghaiTech [238]VAD 2016CVPRReal1,19813Crowd CountingUCF-Crime [140]VAD 2018CVPRReal1,90013Surveillance VideoCrossTask [239]VAD 2019CVPRReal4,70083Weakly Supervised ADCOIN [240]VAD 2019CVPRReal 11,827180Instructional Video AnalysisUBnormal [241]VAD 2022CVPRSynth 236,90229Open-set VideoTEP [242]TAD 1993 Springer Synth-21Industrial ProcessBatchbenchmark [243] TAD 2016CILSSynth5005Chemical ProcessADBench [244]TAD 2022 NeurlPSReal57-Tabular AD9.1.4 Multimodal Anomaly Detection MetricsMAD evaluation addresses both modality-specific and cross-modal performance aspects through comprehensive metricframeworks [223]. Individual modalities employ standardmetrics like Dice coefficient, IoU, and Hausdorff Distancefor localization alongside AUROC, AP, and F1-score for clas-sification. Cross-modal assessment introduces consistencymetrics quantifying information alignment between sources
CONCLUSIONIn this survey, we comprehensively examine anomaly detection and generation with diffusion models (ADGDM) across diverse data modalities.We explore various conditioning strategies and their impact on performance while highlighting adaptations for image, video, time series, and tabular data.We also explore emerging multimodal approaches and assess the potential of DMs for synthetic anomaly generation.Researchers currently face challenges including scalability, generalization, class imbalance, computational efficiency, and robustness across applications.Future research opportunities encompass developing efficient architectures, novel conditioning strategies, hybrid approaches integrating traditional techniques, and leveraging large language models.
Self-supervised anomaly detection with neural transformations. C Qiu, M Kloft, S Mandt, M Rudolph, IEEE Trans. Pattern Anal. Mach. Intell. 473Mar. 2025</p>
<p>On diffusion modeling for anomaly detection. V Livernoche, V Jain, Y Hezaveh, S Ravanbakhsh, ICLR2023</p>
<p>. W H L Pinaya, M S Graham, R Gray, P F Da Costa, P.-D , </p>
<p>Fast unsupervised brain anomaly detection and segmentation with diffusion models. P Tudosiu, Y H Wright, A D Mah, J T Mackinnon, R Teo, D Jager, G Werring, P Rees, S Nachev, M J Ourselin, Cardoso, 2022MICCAI</p>
<p>A novel data augmentation method based on denoising diffusion probabilistic model for fault diagnosis under imbalanced data. X Yang, T Ye, X Yuan, W Zhu, X Mei, F Zhou, IEEE Trans. Ind. Informat. 2052024</p>
<p>Graph anomaly detection in time series: A survey. T K K Ho, A Karami, N Armanfard, IEEE Trans. Pattern Anal. Mach. Intell. 2025</p>
<p>A survey on graph neural networks for time series: Forecasting, classification, imputation, and anomaly detection. M Jin, H Y Koh, Q Wen, D Zambon, C Alippi, G I Webb, I King, S Pan, IEEE Trans. Pattern Anal. Mach. Intell. 46122024</p>
<p>A survey of single-scene video anomaly detection. B Ramachandra, M J Jones, R R Vatsavai, IEEE Trans. Pattern Anal. Mach. Intell. 4452022</p>
<p>Deep learning for time series anomaly detection: A survey. Z Zamanzadeh Darban, G I Webb, S Pan, C Aggarwal, M Salehi, ACM Comput. Surv. 5712025</p>
<p>Self-supervised anomaly detection in computer vision and beyond: A survey and outlook. H Hojjati, T K K Ho, N Armanfard, Neural Netw. 1721061062024</p>
<p>Dataefficient and interpretable tabular anomaly detection. C.-H Chang, J Yoon, S Ö Arik, M Udell, T Pfister, KDD. 2023</p>
<p>Invariant anomaly detection under distribution shifts: A causal perspective. J Carvalho, M Zhang, R Geyer, C Cotrini, J M Buhmann, NeurIPS. 362023</p>
<p>Diffact++: Diffusion action segmentation. D Liu, Q Li, A.-D Dinh, T Jiang, M Shah, C Xu, IEEE Trans. Pattern Anal. Mach. Intell. 4732025</p>
<p>Foundation models defining a new era in vision: A survey and outlook. M Awais, M Naseer, S Khan, R M Anwer, H Cholakkal, M Shah, M.-H Yang, F S Khan, IEEE Trans. Pattern Anal. Mach. Intell. 4742025</p>
<p>Blackout diffusion: Generative diffusion models in discrete-state spaces. J E Santos, Z R Fox, N Lubbers, Y T Lin, ICML. 2023</p>
<p>Soil: Score conditioned diffusion model for imbalanced cloud failure prediction. C Duan, F Yang, P Zhao, L Zheng, Y Dagli, Y Liu, Q Lin, D Zhang, 2024WebConf</p>
<p>Self-supervised diffusion model for anomaly segmentation in medical imaging. K Kumar, S Chakraborty, S Roy, PReMI202314301</p>
<p>Fast non-markovian diffusion model for weakly supervised anomaly detection in brain mr images. J Li, H Cao, J Wang, F Liu, Q Dou, G Chen, P.-A Heng, MICCAI. 202314224</p>
<p>Odd: One-class anomaly detection via the diffusion model. H Wang, L Dai, J Tong, Y Zhai, ICIP. 2023</p>
<p>Vadclip: Adapting vision-language models for weakly supervised video anomaly detection. P Wu, X Zhou, G Pang, L Zhou, Q Yan, P Wang, Y Zhang, AAAI. 3862024</p>
<p>Sparsedm: Toward sparse efficient diffusion models. K Wang, J Chen, H Li, Z Mi, J Zhu, 2024</p>
<p>Safeguarding sustainable cities: Unsupervised video anomaly detection through diffusion-based latent pattern learning. M Zhang, J Wang, Q Qi, P Ren, H Sun, Z Zhuang, L Zhang, J Liao, IJCAI. 82024</p>
<p>D3ad: Dynamic denoising diffusion probabilistic model for anomaly detection. J Tebbe, J Tayyub, 2023</p>
<p>Glad: Towards better reconstruction with global and local adaptive diffusion models for unsupervised anomaly detection. H Yao, M Liu, H Wang, Z Yin, Z Yan, X Hong, W Zuo, 2024</p>
<p>Disyre: Diffusion-inspired synthetic restoration for unsupervised anomaly detection. S N Marimont, M Baugh, V Siomos, C Tzelepis, B Kainz, G Tarroni, 2024</p>
<p>Dynamic addition of noise in a diffusion model for anomaly detection. J Tebbe, J Tayyub, CVPR. 2024</p>
<p>Time series anomaly detection using diffusion-based models. I Pintilie, A Manolache, F Brad, ICDM. 2023</p>
<p>Dual memory units with uncertainty regulation for weakly supervised video anomaly detection. H Zhou, J Yu, W Yang, AAAI. 3732023</p>
<p>Anomaly detection for telemetry time series using a denoising diffusion probabilistic model. J Sui, J Yu, Y Song, J Zhang, IEEE Sensors J. 24102024</p>
<p>Balanced mixed-type tabular data synthesis with diffusion models. Z Yang, H Yu, P Guo, K Zanna, X Yang, A Sano, 2024</p>
<p>Anomaly detection for iot time-series data: A survey. A A Cook, G Misirli, Z Fan, IEEE Internet Things J. 772020</p>
<p>Deep learning for anomaly detection: A review. G Pang, C Shen, L Cao, A V D Hengel, ACM Comput. Surv. 542382021</p>
<p>Deep learning for medical anomaly detection -a survey. T Fernando, H Gammulle, S Denman, S Sridharan, C Fookes, ACM Comput. Surv. 5472022</p>
<p>Anomaly detection in surveillance videos: A thematic taxonomy of deep models, review and performance analysis. S Chandrakala, K Deepak, G Revathy, Artif. Intell. Rev. 5642023</p>
<p>A comprehensive survey on graph anomaly detection with deep learning. X Ma, J Wu, S Xue, J Yang, C Zhou, Q Z Sheng, H Xiong, L Akoglu, IEEE Trans. Knowl. Data Eng. 35122023</p>
<p>Anomaly detection in blockchain networks: A comprehensive survey. M Ul Hassan, M H Rehmani, J Chen, IEEE Commun. Surveys Tuts. 2512023</p>
<p>Generalized video anomaly event detection: Systematic taxonomy and comparison of deep models. Y Liu, D Yang, Y Wang, J Liu, J Liu, A Boukerche, P Sun, L Song, ACM Comput. Surv. 567382024</p>
<p>Networking systems for video anomaly detection: A tutorial and survey. J Liu, Y Liu, J Lin, J Li, L Cao, P Sun, B Hu, L Song, A Boukerche, V C Leung, ACM Comput. Surv. Apr. 2025</p>
<p>On the mathematics of diffusion models. D Mcallester, 2023</p>
<p>Neural sdes as infinitedimensional gans. P Kidger, J Foster, X Li, T J Lyons, ICML. 2021</p>
<p>Elucidating the solution space of extended reverse-time sde for diffusion models. Q Cui, X Zhang, Z Lu, Q Liao, 2023</p>
<p>Dyngma: A robust approach for learning stochastic differential equations from data. A Zhu, Q Li, J. Comput. Phys. 5131132002024</p>
<p>The uncanny valley: A comprehensive analysis of diffusion models. K Ghanem, D Bzdok, 2024</p>
<p>Learning stochastic dynamical systems with neural networks mimicking the euler-maruyama scheme. N Dridi, L Drumetz, R Fablet, 2021EUSIPCO</p>
<p>Generative modeling with phase stochastic bridges. T Chen, J Gu, L Dinh, E A Theodorou, J Susskind, S Zhai, 2024</p>
<p>Fast sampling of diffusion models via operator learning. H Zheng, W Nie, A Vahdat, K Azizzadenesheli, A Anandkumar, ICML. 202342402</p>
<p>Mathematical analysis of singularities in the diffusion model under the submanifold assumption. Y Lu, Z Wang, G Bal, 2024</p>
<p>Glad: Towards better reconstruction with global and local adaptive diffusion models for unsupervised anomaly detection. H Yao, M Liu, Z Yin, Z Yan, X Hong, W Zuo, ECCV. 2025</p>
<p>Perception prioritized training of diffusion models. J Choi, J Lee, C Shin, S Kim, H Kim, S Yoon, CVPR. 202211481</p>
<p>High-fidelity diffusion-based image editing. C Hou, G Wei, Z Chen, AAAI. 3832024</p>
<p>Unsupervised industrial anomaly detection with diffusion models. H Xu, S Xu, W Yang, J. Vis. Commun. Image Represent. 971039832023</p>
<p>Supervised anomaly detection based on deep autoregressive density estimators. T Iwata, Y Yamanaka, 2019</p>
<p>High-dimensional and permutation invariant anomaly detection. V Mikuni, B Nachman, SciPost Physics. 163622024</p>
<p>Deep energy estimator networks. S Saremi, A Mehrjou, B Sch, A Hyvärinen, 2018</p>
<p>Low-rank characteristic tensor density estimation part ii: Compression and latent density estimation. M Amiridi, N Kargas, N D Sidiropoulos, IEEE Trans. Signal Process. 702022</p>
<p>Score approximation, estimation and distribution recovery of diffusion models on lowdimensional data. M Chen, K Huang, T Zhao, M Wang, ICML. 2023</p>
<p>Your diffusion model secretly knows the dimension of the data manifold. J Stanczuk, G Batzolis, T Deveney, C.-B Sch Önlieb, 2023</p>
<p>Maximum likelihood training of score-based diffusion models. Y Song, C Durkan, I Murray, S Ermon, NeurIPS. 342021</p>
<p>Neural network-based score estimation in diffusion models: Optimization and generalization. Y Han, M Razaviyayn, R Xu, 2024</p>
<p>Interpreting and improving diffusion models using the euclidean distance function. F Permenter, C Yuan, 2023</p>
<p>Diffusion model in normal gathering latent space for time series anomaly detection. J Han, S Feng, M Zhou, X Zhang, Y S Ong, X Li, ECML PKDD. 202414943</p>
<p>Unsupervised diffusion based anomaly detection for time series. H Zuo, A Zhu, Y Zhu, Y Liao, S Li, Y Chen, Appl. Intell. 54192024</p>
<p>Enhancing multi-class anomaly detection via diffusion refinement with dual conditioning. J Zhan, J Lai, B.-B Gao, J Liu, X Chen, C Wang, 2024</p>
<p>Anomaly detection with conditioned denoising diffusion models. A Mousakhan, T Brox, J Tayyub, 2023</p>
<p>On conditioning the input noise for controlled image generation with diffusion models. V Singh, S Jandial, A Chopra, S Ramesh, B Krishnamurthy, V N Balasubramanian, 2022</p>
<p>Cads: Unleashing the diversity of diffusion models through condition-annealed sampling. S Sadat, J Buhmann, D Bradley, O Hilliges, R M Weber, 2024</p>
<p>Diffusion models as masked autoencoders. C Wei, K Mangalam, P.-Y Huang, Y Li, H Fan, H Xu, H Wang, C Xie, A Yuille, C Feichtenhofer, ICCV. 202316248</p>
<p>Adversarial guided diffusion models for adversarial purification. G Lin, Z Tao, J Zhang, T Tanaka, Q Zhao, 2025</p>
<p>Progressive distillation for fast sampling of diffusion models. T Salimans, J Ho, ICLR. 2021</p>
<p>Accelerating image generation with sub-path linear approximation model. C Xu, T Song, W Feng, X Li, T Ge, B Zheng, L Wang, ECCV. 202515111</p>
<p>Fast diffusion model. Z Wu, P Zhou, K Kawaguchi, H Zhang, 2023</p>
<p>Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. C Lu, Y Zhou, F Bao, J Chen, C Li, J Zhu, NeurIPS. 352022</p>
<p>Dp-ldms: Differentially private latent diffusion models. M F Liu, S Lyu, M Vinaroz, M Park, 2025</p>
<p>Lora-enhanced distillation on guided diffusion models. P A Golnari, 2023</p>
<p>Anoddpm: Anomaly detection with denoising diffusion probabilistic models using simplex noise. J Wyatt, A Leach, S M Schmon, C G Willcocks, 2022CVPRW</p>
<p>Anofpdm: Anomaly segmentation with forward process of diffusion models for brain mri. Y Che, F Rafsani, J Shah, M M R Siddiquee, T Wu, 2024</p>
<p>Diffusion models with implicit guidance for medical anomaly detection. C I Bercea, B Wiestler, D Rueckert, J A Schnabel, MICCAI202415011</p>
<p>Image-conditioned diffusion models for medical anomaly detection. M Baugh, H Reynaud, S N Marimont, S Cechnicka, J P Üller, G Tarroni, B Kainz, MLMI. 202515167</p>
<p>Unsupervised anomaly detection in medical images using masked diffusion model. H Iqbal, U Khalid, C Chen, J Hua, MLMI. 2024</p>
<p>Cold diffusion: Inverting arbitrary image transforms without noise. A Bansal, E Borgnia, H.-M Chu, J Li, H Kazemi, F Huang, M Goldblum, J Geiping, T Goldstein, NeurIPS. 362822023</p>
<p>Ensembled cold-diffusion restorations for unsupervised anomaly detection. S Marimont, V Siomos, M Baugh, C Tzelepis, B Kainz, G Tarroni, MICCAI. 2024</p>
<p>Unsupervised 3d out-of-distribution detection with latent diffusion models. M S Graham, W H L Pinaya, P Wright, P.-D Tudosiu, Y H Mah, J T Teo, H R Jäger, D Werring, P Nachev, S Ourselin, M J Cardoso, 2023MICCAI</p>
<p>Pancreatic tumor segmentation as anomaly detection in ct images using denoising diffusion models. R Babaei, S Cheng, T Thai, S Zhao, 2024</p>
<p>Igconda-pet: Implicitlyguided counterfactual diffusion for detecting anomalies in pet images. S Ahamed, Y Xu, A Rahmim, 2024</p>
<p>Modality cycles with masked conditional diffusion for unsupervised anomaly segmentation in mri. Z Liang, H Anthony, F Wagner, K Kamnitsas, MICCAI. 2024</p>
<p>Anomalydiffusion: Few-shot anomaly image generation with diffusion model. T Hu, J Zhang, R Yi, Y Du, X Chen, L Liu, Y Wang, C Wang, AAAI. 202438</p>
<p>Dualanodiff: Dual-interrelated diffusion model for few-shot anomaly image generation. Y Jin, J Peng, Q He, T Hu, H Chen, J Wu, W Zhu, M Chi, J Liu, Y Wang, C Wang, 2024</p>
<p>Diffusion models for counterfactual generation and anomaly detection in brain images. A Fontanella, G Mair, J Wardlaw, E Trucco, A Storkey, IEEE Trans. Med. Imag. 2024</p>
<p>Guided image synthesis via initial image editing in diffusion model. J Mao, X Wang, K Aizawa, ACM MM, 2023. </p>
<p>Unimo-g: Unified image generation through multimodal conditional diffusion. W Li, X Xu, J Liu, X Xiao, ACL. 2024</p>
<p>Detecting out-of-distribution earth observation images with diffusion models. G L Bellier, N Audebert, 2024CVPRW</p>
<p>Removing anomalies as noises for industrial defect localization. F Lu, X Yao, C.-W Fu, J Jia, ICCV. 2023175</p>
<p>Draem -a discriminatively trained reconstruction embedding for surface anomaly detection. V Zavrtanik, M Kristan, D Skočaj, ICCV. 2021</p>
<p>Padim: A patch distribution modeling framework for anomaly detection and localization. T Defard, A Setkov, A Loesch, R Audigier, Pattern Recognit. 2021</p>
<p>Towards total recall in industrial anomaly detection. K Roth, L Pemula, J Zepeda, B Sch Ölkopf, T Brox, P Gehler, CVPR. 202214328</p>
<p>Mask, stitch, and re-sample: Enhancing robustness and generalizability in anomaly detection through automatic diffusion models. C I Bercea, M Neumayr, D Rueckert, J A Schnabel, 2023</p>
<p>Spotthe-difference self-supervised pre-training for anomaly detection and segmentation. Y Zou, J Jeong, L Pemula, D Zhang, O Dabeer, ECCV. 2022</p>
<p>Mvtec ad -a comprehensive real-world dataset for unsupervised anomaly detection. P Bergmann, M Fauser, D Sattlegger, C Steger, CVPR. 2019</p>
<p>Sub-image anomaly detection with deep pyramid correspondences. N Cohen, Y Hoshen, 2021</p>
<p>Anomaly detection via reverse distillation from one-class embedding. H Deng, X Li, CVPR. 2022</p>
<p>Boosting positive and unlabeled learning for anomaly detection with multifeatures. J Zhang, Z Wang, J Meng, Y.-P Tan, J Yuan, IEEE Trans. Multimedia. 215May 2019</p>
<p>Abnormal event detection in crowded scenes using sparse representation. Y Cong, J Yuan, J Liu, Pattern Recognit. 467Jul. 2013</p>
<p>Anomalous video event detection using spatiotemporal context. F Jiang, J Yuan, S A Tsaftaris, A K Katsaggelos, Comput. Vis. Image Underst. 1153Mar. 2011</p>
<p>Exploring diffusion models for unsupervised video anomaly detection. A O Tur, N Dall'asen, C Beyan, E Ricci, ICIP. 2023</p>
<p>Vdt: General-purpose video diffusion transformers via mask modeling. H Lu, G Yang, N Fei, Y Huo, Z Lu, P Luo, M Ding, 2023</p>
<p>Spectral motion alignment for video motion transfer using diffusion models. G Y Park, H Jeong, S W Lee, J C Ye, 2024</p>
<p>Movideo: Motion-aware video generation with diffusion model. J Liang, Y Fan, K Zhang, R Timofte, L Van Gool, R Ranjan, ECCV. 202515102</p>
<p>Vidm: Video implicit diffusion models. K Mei, V Patel, AAAI. 3782023</p>
<p>Anomaly detection in satellite videos using diffusion models. A Awasthi, S T Ly, J Nizam, V Mehta, S Ahmad, R Nemani, S Prasad, H Van Nguyen, 2024IEEE MMSP. IEEE</p>
<p>Align your latents: High-resolution video synthesis with latent diffusion models. A Blattmann, R Rombach, H Ling, T Dockhorn, S W Kim, S Fidler, K Kreis, CVPR. 202322575</p>
<p>Reuse and diffuse: Iterative denoising for text-to-video generation. J Gu, S Wang, H Zhao, T Lu, X Zhang, Z Wu, S Xu, W Zhang, Y.-G Jiang, H Xu, 2023</p>
<p>Feature prediction diffusion model for video anomaly detection. C Yan, S Zhang, Y Liu, G Pang, W Wang, ICCV. 2023</p>
<p>Stable video diffusion: Scaling latent video diffusion models to large datasets. A Blattmann, T Dockhorn, S Kulal, D Mendelevitch, M Kilian, D Lorenz, Y Levi, Z English, V Voleti, A Letts, V Jampani, R Rombach, 2023</p>
<p>Diversitymeasurable anomaly detection. W Liu, H Chang, B Ma, S Shan, X Chen, CVPR. 2023</p>
<p>Ensemble anomaly score for video anomaly detection using denoise diffusion model and motion filters. Z Wang, X Gu, J Hu, X Gu, Neurocomputing. 5531265892023</p>
<p>Masked diffusion with task-awareness for procedure planning in instructional videos. F Fang, Y Liu, A Koksal, Q Xu, J.-H Lim, 2023</p>
<p>Gd-vdm: Generated depth for better diffusion-based video generation. A Lapid, I Achituve, L Bracha, E Fetaya, 2023</p>
<p>Aadiff: Audio-aligned video synthesis with text-to-image diffusion. S Lee, C Kong, D Jeon, N Kwak, 2023</p>
<p>Diffusion-based normality pre-training for weakly supervised video anomaly detection. S Basak, A Gautam, Expert Syst. Appl. 2511240132024</p>
<p>Denoising diffusion-augmented hybrid video anomaly detection via reconstructing noised frames. K Cheng, Y Pan, Y Liu, X Zeng, R Feng, IJCAI. 22024</p>
<p>Graph-jigsaw conditioned diffusion model for skeleton-based video anomaly detection. A Karami, T K K Ho, N Armanfard, 2024</p>
<p>Vadiffusion: Compressed domain information guided conditional diffusion for video anomaly detection. H Liu, L He, M Zhang, F Li, IEEE Trans. Circuits Syst. Video Technol. 3492024</p>
<p>Unsupervised conditional diffusion models in video anomaly detection for monitoring dust pollution. L Cai, M Li, D Wang, Sensors. 24514642024</p>
<p>Feddiff: Diffusion model driven federated learning for multi-modal and multi-clients. D Li, W Xie, Z Wang, Y Lu, Y Li, L Fang, IEEE Trans. Circuits Syst. Video Technol. 34102024</p>
<p>Unsupervised anomaly detection for multivariate time series using diffusion model. R Hu, X Yuan, Y Qiao, B Zhang, P Zhao, ICASSP. 2024</p>
<p>Drift doesn't matter: Dynamic decomposition with diffusion reconstruction for unstable multivariate time series anomaly detection. C Wang, Z Zhuang, Q Qi, J Wang, X Wang, H Sun, J Liao, NeurIPS. 367742023</p>
<p>Ddmt: Denoising diffusion mask transformer models for multivariate time series anomaly detection. C Yang, T Wang, X Yan, 2023</p>
<p>Imputationbased time-series anomaly detection with conditional weightincremental diffusion models. C Xiao, Z Gou, W Tai, K Zhang, F Zhou, KDD. 2023</p>
<p>Contaminated multivariate timeseries anomaly detection with spatio-temporal graph conditional diffusion models. T K K Ho, N Armanfard, 2024</p>
<p>Netdiffus: Network traffic generation by diffusion models through time-series imaging. N Sivaroopan, D Bandara, C Madarasingha, G Jourjon, A Jayasumana, K Thilakarathna, Computer Networks. 2511106162024</p>
<p>Video anomaly detection with spatio-temporal dissociation. Y Chang, Z Tu, W Xie, B Luo, S Zhang, H Sui, J Yuan, Pattern Recognit. 122108213Feb. 2022</p>
<p>Clustering driven deep autoencoder for video anomaly detection. Y Chang, Z Tu, W Xie, J Yuan, ECCV. 2020</p>
<p>Video anomaly search in crowded scenes via spatio-temporal motion context. Y Cong, J Yuan, Y Tang, IEEE Trans. Inf. Forensics Security. 810Oct. 2013</p>
<p>Sasdim: Self-adaptive noise scaling diffusion model for spatial time series imputation. S Zhang, S Wang, X Tan, R Liu, J Zhang, J Wang, 2023</p>
<p>Timedit: General-purpose diffusion transformers for time series foundation model. D Cao, W Ye, Y Liu, ICMLW2024</p>
<p>Self-supervised learning of time series representation via diffusion process and imputation-interpolation-forecasting mask. Z Senane, L Cao, V L Buchner, Y Tashiro, L You, P A Herman, M Nordahl, R Tu, V Ehrenheim, KDD. Aug. 2024</p>
<p>Diffusion-based time series imputation and forecasting with structured state space models. J M L Alcaraz, N Strodthoff, 2023</p>
<p>Prodiffad: Progressively distilled diffusion models for multivariate time series anomaly detection in jointcloud environment. F Tian, X Shi, L Zhou, L Chen, C Ma, W Zhu, IJCNN. 2024</p>
<p>Reflip-vad: Towards weakly supervised video anomaly detection via vision-language model. P P Dev, R Hazari, P Das, IEEE Trans. Circuits Syst. Video Technol. 2024</p>
<p>Not only look, but also listen: Learning multimodal violence detection under weak supervision. P Wu, J Liu, Y Shi, Y Sun, F Shao, Z Wu, Z Yang, ECCV. 2020</p>
<p>Real-world anomaly detection in surveillance videos. W Sultani, C Chen, M Shah, CVPR. 2018</p>
<p>Weakly-supervised video anomaly detection with robust temporal feature magnitude learning. Y Tian, G Pang, Y Chen, R Singh, J W Verjans, G Carneiro, ICCV. 2021</p>
<p>Learnable locality-sensitive hashing for video anomaly detection. Y Lu, C Cao, Y Zhang, Y Zhang, IEEE Trans. Circuits Syst. Video Technol. 3322023</p>
<p>Boosting variational inference with margin learning for few-shot sceneadaptive anomaly detection. X Huang, Y Hu, X Luo, J Han, B Zhang, X Cao, IEEE Trans. Circuits Syst. Video Technol. 3362023</p>
<p>Unbiased multiple instance learning for weakly supervised video anomaly detection. H Lv, Z Yue, Q Sun, B Luo, Z Cui, H Zhang, CVPR. 2023</p>
<p>Plovad: Prompting visionlanguage models for open vocabulary video anomaly detection. C Xu, K Xu, X Jiang, T Sun, IEEE Trans. Circuits Syst. Video Technol. 2025</p>
<p>Dynamic splitting of diffusion models for multivariate time series anomaly detection in a jointcloud environment. L Chen, X Shi, L Zhou, Y Wang, C Ma, W Zhu, KSEM. 202414886</p>
<p>Finding short signals in long irregular time series with continuoustime attention policy networks. T Hartvigsen, J Thadajarassiri, X Kong, E Rundensteiner, 2023</p>
<p>Structured time series prediction without structural prior. D Drakulic, J.-M Andreoli, 2022</p>
<p>Tranad: Deep transformer networks for anomaly detection in multivariate time series data. S Tuli, G Casale, N R Jennings, Proc. VLDB Endow. VLDB Endow202215</p>
<p>Triformer: Triangular, variable-specific attentions for long sequence multivariate time series forecasting-full version. R.-G Cirstea, C Guo, B Yang, T Kieu, X Dong, S Pan, 2022</p>
<p>Diffusion-based time series data imputation for cloud failure prediction at microsoft 365. F Yang, W Yin, L Wang, T Li, P Zhao, B Liu, P Wang, B Qiao, Y Liu, M Bj Örkman, S Rajmohan, Q Lin, D Zhang, ESEC/FSE. 2023</p>
<p>Robust anomaly detection for multivariate time series through stochastic recurrent neural network. Y Su, Y Zhao, C Niu, R Liu, W Sun, D Pei, KDD. 2019</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. B Zong, Q Song, M R Min, W Cheng, C Lumezanu, D Cho, H Chen, ICLR2018</p>
<p>Prototype-oriented unsupervised anomaly detection for multivariate time series. Y Li, W Chen, B Chen, D Wang, L Tian, M Zhou, ICML. 202319424</p>
<p>Nominality score conditioned time series anomaly detection by point/sequential reconstruction. C.-Y A Lai, F.-K Sun, Z Gao, J H Lang, D Boning, NeurIPS. 366552023</p>
<p>Anomaly transformer: Time series anomaly detection with association discrepancy. J Xu, H Wu, J Wang, M Long, ICLR2021</p>
<p>Sensitivehue: Multivariate time series anomaly detection by enhancing the sensitivity to normal patterns. Y Feng, W Zhang, Y Fu, W Jiang, J Zhu, W Ren, KDD. 2024</p>
<p>Disk: A diffusion model for structured knowledge. O Kitouni, N Nolte, J Hensman, B Mitra, 2023</p>
<p>Tabsyndex: A universal metric for robust evaluation of synthetic tabular data. V S Chundawat, A K Tarun, M Mandal, M Lahoti, P Narang, 2024</p>
<p>Missdiff: Training diffusion models on tabular data with missing values. Y Ouyang, L Xie, C Li, G Cheng, ICMLW2023</p>
<p>Diffimpute: Tabular data imputation with denoising diffusion probabilistic model. Y Wen, Y Wang, K Yi, J Ke, Y Shen, ICME. 2024</p>
<p>Timeautodiff: Combining autoencoder and diffusion model for time series tabular data synthesizing. N Suh, Y Yang, D.-Y Hsieh, Q Luan, S Xu, S Zhu, G Cheng, 2024</p>
<p>Mixed-type tabular data synthesis with score-based diffusion in latent space. H Zhang, J Zhang, Z Shen, B Srinivasan, X Qin, C Faloutsos, H Rangwala, G Karypis, ICLR. 2023</p>
<p>Tabadm: Unsupervised tabular anomaly detection with diffusion models. G Zamberg, M Salhov, O Lindenbaum, A Averbuch, 2023</p>
<p>Energy-based models for anomaly detection: A manifold diffusion recovery approach. S Yoon, Y.-U Jin, Y.-K Noh, F Park, NeurIPS. 364662023</p>
<p>Generative inpainting for shapley-value-based anomaly explanation. J Tritscher, P Lissmann, M Wolf, A Krause, A Hotho, D Schl Ör, Artif. Intell. 2024in Explain</p>
<p>Unsupervised anomaly detection for tabular data using noise evaluation. W Dai, K Hwang, J Fan, AAAI. 2025</p>
<p>Codi: Co-evolving contrastive diffusion models for mixed-type tabular synthesis. C Lee, J Kim, N Park, ICML. 202318956</p>
<p>Self-supervision improves diffusion models for tabular data imputation. Y Liu, T Ajanthan, H Husain, V Nguyen, CIKM. 2024</p>
<p>Findiff: Diffusion models for financial tabular data generation. T Sattarov, M Schreyer, D Borth, ICAIF. 2023</p>
<p>Prototypeoriented hypergraph representation learning for anomaly detection in tabular data. S Li, Y Lu, S Jiu, H Huang, G Yang, J Yu, Inf. Process. Manag. 6211038772025</p>
<p>Retrieval augmented deep anomaly detection for tabular data. H Thimonier, F Popineau, A Rimmel, B.-L Doan, CIKM. 2024</p>
<p>Neural transformation learning for deep anomaly detection beyond images. C Qiu, T Pfrommer, M Kloft, S Mandt, M Rudolph, ICML. 2021</p>
<p>Anomaly detection for tabular data with internal contrastive learning. T Shenkar, L Wolf, ICLR2021</p>
<p>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. Z Li, Y Zhao, X Hu, N Botta, C Ionescu, G H Chen, IEEE Trans. Knowl. Data Eng. 35122023</p>
<p>Perturbation learning based anomaly detection. J Cai, J Fan, NeurIPS. 352022</p>
<p>D-pad: Deep-shallow multi-frequency patterns disentangling for time series forecasting. X Yuan, L Chen, 2024</p>
<p>Autouad: Hyper-parameter optimization for unsupervised anomaly detection. W Dai, J Fan, ICLR. 2024</p>
<p>Anomalysd: Few-shot multiclass anomaly detection with stable diffusion model. Z Yan, Q Fang, W Lv, Q Su, 2024</p>
<p>Multimodal industrial anomaly detection by crossmodal feature mapping. A Costanzino, P Z Ramirez, G Lisanti, L Di Stefano, CVPR. 202417243</p>
<p>Robust multi-modal sensor fusion: An adversarial approach. S Roheda, H Krim, B S Riggan, IEEE Sensors J. 2122021</p>
<p>Provable dynamic fusion for low-quality multimodal data. Q Zhang, H Wu, C Zhang, Q Hu, H Fu, J T Zhou, X Peng, ICML. 2023202769</p>
<p>Anomalyxfusion: Multi-modal anomaly synthesis with diffusion. J Hu, Y Huang, Y Lu, G Xie, G Jiang, Y Zheng, Z Lu, 2024</p>
<p>Improving vision anomaly detection with the guidance of language modality. D Chen, K Pan, G Dai, G Wang, Y Zhuang, S Tang, M Xu, IEEE Trans. Multimedia. 272025</p>
<p>Interpretation on multi-modal visual fusion. H Chen, H Zhou, Y Deng, 2023</p>
<p>Deep structured cross-modal anomaly detection. Y Li, N Liu, J Li, M Du, X Hu, IJCNN. 2019</p>
<p>Diad: A diffusion-based framework for multi-class anomaly detection. H He, J Zhang, H Chen, X Chen, Z Li, X Chen, Y Wang, C Wang, L Xie, 2023</p>
<p>Counterfactual condition diffusion with continuous prior adaptive correction for anomaly detection in multimodal brain mri. X Chen, Y Peng, Expert Syst. Appl. 2541242952024</p>
<p>Collaborative diffusion for multi-modal face generation and editing. Z Huang, K C K Chan, Y Jiang, Z Liu, CVPR. 2023</p>
<p>Exploiting multimodal latent diffusion models for accurate anomaly detection in industry 5.0. L Capogrosso, A Vivenza, A Chiarini, F Setti, M Cristani, Ital-IA. 37622024</p>
<p>Multimodal motion conditioned diffusion model for skeleton-based video anomaly detection. A Flaborea, L Collorone, G M D'amely Di Melendugno, S D'arrigo, B Prenkaj, F Galasso, ICCV. 202310295</p>
<p>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. Y Li, H Wang, S Yuan, M Liu, D Zhao, Y Guo, C Xu, G Shi, W Zuo, 2025</p>
<p>Neuro-symbolic empowered denoising diffusion probabilistic models for real-time anomaly detection in industry 4.0: Wild-and-crazy-idea paper. L Capogrosso, A Mascolini, F Girella, G Skenderi, S Gaiardelli, N Dall'ora, F Ponzio, E Fraccaroli, S Di Cataldo, S Vinco, E Macii, F Fummi, M Cristani, FDL2023</p>
<p>Cut: A controllable, universal, and training-free visual anomaly generation framework. H Sun, Y Cao, O Fink, 2024</p>
<p>A generalized surface loss for reducing the hausdorff distance in medical imaging segmentation. A Celaya, B Riviere, D Fuentes, 2024</p>
<p>Self-supervised enhanced denoising diffusion for anomaly detection. S Li, J Yu, Y Lu, G Yang, X Du, S Liu, Inf. Sci. 6691206122024</p>
<p>A novel approach to industrial defect generation through blended latent diffusion model with online adaptation. H Li, Z Zhang, H Chen, L Wu, B Li, D Liu, M Wang, 2024</p>
<p>Cutpaste: Self-supervised learning for anomaly detection and localization. C.-L Li, K Sohn, J Yoon, T Pfister, CVPR. 2021</p>
<p>Humanrefiner: Benchmarking abnormal human generation and refining with coarse-to-fine pose-reversible guidance. G Fang, W Yan, Y Guo, J Han, Z Jiang, H Xu, S Liao, X Liang, ECCV. 2024</p>
<p>Video anomaly detection via spatiotemporal pseudo-anomaly generation : A unified approach. A K Rai, T Krishna, F Hu, A Drimbarean, K Mcguinness, A F Smeaton, N E O'connor, CVPR. 2024</p>
<p>Natural synthetic anomalies for self-supervised anomaly detection and localization. H M Schl Üter, J Tan, B Hou, B Kainz, ECCV. 2022</p>
<p>Prototypical residual networks for anomaly detection and localization. H Zhang, Z Wu, Z Wang, Z Chen, Y.-G Jiang, CVPR. 202316291</p>
<p>Defect-gan: High-fidelity defect synthesis for automated defect inspection. G Zhang, K Cui, T.-Y Hung, S Lu, 2021WACV</p>
<p>Few-shot defect image generation via defect-aware feature manipulation. Y Duan, Y Hong, L Niu, L Zhang, AAAI. 3712023</p>
<p>Realnet: A feature selection network with realistic synthetic anomaly for anomaly detection. X Zhang, M Xu, X Zhou, CVPR. 202416708</p>
<p>Defect image sample generation with gan for improving defect recognition. S Niu, B Li, X Wang, H Lin, IEEE Trans. Autom. Sci. Eng. 1732020</p>
<p>Differentiable augmentation for data-efficient gan training. S Zhao, Z Liu, J Lin, J.-Y Zhu, S Han, NeurIPS. 332020</p>
<p>Few-shot defect segmentation leveraging abundant defect-free training samples through normal background regularization and crop-and-paste operation. D Lin, Y Cao, W Zhu, Y Li, ICME. 2021</p>
<p>Few-shot image generation via cross-domain correspondence. U Ojha, Y Li, J Lu, A A Efros, Y J Lee, E Shechtman, R Zhang, CVPR. 202110752</p>
<p>Towards a guideline for evaluation metrics in medical image segmentation. D Üller, I Soto-Rey, F Kramer, BMC Res. Notes. 1512102022</p>
<p>The impact of using voxel-level segmentation metrics on evaluating multifocal prostate cancer localisation. W Yan, Q Yang, T Syer, Z Min, S Punwani, M Emberton, D Barratt, B Chiu, Y Hu, Appl. Med. Artif. Intell. 2022</p>
<p>Anodode: Anomaly detection with diffusion ode. X Hu, C Jin, 2023</p>
<p>Surface anomaly detection and localization with diffusion-based reconstruction. X Sheng, S Tuo, L Wang, IJCNN. 2024</p>
<p>Diffusionad: Normguided one-step denoising diffusion for anomaly detection. H Zhang, Z Wang, Z Wu, Y.-G Jiang, 2023</p>
<p>U-flow: A u-shaped normalizing flow for anomaly detection with unsupervised threshold. M Tailanian, Á Pardo, P Musé, J. Math. Imaging Vis. 6642024</p>
<p>Clustering aided weakly supervised training to detect anomalous events in surveillance videos. M Z Zaheer, A Mahmood, M Astrid, S.-I Lee, Neural Netw. 35102024</p>
<p>Navigating the metric maze: A taxonomy of evaluation metrics for anomaly detection in time series. S Sørbø, M Ruocco, Data Min. Knowl. Discov. 3832024</p>
<p>Unsupervised model selection for time-series anomaly detection. M Goswami, C Challu, L Callot, L Minorics, A Kan, 2023</p>
<p>Developing an unsupervised real-time anomaly detection scheme for time series with multi-seasonality. W Wu, L He, W Lin, Y Su, Y Cui, C Maple, S Jarvis, IEEE Trans. Knowl. Data Eng. 3492022</p>
<p>A comparative study on unsupervised anomaly detection for time series: Experiments and analysis. Y Zhao, L Deng, X Chen, C Guo, B Yang, T Kieu, F Huang, T B Pedersen, K Zheng, C S Jensen, 2022</p>
<p>Reconstruct anomaly to normal: Adversarial learned and latent vector-constrained autoencoder for time-series anomaly detection. C Zhang, W Zuo, X Wang, 2020</p>
<p>Difftad: Denoising diffusion probabilistic models for vehicle trajectory anomaly detection. C Li, G Feng, Y Li, R Liu, Q Miao, L Chang, Knowl. Based Syst. 2861113872024</p>
<p>Msaf: Multimodal supervise-attention enhanced fusion for video anomaly detection. D Wei, Y Liu, X Zhu, J Liu, X Zeng, IEEE Signal Process. Lett. 292022</p>
<p>Neural dependency coding inspired multimodal fusion. S Shankar, 2021</p>
<p>An intermediate fusion vit enables efficient text-image alignment in diffusion models. Z Hu, S Jia, M Rostami, 2024</p>
<p>High-modality multimodal transformer: Quantifying modality &amp; interaction heterogeneity for high-modality representation learning. P P Liang, Y Lyu, X Fan, J Tsaw, Y Liu, S Mo, D Yogatama, L.-P Morency, R Salakhutdinov, 2023</p>
<p>Multimodal sentiment analysis with missing modality: A knowledge-transfer approach. W Liu, H Zhan, H Chen, F Lv, 2025</p>
<p>The brain tumor segmentation (brats) challenge 2023: Focus on pediatrics (cbtn-connect-dipgrasnr-miccai brats-peds). A F Kazerooni, N Khalili, X Liu, D Haldar, Z Jiang, A Resnick, S Bakas, M G Linguraru, 2024</p>
<p>The mvtec 3d-ad dataset for unsupervised 3d anomaly detection and localization. P Bergmann, X Jin, D Sattlegger, C Steger, VISAPP. 2022</p>
<p>Deep learning-based defect detection of metal parts: Evaluating current methods in complex conditions. S Jezek, M Jonak, R Burget, P Dvorak, M Skotak, ICUMT. 2021</p>
<p>Vtadl: A vision transformer network for image anomaly detection and localization. P Mishra, R Verk, D Fornasier, C Piciarelli, G L Foresti, ISIE. 2021</p>
<p>Mixed supervision for surface-defect detection: From weakly to fully supervised learning. J Božič, D Tabernik, D Skočaj, Comput. Ind. 1291034592021</p>
<p>Beyond dents and scratches: Logical constraints in unsupervised anomaly detection and localization. P Bergmann, K Batzner, M Fauser, D Sattlegger, C Steger, Int. J. Comput. Vis. 13042022</p>
<p>A dataset to support research in the design of secure water treatment systems. J Goh, S Adepu, K N Junejo, A Mathur, in Crit. Inf. Infrastruct. Secur. 2017</p>
<p>Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. K Hundman, V Constantinou, C Laporte, I Colwell, T Soderstrom, KDD. 2018</p>
<p>Anomaly detection in crowded scenes. V Mahadevan, W Li, V Bhalodia, N Vasconcelos, CVPR. 2010</p>
<p>Abnormal event detection at 150 fps in matlab. C Lu, J Shi, J Jia, ICCV. 2013</p>
<p>Single-image crowd counting via multi-column convolutional neural network. Y Zhang, D Zhou, S Chen, S Gao, Y Ma, CVPR. 2016</p>
<p>Cross-task weakly supervised learning from instructional videos. D Zhukov, J.-B Alayrac, R G Cinbis, D Fouhey, I Laptev, J Sivic, CVPR. 2019</p>
<p>Coin: A large-scale dataset for comprehensive instructional video analysis. Y Tang, D Ding, Y Rao, Y Zheng, D Zhang, L Zhao, J Lu, J Zhou, CVPR. 2019</p>
<p>Ubnormal: New benchmark for supervised open-set video anomaly detection. A Acsintoae, A Florescu, M.-I Georgescu, T Mare, P Sumedrea, R T Ionescu, F S Khan, M Shah, CVPR. 202220153</p>
<p>Fault Detection and Diagnosis in Industrial Systems. L H Chiang, E L Russell, R D Braatz, 2000</p>
<p>An extensive reference dataset for fault detection and identification in batch processes. J Van Impe, G Gins, Chemometr. Intell. Lab. Syst. 1482015</p>
<p>Adbench: Anomaly detection benchmark. S Han, X Hu, H Huang, M Jiang, Y Zhao, NeurIPS. 352022</p>
<p>A new comprehensive benchmark for semi-supervised video anomaly detection and anticipation. C Cao, Y Lu, P Wang, Y Zhang, CVPR. 202320401</p>
<p>Scene-dependent prediction in latent space for video anomaly detection and anticipation. C Cao, H Zhang, Y Lu, P Wang, Y Zhang, IEEE Trans. Pattern Anal. Mach. Intell. 4712025</p>
<p>Speed is all you need: On-device acceleration of large diffusion models via gpu-aware optimizations. Y.-H Chen, R Sarokin, J Lee, J Tang, C.-L Chang, A Kulik, M Grundmann, CVPR. 2023</p>
<p>Latent diffusion counterfactual explanations. K Farid, S Schrodi, M Argus, T Brox, 2023</p>
<p>Cognitively inspired cross-modal data generation using diffusion models. Z Hu, M Rostami, 2023</p>
<p>Llms understand glass-box models, discover surprises, and suggest repairs. B J Lengerich, S Bordt, H Nori, M E Nunnally, Y Aphinyanaphongs, M Kellis, R Caruana, 2023</p>
<p>Explore the potential of llms in misinformation detection: An empirical study. M Chen, L Wei, H Cao, W Zhou, S Hu, 2024</p>
<p>Hybrid reasoning based on large language models for autonomous car driving. M Azarafza, M Nayyeri, C Steinmetz, S Staab, A Rettberg, ICCMA. 2024</p>
<p>Large language models for spatial trajectory patterns mining. Z Zhang, H Amiri, Z Liu, L Zhao, A Zuefle, ACM SIGSPATIALW. 2024</p>
<p>Stochastic parrots looking for stochastic parrots: Llms are easy to fine-tune and hard to detect with other llms. D S G Henrique, A Kucharavy, R Guerraoui, 2023</p>
<p>Large language models are zero shot hypothesis proposers. B Qi, K Zhang, H Li, K Tian, S Zeng, Z.-R Chen, B Zhou, 2023</p>
<p>Quantifying association capabilities of large language models and its implications on privacy leakage. H Shao, J Huang, S Zheng, K C , -C Chang, 2024</p>
<p>Exploring autonomous agents through the lens of large language models: A review. S Barua, 2024</p>            </div>
        </div>

    </div>
</body>
</html>