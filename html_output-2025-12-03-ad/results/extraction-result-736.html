<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-736 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-736</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-736</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-271601153</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2408.00399v1.pdf" target="_blank">Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures</a></p>
                <p><strong>Paper Abstract:</strong> A fundamental task in science is to determine the underlying causal relations because it is the knowledge of this functional structure what leads to the correct interpretation of an effect given the apparent associations in the observed data. In this sense, Causal Discovery is a technique that tackles this challenge by analyzing the statistical properties of the constituent variables. In this work, we target the generalizability of the discovery method by following a reductionist approach that only involves two variables, i.e., the pairwise or bi-variate setting. We question the current (possibly misleading) baseline results on the basis that they were obtained through supervised learning, which is arguably contrary to this genuinely exploratory endeavor. In consequence, we approach this problem in an unsupervised way, using robust Mutual Information measures, and observing the impact of the different variable types, which is oftentimes ignored in the design of solutions. Thus, we provide a novel set of standard unbiased results that can serve as a reference to guide future discovery tasks in completely unknown environments.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e736.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e736.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RESFIT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REgression with Subsequent Flexible Independence Test</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper's proposed unsupervised pairwise causal discovery algorithm that applies a regression-residual independence test (RESIT) but selects the unconditional independence test (e.g., TIC or Pearson's χ2) adaptively based on variable types; intended to operate on heterogeneous (discrete/continuous/mixed) data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RESFIT</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>RESFIT is a bivariate causal discovery pipeline that fits linear additive functional causal models in both directions, computes regression residuals, then applies an unconditional independence test between residual and putative cause. The novelty is a flexible selector (SelectUIT) that chooses the independence test (e.g., TIC or Pearson's χ2) driven by observed joint variable types (categorical, binary, numerical, mixed) and empirical performance; decision rules on p-values (confidence interval threshold) determine Causal / Anticausal / Independent / Confounded labels.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Benchmark dataset of ~6000 artificially generated cause-effect pairs with mixed variable types (numerical, categorical, binary), balanced numbers of unique values and median instance length ≈2000; synthetic (non-interactive) evaluation environment, not an open-ended or active experimentation platform.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection of confounding/spurious associations via regression-residual unconditional independence testing (MI-based measures or χ2); selection of the independence test based on variable types to improve robustness to spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Latent confounding (unobserved common cause) and irrelevant/heterogeneous variable-type-induced spurious associations; general measurement or sampling noise implicitly addressed via statistical tests.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Tests independence between regression residual (estimated noise) and hypothetical cause using Mutual Information-based measures (TIC) or Pearson's χ2 on discretized residuals; non-zero dependence (p-value below threshold) signals violation of causal hypothesis or latent confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Statistical hypothesis testing (p-value thresholds on residual-vs-cause independence) to reject causal direction hypotheses; MI / TIC used to flag dependence indicative of confounding and thus refute the simple cause→effect hypothesis.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Flexible test-selection (treated as intervention X=1) yields estimated potential outcome E[Y1]=0.3866 ± 0.0690 accuracy (aggregate weighted by data-type balance) on the ChaLearn SUP2 benchmark (unsupervised setting reported in paper). TIC vs χ2 per data type reported in Table 2 (see paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Reference potential outcome with no 'smart' selection E[Y0]=0.3531 ± 0.0357 (random/null test choice); supervised baseline reported in literature ~65% (not achieved by the unsupervised RESFIT).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Introducing flexibility in choosing the unconditional independence test yields a statistically significant average causal effect (ACE) of ≈3.36% in accuracy vs a null selection strategy, but absolute unsupervised accuracies remain far below supervised baselines; RESFIT leverages residual-vs-cause independence tests to detect latent confounding and heterogeneous-variable-induced spurious signals, but no explicit downweighting or intervention-based refutation beyond hypothesis testing is implemented. Paper reports counterintuitive per-type performance of TIC vs χ2, attributing some limitations to sample size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e736.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RESIT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REgression with Subsequent Independence Test (RESIT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A regression-based pairwise causal discovery framework that fits functional causal models in both directions and uses an independence test between residuals and putative cause to infer causal direction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RESIT</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>RESIT fits a model Y = f(X)+ε for both hypothesized directions, computes residuals ε̂, and applies an independence test between ε̂ and the putative cause; the direction for which the residual is independent of the cause is selected as the causal orientation (under the additive noise model assumptions). In this paper RESIT is used as an internal function and extended by flexible choice of the independence test.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic benchmark of paired variables with mixed types used to evaluate pairwise causal discovery; not interactive or active.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects latent confounding/spurious associations by testing dependence between residuals and putative cause; a non-independent residual indicates model violation or confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Latent confounding (unobserved common causes), model-misspecification signals, sampling/noise-induced spurious dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Independence test (e.g., MI/TIC/χ2) applied to regression residuals vs hypothetical cause; dependence signals spurious/confounded relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Hypothesis testing: p-value based rejection of independence to refute a causal direction; if both directions show dependence, confounding or model violation is suspected.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When paired with flexible test selection in RESFIT, RESIT-based pipeline yields E[Y1]=0.3866 ± 0.0690 (paper's aggregate reported outcome for flexible strategy).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>With null/random independence-test selection the reference outcome is E[Y0]=0.3531 ± 0.0357.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>RESIT framework provides a direct mechanism to detect spurious/confounded associations through residual independence tests; the paper's main contribution is showing that selecting the independence test adaptively by variable type improves robustness modestly, but no explicit mechanism for downweighting distractors is implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e736.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mutual Information (MI)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mutual Information</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-theoretic measure of statistical dependence between two variables used here to quantify dependence between regression residuals and hypothetical causes and to detect confounding or violations of the additive noise model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Mutual Information (residual vs cause)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>MI(RR,HC) is computed between regression residual (RR) and hypothetical cause (HC) as a general dependence measure; low MI indicates independence (supporting causal direction), non-zero MI indicates dependence which may flag the wrong causal orientation or latent confounding. MI is also used as the basis for TIC.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic mixed-type pairs dataset used for evaluation; MI applied to residual-vs-cause pairs computed from sample instances (discretized or gridded for estimation).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection of latent confounding via measuring dependence between residuals and putative cause; if MI significantly > 0 the causal hypothesis is violated or confounding is present.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Latent confounding, model-misspecification signals, dependencies arising from spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Estimate MI (via discretization or gridding) and compare to null (e.g., via χ2 relationship or TIC regularized MI); distributions of MI values used to separate causal vs independent vs confounded structures.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Use of MI magnitude and corresponding statistical test (χ2 relation or TIC) to reject independence hypothesis and thus refute the claimed causal orientation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>MI-based criteria (and TIC derived from MI) reliably separate causal orientation from alternatives in simulated experiments presented in the paper; no single scalar global performance outside RESFIT reported beyond the numeric accuracy summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MI between residual and candidate cause is an effective indicator of causal orientation and also flags latent confounding; MI-based statistics underpin the paper's robustness claims, though estimation and sample-size issues limit practical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e736.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TIC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Total Information Coefficient</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Mutual Information-based robust independence test for real-valued variables that searches over griddings to capture diverse associations and provides equitability and generality properties; used as an independence test option in RESFIT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Total Information Coefficient (TIC)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>TIC searches for optimal discrete grids G that partition the joint distribution of two variables and sums regularized MI contributions over those grids: TIC(RR,HC)=Σ_G MI((RR,HC)|G) / log ||G|| (as presented in the paper's formulation). It is heuristic, aims for equitability, and is stronger against independence for continuous variables compared to uniform-grid χ2.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to residual-vs-cause pairs drawn from synthetic benchmark; TIC's gridding is used on continuous or discretized data within the RESFIT pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Improved detection of non-linear or complex dependence (including dependence due to confounding) via optimal gridding and MI aggregation, making the test more robust to spurious signal types that are non-linear or heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Non-linear dependencies, model violations, latent confounding, and other complex associations that uniform-grid tests might miss.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Search over optimal grids and compute regularized MI sums; significant TIC score indicates dependence and therefore potential spurious/confounded relationship.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Use TIC scores/p-values (via permutation or analytic calibration in practice) to reject independence; in RESFIT, a low p-value on TIC refutes independence and thus the causal hypothesis is rejected.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Per Table 2, TIC produced varied results by data type (e.g., categorical: 0.3500 ± 0.1329, binary: 0.5336 ± 0.1375, numerical: 0.3683 ± 0.0211, mixed: 0.2456 ± 0.0219, total: 0.3211 ± 0.0136). TIC yielded slightly smaller variance in scores per the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Compared to Pearson's χ2 in Table 2, TIC performed better for some data types (categorical, binary) and worse for others (numerical, mixed), leading to the proposal of test-selection; no single baseline performance isolated solely as non-robust TIC in the paper beyond these comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>TIC is a robust MI-derived independence test that can capture a wide range of dependencies and helps detect confounding-like signals, but empirical results showed counterintuitive performance across variable types (e.g., TIC performed unexpectedly well on discrete data), likely influenced by sample-size and discretization issues.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e736.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pearson's χ2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pearson's Chi-squared Test</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical contingency-table test for independence used here as an unconditional independence test between discretized regression residuals and putative causes within the RESFIT pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Pearson's χ2 (on discretized residual vs cause)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Discretize real-valued variables (uniform grid) to build contingency table of residual vs hypothetical cause, compute χ2 statistic Σ (O_i − E_i)^2 / E_i and evaluate p-value to accept/reject independence; used as one of two primary unconditional independence tests in the flexible selection scheme.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to discretized residual-vs-cause data from synthetic benchmark; uses uniform gridding (e.g., 10 bins in illustrative example) prior to testing.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection of dependence (including dependence from confounding) via χ2 contingency testing after discretization; a significant χ2 rejects independence and indicates possible spurious/confounded relation.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding, discretization-induced artifacts, non-zero dependence from noise or sampling variability.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Uniform-grid discretization of continuous variables, computation of contingency table, χ2 statistic and p-value; low p-value signals dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>p-value thresholding: if χ2 p < ci (e.g., 0.05) independence is rejected, refuting the causal hypothesis for that direction; both directions tested to detect unique combination identifying true structure or confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Per Table 2, Pearson's χ2 produced the following accuracies: categorical 0.2867 ± 0.1612, binary 0.5027 ± 0.1854, numerical 0.4300 ± 0.0260, mixed 0.3215 ± 0.0392, total 0.3850 ± 0.0181. χ2 had higher mean accuracy than TIC on the paper's total aggregate.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>See comparative numbers for TIC above; χ2 sometimes outperformed TIC depending on data type, motivating RESFIT's flexible selection.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>χ2 on uniform discretization is a viable unconditional independence test in RESFIT and, counterintuitively, sometimes outperformed TIC on numerical data in the experiments; this suggests practical limitations from sample size and discretization decisions rather than theory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e736.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Linear Additive Noise FCM (Linear FCM / LiNGAM assumptions)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Linear Additive Noise Functional Causal Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The causal model class used: the effect is modeled as a linear function of the cause plus an additive noise term independent of the cause (Y = bX + ε), with identifiability when at most one of X and ε is Gaussian.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Linear additive noise FCM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Assume Y = bX + ε and estimate linear regression for both directions; exploit asymmetry that in true direction the noise ε is independent of the cause, while reversed direction typically yields dependent residuals; identifiability holds under non-Gaussian noise assumptions (LiNGAM-like conditions).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to synthetic pairs in which model assumptions may or may not hold; regression residuals are tested for independence to decide orientation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Indirect: residual independence test can reveal violations due to confounders or spurious associations but model itself does not explicitly model distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Latent confounding and violations of functional form (model misspecification) that show as residual dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Residual independence testing (MI/TIC/χ2) after fitting linear regression; dependence indicates model violation or confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Reject a causal orientation if residual is dependent on putative cause; if both directions show dependence, suspect confounding or model violation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Performance depends on noise Gaussianity and sample size; paper reports aggregate unsupervised accuracies (see RESFIT/TIC/χ2 numbers) when using linear FCM assumption.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Linear FCMs are used as the modelling backbone for pairwise orientation; residual independence approach can both identify direction and signal latent confounding, but identifiability degrades when variables/noise approach Gaussianity and with limited sample size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e736.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e736.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChaLearn SUP2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Reference benchmark dataset of artificially generated cause-effect pairs with mixed variable types used to evaluate pairwise causal discovery methods in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2) dataset</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A curated dataset containing ~6000 generated pairs spanning numerical, categorical and binary variable pairs with balanced numbers of unique values and median instance length ≈2000; used as evaluation environment to compare independence tests and the RESFIT pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ChaLearn cause-effect pair (SUP2)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Synthetic, non-interactive benchmark environment; not a virtual lab or active experiment platform—provides observational pairs only.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Contains generated confounded/independent/causal relationships as part of the benchmark (used to test methods' ability to detect confounding and spurious associations).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Used as the primary evaluation environment; results on this benchmark show that flexible independence-test selection improves unsupervised accuracy modestly, and reveal unexpected interactions between test choice and variable types.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Elements of Causal Inference <em>(Rating: 2)</em></li>
                <li>Detecting Novel Associations in Large Data Sets <em>(Rating: 2)</em></li>
                <li>Measuring Dependence Powerfully and Equitably <em>(Rating: 2)</em></li>
                <li>A kernel statistical test of independence <em>(Rating: 2)</em></li>
                <li>Challenge: Cause-effect pairs <em>(Rating: 2)</em></li>
                <li>Distinguishing cause from effect using observational data: methods and benchmarks <em>(Rating: 2)</em></li>
                <li>A linear non-Gaussian acyclic model for causal discovery <em>(Rating: 2)</em></li>
                <li>Inferring causation from time series in Earth system sciences <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-736",
    "paper_id": "paper-271601153",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "RESFIT",
            "name_full": "REgression with Subsequent Flexible Independence Test",
            "brief_description": "The paper's proposed unsupervised pairwise causal discovery algorithm that applies a regression-residual independence test (RESIT) but selects the unconditional independence test (e.g., TIC or Pearson's χ2) adaptively based on variable types; intended to operate on heterogeneous (discrete/continuous/mixed) data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "RESFIT",
            "method_description": "RESFIT is a bivariate causal discovery pipeline that fits linear additive functional causal models in both directions, computes regression residuals, then applies an unconditional independence test between residual and putative cause. The novelty is a flexible selector (SelectUIT) that chooses the independence test (e.g., TIC or Pearson's χ2) driven by observed joint variable types (categorical, binary, numerical, mixed) and empirical performance; decision rules on p-values (confidence interval threshold) determine Causal / Anticausal / Independent / Confounded labels.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Benchmark dataset of ~6000 artificially generated cause-effect pairs with mixed variable types (numerical, categorical, binary), balanced numbers of unique values and median instance length ≈2000; synthetic (non-interactive) evaluation environment, not an open-ended or active experimentation platform.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection of confounding/spurious associations via regression-residual unconditional independence testing (MI-based measures or χ2); selection of the independence test based on variable types to improve robustness to spurious signals.",
            "spurious_signal_types": "Latent confounding (unobserved common cause) and irrelevant/heterogeneous variable-type-induced spurious associations; general measurement or sampling noise implicitly addressed via statistical tests.",
            "detection_method": "Tests independence between regression residual (estimated noise) and hypothetical cause using Mutual Information-based measures (TIC) or Pearson's χ2 on discretized residuals; non-zero dependence (p-value below threshold) signals violation of causal hypothesis or latent confounding.",
            "downweighting_method": null,
            "refutation_method": "Statistical hypothesis testing (p-value thresholds on residual-vs-cause independence) to reject causal direction hypotheses; MI / TIC used to flag dependence indicative of confounding and thus refute the simple cause→effect hypothesis.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Flexible test-selection (treated as intervention X=1) yields estimated potential outcome E[Y1]=0.3866 ± 0.0690 accuracy (aggregate weighted by data-type balance) on the ChaLearn SUP2 benchmark (unsupervised setting reported in paper). TIC vs χ2 per data type reported in Table 2 (see paper).",
            "performance_without_robustness": "Reference potential outcome with no 'smart' selection E[Y0]=0.3531 ± 0.0357 (random/null test choice); supervised baseline reported in literature ~65% (not achieved by the unsupervised RESFIT).",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Introducing flexibility in choosing the unconditional independence test yields a statistically significant average causal effect (ACE) of ≈3.36% in accuracy vs a null selection strategy, but absolute unsupervised accuracies remain far below supervised baselines; RESFIT leverages residual-vs-cause independence tests to detect latent confounding and heterogeneous-variable-induced spurious signals, but no explicit downweighting or intervention-based refutation beyond hypothesis testing is implemented. Paper reports counterintuitive per-type performance of TIC vs χ2, attributing some limitations to sample size.",
            "uuid": "e736.0",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "RESIT",
            "name_full": "REgression with Subsequent Independence Test (RESIT)",
            "brief_description": "A regression-based pairwise causal discovery framework that fits functional causal models in both directions and uses an independence test between residuals and putative cause to infer causal direction.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "RESIT",
            "method_description": "RESIT fits a model Y = f(X)+ε for both hypothesized directions, computes residuals ε̂, and applies an independence test between ε̂ and the putative cause; the direction for which the residual is independent of the cause is selected as the causal orientation (under the additive noise model assumptions). In this paper RESIT is used as an internal function and extended by flexible choice of the independence test.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Synthetic benchmark of paired variables with mixed types used to evaluate pairwise causal discovery; not interactive or active.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects latent confounding/spurious associations by testing dependence between residuals and putative cause; a non-independent residual indicates model violation or confounding.",
            "spurious_signal_types": "Latent confounding (unobserved common causes), model-misspecification signals, sampling/noise-induced spurious dependence.",
            "detection_method": "Independence test (e.g., MI/TIC/χ2) applied to regression residuals vs hypothetical cause; dependence signals spurious/confounded relationships.",
            "downweighting_method": null,
            "refutation_method": "Hypothesis testing: p-value based rejection of independence to refute a causal direction; if both directions show dependence, confounding or model violation is suspected.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "When paired with flexible test selection in RESFIT, RESIT-based pipeline yields E[Y1]=0.3866 ± 0.0690 (paper's aggregate reported outcome for flexible strategy).",
            "performance_without_robustness": "With null/random independence-test selection the reference outcome is E[Y0]=0.3531 ± 0.0357.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "RESIT framework provides a direct mechanism to detect spurious/confounded associations through residual independence tests; the paper's main contribution is showing that selecting the independence test adaptively by variable type improves robustness modestly, but no explicit mechanism for downweighting distractors is implemented.",
            "uuid": "e736.1",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Mutual Information (MI)",
            "name_full": "Mutual Information",
            "brief_description": "An information-theoretic measure of statistical dependence between two variables used here to quantify dependence between regression residuals and hypothetical causes and to detect confounding or violations of the additive noise model.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Mutual Information (residual vs cause)",
            "method_description": "MI(RR,HC) is computed between regression residual (RR) and hypothetical cause (HC) as a general dependence measure; low MI indicates independence (supporting causal direction), non-zero MI indicates dependence which may flag the wrong causal orientation or latent confounding. MI is also used as the basis for TIC.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Synthetic mixed-type pairs dataset used for evaluation; MI applied to residual-vs-cause pairs computed from sample instances (discretized or gridded for estimation).",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection of latent confounding via measuring dependence between residuals and putative cause; if MI significantly &gt; 0 the causal hypothesis is violated or confounding is present.",
            "spurious_signal_types": "Latent confounding, model-misspecification signals, dependencies arising from spurious associations.",
            "detection_method": "Estimate MI (via discretization or gridding) and compare to null (e.g., via χ2 relationship or TIC regularized MI); distributions of MI values used to separate causal vs independent vs confounded structures.",
            "downweighting_method": null,
            "refutation_method": "Use of MI magnitude and corresponding statistical test (χ2 relation or TIC) to reject independence hypothesis and thus refute the claimed causal orientation.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "MI-based criteria (and TIC derived from MI) reliably separate causal orientation from alternatives in simulated experiments presented in the paper; no single scalar global performance outside RESFIT reported beyond the numeric accuracy summaries.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "MI between residual and candidate cause is an effective indicator of causal orientation and also flags latent confounding; MI-based statistics underpin the paper's robustness claims, though estimation and sample-size issues limit practical performance.",
            "uuid": "e736.2",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "TIC",
            "name_full": "Total Information Coefficient",
            "brief_description": "A Mutual Information-based robust independence test for real-valued variables that searches over griddings to capture diverse associations and provides equitability and generality properties; used as an independence test option in RESFIT.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Total Information Coefficient (TIC)",
            "method_description": "TIC searches for optimal discrete grids G that partition the joint distribution of two variables and sums regularized MI contributions over those grids: TIC(RR,HC)=Σ_G MI((RR,HC)|G) / log ||G|| (as presented in the paper's formulation). It is heuristic, aims for equitability, and is stronger against independence for continuous variables compared to uniform-grid χ2.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Applied to residual-vs-cause pairs drawn from synthetic benchmark; TIC's gridding is used on continuous or discretized data within the RESFIT pipeline.",
            "handles_distractors": true,
            "distractor_handling_technique": "Improved detection of non-linear or complex dependence (including dependence due to confounding) via optimal gridding and MI aggregation, making the test more robust to spurious signal types that are non-linear or heterogeneous.",
            "spurious_signal_types": "Non-linear dependencies, model violations, latent confounding, and other complex associations that uniform-grid tests might miss.",
            "detection_method": "Search over optimal grids and compute regularized MI sums; significant TIC score indicates dependence and therefore potential spurious/confounded relationship.",
            "downweighting_method": null,
            "refutation_method": "Use TIC scores/p-values (via permutation or analytic calibration in practice) to reject independence; in RESFIT, a low p-value on TIC refutes independence and thus the causal hypothesis is rejected.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Per Table 2, TIC produced varied results by data type (e.g., categorical: 0.3500 ± 0.1329, binary: 0.5336 ± 0.1375, numerical: 0.3683 ± 0.0211, mixed: 0.2456 ± 0.0219, total: 0.3211 ± 0.0136). TIC yielded slightly smaller variance in scores per the paper.",
            "performance_without_robustness": "Compared to Pearson's χ2 in Table 2, TIC performed better for some data types (categorical, binary) and worse for others (numerical, mixed), leading to the proposal of test-selection; no single baseline performance isolated solely as non-robust TIC in the paper beyond these comparisons.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "TIC is a robust MI-derived independence test that can capture a wide range of dependencies and helps detect confounding-like signals, but empirical results showed counterintuitive performance across variable types (e.g., TIC performed unexpectedly well on discrete data), likely influenced by sample-size and discretization issues.",
            "uuid": "e736.3",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Pearson's χ2",
            "name_full": "Pearson's Chi-squared Test",
            "brief_description": "A classical contingency-table test for independence used here as an unconditional independence test between discretized regression residuals and putative causes within the RESFIT pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Pearson's χ2 (on discretized residual vs cause)",
            "method_description": "Discretize real-valued variables (uniform grid) to build contingency table of residual vs hypothetical cause, compute χ2 statistic Σ (O_i − E_i)^2 / E_i and evaluate p-value to accept/reject independence; used as one of two primary unconditional independence tests in the flexible selection scheme.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Applied to discretized residual-vs-cause data from synthetic benchmark; uses uniform gridding (e.g., 10 bins in illustrative example) prior to testing.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection of dependence (including dependence from confounding) via χ2 contingency testing after discretization; a significant χ2 rejects independence and indicates possible spurious/confounded relation.",
            "spurious_signal_types": "Confounding, discretization-induced artifacts, non-zero dependence from noise or sampling variability.",
            "detection_method": "Uniform-grid discretization of continuous variables, computation of contingency table, χ2 statistic and p-value; low p-value signals dependence.",
            "downweighting_method": null,
            "refutation_method": "p-value thresholding: if χ2 p &lt; ci (e.g., 0.05) independence is rejected, refuting the causal hypothesis for that direction; both directions tested to detect unique combination identifying true structure or confounding.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Per Table 2, Pearson's χ2 produced the following accuracies: categorical 0.2867 ± 0.1612, binary 0.5027 ± 0.1854, numerical 0.4300 ± 0.0260, mixed 0.3215 ± 0.0392, total 0.3850 ± 0.0181. χ2 had higher mean accuracy than TIC on the paper's total aggregate.",
            "performance_without_robustness": "See comparative numbers for TIC above; χ2 sometimes outperformed TIC depending on data type, motivating RESFIT's flexible selection.",
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "χ2 on uniform discretization is a viable unconditional independence test in RESFIT and, counterintuitively, sometimes outperformed TIC on numerical data in the experiments; this suggests practical limitations from sample size and discretization decisions rather than theory.",
            "uuid": "e736.4",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Linear Additive Noise FCM (Linear FCM / LiNGAM assumptions)",
            "name_full": "Linear Additive Noise Functional Causal Model",
            "brief_description": "The causal model class used: the effect is modeled as a linear function of the cause plus an additive noise term independent of the cause (Y = bX + ε), with identifiability when at most one of X and ε is Gaussian.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "Linear additive noise FCM",
            "method_description": "Assume Y = bX + ε and estimate linear regression for both directions; exploit asymmetry that in true direction the noise ε is independent of the cause, while reversed direction typically yields dependent residuals; identifiability holds under non-Gaussian noise assumptions (LiNGAM-like conditions).",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Applied to synthetic pairs in which model assumptions may or may not hold; regression residuals are tested for independence to decide orientation.",
            "handles_distractors": null,
            "distractor_handling_technique": "Indirect: residual independence test can reveal violations due to confounders or spurious associations but model itself does not explicitly model distractors.",
            "spurious_signal_types": "Latent confounding and violations of functional form (model misspecification) that show as residual dependence.",
            "detection_method": "Residual independence testing (MI/TIC/χ2) after fitting linear regression; dependence indicates model violation or confounding.",
            "downweighting_method": null,
            "refutation_method": "Reject a causal orientation if residual is dependent on putative cause; if both directions show dependence, suspect confounding or model violation.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Performance depends on noise Gaussianity and sample size; paper reports aggregate unsupervised accuracies (see RESFIT/TIC/χ2 numbers) when using linear FCM assumption.",
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Linear FCMs are used as the modelling backbone for pairwise orientation; residual independence approach can both identify direction and signal latent confounding, but identifiability degrades when variables/noise approach Gaussianity and with limited sample size.",
            "uuid": "e736.5",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "ChaLearn SUP2",
            "name_full": "ChaLearn cause-effect pair (SUP2)",
            "brief_description": "Reference benchmark dataset of artificially generated cause-effect pairs with mixed variable types used to evaluate pairwise causal discovery methods in this paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "ChaLearn cause-effect pair (SUP2) dataset",
            "method_description": "A curated dataset containing ~6000 generated pairs spanning numerical, categorical and binary variable pairs with balanced numbers of unique values and median instance length ≈2000; used as evaluation environment to compare independence tests and the RESFIT pipeline.",
            "environment_name": "ChaLearn cause-effect pair (SUP2)",
            "environment_description": "Synthetic, non-interactive benchmark environment; not a virtual lab or active experiment platform—provides observational pairs only.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Contains generated confounded/independent/causal relationships as part of the benchmark (used to test methods' ability to detect confounding and spurious associations).",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": false,
            "number_of_distractors": null,
            "key_findings": "Used as the primary evaluation environment; results on this benchmark show that flexible independence-test selection improves unsupervised accuracy modestly, and reveal unexpected interactions between test choice and variable types.",
            "uuid": "e736.6",
            "source_info": {
                "paper_title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Elements of Causal Inference",
            "rating": 2,
            "sanitized_title": "elements_of_causal_inference"
        },
        {
            "paper_title": "Detecting Novel Associations in Large Data Sets",
            "rating": 2,
            "sanitized_title": "detecting_novel_associations_in_large_data_sets"
        },
        {
            "paper_title": "Measuring Dependence Powerfully and Equitably",
            "rating": 2,
            "sanitized_title": "measuring_dependence_powerfully_and_equitably"
        },
        {
            "paper_title": "A kernel statistical test of independence",
            "rating": 2,
            "sanitized_title": "a_kernel_statistical_test_of_independence"
        },
        {
            "paper_title": "Challenge: Cause-effect pairs",
            "rating": 2,
            "sanitized_title": "challenge_causeeffect_pairs"
        },
        {
            "paper_title": "Distinguishing cause from effect using observational data: methods and benchmarks",
            "rating": 2,
            "sanitized_title": "distinguishing_cause_from_effect_using_observational_data_methods_and_benchmarks"
        },
        {
            "paper_title": "A linear non-Gaussian acyclic model for causal discovery",
            "rating": 2,
            "sanitized_title": "a_linear_nongaussian_acyclic_model_for_causal_discovery"
        },
        {
            "paper_title": "Inferring causation from time series in Earth system sciences",
            "rating": 1,
            "sanitized_title": "inferring_causation_from_time_series_in_earth_system_sciences"
        }
    ],
    "cost": 0.01422775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures
1 Aug 2024</p>
<p>Alexandre Trilla 
Santa Perpètua de la Mogoda
08130Alstom, BarcelonaSpain</p>
<p>Nenad Mijatovic 
93482Alstom, Saint Ouen, ParisFrance</p>
<p>Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures
1 Aug 20249BF86BEAAE7FA43247FB19DA5161EFFBarXiv:2408.00399v1[cs.AI]Causal DiscoveryFunctional Causal ModelUnconditional Independence TestMutual InformationUnsupervised LearningHeterogeneous Data
A fundamental task in science is to determine the underlying causal relations because it is the knowledge of this functional structure what leads to the correct interpretation of an effect given the apparent associations in the observed data.In this sense, Causal Discovery is a technique that tackles this challenge by analyzing the statistical properties of the constituent variables.In this work, we target the generalizability of the discovery method by following a reductionist approach that only involves two variables, i.e., the pairwise or bi-variate setting.We question the current (possibly misleading) baseline results on the basis that they were obtained through supervised learning, which is arguably contrary to this genuinely exploratory endeavor.In consequence, we approach this problem in an unsupervised way, using robust Mutual Information measures, and observing the impact of the different variable types, which is oftentimes ignored in the design of solutions.Thus, we provide a novel set of standard unbiased results that can serve as a reference to guide future discovery tasks in completely unknown environments.</p>
<p>Introduction</p>
<p>Causal Discovery methods are able to identify the causal structure from the joint distribution of the data by introducing assumptions that restrict the model of their generating process [1].In a multivariate setting, the traditional constraint-based and scorebased methods exploit conditional independence relationships in the data [2].These approaches have found a great deal of success in challenging environments such as biology and the Earth sciences [3].Nevertheless, they do not necessarily provide complete causal information because they output Markov Equivalence Classes, i.e., a set of causal structures that satisfy the same conditional independence statements.Moreover, they cannot handle isolated cause-effect settings that lack the diversity of other variables for the conditional tests.Therefore, the single reduced cause-effect association, also known as the pairwise or bivariate scenario, constitutes an essential building block of more complex causal structures.</p>
<p>To distinguish cause from effect in this pairwise setting, one needs to find a way to capture the asymmetry between the two variables [2].In this sense, computational meth-ods based on properly defined Functional Causal Models (FCMs) are able to distinguish different structures in the same equivalence class.A FCM represents the effect variable Y as a function of its direct causes X and some noise term ε, i.e., Y = f (X, ε), where ε is independent of X. Thanks to the restricted functional classes, the causal direction between X and Y is generally identifiable because the independence between the noise and the cause holds only for the true causal direction and is violated for the wrong direction [4] (unless the variables are jointly Gaussian, which render the orientation unidentifiable).Additionally, the identifiability of pairwise FCM generalizes to the identifiability of multivariate FCM [5].</p>
<p>In this work, we argue that some reference benchmark results for pairwise causal discovery could be misleading because they tackle this genuinely exploratory objective as a classical supervised classification problem, inducing them to possibly learn specific contextual details beyond causality that tend to overestimate their actual performance [6].Moreover, there exists a tight relationship between the nature of data and the specific tools from statistics that could also accrue the estimation of skewed results, which was not originally addressed.Consequently, we propose a reevaluation of the benchmark driven by the heterogeneity of the data and also by following an unsupervised learning approach.Our method leverages linear functional causal models and combines different unconditional independence tests based on robust Mutual Information measures.The paper is organized as follows: Section 2 introduces the fundamental concepts for pairwise causal discovery, Section 3 describes the enhanced method proposed in this work, Section 4 shows the novel benchmarked results, Section 5 discusses the approach from a causal perspective, along with its limitations, and Section 6 concludes the article.</p>
<p>Background</p>
<p>This section reviews the fundamental concepts that support the discovery of causality in the bivariate or pairwise setting.</p>
<p>Identifiability of a Linear Model with Non-Gaussian Noise</p>
<p>The fundamental principle that enables the identification of cause and effect lies in the asymmetry of the association between them: the causal direction, i.e., from cause to effect, is functionally simpler than the anticausal one, i.e., from effect to cause, which requires a more complex application [2].Thus, a given model with limited capacity will be able to faithfully capture the expressiveness of only one of these two causal orientations.</p>
<p>Linear additive noise models assume that the effect Y is a linear function of the cause X plus a noise term ε that is independent of the cause, formally defined as: Y = bX + ε.The linear FCM is learnable if at most one of X and ε is Gaussian [7].Pairwise discovery approaches such as this one are regarded to be very flexible for identifying causal models in the general case because they don't require a third variable for conditioning.In specific scenarios such as multivariate time series, they can even improve the performance of traditional constraint-based approaches such as the Peter-Clark algorithm and others that utilize Granger causality [3].</p>
<p>The linear model with non-Gaussian noise can be estimated from (unconfounded) observational data by exploiting the inherent asymmetry between cause and effect through a regression as follows: for both directions (i.e., causal and anticausal), the FCM is fit; then, the amount of association between the estimated noise term (i.e., the regression residual) and the hypothetical cause is computed; finally, the direction assignment which gives an independent noise term is considered plausible [2].</p>
<p>Obviously, the cornerstone of this regression-based method is the measure of dependence between the regression residual and its associated potential cause.The next section describes a solution to estimate the strength of this association.</p>
<p>Mutual Information as a Measure of Association</p>
<p>The amount of association between the regression residual RR and the hypothetical cause HC signals the causal direction.However, these variables are uncorrelated by construction of the regression.To properly quantify this dependence, the Mutual Information (MI) measure provides a reliable indicator, which is defined as MI(RR, HC) = ∑ RR,HC P RR,HC log P RR,HC P RR P HC ,</p>
<p>where P RR,HC represents the (discrete) joint probability between RR and HC, and P RR and P HC represent their marginal distributions, respectively.</p>
<p>For illustrative purposes, the following variable dependencies are defined.First, a random Uniform noise sample U is independently assigned to Z, X ind and Y ind .Then, the following structural variable associations are created: Y dep ← X ind + Z, X con f ← X ind + Z, and Y con f ← Y ind + Z, which yield the subsequent relationships:
Causal Between X ind and Y dep : X → Y Anticausal Between Y dep and X ind : Y ← X Independent Between X ind and Y ind : X ⊥ ⊥ Y Confounded Between X con f and Y con f : X ↔ Y Figure 1
shows the distribution of MI between the regression residual and the hypothetical cause considering the preceding types of structural variable associations for a random sample of 1000 instances.The different density plots show how the causal orientation can be reliably recovered using MI when the model assumptions are respected.Note that the overlap between Causal and Independent structures will be disambiguated when both experiments are conducted regarding the different causal direction hypotheses.Finally, MI is also able to detect latent confounding, which is oftentimes assumed (and required) not to occur for discovery [2], i.e., the causal sufficiency principle [8].This feature adds value to the robustness of the MI indicator.</p>
<p>While the distribution of MI is a useful tool to visualize the different causal structures, there is still a missing criterion to make a classification decision in order to construct the underlying causal structure from the data.The next section addresses this point.</p>
<p>Pearson's χ 2 as an Unconditional Independence Test</p>
<p>In a real-word scenario, one cannot expect to get a null measure of association because of sampling noise, the sample size, etc.In this case, the use of an (unconditional) independence test is the proper way to handle this situation.In general, this is known as the REgression with Subsequent Independence Test (RESIT) procedure [9].Once the independence test is in place, a confidence interval needs to be observed to obtain actionable results.To this end, Pearson's χ 2 test is here introduced as a fundamental method to inform the decision process [10].The Pearson's χ 2 test is a statistical hypothesis test used in the analysis of contingency tables for categorical variables.It is used here to determine whether there is a statistically significant difference between the expected frequencies E for independence (i.e., the marginal probabilities) and the observed frequencies O in one or more categories i of the contingency table (RR, HC), formally defined as
χ 2 (RR, HC) = ∑ i∈(RR,HC) (O i − E i ) 2 E i . (2)
The test is valid as long as its statistic is χ 2 distributed under the null hypothesis.Note that χ 2 (RR, HC) is in its essence related to the MI measure of association as is used for the discovery of causal structure.</p>
<p>While the χ 2 test is most suitable for discrete variables [11], a general causal discovery method should be able to seamlessly deal with continuous variables.Typically, a uniform grid is applied to discretize a real-valued space prior to conducting the test.Following the former illustrative example, Table 1 shows the p-values for the different causal structures.Once a threshold is introduced through the confidence interval, e.g., p&lt;0.05 for a given number of degrees of freedom related to the resolution of the grid, passing the test becomes the rule for making further decisions.Note that in all cases, there is a unique combination of results for the two hypothesized causal directions that identifies the true underlying causal structure.Also note that the threshold may be adjusted to require fur-ther decision strength because the closer the variables get to a Gaussian distribution, the harder it is to distinguish the direction of causation [2].While these results may be sufficient as an indication, they may also have some limitations for discovering causal associations between numerical variables.The next section addresses this shortcoming and describes an enhanced solution for this type of variables.</p>
<p>Total Information Coefficient as a Robust Independence Test</p>
<p>The Total Information Coefficient (TIC) is a robust independence test based on MI for real-valued variables that features the two important heuristic properties of generality and equitability [12], which are defined as follows:</p>
<p>Generality With sufficient sample size the statistic should capture a wide range of interesting associations, not limited to specific function types.Equitability The statistic should give similar scores to equally noisy relationships of different types.</p>
<p>For a pair of (RR, RC) variables, the TIC algorithm applies a search procedure to partition their joint probability function and find the grid with the highest induced MI.TIC operates by summing over optimal grids G on the joint density distribution of the two variables, such that it exhibits a stronger power against independence [11], formally expressed as
T IC(RR, HC) = ∑ G MI((RR, HC)| G ) log ∥ G ∥ ,(3)
where ∥ G ∥ denotes the minimum of the number of rows and columns of G.This can be viewed as a regularized version of MI that penalizes complicated grids.Figure 2 shows qualitatively the impact of the optimum grids G.The performance of TIC has been positively rated with other successful approaches for causal discovery dealing with continuous variables, such as the Hilbert-Schmidt independence criterion [13].Finally, an additional motivation for considering TIC in this work is to increase the odds of success in case of model hypothesis violations, i.e., the functional form of the relationship Y = f (X), which is crucial for causal identification.</p>
<p>Method</p>
<p>In the pursuit of a general approach to causal discovery combining several methods [8,14], one common point of success is found in the use of information-theoretic measures, such as Mutual Information, to quantify the amount of regularity in the data [15].However, the nature of the variables, i.e., discrete or continuous, can be problematic in an heterogeneous context if the statistical methods are confused [14].Moreover, supervised learning approaches are excluded from the general objective because these methods do not yet work as standalone techniques for causal learning [4].Therefore, the desideratum in causal discovery is to have methods that work on a broad range of problems under different conditions with relaxed assumptions [16], ideally showing a certain degree of robustness regarding violations of the model hypothesis [17].</p>
<p>In this work we propose a general method to discover the causal structure in heterogeneous data based on a bivariate linear FCM by implementing a flexible RESIT procedure, see Section 2.3, where the unconditional independence test, e.g., χ 2 or TIC, also see Section 2.4, is driven by the nature of the variables involved.The proposed strategy is described with comments in Algorithm 1.Note that the orientation decision rules follow from the evidence given by the illustrative setting in Section 2.3, which is regarded as self-evident.Such explicitly-stated logic rules are meant to increase the interpretability and explainability of the proposed method.Also note that discrete variables are assimilated to real-valued variables for computing the regression residuals on which the RE-SIT method is based.Finally, since our contribution targets the problem of applying one single discovery technique on data with different types of variables, and we focus our effort at the integration level rather than at the fundamental level, we refer the interested reader to the references for the specific methods being integrated for further details about their comparison to other methods from the literature.We rely on the advice from Peters, Reshef, and colleagues [4,11], to select the best methods that we integrate in RESFIT in order to cover a broad range of techniques, and we provide an analysis on how these separate tools perform when they are put together.</p>
<p>Results</p>
<p>This section describes the reference benchmark dataset that was used to evaluate the introduction of the flexible independence test selection, the results that were obtained, and the tools for the implementation of the research.--------------------------</p>
<p>Reference Benchmark Dataset</p>
<p>The "ChaLearn cause-effect pair (SUP2)" is taken for reference as the recommended benchmark dataset to evaluate the performance of pairwise causal discovery [6].It comprises pairs of artificially generated dependent variables with different types (numerical, categorical and binary) for the full causal discovery task (orientation, independence and confounding).The dataset features a balanced number of unique values across all classes and includes around 6000 pairs.In terms of data type balance, the majority is comprised of numerical and mixed variable pairs.Finally, the average median length of an instance is around 2000 values.</p>
<p>Performance Scores</p>
<p>The accuracy classification score, i.e., the total rate of correct predictions statistically given by the overall amount of true positives and true negatives, is used in this research following the previous benchmark evaluation approaches [6], yielding a baseline around 65±2% for the supervised learning setting [15].To further assess the stability of our scores in the unsupervised scenario, statistical bootstrapping is introduced in line with this former work.Moreover, Gaussianity is asserted with the Lilliefors normality test [18], and the main descriptive statistics are extracted despite the low amount of available performance samples, well under 30, which are commonly required to obtain reliable estimations [19].Finally, in terms of statistically significant comparisons, the ttest has been used [20].Table 2 shows the results of the experiments.Note that they are presented separately by data type and independence test, whereas the proposed RESFIT algorithm automatically integrates them.This is done for illustrative purposes and for enriching the ensuing discussion.The first straightforward conclusion that the results show is that, in all cases, there is a statistically significant difference between the accuracy averages for the two unconditional independence tests within each data type stratum.Therefore, introducing a selection action on the test function is expected to impact on the discovery of causal associations.Additionally, TIC yields a slightly smaller variance in all the scores.Finally, when numerical data types are present, the standard deviation in accuracy drops an order of magnitude.</p>
<p>The code for this research is available here1 .The next section discusses the global results with respect to the perspective of a causal effect, and addresses the limitations of the proposed approach.</p>
<p>Discussion</p>
<p>This section delves into the finer details of the results that were obtained, and sheds light on the actual value introduced by the flexibility in selecting the unconditional independence test for causal discovery.</p>
<p>Average Causal Effect of the Flexible Test Selection</p>
<p>To properly quantify the impact of introducing the flexibility on the unconditional independence test, this section treats this selection action as a "treatment" variable X and studies its impact on the "outcome" discovery accuracy score Y .The Average Causal Effect (ACE) of X → Y is expressed using the following counterfactual notation
ACE =E[Y 1 −Y 0 ] = E[Y 1 ] − E[Y 0 ] = E[Y (X = 1)] − E[Y (X = 0)] =E[Y |X = 1] − E[Y |X = 0] ,(4)
where Y x refers to the value the Y accuracy result would have if X was set to x, i.e., Y (X = x).Here, X could take the values x = 1 to indicate flexibility of independence test, and x = 0 to indicate no preference (i.e., the null random choice).The conditionals that eventually follow are the values that are actually observed in the results.Note that all these expected quantities can be exactly because the different experiments can be conducted on the same data (also dispelling any doubts about latent confounding).This setting is thus not subject to the fundamental problem of causal inference where only one of the potential outcomes can be observed [21].</p>
<p>Equation ( 4) is shown to be an unbiased estimator for the ACE [22].For computing the expectations in the causal effect comparison, a weighted mixture of Gaussian random variables is required.The quantity of the reference potential outcome E[Y 0 ], where no smart selection occurs, is given by the arithmetic mean value of the total results, and it yields an accuracy score of 0.3531±0.0357.Alternatively, the potential outcome E[Y 1 ], where the smart flexible test selection is introduced, is given by the average of the best performance results among the different variable types, i.e., a sum weighted by their balance in the dataset, and it yields a value of 0.3866±0.0690.Therefore, the ACE is of 3.36%, and this estimated difference is statistically significant.However, the absolute results are far from the 65% baseline, which suggests that the original supervised approach may have leaked statistical patterns beyond causation.Although the unsupervised learning approach does not seem to offer any pragmatic quantifiable advantage, we believe that its adoption is a must for tackling the inherently hard exploratory objective of causal discovery and avoid any qualms with regards to learned biases.</p>
<p>Limitations</p>
<p>The realization that TIC, which was conceived for numerical data, performed better on discrete data is surprising.Also, χ 2 , which is defined for discrete data, performed better on numerical data.This counterintuitive behavior where theory and practice disagree may suggest that the independence tests that were used are subject to some inherent limitations such as the sample size.We regard the shortage of samples to be the main limitation of our approach on real-world data applications such as the Tuebingen dataset [23].</p>
<p>Finally, while the approach that we propose is able to welcome any testing technique, we selected RESIT flexibly paired with TIC and χ 2 following the advice of Peters, Reshef, and colleagues [4,11].To the best of our knowledge, this limited choice should be sufficient to generally cover the spectrum of approaches.</p>
<p>Conclusion</p>
<p>Environments with heterogeneous data pose challenging questions to the discovery of causal structure, and leveraging one single method may lead to erroneous results in gen-eral.In this work, we propose an unsupervised pairwise approach using linear functional causal models and different unconditional independence tests based on Mutual Information measures, the selection of which is driven by the nature of data and the empirical results from a reference benchmark.The introduction of this independence test selection flexibility is estimated to have a positive and statistically significant average causal effect over 3% in accuracy.These scores may establish the first standard baseline for this kind of flexible focus, but more research is needed because the limitations of the data size and the statistical techniques can result in counterintuitive results.</p>
<p>Figure 1 .
1
Figure 1.Distribution of Mutual Information between the regression residual and the related hypothetical cause for the different causal structures.The low-value overlap (i.e., MI&lt;0.025) between the Causal and the Independent structures illustrates the independence between the noise and the cause.The density of the realvalued MI indicator has been estimated with a smoothed Gaussian kernel.</p>
<p>Figure 2 .
2
Figure 2. A schematic illustrating the difference between the gridding strategies (shown in dotted lines) introduced by the independence tests.(Left) Uniform 3-by-3 grid as is used by the χ 2 test.(Right) Optimum 2-by-3 grid G as is used by the TIC test.</p>
<p>Algorithm 1 .
1
REgression with Subsequent Flexible Independence Test (RESFIT).The traditional RESIT procedure is here used as an internal function (underscore-prepended).Input: A, B //Potential causally-related variables Output: Causal, Anticausal, Independent, Confounded //Causal structure function RESFIT (A, B): histAB = Histogram2D(A, B) //Joint variable distribution varTypes = JointTypes(histAB) //Cat., bin., num., mix.uit = SelectUIT(varTypes) //Uncond.Indep.Test: chi2, tic pCH = __RESIT(A, B, uit) //p-value of Causal hypothesis pACH = __RESIT(B, A, uit) //p-value of Anticausal hypothesis ci = 0.05 //Confidence interval //---Decision Rules -</p>
<p>Table 1 .
1
Pearson's χ 2 p-values for the independence tests between the regression residuals and the hypothesized causal directions for the different illustrative structures, considering 10 bins in the uniform grid.
HypothesisTrue StructureDirectionCausal Anticausal Independent ConfoundedCausal0.50270.00000.48470.0025Anticausal0.00000.50270.46390.0025</p>
<p>Table 2 .
2
Descriptive statistics (mean ± std) for the accuracy classification scores regarding the different data types and unconditional independence tests.The best results (i.e., the highest value within each data type stratum) are shown in boldface.After checking Gaussian normality in the performance scores (with the exception of TIC for the Categorical data type, shown in italics), the p-values of the t-test are also provided to assert the statistical significance of their difference.
Data Typesχ 2TICp-valueCategorical0.2867 ± 0.16120.3500 ± 0.13290.0000Binary0.5027 ± 0.1854 0.5336 ± 0.13750.0014Numerical0.4300 ± 0.0260 0.3683 ± 0.02110.0000Mixed0.3215 ± 0.0392 0.2456 ± 0.02190.0000Total0.3850 ± 0.0181 0.3211 ± 0.01360.0000
Code repository: https://github.com/atrilla/ccia24</p>
<p>. J Pearl, Causality, 2009Cambridge University Press</p>
<p>Review of Causal Discovery Methods Based on Graphical Models. C Glymour, K Zhang, P Spirtes, Frontiers in Genetics. 105242019</p>
<p>Inferring causation from time series in Earth system sciences. J Runge, S Bathiany, E Bollt, Nature Communications. 102019. 2553</p>
<p>Elements of Causal Inference. J Peters, D Janzing, B Schölkopf, 2017MIT Press</p>
<p>Identifiability of causal graphs using functional causal models. J Peters, J M Mooij, Proc of the 27th Annual Conference on Uncertainty in Artificial Intelligence. of the 27th Annual Conference on Uncertainty in Artificial Intelligence2011</p>
<p>Challenge: Cause-effect pairs. I Guyon, 2013</p>
<p>A linear non-Gaussian acyclic model for causal discovery. S Shimizu, P Hoyer, A Hyvärinen, A Kerminen, Journal of Machine Learning Research. 72006</p>
<p>Beyond the Markov Equivalence Class: Extending Causal Discovery under Latent Confounding. M M Van Diepen, Bucur, Proceedings of Machine Learning Research. Machine Learning Research2023213</p>
<p>Causal discovery with continuous additive noise models. J Peters, J M Mooij, D Janzing, B Schölkopf, Journal of Machine Learning Research. 152014</p>
<p>On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. K Pearson, Philosophical Magazine Series. 53021900</p>
<p>Measuring Dependence Powerfully and Equitably. Y A Reshef, D N Reshef, H K Finucane, C Sabeti, M Mitzenmacher, Journal of Machine Learning Research. 172016</p>
<p>Detecting Novel Associations in Large Data Sets. D N Reshef, Y A Reshef, H K Finucane, Science. 33460622011</p>
<p>A kernel statistical test of independence. A Gretton, K Fukumizu, C H Teo, L Song, B Schölkopf, A Smola, Proc of the Conference on Neural Information Processing Systems. of the Conference on Neural Information essing Systems2007</p>
<p>Causal Discovery for Linear Mixed Data. Y Zeng, S Shimizu, H Matsui, F Sun, Proceedings of Machine Learning Research. Machine Learning Research2022140</p>
<p>Initial Results for Pairwise Causal Discovery Using Quantitative Information Flow. F Giori, F Figueiredo, Proc of the 36th Conference on Neural Information Processing Systems -Workshop on Causal Machine Learning for Real-World Impact. of the 36th Conference on Neural Information essing Systems -Workshop on Causal Machine Learning for Real-World Impact2022</p>
<p>Bivariate Causal Discovery via Conditional Divergence. B Duong, T Nguyen, Proceedings of Machine Learning Research. Machine Learning Research2022140</p>
<p>Causal Discovery with Score Matching on Additive Models with Arbitrary Noise. F Montagna, N Noceti, Proceedings of Machine Learning Research. Machine Learning Research2023213</p>
<p>On the Kolmogorov-Smirnov Test for Normality with Mean and Variance Unknown. H W Lilliefors, Journal of the American Statistical Association. 623181967</p>
<p>La théorie et ses applications. M Lejeune, Statistique, 2010Springer Verlag France</p>
<p>The probable error of a mean. W Gosset, Biometrika. 611908</p>
<p>Statistics and Causal Inference. P W Holland, Journal of the American Statistical Association. 813961986</p>
<p>On the application of probability theory to agricultural experiments. J Neyman, Essay on principles. Section. 91923Statistical Science.</p>
<p>Distinguishing cause from effect using observational data: methods and benchmarks. J M Mooij, J Peters, Journal of Machine Learning Research. 17322016</p>            </div>
        </div>

    </div>
</body>
</html>