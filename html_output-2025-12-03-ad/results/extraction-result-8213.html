<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8213 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8213</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8213</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-279410586</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.14234v1.pdf" target="_blank">Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team</a></p>
                <p><strong>Paper Abstract:</strong> Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation - treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solvers - such as Olympiad or programming contest teams - leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition. We introduce Xolver, a training-free multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative interactions, agent-driven evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch - marking a transition from isolated inference toward experience-aware language agents. Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses advanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24 (94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) - highlighting holistic experience learning as a key step toward generalist agents capable of expert-level reasoning. Code and data are available at https://kagnlp.github.io/xolver.github.io/.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8213.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8213.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Xolver</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Xolver: Multi-Agent Reasoning with Holistic Experience Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A training-free, multi-agent inference framework that augments a black-box LLM with dual memories (episodic and an evolving intermediate shared memory) to iteratively accumulate and reuse high-quality reasoning traces across math and coding problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Xolver (multi-agent framework)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A planner-instantiated team of LLM-based specialized agents (e.g., mathematician, programmer, verifier, judge) that iteratively solve a query by (1) retrieving exemplars from episodic memory, (2) running parallel dynamic agents that read/write a fixed-size intermediate shared memory, (3) invoking tools (Python) when needed, and (4) using a judge + verifier pipeline to rank, critique, and validate outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>o3-mini (medium/high) and QWQ-32B (also experiments with other backbones referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Underlying black-box LLM backbones used to instantiate all agents; experiments run with open-weight QWQ-32B and proprietary o3-mini (medium and high) variants. Xolver is backbone-agnostic and shows gains across both weaker and stronger models.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Mathematical reasoning and code generation benchmarks (GSM8K, Math-500, AIME 2024/2025, LiveCodeBench v5)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-step symbolic mathematical problems (arithmetic, algebra, number theory, geometry, combinatorics) and programming problems requiring generation of executable code and passing synthesized/sample testcases.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step reasoning; code synthesis and verification</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>dual: episodic memory (D_E) and intermediate dynamic shared memory (D_S)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Episodic retrieval from an external corpus (BM25 similarity search) or internal self-retrieval from the model; a fixed-size intermediate shared memory D_S is updated every iteration by selecting the Top-K (|D_S| = m) agent trajectories ranked by the judge's scalar score; agents read D_S each iteration and include it in their prompt context.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Stored items are structured tuples of (reasoning trace T, response R, judge feedback T_S, scalar score s, agent metadata a); episodic memory stores past problems, solution traces, and responses (q', T', R').</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>External episodic retrieval: BM25 / similarity-based top-K retrieval; fallback self-retrieval: sampling from the agent LLM; shared memory: direct prompt concatenation of the top-m tuples D_S (recency/quality filtered by judge score).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Xolver (+) (cross-problem episodic updates) reported large gains: with o3-mini-high backbone achieves SOTA numbers reported in paper (GSM8K 98.1%, AIME'24 94.4%, AIME'25 93.7%, Math-500 99.8%, LiveCodeBench 91.6%). With o3-mini-medium and QWQ-32B backbones Xolver (+) also substantially outperforms baselines (examples: o3-mini-medium Xolver (+) AIME'24 93.8; LiveCodeBench 87.3; QWQ-32B Xolver (+) AIME'24 89.9; LiveCodeBench 76.2).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Xolver (-) (no episodic updates across problems, episodic corpus static) remains strong but is consistently outperformed by Xolver (+); the paper reports an average episodic-memory integration benefit of +3.5 points across backbones/datasets and a largest observed gain of +7.7 points (o3-mini-medium on LiveCodeBench).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Ablations show removing Multi-iteration and Multi-Agent yields the largest performance drops, followed by removal of the Judge agent. Removing Verifier/Debugger or Tool has smaller drops. Retrieval ablation: External retrieval > Self-retrieval > No retrieval. Self-judging (agents judge their own outputs) causes drops (~9.9% drop on coding, ~3.88% on math). Iterations and agent count both improve performance; budget-controlled tests indicate agent diversity (beyond 3) yields further emergent gains (~>4%).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining episodic retrieval with an evolving intermediate shared memory and multi-agent iterative refinement produces large, backbone-agnostic performance gains on math and coding benchmarks; external retrieval substantially helps, but self-retrieval is a viable fallback; judge-mediated selection + intermediate memory enables cross-iteration knowledge reuse; Xolver (+) (updating episodic memory across problems) consistently outperforms the static-episodic variant.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Higher token and compute costs (≈1.5× token usage vs a single-agent baseline like Search-o1); runtime communication/coordination overhead; reliance on backbone LLM quality; tool usage remains decoupled and sometimes under-invoked by agents causing calculation errors; episodic memory growth and retrieval quality require further filtering/optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8213.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8213.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dynamic Agents (A)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamic Reasoning Agents (component of Xolver)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Specialized LLM-instantiated agents (e.g., algebra solver, programmer, numerical analyst) that operate in parallel, each receiving a tailored prompt including the query, retrieved exemplars, prior generation, and the intermediate shared memory to produce structured reasoning traces and responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Dynamic Reasoning Agents (in Xolver)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Each agent is prompted with an assigned expert role and constructs a structured reasoning trace T_j^i and response R_j^i per iteration; on iteration 0 they use episodic retrieval exemplars; from iteration ≥1 they rely on shared memory D_S and their own previous outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Same backbone LLMs as Xolver (o3-mini variants, QWQ-32B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Agents are zero-shot LLM prompt templates instantiated from the backbone; no fine-tuning used.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Same benchmarks as Xolver (GSM8K, Math-500, AIME'24/'25, LiveCodeBench)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Produce multi-step solutions and, for code tasks, executable code expected to pass testcases (simulated/executed via verifier/judge).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>iterative multi-agent multi-step reasoning and code generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>use of episodic memory (first iteration exemplars) and read/write access to an intermediate shared memory (D_S) during inference</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Agents include retrieved exemplars (R(D_E)) in initial context; subsequent contexts include their previous trace and the current D_S; after generation, judge returns feedback tuples used to update D_S; agents thus read D_S and adapt their next outputs accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Agents both read and produce entries stored in D_S: (T, R, judge feedback tuple (T_S, s), agent id), i.e., intermediate reasoning traces, responses, and evaluation metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Prompt concatenation: D_S and retrieved exemplars are concatenated into each agent's prompt context; external episodic retrieval uses BM25; internal self-retrieval samples exemplars from the LLM if external corpus unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>As part of Xolver, agents leveraging D_S converge to higher-quality solutions across iterations; paper-level results (Xolver (+)) reflect these gains (see Xolver entry).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>When agents do not access shared memory (ablation of intermediate memory), performance degrades substantially (ablation results show marked drop; Multi-iteration and Multi-Agent removals produce the largest degradations), though the paper does not provide a single isolated numeric value for this exact ablation beyond the plotted drops.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Ablation: removing the multi-iteration/shared-memory mechanism leads to the largest performance drops; increasing number of agents and iterations both improve accuracy; budget-constrained experiments show agent diversity yields emergent gains</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Dynamic agents that read/write a shared high-quality trace pool enable cumulative improvement: agents progressively align and refine solutions via exposure to top-ranked traces, validating that inter-agent memory sharing drives accuracy improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Cost scales with m×I in token usage (but runtime parallelism reduces wall-clock growth); risk of self-bias if agents self-judge rather than using an external Judge (self-judging reduces performance).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8213.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8213.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Episodic Memory (D_E)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Episodic Memory (external corpus and parametric self-retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Long-term memory component storing past problems, reasoning traces, and solutions; can be external (retrieved by BM25) or internal (self-retrieval by sampling the agent LLM), and can be updated across problems in Xolver (+).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Episodic Memory (D_E)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A retrieval store that provides K exemplars relevant to the current query via a retrieval operator R(D_E); supports two forms: (1) external corpus D_ext^E queried via BM25; (2) internal parametric self-retrieval by sampling the model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Used to seed initial contexts for math and coding reasoning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Provides exemplars (q', T', R') to agents on iteration 0 to initialize reasoning from relevant past problems and solutions; in Xolver (+) D_E is updated after solving new problems.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>retrieval-augmented initialization for multi-step reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic (external corpus and parametric self-retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>External retrieval: BM25 similarity search returns top-K (e.g., k=5) problems and full reasoning traces; self-retrieval: sample candidate exemplars from the agent LLM when external corpus unavailable; Xolver (+) can append BESTRESPONSE from D_S as a new episodic entry after solving a problem.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Each episodic entry is (q', optional reasoning trace T', response R'); the external corpus for code comprised a 9M-token dataset of algorithmic problems and C++ solutions; for math used OPENMATHREASON dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Similarity-based BM25 for external corpus; sampling/generation from the LLM for self-retrieval fallback; retrieval applied only for context construction at first iteration (i=0).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>External retrieval yields the best improvements (paper: External Retrieval > Self-Retrieval > No Retrieval). Episodic-memory-enabled Xolver (+) yields average +3.5 points over Xolver (-) across benchmarks; largest benefit observed +7.7 points (o3-mini-medium on LiveCodeBench).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>No episodic retrieval reduces performance relative to external retrieval; self-retrieval performs between external retrieval and no retrieval. Exact numeric deltas vary by dataset and backbone (see summary above).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Retrieval ablation shows External > Self-retrieval > No retrieval. Xolver (+) (episodic updates across problems) consistently outperforms Xolver (-) (static episodic store). Data-shuffle experiments show minimal order sensitivity (std dev ~1 over shuffles).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>External episodic retrieval from a curated corpus is a major contributor to Xolver's performance; self-retrieval is a viable fallback when external corpora are absent but with a measurable drop; updating episodic memory across problems gives consistent further gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Quality and language mismatch of external retrieval (e.g., code corpus in C++ vs target Python) can still help but may limit gains; maintaining and filtering a growing episodic corpus is a future engineering challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8213.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8213.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Intermediate Shared Memory (D_S)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intermediate Dynamic Shared Memory (D_S)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fixed-size, evolving inference-time memory that stores the top-m high-quality agent trajectories (reasoning traces, responses, and judge feedback) and is shared across agents to enable iterative refinement within a single query.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Intermediate Shared Memory (D_S)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A temporary, fixed-size store (|D_S| = m) cleared at query start and updated each iteration by keeping the Top-K tuples from the candidate pool ranked by the Judge's scalar score; agents read D_S to guide subsequent generations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Used across the same math and code reasoning tasks as Xolver</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Facilitates cross-agent, cross-iteration propagation of the highest-quality partial solutions to drive convergence and refinement for a single problem instance.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>working/intermediate memory for iterative reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>working/intermediate shared memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>After each agent generation, the judge returns S = (T_S, s). Candidate pool M = D_S ∪ {new τ_j^i}. D_S is then replaced with TopK(M, m) according to s(e). Agents include D_S in their next context (prompt concatenation). Iteration stops on convergence (all D_S entries perfect) or after max iterations I.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Each entry in D_S is τ = (T, R, (T_S, s), agent_id) representing a reasoning trace, response, structured judge feedback, scalar quality score, and provenance.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Prompt concatenation: D_S entries are incorporated into each agent's context; selection into D_S is quality-based via judge scores; no external vector search is used for D_S (its size is fixed and entries curated by score).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Shared memory is central to Xolver's iterative gains; ablation removing multi-iteration/shared-memory leads to major performance drops (largest among tested removals except multi-agent removal). The convergent iterative behavior driven by D_S improves agent agreement and accuracy across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Removing or disabling D_S (or multi-iteration) yields large performance degradation (quantified in the paper's Figure 3 as among the largest drops; exact percentage depends on dataset/backbone).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Ablation shows that Multi-iteration + Multi-agent + Judge + D_S together are key; the judge is required to select and score D_S entries properly; self-judging degrades performance, indicating the importance of an external judge in updating D_S.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A small, high-quality intermediate shared memory that is iteratively curated by an external judge enables agents to build on successful partial solutions and converge to correct answers more effectively than single-shot or single-agent approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Maintaining a fixed-size D_S may discard some useful diversity if m is too small; keeping only Top-K entries risks premature convergence to suboptimal solutions if judge scoring is noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Reflexion: Language agents with verbal reinforcement learning <em>(Rating: 2)</em></li>
                <li>MemGPT <em>(Rating: 2)</em></li>
                <li>Scratchpads <em>(Rating: 2)</em></li>
                <li>CheatSheet <em>(Rating: 2)</em></li>
                <li>Search-o1: Agentic search-enhanced large reasoning models <em>(Rating: 2)</em></li>
                <li>OctoTools: An agentic framework with extensible tools for complex reasoning <em>(Rating: 2)</em></li>
                <li>Self-Reflexion <em>(Rating: 1)</em></li>
                <li>CodeSim: Multi-agent code generation and problem solving through simulation-driven planning and debugging <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8213",
    "paper_id": "paper-279410586",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [
        {
            "name_short": "Xolver",
            "name_full": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning",
            "brief_description": "A training-free, multi-agent inference framework that augments a black-box LLM with dual memories (episodic and an evolving intermediate shared memory) to iteratively accumulate and reuse high-quality reasoning traces across math and coding problems.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Xolver (multi-agent framework)",
            "agent_description": "A planner-instantiated team of LLM-based specialized agents (e.g., mathematician, programmer, verifier, judge) that iteratively solve a query by (1) retrieving exemplars from episodic memory, (2) running parallel dynamic agents that read/write a fixed-size intermediate shared memory, (3) invoking tools (Python) when needed, and (4) using a judge + verifier pipeline to rank, critique, and validate outputs.",
            "model_name": "o3-mini (medium/high) and QWQ-32B (also experiments with other backbones referenced)",
            "model_description": "Underlying black-box LLM backbones used to instantiate all agents; experiments run with open-weight QWQ-32B and proprietary o3-mini (medium and high) variants. Xolver is backbone-agnostic and shows gains across both weaker and stronger models.",
            "task_name": "Mathematical reasoning and code generation benchmarks (GSM8K, Math-500, AIME 2024/2025, LiveCodeBench v5)",
            "task_description": "Multi-step symbolic mathematical problems (arithmetic, algebra, number theory, geometry, combinatorics) and programming problems requiring generation of executable code and passing synthesized/sample testcases.",
            "task_type": "multi-step reasoning; code synthesis and verification",
            "memory_used": true,
            "memory_type": "dual: episodic memory (D_E) and intermediate dynamic shared memory (D_S)",
            "memory_mechanism": "Episodic retrieval from an external corpus (BM25 similarity search) or internal self-retrieval from the model; a fixed-size intermediate shared memory D_S is updated every iteration by selecting the Top-K (|D_S| = m) agent trajectories ranked by the judge's scalar score; agents read D_S each iteration and include it in their prompt context.",
            "memory_representation": "Stored items are structured tuples of (reasoning trace T, response R, judge feedback T_S, scalar score s, agent metadata a); episodic memory stores past problems, solution traces, and responses (q', T', R').",
            "memory_retrieval_method": "External episodic retrieval: BM25 / similarity-based top-K retrieval; fallback self-retrieval: sampling from the agent LLM; shared memory: direct prompt concatenation of the top-m tuples D_S (recency/quality filtered by judge score).",
            "performance_with_memory": "Xolver (+) (cross-problem episodic updates) reported large gains: with o3-mini-high backbone achieves SOTA numbers reported in paper (GSM8K 98.1%, AIME'24 94.4%, AIME'25 93.7%, Math-500 99.8%, LiveCodeBench 91.6%). With o3-mini-medium and QWQ-32B backbones Xolver (+) also substantially outperforms baselines (examples: o3-mini-medium Xolver (+) AIME'24 93.8; LiveCodeBench 87.3; QWQ-32B Xolver (+) AIME'24 89.9; LiveCodeBench 76.2).",
            "performance_without_memory": "Xolver (-) (no episodic updates across problems, episodic corpus static) remains strong but is consistently outperformed by Xolver (+); the paper reports an average episodic-memory integration benefit of +3.5 points across backbones/datasets and a largest observed gain of +7.7 points (o3-mini-medium on LiveCodeBench).",
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Ablations show removing Multi-iteration and Multi-Agent yields the largest performance drops, followed by removal of the Judge agent. Removing Verifier/Debugger or Tool has smaller drops. Retrieval ablation: External retrieval &gt; Self-retrieval &gt; No retrieval. Self-judging (agents judge their own outputs) causes drops (~9.9% drop on coding, ~3.88% on math). Iterations and agent count both improve performance; budget-controlled tests indicate agent diversity (beyond 3) yields further emergent gains (~&gt;4%).",
            "key_findings": "Combining episodic retrieval with an evolving intermediate shared memory and multi-agent iterative refinement produces large, backbone-agnostic performance gains on math and coding benchmarks; external retrieval substantially helps, but self-retrieval is a viable fallback; judge-mediated selection + intermediate memory enables cross-iteration knowledge reuse; Xolver (+) (updating episodic memory across problems) consistently outperforms the static-episodic variant.",
            "limitations_or_challenges": "Higher token and compute costs (≈1.5× token usage vs a single-agent baseline like Search-o1); runtime communication/coordination overhead; reliance on backbone LLM quality; tool usage remains decoupled and sometimes under-invoked by agents causing calculation errors; episodic memory growth and retrieval quality require further filtering/optimization.",
            "uuid": "e8213.0",
            "source_info": {
                "paper_title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Dynamic Agents (A)",
            "name_full": "Dynamic Reasoning Agents (component of Xolver)",
            "brief_description": "Specialized LLM-instantiated agents (e.g., algebra solver, programmer, numerical analyst) that operate in parallel, each receiving a tailored prompt including the query, retrieved exemplars, prior generation, and the intermediate shared memory to produce structured reasoning traces and responses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Dynamic Reasoning Agents (in Xolver)",
            "agent_description": "Each agent is prompted with an assigned expert role and constructs a structured reasoning trace T_j^i and response R_j^i per iteration; on iteration 0 they use episodic retrieval exemplars; from iteration ≥1 they rely on shared memory D_S and their own previous outputs.",
            "model_name": "Same backbone LLMs as Xolver (o3-mini variants, QWQ-32B)",
            "model_description": "Agents are zero-shot LLM prompt templates instantiated from the backbone; no fine-tuning used.",
            "task_name": "Same benchmarks as Xolver (GSM8K, Math-500, AIME'24/'25, LiveCodeBench)",
            "task_description": "Produce multi-step solutions and, for code tasks, executable code expected to pass testcases (simulated/executed via verifier/judge).",
            "task_type": "iterative multi-agent multi-step reasoning and code generation",
            "memory_used": true,
            "memory_type": "use of episodic memory (first iteration exemplars) and read/write access to an intermediate shared memory (D_S) during inference",
            "memory_mechanism": "Agents include retrieved exemplars (R(D_E)) in initial context; subsequent contexts include their previous trace and the current D_S; after generation, judge returns feedback tuples used to update D_S; agents thus read D_S and adapt their next outputs accordingly.",
            "memory_representation": "Agents both read and produce entries stored in D_S: (T, R, judge feedback tuple (T_S, s), agent id), i.e., intermediate reasoning traces, responses, and evaluation metadata.",
            "memory_retrieval_method": "Prompt concatenation: D_S and retrieved exemplars are concatenated into each agent's prompt context; external episodic retrieval uses BM25; internal self-retrieval samples exemplars from the LLM if external corpus unavailable.",
            "performance_with_memory": "As part of Xolver, agents leveraging D_S converge to higher-quality solutions across iterations; paper-level results (Xolver (+)) reflect these gains (see Xolver entry).",
            "performance_without_memory": "When agents do not access shared memory (ablation of intermediate memory), performance degrades substantially (ablation results show marked drop; Multi-iteration and Multi-Agent removals produce the largest degradations), though the paper does not provide a single isolated numeric value for this exact ablation beyond the plotted drops.",
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Ablation: removing the multi-iteration/shared-memory mechanism leads to the largest performance drops; increasing number of agents and iterations both improve accuracy; budget-constrained experiments show agent diversity yields emergent gains",
            "key_findings": "Dynamic agents that read/write a shared high-quality trace pool enable cumulative improvement: agents progressively align and refine solutions via exposure to top-ranked traces, validating that inter-agent memory sharing drives accuracy improvements.",
            "limitations_or_challenges": "Cost scales with m×I in token usage (but runtime parallelism reduces wall-clock growth); risk of self-bias if agents self-judge rather than using an external Judge (self-judging reduces performance).",
            "uuid": "e8213.1",
            "source_info": {
                "paper_title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Episodic Memory (D_E)",
            "name_full": "Episodic Memory (external corpus and parametric self-retrieval)",
            "brief_description": "Long-term memory component storing past problems, reasoning traces, and solutions; can be external (retrieved by BM25) or internal (self-retrieval by sampling the agent LLM), and can be updated across problems in Xolver (+).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Episodic Memory (D_E)",
            "agent_description": "A retrieval store that provides K exemplars relevant to the current query via a retrieval operator R(D_E); supports two forms: (1) external corpus D_ext^E queried via BM25; (2) internal parametric self-retrieval by sampling the model.",
            "model_name": null,
            "model_description": null,
            "task_name": "Used to seed initial contexts for math and coding reasoning tasks",
            "task_description": "Provides exemplars (q', T', R') to agents on iteration 0 to initialize reasoning from relevant past problems and solutions; in Xolver (+) D_E is updated after solving new problems.",
            "task_type": "retrieval-augmented initialization for multi-step reasoning",
            "memory_used": true,
            "memory_type": "episodic (external corpus and parametric self-retrieval)",
            "memory_mechanism": "External retrieval: BM25 similarity search returns top-K (e.g., k=5) problems and full reasoning traces; self-retrieval: sample candidate exemplars from the agent LLM when external corpus unavailable; Xolver (+) can append BESTRESPONSE from D_S as a new episodic entry after solving a problem.",
            "memory_representation": "Each episodic entry is (q', optional reasoning trace T', response R'); the external corpus for code comprised a 9M-token dataset of algorithmic problems and C++ solutions; for math used OPENMATHREASON dataset.",
            "memory_retrieval_method": "Similarity-based BM25 for external corpus; sampling/generation from the LLM for self-retrieval fallback; retrieval applied only for context construction at first iteration (i=0).",
            "performance_with_memory": "External retrieval yields the best improvements (paper: External Retrieval &gt; Self-Retrieval &gt; No Retrieval). Episodic-memory-enabled Xolver (+) yields average +3.5 points over Xolver (-) across benchmarks; largest benefit observed +7.7 points (o3-mini-medium on LiveCodeBench).",
            "performance_without_memory": "No episodic retrieval reduces performance relative to external retrieval; self-retrieval performs between external retrieval and no retrieval. Exact numeric deltas vary by dataset and backbone (see summary above).",
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Retrieval ablation shows External &gt; Self-retrieval &gt; No retrieval. Xolver (+) (episodic updates across problems) consistently outperforms Xolver (-) (static episodic store). Data-shuffle experiments show minimal order sensitivity (std dev ~1 over shuffles).",
            "key_findings": "External episodic retrieval from a curated corpus is a major contributor to Xolver's performance; self-retrieval is a viable fallback when external corpora are absent but with a measurable drop; updating episodic memory across problems gives consistent further gains.",
            "limitations_or_challenges": "Quality and language mismatch of external retrieval (e.g., code corpus in C++ vs target Python) can still help but may limit gains; maintaining and filtering a growing episodic corpus is a future engineering challenge.",
            "uuid": "e8213.2",
            "source_info": {
                "paper_title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Intermediate Shared Memory (D_S)",
            "name_full": "Intermediate Dynamic Shared Memory (D_S)",
            "brief_description": "A fixed-size, evolving inference-time memory that stores the top-m high-quality agent trajectories (reasoning traces, responses, and judge feedback) and is shared across agents to enable iterative refinement within a single query.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Intermediate Shared Memory (D_S)",
            "agent_description": "A temporary, fixed-size store (|D_S| = m) cleared at query start and updated each iteration by keeping the Top-K tuples from the candidate pool ranked by the Judge's scalar score; agents read D_S to guide subsequent generations.",
            "model_name": null,
            "model_description": null,
            "task_name": "Used across the same math and code reasoning tasks as Xolver",
            "task_description": "Facilitates cross-agent, cross-iteration propagation of the highest-quality partial solutions to drive convergence and refinement for a single problem instance.",
            "task_type": "working/intermediate memory for iterative reasoning",
            "memory_used": true,
            "memory_type": "working/intermediate shared memory",
            "memory_mechanism": "After each agent generation, the judge returns S = (T_S, s). Candidate pool M = D_S ∪ {new τ_j^i}. D_S is then replaced with TopK(M, m) according to s(e). Agents include D_S in their next context (prompt concatenation). Iteration stops on convergence (all D_S entries perfect) or after max iterations I.",
            "memory_representation": "Each entry in D_S is τ = (T, R, (T_S, s), agent_id) representing a reasoning trace, response, structured judge feedback, scalar quality score, and provenance.",
            "memory_retrieval_method": "Prompt concatenation: D_S entries are incorporated into each agent's context; selection into D_S is quality-based via judge scores; no external vector search is used for D_S (its size is fixed and entries curated by score).",
            "performance_with_memory": "Shared memory is central to Xolver's iterative gains; ablation removing multi-iteration/shared-memory leads to major performance drops (largest among tested removals except multi-agent removal). The convergent iterative behavior driven by D_S improves agent agreement and accuracy across iterations.",
            "performance_without_memory": "Removing or disabling D_S (or multi-iteration) yields large performance degradation (quantified in the paper's Figure 3 as among the largest drops; exact percentage depends on dataset/backbone).",
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Ablation shows that Multi-iteration + Multi-agent + Judge + D_S together are key; the judge is required to select and score D_S entries properly; self-judging degrades performance, indicating the importance of an external judge in updating D_S.",
            "key_findings": "A small, high-quality intermediate shared memory that is iteratively curated by an external judge enables agents to build on successful partial solutions and converge to correct answers more effectively than single-shot or single-agent approaches.",
            "limitations_or_challenges": "Maintaining a fixed-size D_S may discard some useful diversity if m is too small; keeping only Top-K entries risks premature convergence to suboptimal solutions if judge scoring is noisy.",
            "uuid": "e8213.3",
            "source_info": {
                "paper_title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Reflexion: Language agents with verbal reinforcement learning",
            "rating": 2,
            "sanitized_title": "reflexion_language_agents_with_verbal_reinforcement_learning"
        },
        {
            "paper_title": "MemGPT",
            "rating": 2
        },
        {
            "paper_title": "Scratchpads",
            "rating": 2,
            "sanitized_title": "scratchpads"
        },
        {
            "paper_title": "CheatSheet",
            "rating": 2,
            "sanitized_title": "cheatsheet"
        },
        {
            "paper_title": "Search-o1: Agentic search-enhanced large reasoning models",
            "rating": 2,
            "sanitized_title": "searcho1_agentic_searchenhanced_large_reasoning_models"
        },
        {
            "paper_title": "OctoTools: An agentic framework with extensible tools for complex reasoning",
            "rating": 2,
            "sanitized_title": "octotools_an_agentic_framework_with_extensible_tools_for_complex_reasoning"
        },
        {
            "paper_title": "Self-Reflexion",
            "rating": 1,
            "sanitized_title": "selfreflexion"
        },
        {
            "paper_title": "CodeSim: Multi-agent code generation and problem solving through simulation-driven planning and debugging",
            "rating": 1,
            "sanitized_title": "codesim_multiagent_code_generation_and_problem_solving_through_simulationdriven_planning_and_debugging"
        }
    ],
    "cost": 0.02104275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team
17 Jun 2025</p>
<p>MdTanzib Hosain 
American International University
Bangladesh</p>
<p>Salman Rahman 
University of California
Los Angeles</p>
<p>Md Kishor Morol 
Cornell University 4 Qatar Computing Research Institute</p>
<p>MdRizwan Parvez mparvez@hbku.edu.qa 
Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team
17 Jun 20251C56FD210DD8FE86EE7DBAC0EB1A3BEDarXiv:2506.14234v1[cs.CL]
Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation-treating each problem as an independent attempt, without accumulating or integrating experiential knowledge.In contrast, expert problem solvers-such as Olympiad or programming contest teams-leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition.Inspired by this, we introduce Xolver-a training-free, multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience.Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative agent interactions, agent-driven evaluation, and iterative reasoning refinement.By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch-marking a transition from isolated inference toward experience-aware language agents.Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents (e.g., OctoTools, CheatSheet, Search-o1).Even when instantiated with lightweight backbones (e.g., QWQ-32B), it often surpasses the most advanced models to date-including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high.With a stronger backbone like o3-mini-high, it achieves a new best result-98.1% on GSM8K, 94.4% on AIME'24, 93.7% on AIME'25, 99.8% on Math-500, and 91.6% on LiveCodeBench-highlighting holistic experience learning as a key step toward dynamic, generalist agents capable of expert-level reasoning.We open-source all code, and data of Xolver at https://kagnlp.github.io/xolver.github.io/.</p>
<p>Introduction</p>
<p>Recent advances in large language models (LLMs) have made remarkable progress in complex reasoning and problem solving across domains such as mathematics [6,15,26] and programming [4,3,21].Yet despite these impressive capabilities, conventional LLM reasoning approaches remain fundamentally limited: they standalone each problem instance, generating solutions from scratch without accumulating or transferring insights from rich, diverse experiential knowledge.This isolated reasoning paradigm marks a significant departure from how expert human problem solvers operate.Expert problem solvers-such as an Olympiad or programming contest teams-rarely LiveCodeBench (v5)</p>
<p>Figure 1: Results Summary on AIME '24 (16 runs), AIME '25 and LiveCodeBench (32 runs).</p>
<p>Our framework Xolver, built on o3-mini-medium and o3-mini-high backbones (denoted (m) and (h)), achieves up to 30.9% gain over the baseline and often outperforms leading models on both tasks.</p>
<p>approach problems in a vacuum.Instead, they draw upon a rich tapestry of cumulative experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality (e.g., calculator), adapting strategies based on peers' expertise and experiences, gaining insights through iterative trial and error, and learning from related problems even during competition.This holistic experience empowers them to tackle new challenges not from scratch, but by dynamically applying accumulated knowledge and adaptive strategies.</p>
<p>While numerous prior studies have enhanced LLM reasoning and problem solving through various forms of experiential knowledge augmentation, they have predominantly operated within discrete modalities-retrieving similar problems or relevant contexts [46,25,14], leveraging external tools [33,32], or facilitating multi-agent collaboration [18,16,62].Despite their individual strengths, these approaches address distinct facets of experiential knowledge independently, preventing LLMs from accumulating and synthesizing a comprehensive repertoire of learning signals across diverse experiential dimensions, thereby limiting the development of the rich, interconnected knowledge structures that characterize human expertise.</p>
<p>In this paper, we introduce Xolver, a unified, memory-augmented, multi-agent inference framework that emulates the holistic experience-driven, collaborative reasoning of expert teams.Xolver dynamically orchestrates a roster of specialized agents-such as mathematicians, programmers, verifiers-that iteratively tackle complex problems.Unlike conventional LLM pipelines, Xolver seamlessly integrates planning, episodic retrieval-both from external or self-parametric long-term memory-an evolving intermediate shared memory, tool invocation, multi-agent collaboration, agentdriven evaluation, and iterative self-refinement into a single adaptive architecture.</p>
<p>Each agent's reasoning begins with exemplars drawn from episodic memory.From the second iteration onward, agents rely exclusively on an evolving shared memory that records the highestquality reasoning paths, solutions, and evaluation feedback generated so far-thereby accumulating symbolic experience over time.This shared repository guides agents to build on successful strategies, correct mistakes, and improve solution quality.When needed, agents invoke external tools (e.g., code execution), and a dedicated judge agent reviews all outputs-selecting top responses, issuing feedback, and enriching the intermediate shared memory with curated traces and collective evaluations for future rounds.Iterations continue until outputs converge or a preset limit is reached, followed by a final verification or external debugging phase to ensure correctness.Additionally, by updating its episodic store with each newly solved problem and its reasoning trace, Xolver can continually expand its knowledge base.Through this closed loop of collaborative agents, memory-guided refinement, and tool guided precision, Xolver features a more holistic experience learning and transcends static LLM inference, delivering adaptive, expert-level reasoning over time.Figure 2 illustrates the workflow.</p>
<p>We conduct large-scale experiments across a range of math and programming benchmarks-including GSM8K, Math-500, AIME (2024 and 2025), and LiveCodeBench (v5)-using both proprietary (o3mini-medium) and open-weight (QWQ-32B) backbone models.Xolver consistently outperforms specialized reasoning systems such as OctoTools [33], CheatSheet [55], and Search-o1 [28].Remarkably, even when instantiated with lightweight models, Xolver often surpasses significantly larger state-of-the-art LLMs, including Qwen3-235B [56], Gemini 2.5 Pro [7], o1, o3, and o4-minihigh [41].As in Figure 1, Xolver (m) achieves 91.6% average accuracy on the AIME '24 and '25 benchmarks-an 18.5-point gain over o3-mini-medium-while Xolver (h) reaches 94.1%, outper- forming o3-mini-high by 7.2 points.On LiveCodeBench, Xolver (m) improves upon its base by 21 points (66.3% to 87.3%), with Xolver (h) achieving 91.6%, a 22.1-point lift over o3-mini-high.
[ T 0 i , R 0 i ] [ T 1 i , R 1 i ] [ T 2 i , R 2 i ] 1. [ T 2 i , R 2 i , S 2 i ,
Our analysis reveals how Xolver's experiential components contribute to its performance.Accuracy improves consistently with more agents and iterations, reflecting the benefits of experience accumulation, though at increased cost.While external retrieval remains powerful, we find that self-retrieval-drawing from the model's own parametric memory-can serve as an alternative with some performance drop.For tasks involving symbolic reasoning and complex arithmetic, multi-agent, multi-iterative refinement is more beneficial than tool use (e.g., Python execution).Our experiments confirm that even without updating episodic memory during inference, Xolver retains substantial performance gains, emphasizing the strength of its intermediate memory and iterative refinement.Together, these findings highlight Xolver 's ability to accumulate, refine, and reuse symbolic experience through collaborative, memory-guided reasoning.</p>
<p>The Xolver Framework</p>
<p>Given a problem query q ∈ Q and a pretrained language model LLM θ (•), a conventional approach generates a solution via single-step inference: y ∼ LLM θ (q).In contrast, Xolver executes a dynamic, multi-agent reasoning process that iteratively accumulates and leverages symbolic experience to solve complex problems more effectively.</p>
<p>To support structured collaborative reasoning, Xolver maintains two complementary forms of memory: an episodic memory D E , which stores a library of past problems, solutions, and reasoning traces; and an intermediate dynamic shared memory D S , which evolves during inference to retain high-quality agent trajectories-comprising reasoning thoughts, responses, agent metadata, and feedback.In Xolver, a multi-agent team A is orchestrated adaptively by a planner agent P, which assigns roles and configures memory access.During inference, A agents leverage an external toolset T (e.g., Python interpreter) to support accurate computation.Finally, a verifier or external debugger V is invoked to extract and format the final answer, and to validate correctness for executable outputs.</p>
<p>Below, we first describe the Xolver agents and tools in Section 2.1, followed by the memory components in Section 2.2, and the inference cycle in Section 2.3.</p>
<p>Agents and Tools</p>
<p>Planner Agent P. The planner agent P is responsible for initiating, planning, and orchestrating the Xolver multi-agent architecture.Given the problem q and the number of agents m, it constructs a team A of m dynamic agents, each assigned a distinct expert role (e.g., algebra solver, mathematician, theorist, programmer, algorithm designer) tailored to the demands of q.To ensure sufficient task coverage and role diversity, P first prompts the underlying LLM to over-generate M &gt; m candidate agents, from which it then selects the most effective subset A ⊂ {a 1 , . . ., a M } such that |A| = m.A summary of the most frequently generated and selected roles is provided in Appendix D.4.</p>
<p>Dynamic Reasoning Agents A. The set A = {a 1 , a 2 , . . ., a m } represents a team of dynamic reasoning agents constructed by the planner agent P. Each agent a j ∈ A is assigned a distinct expert role (e.g., algebra solver, programmer, counter-example generator) tailored to the task query q.Agents are instantiated using a standardized prompting template (see Appendix A) that incorporates the task description, assigned role, retrieved examples, prior reasoning attempts, and shared memory feedback-enabling iterative self-correction and role specialization.</p>
<p>At each iteration i, agent a j receives a context C j i and generates a structured reasoning trace T j i and a response R j i .For the first iteration (i = 0), the context is initialized using the task query and relevant retrieved exemplars:
A ← C j 0 = {q} ∪ R(D E ).
(BUILDCONTEXT) For subsequent iterations (i ≥ 1), the context evolves by incorporating its prior generation (history) and the shared memory:
A ← C j i = {q} ∪ {T j i−1 , R j i−1 } ∪ D S . (BUILDCONTEXT)
Judge Agent J .The judge agent J evaluates intermediate outputs from each agent and returns structured feedback to guide refinement and memory updates.Given a query q, a reasoning trace T , and a response R, it produces a feedback tuple S = (T S , s), where T S is a natural language explanation (e.g., critique, justification, correction), and s is a scalar quality score.The interpretation of s is task-dependent: for math problems, s ∈ [0, 1] reflects an LLM-estimated correctness probability; for code tasks, s ∈ {0, 1, . . ., N test }, where N test denotes the total number of test cases including problem-provided samples and 10 synthesized test cases generated using AceCode-RM-32B [67].</p>
<p>To avoid compiler interaction latency and maintain symbolic traceability, test case outcomes are determined by simulating execution through LLM prompting within the judge agent J , following the CodeSim protocol [18].This structured feedback enables agents to identify failures, receive localized corrections, and improve reasoning over iterations.</p>
<p>Verifier Agent V. Due to linguistic complexity and varying answer specification formats, a response may be incorrect even when the underlying reasoning or open-ended response is valid.For instance, answer formats may require multiple-choice letters (e.g., "(A)" or "Choice B"), boxed numerical values (e.g., " 42 "), or final answers in specific units (e.g., "5 km" or "12%").An additional round of answer extraction and formatting helps reduce such mispredictions [44].This challenge is even more pronounced in code generation tasks, where predicted code may fail to execute or not pass all test cases.To mitigate this, Xolver includes a Verifier Agent V, which operates differently based on the output type.For math and QA problems, V extracts the final reasoning T F , response R F , and answer y from the response associated with the top-ranked entry BESTRESPONSE in D S , ensuring adherence to the expected output format.For executable code, Xolver invokes an external debugger (LDB [70]), where V interacts with a Python runtime to capture execution feedback and iteratively fix runtime errors.</p>
<p>Tools T .Integrating natural language reasoning with tools like Python execution is a proven way to boost performance on complex reasoning tasks [37,57].We observe that even advanced reasoning models often make mistakes in intermediate steps, particularly when computations become non-trivial.To address this, each dynamic agent a j is explicitly instructed to use Python execution during reasoning when needed.While Xolver currently limits T to Python, our prompting strategy is tool-agnostic, allowing an interface for future extensions to richer toolsets [32,33].</p>
<p>All agents are built using the underlying LLM.All prompts are 0-shot and provided in Appendix A.</p>
<p>Memory Components</p>
<p>Episodic Memory D E .Xolver maintains two forms of episodic (long-term) memory: (1) an external memory corpus D ext E = {(q ′ , T ′ , R ′ )}, which consists of past problem instances q ′ , their corresponding reasoning traces T ′ (optional), and solution responses R ′ ; and (2) the internal parametric memory encoded in the weights of the agent-specific language model LLM j .We define a general retrieval operator R(D E ) that returns a set of K examples relevant to the query q.When D ext E is available, retrieval is conducted using similarity-based search (e.g., BM25):
R(D E ) = {(q ′ k , T ′ k , R ′ k )} K k=1 ← Retrieve j (q, D ext E ).
Otherwise, Xolver falls back to internal self-retrieval by sampling from the agent model itself:
R(D E ) = {(q ′ k , T ′ k , R ′ k )} K k=1 ∼ LLM j (q).
In the case of an external episodic memory, D E can also be updated with UPDATEEPISODICMEMORY by adding the top-ranked reasoning and response from D S , paired with the problem q, into the external corpus , s i,j ) from the judge agent J , where
D ext E . That is, D ext E ← D ext E ∪ (q, T,T (i,j) S
is a natural language explanation and s i,j is a scalar score reflecting the quality of the tuple (T j i , R j i ).After collecting the new outputs
τ j i = (T j i , R j i , S j i , a j ), j = 1, . . . , m,(RUNAGENTS)
we form the candidate pool M = D S ∪ {τ 1 i , . . ., τ m i }.We then update the fixed-size shared memory by keeping only the top-m tuples by score
D S ← TopK M, m; key(e) = s(e) , ,(UPDATESHAREDMEMORY)
where s(e) extracts the scalar score from e = (T, R, (T S , s), a).</p>
<p>This replacement mechanism ensures that D S always contains exactly m entries with the highest observed scores across all iterations.By maintaining only the strongest reasoning-response-feedback tuples, the shared memory facilitates knowledge transfer between agents and across iterations, enabling collaborative improvement through exposure to diverse high-quality solutions.</p>
<p>Inference Protocol</p>
<p>Algorithm 1 Xolver Inference Protocol 1: Input: Query q, Tools T , Episodic Memory D E , parameters m, k, I 2: Init: D S ← ∅ 3: A ← PLANNER(q, m) 4: for i = 0 to I do 5:
{C i } m c=1 ← BUILDCONTEXT(A, D E , D S , q, i) 6: {τ j i } m j=1 ← RUNAGENTS(A, C i , T , J ) 7: D S ← UPDATESHAREDMEMORY(D S , {τ j i }) 8:
if CONVERGED(D S ) then end if 11: end for 12: y ← V(BESTRESPONSE(D S )) 13: UPDATEEPISODICMEMORY(D E , q, D S ) 14: Return y Algorithm 1 summarizes the Xolver inference protocol, which operates in three structured stages.Stage-1, which emulates initialization with prior experience, involves the planner constructing a team of agents A (lines 2-3).Stage-2, embodying symbolic experience accumulation and refinement, iterates for I rounds (lines 4-10).In each round, all agents receive access to D S and D E , build their contexts, and generate structured trajectories and responses (D E is only used for context construction at the first iteration).These are evaluated by the judge agent J , and D S is updated with the resulting feedback tuples (line 7).Upon convergence or after I rounds, Stage-3 invokes the verifier agent V, which extracts the final answer from the top-ranked entry in D S (line 11), and updates D E with the new experience.</p>
<p>Experiments</p>
<p>Evaluation Setup</p>
<p>Evaluation Benchmarks We evaluate Xolver across five diverse and challenging benchmarks covering both mathematical and coding reasoning.For math, we use GSM8K [6], Math-500 [15], and the AIME 2024 [34] and 2025 [35], comprising high-school level competition problems requiring multi-step symbolic reasoning.For coding, we use LiveCodeBench (v5) [20], a dynamic benchmark that ensures no data leakage by periodically releasing new problems.These benchmarks span arithmetic, algebra, number theory, geometry, combinatorics, and algorithmic problem solving.</p>
<p>Baselines and Metrics</p>
<p>We compare Xolver against directly using leading reasoning models-(a) proprietary models: Gemini 2.5 (Pro and Flash Think) [7], Grok-3 Beta Think and Grok-3 Mini (Beta) Think [63], Claude 3.7 Sonnet Think [2], o1 [41], o3-mini, o3, and o4-mini [42]; (b) openweight LLMs, e.g., Qwen3-235B [48], QWQ-32B [49], and DeepSeek-R1 [8]; (c) math-and codespecialized models, e.g., AlphaOne [68], OpenMathReason [37], rStar-Math [12], rStar-Coder [30], OpenCodeReason [1], and Kimi-K1-1.6[22].We also compare with (d) agents or frameworks: Self-Reflexion [52], agentic search based framework Search-o1 [28], specialized tool based framework OctoTools [33] which excels general purpose agent platforms outperforming AutoGen or LangChain, cross-problem baseline framework CheatSheet [55], and multi-agent code generation framework CodeSim [18], which leverage refinement, retrieval or online search, fine-grained tool augmentation in addition to online search, dynamic memory updates after solving new problems, and multi-agent reasoning techniques respectively.For agent-based baselines (d), we reproduce results using the same backbone LLMs as Xolver for fair comparison; for model-based baselines (a-c), we report official results from their technical reports or corresponding benchmark leaderboards.As evaluation metric, we use accuracy using GPT-4o [40] for math problems, and pass@1 for code tasks.</p>
<p>Inference Details</p>
<p>We use both open-weight QWQ-32B [48] and proprietary o3-mini (medium and high) [42] as the backbone.To mitigate performance variance inherent in single-run evaluations, we report the average accuracy and pass@1 metric, calculated by averaging 32 inference runs for competitive benchmarks LIVECODEBENCH and AIME '25, and 16 runs for AIME '24, ensuring standard deviation within ∼ 1% (Appendix D.1).For simpler tasks GSM8K and MATH-500, we follow DeepSeek-v3 [29], using a single greedy-decoded generation.By default, we set temperature to 0.2, number of agents m = 3, and max iterations I = 2. Xolver iteration terminates either when the maximum number of iterations I is reached, or when all entries in the shared memory D s converge-i.e., they achieve perfect scores of 1.0 (correct) for math tasks, or pass all test cases (both sample and synthesized) for code tasks.As the external retrieval corpus D ext E in coding task, we collect a 9-million-token dataset of algorithmic code problems and their C++ solutions with explanations from GitHub2 (details in Appendix C).For math, we use the OPENMATHREASON dataset [37] as D ext E .We evaluate two variants of Xolver: (i) Xolver with in-competition cross-problem experience (Xolver (+)), which dynamically updates the episodic memory after solving each problem to utilize accumulated knowledge across problems; and (ii) Xolver (-), which keeps the episodic memory static, focusing solely on problem-specific experience.By default, we refer to Xolver (+) as our method if not specified otherwise.</p>
<p>Main Results</p>
<p>Table 1 evaluates Xolver across diverse mathematical and coding reasoning benchmarks, highlighting its effectiveness compared to state-of-the-art LLMs, specialized models, and other frameworks.</p>
<p>Strong Gains Across Benchmarks Overall, Xolver consistently delivers significant improvements over the backbone LLMs' standard LongCoT prompting.Both the problem-specific Xolver (-) and the cross-problem Xolver (+) variants outperform their respective backbone LLM (LongCoT) baselines across all datasets.For example, with the o3-mini-medium backbone, Xolver (+) improves from 75.8 to 93.8 on AIME'24, and from 66.3 to 79.6 on LiveCodeBench, while the QWQ-32B backbone sees gains from 78.1 to 89.9 on AIME'24 and from 63.4 to 76.2 on LiveCodeBench.</p>
<p>Surpassing Prior Agents Compared to previous frameworks such as Search-o1, OctoTools, and CheatSheet, Xolver demonstrates consistent and significant gains.With o3-mini-medium, Xolver (+) improves over the best baseline by +12.7 points on AIME'25 and +13.5 points on LiveCodeBench, highlighting its superior reasoning capabilities by integrating diverse forms of experience.</p>
<p>In Comparison to Leading LLMs Despite using weaker backbones, Xolver, specifically (+) variant, matches or surpasses proprietary frontier LLMs like o3 and o4-mini-high on key benchmarks.With o3-mini-medium, Xolver (+ outperforms o4-mini-high on AIME '24 (93.8  exceeds it on LiveCodeBench (87.3 vs. 69.5),demonstrating that structured reasoning and dynamic memory can rival even the strongest closed-source models.</p>
<p>Backbone Agnostic Improvements from Xolver are consistent across different backbone LLMs.Both o3-mini-medium and QWQ-32B benefit substantially from the framework, demonstrating its model-agnostic design.For example, on GSM8K, Xolver (+) achieves 97.1 (o3-mini-medium) and 98.0 (QWQ-32B), both surpassing baseline variants by significant margins.</p>
<p>Effectiveness of Dynamic Episodic Memory While both variants excel, the cross-problem variant Xolver (+) consistently outperforms the problem-specific version Xolver (-) in all benchmarks.On average, episodic memory integration yields a +3.5 point improvement across both backbones and datasets where the largest gain is +7.7 points with o3-mini-medium on coding (LiveCodeBench).</p>
<p>Scales with Backbone LLM's Strength Xolver's performance scales consistently with the strength of its backbone LLM.With o3-mini-high, it sets new state-of-the-art results across all benchmarks (98.1 on GSM8K, 94.4 on AIME'24, 93.7 on AIME'25, 99.8 on Math-500, and 91.6 on LiveCodeBench).</p>
<p>Ablation and Analyses</p>
<p>Ablations: Quantifying Component Impact In Figure 3, we present an ablation study quantifying the contribution of individual components in Xolver to overall performance, measured by the average performance drop on math reasoning (Math Avg) and programming (LiveCodeBench) tasks.Each component plays a necessary role, with the most significant degradation observed when removing Multi-iteration and Multi-Agent followed by Judge Agent, highlighting their central importance in complex reasoning and code synthesis.In contrast, removing components like Verifier/Debugger and Tool leads to comparatively smaller drops, suggesting a more auxiliary role in the overall system.Likewise self-retrieval can also work in-place of external retrieval with some drop in accuracy.</p>
<p>M u lt i-it e r a ti o n M u lt i-A g e n t Ju d g e A g e n t E x te</p>
<p>Impact of Agent Count and Iterations, and Emerging Benefits of Collaboration</p>
<p>We analyze the effect of varying the number of agents and reasoning iterations on Xolver's performance.In a controlled setup, we fix one variable (e.g., 3 agents or 2 iterations) and incrementally increase the other.As shown in Figure 4, performance improves consistently on both AIME '25 and LIVECODEBENCH with more agents or iterations, highlighting the advantage of collaborative and iterative problem solving.To probe deeper, we conduct a budget-controlled experiment on the AIME '25 dataset, where the total reasoning budget (i.e., number of agents × number of iterations) is fixed.While iterative reasoning remains a crucial factor for Xolver's performance, we find that increasing the number of agents-particularly beyond a minimum of three-yields additional, emergent improvements, leading to over a 4% performance gain.This suggests that agent diversity and parallelism complement iterative depth, together producing stronger collaborative problem-solving benefits than either alone.External Retrieval &gt; Self-Retrieval &gt; No Retrieval, indicating that external retrieval significantly enhances Xolver's performance.We note that for code tasks, although the external retrieval corpus contains solutions written in C++-a different language from the target Python-external retrieval still provides a substantial performance boost.Nonetheless, while self-retrieval results in a notable performance drop compared to external retrieval, it still outperforms the no-retrieval baseline with notable margins, serving as a viable alternative when external resources are unavailable.</p>
<p>No Retrieval Self-Retrieval External Retrieval</p>
<p>Prealgebra</p>
<p>Math-500 Accuracy by Subject Category</p>
<p>CheatSheet (o3-mini-medium) CheatSheet (QWQ 32B) Xolver (o3-mini-medium) Xolver (QWQ 32B) Fine-grained Performance Analysis We perform a fine-grained analysis of Xolver's performance across both MATH-500 and LIVECODEBENCH, as shown in Figure 6  Can a Self-Judge Replace a Judge Agent?We analyze the effect of different judging mechanisms on Xolver's performance by comparing two setups: (1) self-judging, where each dynamic agent evaluates its own response through self-reflection without altering its role, and (2) external judging, where a separate judge agent is used to assess the responses.We find that self-judging agents tend to be biased in favor of their own outputs, occasionally validating incorrect solutions.This self-bias leads to a noticeable drop in overall performance-specifically, a 9.9% decrease in coding tasks and a 3.88% decrease in math tasks, on average.</p>
<p>GSM8K AIME '24 MATH-500 LiveCodeBench</p>
<p>Cost Analysis and How</p>
<p>Long Do Xolver Agents Think?We perform a detailed analysis of token usage in Figure 8, reporting input, reasoning, and output statistics for Xolver (QWQ-32B) across all datasets.</p>
<p>Our LLM token usage has computational complexity of O(mI), where m is the number of agents and I is the number of reasoning iterations.However, the run-time complexity remains O(I) since the dynamic agents operate in parallel.This is significantly more efficient than the self-consistency [59], which typically require 32-64 generations per example, as well as the baseline CheatSheet framework, which incurs a memory update complexity of O(n 2 )-quadratic in the test dataset size-due to usefulness estimation over all previous examples after solving each new example.As a multi-agent system, Xolver allocates a majority of its tokens to context sharing and inter-agent communication, while approximately 25% are spent on actual reasoning steps.</p>
<p>Nonetheless in Figure 8, we also compare the total token usage of Xolver with a single agent reasoning framework Search-o1 using tiktoken for o3-mini-medium and AutoTokenizer for QWQ-32B for token count.As expected, Xolver incurs higher token costs-approximately 1.5× that of Search-o1-due to its collaborative and iterative multi-agent reasoning.However, this moderate increase represents a highly efficient trade-off given the substantial performance improvements observed.As shown in Figure 6 and Figure 7, Xolver achieves remarkable gains across both domains, including a +32.3% absolute improvement on hard coding problems with o3-mini-medium and 9.05% accuracy boosts across all Math-500 categories with QWQ-32B.These findings demonstrate that Xolver 's slightly higher reasoning cost is well-justified by its superior, generalist performance across diverse problem-solving scenarios.</p>
<p>Does Data Shuffling Affect Xolver (+) Performance?Xolver (+) updates its external memory incrementally after solving each new problem.To examine whether the order of test instances impacts performance, we conduct an ablation study by randomly shuffling the sequence of problems in each task.This helps determine if there is any dependency on the data order.Results in Appendix D.3 show that Xolver exhibits minimal performance variation across different shuffles, with a standard deviation of approximately 1 within only 5 runs, indicating that its performance is largely stable regardless of data ordering.</p>
<p>Qualitative Examples</p>
<p>In Appendix B, we present qualitative examples along with all the prompts of full-cycle Xolver on both math and code reasoning tasks.These examples illustrate how Xolver initiates reasoning from external or self-retrieved exemplars, engages in multi-agent collaboration, and incrementally accumulates experiences through inter-agent propagation and refinement.The full interaction trace highlights Xolver's ability to iteratively decompose, solve, and adapt solutions across reasoning steps, showcasing its capacity for dynamic knowledge construction and generalizable problem solving.Error Rate (%)</p>
<p>More Error Analysis in Math and Code</p>
<p>In Figure 9, we present an error analysis across both math and code tasks that goes beyond simple accuracy or pass@1 metrics.While Xolver significantly improves reasoning and generation capabilities in both domains, both (o3-mini-medium and QWQ-32B) backbone LLMs can still produce solutions that are syntactically correct yet semantically flawed, resulting in failed executions due to incorrect reasoning, incomplete logic, unoptimized implementations, or misaligned tool usage.In code tasks, failure modes include incorrect final code, time limit exceeded (TLE), runtime errors (RTE), and syntax issues.In math tasks, remaining errors are primarily due to flawed logical derivations or faulty intermediate calculations.Although Python-based tools are available, such calculation errors often occur when agents choose not to invoke these tools-highlighting that tool usage remains decoupled from the model's core reasoning process (see Appendix A for our prompt design).These findings provide insights for future improvements by exposing the variety of failure modes across domains, and further emphasize the importance of robust self-verification and refinement mechanisms, as employed by Xolver.</p>
<p>Dynamics of Reasoning Patterns in Xolver Traces</p>
<p>To understand how Xolver adapts its reasoning process to perform complex reasoning, we analyze the dynamics of reasoning pattern frequencies across difficulty levels in LiveCodeBench, as shown in  To further understand the reasoning and problem-solving strategies behind our multi-agent, iterative framework Xolver, we conduct an in-depth analysis combining qualitative runtime inspection with controlled experiments.We begin by manually studying Xolver's agent interaction traces on AIME '25 and Live-CodeBench.These case studies reveal that at each iteration, dynamic agents attempt to improve upon earlier failures by leveraging Judge agent feedback and by aligning with top-ranked outputs stored in the shared memory D S .This process results in progressively refined outputs, increased agent alignment, and eventual convergence toward correct solutions.</p>
<p>To verify this behavior systematically, we conduct a controlled experiment across both math and code tasks.We instantiate two dynamic agents with complementary strengths: a Coder agent and a Mathematician agent, each proficient in one domain but suboptimal in the other.We then measure their performance and agreement across iterations-defined as the percentage of problems in which both agents independently produce the same correct answer (for math) or code that passes the same test cases (for code).As shown in Figure 10, both agents demonstrate consistent accuracy improvements over time, accompanied by a rising agreement rate.This not only illustrates mutual influence and learning-by-alignment but also validates the emergence of collaborative synergy.</p>
<p>Crucially, we observe that the presence of the Judge agent plays a vital role in this convergence process.When the Judge agent is removed-as shown in our first ablation-performance degrades significantly.These findings collectively affirm that Xolver's iterative memory-sharing, feedbackdriven refinement, and role-specialized agents contribute to its strong reasoning performance across domains, making it a compelling framework for general-purpose, self-improving problem solving.</p>
<p>Related Work</p>
<p>Memory-Augmented and Retrieval-Augmented LLMs.Memory-augmented language models have evolved from static retrieval systems like RAG [25] and REALM [14] to dynamic approaches such as Reflexion [53], MemGPT [43], and Scratchpads [39].However, these systems operate on isolated tasks, lack cross-problem experience accumulation, and employ single-agent architectures.Xolver addresses these limitations through a novel dual-memory architecture combining episodic long-term memory with dynamic intermediate memory, enabling specialized agents to collectively build and refine experiential knowledge.While prior work has explored cross-trial information sharing [69,53] and multi-source memory integration [66], these approaches remain confined to single-agent settings.Our framework creates a persistent knowledge base through multi-agent collaboration [10], allowing agents to accumulate expertise from solved problems and leverage collective experience for future tasks.</p>
<p>Multi-Agent Problem Solving.Multi-agent LLM systems address the limitations of single models by leveraging collaborative approaches for improved reliability and task specialization [13,10].From early frameworks like CAMEL [27] with fixed role assignments, the field progressed to dynamic role adjustment in AgentVerse [5] and code execution in AutoGen [62].Recent advances include layered agent networks in DyLAN [31], multi-agent code generation and problem solving [17,18] and multi-agent debate frameworks [9,50,54].While these systems demonstrate effective collaboration, they operate on isolated problems without cross-task experience accumulation.Xolver introduces dual-memory architecture, holistic experience integration, judge-mediated selection, and continuous episodic corpus expansion-transforming single-problem solvers into experience-aware agents.</p>
<p>LLM Reasoning Enhancement Techniques.Various techniques have emerged to enhance LLM reasoning capabilities beyond standard prompting.Chain-of-Thought [61] introduced step-by-step reasoning, Self-Consistency [58] explores multiple reasoning paths with majority voting, and Tree of Thoughts [64] enables exploration of reasoning branches-yet all remain limited to single-pass generation.Self-reflective approaches like Reflexion [53] enable iterative improvement but operate within single tasks, while retrieval-enhanced methods like CheatSheet [55] and Search-o1 [28] remain confined to single-agent architectures.These approaches share fundamental limitations: no cross-problem learning, no persistent memory, and no multi-agent collaboration.Xolver unifies these enhancements within a multi-agent framework where agents collaboratively refine solutions through judge-mediated iterations and leverage dual memory systems for cross-problem learning.</p>
<p>Tool-Augmented Reasoning.Tool integration extends LLM capabilities beyond language processing.Early systems like WebGPT [38] introduced single-tool integration, while PAL [11] enabled code execution for mathematical reasoning.Multi-tool frameworks evolved with ReAct [65] interleaving reasoning with actions, Chameleon [32] composing multiple tools, and OctoTools [33] standardizing tool planning-yet all remain limited to single-agent execution without iterative refinement or crossproblem learning.Xolver transforms tool use into a collaborative, memory-enriched ecosystem where agents collectively execute tools, share outcomes, and accumulate successful strategies across problems-creating an adaptive framework that evolves with experience.</p>
<p>Conclusion</p>
<p>We propose Xolver, an open-source, multi-agent inference framework for complex reasoning tasks that enables holistic experience learning.Xolver integrates (1) episodic retrieval from external or self-parametric memory, (2) an evolving intermediate shared memory that accumulates and reuses high-quality reasoning traces, (3) tool invocation for complex computations, (4) collaborative multiagent reasoning, (5) self-evaluation and iterative refinement, (6) verification or external debugging, and (7) propagation of learned strategies across problems.These components collectively support adaptive, experience-informed problem solving.Despite its strong performance, Xolver faces limitations in computational efficiency, with substantially higher token consumption than traditional approaches, and remains dependent on the quality of backbone LLMs.Future work aims to optimize agent interactions to reduce resource requirements, enhance robustness to variations in model quality, improve retrieval filtering [60,51,45], develop better RAG strategies [19,47,24], and extend the framework to more diverse reasoning domains beyond mathematics and programming.In addition, we plan to integrate advanced external verifiers of reasoning [36] to further enforce validity through structured guardrails.By addressing these challenges, we aim to further advance the development of experience-aware reasoning systems that can approach the adaptability and integrated knowledge use of human experts.</p>
<p>A Lists of Prompts</p>
<p>This section provides the list of prompts for planning, dynamic, judge, verifier and reasoning segmentation we have used in the experimental period.These are crucial to ensure the reproducibility [23] of the framework Xolver.</p>
<p>A  --------------------------------------If external retrieval: You were also given a couple of similar problems to the problem above along with their reasoning and solutions to aid you in solving the problem at hand.Here are the similar problems you were given:</p>
<p>retrieved_dict[query['problem_id']]['retrieval_text']</p>
<p>If self-retrieval: Further, recall a relevant and distinct problem (different from the problem mentioned above) along with its reasoning and solution.</p>
<p>--------------------------------------And here was your original response: --------------------------------------  --------------------------------------If coding task: Think carefully about where you went wrong, relating with responses in the response store.Then, try to fix the solution producing a thought later reply with a {Python} solution to be executed and judged again.
query[['role']]['original_thought','original_response']If iteration i ≥ 1 (i.e.,
Make sure to wrap your code in <code>python</code>block and Markdown delimiters, and include exactly one block of code with the entire solution (in the final code step).</p>
<p>--------------------------------------If math task: Think carefully about where you went wrong, relating with responses in the response store.Then, try to fix the solution producing a thought later reply with a solution to be executed and judged again.You can integrate a {Python} tool to execute the calculations after replying your solution if required.</p>
<p>Make sure to wrap your final answer in \boxed{} block with the entire solution (in the final answer step).</p>
<p>Prompt for FINAL REASONING SEGMENTATION</p>
<p>Below is a thought for solving a question.For the segment between the <unannotated> and </unannotated> tags, figure out what is reasoning pattern used in that segment like problem rephrasing, new approach, self-evaluation, verification, backtracking, subgoal setup, solving a simpler problem first, or something else.Then your task is to identify the reasoning pattern used in the unannotated segment.Rewrite the unannotated segment in the following format:</p>
<p><content> The text within the unannotated segment that corresponds to the pattern.</content> <reasoning> Reasoning for what the pattern should be for the content </reasoning> <pattern> <em>single</em> pattern name </pattern> Thought: {thoughts}</p>
<p>B Qualitative Examples</p>
<p>The subsequent section presents some qualitative examples-agentic interaction breakdown on how Xolver can approach and solve a problem of math and coding tasks when it encounters.</p>
<p>Example for CORRECT MATH TASK GREEN : CORRECT ANSWER.RED : WRONG ANSWER.</p>
<p>Query: Bob is in charge of doing laundry for a large hotel.Each room has two sheets, one comforter, twice as many pillow cases as sheets and twice as many towels as pillow cases.How many pieces of laundry are there in 80 rooms?Make sure to wrap your final answer in \boxed{} block with the entire solution (in the final answer step).</p>
<p>Iteration 1</p>
<p>Mathematical Modeler: Each room contains 2 sheets, 1 comforter, 2 pillow cases (which is twice the number of sheets), and 4 towels (which is twice the number of pillow cases).Hence, the total number of laundry items in each room is: 2 + 1 + 2 + 4 = 9 pieces of laundry.When considering 80 rooms, the total number of pieces of laundry is: 80 × 9 = 720 pieces of laundry.Thus, the final answer is: 720 .</p>
<p>Judge: The candidate's solution contains an error in calculating the number of pillow cases and towels per room.Here's the breakdown: Sheets: 2 (correct).Comforter: 1 (correct Mathematical Modeler: Each room contains 2 sheets, 1 comforter, 2 pillow cases (which is twice the number of sheets), and 4 towels (which is twice the number of pillow cases).Hence, the total number of laundry items in each room is: 2 + 1 + 4 + 8 = 15 pieces of laundry.When considering 80 rooms, the total number of pieces of laundry is: 80 × 15 = 1200 pieces of laundry.Thus, the final answer is: 1200 .This confirms the accuracy of the revised calculation.</p>
<p>Judge: The candidate's final answer is correct, and the mathematical calculations align with the problem's requirements: 1. Sheets: 2 (correct).2. Comforter: 1 (included in the total).3. Pillow Cases:</p>
<p>The problem states "twice as many pillow cases as sheets."Since there are 2 sheets, this should be 2 × 2 = 4.The candidate correctly uses 4 pillow cases in their total calculation (despite a typographical inconsistency in the explanation, where they initially wrote "2 pillow cases").4. Towels: "Twice as many towels as pillow cases" gives 2 × 4 = 8 (correct).</p>
<p>The candidate's total per room is 2 + 1 + 4 + 8 = 15 (correct), leading to 80 × 15 = 1200 (correct).</p>
<p>While the explanation contains a minor inconsistency in wording ("2 pillow cases" instead of 4), the numerical calculations are accurate.Since the final answer is correct and the mathematical steps resolve the inconsistency, the solution is valid.</p>
<p>Score: 1.</p>
<p>Numerical Analyst: Based on the information provided, we know that each room includes 2 sheets, 1 comforter, 4 pillow cases (computed as 2 × 2), and 8 towels (since 4 × 2 = 8).Adding these together, the total number of laundry items required for one room is: 2 + 1 + 4 + 8 = 15 pieces.Multiplying by the total number of rooms, the overall amount of laundry for 80 rooms is: 80 × 15 = 1200 .</p>
<p>Although the other agents correctly determined the number of laundry items required for each room, there was an error in the concluding step-calculate the total number of laundry pieces.</p>
<p>Judge: The candidate's calculations and final answer are correct: sheets: 2 (given), comforter: 1 (given), pillow cases: 2 × 2 = 4 (twice the sheets), towels: 2 × 4 = 8 (twice the pillow cases), total per room: 2 + 1 + 4 + 8 = 15 (correct), total for 80 rooms: 80 × 15 = 1200 (correct).</p>
<p>Score: 1.</p>
<p>Mathematician: According to the provided details, every room is equipped with 2 sheets, 1 comforter, 4 pillow cases (calculated as 2 × 2), and 8 towels (since 4 × 2 = 8).Summing these, the total number of laundry items for one room is: 1 + 4 + 8 = 13 pieces of laundry.</p>
<p>Multiplying by the number of rooms, the total quantity for 80 rooms becomes: 80 × 13 = 1040 .</p>
<p>Judge: The candidate incorrectly omitted the sheets in their final sum.Here's the breakdown: 1. Sheets: 2 (given but not included in the candidate's calculation).2. Comforter: 1 (included).3. Pillow Cases: 2 × 2 = 4 (correct).4. Towels: 2 × 4 = 8 (correct).The candidate's total per room was 1 + 4 + 8 = 13, but the correct total should include the sheets: 2 + 1 + 4 + 8 = 15.Thus, the total for 80 rooms should be 80×15 = 1200, not 1040.The error stems from excluding the sheets in the summation.</p>
<p>Score: 0.
DS 2 rank: [Mathematical Modeler, Numerical Analyst, Mathematician] Iteration 3
Mathematical Modeler: From the details provided, it is clear that each room contains 2 sheets, 1 comforter, 4 pillow cases (as 2 × 2 = 4), and 8 towels (calculated as 4 × 2 = 8).Adding these together, the total number of laundry items per room amounts to: 2 + 1 + 4 + 8 = 15 items.Consequently, for 80 rooms, the total number of laundry pieces becomes: 80 × 15 = 1200 .</p>
<p>I agree with the other agent's corrected calculation.</p>
<p>Judge: The candidate's solution is mathematically accurate and complete: sheets: 2 (correct), comforter: 1 (correct), pillow cases: 2 × 2 = 4 (twice the sheets), towels: 2 × 4 = 8 (twice the pillow cases), total per room: 2+1+4+8 = 15 (correct), total for 80 rooms: 80×15 = 1200 (correct).</p>
<p>Score: 1.</p>
<p>Numerical Analyst: Given the information, we know that each room includes 2 sheets, 1 comforter, 4 pillow cases (computed as 2 × 2), and 8 towels (since 4 × 2 = 8).Adding these together, the total number of laundry items required for one room is:
2 + 1 + 4 + 8 = 15 pieces.
Multiplying by the total number of rooms, the overall amount of laundry for 80 rooms is:
80 × 15 = 1200 .
Although the other agent correctly determined the number of laundry items required for each room, there was an error in the concluding step.Specifically, they incorrectly used 80 × 13 instead of the appropriate multiplication of 80 × 15 to calculate the total number of laundry pieces.</p>
<p>Judge: The candidate's solution is fully correct: sheets: 2 (given), comforter: 1 (given), pillow cases: 2 × 2 = 4 (twice the sheets), towels: 2 × 4 = 8 (twice the pillow cases), total per room:</p>
<p>Mathematician: According to the given details, each room contains 2 sheets, 1 comforter, 4 pillow cases (calculated as 2 × 2), and 8 towels (determined by 4 × 2).Summing these amounts, the total number of laundry items per room is: 2 + 1 + 4 + 8 = 15 pieces of laundry.To find the total for 80 rooms, we multiply: 80 × 15 = 1200 .</p>
<p>I concur with the other agents' results and the computations they presented.</p>
<p>Judge: The candidate's solution is fully correct and aligns with the problem's requirements: sheets: 2 (given), comforter: 1 (given), pillow cases: 2 × 2 = 4 (twice the sheets), towels: 2 × 4 = 8 (twice the pillow cases), total per room: 2 + 1 + 4 + 8 = 15 (correct), total for 80 rooms: 80 × 15 = 1200 (correct).All calculations are accurate, and the final answer matches the problem's constraints.</p>
<p>Score: 1.
DS 3 rank: [Mathematician, Mathematical Modeler, Numerical Analyst]
Example for CORRECT CODING TASK GREEN : CORRECT SOLUTION.RED : WRONG SOLUTION.</p>
<p>Query: Yarik is a big fan of many kinds of music.But Yarik loves not only listening to music but also writing it.He likes electronic music most of all, so he has created his own system of music notes, which, in his opinion, is best for it.</p>
<p>Since Yarik also likes informatics, in his system notes are denoted by integers of Yarik has already chosen n notes that he wants to use in his new melody.However, since their integers can be very large, he has written them down as an array a of length n, then the note i is bi = 2 a i .The integers in array a can be repeated.</p>
<p>The melody will consist of several combinations of two notes.Yarik was wondering how many pairs of notes bi, bj (i &lt; j) exist such that the combination (bi, bj) is equal to the combination (bj, bi).In other words, he wants to count the number of pairs (i, j)
(i &lt; j) such that b b j i = b b i j .
Help him find the number of such pairs.</p>
<p>Input</p>
<p>The first line of the input contains one integer t (1 ≤ t ≤ 10 4 ) -the number of test cases.</p>
<p>The first line of each test case contains one integer n (1 ≤ n ≤ 2 • 10 5 ) -the length of the arrays.</p>
<p>The next line contains n integers a1, a2, . . ., an (1 ≤ ai ≤ 10 9 ) -array a.</p>
<p>It is guaranteed that the sum of n over all test cases does not exceed 2 • 10 5 .</p>
<p>Output</p>
<p>For each test case, output the number of pairs that satisfy the given condition.Sample Input 1: Make sure to wrap your code in <code>python</code>block and Markdown delimiters, and include exactly one block of code with the entire solution (in the final code step).</p>
<p>Iteration 1</p>
<p>Implementation Specialist: To solve this problem, we need to determine the number of pairs of notes j holds.This equation can be broken down into two main cases.The first case is when the values are the same, meaning ai = aj.In this situation, the equation trivially holds because both sides will be identical.The number of such pairs is given by the combination formula C(n, 2) = n(n−1) 2 for each group of identical values.The second case occurs when the values are different but satisfy a special condition: the equation holds when one value is 1 and the other is 2.This is derived from the mathematical simplification of the equation ai • 2 a j = aj • 2 a i , which only holds true for ai = 1 and aj = 2 (or vice versa) when ai ̸ = aj.Programmer: To solve this problem, we need to determine the number of pairs of notes such that the combination of two notes (bi, bj) results in the same integer as the combination (bj, bi).The notes are given as bi = 2 a i , and we are looking for pairs (i, j) where b
b j i = b b i j . The condition b b j i = b b i j can be simplified to checking if ai • 2 a j = aj • 2 a i ,
which holds true in two scenarios: first, when ai = aj, producing identical pairs; and second, when one value is 1 and the other is 2, creating valid cross pairs.To count the identical pairs, for each unique value x in the array, we use the combination formula count 2</p>
<p>, where count is the frequency of x.For cross pairs, which occur specifically between values 1 and 2, the number of such pairs is calculated as the product of the counts of 1 and 2. .By applying logarithms and using the properties of exponents, for notes defined as bi = 2 a i and bj = 2 a j , the condition simplifies to ai • 2 a j = aj • 2 a i .Two key observations arise from this: first, if ai = aj, the equation holds true, meaning all pairs of identical values satisfy the condition; second, the equation also holds when one value is 1 and the other is 2, since 1 • 2 2 = 2 • 2 1 simplifies to 4 = 4.The algorithm to find the number of such pairs involves two parts.For pairs with the same value v, we count the number of pairs using the combination formula C(n, 2) = n(n−1)</p>
<p>2</p>
<p>, where n is the frequency of v.For cross-value pairs where one note corresponds to 1 and the other to 2, the number of valid pairs is simply the product of their counts., where each note is given by bi = 2 a i .We are interested in counting pairs (i, j) with i &lt; j that satisfy this condition.By applying properties of exponents and substituting bi = 2 a i and bj = 2 a j , the condition simplifies to checking when 2 a i a i = 2 a j a j .There are two key observations: first, if ai = aj, the condition is automatically met; second, pairs where one value is 1 and the other is 2 also satisfy the condition, since 2 1 1 = 2 and 2 2 2 = 2.The algorithm involves counting the frequency of each ai, then calculating the number of valid pairs for identical values using the combination formula f 2 , where f is the frequency of the value.Finally, to account for the special case of pairs between 1 and 2, we add the product of their counts to the total.Programmer: I agree with the other agents that, to solve this problem, we need to determine the number of valid pairs of notes such that the combination of two notes (bi, bj) results in the same integer as the combination (bj, bi).This is equivalent to finding pairs (i, j) where b
b j i = b b i j .
The key insight is that this equation holds under two conditions: first, when the exponents ai and aj are equal, the pairs (bi, bj) will always satisfy the equation; second, when one exponent is 1 and the other is 2, the equation also holds.To solve the problem, the approach involves three steps.First, use a frequency counter to count the occurrences of each value in the array.Second, for each value x, compute the number of valid pairs among identical values using the combination formula f 2 , where f is the frequency of x.Third, calculate the number of specific pairs where one value is 1 and the other is 2 by multiplying their counts., where bi = 2 a i and bj = 2 a j .This equation simplifies to ai • 2 a j = aj • 2 a i .To solve this efficiently, we follow several steps.First, for each ai, we perform prime factorization, expressing it as 2 y × x, where x is the odd part of ai and y is the exponent of 2 in its factorization.Next, we generate a key for each ai in the form (x, y − ai).This key is designed such that if two numbers ai and aj share the same key, they satisfy the equation ai • 2 a j = aj • 2 a i .We then use a frequency dictionary to count the occurrences of each key.Finally, for each key, we compute the number of valid pairs using the combination formula f 2 , where f is the frequency of that key.Implementation Specialist: I concur with the other agent that to tackle this problem, our goal is to find the number of valid pairs of notes (bi, bj) such that raising one note to the power of the other yields the same result when the order is reversed; that is, pairs (i, j) satisfying b
b j i = b b i j .
Given that each note can be expressed as bi = 2 a i , the problem reduces to analyzing the equation ai • 2 a j = aj • 2 a i .To approach this effectively, we begin by decomposing each exponent ai into its prime factors, specifically writing it as 2 y × x, where x is the odd component and y indicates the power of two within the factorization.Using this factorization, we create a unique key for each ai defined by the pair (x, y − ai).This construction ensures that any two exponents sharing the same key satisfy the original equation.After generating these keys for all elements, we count their frequencies using a dictionary.Finally, to determine the number of valid pairs, we apply the combination formula f 2 for each key, where f is the frequency of that key, summing these results to obtain the total count of valid pairs.j holds true.Since each note is defined as bi = 2 a i , the equation simplifies to ai • 2 a j = aj • 2 a i .To efficiently solve this, we first factorize each exponent ai into the form 2 y × x, where x represents the odd component and y is the power of two in its prime factorization.Using this decomposition, we construct a key for each ai as (x, y − ai).This key is crafted so that if two exponents ai and aj share the same key, they satisfy the equality condition.Next, we tally the frequency of each key using a dictionary or hash map.Finally, the number of valid pairs corresponding to each key is computed using the combination formula Given that each note bi can be expressed as 2 a i , the equation simplifies to ai • 2 a j = aj • 2 a i .To approach this efficiently, each exponent ai is factorized into the form 2 y × x, where x denotes the odd part of ai and y is the exponent of 2 in its prime factorization.Based on this factorization, we construct a unique key (x, y − ai) for each ai.This key is carefully designed so that two numbers sharing the same key satisfy the given equality condition.Once the keys are generated, a frequency map is used to count how many times each key appears.Finally, for each key, the number of valid pairs is calculated using the combination formula f 2 , where f represents the frequency of that key.Summing these counts across all keys gives the total number of valid pairs.hile the previous codes are correct for the given problem constraints, it implicitly assumes that only pairs of equal values or (1, 2) satisfy the equation later searching iteratively.However, explicitly grouping all valid pairs using a mathematical key, making it more robust and efficient for all scenarios, including possible edge cases not covered by the first approach.</p>
<p>Judge: There are 10 test cases.The candidate passes all 10 test cases with correct result.Score: 10.</p>
<p>C External Retrieval Corpus for Code</p>
<p>As shown in Figure 11, our coding external retrieval corpus has 156 fine grained algorithmic tutorials with relevant problems along with their solutions collections from 10 different categories (algebrea, data structure, dynamic programming, string processing, linear algebrea, combinatorics, numerical methods, geometry, graphs and miscellaneous).</p>
<p>D Additional Analysis</p>
<p>This section presents our multiple runs' results which we tested and list of roles which LLMs selected during the experiments.</p>
<p>D.1 Patterns in Xolver Reasoning Traces</p>
<p>We employ the QWQ-32B model for the initial segmentation of the chain of thought, guided by the first prompt illustrated in Appendix A.5. Subsequently, for segments that remain unannotated, a second segmentation pass is performed using the second prompt depicted in Appendix A.5. Reasoning patterns are identified by extracting content enclosed within the <pattern> tags.Verification and reasoning patterns are combined into a unified self-evaluation category.If the model assigns multiple patterns to a single segment, that segment is excluded due to ambiguity in pattern classification.For  each generated output, we calculate the proportion of occurrences of each pattern relative to the total patterns present, resulting in a frequency vector representing pattern distribution per generation.</p>
<p>In examining the relationship between pattern usage and problem difficulty, we compute the mean frequencies separately for correct and incorrect generations and assess significance through a t-test.</p>
<p>To evaluate pattern prevalence on a per-problem basis, a binary matrix is constructed where rows correspond to problems and entries indicate whether a pattern is more common in correct (1) or incorrect (0) solutions.The statistical significance of these findings is evaluated using a binomial test.</p>
<p>D.2 Performance Variance Statistics</p>
<p>In this experiment on the variance of Xolver performance, we tested Xolver against multiple runs (16 for AIME '24 and 32 for AIME '25 and LiveCodeBench) in AIME and LiveCodeBench dataset.Results shows in Table 4 that it has small scale performance change with multiple runs which is a strong sign on the robustness of Xolver.</p>
<p>Figure 2 :
2
Figure 2: Xolver Scaffold.At each iteration, agents receive their past reasoning history and topranked exemplars to generate new thoughts and responses, using tools (e.g., code) as needed.A judge model ranks outputs, and an intermediate memory maintains the best responses over time.Exemplars are initialized via episodic retrieval and continually updated with high-quality solutions from the memory.Iteration stops when convergence or max steps are reached, followed by final verification.</p>
<p>r n a l R e tr ie v a l S y n th e s iz e</p>
<p>Figure 3 :
3
Figure 3: Performance drop when removing each component from Xolver.Bars show average drop on Math (bottom) and LiveCodeBench (top).Verifier is critical for math tasks and cannot be removed, while Tool (Python) and test cases apply only to math and coding respectively.</p>
<p>Figure 4 :
4
Figure 4: Impact of iterations and agents in Xolver on AIME '25 (QWQ-32B) and LIVECODEBENCH (o3-mini-medium).</p>
<p>2 AIME ' 25 Figure 5 :
2255
Figure 5: Impact of different retrievals in Xolver.Effect of Retrieval Strategies on XolverPerformance.We evaluate the impact of different retrieval strategies on Xolver by comparing three settings: (1) External Retrieval, where the model retrieves the top-k (e.g., k = 5) most similar problems and their solutions from an external corpus using a BM25 retriever; (2) Self-Retrieval, where the model recalls the top-k most similar problems and solutions from its own internal memory; and (3) No Retrieval, where neither external nor self-retrieval is used.As shown in Figure5, performance on both AIME '25 and LIVECODEBENCH follows the trend: External Retrieval &gt; Self-Retrieval &gt; No Retrieval, indicating that external retrieval significantly enhances Xolver's performance.We note that for code tasks, although the external retrieval corpus</p>
<p>Figure 6 :
6
Figure 6: Fine-grained performance comparison in MATH-500.</p>
<p>Figure 8 :
8
Figure 8: Avg numbers of token usage across datasets in Xolver (+).</p>
<p>Figure 9 :
9
Figure 9: Xolver Math and Code error distribution.</p>
<p>5Figure 10 :
10
Case-Study: How Xolver Enhances Reasoning Agents Accuracy and Agreement over iterations.</p>
<p>A. 1 33 D. 1 34 D. 3 35 D. 4
1331343354
Planner Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19 A.2 Dynamic Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19 A.3 Judge Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20 A.4 Verifier Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20 A.5 Reasoning Segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20 Patterns in Xolver Reasoning Traces . . . . . . . . . . . . . . . . . . . . . . . . .33 D.2 Performance Variance Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . .Impact of Data-Shuffling in Xolver (+) Performance . . . . . . . . . . . . . . . . .List of Roles of Selected by Dynamic Agents . . . . . . . . . . . . . . . . . . . .35</p>
<p>2 k , where k ≥ 1 -a positive integer.But, as you know, you can't use just notes to write music, so Yarik uses combinations of two notes.The combination of two notes (a, b), where a = 2 k and b = 2 l , he denotes by the integer a b .For example, if a = 8 = 2 3 , b = 4 = 2 2 , then the combination (a, b) is denoted by the integer a b = 8 4 = 4096.Note that different combinations can have the same notation, e.g., the combination (64, 2) is also denoted by the integer 4096 = 64 2 .</p>
<p>(</p>
<p>bi, bj) such that b b j i = b b i j .The notes are given as bi = 2 a i , where ai is an integer.The key insight is to recognize the conditions under which the equation b b j i = b b i</p>
<p>1 # 2 #
12
input tokens at once x = sys.stdin.read().split()i = 0 # Index to track position in input list t = int(x[i]) # Number of test cases i += 1 for _ in range(t): n = int(x[i]) # Number of elements in this test case i += Extract the list of integers for current test case l = list(map(int, x[i:i+n])) i += n # Count frequencies of each element c = Counter(l) s = 0 # Sum of pairs # Sum pairs of identical elements: count choose 2 for v in c.values(): s += v * (v -1) // Add pairs formed by one element '1' and one element '2' s += c.get(1, 0) * c.get(2, 0) print(s) if <strong>name</strong> == "<strong>main</strong>": main() ``J udge: There are 10 test cases.The candidate passes 5 test cases.Score: 5.</p>
<p>2 #
2
.stdin.read().split()# Read all input tokens i = 0 # Input index pointer t = int(x[i]) # Number of test cases i += 1 for _ in range(t): n = int(x[i]) # Number of elements i += 1 l = list(map(int, x[i:i+n])) # List of integers for this test case i += n f = defaultdict(int) # Frequency dictionary # Count occurrences of each number for v in l: f[v] += 1 s = 0 # Count pairs of identical elements # Sum pairs from frequencies (nC2) for v in f.values(): s += v * (v -1) // Count pairs formed by one '1' and one '2' c = f.get(1,0) * f.get(2, 0) print(s + c) if <strong>name</strong> == "<strong>main</strong>": main() ``J udge: There are 10 test cases.The candidate passes 5 test cases.Score: 5. Data Structure Specialist: To solve this problem, we need to determine the number of pairs of music notes, represented by integers of the form 2 k , such that the combination of two notes (bi, bj) results in the same value as (bj, bi).In other words, we seek pairs (i, j) where b b j i = b b i j</p>
<p>0 # 2 #Score: 5 . 2
0252
.stdin.read().split()# Read all input tokens at once i = 0 # Input index pointer t = int(x[i]) # Number of test cases i += 1 for _ in range(t): n = int(x[i]) # Number of elements i += 1 l = list(map(int, x[i:i+n])) # List of integers for this test case i += n c = Counter(l) # Frequency counter c1 = c.get(1, 0) # Count of 1's c2 = c.get(2, 0) # Count of 2's x = Combine counts of 1 and 2, calculate pairs among them m = c1 + c2 x += m * (m -1) // Calculate pairs for other numbers except 1 and 2 for k in c: if k not in (1, 2): v = c[k] x += v * (v -1) // 2 print(x) if <strong>name</strong> == "<strong>main</strong>": main() ``J udge: There are 10 test cases.The candidate passes 5 test cases.DS 1 rank: [Implementation Specialist, Programmer, Data Structure Specialist] Iteration Implementation Specialist: : After reviewing the solutions provided by other agents, I agree that to solve this problem, we need to determine the number of pairs of notes (bi, bj) such that b b j i = b b i j</p>
<p>2 #
2
.stdin.read().split()# Read all input tokens at once i = 0 # Index pointer t = int(x[i]) # Number of test cases i += 1 for _ in range(t): n = int(x[i]) # Number of elements in this test case i += 1 l = list(map(int, x[i:i+n])) # List of elements i += n c = Counter(l) # Frequency count s = 0 # Sum of pairs # Calculate pairs from identical elements: nC2 for each count for v in c.values(): s += v * (v -1) // Add pairs formed by one '1' and one '2' s += c.get(1, 0) * c.get(2udge:There are 10 test cases.The candidate passes 6 test cases.Score: 6.</p>
<p>2 #
2
(sys.stdin.readline())# Number of test cases for _ in range(t): n = int(sys.stdin.readline().strip())# Number of elements l = list(map(int, sys.stdin.readline().split()))# List of integers c = Counter(l) # Frequency counter s = 0 # Sum of pairs # Calculate pairs among identical elements: nC2 for each frequency for v in c.values(): s += v * (v -1) // Add pairs formed by one '1' and one '2' s += c.get(1, 0) * c.get(2are 10 test cases.The candidate passes 5 test cases.Score: 5. Data Structure Specialist: To solve this problem, we need to determine the number of valid pairs of notes such that the combination of two notes (bi, bj) results in the same integer as the combination (bj, bi).This is equivalent to finding pairs (i, j) where b b j i = b b i j .The key insight comes from the equation b b j i = b b i j</p>
<p>2 print
2
collections import defaultdict def main(): x = sys.stdin.read().split()# Read all input tokens at once i = 0 # Input index pointer t = int(x[i]) # Number of test cases i += 1 for _ in range(t): n = int(x[i]) # Number of elements in this test case i += 1 l = list(map(int, x[i:i+n])) # List of integers i += n f = defaultdict(int) # Frequency dictionary for v in l: a = v b = 0 # Count how many times 2 divides the number while a % 2 == 0: a //= 2 b += 1 # Key is tuple of (odd part, difference of exponents) k = (a, b -v) f[k] += 1 s = 0 # Result accumulator # Count pairs for each unique key using nC2 formula for c in f.values(): s += c * (c -1) // are 10 test cases.The candidate passes all 10 test cases with correct result.Score: 10.DS 2 rank: [Data Structure Specialist, Implementation Specialist, Programmer] Iteration 3</p>
<p>2 # 1 #
21
collections import defaultdict def main(): d = sys.stdin.read().strip().split()# Read and split all input t = int(d[0]) # Number of test cases p = 1 # Current position in input list for _ in range(t): n = int(d[p]) # Number of elements in this test case p += 1 l = list(map(int, d[p:p+n])) # Current list of elements p += n f = defaultdict(int) # Frequency dictionary for v in l: o = v # Original value c = 0 # Count of factors Count how many times 2 divides the value while v % 2 == 0: v //= 2 c += Key: (odd part, count_twos -original_value) k = (v, c -o) f[k] += 1 s = 0 # Result accumulator # Calculate pairs for each unique key using nC2 for x in f.values(): s += x * (x -1) // 2 print(s) if <strong>name</strong> == "<strong>main</strong>": main() ``J udge: There are 10 test cases.The candidate passes all 10 test cases with correct result.Score: 10.Programmer: I agree with the other agent that to address this problem, we aim to find the number of valid pairs of notes (bi, bj) such that the expression b b j i equals b b i j .In other words, we seek pairs (i, j) where the exponentiation relation b b j i = b b i</p>
<p>f 2 , 2 # 1 #
221
where f denotes the frequency of that key.Summing these values yields the total count of valid pairs.<code>`python import sys from collections import defaultdict def main(): d = sys.stdin.read().strip().split()# Read all input tokens t = int(d[0]) # Number of test cases p = 1 # Position pointer in input list for _ in range(t): n = int(d[p]) # Number of elements p += 1 l = list(map(int, d[p:p+n])) # List of elements p += n f = defaultdict(int) # Frequency dictionary for v in l: b = v # Base value c = 0 # Count of factors Count how many times 2 divides b while b % 2 == 0: b //= 2 c += Key is tuple: (odd part, power difference) k = (b, c -v) f[k] += 1 s = 0 # Result accumulator # Count pairs for each frequency using nC2 formula for x in f.values(): s += x * (x -1) // 2 print(s) if __name__ == "__main__": main()</code>J udge: There are 10 test cases.The candidate passes all 10 test cases with correct result.Score: 10.Data Structure Specialist: To solve this problem, the goal is to identify the number of valid pairs of notes (bi, bj) for which the value of b b j i equals that of b b i j .This translates to finding pairs (i, j) satisfying the equation b b j i = b b i j .</p>
<p>2 #
2
.stdin.read().split()# Read all input tokens i = 1 # Index pointer after reading t t = int(d[0]) # Number of test cases for _ in range(t): n = int(d[i]) # Number of elements i += 1 l = list(map(int, d[i:i+n])) # Current list of elements i += n f = defaultdict(int) # Frequency dictionary for v in l: x = v # Current value p = 0 # Count of factor Count how many times 2 divides x while x % 2 == 0: x //= 2 p += 1 k = (x, p) # Key as (odd part, power of two) f[k] += 1 s = 0 # Result accumulator # Count pairs for each unique key using nC2 formula for c in f.values(): s += c * (c -1) // 2 print(s) if <strong>name</strong> == "<strong>main</strong>": main() ``Ẁ</p>
<p>DS 3
3
rank: [Data Structure Specialist, Programmer, Implementation Specialist]</p>
<p>r i n g P r o c e s s i n g L i n e a r A l g e b r a C o m b i n a t o r i c s N u m e r i c a l M e t h o d s G e o m e t r y G r a p h s M i s c e l l a n e o u</p>
<p>Figure 11 :
11
Figure 11: Coding External Retrieval Corpus Count per Subject Category.</p>
<p>R), where (T, R, S, a) is the top-ranked entry in D S .Intermediate Shared Memory D S .The shared memory D S maintains a fixed-size set of highquality intermediate reasoning, responses, and metadata generated by the dynamic agents during inference on the current query q.For simplicity and to preserve the dynamic nature of the framework, we constrain |D S | = m, where m is the number of dynamic agents in A. Initially, D S ← ∅.
At eachiteration i, each agent a j ∈ A produces a reasoning trace T j i , response R j i , and receives structuredfeedback S j i = (T(i,j) S</p>
<p>Table 1 :
1
vs. 93.4)and substantially
AIMEAIMEMathLiveCodeBenchModelAppr.GSM8K'24'25-500(v5)Proprietary ModelsClaude 3.7 Sonnet T.LongCoT-61.349.596.251.4Grok-3 (Beta) T.Direct-83.977.3-70.6Grok-3-mini (Beta) T.LongCoT-89.582.0--Gemini 2.5 Flash T.LongCoT-88.078.0-63.5o1LongCoT96.474.379.296.471.0o3-mini-highLongCoT-87.386.5-69.5Gemini 2.5 Pro.Direct-92.086.7-70.4o3LongCoT96.791.688.9--o4-mini-highLongCoT-93.492.7-69.5Open Weights ModelsDeepSeek-R1LongCoT-79.870.097.364.3Qwen3-235B-A22BLongCoT-85.781.5-70.7Math/Code Specialized ModelsrStar-Math (Best)-95.253.3-90.0-OpenMathReason (Best) --93.380.0--AlphaOne (Best)--53.3-89.475.8OpenCodeReason (Best) -----61.8rStar-Coder (Best)-----62.5Kimi-k1.6-IOI-high-----73.8Reasoning Agents/FrameworksLongCoT95.275.870.497.366.3Self-Refl.93.179.476.595.273.2o3-mini-mediumOctoTools Search-o195.4 95.881.7 81.875.3 76.797.5 97.6-73.6CheatSheet95.982.275.897.7-CodeSim----73.8Xolver (-)95.687.285.197.779.6Xolver (+)97.193.889.499.287.3LongCoT96.178.165.883.263.4Self-Refl.94.079.366.380.469.2OctoTools96.383.071.786.1-QWQ-32BSearch-o196.484.471.887.169.3CheatSheet96.883.572.286.5-CodeSim----70.5Xolver (-)96.589.979.593.176.2Xolver (+)98.093.682.795.579.2o3-mini-highXolver (+)98.194.493.799.891.6
Comparison of Xolver against SoTA reasoning models, specialized models, and other reasoning agents across mathematical and coding tasks.Best results are boldfaced and second-best results are underlined.T: Think models, LongCoT*: standard prompting for reasoning models."-" denotes either n/a (e.g., only math/code specialized models) or results not reported.</p>
<p>The only exception is in Number Theory, where o3-mini-medium scores 99.2 compared to CHEATSHEET's 99.5.As for QWQ-32B, Xolver achieves substantial accuracy gains over CheatSheet across all categories, with improvements of +9.0% in Prealgebra, +8.5% in Algebra, +11.0% in Number Theory, +8.5% in Counting and Probability, +8.8% in Geometry, +10.0% in Intermediate Algebra, and +7.5% in Precalculus.These consistent gains highlight Xolver's strong performance across both symbolic and numerical reasoning.
and Fig-ure 7.On MATH-500, Xolver(both o3-mini-medium andQWQ-32B)consistentlyoutperforms CHEATSHEETacross nearly all seven subjectcategories, despite the latterrelying on costly per-problemMedium 76.7 90.4 LiveCodeBench Accuracy by Difficulty Hard 78.5 53.2 43.8 memory updates. Easy 40 50 60 70 80 Accuracy (%) 90 100 91.1 89.9 95.6 85.8 87.5 95.2 CodeSim (o3-mini-medium) CodeSim (QWQ-32B) Xolver (o3-mini-medium) Xolver (QWQ-32B)70.0Figure 7: Performance comparison perdifficulty levels in LiveCodeBench
On LiveCodeBench, Xolver demonstrates even more pronounced gains.The o3-mini-medium variant achieves 95.6%, 90.4%, and 85.8% accuracy on Easy, Medium, and Hard problems respectively, significantly outperforming CodeSim by +4.5%, +11.9%, and a striking +32.3% margin on hard examples.Even with a weaker QWQ-32B backbone, Xolver (95.2%, 87.5%, 70.0%) surpasses all baselines and achieves similar gains.In contrast to CheatSheet and CodeSim, Xolver leverages multi-agent collaborations and holistic experience learning.These consistent and backbone-agnostic gains across different reasoning tasks underscore Xolver's robustness and position it as a breakthrough in retrieval and tool-augmented, multi-agent and evolving reasoning systems.</p>
<p>Table 2
2Reasoning PatternCorrect SolutionsIncorrect SolutionsEasy → Medium Medium → High Easy → Medium Medium → HighSelf-Evaluation (↑)0.35 → 0.380.38 → 0.400.35 → 0.370.32 → 0.35New Approach (↑)0.18 → 0.210.21 → 0.240.17 → 0.240.24 → 0.26Problem Rephrasing (↓↑)0.20 → 0.170.18 → 0.180.23 → 0.240.24 → 0.25Subgoal Setup (↓↑)0.14 → 0.130.13 → 0.110.11 → 0.120.11 → 0.11
. Detailed description of how we collected the reasoning patterns is provided in the Appendix D.1.Our analysis reveals that Xolver dynamically increases self-evaluation and exploratory strategies (e.g., trying new approaches) as problem difficulty grows.Correct solutions demonstrate a declining need for problem rephrasing and subgoal decomposition, indicating more direct and confident reasoning.In contrast, incorrect</p>
<p>Table 2 :
2
Changes in major reasoning pattern frequencies as problem difficulty increases in Live-CodeBench, comparing correct vs. incorrect solutions.Green and red indicate statistically significant increases or decreases (p &lt; 0.05).Underlined cells highlight patterns where Xolver improves over OpenCodeReasoning, which otherwise shows a declining trend.Direction arrows denote: ↑ = increase, ↓ = decrease, ↓↑ = mixed trend (decrease in correct, increase in incorrect).Xolver increases use of self-evaluation and new approaches with task difficulty, and demonstrates targeted subgoal setup and problem rephrasing when solutions fail-reflecting its adaptive, collaborative reasoning.solutions show increased subgoal setup and rephrasing attempts-suggesting that the system recognizes failure and attempts recovery through restructuring.Compared to OpenCodeReasoning, which shows stagnation or regression in key patterns (e.g., self-evaluation), Xolver exhibits robust and adaptive reasoning behavior, supported by multi-agent collaboration and judge feedback.This behavior highlights the generality and flexibility of Xolver 's reasoning model.</p>
<p>.1 Planner AgentFirst draft required strictly greater than {m} specialized roles to solve the problem collaboratively with reasoning behind your draft of each role.Then select the highly influential {m} roles by re-checking the reasoning behind your selection and assign them to each agent to solve the problem.
Prompt for PLANNER AGENTYou are a planner to solve a {coding/math} problem. Here is the problem for which you have to plan:{problem_dict[query['problem_id']]['description']}
A.2 Dynamic AgentPrompt for DYNAMIC AGENT You are a {role}.Your task is to solve a {coding/math} problem.Here is the problem that you have to solve: problem_dict[query['problem_id']]['description']</p>
<p>The candidate incorrectly used 2 pillow cases (half the required amount).Towels: The problem states "twice as many towels as pillow cases."With the correct pillow case count (4), towels should be 2 × 4 = 8.The candidate used 4 towels (based on their incorrect pillow case count of 2).: The candidate correctly interprets the problem's relationships: sheets: 2 (given), comforter: 1 (given), pillow cases: twice the sheets, 2 × 2 = 4 (correct), towels: twice the pillow cases, 2 × 4 = 8 (correct).Total per room: 2 + 1 + 4 + 8 = 15 (correct).Total for 80 rooms: 80 × 15 = 1200 (correct).All steps align with the problem's specifications, and the final answer is accurate.The candidate's solution is error-free.Thus, the total for 80 rooms should be 80 × 15 = 1200, not 1120.The error stems from excluding the comforter in the summation.
Score: 1.Mathematician: Every room is equipped with 2 sheets, 1 comforter, 4 pillow cases (calculated as2 × 2), and 8 towels (since 4 × 2 = 8). Summing these, the total number of laundry items for one roomis:2 + 4 + 8 = 14 pieces of laundry.Multiplying by the number of rooms, the total quantity for 80 rooms becomes:80 × 14 = 1120 .Judge: The candidate incorrectly omitted the comforter in their final sum. Here's the breakdown:Score: 0.The correct per-room total is:2 (sheets) + 1 (comforter) + 4 (pillow cases) + 8 (towels) = 15items. The total for 80 rooms is:80 × 15 = 1200.The candidate's answer is incorrect due to miscalculating pillow cases and towels.Score: 0.Numerical Analyst: For each room, Bob needs to wash 2 sheets, 1 comforter, 4 pillow cases (since
). Pillow Cases: The problem states "twice as many pillow cases as sheets."Since there are 2 sheets, pillow cases should be 2 × 2 = 4. 2 × 2 = 4), and 8 towels (since 4 × 2 = 8).Therefore, for each room, the total amount of laundry Bob needs to wash is: 2 + 1 + 4 + 8 = 15 pieces of laundry.For 80 rooms, the total number of pieces of laundry Bob must wash is: 80 × 15 = 1200 pieces of laundry.Thus, the final answer is: 1200 .Judgesheets: 2 (correct), comforter: 1 (given but not included in the candidate's calculation), pillow cases: 2 × 2 = 4 (correct), towels: 2 × 4 = 8 (correct).The candidate's total per room was 2 + 4 + 8 = 14, but the correct total should include the comforter: 2 + 1 + 4 + 8 = 15.DS 1 rank: [Numerical Analyst, Mathematical Modeler, Mathematician] Iteration 2</p>
<p>Table 3 :
3
Demonstrating how the frequency of major reasoning pattern changes as problem difficulty increases.Green indicates statistically significant increases and red indicates significant decreases (p &lt; 0.05).Gray boxes highlight opposing trends between OpenCodeReasoning (decrease) and Xolver (increase).Direction arrows indicate the expected trend direction: ↑ = increase, ↓ = decrease, ↓↑ = mixed trend (minor decrease then elevated recovery), ↕ = fluctuating trend (major decrease then recovery).While solving problems, OpenCodeReasoning struggles at Self-Evaluation and Subgoal Setup whereas Xolver overcomes it with increasing Self-Evaluation in both correct and incorrect solutions and elevated recovery in Subgoal Setup in incorrect solutions.Both OpenCodeReasoning and Xolver adapts New Approach while struggles at Problem Rephrasing.</p>
<p>https://github.com/cp-algorithms/cp-algorithms
+ 1 + 4 + 8 = 15 (correct), total for 80 rooms: 80 × 15 = 1200 (correct). All steps align with the problem's specifications, and the final answer is accurate. No errors were made. Score: 1.
A.3 Judge AgentPrompt for JUDGE AGENT You are a judge.Your task is to judge the candidate solution of a {coding/math} problem.Here is the problem for which the candidate solution you have to judge: problem_dict[query['problem_id']]['description']--------------------------------------If coding task: And here is the candidate response along with test cases against which to judge:Please produce a score (based on the number of test cases passed) with reasoning behind your judgement of the candidate solution to the problem.--------------------------------------If math task: And here is the candidate response which to judge:Please produce a score (if the response is correct, it should be 1 otherwise should be 0) with reasoning behind your judgement of the candidate solution to the problem.A.4 Verifier AgentPrompt for VERIFIER AGENTYour are an answer extractor.Your task is to extract answer from the response to a {coding/math} problem.Here is the response for which the answer you have to extract: response_dict[query{'role'}]{'thought', 'response', 'score'}--------------------------------------If coding task:Please extract the answer from inside <code>python</code>block from the response.--------------------------------------If math task:Please extract the answer from inside \boxed{} block from the response.A.5 Reasoning SegmentationD.4 List of Roles of Selected by Dynamic AgentsTable6shows some selected specialized roles by the dynamic agents while testing on coding and math tasks along with their most frequently selected roles.
Opencodereasoning: Advancing data distillation for competitive coding. Sean Wasi Uddin Ahmad, Somshubra Narenthiran, Aleksander Majumdar, Siddhartha Ficek, Jocelyn Jain, Vahid Huang, Boris Noroozi, Ginsburg, 2025</p>
<p>. Anthropic, Claude, 3.7 Sonnet, 2025</p>
<p>Program synthesis with large language models. Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, arXiv:2108.077322021arXiv preprint</p>
<p>. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared</p>
<p>. Harri Kaplan, Yuri Edwards, Nicholas Burda, Greg Joseph, Alex Brockman, Raul Ray, Gretchen Puri, Michael Krueger, Heidy Petrov, Girish Khlaaf, Pamela Sastry, Brooke Mishkin, Scott Chan, Nick Gray, Mikhail Ryder, Alethea Pavlov, Lukasz Power, Mohammad Kaiser, Clemens Bavarian, Philippe Winter, Felipe Petroski Tillet, Dave Such, Matthias Cummings, Fotios Plappert, Suchir Chantzis ; Igor Babuschkin, Shantanu Balaji, William Jain, Christopher Saunders, Hesse, Josh Achiam, Vedant Misra, Evan Morikawa, Alec RadfordJan Leike. 2021Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang,; Andrew N. Carr; Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder; Bob McGrew, Dario Amodei, Sam McCandlishIlya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code</p>
<p>Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, arXiv:2308.10848202326arXiv preprint</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.141682021arXiv preprint</p>
<p>. Google Deepmind, Gemini, 2.5, 2025</p>
<p>Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. Deepseek-Ai , 2025</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>When one llm drools, multi-llm collaboration rules. Shangbin Feng, Wenxuan Ding, Alisa Liu, Zifeng Wang, Weijia Shi, Yike Wang, Zejiang Shen, Xiaochuang Han, Hunter Lang, Chen-Yu Lee, Tomas Pfister, Yejin Choi, Yulia Tsvetkov, ArXiv, abs/2502.045062025</p>
<p>Pal: Program-aided language models. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>rstar-math: Small llms can master math reasoning with self-evolved deep thinking. Xinyu Guan, Li Lyna Zhang, Yifei Liu, Ning Shang, Youran Sun, Yi Zhu, Fan Yang, Mao Yang, 2025</p>
<p>Large language model based multi-agents: A survey of progress and challenges. Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, arXiv:2402.016802024arXiv preprint</p>
<p>REALM: Retrieval-augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang, 10.5555/3524938.3525306International Conference on Machine Learning. JMLR.org. 2020</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks. J Vanschoren, S Yeung, the Neural Information Processing Systems Track on Datasets and Benchmarks20211</p>
<p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, arXiv:2308.00352Meta programming for multi-agent collaborative framework. 202336arXiv preprint</p>
<p>MapCoder: Multi-agent code generation for competitive problem solving. Ashraful Md, Mohammed Eunus Islam, Md Ali, Parvez Rizwan, 10.18653/v1/2024.acl-long.269Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. Lun-Wei Ku, Andre Martins, Vivek Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust 20241</p>
<p>CodeSim: Multi-agent code generation and problem solving through simulation-driven planning and debugging. Ashraful Md, Mohammed Eunus Islam, Md Ali, Parvez Rizwan, 10.18653/v1/2025.findings-naacl.285Findings of the Association for Computational Linguistics: NAACL 2025. Luis Chiruzzo, Alan Ritter, Lu Wang, Albuquerque, New MexicoAssociation for Computational LinguisticsApril 2025</p>
<p>Open-RAG: Enhanced retrieval augmented reasoning with open-source large language models. Shayekh Bin, Md Islam, K S M Asib Rahman, Enamul Tozammel Hossain, Shafiq Hoque, Md Joty, Parvez Rizwan, doi: 10.18653Findings of the Association for Computational Linguistics: EMNLP 2024. Yaser Al-Onaizan, Mohit Bansal, Yun-Nung Chen, Miami, Florida, USAAssociation for Computational LinguisticsNovember 2024</p>
<p>URL. </p>
<p>Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, arXiv:2403.079742024arXiv preprint</p>
<p>XCodeEval: An execution-based large scale multilingual multitask benchmark for code understanding, generation, translation and retrieval. Mohammad Abdullah Matin Khan, M Saiful Bari, Xuan Long Do, Weishi Wang, Md Rizwan Parvez, Shafiq Joty, 10.18653/v1/2024.acl-long.367Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. Lun-Wei Ku, Andre Martins, Vivek Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust 20241</p>
<p>Kimi k1.5: Scaling reinforcement learning with llms. 2025</p>
<p>A systematic survey and critical review on evaluating large language models: Challenges, limitations, and recommendations. Md Tahmid Rahman Laskar, Sawsan Alqahtani, Mizanur Saiful Bari, Mohammad Rahman, Haidar Abdullah Matin Khan, Israt Khan, Amran Jahan, Chee Bhuiyan, Md Wei Tan, Enamul Rizwan Parvez, Shafiq Hoque, Jimmy Joty, Huang, 10.18653/v1/2024.emnlp-main.764Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing. Yaser Al-Onaizan, Mohit Bansal, Yun-Nung Chen, the 2024 Conference on Empirical Methods in Natural Language ProcessingMiami, Florida, USAAssociation for Computational LinguisticsNovember 2024</p>
<p>Techniquerag: Retrieval augmented generation for adversarial technique annotation in cyber threat intelligence text. Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan, Parvez , 2025</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Solving quantitative reasoning problems with language models. Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Advances in Neural Information Processing Systems. 202235</p>
<p>Camel: Communicative agents for" mind" exploration of large language model society. Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, Advances in Neural Information Processing Systems. 202336</p>
<p>Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, Zhicheng Dou, arXiv:2501.05366Search-o1: Agentic search-enhanced large reasoning models. 2025arXiv preprint</p>
<p>Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, arXiv:2412.19437Deepseek-v3 technical report. 2024arXiv preprint</p>
<p>Yifei Liu, Li Lyna Zhang, Yi Zhu, Bingcheng Dong, Xudong Zhou, Ning Shang, Fan Yang, Mao Yang, arXiv:2505.21297rstar-coder: Scaling competitive code reasoning with a large-scale verified dataset. 2025arXiv preprint</p>
<p>Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization. Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, Diyi Yang, arXiv:2310.021702023arXiv preprint</p>
<p>Chameleon: Plug-and-play compositional reasoning with large language models. Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Jianfeng Gao, Advances in Neural Information Processing Systems. 202436</p>
<p>Octotools: An agentic framework with extensible tools for complex reasoning. Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, James Zou, arXiv:2502.112712025arXiv preprint</p>
<p>American invitational mathematics examination -aime. American Invitational Mathematics Examination -AIME 2024. February 2024MAA</p>
<p>American invitational mathematics examination -aime. American Invitational Mathematics Examination -AIME 2025. February 2025MAA</p>
<p>Dakota Mahan, Duy Van Phung, Rafael Rafailov, Chase Blagden, Nathan Lile, Louis Castricato, Jan-Philipp Fränken, Chelsea Finn, Alon Albalak, arXiv:2410.12832Generative reward models. 2024arXiv preprint</p>
<p>Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset. Ivan Moshkov, Darragh Hanley, Ivan Sorokin, Shubham Toshniwal, Christof Henkel, Benedikt Schifferer, Wei Du, Igor Gitman, 2025</p>
<p>Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, arXiv:2112.09332Browser-assisted question-answering with human feedback. 2021arXiv preprint</p>
<p>Show your work: Scratchpads for intermediate computation with language models. Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, arXiv:2112.001142021arXiv preprint</p>
<p>Openai, GPT-4o. 2024</p>
<p>Learning to reason with llms. Openai, 2024</p>
<p>Introducing openai o3 and o4-mini. Openai, 2025</p>
<p>Charles Packer, Vivian Fang, G Shishir, Kevin Patil, Sarah Lin, Joseph Wooders, Gonzalez, Memgpt, ArXiv, abs/2310.08560Towards llms as operating systems. 2023</p>
<p>Chain of evidences and evidence to generate: Prompting for context grounded and retrieval augmented reasoning. Md Rizwan, Parvez , 10.18653/v1/2025.knowledgenlp-1.21Proceedings of the 4th International Workshop on Knowledge-Augmented Methods for Natural Language Processing. Weijia Shi, Wenhao Yu, Akari Asai, Meng Jiang, Greg Durrett, Hannaneh Hajishirzi, Luke Zettlemoyer, the 4th International Workshop on Knowledge-Augmented Methods for Natural Language ProcessingAlbuquerque, New Mexico, USAAssociation for Computational LinguisticsMay 2025</p>
<p>Evaluating the values of sources in transfer learning. Rizwan Md, Kai-Wei Parvez, Luke Chang, Dilek Zettlemoyer, Iz Hakkani-Tur, Steven Beltagy, Ryan Bethard, Tanmoy Cotterell, Yichao Chakraborty, Zhou, 10.18653/v1/2021.naacl-main.402Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Kristina Toutanova, Anna Rumshisky, the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational LinguisticsJune 2021</p>
<p>Retrieval augmented code generation and summarization. Wasi Md Rizwan Parvez, Saikat Ahmad, Baishakhi Chakraborty, Kai-Wei Ray, Chang, 10.18653/v1/2021.findings-emnlp.232Findings of the Association for Computational Linguistics: EMNLP 2021. Marie-Francine Moens, Xuanjing Huang, Lucia Specia, Scott , Wen-Tau Yih, Punta Cana, Dominican RepublicAssociation for Computational LinguisticsNovember 2021</p>
<p>Retrieval enhanced data augmentation for question answering on privacy policies. Jianfeng Md Rizwan Parvez, Chi, Uddin Wasi, Yuan Ahmad, Kai-Wei Tian, Chang, 10.18653/v1/2023.eacl-main.16Proceedings of the 17th Conference of the European Chapter. Andreas Vlachos, Isabelle Augenstein, the 17th Conference of the European ChapterDubrovnik, CroatiaAssociation for Computational LinguisticsMay 2023</p>
<p>Qwq: Reflect deeply on the boundaries of the unknown. Qwen Team, 2024</p>
<p>QwQ-32B: Embracing the power of reinforcement learning. Qwen Team, March 2025</p>
<p>Ai debate aids assessment of controversial claims. Salman Rahman, Sheriff Issaka, Ashima Suvarna, Genglin Liu, James Shiffer, Jaeyoung Lee, Rizwan Md, Hamid Parvez, Shi Palangi, Nanyun Feng, Peng, arXiv:2506.021752025arXiv preprint</p>
<p>DelucionQA: Detecting hallucinations in domain-specific question answering. Mobashir Sadat, Zhengyu Zhou, Lukas Lange, Jun Araki, Arsalan Gundroo, Bingqing Wang, Rakesh Menon, Md Parvez, Zhe Feng, 10.18653/v1/2023.findings-emnlp.59Findings of the Association for Computational Linguistics: EMNLP 2023. Houda Bouamor, Juan Pino, Kalika Bali, SingaporeAssociation for Computational LinguisticsDecember 2023</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Shunyu Karthik R Narasimhan, Yao, Thirty-seventh Conference on Neural Information Processing Systems. 2023</p>
<p>Reflexion: Language agents with verbal reinforcement learning. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao, Advances in Neural Information Processing Systems. 202436</p>
<p>Multiagent finetuning: Self improvement with diverse reasoning chains. Vighnesh Subramaniam, Yilun Du, Joshua B Tenenbaum, Antonio Torralba, Shuang Li, Igor Mordatch, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Mirac Suzgun, Mert Yuksekgonul, Federico Bianchi, Dan Jurafsky, James Zou, arXiv:2504.07952Dynamic cheatsheet: Test-time learning with adaptive memory. 2025arXiv preprint</p>
<p>. Qwen Team, Qwen3, April 2025</p>
<p>Openmathinstruct-1: A 1.8 million math instruction tuning dataset. Shubham Toshniwal, Ivan Moshkov, Sean Narenthiran, Daria Gitman, Fei Jia, Igor Gitman, arXiv:2402.101762024arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Ed H Quoc V Le, Sharan Chi, Aakanksha Narang, Denny Chowdhery, Zhou, The Eleventh International Conference on Learning Representations. </p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai Hsin, Chi , Denny Zhou, ArXiv, abs/2203.111712022</p>
<p>Learning to filter context for retrieval-augmented generation. Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, Graham Neubig, arXiv:2311.083772023arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation framework. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang, arXiv:2308.0815532023arXiv preprint</p>
<p>Grok 3 beta -the age of reasoning agents. 2025</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>React: Synergizing reasoning and acting in language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, International Conference on Learning Representations (ICLR). 2023</p>
<p>Retroformer: Retrospective large language agents with policy gradient optimization. Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, Ran Xu, Phil L Mui, Haiquan Wang, Caiming Xiong, Silvio Savarese, ArXiv, abs/2308.021512023260611249</p>
<p>Acecoder: Acing coder rl via automated test-case synthesis. Huaye Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen, arXiv:2502.017182025arXiv preprint</p>
<p>Alphaone: Reasoning models thinking slow and fast at test time. Junyu Zhang, Runpei Dong, Han Wang, Xuying Ning, Haoran Geng, Peihao Li, Xialin He, Yutong Bai, Jitendra Malik, Saurabh Gupta, Huan Zhang, 2025</p>
<p>Expel: Llm agents are experiential learners. Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Gaetan Lin, Y Liu, Gao Huang, AAAI Conference on Artificial Intelligence. 2023</p>
<p>Ldb: A large language model debugger via verifying runtime execution step-by-step. Li Zhong, Zilong Wang, Jingbo Shang, arXiv:2402.169062024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>