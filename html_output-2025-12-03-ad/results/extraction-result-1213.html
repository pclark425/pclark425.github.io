<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1213 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1213</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1213</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-214754592</p>
                <p><strong>Paper Title:</strong> Neural Topological SLAM for Visual Navigation</p>
                <p><strong>Paper Abstract:</strong> This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation. Experimental study in visually and physically realistic simulation suggests that our method builds effective representations that capture structural regularities and efﬁciently solve long-horizon navigation problems. We observe a relative improvement of more than 50% over existing methods that study this task.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1213.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1213.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NTS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Topological SLAM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised, modular topological navigation system that builds an online graph of panoramic-image nodes (regular + 'ghost' frontier nodes), learns geometric (FG) and semantic (FS) predictors per-node/direction, and uses Dijkstra planning on the graph plus a local point-goal controller to solve image-goal navigation under realistic actuation and sensor noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Habitat simulator (Gibson dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Photorealistic indoor household environments reconstructed in Gibson and simulated in Habitat; episodic image-goal navigation where the agent receives a panoramic goal image and must reach that location in previously unseen scenes.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Sparse, online-built topological graph: nodes are panoramic-image locations; edges connect adjacent areas and store relative pose between consecutive nodes; 'ghost' nodes (frontier hypotheses) connect to exactly one regular node and represent unexplored directions.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Dataset: curated 86 scenes (split 68 train / 4 val / 14 test). Node radius r = 3 m used to define node neighborhoods; training data sampled 300 images per training scene (≈6.12M source-target pairs). Exact number of nodes per scene varies and is not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Neural Topological SLAM (Global Policy + Local Policy)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Modular agent: Graph Update builds/topologically localizes nodes using a learned Connection model (FL); Geometric Explorable Area Predictor (FG) produces 12-direction frontier hypotheses (ghost nodes); Semantic Score Predictor (FS) scores ghost nodes relative to a goal image; Global Policy selects long-term goal node and plans shortest path via Dijkstra; Local Policy is a point-goal controller that executes relative-pose subgoals using a learned local mapper (or geometric projections for RGBD). All prediction modules are trained jointly in a supervised multi-task ResNet18-based model.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Success weighted by inverse Path Length (SPL), success rate, and episode length/steps to goal</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>RGB overall SPL = 0.38 (Succ=0.55); RGBD overall SPL = 0.43 (Succ=0.63). Detailed (NTS RGB): Easy SPL 0.60 (Succ 0.80), Medium SPL 0.31 (Succ 0.47), Hard SPL 0.22 (Succ 0.37). (Values taken from Table 1.)</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>RGB overall 0.55 (55%); RGBD overall 0.63 (63%). See difficulty breakdown in exploration_efficiency_value.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Planning-based topological policy with memory: global graph search (Dijkstra) over learned semantic/geometric node scores combined with a local point-goal controller; i.e., memory + planning + learned semantic priors.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Multiple explicit findings linking topology features to performance: (1) Topological representation (NTS) is robust to actuation/sensor noise because it stores relative poses only between consecutive nodes, preventing long-range accumulation of pose error that degrades metric maps. (2) Semantic scoring of unexplored directions (FS) substantially improves exploration efficiency early on by biasing exploration toward structurally plausible areas (e.g., hallways to kitchens/bedrooms), increasing success/SPL compared to random frontier selection. (3) The topological map (graph memory) becomes increasingly important over multiple sequential goals: removing the graph (greedy per-image direction selection) causes performance to degrade as the number of sequential goals increases, while removing the semantic score mainly hurts initial exploration efficiency. (4) Metric spatial maps' performance drops quickly with increased path length under motion noise due to accumulated pose errors, whereas NTS's topological edges limit error accumulation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>The paper compares topological (NTS) vs metric spatial map baselines (metric mapping + RL, metric mapping + FBE, Active Neural SLAM): (a) Under realistic actuation/sensor noise, metric-map methods degrade with distance to goal and perform worse than NTS—NTS shows large relative improvements, especially in harder (longer) tasks. (b) When motion noise is removed, metric-map baselines improve markedly, indicating their weakness primarily arises from pose error accumulation; NTS performance remains strong with or without noise due to local relative-pose edges. (c) Ablations show semantic scoring improves early exploration, while graph memory yields longer-term benefits across sequential goals.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Key findings on policy structure vs topology: (1) Policies that separate global planning on a topological graph from local point-goal execution perform better in large, noisy environments than end-to-end reactive or purely metric policies. (2) A semantic-scoring module that predicts which frontier directions are more likely to lead to the goal allows the global policy to choose promising ghost nodes (frontiers) and reduces exploratory search. (3) Graph-based memory is necessary for multi-goal/long-horizon tasks because it enables re-use of past observations and avoids purely greedy, myopic exploration that fails over sequences of goals. (4) Metric-map + RL policies require accurate pose estimation (or low-noise conditions); in high-diameter or long-horizon tasks with realistic noise, they need additional mechanisms to avoid pose error accumulation (which NTS's topology avoids by using local relative poses).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1213.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1213.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Metric Spatial Map + RL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Metric Spatial Map (local metric maps) with end-to-end Reinforcement Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Baseline approach that constructs a local metric occupancy map from depth/RGBD projections and uses an end-to-end RL policy to navigate (or uses frontier-based exploration heuristics), susceptible to accumulated pose errors in long-horizon/noisy settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A behavioral approach to visual navigation with graph localization networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Habitat simulator (Gibson dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same indoor household environments as NTS used for direct baseline comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Implicit dense occupancy/metric local maps rather than explicit node-edge graphs; connectivity represented as traversable free-space in metric map.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Same dataset as NTS; exact map size depends on explored metric area and is not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Metric Spatial Map + RL (and variants Metric Spatial Map + FBE + Local)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Constructs geometric local maps from depth (or predicted depth) and feeds them to an RL policy (PPO trained) or uses classical Frontier-Based Exploration (FBE) heuristics to choose frontiers, coupled with a learned Local Policy for goal approach.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SPL, success rate</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Metric Spatial Map + RL (RGBD overall) Succ/SPL = 0.34/0.13 (Table 1). Metric Spatial Map + FBE + Local overall Succ/SPL = 0.42/0.26 (RGBD).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Metric Spatial Map + RL (RGBD overall) 0.34 (34%); Metric Spatial Map + FBE + Local overall 0.42 (42%).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Metric-map-based RL or hybrid classical heuristics (FBE) + local controller; works well when pose is accurate (low-noise) but degrades under realistic noise.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Metric-map-based methods suffer when the environment induces long trajectories (effectively large graph diameter/long shortest paths) under realistic motion/sensor noise because pose error accumulates across long metric tracks, corrupting the map and path planning; removing motion noise improves their scaling with distance, demonstrating sensitivity to accumulated pose error inherent to metric representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Compared to NTS, metric-map baselines perform worse under realistic noise, especially in medium and hard (longer) tasks; when motion noise is removed, metric baselines improve substantially, closing some of the gap with NTS, implying topology/representation choice interacts with noise and path length.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Metric-map policies require robust localization to remain effective across long-horizon tasks; they benefit less from semantic priors unless those are explicitly incorporated, and without that they explore less efficiently in novel environments compared to NTS with semantic scoring.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1213.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1213.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active Neural SLAM (ANS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active Neural SLAM / Learning to Explore using Active Neural SLAM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modular exploration/navigation model based on metric spatial maps and learned exploration policies; adapted as a baseline for image-goal navigation by using NTS localization and local policy to handle goal detection and approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning to Explore using Active Neural SLAM.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Habitat simulator (Gibson dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Photorealistic indoor scene reconstructions used as an exploration/navigation benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Combines learned exploration policy with metric occupancy mapping; not an explicit topological graph like NTS.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Same dataset; details of internal map sizes depend on rollout and are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Active Neural SLAM (ANS)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Learned exploration policy coupled with metric mapping; adapted to image-goal by using NTS's localization and local navigation modules to recognize and navigate to goals.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SPL, success rate</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>ANS (RGB overall) Succ/SPL = 0.35/0.23; ANS (RGBD overall) Succ/SPL = 0.44/0.29 (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>ANS overall: RGB 0.35 (35%), RGBD 0.44 (44%).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Learned exploration on top of metric maps; hybrid approach with learned exploration heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Performs better than purely reactive RL baselines but still worse than NTS under realistic noise/long-horizon tasks; indicates that integrating learned exploration with metric maps helps but does not fully mitigate pose accumulation issues that topological representations address.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>ANS outperforms simple end-to-end RL baselines but is outperformed by NTS (topological + semantic) in hard/longer tasks, demonstrating that explicit topological structure + semantic priors yields superior exploration efficiency under realistic noise.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Active neural exploration policies coupled to metric maps improve exploration but retain sensitivity to long-horizon pose drift; combining learned exploration heuristics with a topological representation (as in NTS) gives additional robustness and improved long-range planning.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Semi-parametric topological memory for navigation <em>(Rating: 2)</em></li>
                <li>Learning to Explore using Active Neural SLAM <em>(Rating: 2)</em></li>
                <li>A behavioral approach to visual navigation with graph localization networks <em>(Rating: 2)</em></li>
                <li>Visual semantic navigation using scene priors <em>(Rating: 1)</em></li>
                <li>Active neural localization <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1213",
    "paper_id": "paper-214754592",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "NTS",
            "name_full": "Neural Topological SLAM",
            "brief_description": "A supervised, modular topological navigation system that builds an online graph of panoramic-image nodes (regular + 'ghost' frontier nodes), learns geometric (FG) and semantic (FS) predictors per-node/direction, and uses Dijkstra planning on the graph plus a local point-goal controller to solve image-goal navigation under realistic actuation and sensor noise.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Habitat simulator (Gibson dataset)",
            "environment_description": "Photorealistic indoor household environments reconstructed in Gibson and simulated in Habitat; episodic image-goal navigation where the agent receives a panoramic goal image and must reach that location in previously unseen scenes.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": null,
            "graph_connectivity": "Sparse, online-built topological graph: nodes are panoramic-image locations; edges connect adjacent areas and store relative pose between consecutive nodes; 'ghost' nodes (frontier hypotheses) connect to exactly one regular node and represent unexplored directions.",
            "environment_size": "Dataset: curated 86 scenes (split 68 train / 4 val / 14 test). Node radius r = 3 m used to define node neighborhoods; training data sampled 300 images per training scene (≈6.12M source-target pairs). Exact number of nodes per scene varies and is not reported.",
            "agent_name": "Neural Topological SLAM (Global Policy + Local Policy)",
            "agent_description": "Modular agent: Graph Update builds/topologically localizes nodes using a learned Connection model (FL); Geometric Explorable Area Predictor (FG) produces 12-direction frontier hypotheses (ghost nodes); Semantic Score Predictor (FS) scores ghost nodes relative to a goal image; Global Policy selects long-term goal node and plans shortest path via Dijkstra; Local Policy is a point-goal controller that executes relative-pose subgoals using a learned local mapper (or geometric projections for RGBD). All prediction modules are trained jointly in a supervised multi-task ResNet18-based model.",
            "exploration_efficiency_metric": "Success weighted by inverse Path Length (SPL), success rate, and episode length/steps to goal",
            "exploration_efficiency_value": "RGB overall SPL = 0.38 (Succ=0.55); RGBD overall SPL = 0.43 (Succ=0.63). Detailed (NTS RGB): Easy SPL 0.60 (Succ 0.80), Medium SPL 0.31 (Succ 0.47), Hard SPL 0.22 (Succ 0.37). (Values taken from Table 1.)",
            "success_rate": "RGB overall 0.55 (55%); RGBD overall 0.63 (63%). See difficulty breakdown in exploration_efficiency_value.",
            "optimal_policy_type": "Planning-based topological policy with memory: global graph search (Dijkstra) over learned semantic/geometric node scores combined with a local point-goal controller; i.e., memory + planning + learned semantic priors.",
            "topology_performance_relationship": "Multiple explicit findings linking topology features to performance: (1) Topological representation (NTS) is robust to actuation/sensor noise because it stores relative poses only between consecutive nodes, preventing long-range accumulation of pose error that degrades metric maps. (2) Semantic scoring of unexplored directions (FS) substantially improves exploration efficiency early on by biasing exploration toward structurally plausible areas (e.g., hallways to kitchens/bedrooms), increasing success/SPL compared to random frontier selection. (3) The topological map (graph memory) becomes increasingly important over multiple sequential goals: removing the graph (greedy per-image direction selection) causes performance to degrade as the number of sequential goals increases, while removing the semantic score mainly hurts initial exploration efficiency. (4) Metric spatial maps' performance drops quickly with increased path length under motion noise due to accumulated pose errors, whereas NTS's topological edges limit error accumulation.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "The paper compares topological (NTS) vs metric spatial map baselines (metric mapping + RL, metric mapping + FBE, Active Neural SLAM): (a) Under realistic actuation/sensor noise, metric-map methods degrade with distance to goal and perform worse than NTS—NTS shows large relative improvements, especially in harder (longer) tasks. (b) When motion noise is removed, metric-map baselines improve markedly, indicating their weakness primarily arises from pose error accumulation; NTS performance remains strong with or without noise due to local relative-pose edges. (c) Ablations show semantic scoring improves early exploration, while graph memory yields longer-term benefits across sequential goals.",
            "policy_structure_findings": "Key findings on policy structure vs topology: (1) Policies that separate global planning on a topological graph from local point-goal execution perform better in large, noisy environments than end-to-end reactive or purely metric policies. (2) A semantic-scoring module that predicts which frontier directions are more likely to lead to the goal allows the global policy to choose promising ghost nodes (frontiers) and reduces exploratory search. (3) Graph-based memory is necessary for multi-goal/long-horizon tasks because it enables re-use of past observations and avoids purely greedy, myopic exploration that fails over sequences of goals. (4) Metric-map + RL policies require accurate pose estimation (or low-noise conditions); in high-diameter or long-horizon tasks with realistic noise, they need additional mechanisms to avoid pose error accumulation (which NTS's topology avoids by using local relative poses).",
            "uuid": "e1213.0"
        },
        {
            "name_short": "Metric Spatial Map + RL",
            "name_full": "Metric Spatial Map (local metric maps) with end-to-end Reinforcement Learning",
            "brief_description": "Baseline approach that constructs a local metric occupancy map from depth/RGBD projections and uses an end-to-end RL policy to navigate (or uses frontier-based exploration heuristics), susceptible to accumulated pose errors in long-horizon/noisy settings.",
            "citation_title": "A behavioral approach to visual navigation with graph localization networks.",
            "mention_or_use": "use",
            "environment_name": "Habitat simulator (Gibson dataset)",
            "environment_description": "Same indoor household environments as NTS used for direct baseline comparison.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": null,
            "graph_connectivity": "Implicit dense occupancy/metric local maps rather than explicit node-edge graphs; connectivity represented as traversable free-space in metric map.",
            "environment_size": "Same dataset as NTS; exact map size depends on explored metric area and is not reported.",
            "agent_name": "Metric Spatial Map + RL (and variants Metric Spatial Map + FBE + Local)",
            "agent_description": "Constructs geometric local maps from depth (or predicted depth) and feeds them to an RL policy (PPO trained) or uses classical Frontier-Based Exploration (FBE) heuristics to choose frontiers, coupled with a learned Local Policy for goal approach.",
            "exploration_efficiency_metric": "SPL, success rate",
            "exploration_efficiency_value": "Metric Spatial Map + RL (RGBD overall) Succ/SPL = 0.34/0.13 (Table 1). Metric Spatial Map + FBE + Local overall Succ/SPL = 0.42/0.26 (RGBD).",
            "success_rate": "Metric Spatial Map + RL (RGBD overall) 0.34 (34%); Metric Spatial Map + FBE + Local overall 0.42 (42%).",
            "optimal_policy_type": "Metric-map-based RL or hybrid classical heuristics (FBE) + local controller; works well when pose is accurate (low-noise) but degrades under realistic noise.",
            "topology_performance_relationship": "Metric-map-based methods suffer when the environment induces long trajectories (effectively large graph diameter/long shortest paths) under realistic motion/sensor noise because pose error accumulates across long metric tracks, corrupting the map and path planning; removing motion noise improves their scaling with distance, demonstrating sensitivity to accumulated pose error inherent to metric representations.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Compared to NTS, metric-map baselines perform worse under realistic noise, especially in medium and hard (longer) tasks; when motion noise is removed, metric baselines improve substantially, closing some of the gap with NTS, implying topology/representation choice interacts with noise and path length.",
            "policy_structure_findings": "Metric-map policies require robust localization to remain effective across long-horizon tasks; they benefit less from semantic priors unless those are explicitly incorporated, and without that they explore less efficiently in novel environments compared to NTS with semantic scoring.",
            "uuid": "e1213.1"
        },
        {
            "name_short": "Active Neural SLAM (ANS)",
            "name_full": "Active Neural SLAM / Learning to Explore using Active Neural SLAM",
            "brief_description": "A modular exploration/navigation model based on metric spatial maps and learned exploration policies; adapted as a baseline for image-goal navigation by using NTS localization and local policy to handle goal detection and approach.",
            "citation_title": "Learning to Explore using Active Neural SLAM.",
            "mention_or_use": "use",
            "environment_name": "Habitat simulator (Gibson dataset)",
            "environment_description": "Photorealistic indoor scene reconstructions used as an exploration/navigation benchmark.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": false,
            "door_constraints_description": null,
            "graph_connectivity": "Combines learned exploration policy with metric occupancy mapping; not an explicit topological graph like NTS.",
            "environment_size": "Same dataset; details of internal map sizes depend on rollout and are not reported.",
            "agent_name": "Active Neural SLAM (ANS)",
            "agent_description": "Learned exploration policy coupled with metric mapping; adapted to image-goal by using NTS's localization and local navigation modules to recognize and navigate to goals.",
            "exploration_efficiency_metric": "SPL, success rate",
            "exploration_efficiency_value": "ANS (RGB overall) Succ/SPL = 0.35/0.23; ANS (RGBD overall) Succ/SPL = 0.44/0.29 (Table 1).",
            "success_rate": "ANS overall: RGB 0.35 (35%), RGBD 0.44 (44%).",
            "optimal_policy_type": "Learned exploration on top of metric maps; hybrid approach with learned exploration heuristics.",
            "topology_performance_relationship": "Performs better than purely reactive RL baselines but still worse than NTS under realistic noise/long-horizon tasks; indicates that integrating learned exploration with metric maps helps but does not fully mitigate pose accumulation issues that topological representations address.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "ANS outperforms simple end-to-end RL baselines but is outperformed by NTS (topological + semantic) in hard/longer tasks, demonstrating that explicit topological structure + semantic priors yields superior exploration efficiency under realistic noise.",
            "policy_structure_findings": "Active neural exploration policies coupled to metric maps improve exploration but retain sensitivity to long-horizon pose drift; combining learned exploration heuristics with a topological representation (as in NTS) gives additional robustness and improved long-range planning.",
            "uuid": "e1213.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Semi-parametric topological memory for navigation",
            "rating": 2,
            "sanitized_title": "semiparametric_topological_memory_for_navigation"
        },
        {
            "paper_title": "Learning to Explore using Active Neural SLAM",
            "rating": 2,
            "sanitized_title": "learning_to_explore_using_active_neural_slam"
        },
        {
            "paper_title": "A behavioral approach to visual navigation with graph localization networks",
            "rating": 2,
            "sanitized_title": "a_behavioral_approach_to_visual_navigation_with_graph_localization_networks"
        },
        {
            "paper_title": "Visual semantic navigation using scene priors",
            "rating": 1,
            "sanitized_title": "visual_semantic_navigation_using_scene_priors"
        },
        {
            "paper_title": "Active neural localization",
            "rating": 1,
            "sanitized_title": "active_neural_localization"
        }
    ],
    "cost": 0.01340175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Neural Topological SLAM for Visual Navigation</p>
<p>Devendra Singh Chaplot 
Carnegie Mellon University</p>
<p>† 
Ruslan Salakhutdinov 
Carnegie Mellon University</p>
<p>Abhinav Gupta 
Carnegie Mellon University</p>
<p>Facebook AI Research</p>
<p>Saurabh Gupta 
UIUC</p>
<p>Neural Topological SLAM for Visual Navigation
Project webpage: https://devendrachaplot.github.io/projects/Neural-Topological-SLAM
This paper studies the problem of image-goal navigation which involves navigating to the location indicated by a goal image in a novel previously unseen environment. To tackle this problem, we design topological representations for space that effectively leverage semantics and afford approximate geometric reasoning. At the heart of our representations are nodes with associated semantic features, that are interconnected using coarse geometric information. We describe supervised learning-based algorithms that can build, maintain and use such representations under noisy actuation. Experimental study in visually and physically realistic simulation suggests that our method builds effective representations that capture structural regularities and efficiently solve long-horizon navigation problems. We observe a relative improvement of more than 50% over existing methods that study this task.</p>
<p>Introduction</p>
<p>Imagine you are in a new house as shown in Fig 1 and you are given the task of finding a target object as shown in Fig 1 (top). While there are multiple possible directions to move, most of us would choose the path number 2 to move. This is because we use strong structural priors -we realize the target is an oven which is more likely to be found in the kitchen which seems accessible via path number 2. Now let us suppose, once you reach the oven, your goal is to reach back to the living room which you saw initially. How would you navigate? The answer to this question lies in how we humans store maps (or layout) of the house we just traversed. One possible answer would be metric maps, in which case we would know exactly how many steps to take to reach the living room. But this is clearly not how we humans operate [16,42]. Instead, most of us would first get out of the kitchen by moving to the hallway and then navigate to the living room which is visible from the hallway.</p>
<p>It is clear from the above examples, there are two main Figure 1: Semantic Priors and Landmarks. When asked to go to target image of an oven most humans would use the path number 2 since it allows access to kitchen. Humans use semantic priors and common-sense to explore and navigate everyday yet most navigation algorithms struggle to do so.</p>
<p>components of a successful visual navigation algorithm: (a) ability to build spatial representations and store them; (b) ability to exploit structural priors. When it comes to spatial representations, the majority of papers in navigation insist on building metrically precise representations of free space. However, metric maps have two major shortcomings: first, metric maps do not scale well with environment size and amount of experience. But more importantly, actuation noise on real-robots makes it challenging to build consistent representations, and precise localization may not always be possible. When it comes to exploiting structural priors, most learning-based approaches do not model these explicitly. Instead, they hope the learned policy function has these priors encoded implicitly. But it still remains unclear if these policy functions can encode semantic priors when learned via RL.</p>
<p>In this paper, we propose to tackle both the problems head-on. Instead of using metric-maps which are brittle to localization and noise, we propose a topological representation of the space. Our proposed representation consists of nodes that are connected in the form of a graph, based on local geometry information. Each node is repre- sented visually via a 360-degree panoramic image. Nodes are connected to each other using approximate relative pose between them. But what makes our visual topological maps novel are two directional functions F g and F s , which extract geometric and semantic properties of nodes. Specifically, F g estimates how likely agent will encounter freespace and F s estimates how likely target image is to be encountered if the agent moves in a particular direction. By explicitly modeling and learning function F s , our model ensures that structural priors are encoded and used when exploring and navigating new unseen environments.</p>
<p>Our representation has few advantages over classical and end-to-end learning-based approaches: (a) it uses graphbased representation which allows efficient long-term planning; (b) it explicitly encodes structural priors via function F s ; (c) the geometric function F g allows efficient exploration and online map building for a new environment; (d) but most importantly, all the functions and policies can be learned in completely supervised manner forgoing the need for unreliable credit assignment via RL.</p>
<p>Related Work</p>
<p>Our paper makes contributions across the following multiple aspects of the navigation problem: space representation, training paradigm for navigation policies, and different navigation tasks. We survey works in these areas below.</p>
<p>Navigation Tasks. Navigation tasks can be divided into two main categories. The first category of tasks is ones where the goal location is known, and limited exploration is necessary. This could be in the form of a simply wandering around without colliding [15,34], following an object [23], getting to a goal coordinate [1,17]: using sequence of images along the path [5,22], or language-based instructions [2]. Sometimes, the goal is specified as an image but experience from the environment is available in the form of demonstrations [13,35], or in the form of reward-based training [25,48], which again limits the role of exploration. The second category of tasks is when the goal is not known and exploration is necessary. Examples are tasks such as finding an object [17], or room [43], in a novel environment, or explicit exploration [6,9]. These task categories involve different challenges. The former tasks focus on effective retrieval and robust execution, while the later tasks involve semantic and common sense reasoning in order to efficiently operate in previously unseen environments. Our focus, in this work, is the task of reaching a target image in a novel environment. No experience is available from the environment, except for the target image. We aren't aware of any works that target this specific problem.</p>
<p>Classical Space Representations. Spatial and topological representations have a rich history in robot navigation. Researchers have used explicit metric spatial representations [12], and have considered how can such representations be built with different sensors [19,[27][28][29]39], and how can agents be localized against such representations [11]. Recent work has started associating semantics with such spatial representations [4]. In a similar vein, non-metric topological representations have also been considered in classical literature [10,21,24]. Some works combine topological and metric representations [40,41], and some study topological representations that are semantic [21]. While our work builds upon the existing literature on topological maps, the resemblance is only at high-level graph structure. Our work focuses on making visual topological mapping and exploration scalable, robust and efficient. We achieve this via the representation of both semantic and geometric properties in our topological maps; the ability to build topological maps in an online manner and finally, posing the learning problem as a supervised problem.</p>
<p>Learned Space Representations. Depending on the problem being considered, different representations have been investigated. For short-range locomotion tasks, purely reactive policies [3,15,23,34] suffice. For more complex problems such as target-driven navigation in a novel environment, such purely reactive strategies do not work well [48], and memory-based policies have been investigated. This can be in the form of vanilla neural network memories such as LSTMs [26,30], or transformers [14]. Researchers have also incorporated insights from classical literature into the design of expressive neural memories for navigation. This includes spatial memories [17,31] and topological approaches [8,13,35,36,43,46]. Learned spatial approaches can acquire expressive spatial representations [17], they are however bottle-necked by their reliance on metric consistency and thus have mostly been shown to work in discrete state spaces for comparatively short-horizon tasks [17,31]. Researchers have also tackled the problem of passive and active localization [7,27], in order to aid building such consistent metric representations. Some topological approaches [8,13,35] work with human explorations or prebuilt topological maps, thus ignoring the problem of exploration. Others build a topological representation with explicit semantics [43,47], which limits tasks and environments that can be tackled. In contrast from past work, we unify spatial and topological representations in a way that is robust to actuation error, show how we can incrementally and autonomously build topological representations, and do semantic reasoning.</p>
<p>Training Methodology. Different tasks have also lead to the design of different training methodologies for training navigation policies. This ranges from reinforcement learning with sparse and shaped rewards [25,26,32,34,48], imitation learning and DAgger [17,33], self-supervised learning for individual components [15,35]. While RL allows learning of rich exploratory behavior, training policies using RL is notoriously hard and sample inefficient. Imitation learning is sample efficient but may not allow learning exploratory behavior. Self-supervised learning is promising but has only been experimented in the context of known goal tasks. We employ a supervised learning approach and show how we can still learn expressive exploration behavior while at the same time not suffering from exuberant sample complexity for training. When the goal image is of the living room (left), the score of the directions in the center are higher as they lead to the living room. When the goal image is of a bedroom (right), the scores corresponding to the pathway on the left are higher as they are more likely to lead to the bedroom.</p>
<p>Task Setup</p>
<p>We consider an autonomous agent situated in an episodic environment. At the beginning of an episode, the agent receives a target goal image, I G . At each time step t, the agent receives observations (s t ) from the environment. Each observation consists of the current first-person image observation, I t , from a panoramic camera and a pose estimate from a noisy motion sensor. At each time step, the agent takes a navigational action a t . The objective is to learn a policy π(a t |s t , I G ) to reach the goal image. In our experimental setup, all images are panoramas, including agent observations and goal image.</p>
<p>Methods</p>
<p>We propose a modular model, 'Neural Topological SLAM (NTS)', which builds and maintains a topological map for navigation. The topological map is represented using a graph, denoted by G t at time t. Each node in the graph (N i ) is associated with a panoramic image (I Ni ) and represents the area visible in this image. Two nodes are connected by an edge (E i,j ) if they represent adjacent areas. Each edge also stores the relative pose between two nodes, ∆p ij .</p>
<p>Our model consists of three components, a Graph Update module, a Global Policy, and a Local Policy. On a high level, the Graph Update module updates the topological map based on agent observations, the Global Policy selects a node in the graph as the long-term goal and finds a subgoal to reach the goal using path planning, and the Local Policy navigates to the subgoal based on visual observations. Fig. 2 provides an overview of the proposed model.</p>
<p>The above components will require access to 4 functions. We first define these 4 functions and then describe how they are used by the components of the model. Graph Localization (F L ). Given a graph G and an image I, this function tries to localize I in a node in the graph. An image is localized in a node if its location is visible from the panoramic image associated with the node. Internally, this requires comparing each node image (I Ni ) with the given image (I) to predict whether I belongs to node N i .</p>
<p>Geometric Explorable Area Prediction (F G ). Given an image I, this function makes n θ = 12 different predictions of whether there's explorable area in the direction θ sampled uniformly between 0 and 2π. Figure 3 shows an example of input and output of this function. Intuitively, it recognizes doors or hallways which lead to other areas.</p>
<p>Semantic Score Prediction (F S ). Given a source image I S and a goal image I G , this function makes n θ = 12 different predictions of how fast the agent is likely to reach the goal image if it explores in the direction θ sampled uniformly between 0 and 2π. Figure 4 shows example inputoutput pairs for this function. The scores corresponding to the same source image change as the goal image changes. Estimating this score requires the model to learn semantic priors about the environment.</p>
<p>Relative Pose Prediction (F R ). Given a source image I S and a goal image I G which belong to the same node, this function predicts the relative pose (∆p S,G ) of the goal image from the source image.</p>
<p>Model components</p>
<p>Assuming that we have access to the above functions, we first describe how these functions are used by the three components to perform Image Goal Navigation. We then describe how we train a single model to learn all the above functions using supervised learning.</p>
<p>Graph Update. The Graph Update module is responsible for updating the topological map given agent observations. At t = 0, the agent starts with an empty graph. At each time step, the Graph Update module (f GU ) takes in the current observations s t and the previous topological map G t−1 and outputs the updated topological map, G t = f GU (s t , G t−1 ). Figure 5 shows an overview of the Graph Update Module.</p>
<p>In order to update the graph, the module first tries to localize the current image in a node in the current graph using the Graph Localization function (F L ). If the current image is localized in a node different from the last node, we add an edge between the current node and the last node (if it does not exist already). If the current image is not localized, then we create a new node with the current image. We also add an edge between the new node and the last node. Every time we add an edge, we also store the relative pose (∆p) between the two nodes connected by the edge using the sensor pose estimate.</p>
<p>The above creates a graph of the explored areas. In order to explore new areas, we also predict and add unexplored areas to the graph. We achieve this by augmenting the graph with 'ghost' nodes which are agent's prediction of explorable areas using the Geometric Explorable Area Prediction function (F G ). If there is an explorable area in a direction θ, we add a 'ghost' node (X k ) and connect it to the new node (N i ) using edge E i,k . Since we do not have the image at the ghost node location, we associate a patch of the node image in the direction of θ, i.e. (I X k = I Ni,θ ). The relative pose between the new node and the ghost node is stored as (r, θ), where θ is the direction and r = 3m is the radius of the node. The ghost nodes are always connected to exactly one regular node and always correspond to unexplored areas. We ensure this by removing ghost nodes when adding regular nodes in the same direction, and not adding ghost nodes in a particular direction if a regular node exists in that direction. Intuitively, ghost nodes correspond to the unexplored areas at the boundary of explored areas denoted by regular nodes.</p>
<p>Global Policy. The Global Policy is responsible for selecting a node in the above graph as the long-term goal. It first tries to localize the goal image in the current graph using the Graph Localization function (F L ). If the goal image (I G ) is  Figure showing an overview of the Global Policy. It takes the current Graph (Gt) and the Goal Image (IG) as input. It first tries to localize the Goal Image in the Graph. If the Goal Image is localized, the corresponding node is selected as the long-term goal. If the Goal Image is not localized, then the semantic scoring function (FS) is used to score all the ghost nodes based on how close they are to the goal image. The ghost node with the highest score is selected as the long-term goal. Given a long-term goal, a subgoal node is computed using graph path planning. The relative directions to the subgoal node are the output of the Global Policy which is passed to the Local Policy. localized in a node N i , then N i is chosen as the long-term goal. If the goal image is not localized, then the Global Policy needs to choose an area to explore, i.e. choose a ghost node for exploration. We use the Semantic Score Prediction (F S ) function to predict the score of all ghost nodes. The Global Policy then just picks the ghost node with the highest score as the long-term goal.</p>
<p>Once a node is selected as a long-term goal, we plan the path to the selected node from the current node using Djikstra's algorithm on the current graph. The next node on the shortest path is chosen to be the subgoal (N SG ). The relative pose associated with the edge to the subgoal node is passed to the Local Policy (∆p i,SG ).</p>
<p>If the goal image is localized in the current node (or the agent reaches the node N i where the goal image (I G ) is localized), the Global policy needs to predict the relative pose of I G with respect to the current agent observation. We use the Relative Pose Prediction (F R ) function to get the relative pose of the goal image, which is then passed to the Local Policy.</p>
<p>Local Policy. The Local Policy receives the relative pose as goal directions which comprises of distance and angle to the goal. Given the current image observation and the relative goal directions, the Local Policy takes navigation actions to reach the relative goal. This means the Local Policy is essentially a PointGoal navigation policy. Our Local Policy is adapted from [6]. It predicts a local spatial map using a learned mapper model in the case of RGB input or using geometric projections of the depth channel in case of RGBD input. It then plans a path to the relative goal using shortest path planning.</p>
<p>Training NTS Multi-task Learning model</p>
<p>Given access to the four functions described above, we discussed how the different components use these functions for navigation. In this subsection, we describe how we train a single multi-task learning model to learn all the four functions. Figure 7 shows an overview of this multitask learning model. It takes a Source Image (I S ) and a Goal Image (I G ) as input and encodes them using a shared ResNet18 [18] encoder. It first predicts whether the two images belong to the same node or not. This prediction is used to implement the Graph Localization function (F L ). If they belong to the same node, it makes Intra-Node predictions which include the direction and score (or equivalently) distance of the Goal Image relative to the Source Image. These predictions are used to implement the Relative Pose Prediction function (F R ). If they belong to different nodes, it makes Inter-Node Predictions which include directions of explorable areas (which is used as the Geometric Explorable Area Prediction function (F G )) and a semantic score corresponding to each explorable area denoting its proximity of the Goal Image (which is used as the Semantic Score Prediction function (F S )). The Connection, Intra-Node Prediction, and Inter-Node Prediction models consist of fully-connected layers with ReLU activations and dropout. Exact details are deferred to the supplementary material.</p>
<p>Experimental Setup</p>
<p>Environment. All our experiments are conducted in the Habitat simulator [37] with the Gibson [44] dataset. The Gibson dataset is visually realistic as it consists of reconstructions of real-world scenes. We also implement physically realistic motion sensor and actuation noise models as proposed by [6]. Actuation motion noise leads to stochastic transitions as the amount translated or rotated by the agent is noisy. This model also adds realistic translational noise in rotation actions and rotational noise in translational actions. The sensor noise model adds realistic noise to the base odometry sensor readings. Both the noise models are based on real-world data and agents trained on these noise models are shown to transfer to the real-world [6].  Figure showing an overview of the NTS Multi-task Learning Model. It takes a Source Image (IS) and a Goal Image (IG) as input and encodes them using a shared ResNet18 encoder. It first predicts whether the two images belong to the same node or not. If they belong to the same node, it makes Intra-Node predictions which include the direction and score (or equivalently) distance of the Goal Image relative to the Source Image. If they belong to different nodes, it makes Inter-Node Predictions which include directions of explorable areas and a semantic score corresponding to each explorable area denoting its proximity of the Goal Image. All the predictions of this model are used at various places in the components of the overall NTS model. See text for more details.</p>
<p>Task setup. We use panoramic images of size 128 × 512 for both agent image observation and target goal image. We conduct experiments with both RGB and RGBD settings. The base odometry sensor provides a 3×1 reading denoting the change in agent's x-y coordinates and orientation. The action space consists of four actions: move forward, turn right, turn left, stop. The forward action moves the agent approximately 25cm forward and the turn actions turn the agent approximately 10 degrees. Note that the state space and motion of the agent are continuous. The agent succeeds in an episode if it takes the stop action within a 1m radius of the target location. The agent fails if it takes stop action anywhere else or does not take the stop till the episode ends. In addition to the success rate, we also use Success weighted by inverse Path Length (SPL) as an evaluation metric as proposed by [1]. It takes into account the efficiency of the agent in reaching the goal (shorter successful trajectories lead to higher SPL).</p>
<p>Training data. We split the curated set of 86 scenes from [37] into sets of 68/4/14 scenes for train/val/test. For training our supervised learning model, we sample 300 images randomly in each of 68 training scenes. We get labels for pairs of source and target images in each scene giving us a total of approximately 68 × 300 × 300 = 6.12 million data points. The labeling process is automated and it only requires the ground-truth map already available with the dataset without the need for any additional human annotation. Details of the labeling process are deferred to the supplementary material. Note that sampling images or the ground-truth map are not required for the test environments.</p>
<p>Test episodes. For creating test episodes, we sample episodes (given by starting and goal locations) in the test scenes to create 3 different sets of difficulty based on the distance of the goal from starting locations: Easy (1.5 − 3m), Medium (3 − 5m) and Hard (5 − 10m). The maximum episode length is 500 steps for each difficulty level.</p>
<p>Baselines</p>
<p>We use the following baselines for our experiments: ResNet + GRU + IL. A simple baseline consisting of ResNet18 image encoder and GRU based policy trained with imitation learning (IL). Target-driven RL. A siamese style model for encoding the current image and the goal image using shared convolutional networks and trained end-to-end with reinforcement learning, adapted from Zhu et al. [48]. Metric Spatial Map + RL. An end-to-end RL model which uses geometric projections of the depth image to create a local map and passes it to the RL policy, adapted from Chen et al. [9]. Metric Spatial Map + FBE + Local. This is a handdesigned baseline which creates a map using depth images and then uses a classical exploration heuristic called Frontier-based Exploration (FBE) [45] which greedily explores nearest unexplored frontiers in the map. We use the Localization model and Local Policy from NTS to detect when a goal is nearby and navigate to it. Active Neural SLAM. This is a recent modular model based on Metric Spatial Maps proposed for the task of exploration. We adapt it to the Image Goal task by using the Localization model and Local Policy from NTS to detect when a goal is nearby and navigate to it.</p>
<p>All the baselines are trained for 25 million frames. RL baselines are trained using Proximal Policy Optimization [38] with a dense reward function. The reward function includes a high reward for success (=SPL*10.), a shaping reward equal to the decrease in distance to the goal and a per step reward of -0.001 to encourage shorter trajectories. ResNet + GRU + IL is trained using behavioral cloning on the ground-truth trajectory. This means just like the proposed model, all the baselines also use the groundtruth map for training. In terms of the number of training samples, sampling 300 random images in the environment would require 300 episode resets in the RL training setup. 300 episodes in 68 scenes would lead to a maximum of 10.2 million (= 68 × 300 × 500) samples. Since we use 25 million frames to train our baselines, they use strictly more data than our model. Furthermore, our model does not require any interaction in the environment and can be trained offline with image data.</p>
<p>Results</p>
<p>We evaluate the proposed method and all the baselines on 1000 episodes for each difficulty setting. We compare all the methods across all difficulty levels in both RGB and RGBD settings in Table  Comparison with end-to-end RL and the effect of stop action. The results indicate that NTS performs better than both end-to-end RL based baselines [9,48] and methods using metric spatial maps [6,9]. The performance of the RLbased baselines is much weaker than the proposed model. We believe the reason behind this is the complexity of the exploration search space. Compared to the Pointgoal navigation task where the agent receives updated direction to the goal at each time step, Image Goal navigation is more difficult in terms of exploration as the goal image does not directly provide the direction to explore. Another difficulty is exploring the 'stop' action. Prior setups of the Image Goal task where end-to-end RL policies were shown to perform reasonably well assumed that the agent succeeded if it hits the goal state. However, based on the suggestion from [1], we added the 'stop' action as it is more realistic. To quantify the effect of stop action, we report the performance of all the models without the stop action in Table 2(left). We see that the performance of RL baselines is much higher. However, the performance of NTS also increases as the agent automatically stops when it reaches the goal state instead of using the prediction of the Relative Pose Estimator to stop. Other differences that make our experimental setup more realistic but also makes exploration harder for RL as compared to prior setups include continuous state space as compared to grid-based state space, fine-grained action as compared to 90 degree turns and grid cell forward steps and stochastic transitions due to realistic motion noise.</p>
<p>Comparison with spatial map-based methods and the effect of motion noise. The performance of metric spatial map-based baselines drops quickly as the distance to the goal increases. This is likely due to the accumulation of pose errors as the trajectory length increases. Errors in pose prediction make the map noisy and eventually lead to incorrect path planning. To quantify this effect, we evaluate all the models without any motion actuation and sensor noise in Table 2(right). The results show that the performance of the metric map-based baselines scales much better with distance in the absence of motion noise, however, the performance of NTS does not increase much. This indicates that NTS is able to tackle motion noise relatively well. This is because NTS only uses pose estimates between consecutive nodes, which do not accumulate much noise as they are a few actions away from each other. The performance of NTS is still better than the baselines even without motion noise as it consists of Semantic Score Predictor (F S ) capable of learning structural priors which the metric spatial map-based baselines lack. We quantify the effect of the Semantic Score Predictor in the following subsection.   </p>
<p>Ablations and Sequential Goals</p>
<p>In this subsection, we evaluate the proposed model on sequential goals in a single episode and study the importance of the topological map or the graph and the Semantic Score Predictor (F S ). For creating a test episode with sequential goals, we randomly sample a goal between 1.5m to 5m away from the last goal. The agent gets a time budget of 500 timesteps for each goal. We consider two ablations:</p>
<p>NTS w/o Graph. We pick the direction with the highest score in the current image greedily, not updating or using the graph over time. Intuitively, the performance of this ablation should deteriorate as the number of sequential goals increases as it has no memory of past observations.</p>
<p>Neural Topological SLAM w/o Score Function. In this ablation, we do not use the Semantic Score Predictor (F S ) and pick a ghost node randomly as the long-term goal when the Goal Image is not localized in the current graph. Intuitively, the performance of this ablation should improve with the increase in the number of sequential goals, as random exploration would build the graph over time and increase the likelihood of the Goal Image being localized.</p>
<p>We report the success rate and SPL of NTS and the two ablations as a function of the number of sequential goals in Figure 8. Success, in this case, is defined as the ratio of goals reached by the agent across a test set of 1000 episodes. The performance of NTS is considerably higher than both the ablations, indicating the importance of both the components. The drop in performance when the semantic score function is removed indicates that the model learns some semantic priors ( Figure 10 shows an example). The performance of all the models decreases with an increase in the number of sequential goals because if the agent fails to reach an intermediate goal, there is a high chance that the subsequent goals are farther away. The performance gap between NTS and NTS w/o Score Function decreases and the performance gap between NTS and NTS w/o Graph increases with increase in the number of sequential goals as expected. This indicates that the topological map becomes more important over time as the agent explores a new environment, and while the Semantic Score Predictor is the most important at the beginning to explore efficiently.</p>
<p>Discussion</p>
<p>We designed topological representations for space that leverage semantics and afford coarse geometric reasoning. We showed how we can build such representation autonomously and use them for the task of image-goal navigation. Topological representations provided robustness to actuation noise, while semantic features stored at nodes allowed the use of statistical regularities for efficient exploration in novel environments. We showed how advances made in this paper make it possible to study this task in settings where no prior experience from the environment is available, resulting in a relative improvement of over 50%.</p>
<p>In the future, we plan to deploy our models on real robots.  Bottom: The goal images is of a bedroom. With the same starting location and the same ghost nodes, the NTS models select a different ghost node which leads to the correct bedroom. The NTS Multi-task Learning model consists of 4 modules, a ResNet18 encoder [18], a Connection model, an Inter-node Predictions model, and an Intra-node Predictions model as shown in Figure 7. Given panoramic source (I S ) and goal (I G ) images, each of size 128 × 512, we first construct n θ = 12 square patches from each panoramic image. The i th patch consists of 128 × 128 image centered at i/n θ * 2π radians. These resulting patches are such that each patch overlaps with 1/3 portion of the adjacent patch on both sides (patches are wrapped around at the edge of the panorama). Each of the n θ patches of both source and target images is passed through the ResNet18 encoder to get a patch representation of size 128. The architecture of the ResNet18 encoder is shown in Figure 11 for RGB setting. For RGBD, we pass the depth channel through separate non-pretrained ResNet18 Conv layers, followed by 1x1 convolution to get a representation of size 512. This representation is concatenated with the 512 size RGB representation and passed through FC1 and FC2 to finally get the same 128 size patch representation. We use a dropout of 0.5 in FC1 and FC2 and ReLU non-linearity between all layers.</p>
<p>Given 12 patch representations for source and goal images each, the connection model predicts whether the two images belong to the same node or not. The architecture of the Connection Model is shown in Figure 12. If the two images belong to the same node, the Intra-Node Predictions model predicts the direction and score (or equivalently distance) of the goal image relative to the source image. The architecture of the Intra-Node Predictions Model is shown in Figure 13. If the two images belong to different nodes, the Inter-Node Predictions model predicts the explorable area directions and the score of each direction. The architecture of the Inter-Node Predictions Model is shown in Figure 14. As shown in the figure, the explorable area directions are specific to the source image patches and independent of the goal image. We use ReLU non-linearity between all layers in all the modules.</p>
<p>The entire model is trained using supervised learning. We use Cross-Entropy Loss for the Connection and direction labels and MSE Loss for score labels. We use a loss coefficient of 10 for the score labels and a loss coefficient of 1 for the connection and direction labels. We train the model jointly with all the 5 losses using the Adam optimizer [20] with a learning rate of 5e-4 and a batch size of 64.</p>
<p>B. Dataset collection and automated labeling</p>
<p>For training the NTS Multi-task Learning model, we need to collect the data and different types of labels. We randomly sample 300 points in each training scene. For each ordered pair of images, source image (I S ) and goal image (I G ), we gather the different labels as follow:</p>
<p>Connection label: This label denotes whether the source and goal image belong to the same node or not. We get this label by detecting whether the goal image location is visible from the source image. To compute this, we take a 5-degree patch of depth image centered at the relative direction of the goal image from the source image. If the maximum depth in this patch is greater than the distance to the goal image, then the goal image belongs to the same node as the source image and the label is 1. Intuitively, the above checks whether the maximum depth value in the direction of the goal image is greater than the distance to the goal. If the maximum depth in the direction of goal image is greater than the distance to the goal image or if the distance to the goal image is greater than r = 3m, then the goal image belongs to a different node and the label is 0. Intra-node labels: If the source and goal image belong to the same node, i.e. the above label is 1, then the intranode direction and score labels are directly obtained from relative position of the goal image from the source image. Let the relative position of the goal image be ∆p = (d, θ), where d is the distance and θ is the angle to the goal image from the source image. Intra-node direction label is just the 360/n θ = 30 degree bin in which θ falls, i.e. nint(θ/2π × n θ ) where nint(·) is the nearest integer function. For the intra-node score label (s), we just convert the distance d to a score between 0 and 1 using the following function: s = max((1 − d/r), 0)</p>
<p>where s denotes the score, r = 3m denotes the radius of the node, d is the distance. Note that the direction label is discrete and the score label is continuous.</p>
<p>Inter-node labels: If the source and goal image do not belong to the same node, i.e. the connection label is 0, we compute the inter-node labels. For computing the internode direction labels, we first project the depth channel in the panoramic source image to compute an obstacle map. We ignore obstacles beyond r = 3m. In this obstacle map, we take n θ = 12 points at angles i/n θ × 2π, ∀i ∈ [1, 2, . . . , 12] and distance r = 3m away. For every, i ∈ [1, 2, . . . , 12], if the shortest path distance to the corresponding is less than 1.05 × r, then the corresponding inter-node direction label is 1 and otherwise 0. Let the inter-score labels be denoted by s i , ∀i ∈ [1, 2, . . . , 12]. For the inter-node score label s i , we find the farthest explored and traversable point in direction i × (2π/n θ ) in the above obstacle map. Let the shortest path distance (geodesic distance) of the goal image from this point be d i . Then the score label is given by:
s i = max((1 − d i /d max ), 0)
where d max = 20m is the maximum distance above which the score is 0.    </p>
<p>Figure 2 :
2Model Overview. Figure showing an overview of the proposed model, Neural Topological SLAM. It consists of 3 components, a Graph Construction module which updates the topological map as it receives observations, a Global Policy which samples subgoals, and a Local Policy which takes navigational actions to reach the subgoal. See text for more details.</p>
<p>Figure 3 :
3Geometric Explorable Area Prediction (FG). Figure showing sample input image (I) and output predictions of the Geometric Explorable Area Prediction function (FG). The green boxes show doorways for reference, and are not available as input.</p>
<p>Figure 4 :
4Semantic Score Prediction (FS). Figure showing sample input and output predictions of the Semantic Score Prediction function (FS). The score predictions change based on the goal image.</p>
<p>Figure 5 :
5Graph Update.Figure showingan overview of the Graph Update Module. It takes the current Graph (Gt) and the agent observation (It) as input. It first tries to localize the agent in the Graph. If the agent is localized in a node different from the last timestep, it changes the location of the agent and adds an edge if required. If the agent is not localized, a new node is added and corresponding ghost nodes are added using the geometric explorable area prediction function (FG). See the text for more details.</p>
<p>Figure 6 :
6Global Policy.</p>
<p>Figure 7 :
7NTS Multi-task Learning Model.</p>
<p>1 .
1The results show that the proposed method outperforms all the baselines by a considerable margin across all difficulty settings with an overall Succ/SPL of 0.55/0.38 vs 0.35/0.23 in RGB and 0.63/0.43 vs 0.44/0.29 in RGBD. The results also indicate the relative improvement of NTS over the baselines increases as the difficulty increases leading to a large improvement in the hard setting (0.43/0.26 vs 0.16/0.09 in RGBD). InFig 9,we visualize an example trajectory using the NTS model.</p>
<p>Figure 8 :
8Performance of the proposed model NTS and two ablations as a function of number of sequential goals.</p>
<p>Figure 9 :
9Example Trajectory Visualization. Figure showing a visualization of an example trajectory using the NTS model. Agent observations are shown on the left and the topological map and pose are shown on the right. Note that the map and the goal location are shown only for visualization and are not available to the NTS model. (t=0) NTS model creates the first node and adds the ghost nodes. Note that ghost node locations are not predicted, the model predicts only the direction of ghost nodes. The model correctly selects the correct ghost node closest to the goal. (t=33) The NTS model creates the second regular node and adds ghost nodes. Note that the ghost node in the direction of the second node from the first node are removed. (t=51) The NTS model creates another new node. (t=86) The agent reaches the goal after creating 4 nodes as shown in the trajectory on the map and decides to take the stop action.</p>
<p>Figure 10 :
10Learning Semantic Priors. Figure showing an example indicating that NTS model learns semantic priors. The figure shows the first time step for two different episodes starting at the same location but with different goal images. Top: The goal image is of a living room. The NTS model successfully selects the ghost node leading down the hallway as other ghost nodes lead to different bedrooms.</p>
<p>Figure 11 :
11ResNet18 Encoder. Figure showing the architecture of the ResNet18 Encoder.</p>
<p>Figure 12 :
12Connection Model. Figure showing the architecture of the Connection Model.</p>
<p>Figure 13 :
13Intra-Node Predictions Model. Figure showing the architecture of the Intra-Node Predictions Model.</p>
<p>Figure 14 :
14Inter-Node Predictions Model. Figure showing the architecture of the Inter-Node Predictions Model.</p>
<p>Table 1: Results. Performance of the proposed model Neural Topological SLAM (NTS) and the baselines in RGB and RGBD settings.Easy </p>
<p>Medium 
Hard 
Overall 
Model 
Succ SPL 
Succ SPL 
Succ SPL 
Succ SPL </p>
<p>RGB </p>
<p>ResNet + GRU + IL 
0.57 0.23 
0.14 0.06 
0.04 0.02 
0.25 0.10 
Target-driven RL [48] 
0.56 0.22 
0.17 0.06 
0.06 0.02 
0.26 0.10 
Active Neural SLAM (ANS) [6] 
0.63 0.45 
0.31 0.18 
0.12 0.07 
0.35 0.23 
Neural Topological SLAM (NTS) 0.80 0.60 
0.47 0.31 
0.37 0.22 
0.55 0.38 </p>
<p>RGBD </p>
<p>ResNet + GRU + IL 
0.72 0.32 
0.16 0.09 
0.05 0.02 
0.31 0.14 
Target-driven RL [48] 
0.68 0.28 
0.21 0.08 
0.09 0.03 
0.33 0.13 
Metric Spatial Map + RL [9] 
0.69 0.27 
0.22 0.07 
0.12 0.04 
0.34 0.13 
Metric Spatial Map + FBE + Local 
0.77 0.56 
0.36 0.18 
0.13 0.05 
0.42 0.26 
Active Neural SLAM (ANS) [6] 
0.76 0.55 
0.40 0.24 
0.16 0.09 
0.44 0.29 
Neural Topological SLAM (NTS) 0.87 0.65 
0.58 0.38 
0.43 0.26 
0.63 0.43 </p>
<p>Table 2 :
2No stop and no noise. Success rate of all the models without stop action (left) and without motion noise (right). </p>
<p>Number of sequential goals </p>
<p>Success Rate </p>
<p>0.00 </p>
<p>0.20 </p>
<p>0.40 </p>
<p>0.60 </p>
<p>0.80 </p>
<p>1 
2 
3 
4 
5 </p>
<p>NTS 
NTS w\o Graph 
NTS w/o Score Function </p>
<p>Number of sequential goals </p>
<p>SPL </p>
<p>0.00 </p>
<p>0.10 </p>
<p>0.20 </p>
<p>0.30 </p>
<p>0.40 </p>
<p>0.50 </p>
<p>1 
2 
3 
4 
5 </p>
<p>NTS 
NTS w\o Graph 
NTS w/o Score Function </p>
<p>Acknowledgements
On evaluation of embodied navigation agents. Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, Amir Zamir, arXiv:1807.0675767arXiv preprintPeter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, and Amir Zamir. On evaluation of embodied navigation agents. arXiv preprint arXiv:1807.06757, 2018. 2, 6, 7</p>
<p>Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments. Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, Anton Van Den, Hengel, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionPeter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, and Anton van den Hengel. Vision-and-language navigation: In- terpreting visually-grounded navigation instructions in real environments. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3674- 3683, 2018. 2</p>
<p>Combining optimal control and learning for visual navigation in novel environments. Somil Bansal, Varun Tolani, Saurabh Gupta, Jitendra Malik, Claire Tomlin, arXiv:1903.02531arXiv preprintSomil Bansal, Varun Tolani, Saurabh Gupta, Jitendra Malik, and Claire Tomlin. Combining optimal control and learning for visual navigation in novel environments. arXiv preprint arXiv:1903.02531, 2019. 2</p>
<p>Probabilistic data association for semantic slam. L Sean, Nikolay Bowman, Kostas Atanasov, George J Daniilidis, Pappas, 2017 IEEE International Conference on Robotics and Automation (ICRA). Sean L Bowman, Nikolay Atanasov, Kostas Daniilidis, and George J Pappas. Probabilistic data association for semantic slam. In 2017 IEEE International Conference on Robotics and Automation (ICRA), pages 1722-1729. IEEE, 2017. 2</p>
<p>Learning deployable navigation policies at kilometer scale from a single traversal. Jake Bruce, Niko Sunderhauf, Piotr Mirowski, Raia Hadsell, Michael Milford, PMLRProceedings of The 2nd Conference on Robot Learning. Aude Billard, Anca DraganThe 2nd Conference on Robot Learning87Jake Bruce, Niko Sunderhauf, Piotr Mirowski, Raia Had- sell, and Michael Milford. Learning deployable navigation policies at kilometer scale from a single traversal. In Aude Billard, Anca Dragan, Jan Peters, and Jun Morimoto, edi- tors, Proceedings of The 2nd Conference on Robot Learning, volume 87 of Proceedings of Machine Learning Research, pages 346-361. PMLR, 29-31 Oct 2018. 2</p>
<p>Learning to Explore using Active Neural SLAM. Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov, International Conference on Learning Representations. 7Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan Salakhutdinov. Learning to Ex- plore using Active Neural SLAM. In International Confer- ence on Learning Representations, 2020. 2, 5, 7, 8</p>
<p>. Devendra Singh Chaplot, Emilio Parisotto, Ruslan Salakhutdinov, arXiv:1801.08214Active neural localization. arXiv preprintDevendra Singh Chaplot, Emilio Parisotto, and Ruslan Salakhutdinov. Active neural localization. arXiv preprint arXiv:1801.08214, 2018. 3</p>
<p>A behavioral approach to visual navigation with graph localization networks. Kevin Chen, Juan Pablo De Vicente, Gabriel Sepulveda, Fei Xia, Alvaro Soto, Marynel Vázquez, Silvio Savarese, Robotics: Science and Systems. Kevin Chen, Juan Pablo de Vicente, Gabriel Sepulveda, Fei Xia, Alvaro Soto, Marynel Vázquez, and Silvio Savarese. A behavioral approach to visual navigation with graph local- ization networks. In Robotics: Science and Systems, 2019. 3</p>
<p>Learning exploration policies for navigation. Tao Chen, Saurabh Gupta, Abhinav Gupta, International Conference on Learning Representations. 7Tao Chen, Saurabh Gupta, and Abhinav Gupta. Learning exploration policies for navigation. In International Confer- ence on Learning Representations, 2019. 2, 6, 7, 8</p>
<p>Topological simultaneous localization and mapping (slam): toward exact localization without explicit localization. Howie Choset, Keiji Nagatani, IEEE Transactions on robotics and automation. 172Howie Choset and Keiji Nagatani. Topological simultaneous localization and mapping (slam): toward exact localization without explicit localization. IEEE Transactions on robotics and automation, 17(2):125-137, 2001. 2</p>
<p>Monte carlo localization for mobile robots. Frank Dellaert, Dieter Fox, Wolfram Burgard, Sebastian Thrun, ICRA. 2Frank Dellaert, Dieter Fox, Wolfram Burgard, and Sebastian Thrun. Monte carlo localization for mobile robots. In ICRA, volume 2, pages 1322-1328, 1999. 2</p>
<p>Using occupancy grids for mobile robot perception and navigation. Alberto Elfes, Computer. 226Alberto Elfes. Using occupancy grids for mobile robot per- ception and navigation. Computer, 22(6):46-57, 1989. 2</p>
<p>Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine, arXiv:1906.05253Search on the replay buffer: Bridging planning and reinforcement learning. 23arXiv preprintBenjamin Eysenbach, Ruslan Salakhutdinov, and Sergey Levine. Search on the replay buffer: Bridging planning and reinforcement learning. arXiv preprint arXiv:1906.05253, 2019. 2, 3</p>
<p>Scene memory transformer for embodied agents in long-horizon tasks. Kuan Fang, Alexander Toshev, Li Fei-Fei, Silvio Savarese, CVPR. Kuan Fang, Alexander Toshev, Li Fei-Fei, and Silvio Savarese. Scene memory transformer for embodied agents in long-horizon tasks. In CVPR, 2019. 2</p>
<p>Learning to fly by crashing. Dhiraj Gandhi, Lerrel Pinto, Abhinav Gupta, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 23Dhiraj Gandhi, Lerrel Pinto, and Abhinav Gupta. Learning to fly by crashing. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 3948-3955. IEEE, 2017. 2, 3</p>
<p>Navigation and acquisition of spatial knowledge in a virtual maze. Sabine Gillner, A Hanspeter, Mallot, Journal of cognitive neuroscience. 104Sabine Gillner and Hanspeter A Mallot. Navigation and ac- quisition of spatial knowledge in a virtual maze. Journal of cognitive neuroscience, 10(4):445-463, 1998. 1</p>
<p>Rahul Sukthankar, and Jitendra Malik. Cognitive mapping and planning for visual navigation. Saurabh Gupta, James Davidson, Sergey Levine, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition23Saurabh Gupta, James Davidson, Sergey Levine, Rahul Suk- thankar, and Jitendra Malik. Cognitive mapping and plan- ning for visual navigation. In Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition, pages 2616-2625, 2017. 2, 3</p>
<p>Deep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition513Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016. 5, 13</p>
<p>OctoMap: An efficient probabilistic 3D mapping framework based on octrees. Armin Hornung, Kai M Wurm, Maren Bennewitz, Cyrill Stachniss, Wolfram Burgard, Autonomous RobotsArmin Hornung, Kai M. Wurm, Maren Bennewitz, Cyrill Stachniss, and Wolfram Burgard. OctoMap: An efficient probabilistic 3D mapping framework based on octrees. Au- tonomous Robots, 2013. 2</p>
<p>Adam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 13</p>
<p>A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations. Benjamin Kuipers, Yung-Tai Byun, Robotics and autonomous systems. 81-2Benjamin Kuipers and Yung-Tai Byun. A robot exploration and mapping strategy based on a semantic hierarchy of spa- tial representations. Robotics and autonomous systems, 8(1- 2):47-63, 1991. 2</p>
<p>Visual memory for robust path following. Ashish Kumar, Saurabh Gupta, David Fouhey, Sergey Levine, Jitendra Malik, Advances in Neural Information Processing Systems. Ashish Kumar, Saurabh Gupta, David Fouhey, Sergey Levine, and Jitendra Malik. Visual memory for robust path following. In Advances in Neural Information Processing Systems, 2018. 2</p>
<p>Learning visual servoing with deep features and fitted q-iteration. Alex X Lee, Sergey Levine, Pieter Abbeel, arXiv:1703.11000arXiv preprintAlex X Lee, Sergey Levine, and Pieter Abbeel. Learning vi- sual servoing with deep features and fitted q-iteration. arXiv preprint arXiv:1703.11000, 2017. 2</p>
<p>Mobile robot navigation using neural networks and nonmetrical environmental models. Min Meng, C Avinash, Kak, IEEE Control Systems Magazine. 135Min Meng and Avinash C Kak. Mobile robot navigation us- ing neural networks and nonmetrical environmental models. IEEE Control Systems Magazine, 13(5):30-39, 1993. 2</p>
<p>Learning to navigate in cities without a map. Piotr Mirowski, Matthew Koichi Grimes, Mateusz Malinowski, Karl Moritz Hermann, Keith Anderson, Denis Teplyashin, Karen Simonyan, Koray Kavukcuoglu, Andrew Zisserman, Raia Hadsell, Neural Information Processing Systems (NeurIPS). 23Piotr Mirowski, Matthew Koichi Grimes, Mateusz Ma- linowski, Karl Moritz Hermann, Keith Anderson, Denis Teplyashin, Karen Simonyan, Koray Kavukcuoglu, Andrew Zisserman, and Raia Hadsell. Learning to navigate in cities without a map. In Neural Information Processing Systems (NeurIPS), 2018. 2, 3</p>
<p>Learning to navigate in complex environments. Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, J Andrew, Andrea Ballard, Misha Banino, Ross Denil, Laurent Goroshin, Koray Sifre, Kavukcuoglu, arXiv:1611.0367323arXiv preprintPiotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, et al. Learn- ing to navigate in complex environments. arXiv preprint arXiv:1611.03673, 2016. 2, 3</p>
<p>Orb-slam: a versatile and accurate monocular slam system. Raul Mur-Artal, Jose Maria Martinez Montiel, Juan D Tardos, IEEE transactions on robotics. 313Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos. Orb-slam: a versatile and accurate monocular slam system. IEEE transactions on robotics, 31(5):1147-1163, 2015. 2, 3</p>
<p>Kinectfusion: Real-time dense surface mapping and tracking. Shahram Richard A Newcombe, Otmar Izadi, David Hilliges, David Molyneaux, Kim, J Andrew, Pushmeet Davison, Jamie Kohli, Steve Shotton, Andrew W Hodges, Fitzgibbon, ISMAR. 11Richard A Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim, Andrew J Davison, Push- meet Kohli, Jamie Shotton, Steve Hodges, and Andrew W Fitzgibbon. Kinectfusion: Real-time dense surface mapping and tracking. In ISMAR, volume 11, pages 127-136, 2011. 2</p>
<p>Dtam: Dense tracking and mapping in real-time. A Richard, Newcombe, J Steven, Andrew J Lovegrove, Davison, 2011 international conference on computer vision. Richard A Newcombe, Steven J Lovegrove, and Andrew J Davison. Dtam: Dense tracking and mapping in real-time. In 2011 international conference on computer vision, pages 2320-2327. IEEE, 2011. 2</p>
<p>Control of memory, active perception, and action in minecraft. Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, Honglak Lee, ICML. Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, and Honglak Lee. Control of memory, active perception, and action in minecraft. In ICML, 2016. 2</p>
<p>Neural map: Structured memory for deep reinforcement learning. Emilio Parisotto, Ruslan Salakhutdinov, ICLR. Emilio Parisotto and Ruslan Salakhutdinov. Neural map: Structured memory for deep reinforcement learning. In ICLR, 2018. 3</p>
<p>Curiosity-driven exploration by self-supervised prediction. Deepak Pathak, Pulkit Agrawal, Alexei A Efros, Trevor Darrell, ICML. Deepak Pathak, Pulkit Agrawal, Alexei A. Efros, and Trevor Darrell. Curiosity-driven exploration by self-supervised pre- diction. In ICML, 2017. 3</p>
<p>A reduction of imitation learning and structured prediction to noregret online learning. Stéphane Ross, Geoffrey Gordon, Drew Bagnell, Proceedings of the fourteenth international conference on artificial intelligence and statistics. the fourteenth international conference on artificial intelligence and statisticsStéphane Ross, Geoffrey Gordon, and Drew Bagnell. A re- duction of imitation learning and structured prediction to no- regret online learning. In Proceedings of the fourteenth inter- national conference on artificial intelligence and statistics, pages 627-635, 2011. 3</p>
<p>Cad2rl: Real singleimage flight without a single real image. Fereshteh Sadeghi, Sergey Levine, arXiv:1611.0420123arXiv preprintFereshteh Sadeghi and Sergey Levine. Cad2rl: Real single- image flight without a single real image. arXiv preprint arXiv:1611.04201, 2016. 2, 3</p>
<p>Semi-parametric topological memory for navigation. Nikolay Savinov, Alexey Dosovitskiy, Vladlen Koltun, International Conference on Learning Representations (ICLR). 23Nikolay Savinov, Alexey Dosovitskiy, and Vladlen Koltun. Semi-parametric topological memory for navigation. In In- ternational Conference on Learning Representations (ICLR), 2018. 2, 3</p>
<p>Nikolay Savinov, Anton Raichuk, Raphaël Marinier, Damien Vincent, Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly, arXiv:1810.02274Episodic curiosity through reachability. arXiv preprintNikolay Savinov, Anton Raichuk, Raphaël Marinier, Damien Vincent, Marc Pollefeys, Timothy Lillicrap, and Sylvain Gelly. Episodic curiosity through reachability. arXiv preprint arXiv:1810.02274, 2018. 3</p>
<p>. Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia</p>
<p>Habitat: A platform for embodied ai research. Vladlen Liu, Jitendra Koltun, Malik, ICCV. 56Liu, Vladlen Koltun, Jitendra Malik, et al. Habitat: A plat- form for embodied ai research. In ICCV, 2019. 5, 6</p>
<p>John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, arXiv:1707.06347Proximal policy optimization algorithms. arXiv preprintJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Rad- ford, and Oleg Klimov. Proximal policy optimization algo- rithms. arXiv preprint arXiv:1707.06347, 2017. 6</p>
<p>Probabilistic robotics. Sebastian Thrun, Wolfram Burgard, Dieter Fox, MIT pressSebastian Thrun, Wolfram Burgard, and Dieter Fox. Proba- bilistic robotics. MIT press, 2005. 2</p>
<p>Integrating topological and metric maps for mobile robot navigation: A statistical approach. Sebastian Thrun, Jens-Steffen Gutmann, Dieter Fox, Wolfram Burgard, Benjamin Kuipers, AAAI/IAAI. Sebastian Thrun, Jens-Steffen Gutmann, Dieter Fox, Wol- fram Burgard, Benjamin Kuipers, et al. Integrating topologi- cal and metric maps for mobile robot navigation: A statistical approach. In AAAI/IAAI, pages 989-995, 1998. 2</p>
<p>Combining topological and metric: A natural integration for simultaneous localization and map building. Nicola Tomatis, Illah Nourbakhsh, Roland Siegwart, Proceedings of the Fourth European Workshop on Advanced Mobile Robots (Eurobot). the Fourth European Workshop on Advanced Mobile Robots (Eurobot)ETH-ZürichNicola Tomatis, Illah Nourbakhsh, and Roland Siegwart. Combining topological and metric: A natural integration for simultaneous localization and map building. In Proceed- ings of the Fourth European Workshop on Advanced Mobile Robots (Eurobot). ETH-Zürich, 2001. 2</p>
<p>Human spatial representation: Insights from animals. Frances Ranxiao, Elizabeth S Wang, Spelke, Trends in cognitive sciences. 6Ranxiao Frances Wang and Elizabeth S Spelke. Human spa- tial representation: Insights from animals. Trends in cogni- tive sciences, 6(9):376-382, 2002. 1</p>
<p>Bayesian relational memory for semantic visual navigation. Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, Yuandong Tian, CVPR. 23Yi Wu, Yuxin Wu, Aviv Tamar, Stuart Russell, Georgia Gkioxari, and Yuandong Tian. Bayesian relational memory for semantic visual navigation. In CVPR, pages 2769-2779, 2019. 2, 3</p>
<p>Gibson Env: real-world perception for embodied agents. Fei Xia, R Amir, Zhi-Yang Zamir, Alexander He, Jitendra Sax, Silvio Malik, Savarese, Computer Vision and Pattern Recognition (CVPR). Fei Xia, Amir R. Zamir, Zhi-Yang He, Alexander Sax, Jiten- dra Malik, and Silvio Savarese. Gibson Env: real-world per- ception for embodied agents. In Computer Vision and Pat- tern Recognition (CVPR), 2018 IEEE Conference on. IEEE, 2018. 5</p>
<p>A frontier-based approach for autonomous exploration. Brian Yamauchi, cira. 97146Brian Yamauchi. A frontier-based approach for autonomous exploration. In cira, volume 97, page 146, 1997. 6</p>
<p>Visual semantic navigation using scene priors. Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi, arXiv:1810.06543arXiv preprintWei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, and Roozbeh Mottaghi. Visual semantic navigation using scene priors. arXiv preprint arXiv:1810.06543, 2018. 3</p>
<p>Rob Fergus, and Arthur Szlam. Amy Zhang, Adam Lerer, Sainbayar Sukhbaatar, arXiv:1803.00512Composable planning with attributes. arXiv preprintAmy Zhang, Adam Lerer, Sainbayar Sukhbaatar, Rob Fer- gus, and Arthur Szlam. Composable planning with attributes. arXiv preprint arXiv:1803.00512, 2018. 3</p>
<p>Target-driven visual navigation in indoor scenes using deep reinforcement learning. Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, J Joseph, Abhinav Lim, Li Gupta, Ali Fei-Fei, Farhadi, 2017 IEEE international conference on robotics and automation (ICRA). 7Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J Lim, Ab- hinav Gupta, Li Fei-Fei, and Ali Farhadi. Target-driven vi- sual navigation in indoor scenes using deep reinforcement learning. In 2017 IEEE international conference on robotics and automation (ICRA), pages 3357-3364. IEEE, 2017. 2, 3, 6, 7, 8</p>            </div>
        </div>

    </div>
</body>
</html>