<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6486 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6486</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6486</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-130.html">extraction-schema-130</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models solving spatial puzzle games, including details about the model, the puzzle, the reasoning or prompting method, performance metrics, internal representations, use of external tools, and any analysis or limitations reported.</div>
                <p><strong>Paper ID:</strong> paper-277271739</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.18394v1.pdf" target="_blank">Solving Situation Puzzles with Large Language Model and External Reformulation</a></p>
                <p><strong>Paper Abstract:</strong> In recent years, large language models (LLMs) have shown an impressive ability to perform arithmetic and symbolic reasoning tasks. However, we found that LLMs (e.g., ChatGPT) cannot perform well on reasoning that requires multiple rounds of dialogue, especially when solving situation puzzles. Specifically, LLMs intend to ask very detailed questions focusing on a specific aspect or same/similar questions after several rounds of Q&As. To help LLMs get out of the above dilemma, we propose a novel external reformulation methodology, where the situation puzzle will be reformulated after several rounds of Q&A or when the LLMs raise an incorrect guess. Experiments show superior performance (e.g., win rate, number of question/guess attempts) of our method than directly using LLMs for solving situation puzzles, highlighting the potential of strategic problem reformulation to enhance the reasoning capabilities of LLMs in complex interactive scenarios.</p>
                <p><strong>Cost:</strong> 0.002</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6486",
    "paper_id": "paper-277271739",
    "extraction_schema_id": "extraction-schema-130",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0023209999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Solving Situation Puzzles with Large Language Model and External Reformulation</p>
<p>Kun Li kunli3@illinois.edu 
Xinwei Chen xinweic2@illinois.edu 
Tianyou Song tianyou.song@columbia.edu 
Chengrui Zhou zhou.chengrui@columbia.edu 
Zhuoran Liu 
Zhenyan Zhang zhenyan2@alumni.cmu.edu 
Jiangjian Guo j9guo@ucsd.edu 
Qing Shan shan.qi@northeastern.edu </p>
<p>University of Illinois Urbana-University of Illinois at Urbana Columbia University</p>
<p>Columbia University Champaign Champaign New York City
New York City, Champaign, ChampaignNY, IL, ILUSA, USA, USA, USA</p>
<p>Carnegie Mellon University Carnegie Mellon University</p>
<p>University of California San Northeastern University Pittsburgh
PittsburghUSA, USA</p>
<p>Diego Seattle
WAUSA</p>
<p>La JollaCAUSA</p>
<p>Solving Situation Puzzles with Large Language Model and External Reformulation
743CBAED075DCFB3D49667FC5D059274
In recent years, large language models (LLMs) have shown an impressive ability to perform arithmetic and symbolic reasoning tasks.However, we found that LLMs (e.g., ChatGPT) cannot perform well on reasoning that requires multiple rounds of dialogue, especially when solving situation puzzles.Specifically, LLMs intend to ask very detailed questions focusing on a specific aspect or same/similar questions after several rounds of Q&amp;As.To help LLMs get out of the above dilemma, we propose to integrate LLMs with external reformulation, where the situation puzzle will be reformulated after several rounds of Q&amp;A or when the LLMs raise an incorrect guess.Experiments show superior performance (e.g., win rate, number of question/guess attempts) of our method than directly using LLMs for solving situation puzzles.</p>
<p>Introuction</p>
<p>Natural language processing (NLP) has made significant progress in recent years, especially with the introduction of transformers and pre-trained language models.However, their ability to perform natural language reasoning is still far from satisfactory.NLR, the process of reasoning based on existing knowledge, is a fundamental aspect of human intelligence and is critical for complex tasks such as comprehension of complex and abstract situations, and decisionmaking.Building artificial intelligence systems with reasoning capabilities is not only the ultimate goal of the re-search but also a necessary way to improve the performance of complex applications.</p>
<p>In recent years, advancements in NLP have led to the development of increasingly sophisticated LLMs (large language models) [19], capable of performing a wide range of language-based tasks with remarkable proficiency.Among these models, ChatGPT, developed by OpenAI, has emerged as a frontrunner, showcasing abilities that often parallel human-like language understanding and generation [15].However, despite these advancements, LLMs continue to exhibit limitations in certain complex cognitive tasks, particularly those requiring deep reasoning and understanding beyond surface-level information processing.One such challenging domain is the realm of situation puzzles, which demand a high degree of creative and lateral thinking.</p>
<p>Situation puzzles, often referred to as lateral thinking puzzles, are a unique and intellectually stimulating class of riddles.These puzzles present scenarios with limited information, requiring solvers to ask targeted questions and make logical inferences to uncover the underlying story or solution, as the example given in Fig. 1.The ability to solve such puzzles is indicative of a sophisticated level of cognitive processing, blending creativity, reasoning, and inference -skills that are inherently human and have been historically challenging for AI to replicate.When applying LLMs to solve situation puzzles, we observe the player (LLMs) often get stuck in a long dialog.Specifically, as examples shown in Fig. 2, after multiple (∼10) rounds of Q&amp;As, the player intends to ask very detailed questions or similar ques- tions.These behaviors indeed contribute trivially to solving the puzzle.</p>
<p>To address the above limitations and help LLMs get out of the long-dialog dilemma, we propose to reformulate the situation description with previously asked Q&amp;As by the LLMs and then restart a new chat session to solve the puzzle.As the overview shown in Fig. 3, to reformulate, previous Q&amp;As are selected as additional hints to formulate the situation description.And the new chat session will start with the reformulated description.Note that the puzzle can be iteratively reformulated once the reformulation conditions are satisfied.By incorporating reformulation, LLMs can easily get out of the above dilemma and quickly come out with the correct answer.To validate, we have conducted experiments to compare our reformulation method with directly using LLMs to solve situation puzzles, which demonstrate considerable improvements.</p>
<p>Related Work</p>
<p>LLMs for Problem Solving</p>
<p>Currently, with the introduction of ChatGPT and GPT-4 (OpenAI, 2023), Large Language Models (LLMs) are gaining increasingly potent capabilities, which enable them to tackle a broad range of tasks effectively.Many benchmarks and research efforts have been dedicated to evaluating LLMs from various perspectives in order to discover whether LLMs think as humans or just merely retrieve from their vast world knowledge, including language tasks [3,14,17], reasoning [1,2], robustness [13], trustworthiness [7], medical applications [5,6], and ethical considerations [4,18].However, those previous tasks do not require multi-turn interactions to thoroughly assess the interactive abilities of LLMs and also lack standardized evaluation criteria for measuring the divergent thinking capa-bilities of LLMs.To tackle this problem, some research focuses on planning and reasoning [22], question answering [8], lateral thinking puzzle [10,11] enabling the evaluation of the divergent thinking capabilities of LLMs.show that the LLMs lack of ability to employ divergent thinking ability during interactions.</p>
<p>Situation Puzzle</p>
<p>The situation puzzle, also called as Lateral Thinking Puzzle, is one of the most popular among enthusiasts of inference, focusing on finding the single best solution to a problem, involving analyzing the problem step-by-step and narrowing down possibilities until the optimal solution is reached.[21] consider that lateral thinking is a cognitive activity employed to construct creative ideas.For the generation of novel ideas that promote progress in different scientific fields from engineering to the arts, politics to personal well-being, research [9] denotes that lateral thinking is oriented to creative thinking skills and problem-solving.Relaiza et al. [20] indicate that lateral thinking can offer alternative approaches and perspectives to vertical thinking, thereby augmenting its efficacy.Research [8,10,11,22] argue that the LLMs have shown powerful performance in vertical thinking, however, lack the ability in lateral thinking.Hence, to build an external tool and reformulate situation puzzles to help LLMs rethink the question laterally.</p>
<p>Reformulation of Prompts for LLMs</p>
<p>The LLMs show their strong ability to solve different kinds of problems compared to conventional models [1-7, 13, 14, 17, 18].However, for complex questions [8,10,11,22], the LLMs are not able to give a satisfactory answer.Especially, there exists a strong need for improving the systematic and extensible planning ability of LLMs and bestowing LLMs with innate planning capabilities.Some pioneer research, such as [8, 10-12, 12, 22, 23], propose the reformulation method to solve the complex problem based on LLMs.[12] proposed to use the small language model fine-tuned to coordinate the large language model to enhance the ability of reasoning capabilities of LLMs.The PlanBanch [23] proposed different reformulation methods for LLMs in planning or reasoning about actions and change.[16] proposed the reframing instructional prompts to reformulate a complex task into multiple subtasks by using multi-step prompting.In summary, most of the current research focuses on reformulating different tasks in a specified designed manner.Hence for situation puzzles, our approach follows the previous research and proposes an external reformulation method.</p>
<p>Methods</p>
<p>In this section, we formally formulate the problem of solving situation puzzles, and then describe our proposed refor-Puzzle: My phone was missing and I was shocked when I found it.After 10 rounds of Q&amp;As, Player: Did your missing phone have anything to do with the phone's condition or appearance when you found it?Host: No Player: Was your missing phone hidden or obscured in any way when you found it?Host: No Player: Was your missing phone accidentally left in the unexpected place where you found it?Host: No Puzzle: My phone was missing and I was shocked when I found it.</p>
<p>Player: Did you find your missing phone in a place where you usually wouldn't expect it to be? Host: Yes After 13 rounds of Q&amp;As, Player: Was your missing phone accidentally left in the unexpected place where you found it?Host: Yes mulation manner.Finally, we explain how to implement the baseline method and conduct reformulation.</p>
<p>Problem Formulation</p>
<p>We refer to the game as solving a given situation puzzle.</p>
<p>There are two roles in the game, i.e., the player and the host.At the beginning of the game, the host will give the description of the situation puzzle, then the player starts asking questions, and the host will answer each question with one of "Yes", "No", or "Irrelevant".Sometimes, the player will give a guess to the puzzle, and the answer from the host should be "Yes" or "No".The game will end if 1.) the player gives a correct guess, 2.) the number of guess attempts reaches the given maximum, or 3.) the number of question attempts reaches the given maximum.When con-dition 1.) satisfied, the player wins the game, otherwise, the player loses the game.</p>
<p>To formulate, we denote the description of the puzzle as S, the answer to the puzzle as A, the question as q, the answer to the question as r ∈ {Yes, No, Irrelevant}, the guess as g, and the answer to the guess as e ∈ {Yes, No}.Assume that the player has asked i questions and given k guesses.Then, in the next round of chatting, the player has two possible actions: asking a question or giving a guess.If the player asks a question, q i+1 = Player.askS, (q j , r j ) i j=1 , (g j , e j ) k j=1 , (1) the host will give the answer r i+1 to the question q i+1 , i.e., r i+1 = Host.answer(S,A, q i+1 ).</p>
<p>(
)2
If the player gives a guess,
g k+1 = Player.guess S, (q j , r j ) i j=1 , (g j , e j ) k j=1 ,(3)
the host will give the answer e k+1 to the guess g k+1 , i.e., e k+1 = Host.answer(S,A, g k+1 ).</p>
<p>(4)</p>
<p>Particularly, if e k+1 is "Yes", the player wins the game and the game ends, otherwise, the game continues.</p>
<p>External Reformulation</p>
<p>We define the concept of the chat session.At the beginning of c-th chat session, the host gives the description of the</p>
<p>Situation Description</p>
<p>Answer A man walks up to a cactus, looks at a piece of paper pinned there, and kills himself.</p>
<p>The man has been wandering lost in the desert.He fears he has been walking in circles.To test this, he pins a blank piece of paper to a cactus and sets off walking.When he encounters the paper again, his fears are confirmed and he knows he will never find his way out.</p>
<p>A hunter aimed his gun carefully and fired.Seconds later, he realized his mistake.Minutes later, he was dead.</p>
<p>He hunted in snow-capped mountains.The shot provoked an avalanche, which covered the man.He died of strangulation.</p>
<p>Jack and Judy were lying on the floor dead.There was a puddle of water and broken glass on the floor.How did they die?</p>
<p>Jack and Judy were two goldfish that swam in a small aquarium placed on a shelf.One afternoon, a cat sneaked into the room through the window and hit the aquarium that fell off the shelf and broke against the ground.</p>
<p>A man woke up at night feeling thirsty.Then he turned off the light everywhere and went to bed again.In the morning he woke up, looked out of the window and yelled.Soon after he committed suicide.</p>
<p>The man was caretaker.Accindetally he turned off the lighthouse and it caused some shipwrecks.When he woke up, he realized what he have done.</p>
<p>A man went to a party and drank some of the punch.He then left early.Everyone at the party who drank the punch subsequently died of poisoning.Why did the man not die?</p>
<p>The poison from the punch came from the ice cubes.When the man drank the punch, the ice was fully frozen.Gradually, as the ice cubes melted, the poison was released into the punch.situation puzzle S c , then the player asks questions/guesses, and the host answers them.Our idea is to end the chat session after several rounds of Q&amp;As, reformulate the description with Q&amp;As, and then start a new chat session.Here, we preset two conditions to ending the chat session: 1.) the player gives an incorrect guess (i.e., the answer to the guess is "No"), 2.) the player has asked K questions in this chat session.If one of the above conditions is satisfied, we end the chat session and start a new chat session with the reformulated description.</p>
<p>To formulate, assume at c-th chat session, the player asked k c (k c ≤ K) questions.We denote k c Q&amp;A pairs as Q c = {(q j , r j )} kc j=1 .Instead of selecting all Q&amp;As for reformulation, we define the priority of questions by their answers and select top-M Q&amp;As pairs, where "Yes" is higher than "No" and "No" is higher than "Irrelevant" (i.e., "Yes" &gt; "No" &gt; "Irrelevant").In practice, all Yes-questions (the answer is "Yes") are selected as they are more related to the answer A of the puzzle.If Yes-questions are fewer than M , we select the rest from No/Irrelevant-questions (the answer is "No"/"Irrelevant") by their priorities ("No" &gt; "Irrelevant").</p>
<p>Then, suppose that there are M c Q&amp;As are selected, denoted as Q ′ c ⊂ Q c .Note that M c can be either larger than M (the player asked more than M Yes-questions) or smaller than M (the player gives an incorrect guess with fewer than M questions being asked).Based on the above, we reformulate the description of the puzzle with Q ′ c ,
S c+1 = Reformulate(S c , Q ′ c ).(5)
Then, a new chat session is started with S c+1 .</p>
<p>Implementation</p>
<p>Assume that the original description of the puzzle is S 0 , the prompt is given as Solve the following situation puzzle and guess the reason.You can ask questions, and I will give the answer yes/no or irrelevant.Once you want to give a guess, please start with "I guess that ..." Description: S 0</p>
<p>For reformulation, we define the following prompt Solve the following situation puzzle and guess the reason.You can ask questions, and I will give the answer yes/no or irrelevant.Once you want to give a guess, please start with "I guess that ..." Description: S 0 Here are some hints: 1. ... 2. ...</p>
<p>Each hint is generated from one pair of questions and answers.For example, for the question "Was the man lost in a desert?" with the answer of "Yes", the hint can be "The man was lost in the desert."In practice, we utilize ChatGPT to automatically generate hints from selected Q&amp;As.</p>
<p>In the baseline, the game starts and ends in the same chat session.In our method, the game starts with the original description, and the chat session can be ended and restarted with reformulated descriptions.When the game ended, we recorded the results, including win/lose, the number of questions, the number of guess attempts, and the number of Yes/No/Irrevelant-questions as evaluation metrics for comparison.</p>
<p>Experiments</p>
<p>To validate the effectiveness of the proposed reformulation manner, we conducted experiments on 5 different situation puzzles given in Fig. 4. We preset the maximum number of questions and guesses to 30 and 5, respectively.In our method, we choose K = 5 and M = 3.Additionally, we compare the performance of different selections of K/M in the ablation study.</p>
<p>Results.Table 1 compares the performance of the baseline model and our method of solving situation puzzles, where the number of game win/lose, questions, guesses, and Yes/No/Irrevelant-questions are recorded and compared.By incorporating the reformulation, the player has a higher win rate with fewer questions and guesses being asked.Additionally, the player asked more Yes-questions and fewer No/Irrelevant-questions, which means that reformulation indeed helped the player (LLMs) to get out of the dilemma and ask more questions related to the correct puzzle answer.</p>
<p>Ablation Study.In Table 2, we compare different conditions to reformulate the situation description.In addition to comparing different selections of K/M , we also tried to reformulate the description only when the player gives an incorrect guess ("Wrong Guess Only").The experimental results show that the best selection of K/M is 5/3, and it would be important to end the chat session early by setting the maximum number of questions being asked.</p>
<p>Case Study.In Fig. 5, we conduct a case study to show how the reformulation works to help the LLMs solve situation puzzles.First, we start a chat session, the host provides the original description, and the player asks questions until the one of reformulation conditions is satisfied.After 5 rounds of Q&amp;As, we end the chat session and select all two Yes-questions and the first No-question to reformulate the situation description.Then, a new chat session starts with the reformulated description, and the player asks questions and finally gives the correct guess.</p>
<p>Conclusion</p>
<p>This study investigates the problem-solving capabilities of large language models (LLMs) when applied to situation puzzles.Our observations reveal that LLMs frequently encounter performance plateaus after extended questionanswer exchanges, manifesting as either excessively granular inquiries or redundant questioning patterns.</p>
<p>To address this limitation, we introduce a novel reformulation methodology wherein the original problem statement is augmented with accumulated Q&amp;A interactions, facilitating the initiation of a new dialogue session.This approach effectively circumvents the cognitive constraints associated with prolonged conversational exchanges while preserving the knowledge capital acquired during previous interactions.The reformulation technique enables LLMs to overcome conversational inertia by providing a consolidated knowledge foundation rather than requiring the maintenance of extensive dialogue history.This restructuring of the problem space creates a more efficient starting point that incorporates all salient discoveries from prior exchanges.</p>
<p>Through systematic empirical evaluation across diverse puzzle scenarios and model architectures, we demonstrate that our reformulation approach significantly outperforms traditional continuous dialogue methods in terms of both solution efficiency and question redundancy reduction.The experimental results validate the efficacy of our methodology and suggest its potential application for enhancing reasoning capabilities in complex, multi-step cognitive tasks.</p>
<p>These findings contribute to the growing body of research on improving LLM performance in tasks requiring sustained reasoning and strategic information gathering.</p>
<p>1 arXivFigure 1 .
11
Figure 1.An example of solving a situation puzzle, including several rounds of interaction between the host and the player.</p>
<p>Figure 2 .Figure 3 .
23
Figure2.Two examples of directly using LLMs to solve situation puzzles.For the example in the top, after several rounds of Q&amp;As, the player intends to ask very detailed questions focusing on a specific aspect.For the example at the bottom, the player asks the same or similar questions after several rounds of Q&amp;As.</p>
<p>Figure 4 .
4
Figure 4. We conducted experiments on the above five situation puzzles.</p>
<p>Figure 5 .
5
Figure 5. Case study.In the first chat session, the game starts with the host giving a description of the situation.After 5 rounds of Q&amp;As, two Yes-questions and the first No-question are selected to generate the hints.To reformulate, hints are integrated into the description prompt and a new chat session starts with the new description.In this case, the game ends in the second chat session as the player gives a correct guess and finally wins the game.</p>
<p>Table 1 .
1
Comparison of baseline and our on solving the situation puzzle.Several evaluation metrics are compared including win/lose and the number of asked questions/guesses.
MetricsBaselineOursWin/Lose2/34/1# Guesses2.82.4# Questions28.622.6# Yes-Questions3.65# No-Questions18.212.2# Irrelevant-Questions6.85.4</p>
<p>Table 2 .
2
Ablation study on different conditions reformulate the situation description."Wrong Guess Only" means that the chat session ends only when the player gives an incorrect guess.
MetricsK = 5, M = 3 (best)Wrong Guess OnlyK = 10, M = 6Win/Lose4/13/23/2# Guesses2.443# Questions22.622.824.2# Yes-Questions56.86# No-Questions12.21210.8# Irrelevant-Questions5.447.4Chat Session -1Chat Session -2Session EndsSession Ends</p>
<p>A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, arXiv:2302.040232023arXiv preprint</p>
<p>Chatgpt is a knowledgeable but inexperienced solver: An investigation of commonsense problem in large language models. Xianpei Ning Bian, Le Han, Hongyu Sun, Yaojie Lin, Ben Lu, He, arXiv:2303.164212023arXiv preprint</p>
<p>Proceedings of the 2nd workshop on natural language generation, evaluation, and metrics (gem). Antoine Bosselut, Khyathi Chandu, Kaustubh Dhole, Varun Gangal, Sebastian Gehrmann, Yacine Jernite, Jekaterina Novikova, Laura Perez-Beltrachini, Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM). the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)2022</p>
<p>Assessing cross-cultural alignment between chatgpt and human societies: An empirical study. Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, Daniel Hershcovich, arXiv:2303.174662023arXiv preprint</p>
<p>Evaluating the feasibility of chatgpt in healthcare: an analysis of multiple clinical and research scenarios. Marco Cascella, Jonathan Montomoli, Valentina Bellini, Elena Bignami, Journal of Medical Systems. 471332023</p>
<p>The promise and peril of using a large language model to obtain clinical information: Chatgpt performs strongly as a fertility counseling tool with limitations. Joseph Chervenak, Harry Lieman, Miranda Blanco-Breindel, Sangita Jindal, Fertility and Sterility. 22023</p>
<p>Human-like intuitive behavior and reasoning biases emerged in language modelsand disappeared in gpt-4. Thilo Hagendorff, Sarah Fabi, arXiv:2306.076222023arXiv preprint</p>
<p>Recent progress in leveraging deep learning methods for question answering. Tianyong Hao, Xinxin Li, Yulan He, Lee Fu, Yingying Wang, Qu, Neural Computing and Applications. 2022</p>
<p>The effectiveness of enrichment test instruments design to measure students' creative thinking skills and problemsolving. Taufiq Hidayat, Endang Susilaningsih, Cepi Kurniawan, Thinking Skills and Creativity. 292018</p>
<p>Lateval: An interactive llms evaluation benchmark with incomplete information from lateral thinking puzzles. Shulin Huang, Shirong Ma, Yinghui Li, Mengzuo Huang, Wuhe Zou, Weidong Zhang, Hai-Tao Zheng, arXiv:2308.108552023arXiv preprint</p>
<p>Yifan Jiang, Filip Ilievski, Kaixin Ma, Brainteaser, arXiv:2310.05057Lateral thinking puzzles for large language model. 2023arXiv preprint</p>
<p>Small language models fine-tuned to coordinate larger language models improve complex reasoning. Gurusha Juneja, Soumen Subhabrata, Sunny Chakrabarti, Tanmoy Manchanda, Chakraborty, arXiv:2310.183382023arXiv preprint</p>
<p>A survey on out-of-distribution evaluation of neural nlp models. Xinzhe Li, Ming Liu, Shang Gao, Wray Buntine, arXiv:2306.152612023arXiv preprint</p>
<p>Holistic evaluation of language models. Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, arXiv:2211.091102022arXiv preprint</p>
<p>What is ai chatbot phenomenon chatgpt and could it replace humans. The Guardian. Samantha Lock, 20225</p>
<p>Reframing instructional prompts to gptk's language. Swaroop Mishra, Daniel Khashabi, Chitta Baral, Yejin Choi, Hannaneh Hajishirzi, arXiv:2109.078302021arXiv preprint</p>
<p>Marie Francine Moens, Xuan-Jing Huang, Lucia Specia, Wen-Tau Yih, Findings of the association for computational linguistics: Emnlp 2021. 2021Findings of the Association for Computational Linguistics: EMNLP 2021</p>
<p>Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu Mon Htut, Samuel R Bowman, arXiv:2110.08193Bbq: A hand-built bias benchmark for question answering. 2021arXiv preprint</p>
<p>Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018</p>
<p>Cognitive processes and creative lateral thinking in students of the naval school of peru. Hector Santa, Maria Relaiza, Doris Fuster-Guillen, Yolvi Ocana-Fernandez, Patricia , Edith Guillen Aparicio, Freddy Antonio Ochoa Tataje, NeuroQuantology. 1952021</p>
<p>Creative thinking patterns in student's scientific works. Alfi Syahrin, Suwignyo Heri, Endah Tri, Priyatni , Eurasian Journal of Educational Research. 19812019</p>
<p>Large language models still can't plan (a benchmark for llms on planning and reasoning about change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, arXiv:2206.104982022arXiv preprint</p>
<p>Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change. Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, Thirtyseventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2023</p>            </div>
        </div>

    </div>
</body>
</html>