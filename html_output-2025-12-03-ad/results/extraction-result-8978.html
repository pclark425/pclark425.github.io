<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8978 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8978</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8978</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-158.html">extraction-schema-158</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-582b1f5c08f79d0d62e41a9c0b1185f3e7292e4e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/582b1f5c08f79d0d62e41a9c0b1185f3e7292e4e" target="_blank">GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This paper proposes a large-scale, general-domain dataset, GenWiki, which has 1.3M text and graph examples, respectively, and provides this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.</p>
                <p><strong>Paper Abstract:</strong> Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8978.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8978.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rule-Based Linearization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rule-Based Graph Linearization (Schmitt et al., 2020 baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple linearization of a knowledge graph into a flat sequence of triples, turning camel-cased relation names into surface phrases and concatenating triple descriptions with conjunctions (e.g., 'and'). Used as a baseline for graph-to-text generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An unsupervised joint system for text generation from knowledge graphs and semantic parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Linearization / Triple Serialization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Each graph is converted to a sequence of triples; each triple is verbalized as 'subject relation-phrase object' by converting camel-cased relation names to normal phrases; multiple triple verbalizations are joined (e.g., with 'and').</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (DBpedia-style RDF triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Deterministic template-like conversion: for each triple, map relation identifier to phrase, emit subject + relation phrase + object; concatenate triple verbalizations into a single sentence or short sequence separated by 'and'.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Graph-to-text generation (unsupervised / baseline evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GenWiki_FINE: BLEU=13.45, METEOR=30.72, ROUGE_L=40.93, CIDEr=1.26; GenWiki_FULL: identical to FINE (BLEU=13.45, METEOR=30.72, ROUGE_L=40.93, CIDEr=1.26).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Performed substantially worse than learned unsupervised methods (CycleGT variants) and worse than NoisySupervised; similar in score to DirectTransfer on this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Deterministic, interpretable, requires no learning or parallel data; simple to implement.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Produces poor generation quality compared to learned models; yields rigid, unnatural phrasing and limited fluency.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Low BLEU and other metric scores indicate poor fluency and content matching; does not generalize to varied, natural Wikipedia-style text and misses natural language phenomena (noability to produce commonsense phrasing or aggregate information).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8978.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Transformer Generation Model (Koncel-Kedziorski et al., 2019)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based graph-to-sequence model that encodes graph structure and produces text; used in this paper as the core seq2seq architecture for DirectTransfer and NoisySupervised baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Text generation from knowledge graphs with graph transformers.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Graph Transformer encoding (graph-to-sequence)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Graph structure is encoded into a transformer-based encoder that respects graph connectivity and node/edge representations; the encoded graph representation is then decoded autoregressively into text.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (RDF-like triples / DBpedia graphs)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Learned graph encoder (graph transformer) maps nodes/edges into contextual embeddings which a sequence decoder uses to generate natural language text; in experiments, models trained on WebNLG (supervised) used this architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Graph-to-text generation (supervised training and transfer to GenWiki), used also inside NoisySupervised pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>As used in DirectTransfer: GenWiki_FINE BLEU=13.89, METEOR=25.76, ROUGE_L=39.75, CIDEr=1.26; GenWiki_FULL identical.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>When trained on WebNLG and applied directly (DirectTransfer) it performed similarly poorly to rule-based linearization on GenWiki, indicating limited cross-corpus generalization without adaptation. When trained on noisy distantly-aligned pairs (NoisySupervised) it substantially improved.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Learned representation that can exploit graph structure and produce fluent text when trained with suitable supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Requires supervised or high-quality pseudo-supervised pairs to perform well; direct transfer across corpora may fail.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>DirectTransfer (trained on WebNLG) produces low scores on GenWiki, showing brittleness to domain/style shifts and limited robustness when training data distribution differs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8978.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DirectTransfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Direct Transfer using Supervised Graph Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transfer baseline that trains a graph transformer model on the supervised WebNLG dataset and directly applies it to GenWiki test data without further adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Text generation from knowledge graphs with graph transformers.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Supervised-trained Graph Transformer (transfer inference)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Representation is the graph-transformer encoding learned on WebNLG; at test time the model receives GenWiki graphs and generates text without additional finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (WebNLG-style RDF triples applied to GenWiki)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Train encoder-decoder on WebNLG parallel graph-text pairs; at inference feed GenWiki graphs to encoder and decode output text.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Graph-to-text generation (transfer evaluation across corpora)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GenWiki_FINE: BLEU=13.89, METEOR=25.76, ROUGE_L=39.75, CIDEr=1.26; GenWiki_FULL identical.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Scores similar to Rule-Based linearization and far below NoisySupervised and CycleGT, indicating poor out-of-domain generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Straightforward application of a strong supervised model; no need to construct new training data for target corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Fails to generalize reliably to corpora with different text styles and distributions; lower METEOR in particular versus other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Performs poorly on GenWiki despite both datasets being wiki-based, suggesting sensitivity to domain/style mismatch and inability to adapt without target supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8978.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NoisySupervised</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NoisySupervised (Distantly Aligned Supervised Training)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline that converts the unsupervised GenWiki training data into pseudo-parallel pairs via distant alignment (entity-overlap matching) and then trains a supervised graph-transformer on these noisy pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Distantly-aligned pseudo-parallel representation</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Graphs and text from the non-parallel corpus are matched by entity overlap heuristics to create noisy graph-text pairs; these pseudo-pairs are used as supervised training data for a graph-to-text model.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (DBpedia-derived small subgraphs of 1-10 triples)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Enumerate small graphs and text sequences per article; select graph-text pairs with high entity-overlap (distant supervision) to create noisy supervision; train a graph transformer in supervised fashion on these pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Graph-to-text generation (supervised training on pseudo-parallel data)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GenWiki_FINE: BLEU=30.12, METEOR=28.12, ROUGE_L=56.96, CIDEr=2.52; GenWiki_FULL: BLEU=35.03, METEOR=33.45, ROUGE_L=58.14, CIDEr=2.63.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Substantially better than Rule-Based and DirectTransfer; worse than CycleGT models by ~10 BLEU points on GenWiki_FINE but closer on GenWiki_FULL; performance validates that GenWiki contains useful alignment signal despite noise.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Leverages large-scale unsupervised corpora by creating pseudo-parallel data; simpler training pipeline (standard supervised learning) and achieves good performance.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Quality depends on the distant alignment heuristic and can introduce noisy or incorrect supervision; no explicit unsupervised cycle training.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Errors tied to noisy distant supervision; cases where entity overlap produces incorrect alignments or misses implicit relations will degrade model quality (paper notes reliance on distant supervision quality).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8978.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CycleGT_Base</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CycleGT Base (Guo et al., 2020 basic iterative back-translation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised cycle-training model that jointly learns graph-to-text generation and text-to-graph relation classification via iterative back-translation without pretraining, achieving strong unsupervised performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Cycle training (iterative back-translation) with graph-text cycle</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Two models (graph->text and text->graph) are trained jointly: generate text from graphs, reconstruct relations from generated text (relation classification given entities), and optimize a cycle loss to enable unsupervised learning.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (closed set of relations, DBpedia-derived)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Iterative back-translation / cycle training: sample a graph, generate text; from generated text predict relations (text-to-graph classifier); enforce reconstruction consistency and alternate training between the two directions.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Unsupervised graph-to-text generation and text-to-graph relation classification (used for generation evaluation on GenWiki).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GenWiki_FINE: BLEU=41.59, METEOR=35.72, ROUGE_L=63.31, CIDEr=3.57; GenWiki_FULL: BLEU=41.29, METEOR=35.39, ROUGE_L=63.73, CIDEr=3.53.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Outperformed NoisySupervised by ~10 BLEU points on GenWiki_FINE and is the strongest unsupervised model among evaluated baselines; comparable or slightly better than CycleGT_Warm depending on metric.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Strong unsupervised performance leveraging cycle consistency; robust learning from large non-parallel corpora without constructing noisy parallel pairs explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Training complexity of joint cycle optimization; requires reliable entity annotation and closed relation set (both provided by GenWiki) to avoid collapse.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Error analysis on CycleGT_Base: 27% of sampled errors are missing graph information (generated text omits triples), 20% are commonsense/semantic mistakes (e.g., reversing agent/owner roles or implausible statements); shows tendency to drop facts and sometimes produce commonsense violations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8978.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CycleGT_Warm</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CycleGT Warm (Guo et al., 2020 with warmup strategy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of CycleGT that uses a warm-up stage before cycle training: it pretrains entity-to-text generation and entity-to-graph relation classification to stabilize subsequent cycle training, achieving near-identical strong performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Warm-start Cycle Training (entity-focused pretraining + iterative back-translation)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Initial warmup: train simpler tasks that map entities to text and entities to relation classification to stabilize models; then perform iterative back-translation/cycle training as in CycleGT_Base.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Knowledge graphs (DBpedia-style with closed relation set)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>First warm up entity-conditioned generation and relation classifiers using entity annotations; then run cycle training (graph<->text) to refine models under unsupervised reconstruction losses.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Unsupervised graph-to-text generation and text-to-graph relation classification</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GenWiki_FINE: BLEU=41.35, METEOR=35.20, ROUGE_L=63.01, CIDEr=3.45; GenWiki_FULL: BLEU=40.47, METEOR=34.84, ROUGE_L=63.40, CIDEr=3.48.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Performance comparable to CycleGT_Base, slightly better on BLEU in one split; both CycleGT variants substantially outperform NoisySupervised and other baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>More stable training (warmup) while achieving top unsupervised performance; leverages entity annotations to bootstrap models.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Adds a warmup stage complexity; still subject to the same types of generation errors (missing facts, commonsense errors).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Same observed failure modes as CycleGT_Base: omission of graph facts (~27% of errors in a sample) and commonsense violations (~20% of errors in a sample).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8978.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hypergraph Concept-to-Text</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unsupervised Concept-to-Text Generation with Hypergraphs (Konstas & Lapata, 2012)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier unsupervised approach that formulates concept-to-text generation using hypergraph structures to represent concepts and their relations, enabling unsupervised mapping from structured inputs to text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Unsupervised concept-to-text generation with hypergraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Hypergraph representation for concept-to-text</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Use of hypergraphs to represent structured concepts and their interrelations as the intermediate structure for unsupervised text generation; modeling focuses on extracting/synthesizing text from these hypergraph concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Concept hypergraphs / abstract structured representations (general structured inputs)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Unsupervised learning maps hypergraph concepts to text, typically via generative or probabilistic mapping without parallel supervision (details are from cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Unsupervised concept-to-text / data-to-text generation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Mentioned as part of prior unsupervised data-to-text literature; not empirically compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Proposed a way to do unsupervised generation from structured inputs before recent neural cycle methods.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Older approaches often require strong structural priors and may not scale to large neural architectures or highly diverse corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not reported in this paper; included as related prior work only.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8978.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e8978.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Template / Probabilistic Templates</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Template-based and Probabilistic Template Approaches (Kukich 1983; Angeli et al. 2010, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical approaches to data-to-text that use handcrafted templates or learned probabilistic templates to map structured data to surface text; typically used in small-data regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Template-based representations / probabilistic templates</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Representation consists of human-crafted or automatically abstracted templates that specify how to realize triples/fields as surface strings; probabilistic variants learn patterns/selection of templates.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Structured data / small knowledge graphs / domain-specific records</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Apply templates or learned templates to fill slots with entity values and connect clauses into sentences; probabilistic methods learn template selection distributions from limited data.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Data-to-text generation in constrained domains (e.g., sportscast, weather, restaurant descriptions)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Described as historically sufficient when data sizes were small; superseded by neural methods in large-data regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Interpretable, reliable in constrained domains, low-data requirements for basic coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Poor scalability, limited linguistic variation and naturalness, manual effort to craft templates or domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not empirically reported in this paper; known limits include brittle coverage and unnatural, repetitive text when applied to diverse corpora like Wikipedia.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training. <em>(Rating: 2)</em></li>
                <li>Text generation from knowledge graphs with graph transformers. <em>(Rating: 2)</em></li>
                <li>An unsupervised joint system for text generation from knowledge graphs and semantic parsing. <em>(Rating: 2)</em></li>
                <li>Unsupervised concept-to-text generation with hypergraphs. <em>(Rating: 2)</em></li>
                <li>The webnlg challenge: Generating text from RDF data. <em>(Rating: 2)</em></li>
                <li>Distant supervision for relation extraction without labeled data. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8978",
    "paper_id": "paper-582b1f5c08f79d0d62e41a9c0b1185f3e7292e4e",
    "extraction_schema_id": "extraction-schema-158",
    "extracted_data": [
        {
            "name_short": "Rule-Based Linearization",
            "name_full": "Rule-Based Graph Linearization (Schmitt et al., 2020 baseline)",
            "brief_description": "A simple linearization of a knowledge graph into a flat sequence of triples, turning camel-cased relation names into surface phrases and concatenating triple descriptions with conjunctions (e.g., 'and'). Used as a baseline for graph-to-text generation.",
            "citation_title": "An unsupervised joint system for text generation from knowledge graphs and semantic parsing.",
            "mention_or_use": "use",
            "representation_name": "Linearization / Triple Serialization",
            "representation_description": "Each graph is converted to a sequence of triples; each triple is verbalized as 'subject relation-phrase object' by converting camel-cased relation names to normal phrases; multiple triple verbalizations are joined (e.g., with 'and').",
            "graph_type": "Knowledge graphs (DBpedia-style RDF triples)",
            "conversion_method": "Deterministic template-like conversion: for each triple, map relation identifier to phrase, emit subject + relation phrase + object; concatenate triple verbalizations into a single sentence or short sequence separated by 'and'.",
            "downstream_task": "Graph-to-text generation (unsupervised / baseline evaluation)",
            "performance_metrics": "GenWiki_FINE: BLEU=13.45, METEOR=30.72, ROUGE_L=40.93, CIDEr=1.26; GenWiki_FULL: identical to FINE (BLEU=13.45, METEOR=30.72, ROUGE_L=40.93, CIDEr=1.26).",
            "comparison_to_others": "Performed substantially worse than learned unsupervised methods (CycleGT variants) and worse than NoisySupervised; similar in score to DirectTransfer on this dataset.",
            "advantages": "Deterministic, interpretable, requires no learning or parallel data; simple to implement.",
            "disadvantages": "Produces poor generation quality compared to learned models; yields rigid, unnatural phrasing and limited fluency.",
            "failure_cases": "Low BLEU and other metric scores indicate poor fluency and content matching; does not generalize to varied, natural Wikipedia-style text and misses natural language phenomena (noability to produce commonsense phrasing or aggregate information).",
            "uuid": "e8978.0",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Graph Transformer",
            "name_full": "Graph Transformer Generation Model (Koncel-Kedziorski et al., 2019)",
            "brief_description": "A transformer-based graph-to-sequence model that encodes graph structure and produces text; used in this paper as the core seq2seq architecture for DirectTransfer and NoisySupervised baselines.",
            "citation_title": "Text generation from knowledge graphs with graph transformers.",
            "mention_or_use": "use",
            "representation_name": "Graph Transformer encoding (graph-to-sequence)",
            "representation_description": "Graph structure is encoded into a transformer-based encoder that respects graph connectivity and node/edge representations; the encoded graph representation is then decoded autoregressively into text.",
            "graph_type": "Knowledge graphs (RDF-like triples / DBpedia graphs)",
            "conversion_method": "Learned graph encoder (graph transformer) maps nodes/edges into contextual embeddings which a sequence decoder uses to generate natural language text; in experiments, models trained on WebNLG (supervised) used this architecture.",
            "downstream_task": "Graph-to-text generation (supervised training and transfer to GenWiki), used also inside NoisySupervised pipeline.",
            "performance_metrics": "As used in DirectTransfer: GenWiki_FINE BLEU=13.89, METEOR=25.76, ROUGE_L=39.75, CIDEr=1.26; GenWiki_FULL identical.",
            "comparison_to_others": "When trained on WebNLG and applied directly (DirectTransfer) it performed similarly poorly to rule-based linearization on GenWiki, indicating limited cross-corpus generalization without adaptation. When trained on noisy distantly-aligned pairs (NoisySupervised) it substantially improved.",
            "advantages": "Learned representation that can exploit graph structure and produce fluent text when trained with suitable supervision.",
            "disadvantages": "Requires supervised or high-quality pseudo-supervised pairs to perform well; direct transfer across corpora may fail.",
            "failure_cases": "DirectTransfer (trained on WebNLG) produces low scores on GenWiki, showing brittleness to domain/style shifts and limited robustness when training data distribution differs.",
            "uuid": "e8978.1",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "DirectTransfer",
            "name_full": "Direct Transfer using Supervised Graph Transformer",
            "brief_description": "A transfer baseline that trains a graph transformer model on the supervised WebNLG dataset and directly applies it to GenWiki test data without further adaptation.",
            "citation_title": "Text generation from knowledge graphs with graph transformers.",
            "mention_or_use": "use",
            "representation_name": "Supervised-trained Graph Transformer (transfer inference)",
            "representation_description": "Representation is the graph-transformer encoding learned on WebNLG; at test time the model receives GenWiki graphs and generates text without additional finetuning.",
            "graph_type": "Knowledge graphs (WebNLG-style RDF triples applied to GenWiki)",
            "conversion_method": "Train encoder-decoder on WebNLG parallel graph-text pairs; at inference feed GenWiki graphs to encoder and decode output text.",
            "downstream_task": "Graph-to-text generation (transfer evaluation across corpora)",
            "performance_metrics": "GenWiki_FINE: BLEU=13.89, METEOR=25.76, ROUGE_L=39.75, CIDEr=1.26; GenWiki_FULL identical.",
            "comparison_to_others": "Scores similar to Rule-Based linearization and far below NoisySupervised and CycleGT, indicating poor out-of-domain generalization.",
            "advantages": "Straightforward application of a strong supervised model; no need to construct new training data for target corpus.",
            "disadvantages": "Fails to generalize reliably to corpora with different text styles and distributions; lower METEOR in particular versus other methods.",
            "failure_cases": "Performs poorly on GenWiki despite both datasets being wiki-based, suggesting sensitivity to domain/style mismatch and inability to adapt without target supervision.",
            "uuid": "e8978.2",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "NoisySupervised",
            "name_full": "NoisySupervised (Distantly Aligned Supervised Training)",
            "brief_description": "A baseline that converts the unsupervised GenWiki training data into pseudo-parallel pairs via distant alignment (entity-overlap matching) and then trains a supervised graph-transformer on these noisy pairs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Distantly-aligned pseudo-parallel representation",
            "representation_description": "Graphs and text from the non-parallel corpus are matched by entity overlap heuristics to create noisy graph-text pairs; these pseudo-pairs are used as supervised training data for a graph-to-text model.",
            "graph_type": "Knowledge graphs (DBpedia-derived small subgraphs of 1-10 triples)",
            "conversion_method": "Enumerate small graphs and text sequences per article; select graph-text pairs with high entity-overlap (distant supervision) to create noisy supervision; train a graph transformer in supervised fashion on these pairs.",
            "downstream_task": "Graph-to-text generation (supervised training on pseudo-parallel data)",
            "performance_metrics": "GenWiki_FINE: BLEU=30.12, METEOR=28.12, ROUGE_L=56.96, CIDEr=2.52; GenWiki_FULL: BLEU=35.03, METEOR=33.45, ROUGE_L=58.14, CIDEr=2.63.",
            "comparison_to_others": "Substantially better than Rule-Based and DirectTransfer; worse than CycleGT models by ~10 BLEU points on GenWiki_FINE but closer on GenWiki_FULL; performance validates that GenWiki contains useful alignment signal despite noise.",
            "advantages": "Leverages large-scale unsupervised corpora by creating pseudo-parallel data; simpler training pipeline (standard supervised learning) and achieves good performance.",
            "disadvantages": "Quality depends on the distant alignment heuristic and can introduce noisy or incorrect supervision; no explicit unsupervised cycle training.",
            "failure_cases": "Errors tied to noisy distant supervision; cases where entity overlap produces incorrect alignments or misses implicit relations will degrade model quality (paper notes reliance on distant supervision quality).",
            "uuid": "e8978.3",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "CycleGT_Base",
            "name_full": "CycleGT Base (Guo et al., 2020 basic iterative back-translation)",
            "brief_description": "An unsupervised cycle-training model that jointly learns graph-to-text generation and text-to-graph relation classification via iterative back-translation without pretraining, achieving strong unsupervised performance.",
            "citation_title": "Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training.",
            "mention_or_use": "use",
            "representation_name": "Cycle training (iterative back-translation) with graph-text cycle",
            "representation_description": "Two models (graph-&gt;text and text-&gt;graph) are trained jointly: generate text from graphs, reconstruct relations from generated text (relation classification given entities), and optimize a cycle loss to enable unsupervised learning.",
            "graph_type": "Knowledge graphs (closed set of relations, DBpedia-derived)",
            "conversion_method": "Iterative back-translation / cycle training: sample a graph, generate text; from generated text predict relations (text-to-graph classifier); enforce reconstruction consistency and alternate training between the two directions.",
            "downstream_task": "Unsupervised graph-to-text generation and text-to-graph relation classification (used for generation evaluation on GenWiki).",
            "performance_metrics": "GenWiki_FINE: BLEU=41.59, METEOR=35.72, ROUGE_L=63.31, CIDEr=3.57; GenWiki_FULL: BLEU=41.29, METEOR=35.39, ROUGE_L=63.73, CIDEr=3.53.",
            "comparison_to_others": "Outperformed NoisySupervised by ~10 BLEU points on GenWiki_FINE and is the strongest unsupervised model among evaluated baselines; comparable or slightly better than CycleGT_Warm depending on metric.",
            "advantages": "Strong unsupervised performance leveraging cycle consistency; robust learning from large non-parallel corpora without constructing noisy parallel pairs explicitly.",
            "disadvantages": "Training complexity of joint cycle optimization; requires reliable entity annotation and closed relation set (both provided by GenWiki) to avoid collapse.",
            "failure_cases": "Error analysis on CycleGT_Base: 27% of sampled errors are missing graph information (generated text omits triples), 20% are commonsense/semantic mistakes (e.g., reversing agent/owner roles or implausible statements); shows tendency to drop facts and sometimes produce commonsense violations.",
            "uuid": "e8978.4",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "CycleGT_Warm",
            "name_full": "CycleGT Warm (Guo et al., 2020 with warmup strategy)",
            "brief_description": "A variant of CycleGT that uses a warm-up stage before cycle training: it pretrains entity-to-text generation and entity-to-graph relation classification to stabilize subsequent cycle training, achieving near-identical strong performance.",
            "citation_title": "Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training.",
            "mention_or_use": "use",
            "representation_name": "Warm-start Cycle Training (entity-focused pretraining + iterative back-translation)",
            "representation_description": "Initial warmup: train simpler tasks that map entities to text and entities to relation classification to stabilize models; then perform iterative back-translation/cycle training as in CycleGT_Base.",
            "graph_type": "Knowledge graphs (DBpedia-style with closed relation set)",
            "conversion_method": "First warm up entity-conditioned generation and relation classifiers using entity annotations; then run cycle training (graph&lt;-&gt;text) to refine models under unsupervised reconstruction losses.",
            "downstream_task": "Unsupervised graph-to-text generation and text-to-graph relation classification",
            "performance_metrics": "GenWiki_FINE: BLEU=41.35, METEOR=35.20, ROUGE_L=63.01, CIDEr=3.45; GenWiki_FULL: BLEU=40.47, METEOR=34.84, ROUGE_L=63.40, CIDEr=3.48.",
            "comparison_to_others": "Performance comparable to CycleGT_Base, slightly better on BLEU in one split; both CycleGT variants substantially outperform NoisySupervised and other baselines.",
            "advantages": "More stable training (warmup) while achieving top unsupervised performance; leverages entity annotations to bootstrap models.",
            "disadvantages": "Adds a warmup stage complexity; still subject to the same types of generation errors (missing facts, commonsense errors).",
            "failure_cases": "Same observed failure modes as CycleGT_Base: omission of graph facts (~27% of errors in a sample) and commonsense violations (~20% of errors in a sample).",
            "uuid": "e8978.5",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Hypergraph Concept-to-Text",
            "name_full": "Unsupervised Concept-to-Text Generation with Hypergraphs (Konstas & Lapata, 2012)",
            "brief_description": "An earlier unsupervised approach that formulates concept-to-text generation using hypergraph structures to represent concepts and their relations, enabling unsupervised mapping from structured inputs to text.",
            "citation_title": "Unsupervised concept-to-text generation with hypergraphs.",
            "mention_or_use": "mention",
            "representation_name": "Hypergraph representation for concept-to-text",
            "representation_description": "Use of hypergraphs to represent structured concepts and their interrelations as the intermediate structure for unsupervised text generation; modeling focuses on extracting/synthesizing text from these hypergraph concepts.",
            "graph_type": "Concept hypergraphs / abstract structured representations (general structured inputs)",
            "conversion_method": "Unsupervised learning maps hypergraph concepts to text, typically via generative or probabilistic mapping without parallel supervision (details are from cited work).",
            "downstream_task": "Unsupervised concept-to-text / data-to-text generation",
            "performance_metrics": "",
            "comparison_to_others": "Mentioned as part of prior unsupervised data-to-text literature; not empirically compared in this paper.",
            "advantages": "Proposed a way to do unsupervised generation from structured inputs before recent neural cycle methods.",
            "disadvantages": "Older approaches often require strong structural priors and may not scale to large neural architectures or highly diverse corpora.",
            "failure_cases": "Not reported in this paper; included as related prior work only.",
            "uuid": "e8978.6",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Template / Probabilistic Templates",
            "name_full": "Template-based and Probabilistic Template Approaches (Kukich 1983; Angeli et al. 2010, etc.)",
            "brief_description": "Classical approaches to data-to-text that use handcrafted templates or learned probabilistic templates to map structured data to surface text; typically used in small-data regimes.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "Template-based representations / probabilistic templates",
            "representation_description": "Representation consists of human-crafted or automatically abstracted templates that specify how to realize triples/fields as surface strings; probabilistic variants learn patterns/selection of templates.",
            "graph_type": "Structured data / small knowledge graphs / domain-specific records",
            "conversion_method": "Apply templates or learned templates to fill slots with entity values and connect clauses into sentences; probabilistic methods learn template selection distributions from limited data.",
            "downstream_task": "Data-to-text generation in constrained domains (e.g., sportscast, weather, restaurant descriptions)",
            "performance_metrics": "",
            "comparison_to_others": "Described as historically sufficient when data sizes were small; superseded by neural methods in large-data regimes.",
            "advantages": "Interpretable, reliable in constrained domains, low-data requirements for basic coverage.",
            "disadvantages": "Poor scalability, limited linguistic variation and naturalness, manual effort to craft templates or domain knowledge.",
            "failure_cases": "Not empirically reported in this paper; known limits include brittle coverage and unnatural, repetitive text when applied to diverse corpora like Wikipedia.",
            "uuid": "e8978.7",
            "source_info": {
                "paper_title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
                "publication_date_yy_mm": "2020-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training.",
            "rating": 2
        },
        {
            "paper_title": "Text generation from knowledge graphs with graph transformers.",
            "rating": 2
        },
        {
            "paper_title": "An unsupervised joint system for text generation from knowledge graphs and semantic parsing.",
            "rating": 2
        },
        {
            "paper_title": "Unsupervised concept-to-text generation with hypergraphs.",
            "rating": 2
        },
        {
            "paper_title": "The webnlg challenge: Generating text from RDF data.",
            "rating": 2
        },
        {
            "paper_title": "Distant supervision for relation extraction without labeled data.",
            "rating": 2
        }
    ],
    "cost": 0.0156315,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation</h1>
<p>Zhijing Jin*<br>Amazon Shanghai AI Lab<br>zhijing.jin@connect.hku.hk<br>Xipeng Qiu<br>Fudan University<br>xpqiu@fudan.edu.cn</p>
<p>Qipeng Guo ${ }^{* \dagger}$<br>Fudan University<br>qpguo16@fudan.edu.cn<br>Zheng Zhang<br>Amazon Shanghai AI Lab<br>zhaz@amazon.com</p>
<h4>Abstract</h4>
<p>Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3 M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs. ${ }^{\dagger}$</p>
<h2>1 Introduction</h2>
<p>Text generation with deep learning models is data hungry. For example, in Figure 1, to make a model learn how to verbalize knowledge graphs, researchers need to collect a large number of human-annotated text and graph pairs. However, good annotation is both expensive and difficult to get - annotators need to have a thorough understanding of hundreds of edge types in the knowledge graphs, as well as proper verbalization of the text, so that the written text can conform to the distribution of the desired text style. Moreover, for dataset curators, checking the quality of annotation is also non-trivial. For example, the WebNLG dataset goes through five updates to fix errors in the annotation over the past 3 years. ${ }^{2}$</p>
<p>These difficulties in dataset collection makes parallel data-to-text datasets small-sized, and even nonexistent for low-resource domains. To make problems worse, data-to-text models are, in many cases, infeasible to transfer from one domain to another. For example, a text generation model that can produce Wikipedia biography-like descriptions cannot be used to generate introductions of plants. This can happen even between domains with similar content but different text styles. For example, given the knowledge graph triple "(Obama, birthYear, 1961)," one domain verbalizes it as "Obama was born in 1961," whereas another domain prefers "Obama (1961 - ) ...". A model trained in the first domain can only generate the entities correctly but fail on all other words in the second domain.</p>
<p>To overcome the lack of labelled data and difficulty in domain adaptation, unsupervised data-to-text generation has emerged as an active research field recently (Freitag and Roy, 2018; Schmitt et al., 2020; Guo et al., 2020). However, the progress of this line of research is slowed down due to the lack of largescale unsupervised datasets. Notably, the curation of graph-to-text unsupervised datasets are non-trivial, as it requires (1) same content distribution between graphs and text, (2) text with high-accuracy entity annotation, (3) a much larger scale than the supervised datasets, and (4) a human-annotated test set. Unfortunately, lacking such an unsupervised dataset, most unsupervised works have to artificially remove the pairing information between text and structured data, to force parallel datasets to be non-parallel. Obviously, splitting parallel datasets, such as the WebNLG dataset (13K), and E2E dataset (50K), into non-parallel ones remains the originally small data size. Consequenty, the research on unsupervised</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overview of the dataset.
models is limited, as these existing unsupervised models cannot even have a deep architecture. In contrast, a relatively faster field, unsupervised machine translation, has dataset sizes on the order of billions, such as 1.6B German and 2.1B English text used in (Artetxe et al., 2019).</p>
<p>Therefore, we propose a large dataset, GenWiki, which contains 1.3 million non-parallel text and graphs with shared content, and meet all four requirements mentioned before. To better facilitate research in unsupervised graph-to-text generation, we provide two versions of our dataset: the full dataset GenWiki ${ }<em _FINE="{FINE" _text="\text">{\text {FULL }}(1.3 \mathrm{M})$, and a fine version, GenWiki ${ }</em>}}$ (750K), which adds constraints on the text and graphs to force them to contain highly overlapped entity sets. The overview of our two datasets are shown in Figure 1. The GenWiki ${ <em _FINE="{FINE" _text="\text">{\text {FULL }}$ on the bottom left contains graphs on the same topic (Dota 2) as the text, and GenWiki ${ }</em>$ imposes a stronger constraint that entities in the graph can largely overlap with entities in text. Both datasets are collected in a scalable, automatic way. The comparison of our dataset and previous data-to-text datasets is illustrated in Table 1.}</p>
<p>An additional contribution is our human-annotated test set with of 1,000 graph and text pairs. Based on our large-scale training dataset and the human-annotated test set, we analyze the performance of several baselines and existing models. We conducted error analysis on the strengths and shortness of these unsupervised models in Section 5.4.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Size</th>
<th style="text-align: center;">Purpose</th>
<th style="text-align: center;">Collection</th>
<th style="text-align: center;">Domain</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">KBGen (Banik et al., 2013)</td>
<td style="text-align: center;">0.2 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Descriptions of biology knowledge bases</td>
</tr>
<tr>
<td style="text-align: center;">RoboCup (Chen and Mooney, 2008)</td>
<td style="text-align: center;">0.7 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Sportscast</td>
</tr>
<tr>
<td style="text-align: center;">RotoWire (Wiseman et al., 2017)</td>
<td style="text-align: center;">5 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Baseketball game summaries</td>
</tr>
<tr>
<td style="text-align: center;">SF Hotels/Restaurants (Wen et al., 2015)</td>
<td style="text-align: center;">10 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Dialogues about restaurants and hotels</td>
</tr>
<tr>
<td style="text-align: center;">WebNLG (Gardent et al., 2017)</td>
<td style="text-align: center;">13 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">15 categories (building, person)</td>
</tr>
<tr>
<td style="text-align: center;">WeatherGov (Liang et al., 2009)</td>
<td style="text-align: center;">22 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Weather forecasts</td>
</tr>
<tr>
<td style="text-align: center;">E2E (Novikova et al., 2017)</td>
<td style="text-align: center;">50 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Restaurant and hotel descriptions</td>
</tr>
<tr>
<td style="text-align: center;">WikiCompany (Qader et al., 2018)</td>
<td style="text-align: center;">51 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Company descriptions</td>
</tr>
<tr>
<td style="text-align: center;">ToTTO (Parikh et al., 2020)</td>
<td style="text-align: center;">100 K</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Human</td>
<td style="text-align: center;">Description of Wikipedia tables</td>
</tr>
<tr>
<td style="text-align: center;">WikiBio (Lebret et al., 2016)</td>
<td style="text-align: center;">$500 \mathrm{~K}^{3}$</td>
<td style="text-align: center;">Supervised</td>
<td style="text-align: center;">Auto</td>
<td style="text-align: center;">First sentence of Wikipedia biographies</td>
</tr>
<tr>
<td style="text-align: center;">GenWiki ${ }_{\text {FINE }}$</td>
<td style="text-align: center;">750 K</td>
<td style="text-align: center;">Unsupervised</td>
<td style="text-align: center;">Auto\&amp;distant align</td>
<td style="text-align: center;">General domain (all wiki topics)</td>
</tr>
<tr>
<td style="text-align: center;">GenWiki ${ }_{\text {FULL }}$</td>
<td style="text-align: center;">1.3 M</td>
<td style="text-align: center;">Unsupervised</td>
<td style="text-align: center;">Auto</td>
<td style="text-align: center;">General domain (all wiki topics)</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of previous text generation datasets and our GenWiki datasets. GenWiki ${ }<em _FULL="{FULL" _text="\text">{\text {FINE }}$ is the fine version (with stronger entity alignment) of our dataset, and GenWiki ${ }</em>$ is our full dataset.}</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>2 Existing Data-to-Text Models and Datasets</h1>
<p>Research in NLP can be viewed as a close interplay between models and datasets. Traditionally, most methods hand-craft linguistic features to build rule-based systems, so datasets containing hundreds or thousands of samples are adequate. For example, in data-to-text generation, the traditional approach is to hand-craft templates (Kukich, 1983; Holmes-Higgin, 1994; McRoy et al., 2000). There are also works that abstract the templates and use probabilistic models to learn the rules (Angeli et al., 2010; Howald et al., 2013). Popular datasets for these methods are, for example, the 0.7 K RoboCup dataset (Chen and Mooney, 2008).</p>
<p>With the advance of deep learning, models have a large number of parameters, so they have to be fueled by large datasets. For data-to-text generation, many supervised methods use large neural networks. To match with these data-hungry models, researchers devote many efforts to curate supervised datasets. Most supervised data-to-text datasets have tens of thousands of data. ${ }^{4}$ For instance, WebNLG dataset (Gardent et al., 2017) has 13 K valid data-text pairs, ${ }^{5}$ WeatherGov (Liang et al., 2009) has 22 K weather forecasts, and E2E (Novikova et al., 2017) has 50K restaurant and hotel descriptions, as shown in Table 1.</p>
<p>Recently, there is a rising trend of unsupervised approaches (Freitag and Roy, 2018; Schmitt et al., 2020; Guo et al., 2020). Unsupervised data-to-text models (Konstas and Lapata, 2012) are proposed in response to the lack of data-text pairs in many domains, similar to the emergence of unsupervised machine translation that addresses lack of data low-resource language pairs. However, to match with the active research on unsupervised data-to-text generation, no suitable dataset has been curated. As a result, most previous works have to artificially force parallel datasets to be non-parallel, by separately shuffling the data part and text part of the original dataset, or directly deleting the text part. However, such formulation will make the unsupervised datasets inherit the small size of the supervised datasets, which are limited to only tens of thousands samples.</p>
<p>There are several caveats of using small datasets for unsupervised models. (1) Limiting the model potential: Unsupervised models can be data-hungry. For example, 1.6B German and 2.1B English tokens are fed to unsupervised machine translation models (Artetxe et al., 2019); 3.3 billion words are used to pretrain the language model BERT (Devlin et al., 2019). With abundant data, the potential of unsupervised models is unleashed - impressive performance, based on an enormous number of parameters, such as 12 layers of transformers. So far, no large data-to-text corpus can be used to unveil the potential of unsupervised data-to-text. (2) Lack of diversity: As many unsupervised models need to impose strong priors such as grammar and dependency tree (Konstas and Lapata, 2012), if a proposed model works well on a specific type of text generation, we cannot validate whether such a model generalizes well. (3) Negligence of model efficiency: The goal of unsupervised models is to learn from as many unsupervised data as possible and thus achieve high accuracy. However, the current designs of many unsupervised models do not take efficiency into consideration because of the small datasets they use does not expose the problem of efficiency.</p>
<p>Hence, to foster research in unsupervised data-to-text learning, we construct a new, large-scale dataset, GenWiki, which can satisfy all constraints imposed by existing unsupervised models. The dataset will be introduced in Section 3 and 4.</p>
<h2>3 Desiderata</h2>
<p>Although it is easy to collect unsupervised datasets for tasks such as machine translation, it is a different story for data-to-text generation. To match with the design of unsupervised data-to-text models, some strict constraints are required. A common constraint is that the text and knowledge graphs should have the same content distribution. Some more specific constraints require, for example, the text corpus to have entity annotations. The reason is that recent unsupervised learning models (Guo et al., 2020; Schmitt et al., 2020) use cycle training of two tasks: graph-to-text, and text-to-graph, which is simplified to relation extraction given entities. This simplification requires the unsupervised text corpus to have</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>entity annotations in text. Additionally, it is also reasonable to make the relation types in the knowledge graphs a closed set of, for example, 300 relations as in WebNLG (Gardent et al., 2017). In this way, the relation extraction model can avoid collapsing on unseen relations in the test set, and it is also an easier job for human annotators as they only need to consider a limited-sized, well-defined set of relations.</p>
<p>We summarize the requirements of the dataset collection as follows:</p>
<ul>
<li>
<p>Basic Requirements</p>
</li>
<li>
<p>Text and graphs should have similar contents, such as a Wikipedia article and a knowledge graph of the same article.</p>
</li>
<li>To fit for recent unsupervised models (Guo et al., 2020; Schmitt et al., 2020), the text corpus should contain entity annotations.</li>
<li>
<p>The knowledge graphs should have a closed set of relations.</p>
</li>
<li>
<p>Preferred Properties</p>
</li>
<li>
<p>Large scale (over 500K).</p>
</li>
<li>Diversity, not limited to one specialized domain.</li>
<li>Human-annotated test set, as opposed to distant supervision test sets (Mintz et al., 2009; Riedel et al., 2010), because noisy test sets can misguide the comparison of unsupervised models.</li>
</ul>
<h1>4 GenWiki Dataset</h1>
<p>Based on the desiderata outlined in Section 3, we will first introduce the construction process of our training set in Section 4.1, and test set in Section 4.2. We will then analyze the characteristics of the resulting dataset in Section 4.3.</p>
<h3>4.1 Training Set Construction</h3>
<p>An ideal unsupervised graph-to-text dataset allows text sequences consisting of multiple sentences, and graphs of several triples. In the collection process of GenWiki, we allow each text sequence to have 1 to 10 sentences and at most 50 words, and graphs to have 1 to 10 triples. Our dataset aims to satisfy all the requirements mentioned in Section 3, namely (1) same content distribution between text and graph, (2) entity annotation in text, (3) a closed set of relations, (4) a large size, (5) diversity, and (6) a human-annotated test set. Specifically, our construction process is as follows.</p>
<p>Step 1. Data Collection Our dataset, GenWiki, is collected from general Wikipedia. Different from other data that are limited to specific categories of Wikipedia (Gardent et al., 2017; Lebret et al., 2016; Wang et al., 2018), we aim at general-domain data-to-text generation. To this end, we collect text from the HTML webpages of all Wikipedia articles by April 2020, and use the titles of these articles to query their corresponding knowledge graphs from DBpedia. ${ }^{6}$ Note that we identify all hyperlinked terms in the HTML files as entities. We tokenize the text corpus using the NLTK package. ${ }^{7}$</p>
<p>The output of this step is Wikipedia articles with hyperlinked entities, and each article's corresponding knowledge graph.</p>
<p>Step 2. Filtering For all the articles retrieved from Wikipedia, we filter out empty pages, and pages containing placeholder contents such as "See the error message at the bottom of this page for more information." To control the quality, we also look at the top 10 frequent sentences, and filter out highfrequency but unrelated sentences such as "Media related to ... at Wikimedia Commons."</p>
<p>For the noisy graphs collected from Step 1, we only keep relations (namely edge types) that can be grounded to DBpedia relation ontology. We then filter out meta-relations such as "wikiPageRedirect," and relations that are unlikely to be described in text such as "latitude" and "longitude." After this filtering, due to the close-set relation constraint, we only keep the top 300 frequent relations, similar to the practice of (Gardent et al., 2017). The full list of relations that are filtered out or kept is available at https://github.com/zhijing-jin/genwiki.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>After Step 2, the resulting dataset include 14,734,778 articles, and 3,009,112 graphs, with 19.45 triples per graph on average.</p>
<p>Step 3. Entity Annotation To fit for the recent advances of unsupervised models based on cycle training, we take a challenging step to annotate the entities in text. From Step 1, terms with hyperlinks are annotated as entities. However, such annotation is very sparse, one per 14.50 words. The reason is that Wikipedia hyperlinks are manually added by human contributors, and not all occurrences of entities are linked. For example, there is no hyperlink in the sentence "In October 1871, Claude Monet returned to France." despite the existence of three entities, "October 1871," "Claude Monet," and "France."</p>
<p>To increase the entity annotation in text, we develop a hybrid of methods based on the following intuitions:</p>
<ol>
<li>All entities in the graph should be annotated if they also occur in the corresponding article.</li>
<li>The surface forms of graph entities (e.g., "President Obama" is a surface form of "Barack Obama") should also be annotated if they appear in the corresponding article.</li>
<li>Named entities, including dates, locations, organizations, and numbers, should be annotated.</li>
<li>Personal pronouns (e.g., "he", "she") should also be annotated.</li>
</ol>
<p>Therefore, we first prepare a set of candidate entities for each sentence, including (1) entities in the knowledge graph corresponding to the Wikipedia article, (2) all surface forms of graph entities, (3) named entities annotated by the stanza package, ${ }^{8}$ and (4) personal pronouns except the versatile "it." We annotate these entities whenever their occurrence in the text is detected. Note that there might be overlapping entities (e.g., "Obama" is a substring of "Barack Obama," but both are entities), so we start from entities with the most number of words to entities with the fewest number of words.</p>
<p>The resulting density of annotated entities in text is one per 4.28 words.
Step 4. Text-Graph Alignment Remember the first hard requirement (that text and graphs should have similar contents). We introduce an alignment step to ensure that this constraint can be approximated. This step is inspired by the assumption introduced in distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2010): if the entity sets of a text sequence and a relation overlap, it is highly likely that the sentence express that relation.</p>
<p>In Step 4, for each article and its corresponding graph, we enumerate all text sequences (1-10 subsequent sentences with at most 50 words) and all small graphs (1-10 triples). For each text sequence, we only add it to the text corpus if its entity set can overlap with the entity set. Similarly, for each small graph, we add it to the graph dataset only if its entity set overlaps with the entity set of at least one text sequence. In this way, we collect the text sequences and graphs with shared content, and form GenWiki $_{\text {FULL }}$.</p>
<p>It is also good to curate a finer version of our dataset by imposing a higher threshold of entity overlap rate. Specifically, we construct GenWiki $_{\text {FINE }}$ which consists of text sequences that have an F1 score of over $40 \%$ and entity overlap of at least 2 with at least one graph, and graphs in the same way.</p>
<h1>4.2 Test Set Annotation</h1>
<p>Apart from the unsupervised training set, we also collect a human-annotated test set of 1,000 text-graph pairs. To ensure the quality, we recruit annotators who have experience in data-to-text research. The annotators are introduced the background of the task, format of the data, and goals of annotation.</p>
<p>As the test set annotation is intensive and challenging, we design a workflow to minimize the annotators' effort. Based on a randomly selected sample set from the training set, we automatically construct distantly aligned graph-text pairs, to serve as a reference for human annotators. Each distantly aligned pair are the text and graph which have a higher entity F1 with each other than with any other text or graph of the same Wikipedia article. The whole workflow is as follows:</p>
<ol>
<li>
<p>We construct distantly aligned pairs, and, as supplementary information, we show the annotator the entire knowledge graph (up to a hundred triples) of the source Wikipedia article of each pair.
<sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
</li>
<li>
<p>We format each example in a reader-friendly way, by underlining all entities in text, and bold-facing overlapped entities between text and graphs. We also provide the corresponding Wikipedia article title, so that the annotator can look up the article if the annotation requires background knowledge.</p>
</li>
<li>
<p>Annotators first check if there is an easy way to edit the text and graph so that they express the same content.</p>
</li>
<li>
<p>If yes, then make minimal edits to align the text and graph</p>
</li>
<li>
<p>If no, then split one sample into two cases, where the first case keeps the text as original and edits the graph to align with the text, and the second case keeps the graph as original and modifies the text.</p>
</li>
<li>
<p>We use programs to check whether in each annotated sample, the text entities perfectly match with the graph entities. If not, we reject the sample, and return it to the annotators to redo Step 3.</p>
</li>
</ol>
<h1>4.3 Analysis</h1>
<p>Reflection on the Desiderata We compare our dataset with the two most similar previous datasets, WikiBio (Lebret et al., 2016) and WebNLG (Gardent et al., 2017). The properties evaluated in Table 2 correspond to the desiderata we outlined previously in Section 3. Unlisted properties imply that all three datasets have satisfied them. The diversity property is evaluated by both the domain and text type.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Basic Requirements</th>
<th style="text-align: center;">Preferred Properties</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Entity Annotation</td>
<td style="text-align: center;">$&gt;500 \mathrm{~K}$</td>
<td style="text-align: center;">Domain</td>
<td style="text-align: center;">Text Type</td>
<td style="text-align: center;">Gold Test</td>
</tr>
<tr>
<td style="text-align: left;">WikiBio</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">Biography</td>
<td style="text-align: center;">1st sentence of biography</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
</tr>
<tr>
<td style="text-align: left;">WebNLG</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">15 specific categories</td>
<td style="text-align: center;">1-7 crowdsourced sentences</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
<tr>
<td style="text-align: left;">GenWiki</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">All wiki categories</td>
<td style="text-align: center;">1-10 Wikipedia sentences</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
</tbody>
</table>
<p>Table 2: Properties of WikiBio, WebNLG, and our dataset with regard to the desiderata in Section 3.
Among the three datasets, WikiBio, despite a large size, does not have entity annotations or a gold test set, so it cannot be used by many unsupervised models. On the other hand, WebNLG is a humanannotated supervised dataset, so it has high-quality entity annotation, and covers relatively diverse topics, 13 wiki categories including athletes, buildings, and universities. However, due to the manual annotation, WebNLG cannot scale to higher orders of magnitudes such as millions of data samples that our dataset has.</p>
<p>Our dataset, GenWiki, satisfies all criteria. Its text corpus has entity annotation, and GenWiki has a gold test. Due to the automatic collection process, it has a large number of data, and can easily scale to other domains in the future. It is also diverse in terms of categories of Wikipedia articles that every data sample is extracted from. The diversity can also be reflected through the text type, as crowdsourced sentences tend to be simpler and have less variations than the well-edited Wikipedia text. We will quantify characteristics of our dataset compared to WebNLG more in detail later in this section.</p>
<p>Dataset Overview For our two versions of datasets, GenWiki ${ }<em _FULL="{FULL" _text="\text">{\text {FINE }}$ and GenWiki ${ }</em>$, we summarize the overall statistics of our GenWiki dataset in Table 3. We compare it with WebNLG, which also meets all three basic requirements, and has been used for previous unsupervised models (Guo et al., 2020; Schmitt et al., 2020).}</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Overview</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Graph</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Examples</td>
<td style="text-align: center;">Entities</td>
<td style="text-align: center;">Triples</td>
<td style="text-align: center;">Avg Triples</td>
<td style="text-align: center;">Relations</td>
<td style="text-align: center;">Tokens</td>
<td style="text-align: center;">Vocab</td>
<td style="text-align: center;">Avg Len</td>
</tr>
<tr>
<td style="text-align: left;">WebNLG</td>
<td style="text-align: center;">13,036</td>
<td style="text-align: center;">1,727</td>
<td style="text-align: center;">33,075</td>
<td style="text-align: center;">$2.54 \pm 1.42$</td>
<td style="text-align: center;">244</td>
<td style="text-align: center;">198,927</td>
<td style="text-align: center;">1,484</td>
<td style="text-align: center;">$15.26 \pm 8.13$</td>
</tr>
<tr>
<td style="text-align: left;">GenWiki $_{\text {FINE }}$</td>
<td style="text-align: center;">757,152</td>
<td style="text-align: center;">$1,230,920$</td>
<td style="text-align: center;">$2,000,636$</td>
<td style="text-align: center;">$2.64 \pm 1.72$</td>
<td style="text-align: center;">287</td>
<td style="text-align: center;">$19,725,390$</td>
<td style="text-align: center;">328,487</td>
<td style="text-align: center;">$26.05 \pm 10.99$</td>
</tr>
<tr>
<td style="text-align: left;">GenWiki $_{\text {FULL }}$</td>
<td style="text-align: center;">$1,336,766$</td>
<td style="text-align: center;">$1,950,664$</td>
<td style="text-align: center;">$2,607,997$</td>
<td style="text-align: center;">$1.95 \pm 1.42$</td>
<td style="text-align: center;">290</td>
<td style="text-align: center;">$28,693,319$</td>
<td style="text-align: center;">476,341</td>
<td style="text-align: center;">$21.46 \pm 10.64$</td>
</tr>
</tbody>
</table>
<p>Table 3: Overall statistics of GenWiki ${ }<em _FULL="{FULL" _text="\text">{\text {FINE }}$ and GenWiki ${ }</em>$, compared with WebNLG.
We can see from Table 3 that our dataset has significantly more data than the human-annotated WebNLG, and can be a better dataset for unsupervised learning. Our GenWiki ${ }_{\text {FINE }}$ contains 757 K ex-}</p>
<p>amples with about 20 M tokens, and GenWiki ${ }<em _FINE="{FINE" _text="\text">{\text {FULL }}$ contains 1.3 M samples with about 30 M tokens. The number of examples of our GenWiki ${ }</em>}}$ is 58 times the size of WebNLG, and GenWiki ${ <em _FINE="{FINE" _text="\text">{\text {FULL }}$ is 102 times the size of WebNLG. Similar to the overall size, the number of entities, triples, tokens, and vocabulary size of our dataset are also several orders of magnitudes higher than that of WebNLG. On average, each graph of GenWiki ${ }</em>}}$ has 2.64 triples and each text 26.05 words; GenWiki ${ <em _FULL="{FULL" _text="\text">{\text {FULL }}$ has 1.94 triples per graph, and 21.46 words per text sequence. The smaller average size of GenWiki ${ }</em>}}$ than GenWiki ${ <em _FULL="{FULL" _text="\text">{\text {FINE }}$ might be due to the lower entity overlap threshold when collecting data for GenWiki ${ }</em>$, which allows for more small graphs, and short text sequences.}</p>
<p>Diversity of Topics We plot the most frequent topics and their counts in Figure 2a, and show some examples of three representative categories in Figure 2b. To make Figure 2a more illustrative, we omit the top-1 frequent category, biography, which has 339 K Wikipedia articles, and plot the next 20 categories which are more on the same scale.</p>
<p>Figure 2a shows that the dataset includes a variety of topic categories such as sports and games (77K), politics and government (30K), and arts and entertainment (29K). It also include many places, ranging from United States (50K), to India (40K), and France (34K). It also has nature-related articles, such as the order of insects Lepidoptera (46K), insects (28K), and geography (27K). Interestingly, there is a considerable number of articles related to women (39K).</p>
<p>Figure 2b shows some typical examples in three categories, sports and games, United States, and women. Bold terms in the text box are automatically annotated entities. Note that in the dataset, each topic has some related graphs and text. Although not strictly aligned, the graphs and text have an overall similar content distribution.
<img alt="img-1.jpeg" src="img-1.jpeg" />
(a) Most frequent categories of topics and corresponding counts in GenWiki ${ }_{\text {FULL }}$.
<img alt="img-2.jpeg" src="img-2.jpeg" />
(b) Non-parallel text and graphs of three frequent categories, sports and games, United States, and women.</p>
<p>Figure 2: Top categories in GenWiki and examples.</p>
<p>Distribution of Relation Types Relation types is an important feature as it indicates the diversity of knowledge graphs, and correlates with the diversity of text generation. As we can see from Figure 3, there are a variety of relations, from the biography-related ones such as birthPlace, birthYear, and deathPlace, to general relations such as country, family, activeYearsStart, populationTotal, isPartOf, and so on. The distribution of relations are long-tailed, as some least frequent relations, although not plotted, have only 10 to 20 occurrences.</p>
<p>Richness of Text and Graphs We evaluate the lexical richness and graph characteristics in Table 4. We first show the lexical diversity by type-token ratio (TTR), on which WebNLG scores 0.007 , compared to 0.016 and 0.017 of the two GenWiki datasets. As TTR is sensitive to sample size, we also show the mean segmental type-token ratio (MSTTR) (Johnson, 1944). MSTTR is the average TTR for successive</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: Top 20 most frequent relations and corresponding counts on GenWiki ${ }_{\text {FULL }}$.
segments of text or transcript that contain a standard number of tokens. We calculate the MSTTR for successive every 50 words in the text corpus of each dataset. WebNLG's MSTTR is lower than that of GenWik by a large margin. We also evaluate the entity density (the number of entity words divided by the number of all words), where we can see that all three datasets have a similar entity density of around $23 \%$ or $27 \%$. Complementary to the entity density, we also define the concept of information density, which refers to the number of words divided by the number of triples, because text and graphs share the same content. Apart from characteristics of text richness, we also look into the graph richness, and calculate the percentage of graphs with more than two triples in Table 4.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">TTR</th>
<th style="text-align: center;">MSTTR</th>
<th style="text-align: center;">Entity Words in Text</th>
<th style="text-align: center;">Information Density</th>
<th style="text-align: center;">Graphs with $\geq 2$ Triples</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">WebNLG</td>
<td style="text-align: center;">0.007</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">$23 \%$</td>
<td style="text-align: center;">6.01</td>
<td style="text-align: center;">$69 \%$</td>
</tr>
<tr>
<td style="text-align: left;">GenWiki $_{\text {FINE }}$</td>
<td style="text-align: center;">0.016</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">$27 \%$</td>
<td style="text-align: center;">9.86</td>
<td style="text-align: center;">$72 \%$</td>
</tr>
<tr>
<td style="text-align: left;">GenWiki $_{\text {FULL }}$</td>
<td style="text-align: center;">0.017</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">$23 \%$</td>
<td style="text-align: center;">11.00</td>
<td style="text-align: center;">$48 \%$</td>
</tr>
</tbody>
</table>
<p>Table 4: Dataset characteristics. Information Density is number of words per triple.</p>
<h1>5 Evaluating Unsupervised Data-to-Text Models</h1>
<p>Since the main purpose of our GenWiki dataset is to serve for future models on unsupervised graph-totext generation, we provide a preliminary set of experiments using previous unsupervised data-to-text models. Our results can serve as baselines for future work developed on this resource.</p>
<h3>5.1 Models</h3>
<p>Based on our datasets, we evaluate the following unsupervised baselines.
Rule-Based As a baseline proposed by (Schmitt et al., 2020), Rule-Based linearizes the graph into a sequence of triples. Each triple is described by turning the camel-cased relation type to a normal phrase. For example, the triple "(New York City, populationTotal, 8 million)" will be verbalized as "New York City population total 8 million." The descriptions of multiple triples are joined by "and."</p>
<p>DirectTransfer DirectTransfer is another intuitive baseline, where we use a model trained on the supervised WebNLG dataset, and test it on the GenWiki test set. For a fair comparison, we use a graph transformer generation model proposed by (Koncel-Kedziorski et al., 2019) for all graph-to-text models.</p>
<p>NoisySupervised We also propose another baseline, NoisySupervised, which attempts to absorb the weak supervision signals in the training set, and convert the difficult unsupervised learning problem into supervised learning. Specifically, NoisySupervised first constructs distantly aligned pairs on the whole training data, using the same matching method that we adopted to create our preliminary test set before human annotation. It then takes these pairs with noises as supervision signals, and learn from them using the graph transformer (Koncel-Kedziorski et al., 2019).</p>
<p>CycleGT ${ }_{\text {Base }}$ (Guo et al., 2020) proposes two models, the first of which uses a basic setting, iterative back translation with no pretraining. The CycleGT model jointly learns from two losses, a graph-to-text generation loss, and text-to-graph relation classification loss. Such a cycle training setting, despite its simplicity, was proved comparable performance with supervised models on the WebNLG dataset.</p>
<p>CycleGT $_{\text {Warm }}$ The second setting proposed in (Guo et al., 2020) uses a warm up strategy before the cycle training process. Specifically, as entities are given by the dataset and serve as shared information between text and graphs, the CycleGT model warms up by learning entity-to-text generation and entity-to-graph relation classification. This warm up strategy is used to make the unsupervised training more stable.</p>
<h1>5.2 Evaluation Metrics</h1>
<p>We evaluate the text generation quality by four commonly used metrics: BLEU (Papineni et al., 2002), Meteor (Banerjee and Lavie, 2005), ROUGE (Lin, 2004) and CIDEr (Vedantam et al., 2015), to measure the closeness of the reconstructed paragraph (model output) to the input paragraph. ${ }^{9}$</p>
<h3>5.3 Implementation Details</h3>
<p>For CycleGT $<em _Warm="{Warm" _text="\text">{\text {Base }}$ and CycleGT $</em>$, we use the same code provided by (Guo et al., 2020). For DirectTransfer and NoisySupervised, we use the graph transformer model (Koncel-Kedziorski et al., 2019) reimplemented by (Guo et al., 2020) using the Deep Graph Library (DGL) (Wang et al., 2019). For a fair comparison, we use the same hyperparameters for the overlapped components of NoisySupervised, CycleGT $}<em _Warm="{Warm" _text="\text">{\text {Base }}$, and CycleGT $</em>$.}</p>
<h3>5.4 Results</h3>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">GenWiki $_{\text {FINE }}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">GenWiki $_{\text {FULL }}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">BLEU</td>
<td style="text-align: center;">METEOR</td>
<td style="text-align: center;">ROUGE $_{\mathrm{L}}$</td>
<td style="text-align: center;">CIDEr</td>
<td style="text-align: center;">BLEU</td>
<td style="text-align: center;">METEOR</td>
<td style="text-align: center;">ROUGE $_{\mathrm{L}}$</td>
<td style="text-align: center;">CIDEr</td>
</tr>
<tr>
<td style="text-align: left;">Rule-Based</td>
<td style="text-align: center;">13.45</td>
<td style="text-align: center;">30.72</td>
<td style="text-align: center;">40.93</td>
<td style="text-align: center;">1.26</td>
<td style="text-align: center;">13.45</td>
<td style="text-align: center;">30.72</td>
<td style="text-align: center;">40.93</td>
<td style="text-align: center;">1.26</td>
</tr>
<tr>
<td style="text-align: left;">DirectTransfer</td>
<td style="text-align: center;">13.89</td>
<td style="text-align: center;">25.76</td>
<td style="text-align: center;">39.75</td>
<td style="text-align: center;">1.26</td>
<td style="text-align: center;">13.89</td>
<td style="text-align: center;">25.76</td>
<td style="text-align: center;">39.75</td>
<td style="text-align: center;">1.26</td>
</tr>
<tr>
<td style="text-align: left;">NoisySupervised</td>
<td style="text-align: center;">30.12</td>
<td style="text-align: center;">28.12</td>
<td style="text-align: center;">56.96</td>
<td style="text-align: center;">2.52</td>
<td style="text-align: center;">35.03</td>
<td style="text-align: center;">33.45</td>
<td style="text-align: center;">58.14</td>
<td style="text-align: center;">2.63</td>
</tr>
<tr>
<td style="text-align: left;">CycleGT $_{\text {Warm }}$</td>
<td style="text-align: center;">41.35</td>
<td style="text-align: center;">35.20</td>
<td style="text-align: center;">63.01</td>
<td style="text-align: center;">3.45</td>
<td style="text-align: center;">40.47</td>
<td style="text-align: center;">34.84</td>
<td style="text-align: center;">63.40</td>
<td style="text-align: center;">3.48</td>
</tr>
<tr>
<td style="text-align: left;">CycleGT $_{\text {Base }}$</td>
<td style="text-align: center;">41.59</td>
<td style="text-align: center;">35.72</td>
<td style="text-align: center;">63.31</td>
<td style="text-align: center;">3.57</td>
<td style="text-align: center;">41.29</td>
<td style="text-align: center;">35.39</td>
<td style="text-align: center;">63.73</td>
<td style="text-align: center;">3.53</td>
</tr>
</tbody>
</table>
<p>Table 5: The performance of unsupervised models on GenWiki ${ }<em _FULL="{FULL" _text="\text">{\text {FINE }}$ and GenWiki $</em>$.
Main Results The main experiment results are listed in Table 5. From the text generation quality of the five models, we can see that the Rule-Based baseline (Schmitt et al., 2020) performs poorly on our GenWiki dataset. The DirectTransfer also has a similar performance as Rule-Based, which implies that even though WebNLG and GenWiki are similar wiki-based datasets, it is difficult to make a model trained on one corpus to do well on the other slightly different one. The NoisySupervised model performs relatively well, scoring 30.30 BLEU points. As it relies on the quality of distant supervision on our non-parallel training set, the good performance of the NoisySupervised model validates that the GenWiki dataset has a good alignment of text and graphs. The two models proposed by (Guo et al., 2020), CycleGT Base and CycleGT $}<em _Warm="{Warm" _text="\text">{\text {Warm }}$ is the strongest out of all unsupervised models, outperforming NoisySupervised by 10 BLEU points. The two models achieve similar performance with each other, with CycleGT $</em>$ higher on the other three metrics.}}$ slightly better on BLEU, and CycleGT ${ }_{\text {Base }</p>
<p>Error Analysis We select 100 samples from the test set, and analyze the outputs of the best performing model, CycleGT $_{\text {Base }}$. There are two main types of error: The first type is that the generated text misses some information in the graph, which comprises $27 \%$ of the errors. For example, the ground truth sentence is "Martial Outlaw is written by Thomas Ritz and Pierre David, produced by Pierre David, and directed by Kurt Anderson.", whereas the model misses a lot of information in its output "Martial Outlaw is a song written by Kurt Anderson and Pierre David." The second error type is that the generated text lacks commonsense, which comprises $20 \%$ of the errors. For example, the ground truth is "Solar</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Entertainment Corporation is founded and owned by the Tieng family." but the model generates "The Tieng family was developed by Solar Entertainment Corporation." which violates common sense.</p>
<h1>6 Conclusion</h1>
<p>In this paper, we constructed a large-scale, general-domain text generation dataset, GenWiki. This work is designed for the emerging research on unsupervised models for text generation. Our dataset is several magnitudes larger than previous text generation datasets, covers a diverse range of topics, and contains more complicated linguistic structures. It relieves the unsupervised models of the limited sizes of previous datasets, and lays the foundation for more future research on unsupervised text generation models.</p>
<h2>Acknowledgements</h2>
<p>We thank all lab mates at AWS Shanghai AI lab for fruitful discussions and suggestions. We also appreciate the reviewers for their helpful and constructive inputs that help us improve this paper.</p>
<h2>References</h2>
<p>Gabor Angeli, Percy Liang, and Dan Klein. 2010. A simple domain-independent probabilistic approach to generation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 October 2010, MIT Stata Center, Massachusetts, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 502-512. ACL.</p>
<p>Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2019. An effective approach to unsupervised machine translation. In Anna Korhonen, David R. Traum, and Llus Mrquez, editors, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages 194-203. Association for Computational Linguistics.</p>
<p>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: an automatic metric for MT evaluation with improved correlation with human judgments. In Jade Goldstein, Alon Lavie, Chin-Yew Lin, and Clare R. Voss, editors, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005, Ann Arbor, Michigan, USA, June 29, 2005, pages 65-72. Association for Computational Linguistics.</p>
<p>Eva Banik, Claire Gardent, and Eric Kow. 2013. The kbgen challenge. In Albert Gatt and Horacio Saggion, editors, ENLG 2013 - Proceedings of the 14th European Workshop on Natural Language Generation, August 8-9, 2013, Sofia, Bulgaria, pages 94-97. The Association for Computer Linguistics.</p>
<p>David L. Chen and Raymond J. Mooney. 2008. Learning to sportscast: a test of grounded language acquisition. In William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, volume 307 of ACM International Conference Proceeding Series, pages 128-135. ACM.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171-4186.</p>
<p>Markus Freitag and Scott Roy. 2018. Unsupervised natural language generation with denoising autoencoders. In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun'ichi Tsujii, editors, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 3922-3929. Association for Computational Linguistics.</p>
<p>Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. 2017. The webnlg challenge: Generating text from RDF data. In Jos M. Alonso, Alberto Bugarn, and Ehud Reiter, editors, Proceedings of the 10th International Conference on Natural Language Generation, INLG 2017, Santiago de Compostela, Spain, September 4-7, 2017, pages 124-133. Association for Computational Linguistics.</p>
<p>Qipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, David Wipf, and Zheng Zhang. 2020. Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training. CoRR, abs/2006.04702.</p>
<p>Paul Holmes-Higgin. 1994. Text generation - using discourse strategies and focus constraints to generate natural language text by kathleen r. mckeown, cambridge university press, 1992, pp 246, 13.95, ISBN 0-521-43802-0. Knowledge Eng. Review, 9(4):421-422.</p>
<p>Blake Howald, Ravikumar Kondadadi, and Frank Schilder. 2013. Domain adaptable semantic clustering in statistical NLG. In Katrin Erk and Alexander Koller, editors, Proceedings of the 10th International Conference on Computational Semantics, IWCS 2013, March 19-22, 2013, University of Potsdam, Potsdam, Germany, pages 143-154. The Association for Computer Linguistics.</p>
<p>Wendell Johnson. 1944. Studies in language behavior: A program of research. Psychological Monographs, $56(2): 1-15$.</p>
<p>Rik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, and Hannaneh Hajishirzi. 2019. Text generation from knowledge graphs with graph transformers. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 2284-2293. Association for Computational Linguistics.</p>
<p>Ioannis Konstas and Mirella Lapata. 2012. Unsupervised concept-to-text generation with hypergraphs. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 3-8, 2012, Montral, Canada, pages 752-761. The Association for Computational Linguistics.</p>
<p>Karen Kukich. 1983. Design of a knowledge-based report generator. In Mitchell P. Marcus, editor, 21st Annual Meeting of the Association for Computational Linguistics, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA, June 15-17, 1983, pages 145-150. ACL.</p>
<p>Rmi Lebret, David Grangier, and Michael Auli. 2016. Neural text generation from structured data with application to the biography domain. In Jian Su, Xavier Carreras, and Kevin Duh, editors, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 1203-1213. The Association for Computational Linguistics.</p>
<p>Percy Liang, Michael I. Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Keh-Yih Su, Jian Su, and Janyce Wiebe, editors, ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009, Singapore, pages 91-99. The Association for Computer Linguistics.</p>
<p>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74-81, Barcelona, Spain, July. Association for Computational Linguistics.</p>
<p>Susan W McRoy, Songsak Channarukul, and Syed S Ali. 2000. Yag: A template-based generator for real-time systems. In INLG'2000 Proceedings of the First International Conference on Natural Language Generation, pages $264-267$.</p>
<p>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Keh-Yih Su, Jian Su, and Janyce Wiebe, editors, ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009, Singapore, pages 1003-1011. The Association for Computer Linguistics.</p>
<p>Amit Moryossef, Yoav Goldberg, and Ido Dagan. 2019. Step-by-step: Separating planning from realization in neural data-to-text generation. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 2267-2277. Association for Computational Linguistics.</p>
<p>Jekaterina Novikova, Ondrej Dusek, and Verena Rieser. 2017. The E2E dataset: New challenges for end-to-end generation. In Kristiina Jokinen, Manfred Stede, David DeVault, and Annie Louis, editors, Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, Saarbrcken, Germany, August 15-17, 2017, pages 201-206. Association for Computational Linguistics.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pages 311-318. ACL.</p>
<p>Ankur P. Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das. 2020. Totto: A controlled table-to-text generation dataset. CoRR, abs/2004.14373.</p>
<p>Raheel Qader, Khoder Jneid, Franois Portet, and Cyril Labb. 2018. Generation of company descriptions using concept-to-text and text-to-text deep models: dataset collection and systems evaluation. In Proceedings of the 11th International Conference on Natural Language Generation, pages 254-263. Association for Computational Linguistics.</p>
<p>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Jos L. Balczar, Francesco Bonchi, Aristides Gionis, and Michle Sebag, editors, Machine Learning and Knowledge Discovery in Databases, European Conference, ECML PKDD 2010, Barcelona, Spain, September 20-24, 2010, Proceedings, Part III, volume 6323 of Lecture Notes in Computer Science, pages 148-163. Springer.</p>
<p>Martin Schmitt, Sahand Sharifzadeh, Volker Tresp, and Hinrich Schtze. 2020. An unsupervised joint system for text generation from knowledge graphs and semantic parsing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, Online, November. Association for Computational Linguistics.</p>
<p>Ramakrishna Vedantam, C. Lawrence Zitnick, and Devi Parikh. 2015. Cider: Consensus-based image description evaluation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015, pages 4566-4575. IEEE Computer Society.</p>
<p>Qingyun Wang, Xiaoman Pan, Lifu Huang, Boliang Zhang, Zhiying Jiang, Heng Ji, and Kevin Knight. 2018. Describing a knowledge base. In Emiel Krahmer, Albert Gatt, and Martijn Goudbeek, editors, Proceedings of the 11th International Conference on Natural Language Generation, Tilburg University, The Netherlands, November 5-8, 2018, pages 10-21. Association for Computational Linguistics.</p>
<p>Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J. Smola, and Zheng Zhang. 2019. Deep graph library: Towards efficient and scalable deep learning on graphs. CoRR, abs/1909.01315.</p>
<p>Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-hao Su, David Vandyke, and Steve J. Young. 2015. Semantically conditioned lstm-based natural language generation for spoken dialogue systems. In Llus Mrquez, Chris Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton, editors, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 1711-1721. The Association for Computational Linguistics.</p>
<p>Sam Wiseman, Stuart M. Shieber, and Alexander M. Rush. 2017. Challenges in data-to-document generation. In Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, pages 2253-2263. Association for Computational Linguistics.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{9}$ We calculate all metrics using the pycocoevalcap tool (https://github.com/salaniz/pycocoevalcap).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>