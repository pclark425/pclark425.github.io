<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6927 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6927</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6927</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-12584984</p>
                <p><strong>Paper Title:</strong> <a href="http://centaur.reading.ac.uk/17118/1/Met_Rod_Bah_Vig_[Cortex_Review]_RESUBMISSION_4.pdf" target="_blank">Coming of age: a review of embodiment and the neuroscience of semantics</a></p>
                <p><strong>Paper Abstract:</strong> Over the last decade, there has been an increasing body of work that explores whether sensory and motor information is a necessary part of semantic representation and processing. This is the embodiment hypothesis. This paper presents a theoretical review of this work that is intended to be useful for researchers in the neurosciences and neuropsychology. Beginning with a historical perspective, relevant theories are placed on a continuum from strongly embodied to completely unembodied representations. Predictions are derived and neuroscientific and neuropsychological evidence that could support different theories is reviewed; finally, criticisms of embodiment are discussed. We conclude that strongly embodied and completely disembodied theories are not supported, and that the remaining theories agree that semantic representation involves some form of Convergence Zones (Damasio, 1989) and the activation of modal content. For the future, research must carefully define the boundaries of semantic processing and tackle the representation of abstract entities and elements in language.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6927.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6927.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fully symbolic / Amodal</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fully symbolic (Amodal) theories of semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classic symbolic theories in which conceptual meanings are represented as amodal symbols or propositional structures, independent of sensory-motor systems; semantics is organized by abstract relations rather than modality-specific content.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Fully symbolic / Amodal representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is stored as modality-invariant symbols or propositional structures (e.g., lemmas, vectors in LSA) that are processed by symbolic cognitive architecture; sensory/motor inputs are transduced into and out of this amodal format.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains arbitrary referential mapping, context-independent reference, symbolic composition; accounts for semantic relations via abstract associations or vector similarity (e.g., LSA); predicts semantic processing independent of sensory-motor system integrity.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical argumentation and computational models (e.g., LSA) discussed alongside neuropsychological data</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>semantic priming, lexical decision, computational distributional modelling (LSA), lesion correlations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Distributional models (LSA) and symbolic frameworks can predict many lexical semantic phenomena; historically provided normative framework for semantic organization.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors argue extremes are unsupported: imaging and neurophysiological studies show early modality-specific activations (e.g., motor cortex ~200ms) and behavioral interactions with perception/action that symbolic-only accounts struggle to explain (see Hauk et al., van Elk et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Landauer & Dumais, 1997</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6927.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Secondary/Derived embodiment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Secondary (derived) embodiment / Amodal hub with modality links</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes core amodal semantic representations (e.g., in anterior temporal lobe) that are non-arbitrarily connected to modality-specific systems which can be activated but are not constitutive of core semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Where do you know what you know? The representation of semantic knowledge in the human brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Secondary/Derived embodiment (Amodal hub + modality links)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high-dimensional space / amodal hub with distributed links</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Semantic content is represented at an abstract, amodal level (a hub) which maps to distributed modality-specific stores; modality systems may be activated when concepts are instantiated but are not necessary for core meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for cross-modal generalization, stable conceptual knowledge despite sensory loss, explains semantic dementia deficits via hub damage; predicts modest or no impairment from sensory/motor disruption.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>lesion studies (semantic dementia), rTMS, fMRI signal considerations</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>semantic tasks in SD patients, rTMS to anterior temporal lobes, fMRI semantic tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Semantic dementia correlated with anterior temporal lobe (ATL) atrophy; rTMS on ATL disrupts comprehension of concrete and abstract words (Pobric et al., 2009), supporting an amodal hub role.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Modality-specific activations in association and premotor areas and early modality-specific neurophysiological responses suggest modality content plays a role; signal dropout in ATL fMRI complicates interpretation; ATL may specialize for some domains (unique entities, social knowledge).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Patterson et al., 2007 (2008 review cited in text)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6927.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Weak embodiment / Convergence Zones (multimodal)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Weak embodiment — convergence zones and modality-proximal representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes that conceptual representations are partly constituted by modality-related information stored in higher-order multimodal zones adjacent to primary sensory-motor cortex (feature conjunctions rather than primary re-enactment).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Weak embodiment (convergence zones / multimodal proximal representations)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / feature-based multimodal convergence</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts arise from patterns of feature conjunctions in multimodal convergence zones that are anatomically proximal to modality-specific cortex; modality content is representational but abstracted (not raw primary cortex activity).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains modality-specificity of conceptual deficits, anterior shift (activation anterior to primary cortices), graded modality involvement, predicts activation in association cortices (not necessarily primary) across semantic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI studies showing anterior/proximal activations, EEG/MEG timing (motor activation ~200ms), patient lesion correlations, computational models (Plaut; Vigliocco FUSS)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>fMRI semantic contrasts (e.g., tool vs animal), EEG/MEG lexical tasks, semantic judgement and naming tasks, patient lesion-deficit mapping</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Imaging shows modality-proximal anterior activations (anterior shift) rather than strict overlap with primary perceptual areas; early motor-related EEG/MEG activity (~160–250ms) consistent with modality recruitment during lexical-semantic access.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Some findings of primary motor/visual cortex activation (esp. during imagery or deeper processing) and variability across tasks/individuals complicate a single weak embodiment account; discriminating representational vs. post-lexical imagery remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Damasio, 1989; Simmons & Barsalou, 2003; Vigliocco et al., 2004</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6927.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Strong embodiment / Full simulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Strong embodiment / Full simulation theories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Argue that conceptual processing routinely involves reenactment in primary sensory/motor cortices — semantic representation is essentially isomorphic with sensory-motor processing (full simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The brain's concepts: The role of the sensory-motor system in conceptual knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Strong embodiment (full simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented by reactivation of the same low-level sensory and motor neural substrates used in perception and action (i.e., semantics 'lives' in primary sensorimotor cortices).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for action-language interactions, predicts effector-specific primary motor activation during word comprehension, implies sensory/motor damage should produce severe, content-specific semantic deficits.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI, EEG/MEG timing studies, TMS disruption studies, behavioral action-language interactions</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>lexical decision, masked priming, fMRI action-word contrasts, TMS to motor cortex, EEG/MEG action-sentence tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Findings include motor/premotor activations during action-word processing and early motor EEG signatures (~160–250ms); TMS to motor areas can modulate action-word processing (Pulvermüller et al., 2005).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors conclude strong embodiment is not well supported outside imagery: (a) patient data rarely show severe category-selective loss tied to primary-sensorimotor damage; (b) many activations are anterior to primary cortices (anterior shift); (c) primary cortex activations often occur during explicit imagery or deeper processing, not routine lexico-semantic access.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Gallese & Lakoff, 2005; Glenberg & Kaschak, 2003; Pulvermüller, 1999/2001</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6927.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perceptual Symbol Systems (PcSS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual Symbol Systems (PcSS) — Barsalou</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulation-based account where conceptual representations are stored as distributed partial perceptual traces (perceptual symbols) reactivated during cognition; simulations are schematic subsets of perceptual states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language and simulation in conceptual processing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Perceptual Symbol Systems (PcSS)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / distributed perceptual traces</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are encoded as ensembles of modality-grounded 'perceptual symbols' (selected subsets of neurons active during perception) which are reactivated (simulated) during conceptual processing; simulations vary with context and are schematic.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains context-dependent conceptualization, grounded meaning for concrete concepts, supports simulation during comprehension and conceptual combination, predicts modality-specific activations that can be partial/schematic.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral property-generation studies, fMRI, EEG/MEG, conceptual combination experiments cited</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>property generation, conceptual combination tasks, fMRI semantic tasks, lexical decision</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Behavioral and imaging data show retrieval of perceptual properties and location-specific activations consistent with partial reactivation; PcSS can account for graded, context-dependent simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note PcSS spans weak-to-strong claims; issues remain about whether simulations use primary cortex routinely and how PcSS accounts for abstract words; some modality activations might be epiphenomenal or driven by spreading activation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barsalou, 1999 (discussed, Barsalou et al., 2009 chapter cited)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6927.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Damasio Convergence Zones (CZ)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convergence Zones framework (Damasio)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conceptual representation arises from multi-regional convergence zones that bind distributed modality-specific traces into coherent representations and can re-instate lower-level patterns when needed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Convergence Zones (CZ)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>convergence / multimodal hub-and-spoke</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Higher-order cortical convergence zones store associations among modality-specific representations and can orchestrate reactivation of distributed sensory-motor traces to reconstruct conceptual content; representation depends on networks of zones.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains binding of features across modalities, graded abstraction along cortical gradients, predicts distributed multimodal activation during retrieval and a role for anterior/association cortices.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>neurophysiological data, fMRI anterior shift observations, lesion mapping</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>recognition vs perception contrasts, semantic retrieval tasks, lesion-behavior correlations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Neuroimaging and patient studies show multimodal association regions and anterior shifts consistent with higher-order convergence zones that code conjunctions/abstracted features rather than raw primary input.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Debate persists whether convergence zones themselves store representational content or merely orchestrate reinstatement in lower zones (Simmons & Barsalou argue higher CZs can be stand-alone representations).</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Damasio, 1989; Damasio & Damasio, 1994</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6927.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hebbian assemblies (Pulvermüller)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hebbian cell assemblies for word meaning (Pulvermüller)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neurally inspired model where distributed neuronal assemblies linking word-form areas to sensory-motor circuits emerge via Hebbian learning and constitute the neural basis of word meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Words in the brain's language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Hebbian cell assemblies for semantics</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed assembly / Hebbian associative network</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Coactivation of word-form representations with sensory-motor circuits during learning leads to distributed assemblies across cortical areas; reactivation of an assembly constitutes concept access and is defined spatio-temporally.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains distributed, effector-specific activations for action words, rapid coactivation dynamics, and learning-dependent plasticity; predicts dependency on parts of the assembly for representation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>EEG/MEG timing studies, TMS disruption, fMRI coactivation studies, patient data</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>lexical decision, TMS to motor cortex during language tasks, EEG/MEG action-word studies</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Early motor cortex involvement and TMS studies showing interactions between motor cortex and action-word processing are consistent with assembly activation; however authors of review argue full dependence on primary motor cortex is not supported.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Review argues that if representation required intact primary sensory/motor nodes, lesions should produce catastrophic content-specific semantic loss — such clear-cut patient evidence is lacking; many activations are anterior/proximal rather than primary.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Pulvermüller, 1999; Pulvermüller et al., 2001; Pulvermüller et al., 2005</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6927.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Latent Semantic Analysis (LSA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Latent Semantic Analysis (LSA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distributional (high-dimensional vector) model where word meaning is derived from statistical patterns of word co-occurrence in large text corpora, representing semantics as vectors in a latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Latent Semantic Analysis (distributional semantics)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector / high-dimensional distributional space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is encoded as points/vectors in a high-dimensional space learned from distributional statistics of language; similarity and semantic relations are derived from vector proximity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains many lexical-semantic phenomena including similarity, priming, acquisition patterns from language exposure; predicts semantic behavior can be modeled by co-occurrence statistics without modality grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation, behavioral correlation with human judgments, modeling</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>computational modeling, semantic similarity prediction, correlation with human data</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>LSA captures a wide range of semantic relationships and can predict some behavioral measures; authors argue pure distributional models fail to account for modality effects and grounding phenomena evident in neuroscience.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Neurophysiological and imaging evidence for early modality-specific activations and modality-dependent effects (e.g., motor cortex signatures for action words) suggest distributional-only accounts are insufficient to fully explain brain instantiation of semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Landauer & Dumais, 1997</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6927.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feature / Featural models (FUSS, McRae)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feature-based (featural) models; FUSS (Featural and Unitary Semantic Space)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as sets of attributes/features (visual, functional, motor, affective) whose pattern and combination determine similarity and category membership; FUSS emphasizes organization by feature type and binding into lexical representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Representing the meaning of object and action words: The featural and unitary semantic space hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Feature-based / Featural models (including FUSS)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector / distributed feature conjunction</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual representations consist of modality-specific and cross-modal features (color, shape, function, action) aggregated into higher-level representations; features can be weighted or combined to yield semantic similarity structure.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains typicality, category structure, patient double dissociations, and graded modality effects; can account for distributed category-specific impairments depending on feature reliance.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral feature-generation studies, computational models, lesion studies (category-specific deficits)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>feature listing/generation, semantic verification, category-specific naming tasks, computational simulations</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Feature-based models predict many semantic-similarity effects and patient patterns; FUSS proposes modality-type organization and a semantic level binding features into lexical items.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Pure feature lists leave open how modality features are neurally instantiated and how abstract words (with fewer perceptual features) are represented; need integration with distributional/affective information for abstract concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>McRae et al., 1997; Vigliocco et al., 2004</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6927.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Similarity-in-Topography (SIT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Similarity-in-Topography principle (Simmons & Barsalou)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Extends convergence zone ideas by proposing that cortical topography within convergence zones reflects featural similarity: neurons that conjoin similar features are spatially proximate, enabling structured multimodal representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The similarity-in-topography principle: Reconciling theories of conceptual deficits</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Similarity-in-Topography (SIT) principle</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>topographic feature-conjunction / embodied multimodal</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Within convergence zones, the spatial arrangement of neurons mirrors feature similarity so that neighboring units represent similar conjunctions of modality-specific attributes, supporting efficient retrieval and abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains graded and topographically-organized conceptual deficits, predicts that cortical proximity indexes feature similarity and underlies semantic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational/architectural argumentation, cognitive neuropsychology reconciliation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>neuropsychological patient patterns, theoretical modeling</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>SIT offers a mechanistic account reconciling modality-specific deficits with distributed representations by invoking cortical topography of feature conjunctions.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Direct empirical mapping of the proposed topographic similarity principle in human cortex is still limited; alternative explanations (unitary hub) also account for some patient data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Simmons & Barsalou, 2003</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6927.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Indexical hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Indexical hypothesis (Glenberg & Kaschak)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes that word meanings are indexed to objects/perceptual symbols and understanding involves deriving affordances (action possibilities) which link language to action planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The body's contribution to language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Indexical hypothesis (affordance-based grounding)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied / affordance-indexing</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Meaning is built by indexing linguistic forms to perceptual symbols or external objects; comprehension derives affordances (possible actions) from perceptual symbols, linking language to sensorimotor planning.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains action-language facilitation of motor planning and affordance effects, links sentence comprehension to potential actions in the environment.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral action-language interaction studies, embodied cognition experiments</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>sentence comprehension with action compatibility tasks, behavioral measures of action facilitation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Behavioral findings show language can prime or interact with motor planning/affordances; authors cite these as evidence that language links to action representations.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Neural data indicate that motor activation during comprehension may be graded, dependent on task depth or experience, and not always necessary for comprehension; this nuance complicates a blanket indexical account as sole mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Glenberg & Kaschak, 2003; Glenberg & Robertson, 2000</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6927.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6927.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Immersed Experiencer Framework (IEF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Immersed Experiencer Framework (Zwaan)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory of language comprehension proposing that comprehenders build situation models by simulating experiential content; comprehension recruits perceptual and motor representations according to context and depth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The immersed experiencer: toward an embodied theory of language comprehension</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Immersed Experiencer Framework (IEF)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / situation model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Understanding language involves simulation of described situations ('vicarious experience'), recruiting modality-specific representations to construct situation models; the degree of simulation depends on context and task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for narrative and sentence-level simulation effects, predicts recruitment of navigation, motor planning and perceptual systems during rich comprehension and imagery-like processing.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI narrative studies, behavioral reading-comprehension experiments, imagery studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>narrative reading with subsequent comprehension/judgement, fMRI of story reading, imagery tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Narrative comprehension activates hippocampal/parahippocampal (navigation) and premotor areas when texts describe navigation or object interaction; supports graded recruitment tied to depth of processing.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note that degree of primary cortex involvement varies with task depth (imagery vs routine lexico-semantic access), suggesting IEF captures higher-level processes but may overpredict routine lexical activation in primary areas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Zwaan, 2004; Zwaan, 2008</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Where do you know what you know? The representation of semantic knowledge in the human brain <em>(Rating: 2)</em></li>
                <li>The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones <em>(Rating: 2)</em></li>
                <li>Perceptual Symbol Systems (original statement, Barsalou 1999) <em>(Rating: 2)</em></li>
                <li>Words in the brain's language <em>(Rating: 2)</em></li>
                <li>The similarity-in-topography principle: Reconciling theories of conceptual deficits <em>(Rating: 2)</em></li>
                <li>Representing the meaning of object and action words: The featural and unitary semantic space hypothesis <em>(Rating: 2)</em></li>
                <li>A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge <em>(Rating: 1)</em></li>
                <li>The immersed experiencer: toward an embodied theory of language comprehension <em>(Rating: 1)</em></li>
                <li>The brain's concepts: The role of the sensory-motor system in conceptual knowledge (Gallese & Lakoff) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6927",
    "paper_id": "paper-12584984",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Fully symbolic / Amodal",
            "name_full": "Fully symbolic (Amodal) theories of semantic representation",
            "brief_description": "Classic symbolic theories in which conceptual meanings are represented as amodal symbols or propositional structures, independent of sensory-motor systems; semantics is organized by abstract relations rather than modality-specific content.",
            "citation_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge",
            "mention_or_use": "mention",
            "theory_name": "Fully symbolic / Amodal representation",
            "theory_type": "symbolic",
            "theory_description": "Conceptual knowledge is stored as modality-invariant symbols or propositional structures (e.g., lemmas, vectors in LSA) that are processed by symbolic cognitive architecture; sensory/motor inputs are transduced into and out of this amodal format.",
            "functional_claims": "Explains arbitrary referential mapping, context-independent reference, symbolic composition; accounts for semantic relations via abstract associations or vector similarity (e.g., LSA); predicts semantic processing independent of sensory-motor system integrity.",
            "evidence_source": "theoretical argumentation and computational models (e.g., LSA) discussed alongside neuropsychological data",
            "experimental_paradigm": "semantic priming, lexical decision, computational distributional modelling (LSA), lesion correlations",
            "key_result": "Distributional models (LSA) and symbolic frameworks can predict many lexical semantic phenomena; historically provided normative framework for semantic organization.",
            "supports_theory": false,
            "counter_evidence": "Authors argue extremes are unsupported: imaging and neurophysiological studies show early modality-specific activations (e.g., motor cortex ~200ms) and behavioral interactions with perception/action that symbolic-only accounts struggle to explain (see Hauk et al., van Elk et al.).",
            "citation": "Landauer & Dumais, 1997",
            "uuid": "e6927.0"
        },
        {
            "name_short": "Secondary/Derived embodiment",
            "name_full": "Secondary (derived) embodiment / Amodal hub with modality links",
            "brief_description": "Proposes core amodal semantic representations (e.g., in anterior temporal lobe) that are non-arbitrarily connected to modality-specific systems which can be activated but are not constitutive of core semantics.",
            "citation_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "mention_or_use": "mention",
            "theory_name": "Secondary/Derived embodiment (Amodal hub + modality links)",
            "theory_type": "high-dimensional space / amodal hub with distributed links",
            "theory_description": "Semantic content is represented at an abstract, amodal level (a hub) which maps to distributed modality-specific stores; modality systems may be activated when concepts are instantiated but are not necessary for core meaning.",
            "functional_claims": "Accounts for cross-modal generalization, stable conceptual knowledge despite sensory loss, explains semantic dementia deficits via hub damage; predicts modest or no impairment from sensory/motor disruption.",
            "evidence_source": "lesion studies (semantic dementia), rTMS, fMRI signal considerations",
            "experimental_paradigm": "semantic tasks in SD patients, rTMS to anterior temporal lobes, fMRI semantic tasks",
            "key_result": "Semantic dementia correlated with anterior temporal lobe (ATL) atrophy; rTMS on ATL disrupts comprehension of concrete and abstract words (Pobric et al., 2009), supporting an amodal hub role.",
            "supports_theory": true,
            "counter_evidence": "Modality-specific activations in association and premotor areas and early modality-specific neurophysiological responses suggest modality content plays a role; signal dropout in ATL fMRI complicates interpretation; ATL may specialize for some domains (unique entities, social knowledge).",
            "citation": "Patterson et al., 2007 (2008 review cited in text)",
            "uuid": "e6927.1"
        },
        {
            "name_short": "Weak embodiment / Convergence Zones (multimodal)",
            "name_full": "Weak embodiment — convergence zones and modality-proximal representations",
            "brief_description": "Proposes that conceptual representations are partly constituted by modality-related information stored in higher-order multimodal zones adjacent to primary sensory-motor cortex (feature conjunctions rather than primary re-enactment).",
            "citation_title": "The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones",
            "mention_or_use": "mention",
            "theory_name": "Weak embodiment (convergence zones / multimodal proximal representations)",
            "theory_type": "embodied simulation / feature-based multimodal convergence",
            "theory_description": "Concepts arise from patterns of feature conjunctions in multimodal convergence zones that are anatomically proximal to modality-specific cortex; modality content is representational but abstracted (not raw primary cortex activity).",
            "functional_claims": "Explains modality-specificity of conceptual deficits, anterior shift (activation anterior to primary cortices), graded modality involvement, predicts activation in association cortices (not necessarily primary) across semantic tasks.",
            "evidence_source": "fMRI studies showing anterior/proximal activations, EEG/MEG timing (motor activation ~200ms), patient lesion correlations, computational models (Plaut; Vigliocco FUSS)",
            "experimental_paradigm": "fMRI semantic contrasts (e.g., tool vs animal), EEG/MEG lexical tasks, semantic judgement and naming tasks, patient lesion-deficit mapping",
            "key_result": "Imaging shows modality-proximal anterior activations (anterior shift) rather than strict overlap with primary perceptual areas; early motor-related EEG/MEG activity (~160–250ms) consistent with modality recruitment during lexical-semantic access.",
            "supports_theory": true,
            "counter_evidence": "Some findings of primary motor/visual cortex activation (esp. during imagery or deeper processing) and variability across tasks/individuals complicate a single weak embodiment account; discriminating representational vs. post-lexical imagery remains challenging.",
            "citation": "Damasio, 1989; Simmons & Barsalou, 2003; Vigliocco et al., 2004",
            "uuid": "e6927.2"
        },
        {
            "name_short": "Strong embodiment / Full simulation",
            "name_full": "Strong embodiment / Full simulation theories",
            "brief_description": "Argue that conceptual processing routinely involves reenactment in primary sensory/motor cortices — semantic representation is essentially isomorphic with sensory-motor processing (full simulation).",
            "citation_title": "The brain's concepts: The role of the sensory-motor system in conceptual knowledge",
            "mention_or_use": "mention",
            "theory_name": "Strong embodiment (full simulation)",
            "theory_type": "embodied simulation",
            "theory_description": "Concepts are represented by reactivation of the same low-level sensory and motor neural substrates used in perception and action (i.e., semantics 'lives' in primary sensorimotor cortices).",
            "functional_claims": "Accounts for action-language interactions, predicts effector-specific primary motor activation during word comprehension, implies sensory/motor damage should produce severe, content-specific semantic deficits.",
            "evidence_source": "fMRI, EEG/MEG timing studies, TMS disruption studies, behavioral action-language interactions",
            "experimental_paradigm": "lexical decision, masked priming, fMRI action-word contrasts, TMS to motor cortex, EEG/MEG action-sentence tasks",
            "key_result": "Findings include motor/premotor activations during action-word processing and early motor EEG signatures (~160–250ms); TMS to motor areas can modulate action-word processing (Pulvermüller et al., 2005).",
            "supports_theory": false,
            "counter_evidence": "Authors conclude strong embodiment is not well supported outside imagery: (a) patient data rarely show severe category-selective loss tied to primary-sensorimotor damage; (b) many activations are anterior to primary cortices (anterior shift); (c) primary cortex activations often occur during explicit imagery or deeper processing, not routine lexico-semantic access.",
            "citation": "Gallese & Lakoff, 2005; Glenberg & Kaschak, 2003; Pulvermüller, 1999/2001",
            "uuid": "e6927.3"
        },
        {
            "name_short": "Perceptual Symbol Systems (PcSS)",
            "name_full": "Perceptual Symbol Systems (PcSS) — Barsalou",
            "brief_description": "A simulation-based account where conceptual representations are stored as distributed partial perceptual traces (perceptual symbols) reactivated during cognition; simulations are schematic subsets of perceptual states.",
            "citation_title": "Language and simulation in conceptual processing",
            "mention_or_use": "mention",
            "theory_name": "Perceptual Symbol Systems (PcSS)",
            "theory_type": "embodied simulation / distributed perceptual traces",
            "theory_description": "Concepts are encoded as ensembles of modality-grounded 'perceptual symbols' (selected subsets of neurons active during perception) which are reactivated (simulated) during conceptual processing; simulations vary with context and are schematic.",
            "functional_claims": "Explains context-dependent conceptualization, grounded meaning for concrete concepts, supports simulation during comprehension and conceptual combination, predicts modality-specific activations that can be partial/schematic.",
            "evidence_source": "behavioral property-generation studies, fMRI, EEG/MEG, conceptual combination experiments cited",
            "experimental_paradigm": "property generation, conceptual combination tasks, fMRI semantic tasks, lexical decision",
            "key_result": "Behavioral and imaging data show retrieval of perceptual properties and location-specific activations consistent with partial reactivation; PcSS can account for graded, context-dependent simulation.",
            "supports_theory": true,
            "counter_evidence": "Authors note PcSS spans weak-to-strong claims; issues remain about whether simulations use primary cortex routinely and how PcSS accounts for abstract words; some modality activations might be epiphenomenal or driven by spreading activation.",
            "citation": "Barsalou, 1999 (discussed, Barsalou et al., 2009 chapter cited)",
            "uuid": "e6927.4"
        },
        {
            "name_short": "Damasio Convergence Zones (CZ)",
            "name_full": "Convergence Zones framework (Damasio)",
            "brief_description": "Conceptual representation arises from multi-regional convergence zones that bind distributed modality-specific traces into coherent representations and can re-instate lower-level patterns when needed.",
            "citation_title": "The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones",
            "mention_or_use": "mention",
            "theory_name": "Convergence Zones (CZ)",
            "theory_type": "convergence / multimodal hub-and-spoke",
            "theory_description": "Higher-order cortical convergence zones store associations among modality-specific representations and can orchestrate reactivation of distributed sensory-motor traces to reconstruct conceptual content; representation depends on networks of zones.",
            "functional_claims": "Explains binding of features across modalities, graded abstraction along cortical gradients, predicts distributed multimodal activation during retrieval and a role for anterior/association cortices.",
            "evidence_source": "neurophysiological data, fMRI anterior shift observations, lesion mapping",
            "experimental_paradigm": "recognition vs perception contrasts, semantic retrieval tasks, lesion-behavior correlations",
            "key_result": "Neuroimaging and patient studies show multimodal association regions and anterior shifts consistent with higher-order convergence zones that code conjunctions/abstracted features rather than raw primary input.",
            "supports_theory": true,
            "counter_evidence": "Debate persists whether convergence zones themselves store representational content or merely orchestrate reinstatement in lower zones (Simmons & Barsalou argue higher CZs can be stand-alone representations).",
            "citation": "Damasio, 1989; Damasio & Damasio, 1994",
            "uuid": "e6927.5"
        },
        {
            "name_short": "Hebbian assemblies (Pulvermüller)",
            "name_full": "Hebbian cell assemblies for word meaning (Pulvermüller)",
            "brief_description": "Neurally inspired model where distributed neuronal assemblies linking word-form areas to sensory-motor circuits emerge via Hebbian learning and constitute the neural basis of word meaning.",
            "citation_title": "Words in the brain's language",
            "mention_or_use": "mention",
            "theory_name": "Hebbian cell assemblies for semantics",
            "theory_type": "distributed assembly / Hebbian associative network",
            "theory_description": "Coactivation of word-form representations with sensory-motor circuits during learning leads to distributed assemblies across cortical areas; reactivation of an assembly constitutes concept access and is defined spatio-temporally.",
            "functional_claims": "Explains distributed, effector-specific activations for action words, rapid coactivation dynamics, and learning-dependent plasticity; predicts dependency on parts of the assembly for representation.",
            "evidence_source": "EEG/MEG timing studies, TMS disruption, fMRI coactivation studies, patient data",
            "experimental_paradigm": "lexical decision, TMS to motor cortex during language tasks, EEG/MEG action-word studies",
            "key_result": "Early motor cortex involvement and TMS studies showing interactions between motor cortex and action-word processing are consistent with assembly activation; however authors of review argue full dependence on primary motor cortex is not supported.",
            "supports_theory": false,
            "counter_evidence": "Review argues that if representation required intact primary sensory/motor nodes, lesions should produce catastrophic content-specific semantic loss — such clear-cut patient evidence is lacking; many activations are anterior/proximal rather than primary.",
            "citation": "Pulvermüller, 1999; Pulvermüller et al., 2001; Pulvermüller et al., 2005",
            "uuid": "e6927.6"
        },
        {
            "name_short": "Latent Semantic Analysis (LSA)",
            "name_full": "Latent Semantic Analysis (LSA)",
            "brief_description": "A distributional (high-dimensional vector) model where word meaning is derived from statistical patterns of word co-occurrence in large text corpora, representing semantics as vectors in a latent space.",
            "citation_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge",
            "mention_or_use": "mention",
            "theory_name": "Latent Semantic Analysis (distributional semantics)",
            "theory_type": "feature-based vector / high-dimensional distributional space",
            "theory_description": "Conceptual knowledge is encoded as points/vectors in a high-dimensional space learned from distributional statistics of language; similarity and semantic relations are derived from vector proximity.",
            "functional_claims": "Explains many lexical-semantic phenomena including similarity, priming, acquisition patterns from language exposure; predicts semantic behavior can be modeled by co-occurrence statistics without modality grounding.",
            "evidence_source": "computational simulation, behavioral correlation with human judgments, modeling",
            "experimental_paradigm": "computational modeling, semantic similarity prediction, correlation with human data",
            "key_result": "LSA captures a wide range of semantic relationships and can predict some behavioral measures; authors argue pure distributional models fail to account for modality effects and grounding phenomena evident in neuroscience.",
            "supports_theory": false,
            "counter_evidence": "Neurophysiological and imaging evidence for early modality-specific activations and modality-dependent effects (e.g., motor cortex signatures for action words) suggest distributional-only accounts are insufficient to fully explain brain instantiation of semantics.",
            "citation": "Landauer & Dumais, 1997",
            "uuid": "e6927.7"
        },
        {
            "name_short": "Feature / Featural models (FUSS, McRae)",
            "name_full": "Feature-based (featural) models; FUSS (Featural and Unitary Semantic Space)",
            "brief_description": "Concepts are represented as sets of attributes/features (visual, functional, motor, affective) whose pattern and combination determine similarity and category membership; FUSS emphasizes organization by feature type and binding into lexical representations.",
            "citation_title": "Representing the meaning of object and action words: The featural and unitary semantic space hypothesis",
            "mention_or_use": "mention",
            "theory_name": "Feature-based / Featural models (including FUSS)",
            "theory_type": "feature-based vector / distributed feature conjunction",
            "theory_description": "Conceptual representations consist of modality-specific and cross-modal features (color, shape, function, action) aggregated into higher-level representations; features can be weighted or combined to yield semantic similarity structure.",
            "functional_claims": "Explains typicality, category structure, patient double dissociations, and graded modality effects; can account for distributed category-specific impairments depending on feature reliance.",
            "evidence_source": "behavioral feature-generation studies, computational models, lesion studies (category-specific deficits)",
            "experimental_paradigm": "feature listing/generation, semantic verification, category-specific naming tasks, computational simulations",
            "key_result": "Feature-based models predict many semantic-similarity effects and patient patterns; FUSS proposes modality-type organization and a semantic level binding features into lexical items.",
            "supports_theory": true,
            "counter_evidence": "Pure feature lists leave open how modality features are neurally instantiated and how abstract words (with fewer perceptual features) are represented; need integration with distributional/affective information for abstract concepts.",
            "citation": "McRae et al., 1997; Vigliocco et al., 2004",
            "uuid": "e6927.8"
        },
        {
            "name_short": "Similarity-in-Topography (SIT)",
            "name_full": "Similarity-in-Topography principle (Simmons & Barsalou)",
            "brief_description": "Extends convergence zone ideas by proposing that cortical topography within convergence zones reflects featural similarity: neurons that conjoin similar features are spatially proximate, enabling structured multimodal representations.",
            "citation_title": "The similarity-in-topography principle: Reconciling theories of conceptual deficits",
            "mention_or_use": "mention",
            "theory_name": "Similarity-in-Topography (SIT) principle",
            "theory_type": "topographic feature-conjunction / embodied multimodal",
            "theory_description": "Within convergence zones, the spatial arrangement of neurons mirrors feature similarity so that neighboring units represent similar conjunctions of modality-specific attributes, supporting efficient retrieval and abstraction.",
            "functional_claims": "Explains graded and topographically-organized conceptual deficits, predicts that cortical proximity indexes feature similarity and underlies semantic structure.",
            "evidence_source": "computational/architectural argumentation, cognitive neuropsychology reconciliation",
            "experimental_paradigm": "neuropsychological patient patterns, theoretical modeling",
            "key_result": "SIT offers a mechanistic account reconciling modality-specific deficits with distributed representations by invoking cortical topography of feature conjunctions.",
            "supports_theory": true,
            "counter_evidence": "Direct empirical mapping of the proposed topographic similarity principle in human cortex is still limited; alternative explanations (unitary hub) also account for some patient data.",
            "citation": "Simmons & Barsalou, 2003",
            "uuid": "e6927.9"
        },
        {
            "name_short": "Indexical hypothesis",
            "name_full": "Indexical hypothesis (Glenberg & Kaschak)",
            "brief_description": "Proposes that word meanings are indexed to objects/perceptual symbols and understanding involves deriving affordances (action possibilities) which link language to action planning.",
            "citation_title": "The body's contribution to language",
            "mention_or_use": "mention",
            "theory_name": "Indexical hypothesis (affordance-based grounding)",
            "theory_type": "embodied / affordance-indexing",
            "theory_description": "Meaning is built by indexing linguistic forms to perceptual symbols or external objects; comprehension derives affordances (possible actions) from perceptual symbols, linking language to sensorimotor planning.",
            "functional_claims": "Explains action-language facilitation of motor planning and affordance effects, links sentence comprehension to potential actions in the environment.",
            "evidence_source": "behavioral action-language interaction studies, embodied cognition experiments",
            "experimental_paradigm": "sentence comprehension with action compatibility tasks, behavioral measures of action facilitation",
            "key_result": "Behavioral findings show language can prime or interact with motor planning/affordances; authors cite these as evidence that language links to action representations.",
            "supports_theory": null,
            "counter_evidence": "Neural data indicate that motor activation during comprehension may be graded, dependent on task depth or experience, and not always necessary for comprehension; this nuance complicates a blanket indexical account as sole mechanism.",
            "citation": "Glenberg & Kaschak, 2003; Glenberg & Robertson, 2000",
            "uuid": "e6927.10"
        },
        {
            "name_short": "Immersed Experiencer Framework (IEF)",
            "name_full": "Immersed Experiencer Framework (Zwaan)",
            "brief_description": "A theory of language comprehension proposing that comprehenders build situation models by simulating experiential content; comprehension recruits perceptual and motor representations according to context and depth.",
            "citation_title": "The immersed experiencer: toward an embodied theory of language comprehension",
            "mention_or_use": "mention",
            "theory_name": "Immersed Experiencer Framework (IEF)",
            "theory_type": "embodied simulation / situation model",
            "theory_description": "Understanding language involves simulation of described situations ('vicarious experience'), recruiting modality-specific representations to construct situation models; the degree of simulation depends on context and task demands.",
            "functional_claims": "Accounts for narrative and sentence-level simulation effects, predicts recruitment of navigation, motor planning and perceptual systems during rich comprehension and imagery-like processing.",
            "evidence_source": "fMRI narrative studies, behavioral reading-comprehension experiments, imagery studies",
            "experimental_paradigm": "narrative reading with subsequent comprehension/judgement, fMRI of story reading, imagery tasks",
            "key_result": "Narrative comprehension activates hippocampal/parahippocampal (navigation) and premotor areas when texts describe navigation or object interaction; supports graded recruitment tied to depth of processing.",
            "supports_theory": true,
            "counter_evidence": "Authors note that degree of primary cortex involvement varies with task depth (imagery vs routine lexico-semantic access), suggesting IEF captures higher-level processes but may overpredict routine lexical activation in primary areas.",
            "citation": "Zwaan, 2004; Zwaan, 2008",
            "uuid": "e6927.11"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "rating": 2,
            "sanitized_title": "where_do_you_know_what_you_know_the_representation_of_semantic_knowledge_in_the_human_brain"
        },
        {
            "paper_title": "The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones",
            "rating": 2,
            "sanitized_title": "the_brain_binds_entities_and_events_by_multiregional_activation_from_convergence_zones"
        },
        {
            "paper_title": "Perceptual Symbol Systems (original statement, Barsalou 1999)",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems_original_statement_barsalou_1999"
        },
        {
            "paper_title": "Words in the brain's language",
            "rating": 2,
            "sanitized_title": "words_in_the_brains_language"
        },
        {
            "paper_title": "The similarity-in-topography principle: Reconciling theories of conceptual deficits",
            "rating": 2,
            "sanitized_title": "the_similarityintopography_principle_reconciling_theories_of_conceptual_deficits"
        },
        {
            "paper_title": "Representing the meaning of object and action words: The featural and unitary semantic space hypothesis",
            "rating": 2,
            "sanitized_title": "representing_the_meaning_of_object_and_action_words_the_featural_and_unitary_semantic_space_hypothesis"
        },
        {
            "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge",
            "rating": 1,
            "sanitized_title": "a_solution_to_platos_problem_the_latent_semantic_analysis_theory_of_acquisition_induction_and_representation_of_knowledge"
        },
        {
            "paper_title": "The immersed experiencer: toward an embodied theory of language comprehension",
            "rating": 1,
            "sanitized_title": "the_immersed_experiencer_toward_an_embodied_theory_of_language_comprehension"
        },
        {
            "paper_title": "The brain's concepts: The role of the sensory-motor system in conceptual knowledge (Gallese & Lakoff)",
            "rating": 1,
            "sanitized_title": "the_brains_concepts_the_role_of_the_sensorymotor_system_in_conceptual_knowledge_gallese_lakoff"
        }
    ],
    "cost": 0.020021,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Coming of age: a review of embodiment and the neuroscience of semantics Coming of age: a review of embodiment and the neuroscience of semantics</p>
<p>Lotte Meteyard 
Sara Rodriguez Cuadrado 
Bahador Bahrami 
Gabriella Vigliocco 
Coming of age: a review of embodiment and the neuroscience of semantics Coming of age: a review of embodiment and the neuroscience of semantics
10.1016/j.cortex.2010.11.002Article Accepted Version Meteyard, L., Rodriguez Cuadrado, S., Bahrami, B. and Vigliocco, G. (2012) Coming of age: a review of embodiment and the neuroscience of semantics. Cortex, 48 (7). pp. 788-804. ISSN 0010-9452 doi: https://doi.org/10.1016/j.cortex.2010.11.002 Available at It is advisable to refer to the publisher's version if you intend to cite from the work. See Guidance on citing . To link to this article DOI: http://dx. CentAUR Central Archive at the University of Reading Reading's research outputs online 1semanticconceptsmultiple semanticsembodimentrepresentation 2
Over the last decade, there has been an increasing body of work that explores whether sensory and motor information is a necessary part of semantic representation and processing. This is the embodiment hypothesis. This paper presents a theoretical review of this work that is intended to be useful for researchers in the neurosciences and neuropsychology. Beginning with a historical perspective, relevant theories are placed on a continuum from strongly embodied to completely unembodied representations. Predictions are derived and neuroscientific and neuropsychological evidence that could support different theories is reviewed; finally, criticisms of embodiment are discussed. We conclude that strongly embodied and completely disembodied theories are not supported, and that the remaining theories agree that semantic representation involves some form of Convergence Zones (Damasio, 1989)  and the activation of modal content. For the future, research must carefully define the boundaries of semantic processing and tackle the representation of abstract entities and elements in language.</p>
<p>Introduction</p>
<p>Cognitive embodiment -the hypothesis that cognitive processes of all kinds are rooted in perception and action -has been keenly taken up by numerous researchers in language and cognition. The last ten years has seen a growth in the number of theories within psycholinguistics and the neuroscience of language that have some element of embodiment. In this paper, we review theories that make some explicit statement about the presence (or absence) of sensory and motor information in single word meaning. This review is not intended to be exhaustive. We assume that there is some cognitive information that can be classified as the semantic representation of an individual word, and it is these representations that we are concerned with. Therefore, we include only those theories that make some explicit reference to the representation of word-meaning, either in the methodologies used in support of the theories (e.g. naming, modelling using verbal labels) or in the explication of the theory itself.</p>
<p>The theories will be placed on a continuum from strongly embodied 'full simulation' to un-embodied, 'fully symbolic' systems. This is intended as a position paper, and we will argue that the extreme ends of the continuum are without substantial support. We will discuss the evidence that is needed to support or refute the theories in the center of the continuum. The review also seeks to establish a clear link between theories in psycholinguistics and theories in neuroscience as they substantially overlap in their cognitive and neural predictions for semantic representation. We will begin by recapping the principle ideas that underpin embodied and non-embodied (classic) cognitive approaches; this serves to clarify how theoretical positions differ and where the battle lines are drawn.</p>
<p>3 Do symbols need bodies? A brief history.</p>
<p>Early cognitive science adopted a symbol processing approach. This was heavily influenced by predicate logic, propositional and computational formalisms (Fodor, 1983;Johnson-Laird, 1993;Simon, 1979;Pylyshyn, 1985) and computation was viewed as an incredibly powerful tool through which to study cognition (Johnson-Laird, 1993). The idea of cognition-as-symbol manipulation provided a means to precisely define and separate psychological processes. 'Cognitive symbols' designate external events and objects, but their nature as internal entities is the same no matter what they symbolize. This internal consistency allows processing to be determined by cognitive architecture (Newell &amp; Simon,p.29) rather than by what the symbols represent in the external world. The structure of the processor is more important than the content of symbols it manipulates; symbols don't change but processes that create, interpret and manipulate symbols do. Similarly, in computing, binary representation in the form of zeros and ones is able to represent whatever is required, but the real trick is in the processing that manipulates that binary code to do everything from emails to touching up photographs. In this framework, a theory of semantic representation needs to define how words (as symbols) are processed and related to one another, not how they are able to refer to things in the world and not what they are composed of (a symbol has no content, it is a designation).</p>
<p>Symbolic cognition can only be achieved if sensory and motor information is transformed into a qualitatively different format (Pylyshyn, 1985). This transformation is termed transduction, literally transforming from one information type (signal) into another (symbol) so that it can be manipulated by cognitive processes. It is not clear whether this transformation is reversible, i.e. once a cognitive symbol has been established, is the path of the transformation lost? The transformation separates the levels at which cognitive symbols are manipulated (a 4 symbol processing level) and at which transduction takes place (some prior 'representational' level) (ibid). Thus, how an internal representation does designate an external entity is sidelined in favour of defining higher order symbolic processes themselves. This is a non-trivial choice, since it allows theories of conceptual and semantic representation to provide symbolic labels for concepts and semantic units, without having to define exactly what it's meaningful content might be. However, the system must be semantically constrained: what the symbol means has an influence on processing (Pylyshyn, 1985). If it were not, we would constantly see "semantically deviant" behaviours (ibid, p.36), for example, '1 + 1 ' would produce the answer 'cheese'. Therefore, cognitive symbols must have consistent and singular reference; i.e. one semantic interpretation. This is unlike true symbolism in which a symbol 'X' can refer to 'cat', 'blue' or 'Wednesday'. Basic, primitive, cognitive symbols cannot take this form and there must be a causal link between cognitive functions and what is represented, otherwise any symbolic explanation is "gratuitous" (Pylyshyn, 1985, p.43). The thorny problem of how symbolic representations refer to things in the world was explicitly recognized (Fodor, 1987;Pylyshyn, 1985;Newell, 1980) but never explained within the symbolic framework.</p>
<p>Determining the organization of cognitive processes was more important than establishing its content.</p>
<p>It is the murky process of transduction that forms the crux of the argument against symbolic cognition, termed the 'symbol grounding problem' (Harnad, 1990;Vogt, 2002). This is best illustrated by the Chinese Room Argument (Searle, 1980), a thought experiment in which an English speaker in a closed room receives Chinese symbols through a hatch and returns other Chinese characters according to strict rules, without ever knowing the meaning of the character strings. If symbols are not causally linked to their referents (the person in the room does not know what the 5 symbols mean), internal manipulation of those symbols is never enough to establish meaning (the person will never know what messages are communicated).</p>
<p>Under the symbolic description, the mental world builds a model of the external world by transducing perceptual input (Clark, 1997). Under the embodied approach, there is only limited modeling of the external world and cognition is about real world action rather than symbolic representation (Clark, 1997;Varela, Thompson &amp; Rosch, 1991). Embodied approaches can be anti-representationalist, rejecting entirely the notion that cognition needs or uses representations of the outside world (Varela, Thompson &amp; Rosch, 1991). However, without the capacity for context independent representation and symbolism of some form, semantics is not possible. This is because semantics allows an arbitrary form (the sound of a word or a visual sign) to consistently refer to some entity or concept (it's meaning), whether or not that entity is present in the immediate environment (e.g. a cup of coffee), imaginary (e.g. a unicorn) or tangible (e.g. truth, beauty, liberty). This means that cognition must be able to (a) represent or at least refer things without them being present and (b) represent or refer to things that have never been tangibly experienced. Both the arbitrary relationship between a word-form and its meaning and the capacity for a lexical item to stand for a referent are essentially, philosophically, symbolic capacities. Therefore, we assume that embodied theories of semantics accept the proposal that if on-line cognition (e.g. drinking a cup of coffee) is intimately connected to perception and action, in order to maintain a coherent system off-line cognition should also be embodied (i.e. thinking about drinking a cup of coffee). In other words, off-line cognition will depend upon perceptual and motor systems. For example, the problem of designation can be partially solved by pushing the world inside the mind, what Jackendoff (2002) terms the 'mentalistic enterprise' (see Lakoff, 1987 andFrith, 2007, for a similar view). The mind constructs "cognitive 6 structures in response to inputs from the senses" (Jackendoff,p.299) which form the basis of conceptual representation. There is no longer a need to refer to things 'outside' the mind, because the world is constructed by the mind in response to experiential input -sensory and motor information. How can a system which is intimately tied to real-world action and dynamic, on-line, processes have stable representations? The answer may be through simulation:</p>
<p>"In general, the function of these sensory-motor resources is to run a simulation of some aspect of the physical world, as a means of representing information or drawing inferences." (Wilson, 2002, p.633).</p>
<p>On experiencing a thing, like a cup of coffee, we have various sensory (taste, smell, touch) and motor (drinking) experiences. When we hear the words "cup of coffee", embodiment states that we re-construct in some form that sensory and motor information. Embodiment focuses on the content of cognitive representations and from that derives organizational principles.</p>
<p>The environment has to be internalised somehow, but instead of transducing the signal into a symbolic format, the signal is recreated. This claim is the most relevant for our purposes, since it directly links to semantic representation and it translates into a simple statement:</p>
<p>The content of semantic representation is sensory and motor information.</p>
<p>Theories of Semantics</p>
<p>In line with symbol processing, early theories of semantic representation focused on how words are related to each-other; i.e., how the semantic system is organized (e.g. Quillian, 1968;Collins &amp; Loftus, 1975;Levelt, 1989). For example, lexical items might be holistic nodes in a connected network (Quillian, Collins &amp; Loftus, 1975), or emerge from a collection of features or attributes (Smith, Shoben &amp; Rips, 1974).</p>
<p>More recently, attributive features, such as "red", "sweet" and "round" for 'cherry', have provided the basis for semantic similarity and the grouping of lexical items (Farah &amp; McClelland, 1991;McRae, de Sa, Seidenberg, 1997;Tyler &amp; Moss, 2001;Jackendoff, 2002;Vigliocco, Vinson, Lewis &amp; Garrett, 2004;Rogers et al, 2004). As well as attributive features, statistics of co-occurance (distributive information) have also been put forward. This information links words which appear in the same contexts, like 'bank' appearing in the same paragraph as 'bonus', and words that appear together and are lexicaly associated like 'cat and mouse' (Landauer &amp; Dumais, 1997;Vigliocco et al, 2008;Simmons, Hamann et al, 2008).</p>
<p>For theories of semantics, the focus on the organisation has been successful.</p>
<p>Theories of semantics have proposed explanations for extant empirical findings from semantic priming or interference paradigms, and patterns of semantic impairments in neuropsychological studies. However, until recently it has meant that the question of semantic content, i.e. what is the 'stuff' of semantics, has been partly neglected.</p>
<p>It is no longer enough to propose that attributive features such as "red", "round" and "sweet" make up the semantic representation of the word 'cherry'; what is the nature of the feature "red"? The way this question is answered can be understood by placing theories on a continuum; this separates out what assumptions are made about the content of semantic representations. Degree of embodiment is used as 8 the primary classification, from symbolic/amodal to analogue/multimodal; producing four categories (see 'Label' on the continuum).</p>
<p>A number of other parameters parallel this classification and are important when considering what predictions the theories make. 'Relationship to sensory-motor systems' defines the degree of dependence or independence that semantic content has from sensory and motor information. 'Explanation of interactions' refers to how theories explain the now large body of evidence that shows interactions between the processing of semantic content and sensory-motor information. 'Neural implementation' defines how these theories would look in the brain (some make explicit neuroscientific predictions and others do not). Note that it is not simply a case of all-or-nothing embodiment. representation. Semantic information is truly symbolic and there is an arbitrary relationship between the format in which semantic information is represented when compared to the information to which it refers. As in the classic cognitive approach, the emphasis is on the organisation of the system. Semantic information is 9 completely independent from sensory and motor systems, so it predicts no impairments in semantic processing if sensory and motor systems are disrupted.</p>
<p>Any interactions between semantic content and sensory-motor systems are explained by an indirect route, for example, semantic information affects working memory processes which may then engage sensory and motor capacities. There is no direct route through which semantic information contacts sensory and motor information. Neurally, we might expect there to be no temporal or topographical overlap between areas that respond to semantic tasks and areas that respond to sensory and motor information.</p>
<p>For Levelt (1989), language must be propositional, i.e. symbolic, and the preverbal message initiates the activation of specific lexical items that are holistic, symbolic lexical representations (lemmas), which are selected from the lexicon. In Latent Semantic Analysis (LSA, Landauer &amp; Dumais, 1997) the meaning of a word is defined by its relation to other words, rather than by what it refers to. Thus the meaning of a word is defined as a set of abstracted symbols (vectors). This is similar to the early network models (Quillian, 1968;Collins &amp; Loftus, 1975) which define similarity as associations between individual items; LSA represents these associations as probabilities of co-occurrence in text.</p>
<p>Secondary embodiment</p>
<p>These theories propose that the format of semantic representations is amodal, i.e. modality invariant, but they do not go so far as to introduce a hard boundary between semantic representation and sensory and motor content. There is a nonarbitrary relationship between semantic representations and sensory-motor content. For Patterson, Rogers and colleagues this is because amodal semantic representations are derived from mappings across sensory and motor input. For</p>
<p>Mahon &amp; Carmazza it is because amodal conceptual representations are instantiated by retrieving sensory and motor information. For Quillian, it is because the properties that make up semantic content are likely to be taken from the same store that supports perception. In all cases, we can say that the semantic system is independent of but directly associated with sensory and motor information; thus we might expect some mild impairment when sensory and motor information is disrupted, but this would be minor in comparison to disruption of the amodal, abstract semantic system 'proper'. Note here the difficulty in quantitatively defining mild, moderate and severe disruption (see below for our attempt at doing this).</p>
<p>Interactions between semantics and sensory motor information are explained via the non-arbitrary, associative connections. The activity of modality specific systems that process sensory and motor information is altered by to the connections that mediate between semantic and sensory and motor information; thus interactions are explained by mediation. Neurally, there may be one location that serves as a semantic hub in combination with distributed sensory and motor locations (Rogers et al, 2004;Patterson et al, 2008). Patterson, Rogers andcolleagues (2004, 2007) propose that the anterior temporal lobes provide the location for a semantic system which maps between modalityspecific information from different domains -it is not clear whether this mapping is reciprocal or unilateral. As such it does not "code explicit semantic content" (Rogers et al,p.206) as it abstracts away from modality specific attributes. These attributes are represented in a widely distributed network of modality specific cortical regions, such as the motor and visual cortices. Mahon &amp; Caramazza (2008) propose that semantic content is 'grounded by interaction' with sensory and motor information.</p>
<p>Here, all concepts are represented at an abstract, amodal level not constituted by sensory and motor information, but when a specific instance of a concept is realised there follows the passive activation of specific sensory and motor information.</p>
<p>Therefore, the disruption of sensory and motor information results in "impoverished or 'isolated' concepts". Interactions are explained away by "spreading activation" from abstract representations to modality specific input, due to non-arbitrary connections (which must be reciprocal for spreading activation to occur) between semantic representations and the sensory and motor experiences they are derived from. At the least, this relegates activity in modality specific areas to being functionally inconsequential as it results from the 'bleeding' of activity from elsewhere. At best, spreading activation makes modality specific activity secondary to the essential amodal semantic information; with a functional role only when an amodal concept has been instantiated. We will return to this point later.</p>
<p>Weak embodiment</p>
<p>This group of theories propose that semantic representations are at least partly constituted by sensory-motor information. Any sensory or motor information that is activated when semantic processing takes place is contentfull, namely it has a representational role, rather than being accessed secondary to abstract information that is considered 'true' semantics (as above). One consequence of this is that a certain degree of abstraction takes place within that sensory and motor information itelf. Integration of features within and between modalities produces more holistic representations that we might expect to be neurally located adjacent to modality specific cortical areas which process the experience of the represented entities. This is most clearly spelled out in Simmons &amp; Barsalou (2003), but a similar idea is presented and modelled in Vigliocco et al (2004). As sensory and motor information has a representational role, there is a partial dependence on sensory and motor sytems, although not on primary cortical regions. Interaction effects between word processing and perception/action are explained by mediation of a stronger form.</p>
<p>Semantic processing involves areas adjacent to and reciprocally linked to primary sensory and motor areas. Activation of semantic content will be able to influence processing in primary areas, and vice versa, through those links. Interactions may be more or less potent depending on the strength, number and activity of the connections; and may be influenced by task demands (e.g. top-down influences from attention that strengthen the influence on primary sensory and motor processing, by making particular task stimuli more salient). Farah &amp; McClelland (1991) defined representations as patterns of activation across 'visual' and 'functional' input units. Visual inputs encode visual features, e.g. colour and shape, whereas functional inputs encoded 'use' information, e.g. that mice are kept as pets or that a broom is used to sweep. The content of semantic representation is cross-modal, with combinations of features from different modalities aggregated into semantic representations for particular entities (in this case objects). The Featural and Unitary Semantic Space hypothesis (FUSS, Vigliocco, Vinson, Lewis &amp; Garrett, 2004) assumes that conceptual structure is organized by feature type, such as those that are modality specific (visual, motor etc.). A separate semantic level is derived from conceptual structure as features are bound together into lexico-semantic representations; these supervene over the individual features that define them but they are at least partly grounded in sensory and motor representations. Simmons and Barsalou (2003) more explicitly extend Damasio's Convergance Zone theory (CZ) with the Similarity in Topography (SIT) principle. See Plaut (2002) for a similar computational approach that models semantic representations with "a graded degree of modality specificity" (p. 613, ibid) 13 that depend on their proximity to modality specific regions. Neurons in early sensory and motor cortices respond to modality specific features, and higher order 'convergance zones' in association cortices respond to patterns of these features for a particular input (e.g. the visual input from seeing a cat). For Damasio (1989), CZs do not perform a representational role, but act to re-instate patterns of activity in lower CZs when representation is required. Representation is therefore not possible without both higher and lower order CZs. Simmons &amp; Barsalou (2003) instead propose that patterns of activity in higher order CZs do act as stand-alone representations; so damage to lower CZs would not remove the capacity for representation. The additional SIT principle allows semantic structure to be derived from the cortical representation of sensory and motor information. Featural similarities are reproduced topographically such that "The spatial proximity of two neurons in a CZ reflects the similarity of the features they conjoin." (ibid, p.457).</p>
<p>There are then two theories which can be classified as both weak and/or strong embodiment, we note here that the predictions are not mutually exclusive: it depends where one draws the line at what is considered to be semantic processing.</p>
<p>It should be becoming clear that as we move from abstract/symbolic theories to strong versions of embodiment, the scope of what is considered semantic widens to include more and more sensory and motor processing, until we end up with 'full simulation' being necessary for semantics. Pulvermüller (1999) proposed a neurally motivated account of word meaning, grounded in Hebbian learning. Assemblies of neural populations in distinct cortical areas act together to achieve representation, producing distributed networks of coactivated regions. Activation is defined spatio-temporally across participating cortical regions. For semantics, the essential process is the association of areas relating to the word form with areas relating to the perceptions and actions to which the word 14 refers. Coactivated neurons "develop into a higher-order assembly" (p.260, 1999).</p>
<p>Areas within an assembly show stimulus specificity only if other areas of the assembly are intact (Pulvermüller, 2001), suggesting that the representations are not robust given damage in one part of the assembly -if true, the theory is strongly embodied as representation is dependent on sensory and motor information.</p>
<p>Using a nominal twist on the classically symbolic Physical Symbol Systems (Newell, 1980), the Perceptual Symbol Systems (PcSS) account is the most wide-ranging theory of how simulation might drive human cognition (Barsalou, 1999). Perceptual Symbols (PcS) are based in the sensory and motor neural systems that are active when a percept is experienced. Complete neural activations generated by perceiving a particular entity are not recreated, rather, attentionally selected elements of that activation are produced: "the symbol formation process selects and stores a subset of the active neurons in a perceptual state" (Barsalou, 1999, p.584). For lexical items, a simulation instantiates the word, varying according to the sentential context: "As comprehension proceeds, representations of individuals develop, as in the perception of a physical scene." (Barsalou, 1999, p.605). Therefore, on the one hand we have abstracted information (a subset of a perceptual state) that could be classed as weakly embodied and simulation during comprehension that could be classed as strongly embodied.</p>
<p>Strong embodiment</p>
<p>In strong embodiment, low level sensory and motor information is activated in primary cortical areas as part of routine semantic processing. This effectively pushes semantics out into primary cortical areas and makes it completely dependent on sensory and motor systems. Interactions are no longer explained by mediation, i.e. semantic information influencing early sensory and motor processing from 'the outside'. Instead, sensory and motor systems are directly modulated by semantic processing, since they are used to represent semantic content during 'simulation'.</p>
<p>Note that Zwaan (2004) and Glenberg and colleagues (2000;2003) are more directly concerned with narrative comprehension, which lends itself to the construction of situation models and fits intuitively with simulation. These theories all subscribe to what we will call 'full simulation': the re-creation of direct experience through the modulation of activity in primary sensory and motor areas. Semantics uses the same resources as sensory motor processing, and they are essentially isomorphic. Recall that both Pulvermüller (2001) and Barsalou (1999) are also compatible with strong embodiment.</p>
<p>One of the strongest formulations of embodied semantic representation comes from Gallese &amp; Lakoff (2005). This theory proposes a neural account of how embodied content underpins conceptual representation. The same neural substrates are used for perceiving/doing, imagining and linguistic understanding. The authors define functional clusters which perform multi-modal integration within a given modal area -rather than having cross-modal integration in association areas outside primary modal areas (as for CZs and weak embodiment). Functional clusters perform action simulations to achieve representation. Thus, representations are organized by the structure of sensory and motor systems and exhausted by them. Zwaan's (2004) Immersed Experiencer Framework (IEF) is a comprehensive theory of how embodied processes might work during language comprehension.</p>
<p>Comprehension involves the simulation of whatever the language describes, and this simulation necessarily recruits sensory and motor representations. The IEF offers a detailed account of the comprehension process, stressing the 'vicarious experience' 16 that is the product of comprehension. Perceptual and motor representations are necessary since comprehension is proposed to be the "reconstruction of an experience with its referent [that requires the] integration and sequencing of traces from actual experience cued by the linguistic input" (p.38).</p>
<p>The indexical hypothesis (Glenberg &amp; Robertson, 2000;Glenberg &amp; Kaschak, 2003) seeks to link language, and specifically semantics, to the preparation of action within the environment. The theory proposes that "the meaning of a situation to an individual consists of set of potential actions available to that individual in that situation" (Glenberg &amp; Kaschak, 2003, p.100), these are termed affordances. Words are Indexed to objects in the environment or to perceptual symbols (Barsalou, 1999), which stand for real world objects. Affordances are then derived from the perceptual symbols, which lend themselves easily to this since they simulate the situation described in the sentence, necessarily recruiting sensory and motor information in a context dependent way. A simulation of the situation is performed and this is how comprehension is possible. It is not completely clear whether these theories assume strong embodiment as the lexical level; it is interesting to note that strong embodiment appears more intuitive as soon as we move outside the lexicon, and towards mental models and imagery.</p>
<p>Summary</p>
<p>We have placed theories of semantic representation on a continuum from 'fully symbolic' to 'full simulation'. It is true that within the neuroscientific literaturesensory and motor cortices are routinely activated during semantic processing of concrete objects and actions but whether this constitutes a case for embodiment or not has not been explicitly debated (see below) (Martin, 2007;Patterson et al, 2008;Thompson-Schill, 2003). Alongside growing behavioural evidence of interactions between language and sensory and motor processes (see Meteyard &amp; Vigliocco, 2008), we feel it is reasonable to reject the extreme left of the continuum representing 'fully symbolic' semantics. Thus, in the remaining sections of the paper we focus on discussing secondary, weak and strong embodiment.</p>
<p>The controversy between symbolic vs. embodied views as discussed in cognitive science also encompasses the opposition between unitary vs. multiple semantic systems as discussed in cognitive neuroscience and neuropsychology. Since cognitive and psycholinguistic theory has taken on board embodied proposals, the theoretical debates can be joined to those in neuroscience. In neuroscience, unitary versus multiple semantic systems have been opposed. A unitary semantic system is one in which the same set of representations are used across all modalities of input and output, and supervene over different kinds of sensory and motor information (Caramazza, Hillis, Rapp, &amp; Romani, 1990;Lambon Ralph, Graham, Patterson, &amp; Hodges, 1999;Patterson et al, 2007;Plaut, 2002;Rapp, Hillis, &amp; Caramazza, 1993). This is similar to fully symbolic, or derived embodiment, as representations are essentially abstracted from a particular input or information type. The neural predictions are therefore similar to those for the left hand side of the continuum. For example, the anterior temporal regions orchestrate semantic representation by mapping across all modalities (Patterson et al, 2008;.</p>
<p>In contrast to this, multiple semantics states that several sub-systems are distributed across cortical regions, and organized by input modality, sensory and motor attributes or category relationships. A 'complete' representation would be defined across all of these sub-systems, and different parts might be more or less recruited depending on the task (e.g. shape judgment versus category judgment) (Paivio, 1971;1986;Warrington &amp; Shallice, 1984;Thompson-Schill et al, 2003;Martin, 2007). This is similar to weak embodiment as representations are located adjacent or close to the sensory and motor content from which they are derived.</p>
<p>The neural predictions are therefore similar and predict distributed, modality specific regions. For example, ventral temporal regions represent colour and form, left lateral temporal regions for motion and parietal regions for size (Thompson-Schill et al, 2003). Neuroscientific theories do not conform to strongly embodied ideas, some degree of abstraction from primary regions is assumed, and across all theories it is recognized that higher order conjunctions must be extracted for conceptual representation to begin (e.g. those that constitute shape, size or motion), and that this process of abstraction and feature conjunction is especially evident for objects in the ventral temporal stream (e.g. Barense et al, 2005).</p>
<p>Deciding between theories: hypotheses and evidence Secondary, weak and strong embodiment can be distinguished on the basis of imaging and patient data.</p>
<p>Imaging Data.</p>
<p>Strong embodiment predicts activation of primary sensory and motor cortices across all semantic tasks.</p>
<p>Strong embodiment proposes 'full simulation' -the re-enactment of sensory and motor activations (to a greater or lesser degree) produced during real experience.</p>
<p>Thus, these theories predict that primary sensory and motor cortices should be engaged during semantic processing, since these areas process the raw stuff of 19 experience. Neither weak nor secondary/derived embodiment theories subscribe to this prediction.</p>
<p>Weakly embodied theories specifically predict activation of areas anterior or adjacent to primary sensory and motor cortices across all semantic tasks for words with sensory and motor content. This shaprply contrasts with the predicitons of secondary embodiment according to which we should observe activation across all semantic tasks of cortical regions that (a) do not overlap with areas known to process sensory and motor information and (b) cannot be interpreted as performing other functions implicated in a task, as we shall discuss in more detail below.</p>
<p>Weak embodiment proposes that modality specific activations should be adjacent, or anterior to primary sensory or motor cortices that process real experience. This evidence goes against strong embodiment as it does not follow 'full simulation' (see above) and against secondary/derived embodiment as it implies a representational role for sensory and motor information. Semantic information could be reliant on association areas that integrate modal information and abstract away from 'raw' information processed in the primary sensory and motor cortices, rather than semantic processing directly requiring the primary cortices themselves.</p>
<p>Distinct modal information could be integrated within the modal areas themselves, rather than requiring a separate association area, as proposed by Damasio (1989) and expanded by Simmons &amp; Barsalou (2003, see also Kemmerer, 2009). For example, Gallese &amp; Lakoff (2005) cite evidence from monkey studies which show neurons in premotor areas selectively responding to motor, visual and somatosensory information for the purpose of controlling movements in peripersonal space. However, this does not preclude the possibility of separate (but proximal) 20 areas that perform feature conjunctions and cross-modal integration for the purposes of semantic representation.</p>
<p>An interesting phenomena that may shed some light on this is the 'anterior shift' noted by Thompson-Schill (2003) and explored alongside other cortical gradients (e.g. ventral-dorsal) by Chatterjee (2008Chatterjee ( , 2010. This is the finding that the areas activated by semantic processing are not iso-morphic to those used in direct experience, but are shifted anterior to those areas. For example, Martin, Wiggs et al (Nature, 1996) find that for animals versus tools, there are various areas close to, but not identical with, areas used in perception and action. Other examples can be found in Wallentin et al (2005) who found an area anterior to MT/V5 active for sentences that described actual and fictive motion (for a wider review see also Chatterjee, 2010) and Willems et al (2009Willems et al ( , 2010 who find activity in pre-motor, not primary motor, cortices for action understanding.</p>
<p>The anterior shift supports the proposals from weak embodiment that sensory motor information may be abstracted from direct experience, rather than a simulation of it.</p>
<p>The possibility of moving away from simulation as an explanatory mechanism is interesting, and it is also in line with findings from the neuroscience of conceptual processing. It does not require a move away from modality specific information, the central idea being that there is a move from simple features conjunctions, for example within one modality, to more complex conjunctions that could cross modalities (e.g. Acres, 2008;Damasio, 1989;Murray &amp; Bussey, 1999;Lerner et al, 2001) and represent more schematic and abstract information (Chatterjee, 2010).</p>
<p>Modality specific activations claimed by strong embodiment to be a 'simulation' may instead be the activation of feature conjunctions sufficient to represent a given object, or word. For example, Bar et al (2001) found that activity in the ventral stream was more anterior when participants recognised very briefly presented object pictures, as compared to percieving a shape without object recognition. If we progress down this route, attractive because of the converging evidence, it is questionable whether the simulation of real experience is necessary for semantic representation (see also work by Tyler and colleagues on object concepts, e.g. Tyler et al, 2004;Taylor, Stamatakis &amp; Tyler, 2009).</p>
<p>Patterson and colleagues (e.g., Patterson et al., 2008) put forward an anatomically defined theory that falls under secondary/derived embodiment. Their clear proposal is that the amodal semantic system is localized in anterior temporal areas. Such localization is inferred primarily on the basis of the anatomo-behavioural correlations observed in patients suffering from semantic dementia (SD, e.g. Jeffries, Patterson, Jones &amp; Lambon-Ralph, 2009). Until recently, functional imaging of the regions around the anterior temporal lobes (ATLs) has been hindered by signal drop out (e.g. Schwarzbauer et al, 2009;Devlin et al, 2000), but other techniques, such as repetitive Transcranial Magnetic Stimulation (rTMS) have produced converging evidence for the role of the ATLs in semantic processing for concrete and abstract words (Pobric, Lambon-Ralph &amp; Jeffries, 2009). However, the potentially diffuse damage in SD and changed activity in distal regions connected to the ATLs in rTMS, mean that the ATLs may not be the stand-alone region dedicated to semantic and conceptual representation; especially when considering evidence that implicates the ATLs in the representation of unique entities and social/affective knowledge (Simmons &amp; Martin, 2009).</p>
<p>To recap, secondary/derived embodiment states that the core of semantic representation is some abstract, amodal information. It is connected to sensory and motor information which may then be activated when particular concepts are instantiated or because activation spreads in a functionally unimportant way (Mahon 22 &amp; Caramazza, 2008). This means that 'true' semantic activation in the brain cannot overlap with sensory and motor cortices (see above). It also means that activations that appear across semantic tasks must be carefully teased apart to separate those areas that are active because they represent semantic information, and those areas that are active because they perform some task related control function, such as lexical selection. For example, Corbett, Jeffries, Ehsan and Lambon-Ralph (2009) argued that the performance of patients with semantic dementia (with damage to the anterior temporal lobes) reflects a central impairment of amodal semantic representations, whereas the performance of patients with semantic aphasic deficits following stroke (with damage to temporo-parietal and frontal regions) reflects damage to control processes. Control mechanisms might be those proposed by Schnur and colleagues (2009), who argue that Broca's area -a region routinely active in language tasks of all kinds -is involved in selecting amongst competing representations.</p>
<p>Related to these issues are the arguments that certain cortical regions, considered to process sensory or motor information, actually represent/process more abstract and potentially grammatical information. For example, Bedny et al (2008) argued that activations for verbs versus nouns in the posterior-lateral-temporal cortex reflected event concepts (i.e. an abstract category for verbs) rather than sensory information related to visual or motion attributes. The fact that activations around are MT for verbs appear to be proximal but not identical to those areas involved in motion processing is dealt with in more detail below (and see Chatterjee, 2010).</p>
<p>In sum, the imaging data can at present be taken to support either weak embodiment, with some form of distributed convergence zones that represent modality specific information and provide semantic content, or derived/secondary embodiment, with an independent region or region(s) that represent abstract, amodal information that is derived from sensory and motor regions.</p>
<p>Lexico-semantics, narrative and imagery</p>
<p>Two of the theories that we have classed as strongly embodied refer to sentential and narrative level processes (Glenberg &amp; Kaschak, 2003;Zwaan, 2004), it is possible that different amounts of sensory and motor information are recruited depending on the depth of semantic processing that is required for a task. One difficulty lies in defining what counts as semantic processing and what counts as deeper, or more 'explicit' processes. Even within language processing there are likely to be differences between single word, sentence and narrative comprehension (e.g. Zwaan, 2004). Evidence has been put forward that sensory and motor information is not accessed when judgments can be made on the basis of lexical associations alone (e.g. Simmons et al, 2008). However, evidence in support of strong and weak embodiment demonstrates the involvement of sensory and motor information at the single word level for passive comprehension tasks (e.g. Meteyard et al, 2008;Pulvermüller, Harle &amp; Hummel, 2001).</p>
<p>There is evidence that primary regions involved in perception are engaged during imagery tasks (e.g. Kossyln, Thompson, Kim &amp; Alpert, 2000). If we assume that narrative comprehension comes closer to conscious imagery than single word or sentence comprehension, it is not surprising to find evidence that areas involved in navigation (hippocampal and parahippocampal regions) and action planning (premotor regions) are engaged when reading a narrative that includes movement/navigation or interacting with objects respectively (Speer et al, 2009).</p>
<p>Such evidence does not allow us to distinguish between strong and weak 24 embodiment given that weak embodiment would predict activation of primary sensory and motor cortices only for tasks requiring the integration of semantic representations (e.g. resolving ambiguities, sentence comprehension, narrative).</p>
<p>It is plausible that primary areas are more engaged the closer semantic processing comes to mental imagery. Because of the thorny issue of where we draw the line between 'semantic representation' and other processes (such as building a situation model during narrative comprehension or generating conscious mental imagery), evidence of this type cannot unequivocally point to a strong version of embodiment. Kemmerer (2010) notes that there is a paucity of work that helps to separate semantic representations from those processed during actual perception and action, and those used during explicit imagery. Preliminary data that addresses this distinction finds dissociations between action verb understanding and motor imagery.</p>
<p>In strongly embodied views, simulation during semantic processing uses identical substrates to motor imagery (Gallese and Lakoff, 2005). Willems et al (2009Willems et al ( , 2010 posited that motor activations during semantic processing of motor verbs are preenactments (simulation of future actions), in order to facilitate future action planning. This is in line with the embodied view that comprehension of language links directly to action within in an environment (see also affordances, e.g. Glenberg &amp; Kaschak, 2003). In contrast, motor imagery is a more reflective process that involves covert enactment, requiring generation of an action plan and predictions about an action's sensory consequences. Willems et al (2009) compared neural activity during action verb processing (lexical decision) with explicit mental imagery of the same actions. Actions were either manual (e.g. 'grasp') or non-manual (e.g. 'giggle'). Results showed effector specific activation for both lexical decision and motor imagery in premotor areas, but activity in the primary motor cortex was only found for motor imagery. Willems et al (2009) emphasize that (in light of the data) 25 embodied semantics must distinguish semantic processing from explicit mental imagery (see also van Elk et al, 2010, described in more detail below). We fully support this conclusion. For those theories that subscribe to 'full simulation', there need to be clear statements about what counts as semantic processing and what distinguishes it from mental imagery and perception. Barsalou (1999) distinguishes representation from imagery and perception by making simulations schematic and unconscious, however, it is not clear whether this still counts as simulation, or whether we might now think of this as accessing more abstract, categorised modal information that is more in line with weak embodiment.</p>
<p>In all likelihood, the answer lies in looking at a continuum of processing 'depth' that depends on the task (e.g. lexical decision, sentence to picture comprehension, narrative and discourse understanding) rather than categorically delineating one process from another. Willems et al (2009Willems et al ( , 2010 conclude that imagery and lexico-semantic activation serve different functions and therefore rely on different neural substrates. Motor activation during semantic processing may serve predictive functions (in order to make communication effective) whereas explicit imagery may be reflective, occurring after a word has been at least partially understood. Understanding action words engages regions involved in motor planning. Imagery is reflective, and engages regions involved in motor planning as well as regions involved in motor execution.</p>
<p>This focus on the function of the two processes is welcome. For all tasks, we must ask -what purpose does it serve? It cannot be stated strongly enough the importance of understanding how a task taps the process of interest, and where the effect of interest might arise. Valid criticisms can be levelled at data taken to support embodiment because an interaction between conceptual/semantic and sensory-motor processing could arise from 'simulation', or from top-down effects on 26 attention and decision processes (Chatterjee, 2010;Mahon &amp; Caramazze, 2008;Meteyard et al, 2008). Similarly, in the imaging literature, careful consideration must be paid to (a) where activation occurs (see above re: the anterior shift); (b) what other activations occur -the presence of motor activations during the comprehension of motor language should not lead to other activations being sidelined as regards explanatory potential (Chatterjee, 2010); and (c) to what extent sensory-motor activation can be attributed to necessary &amp; sufficient 'simulation' rather than, for example, individual variation in experience (e.g. Beilock et al, 2008).</p>
<p>Individual Differences</p>
<p>An interesting but important aside comes from recent evidence that shows how individual differences shape the nature of motor activations seen during comprehension tasks. Willems et al (2010) explored how handedness influences motor activity during semantic processing of words referring to manual actions.</p>
<p>They found that right handers activated the left premotor cortex during lexical decisions on manual actions, and left handers the right premotor areas. These results show that the motor component of manual-action verb semantics is body specific, and therefore shaped by actions one has performed (egocentric motor activity). Similarly, Beilock et al (2008) and Lyons et al (2009) found that experienced players of ice-hockey showed greater activations in the left premotor cortex for sentence referring to hockey actions (e.g. "The hockey player held onto the puck") compared to non-hockey players, these differences were not present for everyday actions (e.g. "the individual closed the book"), for which both groups had similar levels of experience. In sum, personal experience is an important influence on the nature and degree of motor activation observed during comprehension. An 27 extension of this argument is that activation of one's own motor system may not be essential for comprehension (we wouldn't argue that non-hockey players couldn't understand the described hockey actions) but a lesser degree of motor activity might suffice.</p>
<p>Electrophysiology</p>
<p>Predictions thus far have focused on the topography of the brain, looking for activations in regions known to process modality specific (i.e. sensory and/or motor) information when participants complete linguistic tasks. These studies are open to the (valid) criticism of poor temporal resolution, such that activations represented by BOLD responses may reflect 'post-lexical' processing involved in mental imagery or strategic responses to the task (Toni et al, 2008). Whilst it is not straightforward to make specific temporal predictions from embodied theories, one hypothesis produced from both strong and weak embodiment (and explainable by secondary embodiment)</p>
<p>is that sensory and motor activity should occur early. More specifically, it should occur within the time-frame that we know lexico-semantic processing occurs, as opposed to, say, phonological processing. A recent paper has shed some light on the time-frames in question. Sahin et al (2009) took intra-cranial recordings in Broca's area during a word-production task (reading aloud, or producing a word within a sentence frame that demanded implicit or explicit inflection). They found distinct sequential peaks in activity that corresponded to lexical retrieval (200ms), syntactic/inflectional processes (320ms) and phonological changes to the word (450ms). From this study, we can say that the critical time period is therefore around 200ms post exposure to some target word. A review of neurophysiological studies (EEG, MEG and TMS) exploring the motor content of action words found that activation of the motor cortex is significant at around this time-frame (e.g. 200-28 250ms) (Hauk, Shtyrov &amp; Pulvermüller, 2008). In addition, effects are not dependent on whether attention is focused on the motoric/action content of the stimuli, strengthening the conclusion that the activity is a necessary part of lexicosemantic access (Hauk, Shtyrov &amp; Pulvermüller, 2008).</p>
<p>One recent study has begun to explore neurophysiological changes in some detail.</p>
<p>van Elk et al (2010) took EEG recordings whilst participants read action sentences and occasionally made judgements about whether a presented target word was related to the sentence they had just read. Critical sentences described animal actions (e.g. the deer jumps over the fence) or human actions (e.g. the athlete jumps over the hurdle) using the same verbs. To stay on topic, we will focus on the early changes only (note that additional changes were observed for beta-frequency bands and the N400, linking early motor activity to linguistic parameters such as the cloze probability of the sentence constituents). They found changes in the mufrequency band from 160-520ms after verb onset that was focused over frontal and central scalp regions (source analysis localised this activity to the pre-central gyrus); critically preceding the N400 component classically related to semantic integration processes. These early mu-frequency changes were stronger for verbs within an animal context as compared to a human context, not predicted by mental imagery accounts which might propose stronger activation for actions one is able to perform/imagine. In contrast, the authors argued that this increased activity reflected stronger activation of motor information in order to understand actions that the listener cannot perform. In addition, mu-frequency changes have previously been associated to action observation and execution, strengthening the argument that they reflected true motor activation during the comprehension of sentences describing actions (van Elk et al, 2010).</p>
<p>29</p>
<p>In sum, data from neurophysiological studies come out broadly in support of weak or strong embodiment, with early activation of motor regions. To the best of our knowledge, data is only available for motor activations. The study by van Elk et al (2010) begins to relate such motor activations to other parameters known to influence linguistic processing (e.g. cloze probabilities), and future studies would do well to do the same. For example, what is the relationship between the spatial and temporal signatures of motor activations and lexical parameters such as frequency, concreteness, and familiarity? Given that larger activations are seen for less frequent words (Sahin et al, 2009), will motor activations for action words that are lower in frequency also be greater, reflecting a relative increase in the difficulty of retrieval? As with some of the imaging studies cited so far, and the patient studies discussed below, the issue of appropriate control items is critical here. It is absolutely necessary to compare action verbs to non-action verbs, or verbs with different modal content (e.g. those referring to visual, haptic or auditory events).</p>
<p>Only then can modality specific activations be truly attributed to embodied content.</p>
<p>Patient Studies</p>
<p>In parallel of what we have done above concerning imaging studies, we list here the predictions of the different theories and discuss the available patients' evidence. Let us start by considering evidence from damage to sensory or motor systems. Strong embodiment predicts that deficits in sensory or motor systems will cause severe impairments (inability to complete the task, very high error rates) in processing words that refer to things with those sensory or motor attributes. Weak embodiment, instead, predicts that such impairments will not be severe but moderate (significantly more errors or longer reaction times). Finally, secondary/derived embodiment 30 predicts that deficits in sensory or motor systems will cause no impairments in processing words that refer to things with those sensory or motor attributes. Even allowing for some mild degree of impairment as a consequence of sensory and motor systems damage, this impairment will be significantly less than that seen when the semantic system 'proper' is damaged.</p>
<p>The crucial data to support strong embodiment would come from studies reporting patients impaired in processing content specific lexical items (e.g. words referring to motor actions, or specific visual events such as motion, colour or shape) alongside an impairment in processing that particular sensory or motor content (e.g. executing motor actions, perceiving/recognising motion, colour or shape). Crucially, the impairment must not extend to control words from other sensory-motor domains.</p>
<p>At present such data does not exist. Nonetheless there are studies that have attempted to address this question, unfortunately, not providing clear evidence. Mahon and Caramazza (2007) studied patients with Ideational Apraxia. Following Warrington (REF), these patient would be specifically impaired in their ability to recall previously well-established actions, such as those involved in object use. The argument has been made that the study of Apraxia is informative as it helps to test whether motor production processes are critical in the conceptual representation of objects and actions. Mahon and Caramazza asked their participants to use and recognize objects and to imitate and recognize pantomimes. They observed differing results at the group and single-case levels. Single cases were analysed separately as group level analyses could mask single case dissociations that differ with the group pattern.</p>
<p>At the group level (37 patients), positive correlations were found between object use and pantomime recognition, pantomime imitation and object recognition, thus 31 suggesting that the motor production processes engaged when using objects were also involved in recognizing those objects and their associated pantomimes (supporting embodiment). However, a variety of single-case disassociations were found in 19 out of the 37 patients. For example, patients presented with impaired object use as compared to object recognition, and selectively impaired pantomime and action imitation. From this, the authors concluded that motor production processes engaged when using objects were not necessary for recognizing actions and objects (supporting un-embodied or secondary/derived embodiment).it is however the case that this data is not clear-cut and one could argue that indeed Ideational Apraxia cannot be informative context of embodiment because it is a highlevel (hence, presumably engaging the semantic system) motor impairment. Liepmann (1905) stated that Ideational Apraxia manifests when the patient had to formulate an "idea" of the movement, conceptualising the necessary actions and action sequences. The deficit might be attributable to a disorder at the level of access to knowledge about object use, failure to access a central motor programme or damage to the central programme itself (Heilman and Rothi, 1985). The variability in the performance of the patients reported by Mahon and Caramazza (2007) likely reflected the ambiguity between patients whose deficit did involve motor representations and those whose deficit did not.</p>
<p>More revealing in deciding between strong, weak and secondary embodiment, in principle, could be studies of patient groups with direct damage to the motor system, such as Motor Neurone disease (MND), Fronto Temporal Dementia (FTP), Progressive Supra-nuclear Palsy (PSP) and Cortico-basal Degeneration (CBD). Motor Neurone Disease (MND) causes a variety of muscular problems, including weakness, wasting, fasciculations, dysphagia and dysarthria; it is associated with diffuse, mainly frontotemporal atrophy (Bak &amp; Hodges, 2001). Bak (2001) demonstrated that the 32 comprehension and production of verbs/actions was more impaired than that of nouns/objects, when compared to healthy individuals or those with Alzheimer's. Post mortem analyses showed pathological changes in areas 44 (Broca's area) and 45 for these patients, converging with other studies of verb/action processing (see Siri et al., 2008). Thus, although the presence of selective impairment for verbs/actions in these patients is consistent with strong and weak embodiment views; the anatomical data do not provide support for strong embodiment. It is the case, in fact, that the selective deficit can be easily accounted for in terms of differences in processing demands between nouns/objects and verbs/actions (Schnur et al., 2009;Vigliocco et al., 2006;Maetzig et al., 2009). primarily in frontal regions and the basal ganglia). Action naming impairments were observed in all of these pathologies with the exception of SD (in which atrophy is relatively confined to the anterior temporal regions), suggesting that damage to the frontoparietal-subcortical circuits involved in both action knowledge and representation leads to impairment in verb/action processing. These results support weak embodiment: damage to motor circuits leads to moderate impairment of action/verb processing. They do not provide evidence in favor of strong embodiment, according to which impairment should be of an 'all or nothing' style.</p>
<p>Cotelli et al (2006) investigated object and action naming in several subtypes of</p>
<p>33</p>
<p>In a similar vein, Boulenger et al (2007) found that priming effects for action verbs in a lexical decision task varied as a function of levodopa uptake for Parkinsons' Disease (PD) patients. During a masked priming task, where prime and target were identical except for letter case, PD patients showed greater priming for verbs when 'on' medication that increased dopamine uptake as compared to 'off' medication;</p>
<p>priming for concrete nouns did not differ according to medication phase (being strong in both cases). The authors concluded that the motor system impairment present in PD selectively affects action verbs, in line with claims from strong and weak embodiment that the semantic processing of action verbs involves the motor system. However, action verbs were compared to concrete nouns, rather than a set of matched 'non-action' verbs, confounding the effects with the broader noun versus verb distinction. No studies have explored motor verbs (e.g. pinch, kick, kiss, climb, eat) against other events (e.g. sleep, drop, read, spin, rise) in these patients. This comparison is critical to decide whether the greater impairment for actions/verbs than objects/nouns is truly semantic. Verbs are generally more abstract and more complex to process than nouns due to their semantic, syntactic and morphological characteristics (e.g. Schnur et al., 2009;Vigliocco et al., 2006;Maetzig et al., 2009).</p>
<p>Indeed, verb deficits in PD have been explained within this framework when exploring the role of the basal ganglia in language processing. In particular, the basal ganglia may be involved in the controlled retrieval and selection of competing alternatives which would impact verbs more than nouns during lexico-semantic processing (Crescentini et al, 2008).</p>
<p>Turning to sensory impairments, one study has assessed the performance of individuals with congenital blindness. Embodiment proposes that category preferences (e.g. the differences between tools and animals) rely on relationships between conceptual domains and specific types of sensory and motor information 34 (e.g. tools rely on action and motion information, animals rely on visual information).</p>
<p>Disembodied or secondary embodiment views would not make such a prediction assuming that categorical organization derives from other mechanisms (e.g., it is innately specified, see Mahon &amp; Caramazza, 2009).In the study by Mahon and Caramazza (2009), congenitally blind and sighted participants performed size judgments on aurally presented words. It was found that blind individuals activated the same brain regions as sighted individuals when performing these size judgments:</p>
<p>namely regions on the ventral surface of occipital-temporal cortex. These findings led the authors to conclude that visual experience is irrelevant to establishing object representations. However, the results can be interpreted as dependent upon experience: just a different type of experience. Moreover, whilst embodiment makes the prediction that representations depend on sensory and motor information, it does not follow that a system without one form of sensory input will organize in a completely different fashion. Ventral stream organization, in particular the size knowledge required for the task, may have been based in other sensory dimensions such as tactile information, which is integrated into the ventral stream. For example, Reed et al. (2009) found similar temporal activity for tactile and visual pattern recognition. The work of De Volder et al. (2001) also supports this idea. In their study, on the identification of a trigger sound, participants were instructed to retrieve a representation of the "visual" attributes of a stimulus (shape, size, configuration) which had been previously experienced during the training period by both auditory and haptic perception in early blind individuals and by both auditory and vision in sighted individuals. Activations were found in occipital and visual association areas, particularly in the left fusiform gyrus for both blind and sighted subjects. Thus, developmental cross-modal reorganization (in which sensory and motor experience plays a vital role) allows higher order processes to use the same 35 cortical regions. Thus, Mahon and Caramazza's results came about because of an innate brain predisposition, cross-modal reorganization or both.</p>
<p>It is important to keep in mind that this body of research does not directly address the question of whether sensory information is necessary for semantics. It is not straightforward to predict that deprivation of one sensory modality from early in development will lead to a system of cortical organization that is essentially like the 'normal' system minus that sensory input. There is evidence that areas deprived of their typical sensory input are recruited for qualitatively different processes. For example, Amedi (2004) found that repetitive TMS on the left occipital cortex of congenitally blind participants interfered with the generation of an 'appropriate' verb when given a noun; thus implicating the occipital cortex in semantic processing and lexical retrieval. Therefore, we have evidence for similar neural organization (e.g. the ventral stream and fusiform activation for object judgments) and very different neural organization (as above) when we compare congenitally blind and sighted individuals. For these reasons, and more generally because there is not yet a clear model of how the brain develops when one kind of sensory input is removed, data obtained with patients deprived of a sensory channel from birth do not offer a clear testing ground for embodiment. More informative would be to consider cases in which individuals developed typical cognitive systems without impairments and then experienced some damage later in life; i.e. acquired conditions in adults.</p>
<p>Having discussed the kind of data that is needed to decide between different strands of embodiment in semantics, it is necessary to respond to some of the criticisms that are leveled against embodiment itself.</p>
<p>36</p>
<p>Criticisms of embodiment</p>
<p>Spreading Activation Mahon and Caramazza (2008) have argued that engagement of the sensory and motor systems in the brain [could] follow naturally from "activation cascades from disembodied concepts to the sensory and motor systems" (p.60, ibid). Given this logical possibility, Mahon and Caramazza argued that the behavioural and neuroscientific findings that have so far been taken as evidence for the embodiment theories are, in fact, also consistent with disembodied theories. An example of such spreading activation, they argue, is found in phonological activation of unproduced words in a picture naming task (Morsella &amp; Miozzo, 2002;Navarrete &amp; Costa, 2005).</p>
<p>They then extend this example to automatic activation of the motor system when participants name tools. They conclude that activation cascades are ubiquitous in cognitive processes and therefore cannot be taken as evidence refuting the unembodied theories or confirming embodiment.</p>
<p>However, we argue that this equivalence between phonological and motor activation is problematic: naming a picture of a hammer involves phonological activation of the word "hammer" (indirectly facilitating "hammock", by similarity) but it clearly does not involve hammer use. So "spreading" of phonological similarity during phonological production is expected because production is part of the task. However, such spreading is not equivalent to spreading of activation to effector-specific motor units (e.g. the motor cortex enervating the hand muscles) that are not at all needed for performing the experimental task (i.e. picture naming).</p>
<p>The implication is that the null hypothesis facing the predictions embodiment is that motor system is always activated in effector-specific patterns no matter what the task requirement or the cognitive state of the observer may be. However, unless there is a non-trivial connection between naming and using (e.g. embodiment), there is no reason to believe that naming "hammer" should spread activation to the premotor cortex. If the distinction between disembodied and embodied theories didn't require that tool naming has something to do with tool use then arguing about the distinction between them would be meaningless. The non-specific spreading view is particularly problematic in explaining the disruption of semantic processing by application of TMS on motor cortex (Pulvermüller et al 2005). Here, the direction of the cascade has to be reversed from the motor system to the semantic representation and -what is more -the semantic concept should be triggered, specifically, by TMS-induced noise in the motor system (Mahon &amp; Caramazza, 2008, p.62).</p>
<p>Given the above, one may argue that Mahon and Caramazza's criticism has widened the null hypothesis to such a degree that it encompasses both extremes. Such an unconstrained null hypothesis embraces any possible experimental result.</p>
<p>What else contributes to semantics?</p>
<p>For theories that adhere to secondary/derived embodiment, the default position is that semantic content is primarily abstract, with non-arbitrary connections to sensory and motor information. For these theories, there still needs to be a clear statement of what, exactly, semantic content is. For Patterson, Rogers and colleagues (Rogers et al, 2004;Patterson et al, 2008) the semantic system is defined by function, and organization, over content. Since the semantic system is defined as a series of mappings between modality specific information, there appears to be an assumption 38 that content is provided by those modality specific systems, leaving it open to the same criticisms levelled at embodied theories: how do you account for abstract words? For Mahon &amp; Caramazza (2008), they assume that semantic content is abstract in nature, meaning that the content is essentially undefined.</p>
<p>For theories that adhere to weak embodiment, two have recognised that other information contributes to semantic processing. Simmons, Barsalou and colleagues (Simmons, Hamann, Harenski, Xiaoping &amp; Barsalou, 2008; Barsalou, L.W., Santos, A., Simmons, W.K., Wilson, C.D. 2009) and Vigliocco and colleagues (Andrews, Vinson &amp; Vigliocco, 2008;Vigliocco, Meteyard, Andrews &amp; Kousta, 2009) have proposed that linguistic information in the form of word associations may play a role in lexico-semantic processing; alongside embodied content. For Simmons, Barsalou et al, this is dependent on the task that is being performed; word-associations between linguistic forms (e.g. 'bird' and 'house') may be used when only shallow processing is necessary to complete a task (e.g. lexical decision with non-words that violate phonological or orthographic rules). For them, real semantic content is still a simulation of sensory and motor information (e.g. Wu and Barsalou, 2009). For Vigliocco et al, important aspects of word meaning are learnt and represented through their co-occurance (distribution) with other words; and affective information also plays an important role. Under this description, the difference between concrete and abstract words lies in the preponderance of sensory and motor information for concrete words compared to a preponderance of linguistic and affective information for abstract words (Vigliocco, Meteyard, Andrews &amp; Kousta, 2009).</p>
<p>Finally, for strongly embodied theories, there is little or no mention of what else aside from sensory and motor information does contribute to lexico-semantic representation.</p>
<p>We take the position that sensory and motor information does not exhaust semantic content. It is intuitive to adopt the the idea that central to semantic organization is the linkage of different kinds of information, and this has been achieved in connectionist or Bayesian models (e.g. Rogers et al, 2004;Andrews, Vinson &amp; Vigliocco, 2008). However, the key question remains, what is the information that is being linked. This problem is especially salient when we look at abstract words.</p>
<p>Abstract words</p>
<p>A major problem for dominant embodied approaches is how to account for abstract cognition, such as that implicated in conceptual representation and abstract reasoning. Embodied approaches do very well for on-line action between a body and an environment, and offer some intriguing explanations about how the environment is utilised to benefit cognition (Clark, 1997;Wilson, 2002). However, in order to maintain the embodied framework, simulation is at present the only mechanism that could support semantic and conceptual representations. Simulation can provide the content of representation with perceptual and motor activity, but how the information is structured and processed is more problematic and less well defined, especially for abstract cognition (Barsalou, 1999). One mechanism that has been put forward by Lakoff (1987) is that of conceptual methaphor. In this view, abstract domains are grounded into perception and ation via the mediation of concrete domains. Namely, abstract concepts such as love would be embodied because they would be learnt and represented as methaphorical extension from concrete concepts such as journey. These methaphors are clearly identifiable in languages and provide the mechanism by which abstract concepts could be embodied. It is however the case that evidence in favor to such a hypothesis is rather scant (but see e.g., Glenberg, et al., 2008), moreover, it appears that even if possible such an account could not account for all abstract domains of knowledge (e.g., how much of the technical abstract jargon of our scientific knowledge could be characterized in this manner).</p>
<p>We have recently put forward a theoretical account that goes beyond our previous work by accounting for the representaiton of abstract, in addition to concrete words ). In our current theoretical view we have argued for two classes of information that contribute to the representation of both concrete and abstract words: experiential (sensory, motor, but also affective) and linguistic (verbal associations arising through co-occurrence patterns and syntactic information). Differences between concrete and abstract word meanings (as well as within concrete and within abstract word meanings) arise as a result of the proportion and exact type of experiential and linguistic information from which they are derived. Most relevant for our purposes here, we have argued and provided evidence for a statistical preponderance for affective and linguistic information to underlie abstract word meanings (e.g., Kousta et al., 2009;Kousta et al., submitted). Whereas concrete knowledge would be grounded into our experience with the outside world, abstract knowledge could be grounded in our internal experience. Abstract words tend, on the whole, to have more affective associations than concrete words, and the greater the affective associations, the earlier those abstract words are acquired (especially for positive words, Kousta et al., 2009).</p>
<p>Thus, affect may play a critical role in allowing the learning, or bootstrapping, of abstract knowledge.</p>
<p>Of course it is the case that not all abstract words are affectively loaded. Affect, nonetheless could have an important role in allowing for knowledge that cannot be 41 grounded to the external world to begin developing. Once the system is set in place, other abstract concepts can be learned, based on linguistic information solely.</p>
<p>Grammar</p>
<p>Finally, we turn to some of the most abstract elements of language. Thus far we have focused on the lexicon and the semantic information contained within content words. However, languages have a variety of means of expressing other important elements of the world, such as the spatial information conveyed through prepositions (in English) and temporal and tense markers that vary aspect. If embodied theories are to provide a unified account for semantic information, they need to be able to account for how these more abstract elements fit with access to sensory and motor information. Whilst it is relatively intuitive to suggest that 'simulation' underlies the representation of concrete entities and events, it is rather less straightforward to explain how sensory and motor information can underpin the representation of information that is marked by morpho-syntactic changes. This returns to a key facet of all languages: by expressing things in language we necessarily schematize and lose information. Language is a digital medium that uses features of meaning (such as agency, causation or spatial relations) which necessarily lose some of the richness and complexity of sensory experience (Pinker, 2007). These features show how language carves the world up in a way that reflects our human experience, and by implication, any 'simulation' that underpins semantic processing should reflect this schematization. This has been addressed in some incarnations of strongly embodied theories (e.g. Barsalou, 1999) by proposing that simulations are themselves schematic, but there has to be a more explicit treatment of morpho-syntactic information.</p>
<p>42</p>
<p>There is some preliminary work that addresses this area. For spatial relations, as expressed by English prepositions, fMRI work has highlighted the left superior marginal gyrus and patient work has shown double dissociations between the processing of linguistic spatial relations and the performance of various visuo-spatial tasks (Kemmerer, 2010). This implies, in line with weak embodiment or secondary embodiment, that areas proximal to -but not overlapping with -those that are involved in processing spatial information are involved in processing semantic information related to space. For markers related to time, Zwaan (2008) provides a clear rationale for how mental simulations of sentences might change depending on different temporal markers ('immediately' versus 'last year'), tense and aspect (e.g.</p>
<p>progressive versus perfective). The argument is that markers modify the content of simulations by making certain elements (and therefore certain modality specific information) more salient. Bergen &amp; Wheeler (2010) provide some preliminary evidence of this by demonstrating interactions between hand movements and sentences describing movements towards or away from the body for progressive aspect sentences ('Ashley is stretching her arms') but not for perfective aspect sentences ('Ashley had stretched her arms'). The authors argue that grammatical markers for aspect operate over the simulated content to shift the focus of attention to, for example, a motor movement (thereby accessing motor content) or to a completed action (thereby accessing more visual information) (Zwaan, 2008).</p>
<p>This work begins to address the challenge to embodied theories posed by the meaningful consequences of morpho-syntactic information. Stating that such information modifies simulations of semantic content is a reasonable addition to strongly embodied theories. The fact that access to modality specific information appears to be highly flexible and dependent on the linguistic context can be 43 accommodated by all points on the continuum of embodied theory. However, to return to the point made earlier, there is much in language that is schematic and abstract, which begs the question of whether a fully analogue system (as proposed by strong embodiment) is necessary or sufficient for semantic processing.</p>
<p>Conlcusions: converging on convergence zones</p>
<p>There is broad agreement amongst the theories we have reviewed that some form of convergence zones are central to semantic representation. This is based on the assumption that in order to represent something, we must be able to retrieve a collection of sufficient information that stands for that thing. This information is stored neurally as statistical regularities, feature conjunctions or correlations.</p>
<p>Convergence zones are regions of cortex that can be shown to store such information (e.g. through a change in bold response when a semantic representation/concept is processed). Neurophysiological work supports the proposal that modality specific content it is necessary for semantic representation by demonstrating that it appears early in linguistic processing. There is also an increasing body of work that demonstrates a gradient of 'abstraction': as one moves away from primary sensory and motor cortices, more complex conjunctions are captured. This supports the idea of convergence zones as the basis for representation (explicitly predicted in Damasio's original framework, Damasio, 1989;Damasio &amp; Damasio, 1994), particularly when more anterior activations are present when something is recognized (i.e. categorized within extant semantic representations). We find ourselves supporting a position where primary sensory and motor regions are not activated during routine semantic processing (in 44 opposition to strong embodiment) but may be so for deeper processing related to imagery.</p>
<p>Theories differ as to how they define the location and modal content of the zones.</p>
<p>Those within weak embodiment state that these convergence zones are multi-modal, distributed across the cortex and located proximal to sensory and motor regions.</p>
<p>Those theories within secondary embodiment state that there is (probably) one major convergence zone (i.e. it is unitary) and it is located separately to sensory and motor regions. According to weak embodiment, we should not see semantic processing without activation of these modal zones; according to secondary embodiment, we should be able to achieve semantic processing only with the activation of the unitary, major zone (modal activations are not necessary, but may be present).</p>
<p>We have taken the position that fully symbolic, unembodied theories can be rejected and that the validity of strong embodiment is questionable outside conscious imagery. There is broad agreement that sensory and motor information is activated when a semantic representation is accessed. Differences remain as to what constitutes 'true' semantic information that is necessary and sufficient for representation, rather than secondary to it. An important caveat here is the task that is used to access semantic information; different tasks may implicate different configurations of semantic information. This will likely prove to be a particularly thorny problem, and will require explicit theoretical statements about what is 'true' semantic information, and careful consideration of what level of processing an experimental task requires. Part of this work must explore the representation of abstract words, defining how more or less abstract content is realized, relate sensory-motor processing in linguistic tasks to known linguistic variables (like 45 frequency) and begin to tackle the schematic information laid down by morphosyntactic markers.</p>
<p>We have provided predictions and discussed the kind of data that will allow extant theories to be separated, or integrated. Finally, we have discussed the remaining theoretical problems, that theories of semantics need to account for. We hope that this paper serves as a useful starting point for further research in the field.</p>
<p>-
---------------------------Insert Figure 1 about here ------------------------------Un-embodied theories These theories posit no role for sensory and motor information in semantic</p>
<p>Fronto-
Temporal Dementia (FTD): Non-fluent Primary Progressive Aphasia (NfPPA, damage primarily in left frontal and perisylvian regions), Frontal variant of FTD (FvFTD, damage primarily in frontal regions bilaterally), and Semantic Dementia (SD, damage primarily in the anterior temporal lobes bilaterally) as well as Progressive Supranuclear Palsy (PSP, damage primarily in frontal regions, basal ganglia, cerebellum and brainstem) and Cortico-Basal Degeneration (CBD, damage</p>
<p>The organisation of the ventral temporal object processing stream. K Acres, Acres, K. The organisation of the ventral temporal object processing stream.</p>
<p>Unpublished Doctoral Dissertation. Pembroke CollegeUniversity of CambridgeUnpublished Doctoral Dissertation, University of Cambridge, Pembroke College, 2008.</p>
<p>Transcranial magnetic stimulation of the occipital pole interferes with verbal processing in blind subjects. A Amedi, A Floel, S Knetch, E Zohary, L G Cohen, Nature neuroscience. 711Amedi, A., Floel, A., Knetch, S., Zohary, E. and Cohen, L.G. Transcranial magnetic stimulation of the occipital pole interferes with verbal processing in blind subjects. Nature neuroscience, 7(11): 1266-1270, 2004.</p>
<p>Motor neurone disease, dementia and aphasia: coincidence, co-occurrence or continuum. M Andrews, D Vinson, G Vigliocco, Psychological Review. Bak, T.H. &amp; Hodges, J. R1163Journal of NeurologyAndrews, M., Vinson, D., Vigliocco, G. Integrating experiental and distributional data to learn semantic representations. Psychological Review, 116 (3): 463-498, 2009. Bak, T.H. &amp; Hodges, J. R. Motor neurone disease, dementia and aphasia: coincidence, co-occurrence or continuum? Journal of Neurology, 248 : 260-270, 2001.</p>
<p>Selective impairment of verb processing associated with pathological changes in Brodmann areas 44 and 45 and the motor neurone disease-dementia-aphasia syndrome. T H Bak, D G O&apos;donoval, J H Xuereb, S Boniface, J R Hodges, Brain. 124Bak, T.H., O'Donoval, D.G., Xuereb, J.H., Boniface, S. and Hodges, J.R. Selective impairment of verb processing associated with pathological changes in Brodmann areas 44 and 45 and the motor neurone disease-dementia-aphasia syndrome. Brain, 124: 103-120, 2001.</p>
<p>Cortical mechanisms specific to explicit visual object recognition. M Bar, R B H Tootell, D L Schacter, D N Greve, B Fischl, J D Mendola, B R Rosen, A M Dale, Neuron. 292Bar, M., Tootell, R. B. H., Schacter, D. L., Greve, D. N., Fischl, B., Mendola, J. D., Rosen, B.R., Dale, A.M. Cortical mechanisms specific to explicit visual object recognition. Neuron, 29 (2): 529-535, 2001.</p>
<p>. M D Barense, T J Bussey, A C H Lee, T T Rogers, R R Davies, L M Saksida, Barense, M.D., Bussey, T.J., Lee, A.C.H., Rogers, T.T., Davies, R.R., Saksida, L.M.,</p>
<p>Functional Specialization in the Human Medial Temporal Lobe. E A Murray, K S Graham, The Journal of Neuroscience. 2544Murray, E.A., Graham, K.S. Functional Specialization in the Human Medial Temporal Lobe. The Journal of Neuroscience, 25 (44): 10239-10246, 2005.</p>
<p>Language and simulation in conceptual processing. L W Barsalou, A Santos, W K Simmons, C D Wilson, Symbols, Embodiment, and Meaning. De Vega, M., Glenberg, A.M., Graesser, A.OxfordOxford University Press28than percepts: the case of action verbsBarsalou, L.W., Santos, A., Simmons, W.K., Wilson, C.D. Language and simulation in conceptual processing. In: De Vega, M., Glenberg, A.M., Graesser, A. (Eds.), Symbols, Embodiment, and Meaning. Oxford University Press, Oxford, 2009. than percepts: the case of action verbs. Journal of Neuroscience, 28 (44): 11347- 11353, 2008.</p>
<p>Sports experience changes the neural processing of action language. S L Beilock, I M Lyons, A Mattarella-Micke, H C Nusbaum, S L Small, Proceedings of the National Academy of Sciences. 105Beilock, S.L., Lyons, I.M., Mattarella-Micke, A., Nusbaum, H.C. &amp; Small, S.L. Sports experience changes the neural processing of action language. Proceedings of the National Academy of Sciences, 105: 13269-13273, 2008.</p>
<p>Grammatical aspect and mental simulation. B Bergen, K Wheeler, Brain and Language. 112Bergen, B. &amp; Wheeler, K. Grammatical aspect and mental simulation. Brain and Language, 112: 150-158. 2010.</p>
<p>Word processing in Parkinson's disease is impaired for action verbs but not for concrete nouns. V Boulenger, L Mechtouff, S Thobois, E Broussolle, M Jeannerod, T A Nazir, Neuropsychologia. 462Boulenger, V., Mechtouff, L., Thobois, S., Broussolle, E., Jeannerod, M., Nazir, T.A. Word processing in Parkinson's disease is impaired for action verbs but not for concrete nouns. Neuropsychologia, 46(2): 743-756. 2007</p>
<p>Unitary vs multiple semantics: PET studies of word and picture processing. P Bright, H Moss, L K Tyler, Brain and Language. 893Bright, P., Moss, H., Tyler, L.K. Unitary vs multiple semantics: PET studies of word and picture processing. Brain and Language, 89 (3): 417-432, 2004.</p>
<p>The multiple semantics hypothesis: Multiple confusions?. A Caramazza, A E Hillis, B C Rapp, C Romani, Cognitive Neuropsychology. 73Caramazza, A. Hillis, A.E., Rapp, B.C., Romani, C. The multiple semantics hypothesis: Multiple confusions? Cognitive Neuropsychology, 7 (3): 161-189, 1990.</p>
<p>The organization of conceptual knowledge: the evidence from category-specific semantic deficits. A Caramazza, B Z Mahon, Trends in Cognitive Sciences. 78Caramazza, A. and Mahon, B.Z. The organization of conceptual knowledge: the evidence from category-specific semantic deficits. Trends in Cognitive Sciences, 7(8): 354-361, 2003.</p>
<p>The neural organization of spatial thought and language. A Chatterjee, Seminars in Speech and Language. 29Chatterjee, A. The neural organization of spatial thought and language. Seminars in Speech and Language, 29: 226-238, 2008.</p>
<p>Disembodying cognition. A Chatterjee, Language and Cognition. 21Chatterjee, A. Disembodying cognition. Language and Cognition, 2-1: 79-116, 2010.</p>
<p>Being There: Putting Brain. A Clark, Body and World Together Again. MIT PressClark, A. Being There: Putting Brain, Body and World Together Again. London, UK.: MIT Press, 1998.</p>
<p>A Spreading-Activation Theory of Semantic Processing. A M Collins, E F Loftus, Psychological Review. 826Collins, A. M., Loftus, E. F. A Spreading-Activation Theory of Semantic Processing. Psychological Review, 82 (6): 407-428, 1975.</p>
<p>Different impairments of semantic cognition in semantic dementia and semantic aphasia: evidence from the non-verbal domain. F Corbett, E Jefferies, S Ehsan, M A Lambon Ralph, Brain. 132Pt 9Corbett, F., Jefferies, E., Ehsan, S., Lambon Ralph, M.A. Different impairments of semantic cognition in semantic dementia and semantic aphasia: evidence from the non-verbal domain. Brain. 132 (Pt 9): 2593-2608, 2009.</p>
<p>Effect of Transcranial Magnetic Stimulation on Action Naming in Patients With Alzheimer Disease. M Cotelli, R Manenti, S F Cappa, C Geroldi, O Zanetti, P M Rossini, C Miniussi, Arch Neurol. 63Cotelli, M., Manenti, R., Cappa, S.F., Geroldi, C., Zanetti, O., Rossini, P.M., Miniussi, C. Effect of Transcranial Magnetic Stimulation on Action Naming in Patients With Alzheimer Disease. Arch Neurol, 63: 1602-1604, 2006.</p>
<p>Supervisory and Routine Processes in Noun and Verb Generation in Nondemented Patients with Parkinson's Disease. C Crescentini, F Mondolo, E Biasutti, T Shallice, Neuropsychologia. 462Crescentini, C., Mondolo, F., Biasutti, E. &amp; Shallice, T. Supervisory and Routine Processes in Noun and Verb Generation in Nondemented Patients with Parkinson's Disease. Neuropsychologia, 46(2): 434-447, 2008.</p>
<p>The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones. A R Damasio, Neural Computation. 1Damasio, A.R. The Brain Binds Entities and Events by Multiregional Activation from Convergence Zones. Neural Computation, 1, 123-132, 1989.</p>
<p>Cortical Systems for Retrieval of Concrete Knowledge: The Convergance Zone Framework. A R Damasio, H Damasio, C. Koch &amp; Davis, J.L.MIT PressLondon, UK(Eds) Large-Scale Neuronal Theories of the BrainDamasio, A.R. &amp; Damasio, H. Cortical Systems for Retrieval of Concrete Knowledge: The Convergance Zone Framework. Ch. 4 in C. Koch &amp; Davis, J.L. (Eds) Large-Scale Neuronal Theories of the Brain, MIT Press, London, UK, 1994.</p>
<p>De Volder, A G Toyama, H Kimura, Y Kiyosawa, M Nakano, H Vanlierde, A Wanet-Defalque, M C Mishina, M Oda, K Ishiwata, K , Senda, M. Auditory Triggered Mental Imagery of Shape Involves Visual Association Areas in Early Blind Humans. Neuroroimage. 14De Volder, A.G., Toyama, H., Kimura, Y., Kiyosawa, M., Nakano, H., Vanlierde, A., Wanet-Defalque, M.C., Mishina, M., Oda, K., Ishiwata, K., Senda, M. Auditory Triggered Mental Imagery of Shape Involves Visual Association Areas in Early Blind Humans. Neuroroimage, 14: 129-139, 2001.</p>
<p>Susceptibilityinduced loss of signal: Comparing PET and fMRI on a semantic task. J T Devlin, R P Russell, M H Davis, C J Price, J Wilson, H E Moss, Neuroimage. 11Devlin JT, Russell RP, Davis MH, Price CJ, Wilson J, Moss HE, et al. Susceptibility- induced loss of signal: Comparing PET and fMRI on a semantic task. Neuroimage 11: 589-600, 2000.</p>
<p>A Computational Model of Semantic Impairment: Modality Specificity and Emergent Category Specificity. M J Farah, J L Mcclelland, Journal of Experimental Psychology: General. 1204Farah, M. J., McClelland, J. L. A Computational Model of Semantic Impairment: Modality Specificity and Emergent Category Specificity. Journal of Experimental Psychology: General, 120 (4): 339-357, 1991.</p>
<p>The Modularity of Mind: An Essay on Faculty Psychology. J A Fodor, MIT PressLondonFodor, J. A. The Modularity of Mind: An Essay on Faculty Psychology. London: MIT Press, 1983.</p>
<p>Making up the mind: How the Brain Creates our Mental World. C Frith, BlackwellOxford, UK.Frith, C. Making up the mind: How the Brain Creates our Mental World. Oxford, UK.: Blackwell, 2007.</p>
<p>The brain's concepts: The role of the sensory-motor system in conceptual knowledge. V Gallese, G Lakoff, Cognitive Neuropsychology. 223/4Gallese, V., Lakoff, G. The brain's concepts: The role of the sensory-motor system in conceptual knowledge. Cognitive Neuropsychology, 22 (3/4): 455-479, 2005.</p>
<p>The body's contribution to language. A M Glenberg, M P Kaschak, The Psychology of Learning and Motivation. B.H.RossSan Diego, CAAcademic Press43Glenberg, A. M., Kaschak, M. P. The body's contribution to language. In B.H.Ross (Ed.), The Psychology of Learning and Motivation, 43: 93-126. San Diego, CA: Academic Press, 2003.</p>
<p>Symbol Grounding and Meaning: A Comparison of High-Dimensional and Embodied Theories of Meaning. A M Glenberg, D A Robertson, Journal of Memory and Language. 43Glenberg, A. M., Robertson, D. A. Symbol Grounding and Meaning: A Comparison of High-Dimensional and Embodied Theories of Meaning. Journal of Memory and Language, 43: 379-401, 2000.</p>
<p>Use-induced motor plasticity affects the processing of abstract and concrete language. A M Glenberg, M Sato, L Cattaneo, Current Biology. 18Glenberg, A. M., Sato, M., Cattaneo, L. Use-induced motor plasticity affects the processing of abstract and concrete language. Current Biology, 18, R290-R291, 2008.</p>
<p>Pantomime comprehension and ideomotor apraxia. L J Rothi, K M Heilman, R T Watson, Neurosurgery and Pyschiatry. 483Journal of NeurologyRothi, L.J., Heilman, K.M., Watson, R.T. Pantomime comprehension and ideomotor apraxia. Journal of Neurology, Neurosurgery and Pyschiatry, 48 (3): 207-210, 1985.</p>
<p>The time course of action and action-word comprehension in the human brain as revealed by neurophysiology. O Hauk, Y Shtyrov, F Pulvermuller, Journal of Physiology -Paris. 102Hauk, O., Shtyrov, Y. &amp; Pulvermuller, F. The time course of action and action-word comprehension in the human brain as revealed by neurophysiology. Journal of Physiology -Paris, 102: 50-58, 2008.</p>
<p>Foundations of Language: Brain, Meaning, Grammar, Evolution (Large format. R Jackendoff, Oxford University PressJackendoff, R. Foundations of Language: Brain, Meaning, Grammar, Evolution (Large format paperback ed.): Oxford University Press, 2002.</p>
<p>Comprehension of concrete and abstract words in semantic dementia. E Jefferies, K Patterson, R W Jones, Lambon Ralph, M A , Neuropsychology. 4Jefferies E, Patterson K, Jones RW, Lambon Ralph MA. Comprehension of concrete and abstract words in semantic dementia. Neuropsychology, 4: 492-9, 2009.</p>
<p>The neural bases of complex tool use in humans. S H Johnson-Frey, TRENDS in Cognitive Sciences. 82Johnson-Frey, S. H. The neural bases of complex tool use in humans. TRENDS in Cognitive Sciences, 8 (2): 71-78, 2004.</p>
<p>The computer and the mind: An introduction to Cognitive Science. P Johnson-Laird, Fontana PressGlasgowJohnson-Laird, P. The computer and the mind: An introduction to Cognitive Science. Glasgow: Fontana Press, 1993.</p>
<p>Visual and motor features of the meanings of action verbs: A cognitive neuroscience perspective. D Kemmerer, Roberto G. de Almeida &amp; Christina ManouilidouOxford University PressOxford, UKVerb concepts: Cognitive science perspectives on verb representation and processing. to appearKemmerer, D. Visual and motor features of the meanings of action verbs: A cognitive neuroscience perspective. In: Roberto G. de Almeida &amp; Christina Manouilidou (Eds.) Verb concepts: Cognitive science perspectives on verb representation and processing. Oxford, UK: Oxford University Press, to appear.</p>
<p>How words capture visual experience: The perspective from cognitive neuroscience. D Kemmerer, B. Malt &amp; P. WolffOxford University Press14Words and the Mind: How words capture human experienceKemmerer, D. How words capture visual experience: The perspective from cognitive neuroscience. In B. Malt &amp; P. Wolff (Eds) Words and the Mind: How words capture human experience, Ch14: 289-329. Oxford University Press, 2010.</p>
<p>Topographical Representations of Mental Images in Primary Visual Cortex. S M Kossyln, W L Thompson, I J Kim, N M Alpert, M.S. GazzanigaKossyln, S.M., Thompson, W.L., Kim, I.J., Alpert, N.M. Topographical Representations of Mental Images in Primary Visual Cortex, in M.S. Gazzaniga (Ed)</p>
<p>. Cognitive Neuroscience: A Reader. Blackwell. Cognitive Neuroscience: A Reader. Blackwell, Oxford: 202-208, 2000.</p>
<p>The neural representation of abstract word processing. S.-T Kousta, P Dellarosa, D P Vinson, S F Cappa, J Devlin, G Vigliocco, submittedKousta, S.-T., dellaRosa, P., Vinson, D.P., Cappa, S.F., Devlin, J. &amp; Vigliocco, G. The neural representation of abstract word processing, submitted.</p>
<p>The role of emotional valence in the processing of words. S.-T Kousta, D P Vinson, G Vigliocco, Cognition. 112Kousta, S.-T., Vinson, D.P. &amp; Vigliocco, G. The role of emotional valence in the processing of words. Cognition, 112, 473-481, 2009.</p>
<p>Fire and Dangerous Things: What categories reveal about the mind. G Lakoff, Women, University of Chicago PressChicago, ILLakoff, G. Women, Fire and Dangerous Things: What categories reveal about the mind. Chicago, IL.: University of Chicago Press, 1987.</p>
<p>A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge. T K Landauer, S T Dumais, Psychological Review. 1042Landauer, T. K., Dumais, S. T. A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction and Representation of Knowledge. Psychological Review, 104 (2): 211-240, 1997.</p>
<p>Is a picture worth a thousand words? Evidence from concept definitions by patients with semantic dementia. Lambon Ralph, M A Graham, K Patterson, K Hodges, J , Brain and Language. 703Lambon Ralph MA, Graham K, Patterson K, Hodges J. Is a picture worth a thousand words? Evidence from concept definitions by patients with semantic dementia. Brain and Language, 70 (3): 309-35, 1999.</p>
<p>A hierarchical axis of object processing stages in the human visual cortex. Y Lerner, T Hendler, D Ben-Bashat, M Harel, R Malach, Cerebral Cortex. 114Lerner, Y., Hendler, T., Ben-Bashat, D., Harel, M., Malach, R. A hierarchical axis of object processing stages in the human visual cortex. Cerebral Cortex, 11 (4): 287- 297, 2001.</p>
<p>Speaking: From Intention to Articulation. W J Levelt, MIT PressLondon, EnglandLevelt, W. J. M. Speaking: From Intention to Articulation. London, England.: MIT Press, 1989.</p>
<p>Der weitere Krankheitsverlauf bei dem einseitig Apraktischen und der Gehirnbefund auf Grund von Serienschnitten. H Liepmann, 17Monatsschrift fur Psychiatrie und NeurologieLiepmann, H. Der weitere Krankheitsverlauf bei dem einseitig Apraktischen und der Gehirnbefund auf Grund von Serienschnitten. Monatsschrift fur Psychiatrie und Neurologie, 17: 283-311, 1905.</p>
<p>The role of personal experience in the neural processing of action-related language. I M Lyons, A Mattarella-Micke, M Cieslak, H C Nusbaum, S L Small, S L Beilock, Brain and Language. 1123Lyons, I.M., Mattarella-Micke, A., Cieslak, M., Nusbaum, H.C., Small, S.L. &amp; Beilock, S.L. The role of personal experience in the neural processing of action-related language. Brain and Language, 112(3): 214-22, 2009.</p>
<p>Object vs. action naming: A double dissociation?. S Maetzig, J Druks, J Masterson, G Vigliocco, Cortex. 45Maetzig, S., Druks, J., Masterson, J., &amp; Vigliocco, G. Object vs. action naming: A double dissociation? Cortex, 45, 738-758, 2009.</p>
<p>Category-Specific Organization in the Human Brain Does Not Require Visual Experience. B Z Mahon, S Anzaellotti, J Schwarzbach, M Zampini, A Caramazza, Neuron. 63Mahon, B.Z., Anzaellotti, S., Schwarzbach, J., Zampini, M., Caramazza, A. Category- Specific Organization in the Human Brain Does Not Require Visual Experience. Neuron, 63: 397-405, 2009.</p>
<p>A Critical Look at the Embodied Cognition Hypothesis and a New Proposal for Grounding Conceptual Content. B Z Mahon, A Caramazza, Journal of Physiology-Paris. 1021-3Mahon, B. Z., Caramazza, A. A Critical Look at the Embodied Cognition Hypothesis and a New Proposal for Grounding Conceptual Content. Journal of Physiology-Paris, 102 (1-3): 59-70, 2008.</p>
<p>The Representation of Object Concepts in the Brain. A Martin, Annual Review of Psychology. 58Martin, A. The Representation of Object Concepts in the Brain. Annual Review of Psychology, 58: 25-45, 2007.</p>
<p>Neural correlates of categoryspecific knowledge. A Martin, C L Wiggs, L G Ungerleider, J V Haxby, Nature. 379Martin, A., Wiggs, C.L., Ungerleider, L.G., Haxby, J.V. Neural correlates of category- specific knowledge. Nature, 379: 649-652, 1996.</p>
<p>Evidence for a cascade model of lexical access. &amp; Morsella, Miozzo, Journal of Experimental Psychology: Learning, Memory and Cognition. Morsella &amp; Miozzo. Evidence for a cascade model of lexical access. Journal of Experimental Psychology: Learning, Memory and Cognition, 555-563, 2002.</p>
<p>Perceptual-mnemonic functions of the perirhinal cortex. E A Murray, T J Bussey, Trends in Cognitive Sciences. 34Murray, E. A., Bussey, T. J. Perceptual-mnemonic functions of the perirhinal cortex. Trends in Cognitive Sciences, 3 (4):142-151, 1999.</p>
<p>On the Nature and Scope of Featural Representations of Word Meaning. K Mcrae, V R De Sa, M S Seidenberg, Journal of Experimental Psychology: General. 1262McRae, K., de Sa, V. R., Seidenberg, M. S. On the Nature and Scope of Featural Representations of Word Meaning. Journal of Experimental Psychology: General, 126(2): 99-130, 1997.</p>
<p>Phonological activation of ignored pictures: further evidence for a cascade model of lexical access. &amp; Navarrete, Costa, Journal of memory and language. 53Navarrete &amp; Costa, Phonological activation of ignored pictures: further evidence for a cascade model of lexical access. Journal of memory and language, 53, 359-377, 2005.</p>
<p>What is the role of motor simulation in action and object recognition? Evidence from apraxia. G A L Negri, R I Rumiatti, A Zadini, M Ukmar, B Z Mahon, A Caramazza, Cognitive Neuropsychology. 248Negri, G.A.L., Rumiatti, R.I., Zadini, A., Ukmar, M., Mahon, B.Z. and Caramazza, A. What is the role of motor simulation in action and object recognition? Evidence from apraxia. Cognitive Neuropsychology, 24 (8): 795-816, 2007.</p>
<p>. A Newell, Physical Symbol Systems. Cognitive Science. 4Newell, A. Physical Symbol Systems. Cognitive Science, 4, 135-183, 1980.</p>
<p>Human Problem Solving. A Newell, H A Simon, Prentice-Hall IncEnglewood Cliffs, New JerseyNewell, A., Simon, H. A. Human Problem Solving. Englewood Cliffs, New Jersey: Prentice-Hall Inc., 1972.</p>
<p>Imagery and verbal processes. A Paivio, New York: Holt, Rinehart &amp; WinstonPaivio, A. Imagery and verbal processes. New York: Holt, Rinehart &amp; Winston, 1971.</p>
<p>Mental Representations: A Dual-Coding Approach. A Paivio, Oxford Psychology Series. 9Paivio, A. Mental Representations: A Dual-Coding Approach. Oxford Psychology Series, 9. 1986.</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, P J Nestor, T T Rogers, Nature Reviews Neuroscience. 8Patterson, K., Nestor, P.J.,Rogers, T.T. Where do you know what you know? The representation of semantic knowledge in the human brain. Nature Reviews Neuroscience 8: 976-987, 2007.</p>
<p>The Stuff of Thought: Language as a window into human nature. Penguin Group: London. S Pinker, Pinker, S. The Stuff of Thought: Language as a window into human nature. Penguin Group: London, 2007.</p>
<p>Graded modality-specific specialisation in semantics: A computational account of optic aphasia. D C Plaut, Cognitive Neuropsychology. 19Plaut, D. C. Graded modality-specific specialisation in semantics: A computational account of optic aphasia. Cognitive Neuropsychology, 19, 603-639, 2002.</p>
<p>The role of the anterior temporal lobes in the comprehension of concrete and abstract words: rTMS evidence. G Pobric, M Lambon-Ralph, E Jefferies, Cortex. 45Pobric, G., Lambon-Ralph, M., Jefferies, E. The role of the anterior temporal lobes in the comprehension of concrete and abstract words: rTMS evidence. Cortex, 45: 1104-1110, 2009.</p>
<p>Walking or Talking? Behavioral and Neurophysiological Correlates of Action Verb Processing. F Pulvermüller, M Harle, F Hummel, Brain and Language. 78Pulvermüller, F., Harle, M., Hummel, F. Walking or Talking? Behavioral and Neurophysiological Correlates of Action Verb Processing. Brain and Language, 78: 143-168, 2001.</p>
<p>Functional interaction of language and action: a TMS study. F Pulvermüller, O Hauk, V Nikulin, R J Ilmoneimi, European Journal of Neuroscience. 21Pulvermüller, F., Hauk, O., Nikulin, V., Ilmoneimi, R.J. Functional interaction of language and action: a TMS study. European Journal of Neuroscience, 21, 793-797, 2005.</p>
<p>Words in the brain's language. F Pulvermüller, Behavioral and Brain Sciences. 22Pulvermüller, F. Words in the brain's language. Behavioral and Brain Sciences, 22: 253-336, 1999.</p>
<p>Computation and Cognition: Toward a Foundation for Cognitive Science. Z W Pylyshyn, MIT PressLondon, England2nd ed.Pylyshyn, Z. W. Computation and Cognition: Toward a Foundation for Cognitive Science (2nd ed.). London, England.: MIT Press, 1985.</p>
<p>The role of representations in cognitive theory: more or multiple semantics and the agnosias. B C Rapp, A E Hillis, A Caramazza, Cognitive neuropsychology. 103Rapp, B.C., Hillis, A.E., Caramazza, A. The role of representations in cognitive theory: more or multiple semantics and the agnosias. Cognitive neuropsychology, 10 (3): 235-249, 1993.</p>
<p>. T T Rogers, M A Ralph, P Garrard, S Bozeat, J L Mcclelland, Rogers, T. T., Lambon Ralph, M. A., Garrard, P., Bozeat, S., McClelland, J. L.,</p>
<p>Structure and Deterioration of Semantic Memory: A Neuropsychological and Computational Investigation. J R Hodges, K Patterson, Psychological Review. 1111Hodges, J. R., Patterson, K. Structure and Deterioration of Semantic Memory: A Neuropsychological and Computational Investigation. Psychological Review, 111 (1): 205-235, 2004.</p>
<p>. N Sahin, S Pinker, S S Cash, D Schomer, E Halgren, Sequential Processing. Sahin, N., Pinker, S. Cash, S.S. Schomer, D. &amp; Halgren, E. Sequential Processing of</p>
<p>Lexical, Grammatical, and Phonological Information Within Broca's Area. Science. 326Lexical, Grammatical, and Phonological Information Within Broca's Area. Science, 326: 445-449</p>
<p>Localizing interference during naming: convergent neuroimaging and neuropsychological evidence for the function of Broca's area. T T Schnur, M F Schwartz, D Y Kimberg, E Hirshorn, H B Coslett, S L Thompson-Schill, Proceedings of the National Academy of Science U.S.A. 1061Schnur TT, Schwartz MF, Kimberg DY, Hirshorn E, Coslett HB, Thompson-Schill SL. Localizing interference during naming: convergent neuroimaging and neuropsychological evidence for the function of Broca's area. Proceedings of the National Academy of Science U.S.A, 106 (1): 322-327, 2009.</p>
<p>Dual echo EPI--the method of choice for fMRI in the presence of magnetic field inhomogeneities?. C Schwarzbauer, T Mildner, W Heinke, M Brett, R Deichmann, Neuroimage. 491Schwarzbauer C, Mildner T, Heinke W, Brett M, Deichmann R. Dual echo EPI--the method of choice for fMRI in the presence of magnetic field inhomogeneities? Neuroimage. 49 (1): 316-26, 2010.</p>
<p>Brains and Programs. J Searle, Minds, Behavioral and Brain Sciences. 3Searle, J. Minds, Brains and Programs. Behavioral and Brain Sciences, 3: 417-457, 1980.</p>
<p>Is subliminal learning really passive?. A R Seitz, T Watanabe, Nature. 4226927Seitz, A. R., Watanabe, T. Is subliminal learning really passive? Nature, 422 (6927):36-36, 2003.</p>
<p>The similarity-in-topography principle: Reconciling theories of conceptual deficits. K W Simmons, L W Barsalou, Cognitive Neuropsychology. 203Simmons, K.W., Barsalou, L.W. The similarity-in-topography principle: Reconciling theories of conceptual deficits. Cognitive Neuropsychology, 20 (3/4/5/6): 451-486, 2003.</p>
<p>fMRI evidence for word association and situated simulation in conceptual processing. W K Simmons, S B Hamann, C N Harenski, X P Hu, L W Barsalou, Journal of Physiology -Paris. 102Simmons, W.K., Hamann, S.B., Harenski, C.N., Hu, X.P., Barsalou, L.W. fMRI evidence for word association and situated simulation in conceptual processing. Journal of Physiology -Paris, 102: 106-119, 2008.</p>
<p>The anterior temporal lobes and the functional architecture of semantic memory. W K Simmons, A Martin, Journal of the International Neuropsychological Society. 155Simmons, W.K. &amp; Martin, A. The anterior temporal lobes and the functional architecture of semantic memory. Journal of the International Neuropsychological Society, 15(5): 645-9. 2009.</p>
<p>Information Processing Models of Cognition. H A Simon, Annual Review of Psychology. 30Simon, H. A. Information Processing Models of Cognition. Annual Review of Psychology, 30:363-396, 1979.</p>
<p>The neural substrate of naming events. S Siri, M Tettamanti, S Della Cappa, P Rosa, C Saccuman, P Scifo, G Vigliocco, Cerebral Cortex. 18Siri, S., Tettamanti, M., Cappa, S. Della Rosa, P., Saccuman, C., Scifo, P. &amp; Vigliocco, G. The neural substrate of naming events. Cerebral Cortex, 18: 171-177, 2008.</p>
<p>Structure and Process in Semantic Memory: A featural model for semantic decisions. E E Smith, E J Shoben, L J Rips, Psychological Review. 813Smith, E. E., Shoben, E. J., Rips, L. J. Structure and Process in Semantic Memory: A featural model for semantic decisions. Psychological Review, 81 (3): 214-241, 1974.</p>
<p>Reading Stories Activates Neural Representations of Visual and Motor Experiences. N K Speer, J R Reynolds, K M Swallow, J M Zacks, Psychological Science. 208Speer, N.K, Reynolds, J.R., Swallow, K.M., Zacks, J.M. Reading Stories Activates Neural Representations of Visual and Motor Experiences. Psychological Science, 20 (8): 989-999, 2009.</p>
<p>Neuroimaging studies of semantic memory: inferring "how" from "where. S L Thompson-Schill, Neuropsychologia. 41Thompson-Schill, S.L. Neuroimaging studies of semantic memory: inferring "how" from "where". Neuropsychologia, 41: 280-292, 2003.</p>
<p>Language beyond action. I Toni, F P De Lange, M L Noordzij, P Hagoort, Journal of Physiology Paris. 1021-355Toni, I., de Lange, F. P., Noordzij, M. L., &amp; Hagoort, P. Language beyond action. Journal of Physiology Paris, 102(1-3), 71-79, 2008. 55</p>
<p>Towards a distributed account of conceptual knowledge. L K Tyler, H E Moss, Trends in Cognitive Science. 56Tyler, L.K., Moss, H.E. Towards a distributed account of conceptual knowledge. Trends in Cognitive Science, 5 (6): 244-252, 2001.</p>
<p>Processing Objects at Different Levels of Specificity. L K Tyler, E A Stamatakis, P Bright, K Acres, S Abdallah, J M Rodd, H E Moss, Journal of Cognitive Neuroscience. 163Tyler, L. K., Stamatakis, E. A., Bright, P., Acres, K., Abdallah, S., Rodd, J.M. &amp; Moss, H.E. Processing Objects at Different Levels of Specificity. Journal of Cognitive Neuroscience, 16(3): Pages 351-362, 2004.</p>
<p>. K I Taylor, E A Stamatakis, L K Tyler, Crossmodal integration of object features. Taylor, K.I., Stamatakis, E.A. &amp; Tyler, L.K. Crossmodal integration of object features:</p>
<p>Voxel-based correlations in brain-damaged patients. Brain. 1323Voxel-based correlations in brain-damaged patients. Brain. 132(3): 671-683, 2009.</p>
<p>M R Quillian, Semantic Memory, Semantic Information Processing. M. MinskyLondon, EnglandMIT PressQuillian, M. R. Semantic Memory. In M. Minsky (Ed.), Semantic Information Processing, 216-271. London, England.: MIT Press, 1968.</p>
<p>The functional role of motor activation in language processing: motor cortical oscillations support lexical-semantic retrieval. M Van Elk, H T Van Schie, R A Zwaan, H Bekkering, Neuroimage. 502van Elk, M., van Schie, H.T., Zwaan, R.A., Bekkering, H. The functional role of motor activation in language processing: motor cortical oscillations support lexical-semantic retrieval. Neuroimage, 50(2):665-77, 2010.</p>
<p>Towards a theory of semantic representation. G Vigliocco, L Meteyard, M Andrews, S Kousta, Language and cognition. 12Vigliocco, G., Meteyard, L., Andrews, M., Kousta, S. Towards a theory of semantic representation. Language and cognition, 1 (2): 219-247, 2009.</p>
<p>Representing the meaning of object and action words: The featural and unitary semantic space hypothesis. G Vigliocco, D P Vinson, W Lewis, M F Garrett, Vigliocco, G., Vinson, D. P., Lewis, W., Garrett, M. F. Representing the meaning of object and action words: The featural and unitary semantic space hypothesis.</p>
<p>. Cognitive Psychology. 48Cognitive Psychology, 48: 422-488, 2004.</p>
<p>The role of semantics and grammatical class in the neural representation of words. G Vigliocco, J Warren, S Siri, J Arciuli, S Scott, R Wise, Cerebral Cortex. 16Vigliocco, G., Warren, J., Siri, S., Arciuli, J., Scott, S., &amp; Wise, R. The role of semantics and grammatical class in the neural representation of words. Cerebral Cortex, 16: 1790-1796, 2006.</p>
<p>Motion verb sentences activate left posterior middle temporal cortex despite static context. M Wallentin, T Ellegaard, S Ostergaard, L Ostergaard, A Roepstorff, NeuroReport. 166Wallentin, M., Ellegaard, T., Ostergaard, S., Ostergaard, L., Roepstorff, A. Motion verb sentences activate left posterior middle temporal cortex despite static context. NeuroReport, 16 (6): 649-652, 2005. 3): 829-854, 1984.</p>
<p>Body-specific representations of action verbs: neural evidence from right-and left-handers. R M Willems, P Hagoort, D Casasanto, Psychological Science. 21Willems R.M., Hagoort, P., Casasanto, D. Body-specific representations of action verbs: neural evidence from right-and left-handers. Psychological Science. 21:67- 74. 2010.</p>
<p>Neural Dissociations between Action Verb Understanding and Motor Imagery. R M Willems, I Toni, P Hagoort, D Casasanto, Journal of Cognitive Neuroscience. Willems R.M., Toni, I., Hagoort, P., Casasanto, D. Neural Dissociations between Action Verb Understanding and Motor Imagery. Journal of Cognitive Neuroscience, 2009.</p>
<p>Six views of embodied cognition. M Wilson, Psychonomic Bulletin and Review. 94Wilson, M. Six views of embodied cognition. Psychonomic Bulletin and Review, 9 (4): 625-636, 2002.</p>
<p>Perceptual simulation in conceptual combination: Evidence from property generation. L L Wu, L W Barsalou, Acta Psychologica. 132Wu, L.L, Barsalou, L.W. Perceptual simulation in conceptual combination: Evidence from property generation. Acta Psychologica, 132: 173-189, 2009.</p>
<p>Time in Language, Situation Models and Mental Simulation. R Zwaan, Language Learning. 58s1Zwaan, R. Time in Language, Situation Models and Mental Simulation. Language Learning, 58(s1): 13-26. 2008.</p>
<p>The immersed experiencer: toward an embodied theory of language comprehension. R Zwaan, B H Ross, The Psychology of Learning and Motivation. 44Zwaan, R., B.H.Ross. The immersed experiencer: toward an embodied theory of language comprehension. In The Psychology of Learning and Motivation, 44: 35-62.</p>
<p>. C A San Diego, Academic Press57San Diego, CA.: Academic Press, 2004. 57</p>
<p>. Figure. 1Figure 1:</p>            </div>
        </div>

    </div>
</body>
</html>