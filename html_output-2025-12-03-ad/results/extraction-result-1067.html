<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1067 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1067</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1067</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-24.html">extraction-schema-24</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <p><strong>Paper ID:</strong> paper-9da2c718df4711af9dda03e4238c3d2b31e129d6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/9da2c718df4711af9dda03e4238c3d2b31e129d6" target="_blank">Benchmarking Metric Ground Navigation</a></p>
                <p><strong>Paper Venue:</strong> IEEE International Symposium on Safety, Security and Rescue Robotics</p>
                <p><strong>Paper TL;DR:</strong> A standardized testbed with a set of environments and metrics to benchmark difficulty of different scenarios and performance of different systems of metric ground navigation, and potentially serve as a cost function and a curriculum for planning-based and learning-based navigation systems.</p>
                <p><strong>Paper Abstract:</strong> Metric ground navigation addresses the problem of autonomously moving a robot from one point to another in an obstacle-occupied planar environment in a collision-free manner. It is one of the most fundamental capabilities of intelligent mobile robots. This paper presents a standardized testbed with a set of environments and metrics to benchmark difficulty of different scenarios and performance of different systems of metric ground navigation. Current benchmarks focus on individual components of mobile robot navigation, such as perception and state estimation, but the navigation performance as a whole is rarely measured in a systematic and standardized fashion. As a result, navigation systems are usually tested and compared in an ad hoc manner, such as in one or two manually chosen environments. The introduced benchmark provides a general testbed for ground robot navigation in a metric world. The Benchmark for Autonomous Robot Navigation (BARN) dataset includes 300 navigation environments, which are ordered by a set of difficulty metrics. Navigation performance can be tested and compared in those environments in a systematic and objective fashion. This benchmark can be used to predict navigation difficulty of a new environment, compare navigation systems, and potentially serve as a cost function and a curriculum for planning-based and learning-based navigation systems. We have published our dataset and the source code to generate datasets for different robot footprints at www.cs.utexas.edu/~attruong/metric_dataset.html.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1067.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1067.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BARN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Benchmark for Autonomous Robot Navigation (BARN) dataset</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standardized dataset of 300 procedurally generated 30x30-cell navigation environments and associated difficulty metrics, intended to benchmark metric ground navigation systems in simulation and real-world instantiations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BARN navigation environments (300)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>300 obstacle-occupied 30x30 discrete-grid environments generated by a cellular automaton (black/white cells) then converted to robot C-space (inflated for a 5x5-cell Jackal footprint). Start and goal are sampled from left and right edges and A* is used to compute a path; environments that are disconnected are discarded.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_measure</strong></td>
                            <td>Five path-aggregated difficulty metrics: (1) Distance to Closest Obstacle (averaged along path; units = cells; Table II min=1, max=10.20, mean=2.37, std=0.93), (2) Average Visibility (avg of 8-ray visibility per state; range 1–14, mean=4.42, std=1.64), (3) Dispersion (number of alternations in a 16-ray scan, averaged along path; range 0–12, mean=4.35, std=0.89), (4) Characteristic Dimension (minimum-axis visibility from 8 axes, averaged along path; range 0–20, mean=4.05, std=2.66), and (5) Tortuosity (arc/chord ratio over whole path; range 1–1.71, mean=1.21, std=0.14).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_level</strong></td>
                            <td>Spans low-to-high complexity across 300 environments; numeric ranges and means reported above (see Table II). Environments are explicitly ordered from easy to difficult for benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_measure</strong></td>
                            <td>Procedural generation variation: 12 cellular automaton parameter sets (initial fill percentage in {0.15,0.20,0.25,0.30}; smoothing iterations in {2,3,4}; fill threshold=5; clear threshold=1; neighborhood=8) × 25 repetitions = 300 distinct instances. Also original obstacle maps provided so C-spaces can be generated for other robot footprints.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_level</strong></td>
                            <td>High procedural variation (300 distinct generated environments produced by varying CA parameters and random seeds).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Normalized traversal time (seconds per meter, s/m) averaged across trials; variance of traversal time; 30-second penalty for failures.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Aggregate simulation: DWA 3.30 ± 0.50 s/m; E-Band 3.24 ± 0.38 s/m (means ± std over tested environments). 3000 simulation trials (5 trials per planner per environment). Function approximator prediction loss: 0.10 on normalized traversal time (≈0.50 s error for a 5 m path). Physical trials: 50 trials across 5 unseen environments; predicted difficulty vs physical normalized traversal time fitted slope ≈0.96.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_variation_relationship</strong></td>
                            <td>The paper does not present an explicit analytic trade-off between environment complexity and environment variation; rather it (a) orders environments by a learned difficulty measure derived from the five complexity metrics and (b) demonstrates that higher difficulty environments (complexity) correlate with higher variance in traversal time (performance variability) across planner runs. It also shows that different planners respond differently to increases in difficulty (variation across environments) — e.g., sampling-based DWA is more sensitive (higher variance and steeper performance degradation) than optimization-based E-Band.</td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>For the dataset itself: procedural generation via cellular automaton. For difficulty prediction model: supervised learning (neural network) trained on labels produced by 3000 simulation trials (average traversal time normalized by path length).</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_tested</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_results</strong></td>
                            <td>The learned difficulty predictor (neural network) trained on simulation labels was evaluated on 5 unseen real-world environments (instantiated with cardboard obstacles) and showed strong correlation between predicted difficulty and measured normalized traversal time (fitted slope ≈0.96, near-zero intercept), indicating transfer from simulation-labeled training to physical performance prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Difficulty predictor trained on 3000 labeled trials (10 trials per environment × 300 envs); achieved 0.10 normalized-traversal-time prediction loss (example: ~0.50 s error on a 5 m path).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BARN provides a procedurally varied benchmark (300 environments) together with five interpretable difficulty metrics; a simple neural network can combine these to predict normalized traversal time with modest error (0.10 normalized units); higher environment difficulty correlates with higher performance variance; sampling-based DWA shows higher variance and sensitivity to increased difficulty than optimization-based E-Band; predicted difficulty correlates with real-world performance across unseen physical environments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Benchmarking Metric Ground Navigation', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1067.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1067.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Jackal</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Clearpath Jackal (robot)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A small four-wheeled differential-drive outdoor/indoor ground robot used in simulation and physical trials to evaluate navigation planners and validate the difficulty predictor.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Clearpath Jackal</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A four-wheeled, differential-drive, nonholonomic ground robot platform; used here with classical navigation planners (DWA and E-Band); no learning algorithm applied to the robot controller in the presented experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_type</strong></td>
                            <td>physical robot (and simulated robot in Gazebo)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BARN simulated environments and 5 physical cardboard-instantiated environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Simulated: 300 procedurally-generated 30×30 grid C-spaces inflated for Jackal footprint (5×5 cells). Physical: five unseen environments built with cardboard boxes to approximate the generated obstacle maps; in physical trials planners did not have access to pre-built maps (unlike simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_measure</strong></td>
                            <td>Same five difficulty metrics computed in C-space along A*-planned path (see BARN entry).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_level</strong></td>
                            <td>Used across entire BARN range from easy to difficult; physical tests used five newly generated environments spanning a range of predicted difficulties.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_measure</strong></td>
                            <td>Simulation: 300 distinct instances; Physical: 5 unseen procedurally-generated instances. Variation arises from cellular automaton parameters and random seeds.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_level</strong></td>
                            <td>Simulation: high; Physical: small set (5) but intentionally unseen relative to training data.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Normalized traversal time (s/m), variance across trials, failure penalty (30 s).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Simulation aggregate for Jackal controllers: DWA 3.30 ± 0.50 s/m; E-Band 3.24 ± 0.38 s/m. Physical trials: 50 trials total; performance correlated with predicted difficulty (fitted slope ≈0.96).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_variation_relationship</strong></td>
                            <td>Physical trials confirm simulation-derived predicted difficulty generalizes: predicted difficulty correlates with measured normalized traversal time; DWA is observed to be more sensitive to increases in environment difficulty than E-Band (higher slope and variance).</td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>No learning control applied to Jackal for navigation in this paper — planners run with default parameters (DWA from manufacturer, E-Band default) in both simulation and real world.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_tested</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_results</strong></td>
                            <td>Jackal with planners executed in 5 real-world unseen environments; traversal time correlated with predictor's difficulty estimate (slope ≈0.96), validating generalization of the difficulty model from simulation to the real robot.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The Jackal served as a consistent embodied platform to show that simulation-based difficulty measures and learned predictors can transfer to real robot performance; DWA shows higher variance and greater sensitivity to difficulty than E-Band on the Jackal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Benchmarking Metric Ground Navigation', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1067.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1067.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DWA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamic Window Approach (DWA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used sampling-based local motion planner which samples linear/angular velocity commands and scores them by obstacle proximity, progress toward goal, and closeness to a global path; representative of sampling-based planners.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The dynamic window approach to collision avoidance</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>DWA planner controlling Jackal</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Sampling-based local planner (not a learned controller). Given an A*-provided global path, DWA samples velocity commands, scores them for safety and progress, and executes the best sample; stochastic sampling leads to nondeterministic behavior across trials.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_type</strong></td>
                            <td>planning algorithm executed on embodied agent (robot controller)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BARN simulated and physical environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operated on 300 procedurally generated C-spaces in simulation (with pre-built maps) and on 5 physical cardboard environments (no pre-built map in physical trials). Environments vary in obstacle density/tightness as controlled by cellular automaton parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_measure</strong></td>
                            <td>Responds to BARN's five difficulty metrics; paper reports normalized traversal time and variance as result measures.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_level</strong></td>
                            <td>Evaluated across entire BARN range from easy to difficult; performance degrades and variance increases with higher difficulty metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_measure</strong></td>
                            <td>Evaluated across 300 varied simulated environments and 5 unseen physical environments; sensitivity to environment variation observed via variance and slope of performance vs predicted difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_level</strong></td>
                            <td>High (in simulation across 300 envs); limited but unseen in physical test (5 envs).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Normalized traversal time (s/m), traversal-time variance, and failure count (with 30 s penalty).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Simulation: mean normalized traversal time 3.30 ± 0.50 s/m. DWA shows higher standard deviation than E-Band and greater sensitivity to increasing difficulty. Physical: in low-difficulty physical environments DWA performed better than E-Band without a pre-built map, but DWA's performance degrades faster as difficulty increases (reported slope ≈1.17 for DWA vs ≈0.74 for E-Band in physical tests).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_variation_relationship</strong></td>
                            <td>Paper reports that as environment difficulty (combined complexity metrics) increases, DWA exhibits increased mean traversal time and larger variance relative to E-Band; thus sampling-based planners are more sensitive to increases in environment complexity/variation.</td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>Not a learned planner in this study; default manufacturer parameters used. No learning-based tuning applied for DWA in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DWA (sampling-based) achieved similar mean traversal time to E-Band but with higher variance and greater sensitivity to environment difficulty; stochastic sampling contributes to nondeterministic performance, making DWA more affected by increases in environment complexity/variation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Benchmarking Metric Ground Navigation', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1067.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1067.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>E-Band</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Elastic Bands (E-Band)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An optimization-based local motion planner that deforms an initial trajectory using virtual bubbles repelled by obstacles to produce a smooth, collision-free path; representative of optimization-based planners.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Elastic bands: Connecting path planning and control</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>E-Band planner controlling Jackal</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Optimization-based local planner (not a learned controller). Starts from a global path and optimizes it by deforming an elastic-band-like trajectory under repulsive forces from obstacles; deterministic optimization behavior yields lower variance than sampling-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_type</strong></td>
                            <td>planning algorithm executed on embodied agent (robot controller)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BARN simulated and physical environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Same set of procedurally generated environments and physical cardboard instantiations as for DWA; environments vary in obstacle configuration and tightness.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_measure</strong></td>
                            <td>Same five difficulty metrics from BARN; performance measured via normalized traversal time and variance.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_level</strong></td>
                            <td>Evaluated across entire BARN spectrum; performance degrades with higher difficulty but less sensitively than DWA.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_measure</strong></td>
                            <td>Evaluated across 300 simulated environments and 5 unseen physical environments; shown to have smaller performance variance across environment variation compared to DWA.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_level</strong></td>
                            <td>High in simulation; limited but tested for generalization in physical trials.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Normalized traversal time (s/m), variance, failure penalty.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Simulation: mean normalized traversal time 3.24 ± 0.38 s/m. Physical: in low-difficulty physical environments E-Band performed worse than DWA without pre-built maps, but overall E-Band exhibits less sensitivity as difficulty increases (reported physical-test slope ≈0.74 vs DWA ≈1.17).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_variation_relationship</strong></td>
                            <td>E-Band demonstrates more stable performance (lower variance) across increasing environment difficulty compared to sampling-based DWA; optimization-based methods may be more robust to environment-induced variation in this benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>Not a learned planner here; default E-Band parameters used, with velocity caps matched to DWA for fair comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_tested</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>E-Band (optimization-based) achieved slightly better or similar mean traversal times with lower variance relative to DWA and was less sensitive to increases in environment difficulty, indicating robustness to environment complexity/variation in the tested scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Benchmarking Metric Ground Navigation', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1067.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1067.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of embodied learning systems or agents operating in environments with varying levels of complexity and variation, including performance metrics, trade-offs, and relationships between environment complexity and environment variation.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DifficultyNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-network difficulty function approximator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A supervised two-layer fully connected neural network used to map the five difficulty metrics to a predicted normalized traversal time (combined difficulty measure).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>difficulty-predictor neural network</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A supervised regression model (two fully connected layers, 64 neurons each) trained on labels equal to average traversal time normalized by path length from 3000 simulation trials; inputs are the five normalized difficulty metrics (Distance to Closest Obstacle, Average Visibility, Dispersion, Characteristic Dimension, Tortuosity).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_type</strong></td>
                            <td>learned function approximator (non-embodied model used to predict difficulty of embodied tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>BARN navigation environments (training on 300 simulated envs; tested on unseen physical envs)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Trained on the full variation of BARN (300 environments × trials); tested on 5 physically instantiated unseen environments.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_measure</strong></td>
                            <td>Inputs are the five path-aggregated difficulty metrics; metrics normalized by mean and std before training (see Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_level</strong></td>
                            <td>Model trained across full complexity spectrum present in BARN (numeric ranges in Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>variation_measure</strong></td>
                            <td>Trained on labels aggregated from 3000 trials across 300 varied environments; tested on 5 unseen physical environments to measure generalization across environment variation.</td>
                        </tr>
                        <tr>
                            <td><strong>variation_level</strong></td>
                            <td>High training variation (300 distinct environments); limited test variation (5 real-world instances) but unseen during training.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Prediction loss on normalized traversal time (regression error); correlation (slope) between predicted difficulty and measured normalized traversal time in physical tests.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Prediction loss: 0.10 (normalized traversal time units). Interpreted as ≈0.50 s error for a 5 m path. Physical-test correlation slope ≈0.96 (near-unity), indicating strong predictive alignment with real-world performance.</td>
                        </tr>
                        <tr>
                            <td><strong>complexity_variation_relationship</strong></td>
                            <td>Model implicitly encodes relationships among the five complexity metrics and maps them to expected traversal time; paper reports that the learned mapping successfully orders environments by difficulty and generalizes to unseen real-world instances, but does not explicitly decompose interactions between environment complexity and environment variation beyond predictive performance and observed increased variance in harder environments.</td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>high_complexity_high_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>low_complexity_low_variation_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>Supervised regression training on 3000 simulation-labeled examples (normalized metric inputs and normalized traversal-time targets). Two fully connected layers (64 neurons each).</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_tested</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_results</strong></td>
                            <td>Tested on 5 unseen physical environments (50 real-world trials); predicted difficulty correlated strongly with measured normalized traversal time (fitted slope ≈0.96), demonstrating transfer from simulation-labeled training to real robot performance prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Trained with 3000 labeled trials. Achieved 0.10 normalized-traversal-time loss; example interpretation: ≈0.5 s error on 5 m path.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A modest-capacity neural network can combine multiple interpretable metrics to produce a reliable predictive difficulty measure; this predictor generalizes from simulation labels to real-world trials and can be used as a cost function or curriculum for planning- and learning-based navigation systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Benchmarking Metric Ground Navigation', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Elastic bands: Connecting path planning and control <em>(Rating: 2)</em></li>
                <li>The dynamic window approach to collision avoidance <em>(Rating: 2)</em></li>
                <li>Risk-aware path and motion planning for a tethered aerial visual assistant in unstructured or confined environments <em>(Rating: 1)</em></li>
                <li>A machine learning approach to visual perception of forest trails for mobile robots <em>(Rating: 1)</em></li>
                <li>From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1067",
    "paper_id": "paper-9da2c718df4711af9dda03e4238c3d2b31e129d6",
    "extraction_schema_id": "extraction-schema-24",
    "extracted_data": [
        {
            "name_short": "BARN",
            "name_full": "Benchmark for Autonomous Robot Navigation (BARN) dataset",
            "brief_description": "A standardized dataset of 300 procedurally generated 30x30-cell navigation environments and associated difficulty metrics, intended to benchmark metric ground navigation systems in simulation and real-world instantiations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": null,
            "agent_description": null,
            "agent_type": null,
            "environment_name": "BARN navigation environments (300)",
            "environment_description": "300 obstacle-occupied 30x30 discrete-grid environments generated by a cellular automaton (black/white cells) then converted to robot C-space (inflated for a 5x5-cell Jackal footprint). Start and goal are sampled from left and right edges and A* is used to compute a path; environments that are disconnected are discarded.",
            "complexity_measure": "Five path-aggregated difficulty metrics: (1) Distance to Closest Obstacle (averaged along path; units = cells; Table II min=1, max=10.20, mean=2.37, std=0.93), (2) Average Visibility (avg of 8-ray visibility per state; range 1–14, mean=4.42, std=1.64), (3) Dispersion (number of alternations in a 16-ray scan, averaged along path; range 0–12, mean=4.35, std=0.89), (4) Characteristic Dimension (minimum-axis visibility from 8 axes, averaged along path; range 0–20, mean=4.05, std=2.66), and (5) Tortuosity (arc/chord ratio over whole path; range 1–1.71, mean=1.21, std=0.14).",
            "complexity_level": "Spans low-to-high complexity across 300 environments; numeric ranges and means reported above (see Table II). Environments are explicitly ordered from easy to difficult for benchmarking.",
            "variation_measure": "Procedural generation variation: 12 cellular automaton parameter sets (initial fill percentage in {0.15,0.20,0.25,0.30}; smoothing iterations in {2,3,4}; fill threshold=5; clear threshold=1; neighborhood=8) × 25 repetitions = 300 distinct instances. Also original obstacle maps provided so C-spaces can be generated for other robot footprints.",
            "variation_level": "High procedural variation (300 distinct generated environments produced by varying CA parameters and random seeds).",
            "performance_metric": "Normalized traversal time (seconds per meter, s/m) averaged across trials; variance of traversal time; 30-second penalty for failures.",
            "performance_value": "Aggregate simulation: DWA 3.30 ± 0.50 s/m; E-Band 3.24 ± 0.38 s/m (means ± std over tested environments). 3000 simulation trials (5 trials per planner per environment). Function approximator prediction loss: 0.10 on normalized traversal time (≈0.50 s error for a 5 m path). Physical trials: 50 trials across 5 unseen environments; predicted difficulty vs physical normalized traversal time fitted slope ≈0.96.",
            "complexity_variation_relationship": "The paper does not present an explicit analytic trade-off between environment complexity and environment variation; rather it (a) orders environments by a learned difficulty measure derived from the five complexity metrics and (b) demonstrates that higher difficulty environments (complexity) correlate with higher variance in traversal time (performance variability) across planner runs. It also shows that different planners respond differently to increases in difficulty (variation across environments) — e.g., sampling-based DWA is more sensitive (higher variance and steeper performance degradation) than optimization-based E-Band.",
            "high_complexity_low_variation_performance": null,
            "low_complexity_high_variation_performance": null,
            "high_complexity_high_variation_performance": null,
            "low_complexity_low_variation_performance": null,
            "training_strategy": "For the dataset itself: procedural generation via cellular automaton. For difficulty prediction model: supervised learning (neural network) trained on labels produced by 3000 simulation trials (average traversal time normalized by path length).",
            "generalization_tested": true,
            "generalization_results": "The learned difficulty predictor (neural network) trained on simulation labels was evaluated on 5 unseen real-world environments (instantiated with cardboard obstacles) and showed strong correlation between predicted difficulty and measured normalized traversal time (fitted slope ≈0.96, near-zero intercept), indicating transfer from simulation-labeled training to physical performance prediction.",
            "sample_efficiency": "Difficulty predictor trained on 3000 labeled trials (10 trials per environment × 300 envs); achieved 0.10 normalized-traversal-time prediction loss (example: ~0.50 s error on a 5 m path).",
            "key_findings": "BARN provides a procedurally varied benchmark (300 environments) together with five interpretable difficulty metrics; a simple neural network can combine these to predict normalized traversal time with modest error (0.10 normalized units); higher environment difficulty correlates with higher performance variance; sampling-based DWA shows higher variance and sensitivity to increased difficulty than optimization-based E-Band; predicted difficulty correlates with real-world performance across unseen physical environments.",
            "uuid": "e1067.0",
            "source_info": {
                "paper_title": "Benchmarking Metric Ground Navigation",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "Jackal",
            "name_full": "Clearpath Jackal (robot)",
            "brief_description": "A small four-wheeled differential-drive outdoor/indoor ground robot used in simulation and physical trials to evaluate navigation planners and validate the difficulty predictor.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Clearpath Jackal",
            "agent_description": "A four-wheeled, differential-drive, nonholonomic ground robot platform; used here with classical navigation planners (DWA and E-Band); no learning algorithm applied to the robot controller in the presented experiments.",
            "agent_type": "physical robot (and simulated robot in Gazebo)",
            "environment_name": "BARN simulated environments and 5 physical cardboard-instantiated environments",
            "environment_description": "Simulated: 300 procedurally-generated 30×30 grid C-spaces inflated for Jackal footprint (5×5 cells). Physical: five unseen environments built with cardboard boxes to approximate the generated obstacle maps; in physical trials planners did not have access to pre-built maps (unlike simulation).",
            "complexity_measure": "Same five difficulty metrics computed in C-space along A*-planned path (see BARN entry).",
            "complexity_level": "Used across entire BARN range from easy to difficult; physical tests used five newly generated environments spanning a range of predicted difficulties.",
            "variation_measure": "Simulation: 300 distinct instances; Physical: 5 unseen procedurally-generated instances. Variation arises from cellular automaton parameters and random seeds.",
            "variation_level": "Simulation: high; Physical: small set (5) but intentionally unseen relative to training data.",
            "performance_metric": "Normalized traversal time (s/m), variance across trials, failure penalty (30 s).",
            "performance_value": "Simulation aggregate for Jackal controllers: DWA 3.30 ± 0.50 s/m; E-Band 3.24 ± 0.38 s/m. Physical trials: 50 trials total; performance correlated with predicted difficulty (fitted slope ≈0.96).",
            "complexity_variation_relationship": "Physical trials confirm simulation-derived predicted difficulty generalizes: predicted difficulty correlates with measured normalized traversal time; DWA is observed to be more sensitive to increases in environment difficulty than E-Band (higher slope and variance).",
            "high_complexity_low_variation_performance": null,
            "low_complexity_high_variation_performance": null,
            "high_complexity_high_variation_performance": null,
            "low_complexity_low_variation_performance": null,
            "training_strategy": "No learning control applied to Jackal for navigation in this paper — planners run with default parameters (DWA from manufacturer, E-Band default) in both simulation and real world.",
            "generalization_tested": true,
            "generalization_results": "Jackal with planners executed in 5 real-world unseen environments; traversal time correlated with predictor's difficulty estimate (slope ≈0.96), validating generalization of the difficulty model from simulation to the real robot.",
            "sample_efficiency": null,
            "key_findings": "The Jackal served as a consistent embodied platform to show that simulation-based difficulty measures and learned predictors can transfer to real robot performance; DWA shows higher variance and greater sensitivity to difficulty than E-Band on the Jackal.",
            "uuid": "e1067.1",
            "source_info": {
                "paper_title": "Benchmarking Metric Ground Navigation",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "DWA",
            "name_full": "Dynamic Window Approach (DWA)",
            "brief_description": "A widely-used sampling-based local motion planner which samples linear/angular velocity commands and scores them by obstacle proximity, progress toward goal, and closeness to a global path; representative of sampling-based planners.",
            "citation_title": "The dynamic window approach to collision avoidance",
            "mention_or_use": "use",
            "agent_name": "DWA planner controlling Jackal",
            "agent_description": "Sampling-based local planner (not a learned controller). Given an A*-provided global path, DWA samples velocity commands, scores them for safety and progress, and executes the best sample; stochastic sampling leads to nondeterministic behavior across trials.",
            "agent_type": "planning algorithm executed on embodied agent (robot controller)",
            "environment_name": "BARN simulated and physical environments",
            "environment_description": "Operated on 300 procedurally generated C-spaces in simulation (with pre-built maps) and on 5 physical cardboard environments (no pre-built map in physical trials). Environments vary in obstacle density/tightness as controlled by cellular automaton parameters.",
            "complexity_measure": "Responds to BARN's five difficulty metrics; paper reports normalized traversal time and variance as result measures.",
            "complexity_level": "Evaluated across entire BARN range from easy to difficult; performance degrades and variance increases with higher difficulty metrics.",
            "variation_measure": "Evaluated across 300 varied simulated environments and 5 unseen physical environments; sensitivity to environment variation observed via variance and slope of performance vs predicted difficulty.",
            "variation_level": "High (in simulation across 300 envs); limited but unseen in physical test (5 envs).",
            "performance_metric": "Normalized traversal time (s/m), traversal-time variance, and failure count (with 30 s penalty).",
            "performance_value": "Simulation: mean normalized traversal time 3.30 ± 0.50 s/m. DWA shows higher standard deviation than E-Band and greater sensitivity to increasing difficulty. Physical: in low-difficulty physical environments DWA performed better than E-Band without a pre-built map, but DWA's performance degrades faster as difficulty increases (reported slope ≈1.17 for DWA vs ≈0.74 for E-Band in physical tests).",
            "complexity_variation_relationship": "Paper reports that as environment difficulty (combined complexity metrics) increases, DWA exhibits increased mean traversal time and larger variance relative to E-Band; thus sampling-based planners are more sensitive to increases in environment complexity/variation.",
            "high_complexity_low_variation_performance": null,
            "low_complexity_high_variation_performance": null,
            "high_complexity_high_variation_performance": null,
            "low_complexity_low_variation_performance": null,
            "training_strategy": "Not a learned planner in this study; default manufacturer parameters used. No learning-based tuning applied for DWA in experiments.",
            "generalization_tested": false,
            "generalization_results": null,
            "sample_efficiency": null,
            "key_findings": "DWA (sampling-based) achieved similar mean traversal time to E-Band but with higher variance and greater sensitivity to environment difficulty; stochastic sampling contributes to nondeterministic performance, making DWA more affected by increases in environment complexity/variation.",
            "uuid": "e1067.2",
            "source_info": {
                "paper_title": "Benchmarking Metric Ground Navigation",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "E-Band",
            "name_full": "Elastic Bands (E-Band)",
            "brief_description": "An optimization-based local motion planner that deforms an initial trajectory using virtual bubbles repelled by obstacles to produce a smooth, collision-free path; representative of optimization-based planners.",
            "citation_title": "Elastic bands: Connecting path planning and control",
            "mention_or_use": "use",
            "agent_name": "E-Band planner controlling Jackal",
            "agent_description": "Optimization-based local planner (not a learned controller). Starts from a global path and optimizes it by deforming an elastic-band-like trajectory under repulsive forces from obstacles; deterministic optimization behavior yields lower variance than sampling-based methods.",
            "agent_type": "planning algorithm executed on embodied agent (robot controller)",
            "environment_name": "BARN simulated and physical environments",
            "environment_description": "Same set of procedurally generated environments and physical cardboard instantiations as for DWA; environments vary in obstacle configuration and tightness.",
            "complexity_measure": "Same five difficulty metrics from BARN; performance measured via normalized traversal time and variance.",
            "complexity_level": "Evaluated across entire BARN spectrum; performance degrades with higher difficulty but less sensitively than DWA.",
            "variation_measure": "Evaluated across 300 simulated environments and 5 unseen physical environments; shown to have smaller performance variance across environment variation compared to DWA.",
            "variation_level": "High in simulation; limited but tested for generalization in physical trials.",
            "performance_metric": "Normalized traversal time (s/m), variance, failure penalty.",
            "performance_value": "Simulation: mean normalized traversal time 3.24 ± 0.38 s/m. Physical: in low-difficulty physical environments E-Band performed worse than DWA without pre-built maps, but overall E-Band exhibits less sensitivity as difficulty increases (reported physical-test slope ≈0.74 vs DWA ≈1.17).",
            "complexity_variation_relationship": "E-Band demonstrates more stable performance (lower variance) across increasing environment difficulty compared to sampling-based DWA; optimization-based methods may be more robust to environment-induced variation in this benchmark.",
            "high_complexity_low_variation_performance": null,
            "low_complexity_high_variation_performance": null,
            "high_complexity_high_variation_performance": null,
            "low_complexity_low_variation_performance": null,
            "training_strategy": "Not a learned planner here; default E-Band parameters used, with velocity caps matched to DWA for fair comparison.",
            "generalization_tested": false,
            "generalization_results": null,
            "sample_efficiency": null,
            "key_findings": "E-Band (optimization-based) achieved slightly better or similar mean traversal times with lower variance relative to DWA and was less sensitive to increases in environment difficulty, indicating robustness to environment complexity/variation in the tested scenarios.",
            "uuid": "e1067.3",
            "source_info": {
                "paper_title": "Benchmarking Metric Ground Navigation",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "DifficultyNet",
            "name_full": "Neural-network difficulty function approximator",
            "brief_description": "A supervised two-layer fully connected neural network used to map the five difficulty metrics to a predicted normalized traversal time (combined difficulty measure).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "difficulty-predictor neural network",
            "agent_description": "A supervised regression model (two fully connected layers, 64 neurons each) trained on labels equal to average traversal time normalized by path length from 3000 simulation trials; inputs are the five normalized difficulty metrics (Distance to Closest Obstacle, Average Visibility, Dispersion, Characteristic Dimension, Tortuosity).",
            "agent_type": "learned function approximator (non-embodied model used to predict difficulty of embodied tasks)",
            "environment_name": "BARN navigation environments (training on 300 simulated envs; tested on unseen physical envs)",
            "environment_description": "Trained on the full variation of BARN (300 environments × trials); tested on 5 physically instantiated unseen environments.",
            "complexity_measure": "Inputs are the five path-aggregated difficulty metrics; metrics normalized by mean and std before training (see Table II).",
            "complexity_level": "Model trained across full complexity spectrum present in BARN (numeric ranges in Table II).",
            "variation_measure": "Trained on labels aggregated from 3000 trials across 300 varied environments; tested on 5 unseen physical environments to measure generalization across environment variation.",
            "variation_level": "High training variation (300 distinct environments); limited test variation (5 real-world instances) but unseen during training.",
            "performance_metric": "Prediction loss on normalized traversal time (regression error); correlation (slope) between predicted difficulty and measured normalized traversal time in physical tests.",
            "performance_value": "Prediction loss: 0.10 (normalized traversal time units). Interpreted as ≈0.50 s error for a 5 m path. Physical-test correlation slope ≈0.96 (near-unity), indicating strong predictive alignment with real-world performance.",
            "complexity_variation_relationship": "Model implicitly encodes relationships among the five complexity metrics and maps them to expected traversal time; paper reports that the learned mapping successfully orders environments by difficulty and generalizes to unseen real-world instances, but does not explicitly decompose interactions between environment complexity and environment variation beyond predictive performance and observed increased variance in harder environments.",
            "high_complexity_low_variation_performance": null,
            "low_complexity_high_variation_performance": null,
            "high_complexity_high_variation_performance": null,
            "low_complexity_low_variation_performance": null,
            "training_strategy": "Supervised regression training on 3000 simulation-labeled examples (normalized metric inputs and normalized traversal-time targets). Two fully connected layers (64 neurons each).",
            "generalization_tested": true,
            "generalization_results": "Tested on 5 unseen physical environments (50 real-world trials); predicted difficulty correlated strongly with measured normalized traversal time (fitted slope ≈0.96), demonstrating transfer from simulation-labeled training to real robot performance prediction.",
            "sample_efficiency": "Trained with 3000 labeled trials. Achieved 0.10 normalized-traversal-time loss; example interpretation: ≈0.5 s error on 5 m path.",
            "key_findings": "A modest-capacity neural network can combine multiple interpretable metrics to produce a reliable predictive difficulty measure; this predictor generalizes from simulation labels to real-world trials and can be used as a cost function or curriculum for planning- and learning-based navigation systems.",
            "uuid": "e1067.4",
            "source_info": {
                "paper_title": "Benchmarking Metric Ground Navigation",
                "publication_date_yy_mm": "2020-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Elastic bands: Connecting path planning and control",
            "rating": 2
        },
        {
            "paper_title": "The dynamic window approach to collision avoidance",
            "rating": 2
        },
        {
            "paper_title": "Risk-aware path and motion planning for a tethered aerial visual assistant in unstructured or confined environments",
            "rating": 1
        },
        {
            "paper_title": "A machine learning approach to visual perception of forest trails for mobile robots",
            "rating": 1
        },
        {
            "paper_title": "From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots",
            "rating": 1
        }
    ],
    "cost": 0.0146565,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Benchmarking Metric Ground Navigation</h1>
<p>Daniel Perille ${ }^{1}$, Abigail Truong ${ }^{1}$, Xuesu Xiao ${ }^{1}$, and Peter Stone ${ }^{1}$</p>
<h4>Abstract</h4>
<p>Metric ground navigation addresses the problem of autonomously moving a robot from one point to another in an obstacle-occupied planar environment in a collision-free manner. It is one of the most fundamental capabilities of intelligent mobile robots. This paper presents a standardized testbed with a set of environments and metrics to benchmark difficulty of different scenarios and performance of different systems of metric ground navigation. Current benchmarks focus on individual components of mobile robot navigation, such as perception and state estimation, but the navigation performance as a whole is rarely measured in a systematic and standardized fashion. As a result, navigation systems are usually tested and compared in an ad hoc manner, such as in one or two manually chosen environments. The introduced benchmark provides a general testbed for ground robot navigation in a metric world. The Benchmark for Autonomous Robot Navigation (BARN) dataset includes 300 navigation environments, which are ordered by a set of difficulty metrics. Navigation performance can be tested and compared in those environments in a systematic and objective fashion. This benchmark can be used to predict navigation difficulty of a new environment, compare navigation systems, and potentially serve as a cost function and a curriculum for planning-based and learningbased navigation systems. We have published our dataset and the source code to generate datasets for different robot footprints at www.cs.utexas.edu/ xiao/BARN/BARN.html.</p>
<h2>I. INTRODUCTION</h2>
<p>Autonomously moving from one point to another, especially in challenging environments, is one essential capability of intelligent mobile robots. This problem of mobile robot navigation has been studied by the robotics community for decades [1]-[3]. Sophisticated navigation systems have been developed using classical control methods [3]-[5], path and motion planning [1], [2], [6], or, more recently, machine learning techniques [7]-[11].</p>
<p>However, despite the plethora of works in mobile robot navigation, there is no generally accepted metric by which to compare different approaches against one another, even for navigation in a simple metric world, where only geometric obstacles are considered. Although in relatively open space, navigation performance of different systems may not vary significantly, the lack of an accepted metric becomes particularly relevant in environments that are more difficult to navigate. Those environments include, for example, unstructured or confined spaces for search and rescue [12] and highly constrained spaces where agile maneuvers are required for robots with nonholonomic motion constraints [10]. Newly</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>developed navigation systems are only tested and compared to existing ones in a limited number of ad hoc environments with unquantified difficulties.</p>
<p>To address the lack of a standardized method to test and compare mobile robot navigation systems, this work provides a Benchmark for Autonomous Robot Navigation (BARN) of 300 simulated test environments, which can also be easily instantiated in the physical world. We design a set of metrics to quantify navigation difficulty of these simulated environments for ground mobile robots to move in obstacleoccupied spaces without collision. We then unify this set of metrics via a learned function approximator to introduce a novel measure of an environment's difficulty level for metric ground navigation. Through an extensive amount of 3000 simulated trials using two widely used planners, Dynamic Window Approach (DWA) [2] and Elastic Bands (E-Band) [1], we benchmark the relative difficulty levels for the test environments. We also run multiple physical navigation trials to validate our model's predictive power of navigation difficulty. To summarize, the main contributions of this work are:</p>
<ul>
<li>A benchmark dataset (BARN) of 300 simulated test environments for metric ground navigation,</li>
<li>A set of metrics and a data-driven model to combine them to quantify the challenge posed by a particular environment for mobile robot navigation.
The rest of the paper is organized as follows: Section II reviews existing benchmarks related to mobile robot navigation. Section III describes our method of constructing BARN, including the test environments, the set of difficulty metrics, and the data-driven model to combine them. Section IV provides implementation details and experiment results to validate that the proposed difficulty metrics and the learned function approximator can predict navigation difficulties using a physical mobile robot in the real world. Section V concludes the paper.</li>
</ul>
<h2>II. RELATED WORK</h2>
<p>This section reviews existing testbeds and metrics related to mobile robot navigation.</p>
<h2>A. Testbeds</h2>
<p>Testbeds are designed as an apparatus to quantify performance based on a set of pre-defined metrics. The tests can be replicated when following a standardized testing procedure.</p>
<p>1) Physical Testbeds: National Institute of Standards and Technology (NIST) has created standard testbeds for response robots, including ground, aerial, and aquatic vehicles [13]. Specialized test methods are developed to test</p>
<p>individual robot capacity, e.g. locomotion, sensing, communication, durability. Robotarium [14] is a testbed developed to test algorithms for multi-robot research, using a fleet of miniature differential drive robots. Xiao et al [15] reviewed 20 physical testbeds for snake robots and pointed out that all of them are designed in an ad hoc manner, i.e. tailored to demonstrate the newly developed capability. They also provided suggestions on a general testbed design. The research thrust on developing robot testbeds demonstrates the robotics community’s need for standardized test methods to quantify robot performance and research progress. Similar to the aforementioned testbeds but with a different purpose, the proposed testbed is developed to benchmark mobile robot navigation systems operating in a metric world.
2) Software Testbeds: Thanks to the recent progress on data-driven approaches, testbeds are frequently instantiated as datasets, e.g. ImageNet [16]. In the mobile robot navigation domain, especially on the perception and estimation side, many such software testbeds have also been created [17][20], where perceptual data is collected along a fixed motion trajectory. However, when arbitrary motion execution is required, such interactive testbeds become sparse. Even when motion is allowed [21], [22], the locomotion part of navigation is assumed to be trivial, i.e. the testbeds only benchmark the robot’s ability to infer “where” to navigate, instead of to generate feasible and optimal motion commands for “how” to navigate. The proposed testbed focuses on the ability to autonomously generate viable motion commands in order to navigate between two fixed points in a given environment. Since only geometric obstacles are considered, it can easily be instantiated into a physical testbed.</p>
<h2>B. Metrics</h2>
<p>A common metric to quantify mobile robot navigation difficulty is distance from points on the path to the closest obstacle [23], [24], as the closer the robot needs to come to an obstacle, the more difficult the navigation task. Past experiences (e.g. previous failure cases) have also been utilized to quantify difficulty as a function of a single state when navigating in the ocean [25] or in city traffic [26]. Not many works considered more than one single source of difficulty: Soltani et al. [27] represented difficulty with both distance to closest obstacle and visibility of a particular location and combined their effects using manually defined weights. Robot motion risk can also be viewed as an indication of difficulty: recent risk reasoning frameworks extended the dependency of risk associated with a certain state into motion history [12], [28], and pointed out that difficulty/risk caused by, for example, turning or dragging a tether, cannot be determined by a single state alone. The multiple difficulty metrics designed in this work are inspired by the risk universe [12]. In order to determine the combined effect of all individual elements, we use a datadriven approach instead of manually assigned weights.</p>
<h2>III. APPROACH</h2>
<p>In this section, we describe our method of constructing BARN. The navigation environments are first generated using cellular automaton [29], for which navigational paths are planned on the robot Configuration Space (C-Space) [30]. Second, we introduce a set of metrics used to quantify navigation difficulty level. Third, a function approximator is learned in a data-driven manner to combine these difficulty metrics and determine the final difficulty level of navigating through a specific environment.</p>
<h2>A. Navigation Environments</h2>
<p>Navigation environments are systematically generated through the method of cellular automaton [29]. A cellular automaton was originally designed as a collection of black cells on a white grid of specified shape that evolves through a number of discrete time steps according to a set of rules based on the states of neighboring cells [29]. In this work, we use black cells to represent obstacle-occupied space and white cells to represent free space. The evolution of the black cells generates different obstacle configurations. Cellular automaton is easy to scale to any size, generates more realistic environments than random fill, and is also easily customizable due to its parameters that can be changed to generate different types of worlds. Due to the smoothing iterations, the resulting grid resembles real-world obstacles more than the initial randomly filled grid does. We use four parameters of the cellular automaton to control the generation of obstacles: initial fill percentage, smoothing iterations, fill threshold, and clear threshold. The procedure to generate navigation environments using cellular automaton is provided in Algorithm 1, with an example in Figure 1.</p>
<div class="codehilite"><pre><span></span><code><span class="nv">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="nv">Navigation</span><span class="w"> </span><span class="nv">Environments</span><span class="w"> </span><span class="nv">Generation</span>
<span class="mi">1</span>:<span class="w"> </span><span class="nv">Inputs</span>:<span class="w"> </span><span class="nv">m</span>,<span class="w"> </span><span class="nv">n</span>,<span class="w"> </span><span class="nv">initial</span><span class="w"> </span><span class="nv">fill</span><span class="w"> </span><span class="nv">percentage</span>,<span class="w"> </span><span class="nv">smoothing</span><span class="w"> </span><span class="nv">itera</span><span class="o">-</span>
<span class="w">    </span><span class="nv">fill</span><span class="w"> </span><span class="nv">threshold</span>,<span class="w"> </span><span class="nv">clear</span><span class="w"> </span><span class="nv">threshold</span>,
<span class="mi">2</span>:<span class="w"> </span><span class="nv">Randomly</span><span class="w"> </span><span class="nv">fill</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="nv">m</span><span class="w"> </span>\<span class="nv">times</span><span class="w"> </span><span class="nv">n</span><span class="w"> </span><span class="nv">grid</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="mi">0</span><span class="err">&#39;s with initial fill</span>
<span class="w">    </span><span class="nv">percentage</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="mi">1</span><span class="err">&#39;s</span>
<span class="err">    for iteration k=1: smoothing iterations do</span>
<span class="err">        for cell in grid do</span>
<span class="err">            if |FilledNeighbors(cell)| \geq fill threshold then</span>
<span class="err">                cell \leftarrow1</span>
<span class="err">            end if</span>
<span class="err">            if |FilledNeighbors(cell)| \leq clear threshold then</span>
<span class="err">                cell \leftarrow 0</span>
<span class="err">            end if</span>
<span class="err">        end for</span>
<span class="err">2: end for</span>
</code></pre></div>

<p>Each obstacle grid is then converted into the robot’s Cspace based on the robot dimension. In the C-space, one free point on both the left and right edge are chosen at random to be the start and end points of the path, respectively. A flood-fill algorithm [31] is used to determine if there is an open path between the points. If no path is possible, then the space is discarded. A* algorithm [32] is then used to plan a path in the free C-space.</p>
<h3>III-B Difficulty Metrics</h3>
<p>Upon generating an environment through cellular automaton and establishing a path therein, various metrics are calculated in the C-space along the path to quantify the difficulty of traversal.</p>
<p>1) Distance to Closest Obstacle: At each cell in the environment, the Distance to Closest Obstacle is defined as the distance from this cell to the nearest occupied space. This metric is averaged over all points in the path.</p>
<p>2) Average Visibility: A cell’s Average Visibility is defined as the average of the distances to an obstacle along each ray in a $360^{\circ}$ scan. In our discrete space, we average the visibility along eight rays (four cardinal directions and four diagonals), then average this metric over all points in the path. Figure 2 provides examples of high and low visibility.</p>
<p>3) Dispersion: From a given state in the environment, a $360^{\circ}$ scan is cast up to a certain max length. The dispersion at that state is defined as the number of alternations in that scan from occupied to unoccupied space or vice versa, as shown in Figure 3.</p>
<p>Dispersion captures the number of potential paths out of a given location. A higher dispersion means more possible options for the navigation algorithm and therefore means the environment poses more challenges, especially for a sampling-based local planner, like DWA [2]. In our discrete space, dispersion is calculated by casting 16 rays up to a max length, and checking which are blocked or open. This metric is calculated for each point in the path and averaged over the length of the path.</p>
<p>4) Characteristic Dimension: The Characteristic Dimension at a given cell is defined as the visibility of the axis through the cell with the lowest visibility. In our discrete space, 8 axes (each made up of 2 rays $180^{\circ}$ apart) are cast $22.5^{\circ}$ apart from one another. Each axis’ visibility is calculated as the sum of the distances to an obstacle along both of the rays that make it up. The Characteristic Dimension is defined as the visibility of the axis with the lowest visibility. The Characteristic Dimension captures the tightness of a space. A low Distance to Closest Obstacle could occur in a relatively open space and therefore still be quite easy to navigate. Additionally, a space might be tight along one axis yet very open along another (e.g. a long tunnel) and therefore have a high Average Visibility despite being narrow. Figure 4 captures such an instance of when Distance to Closest Obstacle and Average Visibility may fail to completely represent the difficulty of a space.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Three smoothing iterations of a cellular automaton with an initial fill percentage of 0.35, fill threshold of 5, and clear threshold of 1</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. An example of high and low Average Visibility</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Dispersion represents the alternations from occupied to unoccupied space or vice versa.</p>
<p>5) Tortuosity: Tortuosity, as a property of a curve being tortuous, is calculated over the entire path using the arc-chord ratio. The arc length is the length of the entire path, while the chord length is the length of a straight line between the start and end points. This metric captures bends in the path that make navigation more difficult compared to navigation along a relatively straight path.</p>
<h3>III-C Combined Difficulty Level</h3>
<p>We first use a data-driven approach to benchmark the relative difficulty level of all the navigation environments in our dataset. Thousands of simulation trials using representative and widely-used navigation systems are conducted to reveal the actual difficulty of an environment. Second, to investigate how the difficulty metrics interact with each other and contribute to the combined difficulty measure, we learn a function approximator to map from the individual difficulty metrics to the final difficulty level of a given environment. This model can be used to predict difficulty of unseen navigation environments. Please refer to Section IV for details.</p>
<h2>IV EXPERIMENTS</h2>
<p>In this section, we present implementation details of our dataset generation and physical experiments using a ground robot to validate that our benchmark model can accurately predict the difficulty level of unseen physical navigation environments.</p>
<h3>IV-A Dataset Generation</h3>
<p>We use 12 sets of cellular automaton parameters to generate the 300 navigation environments of 30 by 30 cells in our dataset, shown in Table I. The parameters are chosen to generate varied worlds with reasonably realistic configurations. Each of those parameter sets is repeated 25 times. We use a Clearpath Jackal robot’s dimension (0.508m by 0.430m, corresponding to 5 by 5 cells) to inflate the obstacles and</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Characteristic Dimension captures the tightness of a state in an environment.</p>
<p>generate the C-spaces. We also provide the original obstacle map in the dataset so that C-spaces corresponding to different robot sizes can be generated by the users.</p>
<p><strong>TABLE I</strong></p>
<p><strong>CELLULAR AUTOMATON PARAMETERS</strong></p>
<table>
<thead>
<tr>
<th>Parameters</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>initial fill percentage</td>
<td>{0.15, 0.20, 0.25, 0.30}</td>
</tr>
<tr>
<td>smoothing iterations</td>
<td>{2, 3, 4}</td>
</tr>
<tr>
<td>fill threshold</td>
<td>5</td>
</tr>
<tr>
<td>clear threshold</td>
<td>1</td>
</tr>
<tr>
<td>neighborhood</td>
<td>8</td>
</tr>
<tr>
<td>Repetitions</td>
<td>25</td>
</tr>
</tbody>
</table>
<p>The minimum, maximum, mean, and standard deviation of the five difficulty metrics present in the dataset are shown in Table II. For a given cell, the minimum Distance to Closest Obstacle is 1 for an unoccupied space, and the maximum is 10.20. We cast eight rays to compute Average Visibility, resulting in a range from 1 to 14. The minimum dispersion is 0 (no alternations between occupied and unoccupied spaces along the 16 axes) and the maximum is 12. The minimum Characteristic Dimension is 0 (completely closed space) and the maximum is 20.00. The four metrics above are computed for and averaged over all states on a path. The minimum tortuosity of a path is 1 (straight line) and the maximum is 1.71.</p>
<p><strong>TABLE II</strong></p>
<p><strong>DIFFICULTY METRIC VALUES</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>Min.</th>
<th>Max.</th>
<th>Mean</th>
<th>Std.</th>
</tr>
</thead>
<tbody>
<tr>
<td>Distance to Closest Obstacle</td>
<td>1</td>
<td>10.20</td>
<td>2.37</td>
<td>0.93</td>
</tr>
<tr>
<td>Average Visibility</td>
<td>1</td>
<td>14.00</td>
<td>4.42</td>
<td>1.64</td>
</tr>
<tr>
<td>Dispersion</td>
<td>0</td>
<td>12</td>
<td>4.35</td>
<td>0.89</td>
</tr>
<tr>
<td>Characteristic Dimension</td>
<td>0</td>
<td>20.00</td>
<td>4.05</td>
<td>2.66</td>
</tr>
<tr>
<td>Tortuosity</td>
<td>1</td>
<td>1.71</td>
<td>1.21</td>
<td>0.14</td>
</tr>
</tbody>
</table>
<p>1) <strong>Simulation Trials:</strong> We use a simulated Clearpath Jackal, a four-wheeled, differential drive, nonholonomic ground robot, in a Robot Operating System (ROS) Gazebo simulator [33] to benchmark the relative difficulty levels of the navigation environments in our dataset.</p>
<p>We choose two different widely used navigation planners, DWA [2] and E-Band [1] to navigate Jackal. DWA is a representative sampling-based motion planner. Given a global path produced by the A* algorithm [32], DWA generates samples of linear and angular velocities and evaluates the score of each sample based on closeness to the obstacle, to the global path, and progress toward the local goal. The action sample with the best score is executed to move the robot. The randomness in the sampling process leads to nondeterministic behavior in the same environment. E-Band is a representative optimization-based motion planner, which optimizes an initial trajectory. It deforms the trajectory using virtual bubbles along it, which are subject to repulsive force from the obstacles. The optimized trajectory acts like an elastic band. The default navigation planner from the robot manufacturer, Clearpath Robotics, is the DWA planner. We use the default planner parameters from the manufacturer^{1} for DWA, and the default parameters from the E-Band designer^{2} for the E-Band planner. We set E-Band's maximum allowable linear and angular velocities (0.5m/s and 1.57rad/s) to match with those of DWA for a fair comparison.</p>
<p>For each one of the 300 environments in our dataset, a pre-built map is provided to the planner, and we run five trials each for DWA and E-Band, resulting in a total number of 3000 trials (Figure 5). The final difficulty measure is the traversal time averaged over the ten trials and normalized by path length. We also compute the variance of the traversal time. A 30-second penalty is introduced to trials where the robot fails to reach the goal, e.g. getting stuck. The DWA, E-Band, and combined (averaged) with predicted navigation performance is shown in Figure 6. From left to right, the 300 environments are ordered from easy to difficult. High difficulty level is correlated with high variance. Operating with a map, DWA and E-Band achieve an average normalized traversal time of 3.30 ± 0.50s/m and 3.24 ± 0.38s/m, respectively. As a sampling-based planner, DWA results in higher standard deviation than the optimization-based E-Band, and is more sensitive to the increased difficulty level.</p>
<p>2) <strong>Function Approximator:</strong> To approximate the combined effect of all five difficulty metrics, we use a simple neural network consisting of two fully connected layers with 64 neurons each. Distance to Closest Obstacle, Average Visibility, Dispersion, and Characteristic Dimension are computed for and averaged over all the states on a path. Tortuosity is computed for the entire path. All these metrics are normalized based on their mean and standard deviation (Table II). The label of the neural network output is the average traversal time normalized by path length, computed from the 3000 simulation trials. Our function approximator can achieve a 0.10 prediction loss on normalized traversal time, which corresponds to, for example, 0.50 seconds error while traversing a 5m long path.</p>
<h4>B. Physical Experiments</h4>
<p>To validate our benchmarks in the real world, we also conduct physical trials in unseen navigation environments. We use a physical Jackal with DWA and E-Band planners</p>
<p>^{1}https://github.com/jackal/jackal/tree/melodic-devel/jackal_navigation/params</p>
<p>^{2}http://wiki.ros.org/eband_local_planner</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5. Four Example Environments in Gazebo Simulation (ordered by ascending relative difficulty level)</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6. Environment Difficulty Benchmarked by Navigation Performance of DWA and E-Band</p>
<p>parameterized in the same way as in the simulation trials. Five new navigation environments are created using cellular automaton and instantiated in the real-world with cardboard boxes representing obstacles (Figure 7). We run five trials with each planner in each environment, resulting in a total of 50 physical trials. Unlike the simulated trials, the planners do not have access to a pre-built map. As shown in Figure 8, higher predicted difficulty corresponds to longer normalized traversal time (The fitted blue line has a slope of 0.96 and almost zero intercept). In physical environments with low difficulty, DWA performs better than E-Band without a pre-built map. However, the steeper slope of the green line (1.17) than that of the red line (0.74) indicates that DWA is more sensitive to increased difficulty level than E-Band is, which is a similar trend we observe in simulation.</p>
<h2>V. CONCLUSIONS</h2>
<p>We present a dataset<sup>3</sup> of 300 simulated navigation environments and five difficulty metrics along with a data-driven model to quantify the difficulty measure of a particular environment for mobile robot navigation. We benchmark the relative difficulty level using 3000 simulated navigation trials with two widely used navigation planners, DWA and E-Band, which are representative of sampling-based and optimization-based planners, respectively. Our model can predict the difficulty of unseen navigation environments based on the five difficulty metrics, i.e. Distance to Closest Obstacle, Average Visibility, Dispersion, Characteristic Dimension, and Tortuosity. 50 physical experiment trials demonstrate that the difficulty level predicted by our model corresponds to real-world performance in unseen environments. As a general testbed, metric ground navigation performance of different systems can be tested and compared with each other in a systematic and objective fashion. The difficulty metrics and the learned function approximator can be used as a new cost function and a curriculum for planning-based and learning-based navigation systems.</p>
<h2>ACKNOWLEDGMENT</h2>
<p>This work has taken place in the Learning Agents Research Group (LARG) at UT Austin. LARG research is supported in part by NSF (CPS-1739964, IIS-1724157, NRI-1925082), ONR (N00014-18-2243), FLI (RFP2-000), ARO (W911NF-19-2-0333), DARPA, Lockheed Martin, GM, and Bosch. Peter Stone serves as the Executive Director of Sony AI America and receives financial compensation for this work. The terms of this arrangement have been reviewed and approved by the University of Texas at Austin in accordance with its policy on objectivity in research.</p>
<h2>REFERENCES</h2>
<ul>
<li>[1] S. Quinlan and O. Khatib, "Elastic bands: Connecting path planning and control," in <em>[1993] Proceedings IEEE International Conference on Robotics and Automation</em>. IEEE, 1993, pp. 802–807.</li>
<li>[2] www.cs.utexas.edu/~attruong/metrics_dataset.html</li>
</ul>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7. For each of the five physical navigation environments, five DWA and five E-Band trials are conducted.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 8. Real-World Navigation Performance vs. Predicted Difficulty</p>
<ul>
<li>[2] D. Fox, W. Burgard, and S. Thrun, "The dynamic window approach to collision avoidance," <em>IEEE Robotics &amp; Automation Magazine</em>, vol. 4, no. 1, pp. 23–33, 1997.</li>
<li>[3] R. M. Knotts, I. R. Nourbakhsh, and R. C. Morris, "Navigates: A benchmark for indoor navigation," in <em>Robotics 98</em>, 1998, pp. 36–42.</li>
<li>[4] X. Xiao, J. Dufek, T. Woodbury, and R. Murphy, "Uav assisted uav visual navigation for marine mass casualty incident response," in <em>2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2017, pp. 6105–6110.</li>
<li>[5] X. Xiao, E. Cappo, W. Zhen, J. Dai, K. Sun, C. Gong, M. J. Travers, and H. Choset, "Locomotive reduction for snake robots," in <em>2015 IEEE International Conference on Robotics and Automation (ICRA)</em>. IEEE, 2015, pp. 3735–3740.</li>
<li>[6] X. Xiao, J. Dufek, M. Suhail, and R. Murphy, "Motion planning for a uav with a straight or kinked tether," in <em>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2018, pp. 8486–8492.</li>
<li>[7] A. Giusti, J. Guzzi, D. C. Cireşan, F.-L. He, J. P. Rodríguez, F. Fontana, M. Faessler, C. Forster, J. Schmidhuber, G. Di Caro <em>et al.</em>, "A machine learning approach to visual perception of forest trails for mobile robots," <em>IEEE Robotics and Automation Letters</em>, vol. 1, no. 2, pp. 661–667, 2015.</li>
<li>[8] M. Pfeiffer, M. Schaeuble, J. Nieto, R. Siegwart, and C. Cadena, "From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots," in <em>2017 ieee international conference on robotics and automation (icra)</em>. IEEE, 2017, pp. 1527–1533.</li>
<li>[9] X. Xiao, B. Liu, G. Warnell, J. Fink, and P. Stone, "Appld: Adaptive planner parameter learning from demonstration," <em>IEEE Robotics and Automation Letters</em>, vol. 5, no. 3, pp. 4541–4547, 2020.</li>
<li>[10] X. Xiao, B. Liu, G. Warnell, and P. Stone, "Toward agile maneuvers in highly constrained spaces: Learning from hallucination," <em>arXiv preprint arXiv:2007.14479</em>, 2020.</li>
<li>[11] B. Liu, X. Xiao, and P. Stone, "Lifelong navigation," <em>arXiv preprint arXiv:2007.14486</em>, 2020.</li>
<li>[12] X. Xiao, "Risk-aware path and motion planning for a tethered aerial visual assistant in unstructured or confined environments," <em>arXiv preprint arXiv:2007.09595</em>, 2020.</li>
<li>[13] NIST. Standard test methods for response robots. [Online]. Available: https://www.nist.gov/el/intelligent-systems-division-73500/standard-test-methods-response-robots</li>
<li>[14] D. Pickem, P. Glotfelter, L. Wang, M. Mote, A. Ames, E. Feron, and M. Egerstedt, "The robotarium: A remotely accessible swarm robotics research testbed," in <em>2017 IEEE International Conference on Robotics and Automation (ICRA)</em>. IEEE, 2017, pp. 1699–1706.</li>
<li>[15] X. Xiao and R. Murphy, "A review on snake robot testbeds in granular and restricted maneuverability spaces," <em>Robotics and Autonomous Systems</em>, vol. 110, pp. 160–172, 2018.</li>
<li>[16] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, "Imagenet: A large-scale hierarchical image database," in <em>2009 IEEE conference on computer vision and pattern recognition</em>. Ieee, 2009, pp. 248–255.</li>
<li>[17] J. Sturm, N. Engelhard, F. Endres, W. Burgard, and D. Cremers, "A benchmark for the evaluation of rgb-d slam systems," in <em>2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</em>. IEEE, 2012, pp. 573–580.</li>
<li>[18] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, "Vision meets robotics: The kitti dataset," <em>The International Journal of Robotics Research</em>, vol. 32, no. 11, pp. 1231–1237, 2013.</li>
<li>[19] W. Maddern, G. Pascoe, C. Linegar, and P. Newman, "1 year, 1000 km: The oxford robotcar dataset," <em>The International Journal of Robotics Research</em>, vol. 36, no. 1, pp. 3–15, 2017.</li>
<li>[20] W. Wang, D. Zhu, X. Wang, Y. Hu, Y. Qiu, C. Wang, Y. Hu, A. Kapoor, and S. Scherer, "Tartanair: A dataset to push the limits of visual slam," in <em>2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2020.</li>
<li>[21] E. Kolve, R. Mottaghi, W. Han, E. VanderBilt, L. Weihs, A. Herrasti, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi, "Ai2-thor: An interactive 3d environment for visual ai," <em>arXiv preprint arXiv:1712.05474</em>, 2017.</li>
<li>[22] M. Savva, A. Kadian, O. Maksymets, Y. Zhao, E. Wijmans, B. Jain, J. Straub, J. Liu, V. Koltun, J. Malik <em>et al.</em>, "Habitat: A platform for embodied ai research," in <em>Proceedings of the IEEE International Conference on Computer Vision</em>, 2019, pp. 9339–9347.</li>
<li>[23] L. De Filippis, G. Guglieri, and F. Quagliotti, "A minimum risk approach for path planning of uavs," <em>Journal of Intelligent &amp; Robotic Systems</em>, vol. 61, no. 1-4, pp. 203–219, 2011.</li>
<li>[24] S. Feyzabadi and S. Carpin, "Risk-aware path planning using hierarchical constrained markov decision processes," in <em>Automation Science and Engineering (CASE), 2014 IEEE International Conference on</em>. IEEE, 2014, pp. 297–303.</li>
<li>[25] A. A. Pereira, J. Binney, G. A. Hollinger, and G. S. Sukhatme, "Risk-aware path planning for autonomous underwater vehicles using predictive ocean models," <em>Journal of Field Robotics</em>, vol. 30, no. 5, pp. 741–762, 2013.</li>
<li>[26] J. Krumm and E. Horvitz, "Risk-aware planning: Methods and case study for safer driving routes." in <em>AAAI</em>, 2017, pp. 4708–4714.</li>
<li>[27] A. Soltani and T. Fernando, "A fuzzy based multi-objective path planning of construction sites," <em>Automation in construction</em>, vol. 13, no. 6, pp. 717–734, 2004.</li>
<li>[28] X. Xiao, J. Dufek, and R. R. Murphy, "Robot risk-awareness by formal risk reasoning and planning," <em>IEEE Robotics and Automation Letters</em>, vol. 5, no. 2, pp. 2856–2863, 2020.</li>
<li>[29] S. Wolfram, "Statistical mechanics of cellular automata," <em>Reviews of modern physics</em>, vol. 55, no. 3, p. 601, 1983.</li>
<li>[30] J.-C. Lutombe, <em>Robot motion planning</em>. Springer Science &amp; Business Media, 2012, vol. 124.</li>
<li>[31] S. Torbert, <em>Applied computer science</em>. Springer, 2016.</li>
<li>[32] P. Hart, N. Nilsson, and B. Raphael, "A formal basis for the heuristic determination of minimum cost paths," <em>IEEE Transactions on Systems Science and Cybernetics</em>, vol. 4, no. 2, pp. 100–107, 1968. [Online]. Available: https://doi.org/10.1109/tssc.1968.300136</li>
<li>[33] N. Koenig and A. Howard, "Design and use paradigms for gazebo, an open-source multi-robot simulator," in <em>2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566)</em>, vol. 3. IEEE, 2004, pp. 2149–2154.</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Daniel Perille, Abigail Truong, Xuesu Xiao, and Peter Stone are with Department of Computer Science, University of Texas at Austin, Austin, TX 78712 {danny.perille, a.truong}@utexas.edu, {xiao, pstone}@cs.utexas.edu&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>