<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6914 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6914</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6914</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-a00b7251fe4b078865ef68bdfe38694313b0a544</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a00b7251fe4b078865ef68bdfe38694313b0a544" target="_blank">The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems</a></p>
                <p><strong>Paper Venue:</strong> Journal of Neuroscience</p>
                <p><strong>Paper TL;DR:</strong> It is shown using functional magnetic resonance imaging and recordings of event-related potentials, that acoustic conceptual features recruit auditory brain areas even when implicitly presented through visual words, the first direct evidence for a link between perceptual and conceptual acoustic processing.</p>
                <p><strong>Paper Abstract:</strong> Traditionally, concepts are conceived as abstract mental entities distinct from perceptual or motor brain systems. However, recent results let assume modality-specific representations of concepts. The ultimate test for grounding concepts in perception requires the fulfillment of the following four markers: conceptual processing during (1) an implicit task should activate (2) a perceptual region (3) rapidly and (4) selectively. Here, we show using functional magnetic resonance imaging and recordings of event-related potentials, that acoustic conceptual features recruit auditory brain areas even when implicitly presented through visual words. Fulfilling the four markers, the findings of our study unequivocally link the auditory and conceptual brain systems: recognition of words denoting objects, for which acoustic features are highly relevant (e.g.,“telephone”), ignited cell assemblies in posterior superior and middle temporal gyri (pSTG/MTG) within 150 ms that were also activated by sound perception. Importantly, activity within a cluster of pSTG/MTG increased selectively as a function of acoustic, but not of visual and action-related feature relevance. The implicitness of the conceptual task, the selective modulation of left pSTG/MTG activity by acoustic feature relevance, the early onset of this activity at 150 ms and its anatomical overlap with perceptual sound processing are four markers for a modality-specific representation of auditory conceptual features in left pSTG/MTG. Our results therefore provide the first direct evidence for a link between perceptual and conceptual acoustic processing. They demonstrate that access to concepts involves a partial reinstatement of brain activity during the perception of objects.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6914.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6914.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal / Symbolic theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amodal (symbolic) representation of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical view that concepts are abstract, amodal entities distinct from sensory/motor systems, with sensory information transformed into a common format losing modality-specific detail.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The architecture of cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Amodal / Symbolic theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented in an abstract, modality-independent format (symbols or amodal propositions); modality-specific sensory/motor activity is not part of the core concept representation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains abstraction and generalization across modalities, supports symbolic manipulation independent of perceptual systems.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical works and reviews (historical literature cited)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>n/a (theory-level claim; typically discussed relative to behavioral/neuropsychological dissociations)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>This paper reports modality-specific neural activation for acoustic conceptual features that challenges the amodal claim that modality-specific information is lost at concept level.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>fMRI and ERP evidence that visually presented words selectively and rapidly activate auditory association cortex (left pSTG/MTG) in proportion to acoustic feature relevance, inconsistent with a purely amodal, non-modal representation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Anderson 1983; Tyler and Moss 2001 (as cited in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6914.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embodied cognition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embodied (modality-specific) conceptual representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that conceptual knowledge is grounded in perception and action systems: conceptual features are represented in modality-specific sensory and motor cortical areas and access involves partial reinstatement of perceptual/action activity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Grounding conceptual knowledge in modality-specific systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Embodied Cognition / Modality-specific representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / modality-specific feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are implemented by modality-specific cortical representations (feature-coding in sensory and motor areas); conceptual access involves reactivation (partial reinstatement) of the sensory/motor patterns that accompanied experience.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for category- and attribute-specific activations, rapid access to modality-relevant features, ties conceptual retrieval to sensory/motor systems, explains behavioral interactions between perception/action and language.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral studies, neuropsychology, electrophysiology, and neuroimaging (cited) and the present paper's fMRI and ERP experiments</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>lexical decision on visually presented words with varying rated relevance of acoustic features (implicit conceptual access), fMRI contrasts and parametric modulation by feature relevance, ERP with source localization</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Visually presented words denoting objects with high acoustic relevance selectively activated left posterior STG/MTG (auditory association cortex), this activation overlapped with perceptual sound activations and emerged rapidly (~150 ms), and scaled with acoustic feature relevance — supporting modality-specific reinstatement.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Activation for conceptual processing was confined to auditory association cortex and did not include primary/secondary auditory cortex; earlier literature has mixed replication for visual feature effects and imagery confounds must be considered, but the present data address these concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Barsalou et al. 2003; Pulvermüller 2005; Gallese & Lakoff 2005; Kiefer & Spitzer 2001 (as discussed and tested in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6914.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cell-assembly model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pulvermüller's cortical cell assembly account of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neuronal cell-assembly model proposing that concepts correspond to distributed cortical assemblies linking modality-specific sensory and motor neurons formed during learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Brain mechanisms linking language and action.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Cell assembly model (Pulvermüller)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / neuronal assemblies</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are realized by distributed neuronal assemblies that span sensory, motor and associative cortex; activation of a concept corresponds to the rapid, joint activation of these assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Predicts rapid activation of modality-specific cortex on conceptual access, explains ultra-fast semantics in EEG/MEG (~100–200 ms), and provides a neuronal mechanism for embodiment.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>electrophysiological studies, neuroimaging, and theoretical/empirical literature (cited); present ERP results are relevant.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>EEG/MEG signatures of word/concept processing, source analysis, and comparisons with perceptual activation patterns</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>ERP divergence between words with vs without acoustic features around 150–200 ms localized to generators in/near left pSTG/MTG, consistent with rapid activation of modality-linked cell assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>The observed reinstatement is in higher-level auditory association cortex rather than primary auditory cortex, which may require more nuanced account of which nodes of assemblies are engaged during conceptual access.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Pulvermüller 2005 (as referenced and tested in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6914.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Damasio convergence-zone</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Damasio's convergence zone / retroactivation model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Systems-level proposal that recall/recognition is mediated by convergence zones which store pointers to modality-specific representations and reactivate them (time-locked multiregional retroactivation).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Convergence-zone / retroactivation model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational network / pointer-based reactivation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Higher-level convergence zones bind and index distributed modality-specific representations and, upon retrieval, orchestrate time-locked reactivation of those modality-specific areas to reconstruct memory or concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how retrieval can reinstate distributed perceptual representations without storing full sensory detail in a single locus; supports modality-specific reactivation during recall.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical proposal supported by neuroimaging and lesion literature (cited); present paper interprets pSTG/MTG as a possible auditory convergence zone.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>memory retrieval and recognition tasks with neuroimaging; here, conceptual retrieval (lexical decision) compared with perception</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Left pSTG/MTG is suggested to act as an auditory convergence zone coding higher-level acoustic object information; conceptual access partially reinstates perceptual activity consistent with Damasio's proposal.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Reinstatement observed restricted to association cortex rather than primary sensory areas, which Damasio's model can accommodate but requires specification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Damasio 1989 (as discussed in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6914.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Featural (Smith et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Featural model of semantic memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A feature-based account proposing that concepts are represented as sets of semantic features and that semantic decisions operate over these feature representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Structure and process in semantic memory: a featural model for semantic decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Featural model / feature-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature-based vector</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are collections of semantic features (e.g., visual, acoustic, motor); conceptual processing involves activation and combination of relevant feature dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for semantic decision behavior, typicality effects, and graded feature relevance; allows parametric predictions based on feature relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments and psycholinguistic studies (cited); operationalized in this paper via behavioral ratings of acoustic/visual/action feature relevance and parametric fMRI analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>semantic feature rating and parametric modulation analyses linking rated feature relevance to neural activation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Parametric modulation showed MR signal in left pSTG/MTG increased linearly with rated acoustic feature relevance, indicating feature-specific neural coding consistent with featural representation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Visual and action features did not modulate this auditory region, showing modality specificity rather than indiscriminate distributed coding across all regions; no counterevidence to featural models per se but indicates modality-specific anatomical mapping of features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Smith et al. 1974 (as cited and operationalized in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6914.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Imagery account</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual imagery as explanation for sensory-cortex activation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The view that activations of sensory cortical areas during conceptual tasks can be explained by voluntary or involuntary imagery processes rather than by core conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Image and brain: the resolution of the imagery debate.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Imagery explanation for sensory activations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>perceptual simulation / imagery</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Sensory cortex activations during conceptual tasks arise from mental imagery (post-conceptual, strategic visualization/hearing) rather than from core conceptual representation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for sensory-area activation as epiphenomenal or strategic rather than constitutive of conceptual representation; imagery tends to occur later and is associated with vivid sensory experience.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral and neuroimaging studies of imagery (cited); discussed as an alternative explanation in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>explicit imagery tasks and comparisons of timing/location of activations; contrasted with implicit tasks like lexical decision</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>This paper argues against imagery as explanation for their effects because activations are early (~150 ms) after word onset and occur in an implicit lexical decision task, making post-conceptual imagery implausible.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Early ERP onset (~150 ms), anatomical overlap with perceptual sound processing, and implicit task demands argue that effects reflect conceptual access rather than later imagery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Kosslyn 1994; Machery 2007 (as discussed in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6914.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sensory reinstatement (memory)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sensory reinstatement / reactivation in episodic and working memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical principle that retrieval of memories reinstates activity in the same sensory cortical areas that were active during encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memory's echo: vivid remembering reactivates sensory-specific cortex.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Sensory reinstatement / reactivation principle</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>reinstatement / reactivation (high-dimensional patterns)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Retrieval or recall of perceptual information reactivates modality-specific sensory areas (a partial reinstatement of encoding-related activity), observed in episodic and working memory tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains sensory cortex activation during memory retrieval and implies similar mechanisms may operate during conceptual retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI and electrophysiological episodic memory studies (cited) and parallels drawn from the present conceptual results.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>episodic recall/working memory tasks with neuroimaging; in this paper, conceptual retrieval compared to direct perception</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>The paper draws a parallel between sensory reinstatement in memory (Wheeler et al., 2000; Ranganath et al., 2004) and the observed partial reinstatement of auditory cortical activity during conceptual access to acoustic features.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>None reported; paper proposes modality-specific conceptual reinstatement may reflect a general organizing principle shared with memory systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wheeler et al. 2000; Ranganath et al. 2004 (as cited in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6914.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed account (Tyler & Moss)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed account of conceptual knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposal that conceptual knowledge is represented in distributed networks across the cortex rather than in a single amodal store; different studies vary on the degree and localization of distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards a distributed account of conceptual knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributed representation account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed network / relational</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are supported by widely distributed cortical networks; semantic content arises from distributed activation patterns rather than localized modules.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains category-specificity by patterns across distributed regions and allows for partial lesion effects; accounts for heterogeneity in neural correlates of concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical review and neuroimaging literature (cited); contrasted in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>various neuroimaging and lesion paradigms across studies; here, tested by assessing localization/overlap of perceptual and conceptual activation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Kiefer et al. (2008) argue that conceptual features are localizable in modality-specific association cortices (e.g., left pSTG/MTG for acoustic features), challenging claims that conceptual content is arbitrarily distributed without modality-specific localization.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Specific, selective parametric modulation of left pSTG/MTG by acoustic feature relevance indicates modality-specific localization rather than arbitrary distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Tyler & Moss 2001 (as cited in Kiefer et al., 2008)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6914.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6914.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Four markers method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Four markers for grounding concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methodological criteria introduced in this paper for demonstrating grounding of conceptual features in perceptual systems: implicit task, activation of perceptual region, rapid onset (<200 ms), and selectivity for feature type.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Four markers test for modality-specific grounding</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>methodological criteria</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>A four-part empirical test requiring (1) conceptual processing in an implicit task, (2) engagement of a perceptual brain region, (3) rapid activation within ~200 ms, and (4) selective modulation by the relevant feature dimension to support modality-specific conceptual representation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Provides an operational test to distinguish genuine modality-specific conceptual activation from perceptual processing of stimuli or later imagery/strategic processes.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>implemented in the present paper using fMRI (event-related and block), parametric feature-rating modulation, and ERP source localization.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>lexical decision task on visually presented words with feature relevance ratings (fMRI & ERP), and a perceptual listening fMRI block design to establish overlap</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>All four markers were satisfied for auditory conceptual features: implicit lexical decision activated left pSTG/MTG, activation overlapped with perceptual sound processing, emerged at ~150 ms in ERP, and scaled selectively with acoustic feature relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>No counterevidence for the markers in the context of auditory features in this study; limitations include that only acoustic features were optimized and generalization to other features remains to be tested.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Kiefer et al. 2008</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems', 'publication_date_yy_mm': '2008-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Grounding conceptual knowledge in modality-specific systems. <em>(Rating: 2)</em></li>
                <li>Brain mechanisms linking language and action. <em>(Rating: 2)</em></li>
                <li>Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition. <em>(Rating: 2)</em></li>
                <li>Structure and process in semantic memory: a featural model for semantic decisions. <em>(Rating: 2)</em></li>
                <li>Memory's echo: vivid remembering reactivates sensory-specific cortex. <em>(Rating: 2)</em></li>
                <li>Image and brain: the resolution of the imagery debate. <em>(Rating: 1)</em></li>
                <li>Towards a distributed account of conceptual knowledge. <em>(Rating: 1)</em></li>
                <li>Imagery or meaning? Evidence for a semantic origin of category-specific brain activity in metabolic imaging. <em>(Rating: 1)</em></li>
                <li>Auditory cortex on the human posterior superior temporal gyrus. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6914",
    "paper_id": "paper-a00b7251fe4b078865ef68bdfe38694313b0a544",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Amodal / Symbolic theory",
            "name_full": "Amodal (symbolic) representation of concepts",
            "brief_description": "Classical view that concepts are abstract, amodal entities distinct from sensory/motor systems, with sensory information transformed into a common format losing modality-specific detail.",
            "citation_title": "The architecture of cognition.",
            "mention_or_use": "mention",
            "theory_name": "Amodal / Symbolic theory",
            "theory_type": "symbolic",
            "theory_description": "Conceptual knowledge is represented in an abstract, modality-independent format (symbols or amodal propositions); modality-specific sensory/motor activity is not part of the core concept representation.",
            "functional_claims": "Explains abstraction and generalization across modalities, supports symbolic manipulation independent of perceptual systems.",
            "evidence_source": "theoretical works and reviews (historical literature cited)",
            "experimental_paradigm": "n/a (theory-level claim; typically discussed relative to behavioral/neuropsychological dissociations)",
            "key_result": "This paper reports modality-specific neural activation for acoustic conceptual features that challenges the amodal claim that modality-specific information is lost at concept level.",
            "supports_theory": false,
            "counter_evidence": "fMRI and ERP evidence that visually presented words selectively and rapidly activate auditory association cortex (left pSTG/MTG) in proportion to acoustic feature relevance, inconsistent with a purely amodal, non-modal representation.",
            "citation": "Anderson 1983; Tyler and Moss 2001 (as cited in Kiefer et al., 2008)",
            "uuid": "e6914.0",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Embodied cognition",
            "name_full": "Embodied (modality-specific) conceptual representation",
            "brief_description": "Theory that conceptual knowledge is grounded in perception and action systems: conceptual features are represented in modality-specific sensory and motor cortical areas and access involves partial reinstatement of perceptual/action activity.",
            "citation_title": "Grounding conceptual knowledge in modality-specific systems.",
            "mention_or_use": "use",
            "theory_name": "Embodied Cognition / Modality-specific representation",
            "theory_type": "embodied simulation / modality-specific feature-based",
            "theory_description": "Concepts are implemented by modality-specific cortical representations (feature-coding in sensory and motor areas); conceptual access involves reactivation (partial reinstatement) of the sensory/motor patterns that accompanied experience.",
            "functional_claims": "Accounts for category- and attribute-specific activations, rapid access to modality-relevant features, ties conceptual retrieval to sensory/motor systems, explains behavioral interactions between perception/action and language.",
            "evidence_source": "behavioral studies, neuropsychology, electrophysiology, and neuroimaging (cited) and the present paper's fMRI and ERP experiments",
            "experimental_paradigm": "lexical decision on visually presented words with varying rated relevance of acoustic features (implicit conceptual access), fMRI contrasts and parametric modulation by feature relevance, ERP with source localization",
            "key_result": "Visually presented words denoting objects with high acoustic relevance selectively activated left posterior STG/MTG (auditory association cortex), this activation overlapped with perceptual sound activations and emerged rapidly (~150 ms), and scaled with acoustic feature relevance — supporting modality-specific reinstatement.",
            "supports_theory": true,
            "counter_evidence": "Activation for conceptual processing was confined to auditory association cortex and did not include primary/secondary auditory cortex; earlier literature has mixed replication for visual feature effects and imagery confounds must be considered, but the present data address these concerns.",
            "citation": "Barsalou et al. 2003; Pulvermüller 2005; Gallese & Lakoff 2005; Kiefer & Spitzer 2001 (as discussed and tested in Kiefer et al., 2008)",
            "uuid": "e6914.1",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Cell-assembly model",
            "name_full": "Pulvermüller's cortical cell assembly account of concepts",
            "brief_description": "Neuronal cell-assembly model proposing that concepts correspond to distributed cortical assemblies linking modality-specific sensory and motor neurons formed during learning.",
            "citation_title": "Brain mechanisms linking language and action.",
            "mention_or_use": "mention",
            "theory_name": "Cell assembly model (Pulvermüller)",
            "theory_type": "embodied simulation / neuronal assemblies",
            "theory_description": "Concepts are realized by distributed neuronal assemblies that span sensory, motor and associative cortex; activation of a concept corresponds to the rapid, joint activation of these assemblies.",
            "functional_claims": "Predicts rapid activation of modality-specific cortex on conceptual access, explains ultra-fast semantics in EEG/MEG (~100–200 ms), and provides a neuronal mechanism for embodiment.",
            "evidence_source": "electrophysiological studies, neuroimaging, and theoretical/empirical literature (cited); present ERP results are relevant.",
            "experimental_paradigm": "EEG/MEG signatures of word/concept processing, source analysis, and comparisons with perceptual activation patterns",
            "key_result": "ERP divergence between words with vs without acoustic features around 150–200 ms localized to generators in/near left pSTG/MTG, consistent with rapid activation of modality-linked cell assemblies.",
            "supports_theory": true,
            "counter_evidence": "The observed reinstatement is in higher-level auditory association cortex rather than primary auditory cortex, which may require more nuanced account of which nodes of assemblies are engaged during conceptual access.",
            "citation": "Pulvermüller 2005 (as referenced and tested in Kiefer et al., 2008)",
            "uuid": "e6914.2",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Damasio convergence-zone",
            "name_full": "Damasio's convergence zone / retroactivation model",
            "brief_description": "Systems-level proposal that recall/recognition is mediated by convergence zones which store pointers to modality-specific representations and reactivate them (time-locked multiregional retroactivation).",
            "citation_title": "Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition.",
            "mention_or_use": "mention",
            "theory_name": "Convergence-zone / retroactivation model",
            "theory_type": "relational network / pointer-based reactivation",
            "theory_description": "Higher-level convergence zones bind and index distributed modality-specific representations and, upon retrieval, orchestrate time-locked reactivation of those modality-specific areas to reconstruct memory or concepts.",
            "functional_claims": "Explains how retrieval can reinstate distributed perceptual representations without storing full sensory detail in a single locus; supports modality-specific reactivation during recall.",
            "evidence_source": "theoretical proposal supported by neuroimaging and lesion literature (cited); present paper interprets pSTG/MTG as a possible auditory convergence zone.",
            "experimental_paradigm": "memory retrieval and recognition tasks with neuroimaging; here, conceptual retrieval (lexical decision) compared with perception",
            "key_result": "Left pSTG/MTG is suggested to act as an auditory convergence zone coding higher-level acoustic object information; conceptual access partially reinstates perceptual activity consistent with Damasio's proposal.",
            "supports_theory": true,
            "counter_evidence": "Reinstatement observed restricted to association cortex rather than primary sensory areas, which Damasio's model can accommodate but requires specification.",
            "citation": "Damasio 1989 (as discussed in Kiefer et al., 2008)",
            "uuid": "e6914.3",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Featural (Smith et al.)",
            "name_full": "Featural model of semantic memory",
            "brief_description": "A feature-based account proposing that concepts are represented as sets of semantic features and that semantic decisions operate over these feature representations.",
            "citation_title": "Structure and process in semantic memory: a featural model for semantic decisions.",
            "mention_or_use": "mention",
            "theory_name": "Featural model / feature-based representation",
            "theory_type": "feature-based vector",
            "theory_description": "Concepts are collections of semantic features (e.g., visual, acoustic, motor); conceptual processing involves activation and combination of relevant feature dimensions.",
            "functional_claims": "Accounts for semantic decision behavior, typicality effects, and graded feature relevance; allows parametric predictions based on feature relevance.",
            "evidence_source": "behavioral experiments and psycholinguistic studies (cited); operationalized in this paper via behavioral ratings of acoustic/visual/action feature relevance and parametric fMRI analysis.",
            "experimental_paradigm": "semantic feature rating and parametric modulation analyses linking rated feature relevance to neural activation",
            "key_result": "Parametric modulation showed MR signal in left pSTG/MTG increased linearly with rated acoustic feature relevance, indicating feature-specific neural coding consistent with featural representation.",
            "supports_theory": true,
            "counter_evidence": "Visual and action features did not modulate this auditory region, showing modality specificity rather than indiscriminate distributed coding across all regions; no counterevidence to featural models per se but indicates modality-specific anatomical mapping of features.",
            "citation": "Smith et al. 1974 (as cited and operationalized in Kiefer et al., 2008)",
            "uuid": "e6914.4",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Imagery account",
            "name_full": "Perceptual imagery as explanation for sensory-cortex activation",
            "brief_description": "The view that activations of sensory cortical areas during conceptual tasks can be explained by voluntary or involuntary imagery processes rather than by core conceptual representations.",
            "citation_title": "Image and brain: the resolution of the imagery debate.",
            "mention_or_use": "mention",
            "theory_name": "Imagery explanation for sensory activations",
            "theory_type": "perceptual simulation / imagery",
            "theory_description": "Sensory cortex activations during conceptual tasks arise from mental imagery (post-conceptual, strategic visualization/hearing) rather than from core conceptual representation.",
            "functional_claims": "Accounts for sensory-area activation as epiphenomenal or strategic rather than constitutive of conceptual representation; imagery tends to occur later and is associated with vivid sensory experience.",
            "evidence_source": "behavioral and neuroimaging studies of imagery (cited); discussed as an alternative explanation in this paper.",
            "experimental_paradigm": "explicit imagery tasks and comparisons of timing/location of activations; contrasted with implicit tasks like lexical decision",
            "key_result": "This paper argues against imagery as explanation for their effects because activations are early (~150 ms) after word onset and occur in an implicit lexical decision task, making post-conceptual imagery implausible.",
            "supports_theory": false,
            "counter_evidence": "Early ERP onset (~150 ms), anatomical overlap with perceptual sound processing, and implicit task demands argue that effects reflect conceptual access rather than later imagery.",
            "citation": "Kosslyn 1994; Machery 2007 (as discussed in Kiefer et al., 2008)",
            "uuid": "e6914.5",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Sensory reinstatement (memory)",
            "name_full": "Sensory reinstatement / reactivation in episodic and working memory",
            "brief_description": "Empirical principle that retrieval of memories reinstates activity in the same sensory cortical areas that were active during encoding.",
            "citation_title": "Memory's echo: vivid remembering reactivates sensory-specific cortex.",
            "mention_or_use": "mention",
            "theory_name": "Sensory reinstatement / reactivation principle",
            "theory_type": "reinstatement / reactivation (high-dimensional patterns)",
            "theory_description": "Retrieval or recall of perceptual information reactivates modality-specific sensory areas (a partial reinstatement of encoding-related activity), observed in episodic and working memory tasks.",
            "functional_claims": "Explains sensory cortex activation during memory retrieval and implies similar mechanisms may operate during conceptual retrieval.",
            "evidence_source": "fMRI and electrophysiological episodic memory studies (cited) and parallels drawn from the present conceptual results.",
            "experimental_paradigm": "episodic recall/working memory tasks with neuroimaging; in this paper, conceptual retrieval compared to direct perception",
            "key_result": "The paper draws a parallel between sensory reinstatement in memory (Wheeler et al., 2000; Ranganath et al., 2004) and the observed partial reinstatement of auditory cortical activity during conceptual access to acoustic features.",
            "supports_theory": true,
            "counter_evidence": "None reported; paper proposes modality-specific conceptual reinstatement may reflect a general organizing principle shared with memory systems.",
            "citation": "Wheeler et al. 2000; Ranganath et al. 2004 (as cited in Kiefer et al., 2008)",
            "uuid": "e6914.6",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Distributed account (Tyler & Moss)",
            "name_full": "Distributed account of conceptual knowledge",
            "brief_description": "Proposal that conceptual knowledge is represented in distributed networks across the cortex rather than in a single amodal store; different studies vary on the degree and localization of distribution.",
            "citation_title": "Towards a distributed account of conceptual knowledge.",
            "mention_or_use": "mention",
            "theory_name": "Distributed representation account",
            "theory_type": "distributed network / relational",
            "theory_description": "Concepts are supported by widely distributed cortical networks; semantic content arises from distributed activation patterns rather than localized modules.",
            "functional_claims": "Explains category-specificity by patterns across distributed regions and allows for partial lesion effects; accounts for heterogeneity in neural correlates of concepts.",
            "evidence_source": "theoretical review and neuroimaging literature (cited); contrasted in the present paper.",
            "experimental_paradigm": "various neuroimaging and lesion paradigms across studies; here, tested by assessing localization/overlap of perceptual and conceptual activation.",
            "key_result": "Kiefer et al. (2008) argue that conceptual features are localizable in modality-specific association cortices (e.g., left pSTG/MTG for acoustic features), challenging claims that conceptual content is arbitrarily distributed without modality-specific localization.",
            "supports_theory": false,
            "counter_evidence": "Specific, selective parametric modulation of left pSTG/MTG by acoustic feature relevance indicates modality-specific localization rather than arbitrary distribution.",
            "citation": "Tyler & Moss 2001 (as cited in Kiefer et al., 2008)",
            "uuid": "e6914.7",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        },
        {
            "name_short": "Four markers method",
            "name_full": "Four markers for grounding concepts",
            "brief_description": "Methodological criteria introduced in this paper for demonstrating grounding of conceptual features in perceptual systems: implicit task, activation of perceptual region, rapid onset (&lt;200 ms), and selectivity for feature type.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Four markers test for modality-specific grounding",
            "theory_type": "methodological criteria",
            "theory_description": "A four-part empirical test requiring (1) conceptual processing in an implicit task, (2) engagement of a perceptual brain region, (3) rapid activation within ~200 ms, and (4) selective modulation by the relevant feature dimension to support modality-specific conceptual representation.",
            "functional_claims": "Provides an operational test to distinguish genuine modality-specific conceptual activation from perceptual processing of stimuli or later imagery/strategic processes.",
            "evidence_source": "implemented in the present paper using fMRI (event-related and block), parametric feature-rating modulation, and ERP source localization.",
            "experimental_paradigm": "lexical decision task on visually presented words with feature relevance ratings (fMRI & ERP), and a perceptual listening fMRI block design to establish overlap",
            "key_result": "All four markers were satisfied for auditory conceptual features: implicit lexical decision activated left pSTG/MTG, activation overlapped with perceptual sound processing, emerged at ~150 ms in ERP, and scaled selectively with acoustic feature relevance.",
            "supports_theory": true,
            "counter_evidence": "No counterevidence for the markers in the context of auditory features in this study; limitations include that only acoustic features were optimized and generalization to other features remains to be tested.",
            "citation": "Kiefer et al. 2008",
            "uuid": "e6914.8",
            "source_info": {
                "paper_title": "The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems",
                "publication_date_yy_mm": "2008-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Grounding conceptual knowledge in modality-specific systems.",
            "rating": 2,
            "sanitized_title": "grounding_conceptual_knowledge_in_modalityspecific_systems"
        },
        {
            "paper_title": "Brain mechanisms linking language and action.",
            "rating": 2,
            "sanitized_title": "brain_mechanisms_linking_language_and_action"
        },
        {
            "paper_title": "Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition.",
            "rating": 2,
            "sanitized_title": "timelocked_multiregional_retroactivation_a_systemslevel_proposal_for_the_neural_substrates_of_recall_and_recognition"
        },
        {
            "paper_title": "Structure and process in semantic memory: a featural model for semantic decisions.",
            "rating": 2,
            "sanitized_title": "structure_and_process_in_semantic_memory_a_featural_model_for_semantic_decisions"
        },
        {
            "paper_title": "Memory's echo: vivid remembering reactivates sensory-specific cortex.",
            "rating": 2,
            "sanitized_title": "memorys_echo_vivid_remembering_reactivates_sensoryspecific_cortex"
        },
        {
            "paper_title": "Image and brain: the resolution of the imagery debate.",
            "rating": 1,
            "sanitized_title": "image_and_brain_the_resolution_of_the_imagery_debate"
        },
        {
            "paper_title": "Towards a distributed account of conceptual knowledge.",
            "rating": 1,
            "sanitized_title": "towards_a_distributed_account_of_conceptual_knowledge"
        },
        {
            "paper_title": "Imagery or meaning? Evidence for a semantic origin of category-specific brain activity in metabolic imaging.",
            "rating": 1,
            "sanitized_title": "imagery_or_meaning_evidence_for_a_semantic_origin_of_categoryspecific_brain_activity_in_metabolic_imaging"
        },
        {
            "paper_title": "Auditory cortex on the human posterior superior temporal gyrus.",
            "rating": 1,
            "sanitized_title": "auditory_cortex_on_the_human_posterior_superior_temporal_gyrus"
        }
    ],
    "cost": 0.01686925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>The Sound of Concepts: Four Markers for a Link between Auditory and Conceptual Brain Systems</h1>
<p>Markus Kiefer, ${ }^{1}$ Eun-Jin Sim, ${ }^{1,2}$ Bärbel Herrnberger, ${ }^{1}$ Jo Grothe, ${ }^{1}$ and Klaus Hoenig ${ }^{1,2}$<br>${ }^{1}$ Department of Psychiatry, University of Ulm, and ${ }^{2}$ Transfer Center for Neurosciences and Learning, 89075 Ulm, Germany</p>
<h4>Abstract</h4>
<p>Traditionally, concepts are conceived as abstract mental entities distinct from perceptual or motor brain systems. However, recent results let assume modality-specific representations of concepts. The ultimate test for grounding concepts in perception requires the fulfillment of the following four markers: conceptual processing during (1) an implicit task should activate (2) a perceptual region (3) rapidly and (4) selectively. Here, we show using functional magnetic resonance imaging and recordings of event-related potentials, that acoustic conceptual features recruit auditory brain areas even when implicitly presented through visual words. Fulfilling the four markers, the findings of our study unequivocally link the auditory and conceptual brain systems: recognition of words denoting objects, for which acoustic features are highly relevant (e.g.,"telephone"), ignited cell assemblies in posterior superior and middle temporal gyri (pSTG/ MTG) within 150 ms that were also activated by sound perception. Importantly, activity within a cluster of pSTG/MTG increased selectively as a function of acoustic, but not of visual and action-related feature relevance. The implicitness of the conceptual task, the selective modulation of left pSTG/MTG activity by acoustic feature relevance, the early onset of this activity at 150 ms and its anatomical overlap with perceptual sound processing are four markers for a modality-specific representation of auditory conceptual features in left pSTG/ MTG. Our results therefore provide the first direct evidence for a link between perceptual and conceptual acoustic processing. They demonstrate that access to concepts involves a partial reinstatement of brain activity during the perception of objects.</p>
<p>Key words: conceptual brain systems; auditory cortex; language; embodied cognition; fMRI; EEG</p>
<h2>Introduction</h2>
<p>Concepts in long-term memory are important building blocks of human cognition and form the basis for object recognition, language and thought (Humphreys et al., 1988; Levelt et al., 1999). Traditionally, concepts are specified as abstract mental entities different from perceptual or motor brain systems (Anderson, 1983; Tyler and Moss, 2001): sensory or motor features of objects and events are transformed into a common amodal representation format, in which original modality-specific information is lost.</p>
<p>Challenging this classical view, recent modality-specific approaches propose close links between the perceptual and motor brain systems and the conceptual system. They assume that concepts are embodied (Gallese and Lakoff, 2005) in the sense that they are essentially grounded in perception and action (Warrington and McCarthy, 1987; Kiefer and Spitzer, 2001; Martin and Chao, 2001; Barsalou et al., 2003; Pulvermüller, 2005): conceptual features (e.g., visual, acoustic, action-related) are represented by cortical cell assemblies in sensory and motor areas es-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>tablished during concept acquisition (Pulvermüller, 2005; Kiefer et al., 2007b). Activation of these modality-specific cell assemblies either bottom-up by words and objects, or top-down by thought constitutes the concept. Hence, access to concepts involves a partial reinstatement of brain activity during perception and action.</p>
<p>Support for modality-specific approaches comes from behavioral (Boulenger et al., 2006; Helbig et al., 2006), neuropsychological (Warrington and McCarthy, 1987), electrophysiological (Kiefer, 2005) and neuroimaging studies (Martin and Chao, 2001). Although conceptual tasks activated sensory brain areas convincing evidence for a link between perceptual and conceptual systems is hitherto missing: conceptual categories with a strong emphasis on visual features (i.e., natural kinds) elicited activity in visual brain areas (Martin et al., 1996). However, these findings were not consistently replicated (Gerlach, 2007). Furthermore, they could be alternatively explained by perceptual processing of the visual stimuli themselves (Gerlach et al., 1999; Kiefer, 2001) or by postconceptual strategic processes such as visual imagery (Machery, 2007) that occur after the concept had been fully accessed (Kosslyn, 1994; Hauk et al., 2008a). Hence, it is not sufficient to simply demonstrate a functional-anatomical overlap between conceptual and perceptual processing.</p>
<p>Bridging the gap between the perceptual and conceptual systems, we investigated the neural representation of acoustic conceptual features during the recognition of visually presented object names. In our study, we used functional magnetic resonance imaging (fMRI) and event-related potentials (ERPs) to obtain</p>
<p>four converging markers for a link between auditory and conceptual brain systems: (1) We assess whether implicit retrieval of acoustic conceptual features during the lexical decision task is sufficient to drive activity in auditory brain areas. (2) We determine whether this activity emerges rapidly within the first 200 ms of visual word processing. (3) We identify the functionalanatomical overlap between conceptual and perceptual processing of acoustic information. (4) We test the selectivity of the brain response to acoustic conceptual features. To this end, we assess whether the relevance of acoustic features specifically correlates with the MR signal in regions representing acoustic conceptual information. Only if these four markers are simultaneously met, a grounding of acoustic conceptual representations in the auditory perceptual system can be convincingly demonstrated.</p>
<h2>Materials and Methods</h2>
<p>General. All subjects were right-handed (Oldfield, 1971) native Germanspeaking volunteers with normal or corrected-to normal visual acuity and without any history for neurological or psychiatric disorders. They participated after giving written informed consent; the procedures of the study have been approved by the local Ethical Committee. In the fMRI experiments (experiment 1 and 2), 16 subjects ( 7 female; mean age $=$ 25.5) participated. In the ERP experiment (experiment 3), a new sample of twenty subjects ( 10 female; mean age $=24.0$ ) was involved. Experimental control and data acquisition were performed by the ERTS software package (Berisoft). In the fMRI experiments visual stimuli were delivered through MR-compatible video goggles (Resonance Technology), and acoustic stimuli through MR-compatible pneumatic headphones (Siemens). In the ERP experiment, visual stimuli were presented on a computer screen.</p>
<p>Stimuli and procedure for the conceptual acoustic task (experiments 1 and 3). One hundred words and 100 pseudowords were presented visually for 500 ms , preceded by a fixation cross of 750 ms duration. Pronounceable letter strings (pseudowords) served as distracters and were not further analyzed. Two word sets that differed only with regard to the relevance of acoustic conceptual features were formed according to the results of a preceding norming study: a first subject group $(n=20)$, who did not participate in the main experiments, had to rate a sample of 261 object names for relevance of acoustic features on a scale from 1 to 6 . They were asked how strongly they associate acoustic features with the named object. A second independent subject group $(n=20)$ had to rate the relevance of visual and motor object features as well as emotional valence (pleasant vs unpleasant) of each named object $(n=238)$ in the same way. These word sets differed significantly only with regard to the relevance of acoustic features (with vs without acoustic features: 5.0, SD 0.54 vs 1.7, SD $0.55, p&lt;0.0001$ ), but were comparable for visual (3.76, SD 0.58 vs 3.96 , SD $0.49, p=0.35$ ) and motor features ( 3.69 , SD 0.61 vs $3.54, \mathrm{SD} 0.61, p=0.15$ ). Sets were also matched for emotional valence ( 0.1 , SD 0.70 vs $-0.1, \mathrm{SD} 0.76, p=0.12$ ), word length ( 6.0 , SD 1.6 vs 6.0 , SD $1.4, p=1.0$ ) and word frequency ( 29.0 , SD 30 vs $29.0, \mathrm{SD} 24, p=1.0$; according to the CELEX lexical data base). Half of the words in each set referred to objects from natural categories (animals, plants, fruit), the other half referred to objects from artifact categories (tools, musical instruments, transportation). A pilot study with a lexical decision task ( $n=$ 9) showed that word sets with high and low relevance of acoustic features showed similar reaction times ( 607 ms vs $609 \mathrm{~ms}, p=0.66$ ) and error rates ( 2.4 vs $2.4, p=1.0$ ). Hence, word sets exhibited a comparable word recognition difficulty. In fMRI experiment 1, words and pseudowords were presented in a randomized manner (event-related design) intermixed with trials in which just a black screen was shown (null events). For each stimulus, participants had to respond within a time window of 2000 ms before the next trial started. The mean intertrial interval was 6.1 s varying randomly between 2.4 and 9.8 s . Stimuli were presented within five blocks of 40 trials each (plus 10 null events). In the ERP experiment, words and pseudowords were also presented in a randomized order, but participants initiated each trial with a button press to reduce ocular artifacts in the EEG recordings during the trials.</p>
<p>Stimuli and procedure for the perceptual acoustic task (experiment 2). Ten real sounds from animal and artifactual objects, respectively, and 10 amplitude-modulated colored noise sounds were used as stimuli. All acoustic stimuli had a duration of 500 ms (including rise and fall time) and were presented binaurally at $\sim 90 \mathrm{~dB} \mathrm{nHL}$ via closed headphones. All sounds were presented in blocks with a duration of 24 s each ( 10 stimuli per block with a mean interstimulus interval of 850 ms randomly varying between 400 and 1300 ms ). Throughout the experiment, a fixation cross was displayed to minimize eye movements. Participants' task was to attentively listen to the acoustic stimuli while maintaining fixation. Each acoustic stimulation block was preceded and followed by a resting block in which only the fixation cross was shown. The acoustic stimulation blocks (real sounds, acoustic noise) were presented four times in a randomized order. Postexperimental debriefing showed that participants followed the instruction of the sound listening task. Brain activity in response to real sounds and acoustic noise was determined by using functional magnetic resonance imaging (see below).</p>
<p>fMRI scanning and data analysis. Functional and structural MR images were recorded with a 3 Tesla Allegra MRI system (Siemens). For the functional scans, a T2*-weighted single-shot gradient-echo EPI sequence [ $\mathrm{TE}=38 \mathrm{~ms}, \mathrm{TR}=2000 \mathrm{~ms}$, flip angle $=90^{\circ}$, matrix $64 \times 64$ pixels, field of view (FOV) $210 \times 210 \mathrm{~mm}^{2}$, voxel size $3.3 \times 3.3 \times 4.9 \mathrm{~mm}^{3}$ ] was used. Starting from the bottom of the brain, 30 transversal slices were acquired in interleaved order. Slice orientation was parallel to a line connecting the bases of the frontal lobe and the cerebellum. There were five imaging runs for the entire fMRI experiment, resulting in a total of 1225 functional volumes. Run duration was $\sim 8 \mathrm{~min}$. Structural images were acquired with T1-weighted MPRAGE sequence ( $\mathrm{TR}=2300 \mathrm{~ms}$; $\mathrm{TE}=3.9 \mathrm{~ms}$; flip angle $=12^{\circ}$; matrix $256 \times 256$ pixels, FOV $=256 \times 256$ $\mathrm{mm}^{2}$, voxel size $1 \times 1 \times 1 \mathrm{~mm}^{3}$ ). Functional data preprocessing and statistical analyses were performed with SPM2 (http://www.fil.ion. ucl.ac.uk/spm/spm2.html). Functional images were corrected for differences in slice-timing, spatially realigned to the first volume of the first run and smoothed with an isotropic Gaussian kernel of 6 mm FWHM. Before smoothing, the realigned images were spatially normalized to the MNI reference brain (resampled voxel size: $2 \times 2 \times 2 \mathrm{~mm}^{3}$ ). A temporal highpass filter with cutoff frequency $1 / 128 \mathrm{~Hz}$ was applied to the data, and temporal autocorrelation in the fMRI time series was estimated (and corrected for) using a first-order autoregressive model. Statistical analysis used a hierarchical random-effects model with two levels. At the first level, single-subject fMRI responses were modeled by a design matrix comprised of the stimuli (experiment 1: words with and without acoustic features and pseudowords; experiment 2: blocks of acoustic stimuli) convolved with the canonical hemodynamic response function. In experiment 1, we additionally determined whether voxels that are responsive to words with acoustic features specifically increase their signal as a function of the relevance of acoustic conceptual features in a parametric manner. Therefore, a second model was set up which included a linear parametric modulation of the canonical hemodynamic response by the semantic relevance ratings of acoustic, visual and action-related features for each individual object name (for a similar approach, see Hauk et al., 2008c; Hauk et al., 2008b). We restricted the analysis to conceptual features as modulators and did not extend this analysis to linguistic variables such as word frequency or word length, because only conceptual factors were of primary interest. For pseudowords, no parametric modulators were defined. In this analysis, only words and pseudowords were distinguished as conditions. To allow for inferences at the population level, a second-level analysis (one-sample $t$ test) considered the contrast images of all subjects and treated subjects as a random effect. In the event-related analysis of experiment 1 (conceptual task), all comparisons were thresholded at a significance level of $p&lt;0.05$ and corrected for multiple comparisons across the entire brain [false discovery rate (FDR)]. In the parametric modulation analysis of experiment 1, only voxels exceeding the threshold of $p&lt;0.05$ (FDR-corrected) for the contrast between words with and without acoustic conceptual features were considered. For the analysis of the block design of experiment 2 (perceptual task), significance level was set to $p&lt;0.01$ (FDR-corrected). The spatial extent threshold of clusters was 10 voxels in all comparisons. All functional group activation maps are overlaid on the MNI reference brain.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Functional brain activation during the conceptual and the perceptual tasks. A, Conceptual task: activation to words with versus words without acoustic features (AF), $p&lt;0.05$, corrected. B, Perceptual task: activation during listening to acoustic noise and real sounds, respectively, $p&lt;0.01$, corrected. C, Parametric modulation: linear increase of the MR signal by acoustic feature relevance (left), $p&lt;0.05$ corrected. The bar chart (right) depicts the effect size for the contributions of acoustic, action-related, and visual conceptual features at the peak voxel within the pSTG/MTG cluster. Small vertical bars indicate the SEM.</p>
<p>ERP recordings and data analysis. ERP recordings were performed in a dimly lit, sound-attenuated, electrically shielded booth. Scalp potentials were collected using an equidistant montage of 64 sintered $\mathrm{Ag} / \mathrm{AgCl}$ electrodes mounted in an elastic cap (Easy Cap). An electrode between Fpz and Fz was connected to the ground, and an electrode between Cz and FCz was used as recording reference. Eye movements were monitored with supra- and infraorbital electrodes and with electrodes on the external canthi. Electrode impedance was kept $&lt;5 \mathrm{k} \Omega$. Electrical signals were amplified with Synamps amplifiers (low-pass filter: $70 \mathrm{~Hz}, 24 \mathrm{~dB} /$ octave attenuation; 50 Hz notch filter) and continuously recorded (digitization rate: 250 Hz ), digitally bandpass filtered (high cutoff: $16 \mathrm{~Hz}, 24 \mathrm{~dB} /$ octave attenuation; low cutoff: $0.1 \mathrm{~Hz}, 12 \mathrm{~dB} /$ octave attenuation) and segmented ( 152 ms before to 1000 ms after the onset of the stimulus). EEG data were corrected to a 152 ms baseline before the onset of the stimulus. Separately for each experimental condition, artifact-free EEG segments to trials with correct responses were averaged synchronous to the onset of the stimulus (BrainVision Analyzer, BrainProducts). To obtain a reference independent estimation of scalp voltage, the average-reference transformation was applied to the ERP data.</p>
<p>Statistical analysis of the ERP data focused on a time window of interest around the offset of the word recognition process (150-250 ms after stimulus onset) (Pulvermüller et al., 2005). Analysis was performed for central electrodes, at which auditory evoked potentials are typically recorded (electrodes F1/F2, FC1/FC2, CP1/CP2, Cz, FCz,</p>
<p>Fz) (Näätänen, 1992). When appropriate, degrees of freedom were adjusted according to the method of Huynh-Feldt (Huynh and Feldt, 1970). Only the corrected significance levels were reported. Significance level was $p&lt;0.05$. We determined the neural sources for significant effects of word type (words with and without acoustic features) using distributed source modeling (minimum norm source estimates) (Hauk, 2004) implemented in BESA 5.1 (MEGIS). Sources were computed for the grand-averaged ERP difference waves between words with and without acoustic conceptual features to eliminate unspecific brain activity associated with word reading. Minimum norm source estimates (minimum L2 norm) were calculated using a standardized realistic head model [finite element model (FEM)]. For estimating the noise regularization parameters, the prestimulus baseline was used. Minimum norm was computed with depth weighting, spatio-temporal weighting and noise weighting for each individual channel. Cortical currents were determined within the time window during which significant ERP differences were obtained at the time point of maximal global field power (GFP) in the ERP difference waves to ensure optimal signal-to-noise-ratio (Kiefer et al., 2007a). Talairach coordinates for the activation peaks were determined on the 2D surface covering the cortex on which the source solution was computed. We report the nearest Brodmann areas (BA) to the peak activations located by the Talairach Daemon (Lancaster et al., 2000).</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Functional-anatomical overlap between conceptual and perceptual processing of acoustic features. Increased functional activation to words with acoustic features (p &lt; 0.05, corrected) overlaps with brain activation during listening to real sounds (p &lt; 0.01, corrected) in pSTG/MTG. Shown are contiguous slices centered on the peak coordinates.</p>
<h2>Results</h2>
<h3>fMRI experiment 1: conceptual task</h3>
<p>Analysis of the behavioral data of the lexical decision task revealed similar reaction times (RT) and error rate (ER) for words with acoustic conceptual features (RT: 749 ms, SD 140; ER: 3.3%, SD 3.5) and without acoustic conceptual features (RT: 753 ms, SD 147 ms; ER: 2.1%, SD 2.8; all p &gt; 0.07). This shows that visual recognition of both word types was comparably difficult.</p>
<p>In a first step of the analysis of the MR data, we identified brain areas involved in conceptual processing of acoustic features by comparing the MR signal to words with acoustic conceptual features and to those without such features. As shown in Figure 1A, we found greater activity to words with acoustic conceptual features in a large cluster of voxels encompassing left posterior superior gyrus (pSTG) and middle temporal gyrus (pMTG) corresponding to BA 22 and 21, respectively (p &lt; 0.05, corrected for multiple comparisons across the entire brain). This region belongs to the auditory association cortex (see Fig. 4). Smaller clusters were obtained in left supramarginal and right fusiform gyri. Words without acoustic conceptual features, in contrast, did not elicit a significantly higher MR signal. In a next step, we related relevance ratings of acoustic, visual and action-related conceptual features to the MR signal in a parametric modulation analysis for the entire brain. Most importantly, we observed a specific brain–behavior relationship between activity in left pSTG/MTG and acoustic conceptual features: the MR signal in this area was parametrically modulated and increased linearly as a function of the relevance of acoustic features for a concept as measured by the word ratings (Fig. 1C). In contrast, the relevance of visual and action features did not significantly modulate the MR signal in left pSTG/pMTG. Extend and location of this cluster obtained in the parametric modulation analysis was identical with the cluster found in the conventional contrast analysis. Activity in left supramarginal gyrus was modulated by the relevance of both acoustic and action feature thereby lacking the specificity for acoustic conceptual features found in pSTG/pMTG. Relevance of visual conceptual features as parameter did not significantly modulate the MR signal. These findings show that left pSTG/pMTG is essentially and specifically involved in representing acoustic conceptual features.</p>
<h3>fMRI experiment 2: perceptual task</h3>
<p>In the second experiment conducted within the participant group of experiment 1, we determined brain areas involved in listening to real sounds (p &lt; 0.01, corrected for multiple comparisons across the entire brain). When contrasted to the resting condition, both active conditions (real sounds, acoustic noise) recruited the superior temporal cortex including the temporal plane bilaterally (Fig. 1B). Based on the known neuroanatomy of the auditory system (Howard et al., 2000), the temporal plane comprises primary and secondary auditory cortex whereas the neighboring areas in superior and middle temporal gyri encompass auditory association areas. The MR signal was generally higher to real sounds than to acoustic noise in the temporal plane and in superior temporal cortex. Most importantly, the large cluster that responded to real sounds encompassed a region of the auditory association cortex in left pSTG/MTG (1.4 cm³ = 7 voxels) which overlapped with the cluster activated by words with acoustic conceptual features (Fig. 2). Because the latter cluster was identical with that obtained in the parametric modulation analysis, this overlapping cluster for perceptual and conceptual sound processing had the same size regardless of the form of analysis in determining the neural substrate of acoustic conceptual features. Hence, perceiving real sounds and processing of acoustic conceptual features share a common neural substrate in temporal cortex.</p>
<h3>ERP experiment 3: conceptual task</h3>
<p>In the ERP experiment, lexical decision latencies and ER were similar for words with acoustic conceptual features (RT: 591 ms, SD 79; ER: 3.9%, SD 1.7) and without acoustic conceptual features (RT 599 ms, SD 80; ER: 3.9%, SD 2.6; all p &gt; 0.08) demonstrating a comparable level of task difficulty for both word types as in experiment 1.</p>
<p>Analysis of ERP recordings revealed that auditory areas are rapidly ignited at ~150 ms after word onset (Fig. 3): ERPs to words with and without conceptual features diverged significantly (p = 0.03) from each other within a time window of 150–200 ms at all electrodes of the central electrode cluster. At these electrode sites, acoustically evoked potentials are typically recorded (Näätänen, 1992). Hence, scalp ERP effects had the topography of auditory evoked potentials with an amplitude maximum at central electrodes (Scherg and von Cramon, 1984). Amplitude of these ERP components is increased, if attention is directed toward auditory stimuli (Rugg and Coles, 1995). Source analysis of scalp ERPs with minimum norm estimates (Hauk, 2004) identified generators in and close to pSTG/MTG (BA 21, 22).</p>
<h2>Discussion</h2>
<p>Theories of embodied conceptual representations propose that concepts are grounded in the sensory and motor systems of the</p>
<p>brain (Warrington and McCarthy, 1987; Kiefer and Spitzer, 2001; Martin and Chao, 2001; Barsalou et al., 2003; Gallese and Lakoff, 2005; Pulvermüller, 2005). It is assumed that access to a concept depends on a partial reinstatement of brain activity that initially occurred during perception of objects and events. The ultimate test for grounding concepts in perception requires the fulfillment of the following four criteria: conceptual processing during (1) an implicit task should activate (2) a perceptual region (3) rapidly and (4) selectively. We therefore investigated the neural correlates of acoustic conceptual features (conceptual task) and sound perception (perceptual task) in three experiments with fMRI and ERP measurements. In the conceptual task, participants performed lexical decisions on visually presented object names. This task induces an implicit access to conceptual features thereby minimizing the possibility of postconceptual strategic processes such as imagery. In the perceptual task, participants listened to real sounds.</p>
<p>In line with these criteria, we provide four converging markers for a link between auditory and conceptual brain systems. First and second, with the implicit lexical decision task, we found overlapping activation within temporal cortex for conceptual and perceptual processing of acoustic features: words with acoustic conceptual features elicited higher activity in left pSTG/MTG compared with words without acoustic conceptual features. This posterior temporal area was also activated when participants listened to real sounds. Thirdly, ERP recordings revealed an early onset of left pSTG/ MTG activity starting at $\sim 150 \mathrm{~ms}$ after word onset. Taking into account the limited spatial resolution of ERPs, the results from source analysis are in good agreement with our fMRI findings.</p>
<p>The time course of brain activity as derived from ERPs allows determining whether the present activation in temporal cortex is due to conceptual processing of acoustic features or auditory imagery. Visual word recognition is completed at $\sim 150 \mathrm{~ms}$ (Pulvermüller et al., 2005), and full access to a concept is a prerequisite for postconceptual imagery processes to subsequently occur (Kosslyn, 1994). Therefore, the early onset of the ERP effects immediately thereafter suggests that the observed activity in left pSTG/MTG reflects access to acoustic conceptual features rather than temporarily later imagery processes (for a distinction between conceptual processing and imagery, see also below). Although an early access to modality-specific conceptual features is an important criterion to differentiate between conceptual processing and imagery, this does not preclude the possibility of conceptual feature retrieval at later time points as proposed by semantic memory models (e.g., Smith et al., 1974). Fourthly and most importantly, activity in left pSTG/MTG increased linearly as a function of the relevance of acoustic conceptual features as determined in a behavioral rating study. In contrast, relevance ratings of visual and action-related related features did not modulate activity in this region. Hence, we found a specific brain-
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Time course of conceptual processing of acoustic features. A, Event-related scalp potentials to words with vs without acoustic features at central electrodes. Potentials are collapsed across electrode sites. The arrow indicates the onset of the effect. B, Topography of the ERP effect as recorded at the scalp at its maximum global field power. Shown is the interpolated potential difference between conditions (ERPs to words with acoustic features subtracted from ERPs to words without acoustic features). Note the relative negativity to words with acoustic features at the central scalp (visualized in blue color). In this scalp region, auditory evoked potentials are typically recorded (Näätänen, 1992). C, Brain electrical sources of scalp ERPs: maps of cortical currents calculated according to the minimum norm algorithm from the ERP difference waves. Maps are shown for the respective maxima in global field power. Strongest cortical currents (visualized in blue color) were observed in and close to left pSTG/MTG.
behavior relation between activity in left pSTG/MTG and relevance ratings of acoustic conceptual features.</p>
<p>The MR signal in the supramarginal gyrus (SMG) was modulated by both action-related and acoustic features, thus lacking the specificity of the pSTG/MTG response. SMG activation could reflect simulating the actions that cause a sound to occur given its role in action representation (Vingerhoets, 2008). Alternatively, SMG could support semantic feature integration regardless of feature type (Snyder et al., 1995; Corina et al., 1999). Unlike in earlier studies (Davis et al., 2004; Hauk et al., 2008c; Hoenig et al., 2008), we did not observe a modulation of brain activity by visual and action-related features in sensory and motor cortex. This is because of the fact that the stimulus material was optimized for investigating acoustic conceptual features as the main purpose of this study.</p>
<p>The involvement of left pSTG/MTG in higher level sound processing has been shown by previous imaging studies as summarized in Figure 4. This region contributes to the processing of complex sounds including human voices (Belin et al., 2000; Specht and Reul, 2003) and is activated during sound recognition (Lewis et al., 2004), episodic recall of sounds (Wheeler et al., 2000), and music imagery (Zatorre et al., 1996; Kraemer et al., 2005). Activity in pSTG/MTG was also observed for decisions on acoustic object attributes (Kellenbach et al., 2001; Goldberg et al., 2006) and during recognition of novel objects for which acoustic attributes were learned in a preceding training phase (James and Gauthier, 2003). Patients with a lesion in this area exhibit sound recognition deficits (Clarke et al., 2000). This evidence clearly demonstrates that pSTG/MTG is part of auditory association</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. Summary of findings from previous imaging studies on the role of pSTG/MTG in sound processing. Peak activations (red symbols) are overlaid on the MNI reference brain. Posterior STG/MTG has been found activated during voice listening (Belin et al., 2000) (◇), sound recognition (Lewis et al., 2004) (×); Specht and Reul, 2003 (■), word recognition (Specht and Reul, 2003) (■), sound retrieval (Wheeler et al., 2000) (○), sound imagery (Zatorre et al., 1996) (♦, □), and sound verification (Kellenbach et al., 2001) (+). Peak activation of acoustic conceptual processing from the present study (blue diamond) is located within this cluster of previously reported activations in pSTG/MTG. The gray-shaded areas schematically delineate the respective anatomical location of primary (BA 41) and secondary auditory cortex (BA 42) as well as auditory association cortex (BA 22).</p>
<p>Cortex, both with respect to its functional and anatomical properties (Howard et al., 2000).</p>
<p>The present study shows for the first time that left pSTG/MTG is the neural substrate of acoustic conceptual processing: this region responded to acoustic conceptual features even when probed implicitly in a lexical decision task. Furthermore, activity was gradually modulated by the relevance of acoustic conceptual features, but not by the relevance of visual or action-related features. Hence, this region in auditory association cortex selectively codes acoustic conceptual object features.</p>
<p>Our results strongly suggest that conceptual features are localizable in the brain and not arbitrarily distributed across the cortex as previously proposed (Anderson, 1983; Tyler and Moss, 2001). Rather, they are coded in the corresponding sensory association areas that are also activated during perception. The selective brain–behavior relation for acoustic conceptual features in an auditory brain region (left pSTG/MTG), its early onset of 150 ms and the implicitness of the conceptual task unequivocally point to a conceptual origin of this effect thereby ruling out postconceptual strategies such as imagery. The selective modulation of left pSTG/MTG activity by auditory, but not by visual or action-related conceptual features demonstrates that this region represents auditory conceptual knowledge rather than playing a general, unspecific role in conceptual processing. The present findings provide compelling evidence for a functional and anatomical link between the perceptual and conceptual brain systems, thereby considerably extending findings from earlier studies (Chao et al., 1999; Simmons et al., 2005; Hoenig et al., 2008).</p>
<p>Unlike perceptual sound processing and sound imagery (Zatorre et al., 1996; Kraemer et al., 2005), conceptual processing of acoustic features is confined to higher-level auditory association cortex and does not encompass primary and secondary auditory cortex within the temporal plane. These differences in functional neuroanatomy might reflect differences in experiential quality (for a distinction between imagery and conceptual processing, see Hauk et al., 2008c; Kosslyn, 1994; Kiefer et al., 2007b; Machery, 2007). Conceptual processing of acoustic features lacks the vivid sensory experience typically present in perception and imagery: obviously, we do not experience a "ringing" sound when reading the word "telephone." In fact, the lack of experiential quality in conceptual processing is appropriate and instrumental because the modality-specific experience of sensory conceptual features during thought and verbal communication would considerably interfere with action planning processes that must rely on perceptual information from the current situation (Milner and Goodale, 1995). Left pSTG/MTG may therefore serve as an auditory convergence zone (Damasio, 1989) that codes higher-level acoustic object information contributing to a concept. Although perceptual and conceptual processing of acoustic features considerably overlap in functional neuroanatomy as demonstrated here, both levels of representation are not identical with regard to subjective phenomenal experience and their neural substrate.</p>
<p>In conclusion, our results provide unequivocal evidence for a link between perceptual and conceptual acoustic processing, with the left pSTG/MTG as the shared neural substrate. Hence, conceptual processing of acoustic features involves a partial reinstatement of brain activity during perceptual experience. The currently presented four converging markers fulfill the requirements for demonstrating this link at a functional and anatomical level: the implicitness of the conceptual task, the selective modulation of left pSTG/MTG activity by acoustic feature relevance, the early onset of this activity at 150 ms and its anatomical overlap with perceptual sound processing show that left pSTG/MTG represents auditory conceptual features in a modality-specific manner. Because we used stimuli from a variety of object categories, our findings strongly suggest a modality-specific representation for a broad range of object concepts that are central for everyday life. Possibly, a modality-specific representation could generalize to other object concepts or even to abstract concepts such as "freedom" or "justice". These fascinating issues have to be addressed in future studies. Furthermore, our findings stress the necessity of sensory experiences in the relevant modalities to acquire rich, fully developed concepts of our physical and social world. Conversely, a lack of multimodal sensory experience would result in an impoverished development of conceptual representations. Finally, our results draw a strong parallel with the functional neuroanatomy of episodic or working memory systems. For these other memory systems, retrieval of sensory properties of an object or event recruits corresponding modality-specific sensory areas that were initially activated during encoding (Wheeler et al., 2000; Ranganath et al., 2004; Kessler and Kiefer, 2005; Khader et al., 2005). Thus, modality-specificity might be a general organizational principle in cortical memory representation.</p>
<h3>References</h3>
<p>Anderson JR (1983) The architecture of cognition. Hillsdale, NJ: Erlbaum.</p>
<p>Barsalou LW, Kyle Simmons W, Barbey AK, Wilson CD (2003) Grounding conceptual knowledge in modality-specific systems. Trends Cogn Sci 7:84–91.</p>
<p>Belin P, Zatorre RJ, Lafaille P, Ahad P, Pike B (2000) Voice-selective areas in human auditory cortex. Nature 403:309–312.</p>
<p>Boulenger V, Roy AC, Paulignan Y, Deprez V, Jeannerod M, Nazir TA (2006)</p>
<p>Cross-talk between language processes and overt motor behavior in the first 200 msec of processing. J Cogn Neurosci 18:1607-1615.
Chao LL, Haxby JV, Martin A (1999) Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. Nat Neurosci 2:913-919.
Clarke S, Bellmann A, Meuli RA, Assal G, Steck AJ (2000) Auditory agnosia and auditory spatial deficits following left hemispheric lesions: evidence for distinct processing pathways. Neuropsychologia 38:797-807.
Corina DP, McBurney SL, Dodrill C, Hinshaw K, Brinkley J, Ojemann G (1999) Functional roles of Broca's area and SMG: evidence from cortical stimulation mapping in a deaf signer. Neuroimage 10:570-581.
Damasio AR (1989) Time-locked multiregional retroactivation: a systemslevel proposal for the neural substrates of recall and recognition. Cognition 33:25-62.
Davis MH, Meunier F, Marslen-Wilson WD (2004) Neural responses to morphological, syntactic, and semantic properties of single words: an fMRI study. Brain Lang 89:439-449.
Gallese V, Lakoff G (2005) The brain's concepts: the role of the sensorymotor system in conceptual knowledge. Cogn Neuropsychol 22:455-479.
Gerlach C (2007) A review of functional imaging studies on category specificity. J Cogn Neurosci 19:296-314.
Gerlach C, Law I, Gade A, Paulson OB (1999) Perceptual differentiation and category effects in normal object recognition: a PET study. Brain 122:2159-2170.
Goldberg RF, Perfetti CA, Schneider W (2006) Perceptual knowledge retrieval activates sensory brain regions. J Neurosci 26:4917-4921.
Hauk O (2004) Keep it simple: a case for using classical minimum norm estimation in the analysis of EEG and MEG data. Neuroimage 21:1612-1621.
Hauk O, Shtyrov Y, Pulvermuller F (2008a) The time course of action and action-word comprehension in the human brain as revealed by neurophysiology. J Physiol Paris 102:50-58.
Hauk O, Davis MH, Pulvermüller F (2008b) Modulation of brain activity by multiple lexical and word form variables in visual word recognition: a parametric fMRI study. Neuroimage 42:1185-1195.
Hauk O, Davis MH, Kherif F, Pulvermüller F (2008c) Imagery or meaning? Evidence for a semantic origin of category-specific brain activity in metabolic imaging. Eur J Neurosci 27:1856-1866.
Helbig HB, Graf M, Kiefer M (2006) The role of action representations in visual object recognition. Exp Brain Res 174:221-228.
Hoenig K, Sim EJ, Bochev V, Herrnberger B, Kiefer M (2008) Conceptual flexibility in the human brain: dynamic recruitment of semantic maps from visual, motion and motor-related areas. J Cogn Neurosci 20:1799-1814.
Howard MA, Volkov IO, Mirsky R, Garell PC, Noh MD, Granner M, Damasio H, Steinschneider M, Reale RA, Hind JE, Brugge JF (2000) Auditory cortex on the human posterior superior temporal gyrus. J Comp Neurol 416:79-92.
Humphreys GW, Riddoch MJ, Quinlan PT (1988) Cascade processes in picture identification. Cogn Neuropsychol 5:67-103.
Huynh H, Feldt LS (1970) Conditions under which mean square ratios in repeated measures designs have exact F-distributions. J Am Stat Assoc 65:1582-1589.
James TW, Gauthier I (2003) Auditory and action semantic features activate sensory-specific perceptual brain regions. Curr Biol 13:1792-1796.
Kellenbach ML, Brett M, Patterson K (2001) Large, colorful, or noisy? Attribute- and modality-specific activations during retrieval of perceptual attribute knowledge. Cogn Affect Behav Neurosci 1:207-221.
Kessler K, Kiefer M (2005) Disturbing visual working memory: Electrophysiological evidence for a role of prefrontal cortex in recovery from interference. Cereb Cortex 15:1075-1087.
Khader P, Burke M, Bien S, Ranganath C, Rösler F (2005) Content-specific activation during associative long-term memory retrieval. Neuroimage 27:805-816.
Kiefer M (2001) Perceptual and semantic sources of category-specific effects in object categorization: event-related potentials during picture and word categorization. Mem Cogn 29:100-116.
Kiefer M (2005) Repetition priming modulates category-related effects on event-related potentials: further evidence for multiple cortical semantic systems. J Cogn Neurosci 17:199-211.</p>
<p>Kiefer M, Spitzer M (2001) The limits of a distributed account of conceptual knowledge. Trends Cogn Sci 5:469-471.
Kiefer M, Schuch S, Schenck W, Fiedler K (2007a) Mood states modulate activity in semantic brain areas during emotional word encoding. Cereb Cortex 17:1516-1530.
Kiefer M, Sim EJ, Liebich S, Hauk O, Tanaka J (2007b) Experiencedependent plasticity of conceptual representations in human sensorymotor areas. J Cogn Neurosci 19:525-542.
Kosslyn SM (1994) Image and brain: the resolution of the imagery debate. Cambridge, MA: MIT.
Kraemer DJ, Macrae CN, Green AE, Kelley WM (2005) Musical imagery: sound of silence activates auditory cortex. Nature 434:158.
Lancaster JL, Woldorff MG, Parsons LM, Liotti M, Freitas CS, Rainey L, Kochunov PV, Nickerson D, Mikiten SA, Fox PT (2000) Automated Talairach atlas labels for functional brain mapping. Hum Brain Mapp 10:120-131.
Levelt WJ, Roelofs A, Meyer AS (1999) A theory of lexical access in speech production. Behav Brain Sci 22:1-38.
Lewis JW, Wightman FL, Brefczynski JA, Phinney RE, Binder JR, DeYoe EA (2004) Human brain regions involved in recognizing environmental sounds. Cereb Cortex 14:1008-1021.
Machery E (2007) Concept empiricism: a methodological critique. Cognition 104:19-46.
Martin A, Chao LL (2001) Semantic memory and the brain: structure and processes. Curr Opin Neurobiol 11:194-201.
Martin A, Wiggs CL, Ungerleider LG, Haxby JV (1996) Neural correlates of category-specific knowledge. Nature 379:649-652.
Milner AD, Goodale MA (1995) The visual brain in action. Oxford: Oxford UP.
Näätänen R (1992) Attention and brain function. Hillsdale, NJ: Erlbaum.
Oldfield RC (1971) The assessment and analysis of handedness: the Edinburgh Inventory. Neuropsychologia 9:97-113.
Pulvermüller F (2005) Brain mechanisms linking language and action. Nat Rev Neurosci 6:576-582.
Pulvermüller F, Shtyrov Y, Ilmoniemi R (2005) Brain signatures of meaning access in action word recognition. J Cogn Neurosci 17:884-892.
Ranganath C, Cohen MX, Dam C, D'Esposito M (2004) Inferior temporal, prefrontal, and hippocampal contributions to visual working memory maintenance and associative memory retrieval. J Neurosci 24:3917-3925.
Rugg MD, Coles MGH (1995) The ERP and cognitive psychology: Conceptual issues. In: Electrophysiology of mind (Rugg MD, Coles MGH, eds), pp 27-39. Oxford: Oxford UP.
Scherg M, von Cramon D (1984) Topographical analysis of auditory evoked potentials: Derivation of components. In: Evoked potentials (Nodar RH, Barber C, eds), pp 73-81. Boston: Butterworth.
Simmons WK, Martin A, Barsalou LW (2005) Pictures of appetizing foods activate gustatory cortices for taste and reward. Cereb Cortex 15:1602-1608.
Smith EE, Shoben EJ, Rips LJ (1974) Structure and process in semantic memory: a featural model for semantic decisions. Psychol Rev 81:214-241.
Snyder AZ, Abdullaev YG, Posner MI, Raichle ME (1995) Scalp electrical potentials reflect regional blood flow responses during processing of written words. Proc Natl Acad Sci U S A 92:1689-1693.
Specht K, Reul J (2003) Functional segregation of the temporal lobes into highly differentiated subsystems for auditory perception: an auditory rapid event-related fMRI-task. Neuroimage 20:1944-1954.
Tyler LK, Moss HE (2001) Towards a distributed account of conceptual knowledge. Trends Cogn Sci 5:244-252.
Vingerhoets G (2008) Knowing about tools: neural correlates of tool familiarity and experience. Neuroimage 40:1380-1391.
Warrington EK, McCarthy RA (1987) Categories of knowledge. Brain 110:1273-1296.
Wheeler ME, Petersen SE, Buckner RL (2000) Memory's echo: vivid remembering reactivates sensory-specific cortex. Proc Natl Acad Sci U S A 97:11125-11129.
Zatorre RJ, Halpern AR, Perry DW, Meyer E, Evans AC (1996) Hearing in the mind's ear: a PET investigation of musical imagery and perception. J Cogn Neurosci 8:29-46.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Received July 30, 2008; revised Oct. 6, 2008; accepted Oct. 8, 2008.
This work was supported by grants from the German Research Foundation (DFG Ki 804/1-3) and from the European Social Foundation to M.K. We thank Cornelia Müller, Florian Diehl, and Gerwin Müller for their help with data acquisition. We are grateful to Michael Posner, Stanislas Dehaene, Friedemann Pulvermüller, Lawrence Barsalou, and one anonymous reviewer for providing helpful comments on this manuscript.</p>
<p>Correspondence should be addressed to Markus Kiefer, Department of Psychiatry, University of Ulm, Section for Cognitive Electrophysiology, Leimgrubenweg 12, 89075 Ulm, Germany. E-mail: Markus.Kiefer@uni-ulm.de. URL: http://www.uni-ulm.de/ mkiefer/.
DOI:10.1523/JRESROSCI.3579-08.2008
Copyright (c) 2008 Society for Neuroscience 0270-6474/08/2812224-07515.00/0&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>