<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2660 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2660</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2660</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-5f488bcca8af38157201b1075da2e08fbc6b0489</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/5f488bcca8af38157201b1075da2e08fbc6b0489" target="_blank">Representation of probabilistic scientific knowledge</a></p>
                <p><strong>Paper Venue:</strong> Journal of Biomedical Semantics</p>
                <p><strong>Paper TL;DR:</strong> The ontology HELO is designed to support probabilistic reasoning, and provides semantic descriptors for reporting on research that involves operations with probabilities, and demonstrates the utility of HELO on three worked examples.</p>
                <p><strong>Paper Abstract:</strong> The theory of probability is widely used in biomedical research for data analysis and modelling. In previous work the probabilities of the research hypotheses have been recorded as experimental metadata. The ontology HELO is designed to support probabilistic reasoning, and provides semantic descriptors for reporting on research that involves operations with probabilities. HELO explicitly links research statements such as hypotheses, models, laws, conclusions, etc. to the associated probabilities of these statements being true. HELO enables the explicit semantic representation and accurate recording of probabilities in hypotheses, as well as the inference methods used to generate and update those hypotheses. We demonstrate the utility of HELO on three worked examples: changes in the probability of the hypothesis that sirtuins regulate human life span; changes in the probability of hypotheses about gene functions in the S. cerevisiae aromatic amino acid pathway; and the use of active learning in drug design (quantitative structure activity relation learning), where a strategy for the selection of compounds with the highest probability of improving on the best known compound was used. HELO is open source and available at https://github.com/larisa-soldatova/HELO</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2660.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2660.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HELO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypothEsis and Law Ontology</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An OWL-DL ontology for explicit semantic representation of research statements and their associated probabilities, methods of probability estimation, and probabilistic operations to support automated scientific reasoning and Robot Scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HELO (HypothEsis and Law Ontology)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A knowledge-representation ontology (expressed in OWL-DL) that models research statements (hypotheses, laws, conclusions, etc.) and links each to probability values (prior/posterior) and to the method/procedure by which those probabilities were estimated. HELO defines probability as a subclass of mathematical function and includes classes for probability distributions, variables, mean, variance, and qualities (random, independent, joint). It imports top-level classes (BFO, IAO, OBI) and re-uses relations (supports, refutes, HAS-SUPPORTING-EVIDENCE, etc.). HELO records methods of probability estimation (Bayesian inference, expert estimation, statistical calculation, deduction, abduction, induction, homological inference) and links to concrete algorithm implementations via a procedure class.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>ontology / knowledge representation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedicine / bioinformatics</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>HELO does not itself generate hypotheses; it provides structured representation to record hypotheses produced by other systems (logical models, Robot Scientists, text mining). It supports representation of hypothesis sets and logical combination of atomic statements defined in domain ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Records and associates plausibility via explicit probability values (prior/posterior) and linked evidence (supporting/refuting) and records method used to obtain probability (e.g., Bayesian inference, expert estimation).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Represents hypothesis quality as numeric probability values (prior and posterior) and supports recording of statistical descriptors (mean, variance, distributions) and provenance of probability estimates; no specific single metric beyond probability is prescribed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Enables recording of experimental validation outcomes and updates of probabilities (posterior computation) but does not itself run experiments; used to store validation provenance and evidence links.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>HELO is OWL-DL, checked for logical consistency with reasoners (HermiT, FaCT++), and is open source (GitHub) enabling shared formal representation; the paper does not list experimental reproducibility protocols beyond representation and provenance capture.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Explicit representation of uncertainty via prior/posterior probabilities, support for probability distributions (continuous/discrete), and explicit linking to estimation methods (Bayesian inference, frequentist interpretations). HELO models probability as mathematical function enabling operations with distributions, means, variances.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Does not itself compute probabilities; it relies on external methods and expert inputs for probability estimates (paper notes difficulty of eliciting priors). The ontology requires consistent upstream probability estimations and accurate evidence provenance to be useful.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2660.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adam (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A physically implemented Robot Scientist that uses logical models and abductive inference to generate hypotheses, plans and executes automated experiments, and updates hypothesis probabilities until hypotheses are rejected or accepted.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adam (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A robotic laboratory automation system that performs cycles of automated scientific discovery: it uses a logical model of a biological pathway, employs abductive inference to formulate a hypothesis set (e.g., 8 candidate deleted genes), assigns prior probabilities (uniform in the example), plans experiments based on predicted information gain and experimental cost, executes wet-lab auxotrophic experiments, observes outcomes, and updates posterior probabilities iteratively until a single hypothesis remains (posterior 1).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>robotic automation with symbolic/logic inference (abductive inference) and decision-theoretic experiment planning</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology (functional genomics, yeast genetics)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Abductive inference from a logical model of the S. cerevisiae aromatic amino acid pathway to produce a set of candidate hypotheses (PREDICATE(entity_i, entity_j) forms), forming a hypotheses set with summed probability 1.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Initial plausibility encoded as prior probabilities (e.g., uniform priors) and updated by experimental outcomes; plausibility also influenced by logical model consistency and available supporting/refuting evidence recorded in HELO.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Hypothesis quality operationalized as numeric prior/posterior probability; selection of experiments considers predicted information gain and cost; no additional scalar quality metric reported beyond probability and information gain estimations.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Empirical wet-lab experimental cycles executed by the robot: experiments test hypotheses and posterior probabilities are updated; hypotheses are rejected/retained based on experimental outcomes until convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Automated experiment execution and metadata recording (previous work recorded hypothesis probabilities in experiment metadata) enabling reproducibility; not further detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Bayesian-style updating of hypothesis probabilities (priors → posteriors) based on experimental evidence; experiment selection uses predicted information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Worked example on the S. cerevisiae aromatic amino acid pathway (King et al. Robot Scientist experiments referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Demonstrated full automation of discovery: Adam reduced an 8-hypothesis set to a single accepted hypothesis via iterative experimentation; posterior probabilities converged to 1 for the accepted hypothesis and 0 for rejected ones in the example. No standard classification metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on availability of a logical model and reasonably specified priors; eliciting accurate prior probabilities is difficult (noted generally), and results depend on model fidelity and experimental noise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2660.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gaussian process QSAR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian process regression model for QSAR (quantitative structure–activity relationship)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Gaussian process regression model used to predict pGI50 activity of compounds; it outputs a predictive Normal distribution per compound enabling active selection based on acquisition functions that use uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian process QSAR model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A regression model (Gaussian process) fitted to measured pGI50 values that produces a predictive Normal distribution (mean and variance) for each untested compound's activity; the predictive distribution enables computation of probabilities (e.g., probability a compound exceeds current kth-best) and supports acquisition functions for active selection (MPI, MEI, LCB).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic regression / Gaussian process</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / drug discovery / computational biology</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates ranked candidate hypotheses (compounds likely to have high pGI50) by predicting pGI50 distributions and computing probabilities/expected improvements relative to current bests.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility expressed as predictive probability derived from Gaussian predictive distribution (e.g., probability that a compound's pGI50 exceeds current k-th best).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Uses predictive mean and variance from the GP to compute acquisition values: probability of improvement (MPI), expected improvement (MEI), and lower confidence bound criteria; also reports probabilities P1/P2/P3 for candidate improvement as examples.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational cross-validated selection experiments on the NCI60 dataset: selected compounds were evaluated by retrieving their measured pGI50 values from the dataset (the study simulated active selection and measured how quickly high-activity compounds were found).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Experiments repeated 20 times per computational experiment and averaged; use of public NCI60 dataset provides reproducibility baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Gaussian process predictive distributions (Normal) providing mean and variance per compound; probabilities of improvement computed from these distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>NCI60 human tumor cell line anticancer drug screen dataset</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Qualitative results: active selection substantially speeds finding high pGI50 compounds; table examples show per-iteration probabilities (P3 values up to 0.99994 at an early stage for a particular compound). No standard accuracy/ROC metrics reported in the paper; experimental selection strategies were compared averaged over 20 repeats.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared selection strategies (optimistic/LCB, MPI, MEI, random). Optimistic strategy was most robust across situations, MPI competitive at medium budgets, MEI performs well when ~10 compounds are sought, and random selection performs worst.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Performance of strategies depends on experimental budget: MPI may fail under low budgets and does not exploit high budgets optimally; MEI suited when several compounds (~10) required. No absolute guarantees provided; results are dataset-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2660.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active k-optimization strategies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Active selection / Bayesian optimization strategies (Lower confidence bound, MPI, MEI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Acquisition-function–based selection strategies used in active learning to choose compounds for experimental evaluation: lower confidence bound (optimistic), most probable improvement (MPI), and maximum expected improvement (MEI).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Active k-optimization strategies (LCB / MPI / MEI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A set of decision-theoretic acquisition strategies implemented on top of predictive models (Gaussian process) to select which instances to test next: Lower confidence bound (optimistic strategy) selects by an LCB criterion combining mean and uncertainty; MPI selects the compound with maximal probability to improve on the current kth-best; MEI selects by maximum expected improvement (expected value of improvement over current best).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>active learning / Bayesian optimization / acquisition functions</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>drug discovery / high-throughput screening</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Selects experimental hypotheses (which compound to test next) by optimizing acquisition functions computed from the predictive distribution (probability of improvement, expected improvement, or lower confidence bounds).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td>MPI and MEI inherently quantify potential novelty relative to current best via probability or expected magnitude of improvement; no additional novelty metric reported.</td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility derived from predictive distributions (GP mean and variance) producing probabilities or expectations used to rank candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Managed via choice of acquisition function: MPI emphasizes probability of improvement (plausibility), MEI balances plausibility with magnitude of improvement (novelty magnitude), and LCB (optimistic) trades off mean and uncertainty; the paper reports empirical trade-offs (e.g., MPI good for medium budgets, MEI for ~10 compounds).</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Acquisition scores (probability of improvement, expected improvement, LCB score) computed from Gaussian predictive distributions; these scores are used as pre-experiment quality proxies.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Simulated active learning experiments on NCI60 where acquisition-guided picks are compared against random baseline and other strategies by how quickly high-activity compounds are found (averaged over 20 repeats).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Repeated runs (20 repeats), use of public dataset (NCI60); results averaged.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Depends on GP predictive mean and variance; acquisition functions explicitly use these uncertainties (probability and expectation of improvement, confidence bound calculations).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>NCI60 dataset (US NCI 60 anticancer drug screen)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical comparative statements: optimistic (LCB) strategy most robust (either best or not significantly worse than best in all considered situations); MPI competitive for medium budgets; MEI best when around 10 compounds needed; random selection worst. No single numeric summary metrics provided beyond per-iteration example probabilities and qualitative comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared against random selection and across strategies; random selection performs worse than optimized strategies in all settings considered.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Strategy performance sensitive to experimental budget and task (e.g., MPI can fail under very low budgets and may not use high budgets optimally).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2660.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureka</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureka system (law discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system referenced as producing research laws or production rules (models) and distilling natural laws from experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eureka (law-discovery system)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Cited as an example of a system that outputs research laws (models, production rules) that can be represented in HELO (reference to systems that distill laws of nature from data). The paper references such systems as sources of research laws that HELO can encode.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic discovery / equation / law induction system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific modeling (cited in context of natural law discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Inductive distillation of laws from experimental data (symbolic regression / equation discovery approaches referenced in literature).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2660.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GeneWays</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GeneWays text-mining system / GeneWays 7.0 database</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated text-mining pipeline that extracted molecular interaction assertions from hundreds of thousands of full-text articles and abstracts to create a large structured database (used to support evidence counts for biological claims).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GeneWays (text mining / knowledge extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An automated literature-mining system that produced GeneWays 7.0 by processing 368,331 full-text articles and over 8 million abstracts, extracting molecular interaction relations (~500 relation types). In the paper, a subset (yeast70) is used to quantify frequency of assertions about SIR2 and aging to argue for high support for the hypothesis that SIR2 regulates yeast lifespan.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>text-mining / information extraction / knowledge base construction</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>bioinformatics / literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Produces candidate assertions and supports for hypotheses by extracting relations and co-mentions from literature; these extractions contribute to evidence supporting hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Provides counts/frequency of supporting sentences (e.g., 492 sentences containing SIR2 and 'aging') that can be interpreted as evidence weight for plausibility estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Indirect: frequency counts of supporting sentences and relations in the text-mined database used as an input to human/expert probability estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Text-mining derived evidence cited as supportive material; validation of text-mining extractions is not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>yeast70 subset of GeneWays 7.0 was used to count sentences linking SIR2 and aging</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Text-mining outputs require downstream curation/evaluation: frequency of mentions does not equal truth; the paper uses counts qualitatively to argue support but notes provenance and quality factors (lab, publisher) affect weight of evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2660.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Abductive inference</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Abductive inference (inference to best explanation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An AI reasoning approach used by the Robot Scientist to generate explanatory hypotheses from a logical model and observed phenomena (used to produce candidate hypotheses that are then experimentally tested).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Abductive inference</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A symbolic reasoning technique that generates hypotheses that would, if true, best explain observed or desired outcomes given a background logical model; in the Robot Scientist example abductive inference produced an initial hypotheses set (8 candidates) about which gene was deleted in a pathway.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>symbolic reasoning / logical inference</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biology (experimental design), general scientific reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generates candidate hypotheses by finding assumable facts that would make the logical model consistent with observed data or desired explanatory goals (abduction).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility initially set via prior probabilities (e.g., uniform) and then updated by experimental evidence; abduction itself does not assign numeric plausibility unless coupled with probabilistic machinery.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Coupled with automated experiments (e.g., Adam) that test abductively generated hypotheses and update their posterior probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>When used within the Robot Scientist framework, abductive hypotheses are assigned prior probabilities and updated via Bayesian-like posterior updates based on experimental evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Abductive inference depends on completeness and correctness of the underlying logical model; without probabilistic priors it yields candidate explanations but not graded certainty.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2660.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian inference</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian inference / Bayesian updating</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic framework for updating prior beliefs about hypotheses into posterior probabilities given new evidence, presented as the rational approach for scientific belief updating and directly supported/recorded by HELO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bayesian inference</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A probabilistic method where prior probabilities for hypotheses are updated to posterior probabilities via Bayes' rule in light of new evidence; HELO explicitly models priors and posteriors and records Bayesian inference as a method of probability estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>probabilistic / Bayesian</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>general scientific reasoning / biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is encoded as prior and posterior probabilities; the Bayesian framework yields quantitative plausibility updates according to evidence likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Quality represented as posterior probability; HELO supports recording mean/variance and probability distributions for quantitative descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Posterior updates following evidence; experimental data serve as likelihood in Bayes' rule to validate/refute hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Bayesian priors and posteriors provide principled uncertainty quantification; HELO records whether probability values were obtained by Bayesian inference.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires specification of prior probabilities (elicitation is difficult); posterior conclusions depend on the chosen priors and likelihood models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2660.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2660.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Homological inference</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Homologous inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific probabilistic inference method used to transfer evidence from model organisms (homologs) to human hypotheses by adjusting probabilities based on homology relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Homologous inference</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A biological inference mechanism whereby probabilities of hypotheses about one species (e.g., C. elegans or S. cerevisiae) are used to influence the probability of related hypotheses in another species (e.g., human SIRT1) through homology mappings (HAS-PROBABILITY(h_source, p_source) → HAS-PROBABILITY(h_target, p_translated)).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>domain-specific probabilistic inference / knowledge-based transfer</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>comparative biology / evolutionary inference</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility of human-relevant hypotheses is increased or decreased by probabilistic evidence from homologs using homology-based inference rules recorded in HELO.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Indirect: model-organism experimental results alter probabilities of human hypotheses; specific experimental validation for transferred inferences not detailed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Transfers numeric probabilities (p2, p3 → p12, p13) from model-organism hypotheses to human hypotheses and records provenance of such transfers.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Literature evidence summarized (GeneWays counts) and cited experimental papers on sirtuins (Tissenbaum & Guarente 2001; Burnett et al. 2011; Kanfi et al. 2012) used illustratively.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Strength of transferred inference depends on many contextual factors (amount/quality of evidence, species differences, lab provenance); simple homology-based probability transfer may over- or under-weight evidence if such factors are not modeled.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representation of probabilistic scientific knowledge', 'publication_date_yy_mm': '2013-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist <em>(Rating: 2)</em></li>
                <li>The Automation of Science <em>(Rating: 2)</em></li>
                <li>Active Learning for High Throughput Screening <em>(Rating: 2)</em></li>
                <li>Distilling Free-Form Natural Laws from Experimental Data <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2660",
    "paper_id": "paper-5f488bcca8af38157201b1075da2e08fbc6b0489",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "HELO",
            "name_full": "HypothEsis and Law Ontology",
            "brief_description": "An OWL-DL ontology for explicit semantic representation of research statements and their associated probabilities, methods of probability estimation, and probabilistic operations to support automated scientific reasoning and Robot Scientists.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "HELO (HypothEsis and Law Ontology)",
            "system_description": "A knowledge-representation ontology (expressed in OWL-DL) that models research statements (hypotheses, laws, conclusions, etc.) and links each to probability values (prior/posterior) and to the method/procedure by which those probabilities were estimated. HELO defines probability as a subclass of mathematical function and includes classes for probability distributions, variables, mean, variance, and qualities (random, independent, joint). It imports top-level classes (BFO, IAO, OBI) and re-uses relations (supports, refutes, HAS-SUPPORTING-EVIDENCE, etc.). HELO records methods of probability estimation (Bayesian inference, expert estimation, statistical calculation, deduction, abduction, induction, homological inference) and links to concrete algorithm implementations via a procedure class.",
            "system_type": "ontology / knowledge representation",
            "scientific_domain": "biomedicine / bioinformatics",
            "hypothesis_generation_method": "HELO does not itself generate hypotheses; it provides structured representation to record hypotheses produced by other systems (logical models, Robot Scientists, text mining). It supports representation of hypothesis sets and logical combination of atomic statements defined in domain ontologies.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Records and associates plausibility via explicit probability values (prior/posterior) and linked evidence (supporting/refuting) and records method used to obtain probability (e.g., Bayesian inference, expert estimation).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Represents hypothesis quality as numeric probability values (prior and posterior) and supports recording of statistical descriptors (mean, variance, distributions) and provenance of probability estimates; no specific single metric beyond probability is prescribed in the paper.",
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Enables recording of experimental validation outcomes and updates of probabilities (posterior computation) but does not itself run experiments; used to store validation provenance and evidence links.",
            "reproducibility_measures": "HELO is OWL-DL, checked for logical consistency with reasoners (HermiT, FaCT++), and is open source (GitHub) enabling shared formal representation; the paper does not list experimental reproducibility protocols beyond representation and provenance capture.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Explicit representation of uncertainty via prior/posterior probabilities, support for probability distributions (continuous/discrete), and explicit linking to estimation methods (Bayesian inference, frequentist interpretations). HELO models probability as mathematical function enabling operations with distributions, means, variances.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Does not itself compute probabilities; it relies on external methods and expert inputs for probability estimates (paper notes difficulty of eliciting priors). The ontology requires consistent upstream probability estimations and accurate evidence provenance to be useful.",
            "uuid": "e2660.0",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Adam",
            "name_full": "Adam (Robot Scientist)",
            "brief_description": "A physically implemented Robot Scientist that uses logical models and abductive inference to generate hypotheses, plans and executes automated experiments, and updates hypothesis probabilities until hypotheses are rejected or accepted.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Adam (Robot Scientist)",
            "system_description": "A robotic laboratory automation system that performs cycles of automated scientific discovery: it uses a logical model of a biological pathway, employs abductive inference to formulate a hypothesis set (e.g., 8 candidate deleted genes), assigns prior probabilities (uniform in the example), plans experiments based on predicted information gain and experimental cost, executes wet-lab auxotrophic experiments, observes outcomes, and updates posterior probabilities iteratively until a single hypothesis remains (posterior 1).",
            "system_type": "robotic automation with symbolic/logic inference (abductive inference) and decision-theoretic experiment planning",
            "scientific_domain": "biology (functional genomics, yeast genetics)",
            "hypothesis_generation_method": "Abductive inference from a logical model of the S. cerevisiae aromatic amino acid pathway to produce a set of candidate hypotheses (PREDICATE(entity_i, entity_j) forms), forming a hypotheses set with summed probability 1.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Initial plausibility encoded as prior probabilities (e.g., uniform priors) and updated by experimental outcomes; plausibility also influenced by logical model consistency and available supporting/refuting evidence recorded in HELO.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Hypothesis quality operationalized as numeric prior/posterior probability; selection of experiments considers predicted information gain and cost; no additional scalar quality metric reported beyond probability and information gain estimations.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Empirical wet-lab experimental cycles executed by the robot: experiments test hypotheses and posterior probabilities are updated; hypotheses are rejected/retained based on experimental outcomes until convergence.",
            "reproducibility_measures": "Automated experiment execution and metadata recording (previous work recorded hypothesis probabilities in experiment metadata) enabling reproducibility; not further detailed in this paper.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Bayesian-style updating of hypothesis probabilities (priors → posteriors) based on experimental evidence; experiment selection uses predicted information gain.",
            "benchmark_dataset": "Worked example on the S. cerevisiae aromatic amino acid pathway (King et al. Robot Scientist experiments referenced).",
            "performance_metrics": "Demonstrated full automation of discovery: Adam reduced an 8-hypothesis set to a single accepted hypothesis via iterative experimentation; posterior probabilities converged to 1 for the accepted hypothesis and 0 for rejected ones in the example. No standard classification metrics reported.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Relies on availability of a logical model and reasonably specified priors; eliciting accurate prior probabilities is difficult (noted generally), and results depend on model fidelity and experimental noise.",
            "uuid": "e2660.1",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Gaussian process QSAR",
            "name_full": "Gaussian process regression model for QSAR (quantitative structure–activity relationship)",
            "brief_description": "A Gaussian process regression model used to predict pGI50 activity of compounds; it outputs a predictive Normal distribution per compound enabling active selection based on acquisition functions that use uncertainty.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Gaussian process QSAR model",
            "system_description": "A regression model (Gaussian process) fitted to measured pGI50 values that produces a predictive Normal distribution (mean and variance) for each untested compound's activity; the predictive distribution enables computation of probabilities (e.g., probability a compound exceeds current kth-best) and supports acquisition functions for active selection (MPI, MEI, LCB).",
            "system_type": "probabilistic regression / Gaussian process",
            "scientific_domain": "chemistry / drug discovery / computational biology",
            "hypothesis_generation_method": "Generates ranked candidate hypotheses (compounds likely to have high pGI50) by predicting pGI50 distributions and computing probabilities/expected improvements relative to current bests.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility expressed as predictive probability derived from Gaussian predictive distribution (e.g., probability that a compound's pGI50 exceeds current k-th best).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Uses predictive mean and variance from the GP to compute acquisition values: probability of improvement (MPI), expected improvement (MEI), and lower confidence bound criteria; also reports probabilities P1/P2/P3 for candidate improvement as examples.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational cross-validated selection experiments on the NCI60 dataset: selected compounds were evaluated by retrieving their measured pGI50 values from the dataset (the study simulated active selection and measured how quickly high-activity compounds were found).",
            "reproducibility_measures": "Experiments repeated 20 times per computational experiment and averaged; use of public NCI60 dataset provides reproducibility baseline.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Gaussian process predictive distributions (Normal) providing mean and variance per compound; probabilities of improvement computed from these distributions.",
            "benchmark_dataset": "NCI60 human tumor cell line anticancer drug screen dataset",
            "performance_metrics": "Qualitative results: active selection substantially speeds finding high pGI50 compounds; table examples show per-iteration probabilities (P3 values up to 0.99994 at an early stage for a particular compound). No standard accuracy/ROC metrics reported in the paper; experimental selection strategies were compared averaged over 20 repeats.",
            "comparison_with_baseline": "Compared selection strategies (optimistic/LCB, MPI, MEI, random). Optimistic strategy was most robust across situations, MPI competitive at medium budgets, MEI performs well when ~10 compounds are sought, and random selection performs worst.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Performance of strategies depends on experimental budget: MPI may fail under low budgets and does not exploit high budgets optimally; MEI suited when several compounds (~10) required. No absolute guarantees provided; results are dataset-dependent.",
            "uuid": "e2660.2",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Active k-optimization strategies",
            "name_full": "Active selection / Bayesian optimization strategies (Lower confidence bound, MPI, MEI)",
            "brief_description": "Acquisition-function–based selection strategies used in active learning to choose compounds for experimental evaluation: lower confidence bound (optimistic), most probable improvement (MPI), and maximum expected improvement (MEI).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Active k-optimization strategies (LCB / MPI / MEI)",
            "system_description": "A set of decision-theoretic acquisition strategies implemented on top of predictive models (Gaussian process) to select which instances to test next: Lower confidence bound (optimistic strategy) selects by an LCB criterion combining mean and uncertainty; MPI selects the compound with maximal probability to improve on the current kth-best; MEI selects by maximum expected improvement (expected value of improvement over current best).",
            "system_type": "active learning / Bayesian optimization / acquisition functions",
            "scientific_domain": "drug discovery / high-throughput screening",
            "hypothesis_generation_method": "Selects experimental hypotheses (which compound to test next) by optimizing acquisition functions computed from the predictive distribution (probability of improvement, expected improvement, or lower confidence bounds).",
            "novelty_assessment_method": "MPI and MEI inherently quantify potential novelty relative to current best via probability or expected magnitude of improvement; no additional novelty metric reported.",
            "plausibility_assessment_method": "Plausibility derived from predictive distributions (GP mean and variance) producing probabilities or expectations used to rank candidates.",
            "novelty_plausibility_balance": "Managed via choice of acquisition function: MPI emphasizes probability of improvement (plausibility), MEI balances plausibility with magnitude of improvement (novelty magnitude), and LCB (optimistic) trades off mean and uncertainty; the paper reports empirical trade-offs (e.g., MPI good for medium budgets, MEI for ~10 compounds).",
            "hypothesis_quality_metrics": "Acquisition scores (probability of improvement, expected improvement, LCB score) computed from Gaussian predictive distributions; these scores are used as pre-experiment quality proxies.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Simulated active learning experiments on NCI60 where acquisition-guided picks are compared against random baseline and other strategies by how quickly high-activity compounds are found (averaged over 20 repeats).",
            "reproducibility_measures": "Repeated runs (20 repeats), use of public dataset (NCI60); results averaged.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Depends on GP predictive mean and variance; acquisition functions explicitly use these uncertainties (probability and expectation of improvement, confidence bound calculations).",
            "benchmark_dataset": "NCI60 dataset (US NCI 60 anticancer drug screen)",
            "performance_metrics": "Empirical comparative statements: optimistic (LCB) strategy most robust (either best or not significantly worse than best in all considered situations); MPI competitive for medium budgets; MEI best when around 10 compounds needed; random selection worst. No single numeric summary metrics provided beyond per-iteration example probabilities and qualitative comparisons.",
            "comparison_with_baseline": "Compared against random selection and across strategies; random selection performs worse than optimized strategies in all settings considered.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Strategy performance sensitive to experimental budget and task (e.g., MPI can fail under very low budgets and may not use high budgets optimally).",
            "uuid": "e2660.3",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Eureka",
            "name_full": "Eureka system (law discovery)",
            "brief_description": "A system referenced as producing research laws or production rules (models) and distilling natural laws from experimental data.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Eureka (law-discovery system)",
            "system_description": "Cited as an example of a system that outputs research laws (models, production rules) that can be represented in HELO (reference to systems that distill laws of nature from data). The paper references such systems as sources of research laws that HELO can encode.",
            "system_type": "symbolic discovery / equation / law induction system",
            "scientific_domain": "general scientific modeling (cited in context of natural law discovery)",
            "hypothesis_generation_method": "Inductive distillation of laws from experimental data (symbolic regression / equation discovery approaches referenced in literature).",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": null,
            "uuid": "e2660.4",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "GeneWays",
            "name_full": "GeneWays text-mining system / GeneWays 7.0 database",
            "brief_description": "An automated text-mining pipeline that extracted molecular interaction assertions from hundreds of thousands of full-text articles and abstracts to create a large structured database (used to support evidence counts for biological claims).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "GeneWays (text mining / knowledge extraction)",
            "system_description": "An automated literature-mining system that produced GeneWays 7.0 by processing 368,331 full-text articles and over 8 million abstracts, extracting molecular interaction relations (~500 relation types). In the paper, a subset (yeast70) is used to quantify frequency of assertions about SIR2 and aging to argue for high support for the hypothesis that SIR2 regulates yeast lifespan.",
            "system_type": "text-mining / information extraction / knowledge base construction",
            "scientific_domain": "bioinformatics / literature mining",
            "hypothesis_generation_method": "Produces candidate assertions and supports for hypotheses by extracting relations and co-mentions from literature; these extractions contribute to evidence supporting hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Provides counts/frequency of supporting sentences (e.g., 492 sentences containing SIR2 and 'aging') that can be interpreted as evidence weight for plausibility estimates.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Indirect: frequency counts of supporting sentences and relations in the text-mined database used as an input to human/expert probability estimates.",
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Text-mining derived evidence cited as supportive material; validation of text-mining extractions is not detailed in this paper.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "yeast70 subset of GeneWays 7.0 was used to count sentences linking SIR2 and aging",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Text-mining outputs require downstream curation/evaluation: frequency of mentions does not equal truth; the paper uses counts qualitatively to argue support but notes provenance and quality factors (lab, publisher) affect weight of evidence.",
            "uuid": "e2660.5",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Abductive inference",
            "name_full": "Abductive inference (inference to best explanation)",
            "brief_description": "An AI reasoning approach used by the Robot Scientist to generate explanatory hypotheses from a logical model and observed phenomena (used to produce candidate hypotheses that are then experimentally tested).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Abductive inference",
            "system_description": "A symbolic reasoning technique that generates hypotheses that would, if true, best explain observed or desired outcomes given a background logical model; in the Robot Scientist example abductive inference produced an initial hypotheses set (8 candidates) about which gene was deleted in a pathway.",
            "system_type": "symbolic reasoning / logical inference",
            "scientific_domain": "biology (experimental design), general scientific reasoning",
            "hypothesis_generation_method": "Generates candidate hypotheses by finding assumable facts that would make the logical model consistent with observed data or desired explanatory goals (abduction).",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility initially set via prior probabilities (e.g., uniform) and then updated by experimental evidence; abduction itself does not assign numeric plausibility unless coupled with probabilistic machinery.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Coupled with automated experiments (e.g., Adam) that test abductively generated hypotheses and update their posterior probabilities.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "When used within the Robot Scientist framework, abductive hypotheses are assigned prior probabilities and updated via Bayesian-like posterior updates based on experimental evidence.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Abductive inference depends on completeness and correctness of the underlying logical model; without probabilistic priors it yields candidate explanations but not graded certainty.",
            "uuid": "e2660.6",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Bayesian inference",
            "name_full": "Bayesian inference / Bayesian updating",
            "brief_description": "A probabilistic framework for updating prior beliefs about hypotheses into posterior probabilities given new evidence, presented as the rational approach for scientific belief updating and directly supported/recorded by HELO.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Bayesian inference",
            "system_description": "A probabilistic method where prior probabilities for hypotheses are updated to posterior probabilities via Bayes' rule in light of new evidence; HELO explicitly models priors and posteriors and records Bayesian inference as a method of probability estimation.",
            "system_type": "probabilistic / Bayesian",
            "scientific_domain": "general scientific reasoning / biomedicine",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is encoded as prior and posterior probabilities; the Bayesian framework yields quantitative plausibility updates according to evidence likelihoods.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Quality represented as posterior probability; HELO supports recording mean/variance and probability distributions for quantitative descriptors.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Posterior updates following evidence; experimental data serve as likelihood in Bayes' rule to validate/refute hypotheses.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Bayesian priors and posteriors provide principled uncertainty quantification; HELO records whether probability values were obtained by Bayesian inference.",
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Requires specification of prior probabilities (elicitation is difficult); posterior conclusions depend on the chosen priors and likelihood models.",
            "uuid": "e2660.7",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        },
        {
            "name_short": "Homological inference",
            "name_full": "Homologous inference",
            "brief_description": "A domain-specific probabilistic inference method used to transfer evidence from model organisms (homologs) to human hypotheses by adjusting probabilities based on homology relationships.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Homologous inference",
            "system_description": "A biological inference mechanism whereby probabilities of hypotheses about one species (e.g., C. elegans or S. cerevisiae) are used to influence the probability of related hypotheses in another species (e.g., human SIRT1) through homology mappings (HAS-PROBABILITY(h_source, p_source) → HAS-PROBABILITY(h_target, p_translated)).",
            "system_type": "domain-specific probabilistic inference / knowledge-based transfer",
            "scientific_domain": "comparative biology / evolutionary inference",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility of human-relevant hypotheses is increased or decreased by probabilistic evidence from homologs using homology-based inference rules recorded in HELO.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Indirect: model-organism experimental results alter probabilities of human hypotheses; specific experimental validation for transferred inferences not detailed in the paper.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Transfers numeric probabilities (p2, p3 → p12, p13) from model-organism hypotheses to human hypotheses and records provenance of such transfers.",
            "benchmark_dataset": "Literature evidence summarized (GeneWays counts) and cited experimental papers on sirtuins (Tissenbaum & Guarente 2001; Burnett et al. 2011; Kanfi et al. 2012) used illustratively.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Strength of transferred inference depends on many contextual factors (amount/quality of evidence, species differences, lab provenance); simple homology-based probability transfer may over- or under-weight evidence if such factors are not modeled.",
            "uuid": "e2660.8",
            "source_info": {
                "paper_title": "Representation of probabilistic scientific knowledge",
                "publication_date_yy_mm": "2013-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "rating": 2
        },
        {
            "paper_title": "The Automation of Science",
            "rating": 2
        },
        {
            "paper_title": "Active Learning for High Throughput Screening",
            "rating": 2
        },
        {
            "paper_title": "Distilling Free-Form Natural Laws from Experimental Data",
            "rating": 1
        }
    ],
    "cost": 0.01816825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Representation of probabilistic scientific knowledge</h1>
<p>Larisa N. Soldatova ${ }^{1 *}$, Andrey Rzhetsky ${ }^{2}$, Kurt De Grave ${ }^{3}$, Ross D King ${ }^{4}$<br>From Bio-Ontologies 2012<br>Long Beach, CA, USA. 13-14 July 2012</p>
<ul>
<li>Correspondence: larisa. soldatova@brunel.ac.uk ${ }^{1}$ Department of Information Systems and Computing, Brunel University, London, UK</li>
</ul>
<h4>Abstract</h4>
<p>The theory of probability is widely used in biomedical research for data analysis and modelling. In previous work the probabilities of the research hypotheses have been recorded as experimental metadata. The ontology HELO is designed to support probabilistic reasoning, and provides semantic descriptors for reporting on research that involves operations with probabilities. HELO explicitly links research statements such as hypotheses, models, laws, conclusions, etc. to the associated probabilities of these statements being true. HELO enables the explicit semantic representation and accurate recording of probabilities in hypotheses, as well as the inference methods used to generate and update those hypotheses. We demonstrate the utility of HELO on three worked examples: changes in the probability of the hypothesis that sirtuins regulate human life span; changes in the probability of hypotheses about gene functions in the S. cerevisiae aromatic amino acid pathway; and the use of active learning in drug design (quantitative structure activity relation learning), where a strategy for the selection of compounds with the highest probability of improving on the best known compound was used. HELO is open source and available at https://github.com/larisa-soldatova/HELO</p>
<h2>Introduction</h2>
<p>"All knowledge resolves itself into probability".
David Hume, in a treatise of Human Nature (1888), 181-182.
Scientific knowledge is inherently uncertain: experimental observations may be corrupted by noise, and no matter how many times a theory has been tested there is still the possibility that new experimental observations will refute it - as famously happened to Newtonian mechanics. Probability theory has from its conception been utilized to represent this uncertainty in scientific knowledge. However the role of probability theory has proved controversial, with for example the great philosopher of science Karl Popper arguing that probabilities cannot be applied to scientific theories on the grounds that an infinite number of theories can explain any scientific data, therefore their a priori probabilities are zero. This view is now generally disregarded and a Bayesian approach to the use of probabilities in science is widely accepted. In Bayesian reasoning a priori probability estimates for hypotheses are updated through</p>
<p>observation of additional evidence [1]. The Bayesian approach is arguably the only rational method for updating beliefs $[2,3]$.
Despite the undoubted importance of probabilities in science it is unfortunately the case that conventional knowledge representations in bio-medicine are insufficient to support probabilistic reasoning. The best available representation, in our view, is the Evidence Code Ontology (ECO) [4]. ECO enables the recording of evidence that supports scientific statements, e.g. experimental evidence, sequence similarity, curator inference; and also by what method the evidence was obtained, e.g. through computational combinatorial analysis, inference from background knowledge, non-traceable author statement. This information enables researchers to qualitatively evaluate the degree of uncertainty of scientific statements. However, such evaluations are rarely recorded, not checked for consistency with other relevant evaluations, and therefore are difficult to use for probabilistic reasoning. There is a need for a resource that would enable the explicit quantitative recording of probabilities associated with research statements. To address this need we propose the ontology HELO (HypothEsis and Law Ontology) that supports probabilistic reasoning about bio-medical research statements.</p>
<h1>HELO aims</h1>
<p>The HELO ontology was originally designed to support development of Robot Scientists, these are physically implemented laboratory automation systems that exploit techniques from the field of artificial intelligence to execute cycles of scientific experimentation.
A probability that a research statement is true may vary greatly depending on the source of the statement. While experimental data from good laboratories are likely to be true, even research statements extracted from very high impact journals are not necessarily valid. C.G. Bengley and L.M. Ellis in their recent article in Nature report that scientific findings have been confirmed only in 6 out of 53 "landmark" studies in haematology and oncology [5]. This is consistent with results in other areas. For example Prinz et. al report that only $25 \%$ of published pre-clinical studies could be validated [6]. The authors stressed that validation attempts could fail for various reasons, including technical differences. HELO aims to provide a framework for the recording of probabilities that research statements are true, and for probabilistic reasoning with such statements.</p>
<h2>The key HELO classes</h2>
<h2>Research statements</h2>
<p>The HELO representation of research statements is based on the representation of research hypothesis as PREDICATE(entity ${ }<em j="j">{i}$, entity $</em>}$ ) defined in an ontology LABORS, where predicate is a relation and entity is a class or instance defined in a domain ontology [7]. HELO enables one to formulate complex research statements, where basic (atomic) statements like PREDICATE(entity ${ <em j="j">{i}$, entity $</em>, \cdot, \neg, \rightarrow, \leftrightarrow$. Entities that form research statements may be replaced by more generic entities (parent classes) and/or be specialized by their properties: individual gene names could be replaced with classes from Gene Ontology (GO) [8]; specific environmental factors could be replaced with general terms such as increased/ decreased temperature, carbon source, addition of drugs, etc.; and measurable}$ ) are combined by logical operators ${ }^{\prime</p>
<p>phenotypes could be replaced with general terms such as relate to growth, cell shape, etc. The following complex statement about yeast strains could be then represented: "If all genes with lactase activity are deleted from a yeast strain and if this strain is grown in medium with lactose as the sole carbon source, then the phenotype will be no growth." This could be expressed in logic using terms defined in various ontologies as:</p>
<div class="codehilite"><pre><span></span><code><span class="p">(((</span><span class="err">∀</span><span class="nx">gene</span><span class="p">,</span><span class="err">∀</span><span class="nx">yeast_strain</span><span class="p">,</span><span class="err">∀</span><span class="nx">x</span><span class="o">|</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">FUNCTION</span><span class="p">(</span><span class="nx">gene</span><span class="p">,</span><span class="nx">lactase_activity</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">PART</span><span class="p">(</span><span class="nx">yeast_strain</span><span class="p">,</span><span class="w"> </span><span class="nx">gene</span><span class="p">)</span><span class="o">^</span>
<span class="nx">IS</span><span class="o">-</span><span class="nx">A</span><span class="p">(</span><span class="nx">process</span><span class="p">,</span><span class="w"> </span><span class="nx">deletion</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">PARTICIPANT</span><span class="p">(</span><span class="nx">gene</span><span class="p">,</span><span class="w"> </span><span class="nx">deletion</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">OUTPUT</span><span class="p">(</span><span class="nx">deletion</span><span class="p">,</span><span class="w"> </span><span class="nx">yeast_strain</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">PART</span><span class="p">(</span><span class="nx">growth_medium</span><span class="p">,</span><span class="nx">lactose</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">FUNCTION</span><span class="p">(</span><span class="nx">lactose</span><span class="p">,</span><span class="w"> </span><span class="nx">carbon_source</span><span class="p">)</span><span class="o">^</span>
<span class="nx">HAS</span><span class="o">-</span><span class="nx">PART</span><span class="p">(</span><span class="nx">growth_medium</span><span class="p">,</span><span class="w"> </span><span class="nx">x</span><span class="p">)</span><span class="o">^</span>
<span class="nx">IS</span><span class="o">-</span><span class="nx">A</span><span class="p">(</span><span class="nx">phenotype</span><span class="p">,</span><span class="w"> </span><span class="nx">no_growth</span><span class="p">)</span><span class="o">^</span>
<span class="o">~</span><span class="nx">HAS</span><span class="o">-</span><span class="nx">FUNCTION</span><span class="p">(</span><span class="nx">x</span><span class="p">,</span><span class="w"> </span><span class="nx">carbon</span><span class="w"> </span><span class="nx">_</span><span class="w"> </span><span class="nx">source</span><span class="p">))</span>
</code></pre></div>

<p>In combination with a logical model of metabolism these statements would enable deduction of the fact:</p>
<p>$$
\rightarrow(\text { HAS-QUALITY(yeast_strain, no_growth) }) .
$$</p>
<p>HELO defines a hierarchy of research statements: research hypothesis, hypotheses set (a collection of hypotheses with a total probability 1 , it usually combines research hypotheses, negative hypotheses, and alternative hypotheses, see [7] for more detail), assumption, conclusion, scientific law (models and generic rules, including Bayes rule), theorem (including Bayes theorem). Research laws may be represented as production rules (statement ${ }<em j="j">{i} \rightarrow$ statement $</em>$ ), where statements correspond to hypotheses, evidence, conclusions. For example,</p>
<p>$$
\begin{aligned}
&amp; \text { INTERACT-PHYSICALLY }\left(\text { gene }- \text { product }<em j="j">{i}, \text { gene }- \text { product }</em>\right) \
&amp; \quad \rightarrow \text { INTERACT-EPISTATICALLY }\left(\text { gene }<em j="j">{i}, \text { gene }</em>\right) .
\end{aligned}
$$</p>
<p>Research laws may be models that are produced for example by the Eureka system that outputs laws of nature [9].</p>
<p>HELO is designed to consistently accommodate scientific hypotheses and laws collected from different sources: interviews with scientists, web pages, research papers, databases, program codes. Any research statement in HELO has an associated probability of being true.</p>
<h1>Probability</h1>
<p>Probabilistic reasoning is essential in biomedicine, e.g. the Ontology of Adverse Events (OAE) models causal adverse event probability (an information content entity that represents a probability that an adverse event is caused (induced) by a medical intervention) [10], the Mass Spectrometry (MS) structured controlled vocabulary developed by the HUPO Proteomics Standards Initiative models modification probability (a priori probability of a modification) [11]. However, the concept of a probability is not modeled</p>
<p>consistently in biomedical ontologies. MS models the class probability as a subclass of the class modification parameters. The Parasite Experiment Ontology (PEO) defines the concept as a subclass of the class statistical measure and data collection (a statistical way of expressing knowledge or belief that an event will occur or has occurred) [12]. Computational Neuroscience Ontology (CNO) defines probability as the subclass of the class model parameter [13]. CNO has the class mathematical concept ("a thing that represents the different mathematical concepts used to represent models"), but for some reason probability is not considered as a mathematical concept. The Semanticscience Integrated Ontology (SIO) [14] defines the class probability as the subclass of the class description. SIO has the class mathematical entity, but again probability is not considered as such.</p>
<p>HELO follows the theory of probability [15], [16] and defines the class probability as a subclass of the class mathematical function to enable mathematical operations with probabilities (a mathematical function expressing knowledge or belief that a research statement is true). This definition covers frequentist probabilities (taken as a limiting frequency of experimental observations), and also Bayesian "subjective" probabilities, or beliefs.</p>
<p>Reliable statistical estimates of the probability of a statement being true are often unavailable. In the subjective Bayesian framework human experts are expected to provide priors that capture scientific background knowledge and intuition. Obtaining such probabilities is notoriously difficult and there is an extensive literature on the subject. Once prior probabilities are given the probabilities of scientific statements may be then iteratively updated (increased or decreased) with new evidence. It is important to record these changes in value and how they were inferred.</p>
<p>HELO enables the recording of how probabilities were obtained. The class method of probability estimation has subclasses Bayesian inference, expert estimation, statistical calculation, deduction, abduction, induction, homological inference; and linked to the class procedure that records a specific algorithm implementation for obtaining a probability of a research statement. The class probability has the subclasses prior probability and posterior probability. A research statement is linked to an associated probability via the functional relation HAS-PROBABILTY.</p>
<p>HELO imports from SIO the relations refutes, supports, disputes to link research statements, and the relations HAS-DISPUTING-EVIDENCE, HAS-REFUTING-EVIDENCE, HAS-SUPPORTING-EVIDENCE to link research statements and evidence (see Fig.1).</p>
<h1>An ontology of the theory of probability</h1>
<p>HELO defines the key entities of the theory of probability to enable logically consistent recording of operations that involve probabilities. HELO includes such classes as variable, probability distribution function, probability mass function, mean, variance, and such qualities as independent, random (variable), joint (probability). In order to organize these classes into a hierarchical system, HELO imports the following top-level classes: continuant (from BFO [17]), information content entity (from IAO [18]), plan specification (from OBI [19]), procedure (from LABORS [20]), representation (from LABORS and SIO [14]) (see Fig.2).</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p><strong>Figure 1 An example of the HELO representation of a research statement.</strong> The figure shows the representation of the values of the prior and posterior probabilities of the research statement about sirtuins, and also the supporting and refuting evidence.</p>
<p>Additionally, the class <em>random event</em> is defined as an upper class, because the concept of an <em>event</em> ontologically differs from the notion of a <em>process</em> or any other notion. It may involve a process and participants and it has an associated time point, e.g., the end of the process. The theory of probability deals with <em>random events</em> defined on a <em>sample space</em> of all possible outcomes of a random event.</p>
<p>HELO is expressed in OWL-DL. It has been checked for logical consistency with the reasoners HermiT 1.3.6 and FaCT++. HELO is open source and available at https://github.com/larisa-soldatova/HELO.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p><strong>Figure 2 An overview of the ontology HELO</strong>. The figure shows the top-level classes of HELO and some of their extentions.</p>
<h1>Worked examples</h1>
<h2>The <em>S. cerevisiae</em> aromatic amino acid pathway</h2>
<p>This example demonstrates how a probability that a research hypothesis is true is used for automated experimentation.</p>
<p>King <em>et al.</em> (2009) demonstrated the full automation of scientific discovery [20]. The Robot Scientist "Adam" employed abductive inference to formulate a set of 8 hypotheses based on its logical model of the <em>S. cerevisiae</em> aromatic amino acid (AAA) pathway concerning which gene had been deleted (see Supplementary Information in [20] for more detail). The <em>prior probability</em> of each hypothesis from the set of being correct, (using a uniform distribution) was 1/8. Adam then planned and executed cycles of auxotrophic experiments to test these hypotheses. Each cycle resulted in the rejection of one or more hypotheses, and the probabilities of the remaining hypotheses were increased with each cycle. The experiments were executed until only one hypothesis was left. The <em>posterior probability</em> of the remaining hypothesis was 1 and all of the others - 0.</p>
<p>In making its decision about which experiment to execute in each cycle Adam used the probabilities of the hypotheses being true, the cost of the compounds required in the experiments to test those hypotheses, and the predicted information gain in testing the hypotheses. Previously, probabilities of research hypotheses were represented and recorded as associated with the experiment's metadata [21]. HELO enables the direct recording of <em>prior</em> and <em>posterior probabilities</em> as properties of research hypotheses. This makes the representation of probabilistic knowledge explicit, and streamlines probabilistic reasoning, decision making, and automated experimentation.</p>
<h2>Sirtuins</h2>
<p>We use the example of sirtuins as an example of how to utilize HELO for probabilistic representation of research statements. We are interested in recording and automating the argumentation involved in the sirtuin case, both to direct our own research into aging, but also as an exemplar of biological reasoning. This example is typical in how</p>
<p>the probability of scientific statements varies over time with the observation of new experiments. The example also illustrates the use of homologous inference, which is the basis of much biological reasoning, and which is essentially probabilistic.</p>
<p>Sirtuins are highly conserved $N A D^{+}$- dependent deacetylases that are believed to play a role in regulating lifespan in many organisms. The potential role of sirtuins in extending human lifespan has led to extensive research into the human gene SIRT1 and its orthologs. For example in 2001 Tissenbaum \&amp; Guarente showed that increased dosage of the SIRT1 homolog extends lifespan in the nematode (Caenorhabditis elegans) [22]. Increasing sirtuin level through genetic manipulation has been observed to extend lifespan in C. elegans, the yeast (Saccharomyces cerevisiae), the fruitfly (Drosophila melanogaster), and the mouse (Mus musculus) [23,24]. This research sparked commercial interest and in 2008 Sirtris Pharmaceuticals Inc., working on exploiting sirtuin modulation for the treatment of human disease, was bought by GlaxoSmithKline for approximately USD 720 million.</p>
<p>This excitement about the potential of sirtuins suffered a major setback in 2011 when Burnett et al. reported that overexpressing the sirtuin gene in two model organisms, C. elegans and D. melanogaster did not in fact boost longevity as had been previously reported [25]. The situation changed again in 2012 when Kanfi et al. reported that the sirtuin SIRT6 regulates lifespan in male mice, but not in female ones [23]. Therefore the probability of the research hypothesis that sirtuins regulate organism lifespan has increased and decreased over the last decade.</p>
<p>The primary research hypothesis $h_{1}$ we are interested in is: "SIRT1 regulates human life span" (SIRT1 is a sirtuin gene in humans). HELO enables the recording of this research statement:</p>
<p>IS-A(human, organism) $\wedge$
HAS-QUALITY(organism, life-span) $\wedge$
REGULATES(SIRT1, life-span).
However, it is difficult to directly test this hypothesis, so most evidence relating to it comes from laboratory experiments using model eukaryotes. For example a hypothesis $h_{2}$ is about C. elegans:</p>
<p>IS-A(C.elegans, organism) $\wedge$
HAS-QUALITY(organism, life-span) $\wedge$
REGULATES(SIRT2, life-span).
and a hypothesis $h_{3}$ is about $S$. cerevisiae:
IS-A(S. cerevisiae, organism) $\wedge$
HAS-QUALITY(organism, life-span) $\wedge$
REGULATES(SIRT2, life-span).
The evidence about $h_{2}$ and $h_{3}$ is then related to $h_{1}$ by probabilistic reasoning (homological inference):</p>
<p>HAS-PROBABILITY $\left(h_{2}, p_{2}\right) \rightarrow$ HAS-PROBABILITY $\left(h_{1}, p_{12}\right)$
HAS-PROBABILITY $\left(h_{3}, p_{3}\right) \rightarrow$ HAS-PROBABILITY $\left(h_{1}, p_{13}\right)$.</p>
<p>SIR2 is the S. cerevisiae homolog of SIRT1. The research hypothesis $h_{3}$ "SIR2 regulates yeast life span" is very well supported by the scientific literature. The dataset yeast70 is a subset of Gene Ways 7.0 database [26]. The Gene Ways 7.0 database was produced through automated analysis of 368,331 full-text research articles and 8,039,972 article abstracts from the PubMed database, using the GeneWays system. The database covers a wide spectrum of molecular interactions, such as bind, phosphorylate, glycosylate, and activate (nearly 500 relations in total). The dataset yeast70 has 1,135 sentences containing the keyword "aging" and yeast gene names, 492 of them contain SIR2, the gene SIR1 is not mentioned, and SIR3 is mentioned 42 times. Examining these papers suggests that the probability of $h_{2}$ is close to 1.0 .</p>
<p>The probability of scientific hypotheses changes with new evidence, and we wish to use HELO to represent this. For example Burnett et al. results directly decreased the probability of the hypotheses regarding the function of the SIRT1 homologs in Caenorhabditis elegans and Drosophila melanogaster, and these indirectly decreased the probability of $h_{1}$. The situation changed again in 2012 with Kanfi et al. where the evidence directly increased the probability of the hypotheses regarding the function of the SIRT1 homolog in Mus musculus, and this indirectly increased the probability of $h_{1}$ (see Fig.1).</p>
<p>Of course the weight of the evidence in these papers on $h_{1}$ depends on a host of factors other than simply the model species involved: the amount and variety of evidence, its statistical confidence, the lab where the work was done, the publisher, etc. Taking all these into account an expert estimate of the probability that $h_{1}$ is held after the publication of the paper [22] is 0.8 (see Fig.1). It should be noted that the exact probability of $h_{1}$, say 0.8 or 0.82 , is not that critical. What is important is the "ball-park" figure, and the direction of change with new evidence. Our idea is that addition of more and more evidence and inferences to the argument constrain the probabilities to reasonable numbers. It is our contention that all human scientists make such implicit inferences and much is to be gained by making them explicit. In addition these probability can be used for further automated inference and experimentation.</p>
<p>Experiments with a Sir2 deletant strain run within the Robot Scientists project showed no difference between the wild type, while yeast strains with $N A D^{+}$grew to a significantly higher biomass than the wild type. The experiments demonstrate that Sir2 functions differently from other $N A D^{+}$genes, and this indirectly supports the hypothesis $h_{1}$. It is clear that further experimentation is required to accept or reject the hypothesis $h_{1}$.</p>
<h1>Active learning for drug discovery</h1>
<p>This example demonstrates the recording of probabilities in drug discovery experiments. The goal of these experiments was to find the best compound (with respect to a biomedical assay, e.g. for treating cancer) without having to test all the compounds against the assay. This involved learning quantitative structure activity relationships (QSARs). These are functions that take as input the structure of a compound and output an estimate of how well the compound will perform in a biomedical assay. The investigation was computational and used existing assay results.</p>
<p>The task of finding the best instance (e.g. compounds, parameters) as evaluated on an unknown target function (e.g. high biological activity, minimal costs) using limited</p>
<p>resources (e.g. time) is important to many scientific disciplines. In drug discovery it is not sufficient to find just a single best compound or "lead" as several leads improve the chances of finding a compound that passes toxicology tests. The challenge therefore is to identify the $k$ best performing instances ( $=$ compounds in this context) using as few experiments as possible. We refer to this task as active $k$-optimization.</p>
<p>We applied machine learning to solve the active $k$-optimization task and to propose the best candidates for screening [27]. We considered several selection strategies for the best instances: Cox and John's lower confidence bound criterion [28] (we refer to it as the optimistic strategy), the most probable improvement (MPI) of the current solution strategy [29], the maximum expected improvement (MEI) strategy, and also the random choice (see [27] for more detail).</p>
<p>These strategies were evaluated on the US National Cancer Institute 60 anticancer drug screen (NCI60) dataset [30]. This repository contains measurements of the inhibitory power of tens of thousands of chemical compounds against 59 different cancer cell lines (one of the originally 60 cell lines was evicted because it was essentially a replicate of another one [31]). NCI reports the negative log-concentration required for $50 \%$ cancer cell growth inhibition $\left(\mathrm{pGI}<em 50="50">{50}\right)$ as well as cytostatic and cytotoxic effect measures, but we only used the $\mathrm{pGI}</em>$.</p>
<p>The goal is to find compounds in a library that have a high $\mathrm{pGI}<em 50="50">{50}$, and to do so using as few $\mathrm{pGI}</em>}$ measurements as possible. The program bootstraps by selecting 10 random compounds and measuring their $\mathrm{pGI<em 50="50">{50}$. In each subsequent step, a current QSAR model is fitted to all available $\mathrm{pGI}</em>}$ values. The model is used to predict the $\mathrm{pGI<em 50="50">{50}$ for all remaining (untested) compounds in the library. The model is a Gaussian process, which outputs a (Normal) distribution for the $\mathrm{pGI}</em>}$ value rather than only a point prediction. This enables the implementation of the previously listed strategies. For example, for the MPI strategy, one computes the probability that a compound has a $\mathrm{pGI<em 50="50">{50}$ which is larger than the current $k$-th best one. The compound with the highest probability is selected for the next measurement of $\mathrm{pGI}</em>$.</p>
<p>The table in Figure 3 illustrates MPI for a particular cell line 786-0, for a specific bootstrap, and for $k=1$. The first column of the table shows the number of known $\mathrm{pGI}<em 50="50">{50}$ values at that time. $P 1$ is the probability, given the current evidence, that a particular compound NSC 642567 will have a $\mathrm{pGI}</em>$ than the current best value. The third column shows the highest such probability $P 3$ for any of the compounds remaining in the library.}$ better than the best bootstrap compound. The subsequent column shows what is the probability $P 2$ that NSC 642567 has a better $\mathrm{pGI}_{50</p>
<p>Each computational experiment was repeated 20 times and the results were averaged. Overall, on the NCI60 datasets, the optimistic strategy was most robust. In all situations considered, it performed either best or not significantly worse than the best strategy (see [27] for detail and diagrams). The performance of MPI is competitive for medium experimental budgets, but it may fail to find more than one good compound when constrained to low budgets, and it does not optimally exploit high budgets. MEI is a very good strategy when about 10 compounds are needed. The random selection strategy performs worse than all other selection methods in all settings. Actively choosing compounds substantially speeds up the finding of the compounds with high $\mathrm{pGI}_{50}$.</p>
<p>HELO enables the recording of these important results in a semantically defined way. The following semantic descriptors are required for the reporting of this study:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Incremental evidence</th>
<th style="text-align: center;">P1</th>
<th style="text-align: center;">P2</th>
<th style="text-align: center;">P3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><img alt="img-2.jpeg" src="img-2.jpeg" /></td>
<td style="text-align: center;">$5.98 \times 10^{-1}$</td>
<td style="text-align: center;">$5.98 \times 10^{-1}$</td>
<td style="text-align: center;">$9.9994 \times 10^{-1}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5.21 \times 10^{-1}$</td>
<td style="text-align: center;">$5.21 \times 10^{-1}$</td>
<td style="text-align: center;">$9.92 \times 10^{-1}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5.03 \times 10^{-1}$</td>
<td style="text-align: center;">$1.27 \times 10^{-1}$</td>
<td style="text-align: center;">$8.05 \times 10^{-1}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5.11 \times 10^{-1}$</td>
<td style="text-align: center;">$1.32 \times 10^{-1}$</td>
<td style="text-align: center;">$6.58 \times 10^{-1}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5.82 \times 10^{-1}$</td>
<td style="text-align: center;">$1.75 \times 10^{-1}$</td>
<td style="text-align: center;">$5.56 \times 10^{-1}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$5.87 \times 10^{-1}$</td>
<td style="text-align: center;">$2.04 \times 10^{-4}$</td>
<td style="text-align: center;">$1.27 \times 10^{-2}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$4.07 \times 10^{-1}$</td>
<td style="text-align: center;">$9.99 \times 10^{-6}$</td>
<td style="text-align: center;">$5.23 \times 10^{-3}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$4.05 \times 10^{-1}$</td>
<td style="text-align: center;">$9.75 \times 10^{-6}$</td>
<td style="text-align: center;">$5.10 \times 10^{-3}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$4.09 \times 10^{-1}$</td>
<td style="text-align: center;">$1.03 \times 10^{-5}$</td>
<td style="text-align: center;">$3.19 \times 10^{-3}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$3.41 \times 10^{-1}$</td>
<td style="text-align: center;">$3.01 \times 10^{-6}$</td>
<td style="text-align: center;">$9.46 \times 10^{-4}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">..</td>
<td style="text-align: center;">..</td>
<td style="text-align: center;">..</td>
</tr>
</tbody>
</table>
<p>Figure 3 The probabilities that the selected compounds have high $G_{50}$</p>
<p>Gaussian distribution, zero mean, variance, prior belief, posterior probability, random variable, likelihood, estimated probability. HELO contains exact matching terms or equivalent synonyms of the required semantic descriptors, for example HAS-VALUE (mean, 0 ) is equivalent to zero mean.</p>
<h1>Conclusion</h1>
<p>Scientific knowledge is inherently uncertain. There is therefore a need for a representation that focuses on the probabilistic features of research statements, and supports probabilistic reasoning. In order to address this need we proposed the ontology HELO that supports probabilistic reasoning over uncertain scientific statements. HELO defines a hierarchy of typical research statements and links them to their associated probabilities, and methods of obtaining those probabilities. We demonstrated HELO on the representation of scientific belief that sirtuins regulate organism life span, and regarding deleted genes in the S. cerevisiae aromatic amino acid pathway. In both cases the probability of research statements changed with new evidence, and it is clearly important to employ the most updated probability estimate for making decisions about research involving these genes. The active learning for drug discovery study is based on operations with probabilities. The probabilities of having a high $\mathrm{pGI}_{50}$ were iteratively computed for all compounds in the library, and the best compounds were chosen for further study. HELO enables accurate recording of supporting and refuting evidence of research statements, and how they participate in the process of updating probability values.</p>
<p>HELO is specifically designed to support the cycles of automatic scientific discovery that incorporate text mining, machine learning, robotic automation, and knowledge representation, and may be of use for other of research that involve probabilistic reasoning.</p>
<h1>Author's contributions</h1>
<p>LNS originated the idea of ontological representation of the key entities of the theory of probability and worked on the ontology HELO. AR originated the idea of annotating research statements extracted from natural language text with semantic descriptors indicating the level of truthfulness of those statements, and also the recording of competing and contradictory statements. KDeG applied HELO for the reporting on the active learning for high throughput screening study. RDK originated the idea of using probabilities of hypotheses for the choice of experiments in automated experimentation. He also contributed to the development of HELO and other worked examples.</p>
<h2>Acknowledgements</h2>
<p>This work was partially supported by grant BB/F008228/1 from the UK Biotechnology \&amp; Biological Sciences Research Council, from the European Commission under the FP7 Collaborative Programme, UNICELLSYS, KU Leuven GOA/08/ 008 and ERC Starting Grant 240186.</p>
<h2>Declarations</h2>
<p>The publication costs for this article were funded by the corresponding author's institution, Brunei University, London. This article has been published as part of Journal of Biomedical Semantics Volume 4 Supplement 1, 2013: Proceedings of the Bio-Ontologies Special Interest Group 2012. The full contents of the supplement are available online at http:// www.jbiomedsem.com/supplements/4/51</p>
<h2>Author details</h2>
<p>${ }^{1}$ Department of Information Systems and Computing, Brunel University, London, UK. ${ }^{2}$ Department of Medicine \&amp; Department of Human Genetics, the University of Chicago, US. ${ }^{3}$ Department of Computer Science, KU Leuven, Belgium. ${ }^{4}$ Manchester Institute of Biotechnology, the University of Manchester, UK.</p>
<p>Published: 15 April 2013</p>
<h2>References</h2>
<ol>
<li>Barber D: Bayesian Reasoning and Machine Learning. Cambridge University Press; 2012.</li>
<li>Gillies D: Philosophical Theories of Probability. Routledge; 2000.</li>
<li>Howson C, Urbach P: Scientific reasoning: The Bayesian approach. Chicago: Open Court; 1993.</li>
<li>Evidence Code Ontology. [www.obofoundry.org/cgi-bin/detail.cgi?id=evidence_code].</li>
<li>Bengley CG, Ellis LM: Raise standards for preclinical cancer research. Nature 2012, 483:531-533.</li>
<li>Prinz F, Gilliand DG: Drug development and clinical trials - the path to an approved cancer drug. Nature Rev.Clin. Oncol 2012, 22.</li>
<li>Soldatova L, Rzhetsky A: Representation research hypotheses. J. of Biomedical Semantic 2011, 2(2):59.</li>
<li>Gene Ontology. [www.geneontology.org].</li>
<li>Schmidt M, Lipson H: Distilling Free-Form Natural Laws from Experimental Data. Science 2009, 81-85.</li>
<li>Ontology of Adverse Events. [www.oae-ontology.org].</li>
<li>Mass Spectrometry. [bioportal.bioontology.org/ontologies/1105].</li>
<li>Parasite Experiment Ontology. [bioportal.bioontology.org/ontologies/1335].</li>
<li>Computational Neuroscience Ontology. [bioportal.bioontology.org/ontologies/3003].</li>
<li>Semanticscience Integrated Ontology. [code.google.com/p/semanticscience/wiki/SIO].</li>
<li>Ross SM: Introduction to probability Models. Academic Press; 2007.</li>
<li>Lee PM: Bayesian Statistics. New York: Hodder Arnold; 2004.</li>
<li>Basic Formal Ontology. [www.ifomis.org/bfo].</li>
<li>Information Artifact Ontology. [code.google.com/p/information-artifact-ontology].</li>
<li>Ontology for Biomedical Investigations. [obi-ontology.org].</li>
<li>King R, Whelan K, Jones F, et al: Functional genomic hypothesis generation and experimentation by a robot scientist. Nature 2004, 427:247-252.</li>
<li>King R, Rowland J, Oliver SG, Young M, Aubrey W, Byrne E, Liakata M, Markham M, Pir P, Soldatova LN, Sparkes A, Whelan K, Clare A: The Automation of Science. Science 2009, 324(5923):65-89.</li>
<li>Tissenbaum HA, Guarente L: Increased dosage of a sir-2 gene extends lifespan in Caenorhabditis elegans. Nature 2001, 410:227-230.</li>
<li>Kanfi Y, Naiman S, Amir G, et al: The sirtuin SIRT6 regulates lifespan in male mice. Nature 2008, 483(7388):218-21.</li>
<li>
<p>Michan S, Sinclair S: Sirtuins in mammals: insights into their biological function. Biochem 2007, 404:1-13.</p>
</li>
<li>
<p>Burnett C, Valentini S, Cabreiro F, et al: Absence of effects of Sir2 overexpression on lifespan in C. elegans and Drosophila. Nature 2011, 477:482-485.</p>
</li>
<li>Vossifov I, Rodriguez-Esteban R, Mayzus I, Millen K, Rzhetsky A: Looking at cerebellar malformations through textmined interactomes of mice and humans. PLoS Comput Biol 2009, 5(e1000559).</li>
<li>De Grave K, Ramon J, De Raedt L: Active Learning for High Throughput Screening. Proceedings of the Eleventh International Conference on Discovery Science, Volume 5255 of Lecture Notes in Computer Science Springer, 2008, 185-196.</li>
<li>Cox D, John S: SDO: a statistical method for global optimization. In Multidisciplinary Design Optimization. Philadelphia, PA: SIAM;Hampton VA 1997:315-329.</li>
<li>Kushner H: A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. Journal of Basic Engineering 1964, 97-106.</li>
<li>Shoemaker R: The NCI60 human tumor cell line anticancer drug screen. Nat. Rev. Cancer 2006, 6:813-823.</li>
<li>Nishizuka S, et al: Proteomic profiling of the NCI-60 cancer cell lines using new high-density reverse-phase lysate microarrays. PNAS 2003, 100(24):14229-14234.
doi:10.1186/2041-1480-4-S1-57
Cite this article as: Soldatova et al.: Representation of probabilistic scientific knowledge. Journal of Biomedical Semantics 2013 4(Suppl 1):S7.</li>
</ol>
<h1>Submit your next manuscript to BioMed Central and take full advantage of:</h1>
<ul>
<li>Convenient online submission</li>
<li>Thorough peer review</li>
<li>No space constraints or color figure charges</li>
<li>Immediate publication on acceptance</li>
<li>Inclusion in PubMed, CAS, Scopus and Google Scholar</li>
<li>Research which is freely available for redistribution</li>
</ul>
<p>Submit your manuscript at www.biomedcentral.com/submit
(1) BioMed Central</p>            </div>
        </div>

    </div>
</body>
</html>