<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5043 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5043</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5043</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-3a58efcc4558727cc5c131c44923635da4524f33</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3a58efcc4558727cc5c131c44923635da4524f33" target="_blank">Relational inductive biases, deep learning, and graph networks</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> It is argued that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective.</p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. 
The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5043",
    "paper_id": "paper-3a58efcc4558727cc5c131c44923635da4524f33",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.005785749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Relational inductive biases, deep learning, and graph networks</h1>
<p>Peter W. Battaglia ${ }^{1}$, Jessica B. Hamrick ${ }^{1}$, Victor Bapst ${ }^{1}$, Alvaro Sanchez-Gonzalez ${ }^{1}$, Vinicius Zambaldi ${ }^{1}$, Mateusz Malinowski ${ }^{1}$, Andrea Tacchetti ${ }^{1}$, David Raposo ${ }^{1}$, Adam Santoro ${ }^{1}$, Ryan Faulkner ${ }^{1}$, Caglar Gulcehre ${ }^{1}$, Francis Song ${ }^{1}$, Andrew Ballard ${ }^{1}$, Justin Gilmer ${ }^{2}$, George Dahl ${ }^{2}$, Ashish Vaswani ${ }^{2}$, Kelsey Allen ${ }^{3}$, Charles Nash ${ }^{4}$, Victoria Langston ${ }^{1}$, Chris Dyer ${ }^{1}$, Nicolas Heess ${ }^{1}$, Daan Wierstra ${ }^{1}$, Pushmeet Kohli ${ }^{1}$, Matt Botvinick ${ }^{1}$, Oriol Vinyals ${ }^{1}$, Yujia Li ${ }^{1}$, Razvan Pascanu ${ }^{1}$<br>${ }^{1}$ DeepMind; ${ }^{2}$ Google Brain; ${ }^{3}$ MIT; ${ }^{4}$ University of Edinburgh</p>
<h4>Abstract</h4>
<p>Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences - a hallmark of human intelligence from infancy - remains a formidable challenge for modern AI.</p>
<p>The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between "hand-engineering" and "end-to-end" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias - the graph network-which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have also released an open-source software library for building graph networks, with demonstrations of how to use them in practice.</p>
<h2>1 Introduction</h2>
<p>A key signature of human intelligence is the ability to make "infinite use of finite means" (Humboldt, 1836; Chomsky, 1965), in which a small set of elements (such as words) can be productively composed in limitless ways (such as into new sentences). This reflects the principle of combinatorial generalization, that is, constructing new inferences, predictions, and behaviors from known building blocks. Here we explore how to improve modern AI's capacity for combinatorial generalization by</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>biasing learning towards structured representations and computations, and in particular, systems that operate on graphs.</p>
<p>Humans' capacity for combinatorial generalization depends critically on our cognitive mechanisms for representing structure and reasoning about relations. We represent complex systems as compositions of entities and their interactions ${ }^{1}$ (Navon, 1977; McClelland and Rumelhart, 1981; Plaut et al., 1996; Marcus, 2001; Goodwin and Johnson-Laird, 2005; Kemp and Tenenbaum, 2008), such as judging whether a haphazard stack of objects is stable (Battaglia et al., 2013). We use hierarchies to abstract away from fine-grained differences, and capture more general commonalities between representations and behaviors (Botvinick, 2008; Tenenbaum et al., 2011), such as parts of an object, objects in a scene, neighborhoods in a town, and towns in a country. We solve novel problems by composing familiar skills and routines (Anderson, 1982), for example traveling to a new location by composing familiar procedures and objectives, such as "travel by airplane", "to San Diego", "eat at", and "an Indian restaurant". We draw analogies by aligning the relational structure between two domains and drawing inferences about one based on corresponding knowledge about the other (Gentner and Markman, 1997; Hummel and Holyoak, 2003).</p>
<p>Kenneth Craik's "The Nature of Explanation" (1943), connects the compositional structure of the world to how our internal mental models are organized:
...[a human mental model] has a similar relation-structure to that of the process it imitates. By 'relation-structure' I do not mean some obscure non-physical entity which attends the model, but the fact that it is a working physical model which works in the same way as the process it parallels... physical reality is built up, apparently, from a few fundamental types of units whose properties determine many of the properties of the most complicated phenomena, and this seems to afford a sufficient explanation of the emergence of analogies between mechanisms and similarities of relation-structure among these combinations without the necessity of any theory of objective universals. (Craik, 1943, page 51-55)</p>
<p>That is, the world is compositional, or at least, we understand it in compositional terms. When learning, we either fit new knowledge into our existing structured representations, or adjust the structure itself to better accommodate (and make use of) the new and the old (Tenenbaum et al., 2006; Griffiths et al., 2010; Ullman et al., 2017).</p>
<p>The question of how to build artificial systems which exhibit combinatorial generalization has been at the heart of AI since its origins, and was central to many structured approaches, including logic, grammars, classic planning, graphical models, causal reasoning, Bayesian nonparametrics, and probabilistic programming (Chomsky, 1957; Nilsson and Fikes, 1970; Pearl, 1986, 2009; Russell and Norvig, 2009; Hjort et al., 2010; Goodman et al., 2012; Ghahramani, 2015). Entire sub-fields have focused on explicit entity- and relation-centric learning, such as relational reinforcement learning (Džeroski et al., 2001) and statistical relational learning (Getoor and Taskar, 2007). A key reason why structured approaches were so vital to machine learning in previous eras was, in part, because data and computing resources were expensive, and the improved sample complexity afforded by structured approaches' strong inductive biases was very valuable.</p>
<p>In contrast with past approaches in AI, modern deep learning methods (LeCun et al., 2015; Schmidhuber, 2015; Goodfellow et al., 2016) often follow an "end-to-end" design philosophy which emphasizes minimal a priori representational and computational assumptions, and seeks to avoid explicit structure and "hand-engineering". This emphasis has fit well with-and has perhaps been affirmed by-the current abundance of cheap data and cheap computing resources, which make</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>trading off sample efficiency for more flexible learning a rational choice. The remarkable and rapid advances across many challenging domains, from image classification (Krizhevsky et al., 2012; Szegedy et al., 2017), to natural language processing (Sutskever et al., 2014; Bahdanau et al., 2015), to game play (Mnih et al., 2015; Silver et al., 2016; Moravčík et al., 2017), are a testament to this minimalist principle. A prominent example is from language translation, where sequence-to-sequence approaches (Sutskever et al., 2014; Bahdanau et al., 2015) have proven very effective without using explicit parse trees or complex relationships between linguistic entities.</p>
<p>Despite deep learning's successes, however, important critiques (Marcus, 2001; Shalev-Shwartz et al., 2017; Lake et al., 2017; Lake and Baroni, 2018; Marcus, 2018a,b; Pearl, 2018; Yuille and Liu, 2018) have highlighted key challenges it faces in complex language and scene understanding, reasoning about structured data, transferring learning beyond the training conditions, and learning from small amounts of experience. These challenges demand combinatorial generalization, and so it is perhaps not surprising that an approach which eschews compositionality and explicit structure struggles to meet them.</p>
<p>When deep learning's connectionist (Rumelhart et al., 1987) forebears were faced with analogous critiques from structured, symbolic positions (Fodor and Pylyshyn, 1988; Pinker and Prince, 1988), there was a constructive effort (Bobrow and Hinton, 1990; Marcus, 2001) to address the challenges directly and carefully. A variety of innovative sub-symbolic approaches for representing and reasoning about structured objects were developed in domains such as analogy-making, linguistic analysis, symbol manipulation, and other forms of relational reasoning (Smolensky, 1990; Hinton, 1990; Pollack, 1990; Elman, 1991; Plate, 1995; Eliasmith, 2013), as well as more integrative theories for how the mind works (Marcus, 2001). Such work also helped cultivate more recent deep learning advances which use distributed, vector representations to capture rich semantic content in text (Mikolov et al., 2013; Pennington et al., 2014), graphs (Narayanan et al., 2016, 2017), algebraic and logical expressions (Allamanis et al., 2017; Evans et al., 2018), and programs (Devlin et al., 2017; Chen et al., 2018b).</p>
<p>We suggest that a key path forward for modern AI is to commit to combinatorial generalization as a top priority, and we advocate for integrative approaches to realize this goal. Just as biology does not choose between nature versus nurture - it uses nature and nurture jointly, to build wholes which are greater than the sums of their parts - we, too, reject the notion that structure and flexibility are somehow at odds or incompatible, and embrace both with the aim of reaping their complementary strengths. In the spirit of numerous recent examples of principled hybrids of structure-based methods and deep learning (e.g., Reed and De Freitas, 2016; Garnelo et al., 2016; Ritchie et al., 2016; Wu et al., 2017; Denil et al., 2017; Hudson and Manning, 2018), we see great promise in synthesizing new techniques by drawing on the full AI toolkit and marrying the best approaches from today with those which were essential during times when data and computation were at a premium.</p>
<p>Recently, a class of models has arisen at the intersection of deep learning and structured approaches, which focuses on approaches for reasoning about explicitly structured data, in particular graphs (e.g. Scarselli et al., 2009b; Bronstein et al., 2017; Gilmer et al., 2017; Wang et al., 2018c; Li et al., 2018; Kipf et al., 2018; Gulcehre et al., 2018). What these approaches all have in common is a capacity for performing computation over discrete entities and the relations between them. What sets them apart from classical approaches is how the representations and structure of the entities and relations - and the corresponding computations - can be learned, relieving the burden of needing to specify them in advance. Crucially, these methods carry strong relational inductive biases, in the form of specific architectural assumptions, which guide these approaches towards learning about entities and relations (Mitchell, 1980), which we, joining many others (Spelke et al., 1992; Spelke and Kinzler, 2007; Marcus, 2001; Tenenbaum et al., 2011; Lake et al., 2017; Lake and Baroni, 2018; Marcus, 2018b), suggest are an essential ingredient for human-like intelligence.</p>
<h1>Box 1: Relational reasoning</h1>
<p>We define structure as the product of composing a set of known building blocks. "Structured representations" capture this composition (i.e., the arrangement of the elements) and "structured computations" operate over the elements and their composition as a whole. Relational reasoning, then, involves manipulating structured representations of entities and relations, using rules for how they can be composed. We use these terms to capture notions from cognitive science, theoretical computer science, and AI, as follows:</p>
<ul>
<li>An entity is an element with attributes, such as a physical object with a size and mass.</li>
<li>A relation is a property between entities. Relations between two objects might include same size as, heavier than, and distance from. Relations can have attributes as well. The relation more than $X$ times heavier than takes an attribute, $X$, which determines the relative weight threshold for the relation to be true vs. false. Relations can also be sensitive to the global context. For a stone and a feather, the relation falls WITH GREATER ACCELERATION THAN depends on whether the context is IN AIR vs. IN A vacuum. Here we focus on pairwise relations between entities.</li>
<li>A rule is a function (like a non-binary logical predicate) that maps entities and relations to other entities and relations, such as a scale comparison like is entity X large? and is entity X heavier than entity Y?. Here we consider rules which take one or two arguments (unary and binary), and return a unary property value.</li>
</ul>
<p>As an illustrative example of relational reasoning in machine learning, graphical models (Pearl, 1988; Koller and Friedman, 2009) can represent complex joint distributions by making explicit random conditional independences among random variables. Such models have been very successful because they capture the sparse structure which underlies many real-world generative processes and because they support efficient algorithms for learning and reasoning. For example, hidden Markov models constrain latent states to be conditionally independent of others given the state at the previous time step, and observations to be conditionally independent given the latent state at the current time step, which are well-matched to the relational structure of many real-world causal processes. Explicitly expressing the sparse dependencies among variables provides for various efficient inference and reasoning algorithms, such as message-passing, which apply a common information propagation procedure across localities within a graphical model, resulting in a composable, and partially parallelizable, reasoning procedure which can be applied to graphical models of different sizes and shape.</p>
<p>In the remainder of the paper, we examine various deep learning methods through the lens of their relational inductive biases, showing that existing methods often carry relational assumptions which are not always explicit or immediately evident. We then present a general framework for entity- and relation-based reasoning-which we term graph networks-for unifying and extending existing methods which operate on graphs, and describe key design principles for building powerful architectures using graph networks as building blocks. We have also released an open-source library for building graph networks, which can be found here: github.com/deepmind/graph_nets.</p>
<h2>2 Relational inductive biases</h2>
<p>Many approaches in machine learning and AI which have a capacity for relational reasoning</p>
<h1>Box 2: Inductive biases</h1>
<p>Learning is the process of apprehending useful knowledge by observing and interacting with the world. It involves searching a space of solutions for one expected to provide a better explanation of the data or to achieve higher rewards. But in many cases, there are multiple solutions which are equally good (Goodman, 1955). An inductive bias allows a learning algorithm to prioritize one solution (or interpretation) over another, independent of the observed data (Mitchell, 1980). In a Bayesian model, inductive biases are typically expressed through the choice and parameterization of the prior distribution (Griffiths et al., 2010). In other contexts, an inductive bias might be a regularization term (McClelland, 1994) added to avoid overfitting, or it might be encoded in the architecture of the algorithm itself. Inductive biases often trade flexibility for improved sample complexity and can be understood in terms of the bias-variance tradeoff (Geman et al., 1992). Ideally, inductive biases both improve the search for solutions without substantially diminishing performance, as well as help find solutions which generalize in a desirable way; however, mismatched inductive biases can also lead to suboptimal performance by introducing constraints that are too strong.</p>
<p>Inductive biases can express assumptions about either the data-generating process or the space of solutions. For example, when fitting a 1D function to data, linear least squares follows the constraint that the approximating function be a linear model, and approximation errors should be minimal under a quadratic penalty. This reflects an assumption that the datagenerating process can be explained simply, as a line process corrupted by additive Gaussian noise. Similarly, $L 2$ regularization prioritizes solutions whose parameters have small values, and can induce unique solutions and global structure to otherwise ill-posed problems. This can be interpreted as an assumption about the learning process: that searching for good solutions is easier when there is less ambiguity among solutions. Note, these assumptions need not be explicit-they reflect interpretations of how a model or algorithm interfaces with the world.
(Box 1) use a relational inductive bias. While not a precise, formal definition, we use this term to refer generally to inductive biases (Box 2) which impose constraints on relationships and interactions among entities in a learning process.</p>
<p>Creative new machine learning architectures have rapidly proliferated in recent years, with (perhaps not surprisingly given the thesis of this paper) practitioners often following a design pattern of composing elementary building blocks to form more complex, deep ${ }^{2}$ computational hierarchies and graphs ${ }^{3}$. Building blocks such as "fully connected" layers are stacked into "multilayer perceptrons" (MLPs), "convolutional layers" are stacked into "convolutional neural networks" (CNNs), and a standard recipe for an image processing network is, generally, some variety of CNN composed with a MLP. This composition of layers provides a particular type of relational inductive bias-that of hierarchical processing-in which computations are performed in stages, typically resulting in increasingly long range interactions among information in the input signal. As we explore below, the building blocks themselves also carry various relational inductive biases (Table 1). Though beyond the scope of this paper, various non-relational inductive biases are used in deep learning as well: for example, activation non-linearities, weight decay, dropout (Srivastava et al., 2014), batch and layer normalization (Ioffe and Szegedy, 2015; Ba et al., 2016), data augmentation, training curricula, and optimization algorithms all impose constraints on the trajectory and outcome of learning.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Entities</th>
<th>Relations</th>
<th>Rel. inductive bias</th>
<th>Invariance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fully connected</td>
<td>Units</td>
<td>All-to-all</td>
<td>Weak</td>
<td>-</td>
</tr>
<tr>
<td>Convolutional</td>
<td>Grid elements</td>
<td>Local</td>
<td>Locality</td>
<td>Spatial translation</td>
</tr>
<tr>
<td>Recurrent</td>
<td>Timesteps</td>
<td>Sequential</td>
<td>Sequentiality</td>
<td>Time translation</td>
</tr>
<tr>
<td>Graph network</td>
<td>Nodes</td>
<td>Edges</td>
<td>Arbitrary</td>
<td>Node, edge permutations</td>
</tr>
</tbody>
</table>
<p>Table 1: Various relational inductive biases in standard deep learning components. See also Section 2.</p>
<p>To explore the relational inductive biases expressed within various deep learning methods, we must identify several key ingredients, analogous to those in Box 1: what are the entities, what are the relations, and what are the rules for composing entities and relations, and computing their implications? In deep learning, the entities and relations are typically expressed as distributed representations, and the rules as neural network function approximators; however, the precise forms of the entities, relations, and rules vary between architectures. To understand these differences between architectures, we can further ask how each supports relational reasoning by probing:</p>
<ul>
<li>The arguments to the rule functions (e.g., which entities and relations are provided as input).</li>
<li>How the rule function is reused, or shared, across the computational graph (e.g., across different entities and relations, across different time or processing steps, etc.).</li>
<li>How the architecture defines interactions versus isolation among representations (e.g., by applying rules to draw conclusions about related entities, versus processing them separately).</li>
</ul>
<h1>2.1 Relational inductive biases in standard deep learning building blocks</h1>
<h3>2.1.1 Fully connected layers</h3>
<p>Perhaps the most common building block is a fully connected layer (Rosenblatt, 1961). Typically implemented as a non-linear vector-valued function of vector inputs, each element, or "unit", of the output vector is the dot product between a weight vector, followed by an added bias term, and finally a non-linearity such as a rectified linear unit (ReLU). As such, the entities are the units in the network, the relations are all-to-all (all units in layer $i$ are connected to all units in layer $j$ ), and the rules are specified by the weights and biases. The argument to the rule is the full input signal, there is no reuse, and there is no isolation of information (Figure 1a). The implicit relational inductive bias in a fully connected layer is thus very weak: all input units can interact to determine any output unit's value, independently across outputs (Table 1).</p>
<h3>2.1.2 Convolutional layers</h3>
<p>Another common building block is a convolutional layer (Fukushima, 1980; LeCun et al., 1989). It is implemented by convolving an input vector or tensor with a kernel of the same rank, adding a bias term, and applying a point-wise non-linearity. The entities here are still individual units (or grid elements, e.g. pixels), but the relations are sparser. The differences between a fully connected layer and a convolutional layer impose some important relational inductive biases: locality and translation invariance (Figure 1b). Locality reflects that the arguments to the relational rule are those entities in close proximity with one another in the input signal's coordinate space, isolated from distal entities. Translation invariance reflects reuse of the same rule across localities in the input. These biases are very effective for processing natural image data because there is high covariance within local</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Reuse and sharing in common deep learning building blocks. (a) Fully connected layer, in which all weights are independent, and there is no sharing. (b) Convolutional layer, in which a local kernel function is reused multiple times across the input. Shared weights are indicated by arrows with the same color. (c) Recurrent layer, in which the same function is reused across different processing steps.
neighborhoods, which diminishes with distance, and because the statistics are mostly stationary across an image (Table 1).</p>
<h1>2.1.3 Recurrent layers</h1>
<p>A third common building block is a recurrent layer (Elman, 1990), which is implemented over a sequence of steps. Here, we can view the inputs and hidden states at each processing step as the entities, and the Markov dependence of one step's hidden state on the previous hidden state and the current input, as the relations. The rule for combining the entities takes a step's inputs and hidden state as arguments to update the hidden state. The rule is reused over each step (Figure 1c), which reflects the relational inductive bias of temporal invariance (similar to a CNN's translational invariance in space). For example, the outcome of some physical sequence of events should not depend on the time of day. RNNs also carry a bias for locality in the sequence via their Markovian structure (Table 1).</p>
<h3>2.2 Computations over sets and graphs</h3>
<p>While the standard deep learning toolkit contains methods with various forms of relational inductive biases, there is no "default" deep learning component which operates on arbitrary relational structure. We need models with explicit representations of entities and relations, and learning algorithms which find rules for computing their interactions, as well as ways of grounding them in data. Importantly, entities in the world (such as objects and agents) do not have a natural order; rather, orderings can be defined by the properties of their relations. For example, the relations between the sizes of a set of objects can potentially be used to order them, as can their masses, ages, toxicities, and prices. Invariance to ordering - except in the face of relations - is a property that should ideally be reflected by a deep learning component for relational reasoning.</p>
<p>Sets are a natural representation for systems which are described by entities whose order is undefined or irrelevant; in particular, their relational inductive bias does not come from the presence of something, but rather from the absence. For illustration, consider the task of predicting the center</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Different graph representations. (a) A molecule, in which each atom is represented as a node and edges correspond to bonds (e.g. Duvenaud et al., 2015). (b) A mass-spring system, in which the rope is defined by a sequence of masses which are represented as nodes in the graph (e.g. Battaglia et al., 2016; Chang et al., 2017). (c) A $n$-body system, in which the bodies are nodes and the underlying graph is fully connected (e.g. Battaglia et al., 2016; Chang et al., 2017). (d) A rigid body system, in which the balls and walls are nodes, and the underlying graph defines interactions between the balls and between the balls and the walls (e.g. Battaglia et al., 2016; Chang et al., 2017). (e) A sentence, in which the words correspond to leaves in a tree, and the other nodes and edges could be provided by a parser (e.g. Socher et al., 2013). Alternately, a fully connected graph could be used (e.g. Vaswani et al., 2017). (f) An image, which can be decomposed into image patches corresponding to nodes in a fully connected graph (e.g. Santoro et al., 2017; Wang et al., 2018c).
of mass of a solar system comprised of $n$ planets, whose attributes (e.g., mass, position, velocity, etc.) are denoted by $\left{\mathbf{x}<em 2="2">{1}, \mathbf{x}</em>}, \ldots, \mathbf{x<em 1="1">{n}\right}$. For such a computation, the order in which we consider the planets does not matter because the state can be described solely in terms of aggregated, averaged quantities. However, if we were to use a MLP for this task, having learned the prediction for a particular input $\left(\mathbf{x}</em>}, \mathbf{x<em n="n">{2}, \ldots, \mathbf{x}</em>}\right)$ would not necessarily transfer to making a prediction for the same inputs under a different ordering $\left(\mathbf{x<em 1="1">{n}, \mathbf{x}</em>\right)$. Since there are $n$ ! such possible permutations, in the worst case, the MLP could consider each ordering as fundamentally different, and thus require an exponential number of input/output training examples to learn an approximating function. A natural way to handle such combinatorial explosion is to only allow the prediction to depend on symmetric functions of the inputs' attributes. This might mean computing shared per-object}, \ldots, \mathbf{x}_{2</p>
<p>features $\left{f\left(\mathbf{x}<em n="n">{1}\right), \ldots, f\left(\mathbf{x}</em>\right)\right}$ which are then aggregated in a symmetric way (for example, by taking their mean). Such an approach is the essence of the Deep Sets and related models (Zaheer et al., 2017; Edwards and Storkey, 2016; Pevnỳ and Somol, 2017), which we explore further in Section 4.2.3.</p>
<p>Of course, permutation invariance is not the only important form of underlying structure in many problems. For example, each object in a set may be affected by pairwise interactions with the other objects in the set (Hartford et al., 2018). In our planets scenario, consider now the task of predicting each individual planet's position after a time interval, $\Delta t$. In this case, using aggregated, averaged information is not enough because the movement of each planet depends on the forces the other planets are exerting on it. Instead, we could compute the state of each object as $\mathbf{x}<em i="i">{i}^{\prime}=f\left(\mathbf{x}</em>}, \sum_{j} g\left(\mathbf{x<em j="j">{i}, \mathbf{x}</em>$}\right)\right)$, where $g$ could compute the force induced by the $j$-th planet on the $i$-th planet, and $f$ could compute the future state of the $i$-th planet which results from the forces and dynamics. The fact that we use the same $g$ everywhere is again a consequence of the global permutation invariance of the system; however, it also supports a different relational structure because $g$ now takes two arguments rather than one. ${ }^{4</p>
<p>The above solar system examples illustrate two relational structures: one in which there are no relations, and one which consists of all pairwise relations. Many real-world systems (such as in Figure 2) have a relational structure somewhere in between these two extremes, however, with some pairs of entities possessing a relation and others lacking one. In our solar system example, if the system instead consists of the planets and their moons, one may be tempted to approximate it by neglecting the interactions between moons of different planets. In practice, this means computing interactions only between some pairs of objects, i.e. $x_{i}^{\prime}=f\left(\mathbf{x}<em _delta_i_="\delta(i)" _in="\in" j="j">{i}, \sum</em>} g\left(\mathbf{x<em j="j">{i}, \mathbf{x}</em>$}\right)\right)$, where $\delta(i) \subseteq{1, \ldots, n}$ is a neighborhood around node $i$. This corresponds to a graph, in that the $i$-th object only interacts with a subset of the other objects, described by its neighborhood. Note, the updated states still do not depend in the order in which we describe the neighborhood. ${ }^{5</p>
<p>Graphs, generally, are a representation which supports arbitrary (pairwise) relational structure, and computations over graphs afford a strong relational inductive bias beyond that which convolutional and recurrent layers can provide.</p>
<h1>3 Graph networks</h1>
<p>Neural networks that operate on graphs, and structure their computations accordingly, have been developed and explored extensively for more than a decade under the umbrella of "graph neural networks" (Gori et al., 2005; Scarselli et al., 2005, 2009a; Li et al., 2016), but have grown rapidly in scope and popularity in recent years. We survey the literature on these methods in the next sub-section (3.1). Then in the remaining sub-sections, we present our graph networks framework, which generalizes and extends several lines of work in this area.</p>
<h3>3.1 Background</h3>
<p>Models in the graph neural network family (Gori et al., 2005; Scarselli et al., 2005, 2009a; Li et al., 2016) have been explored in a diverse range of problem domains, across supervised, semi-supervised, unsupervised, and reinforcement learning settings. They have been effective at tasks thought to have rich relational structure, such as visual scene understanding tasks (Raposo et al., 2017; Santoro</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>et al., 2017) and few-shot learning (Garcia and Bruna, 2018). They have also been used to learn the dynamics of physical systems (Battaglia et al., 2016; Chang et al., 2017; Watters et al., 2017; van Steenkiste et al., 2018; Sanchez-Gonzalez et al., 2018) and multi-agent systems (Sukhbaatar et al., 2016; Hoshen, 2017; Kipf et al., 2018), to reason about knowledge graphs (Bordes et al., 2013; Oñoro-Rubio et al., 2017; Hamaguchi et al., 2017), to predict the chemical properties of molecules (Duvenaud et al., 2015; Gilmer et al., 2017), to predict traffic on roads (Li et al., 2017; Cui et al., 2018), to classify and segment images and videos (Wang et al., 2018c; Hu et al., 2017) and 3D meshes and point clouds (Wang et al., 2018d), to classify regions in images (Chen et al., 2018a), to perform semi-supervised text classification (Kipf and Welling, 2017), and in machine translation (Vaswani et al., 2017; Shaw et al., 2018; Gulcehre et al., 2018). They have been used within both model-free (Wang et al., 2018b) and model-based (Hamrick et al., 2017; Pascanu et al., 2017; Sanchez-Gonzalez et al., 2018) continuous control, for model-free reinforcement learning (Hamrick et al., 2018; Zambaldi et al., 2018), and for more classical approaches to planning (Toyer et al., 2017).</p>
<p>Many traditional computer science problems, which involve reasoning about discrete entities and structure, have also been explored with graph neural networks, such as combinatorial optimization (Bello et al., 2016; Nowak et al., 2017; Dai et al., 2017), boolean satisfiability (Selsam et al., 2018), program representation and verification (Allamanis et al., 2018; Li et al., 2016), modeling cellular automata and Turing machines (Johnson, 2017), and performing inference in graphical models (Yoon et al., 2018). Recent work has also focused on building generative models of graphs (Li et al., 2018; De Cao and Kipf, 2018; You et al., 2018; Bojchevski et al., 2018), and unsupervised learning of graph embeddings (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016; García-Durán and Niepert, 2017).</p>
<p>The works cited above are by no means an exhaustive list, but provide a representative crosssection of the breadth of domains for which graph neural networks have proven useful. We point interested readers to a number of existing reviews which examine the body of work on graph neural networks in more depth. In particular, Scarselli et al. (2009a) provides an authoritative overview of early graph neural network approaches. Bronstein et al. (2017) provides an excellent survey of deep learning on non-Euclidean data, and explores graph neural nets, graph convolution networks, and related spectral approaches. Recently, Gilmer et al. (2017) introduced the message-passing neural network (MPNN), which unified various graph neural network and graph convolutional network approaches (Monti et al., 2017; Bruna et al., 2014; Henaff et al., 2015; Defferrard et al., 2016; Niepert et al., 2016; Kipf and Welling, 2017; Bronstein et al., 2017) by analogy to message-passing in graphical models. In a similar vein, Wang et al. (2018c) introduced the non-local neural network (NLNN), which unified various "self-attention"-style methods (Vaswani et al., 2017; Hoshen, 2017; Veličković et al., 2018) by analogy to methods from computer vision and graphical models for capturing long range dependencies in signals.</p>
<h1>3.2 Graph network (GN) block</h1>
<p>We now present our graph networks (GN) framework, which defines a class of functions for relational reasoning over graph-structured representations. Our GN framework generalizes and extends various graph neural network, MPNN, and NLNN approaches (Scarselli et al., 2009a; Gilmer et al., 2017; Wang et al., 2018c), and supports constructing complex architectures from simple building blocks. Note, we avoided using the term "neural" in the "graph network" label to reflect that they can be implemented with functions other than neural networks, though here our focus is on neural network implementations.</p>
<p>The main unit of computation in the GN framework is the GN block, a "graph-to-graph" module</p>
<h1>Box 3: Our definition of "graph"</h1>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Here we use "graph" to mean a directed, attributed multi-graph with a global attribute. In our terminology, a node is denoted as $\mathbf{v}<em k="k">{i}$, an edge as $\mathbf{e}</em>$ to indicate the indices of the sender and receiver nodes (see below), respectively, for edge $k$. To be more precise, we define these terms as:}$, and the global attributes as $\mathbf{u}$. We also use $s_{k}$ and $r_{k</p>
<p>Directed : one-way edges, from a "sender" node to a "receiver" node.
Attribute : properties that can be encoded as a vector, set, or even another graph.
Attributed : edges and vertices have attributes associated with them.
Global attribute : a graph-level attribute.
Multi-graph : there can be more than one edge between vertices, including self-edges.
Figure 2 shows a variety of different types of graphs corresponding to real data that we may be interested in modeling, including physical systems, molecules, images, and text.
which takes a graph as input, performs computations over the structure, and returns a graph as output. As described in Box 3, entities are represented by the graph's nodes, relations by the edges, and system-level properties by global attributes. The GN framework's block organization emphasizes customizability and synthesizing new architectures which express desired relational inductive biases. The key design principles are: Flexible representations (see Section 4.1); Configurable within-block structure (see Section 4.2); and Composable multi-block architectures (see Section 4.3).</p>
<p>We introduce a motivating example to help make the GN formalism more concrete. Consider predicting the movements a set of rubber balls in an arbitrary gravitational field, which, instead of bouncing against one another, each have one or more springs which connect them to some (or all) of the others. We will refer to this running example throughout the definitions below, to motivate the graph representation and the computations operating over it. Figure 2 depicts some other common scenarios that can be represented by graphs and reasoned over using graph networks.</p>
<h3>3.2.1 Definition of "graph"</h3>
<p>Within our GN framework, a graph is defined as a 3-tuple $G=(\mathbf{u}, V, E)$ (see Box 3 for details of graph representations). The $\mathbf{u}$ is a global attribute; for example, $\mathbf{u}$ might represent the gravitational field. The $V=\left{\mathbf{v}<em N_v="N^{v" i="1:">{i}\right}</em>}}$ is the set of nodes (of cardinality $N^{v}$ ), where each $\mathbf{v<em k="k">{i}$ is a node's attribute. For example, $V$ might represent each ball, with attributes for position, velocity, and mass. The $E=\left{\left(\mathbf{e}</em>\right)\right}}, r_{k}, s_{k<em k="k">{k=1: N^{e}}$ is the set of edges (of cardinality $N^{e}$ ), where each $\mathbf{e}</em>$ is the index of the sender node. For example, $E$ might represent the presence of springs between different balls, and their corresponding spring constants.}$ is the edge's attribute, $r_{k}$ is the index of the receiver node, and $s_{k</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mh">1</span><span class="w"> </span><span class="n">Steps</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">computation</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">full</span><span class="w"> </span><span class="n">GN</span><span class="w"> </span><span class="n">block</span><span class="p">.</span>
<span class="k">function</span><span class="w"> </span><span class="n">\(\operatorname{GrApHNetwork}(E,</span><span class="w"> </span><span class="n">V</span><span class="p">,</span><span class="w"> </span><span class="n">\mathbf{u})\)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">\(k</span><span class="w"> </span><span class="n">\in\left\{1</span><span class="w"> </span><span class="n">\ldots</span><span class="w"> </span><span class="n">N</span><span class="o">^</span><span class="p">{</span><span class="n">e</span><span class="p">}</span><span class="n">\right\}\)</span><span class="w"> </span><span class="k">do</span>
<span class="w">        </span><span class="n">\(\mathbf{e}_{k}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\phi^{e}\left(\mathbf{e}_{k},</span><span class="w"> </span><span class="n">\mathbf{v}_{r_{k}},</span><span class="w"> </span><span class="n">\mathbf{v}_{s_{k}},</span><span class="w"> </span><span class="n">\mathbf{u}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">1</span><span class="n">\).</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span><span class="k">edge</span><span class="w"> </span><span class="n">attributes</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">\(i</span><span class="w"> </span><span class="n">\in\left\{1</span><span class="w"> </span><span class="n">\ldots</span><span class="w"> </span><span class="n">N</span><span class="o">^</span><span class="p">{</span><span class="n">n</span><span class="p">}</span><span class="n">\right\}\)</span><span class="w"> </span><span class="k">do</span>
<span class="w">        </span><span class="n">let</span><span class="w"> </span><span class="n">\(E_{i}^{\prime}=\left\{\left(\mathbf{e}_{k}^{\prime},</span><span class="w"> </span><span class="n">r_</span><span class="p">{</span><span class="n">k</span><span class="p">},</span><span class="w"> </span><span class="n">s_</span><span class="p">{</span><span class="n">k</span><span class="p">}</span><span class="n">\right)\right\}_{r_{k}=i,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mh">1</span><span class="o">:</span><span class="w"> </span><span class="n">N</span><span class="o">^</span><span class="p">{</span><span class="n">e</span><span class="p">}}</span><span class="n">\)</span>
<span class="w">        </span><span class="n">\(\overline{\mathbf{e}}_{i}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\rho^{e</span><span class="w"> </span><span class="n">\rightarrow</span><span class="w"> </span><span class="n">v</span><span class="p">}</span><span class="n">\left(E_{i}^{\prime}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">2</span><span class="n">\).</span><span class="w"> </span><span class="n">Aggregate</span><span class="w"> </span><span class="k">edge</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">per</span><span class="w"> </span><span class="n">node</span>
<span class="w">        </span><span class="n">\(\mathbf{v}_{i}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\phi^{v}\left(\overline{\mathbf{e}}_{i}^{\prime},</span><span class="w"> </span><span class="n">\mathbf{v}_{i},</span><span class="w"> </span><span class="n">\mathbf{u}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">3</span><span class="n">\).</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n">attributes</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="w">    </span><span class="n">let</span><span class="w"> </span><span class="n">\(V^{\prime}=\left\{\mathbf{v}^{\prime}\right\}_{i=1:</span><span class="w"> </span><span class="n">N</span><span class="o">^</span><span class="p">{</span><span class="n">v</span><span class="p">}}</span><span class="n">\)</span>
<span class="w">    </span><span class="n">let</span><span class="w"> </span><span class="n">\(E^{\prime}=\left\{\left(\mathbf{e}_{k}^{\prime},</span><span class="w"> </span><span class="n">r_</span><span class="p">{</span><span class="n">k</span><span class="p">},</span><span class="w"> </span><span class="n">s_</span><span class="p">{</span><span class="n">k</span><span class="p">}</span><span class="n">\right)\right\}_{k=1:</span><span class="w"> </span><span class="n">N</span><span class="o">^</span><span class="p">{</span><span class="n">v</span><span class="p">}}</span><span class="n">\)</span>
<span class="w">    </span><span class="n">\(\overline{\mathbf{e}}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\rho^{v</span><span class="w"> </span><span class="n">\rightarrow</span><span class="w"> </span><span class="n">u</span><span class="p">}</span><span class="n">\left(E^{\prime}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">4</span><span class="n">\).</span><span class="w"> </span><span class="n">Aggregate</span><span class="w"> </span><span class="k">edge</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">globally</span>
<span class="w">    </span><span class="n">\(\overline{\mathbf{v}}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\rho^{v</span><span class="w"> </span><span class="n">\rightarrow</span><span class="w"> </span><span class="n">u</span><span class="p">}</span><span class="n">\left(V^{\prime}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">5</span><span class="n">\).</span><span class="w"> </span><span class="n">Aggregate</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n">attributes</span><span class="w"> </span><span class="n">globally</span>
<span class="w">    </span><span class="n">\(\mathbf{u}^{\prime}</span><span class="w"> </span><span class="n">\leftarrow</span><span class="w"> </span><span class="n">\phi^{u}\left(\overline{\mathbf{e}}^{\prime},</span><span class="w"> </span><span class="n">\overline{\mathbf{v}}^{\prime},</span><span class="w"> </span><span class="n">\mathbf{u}\right)</span><span class="w"> </span><span class="n">\quad</span><span class="w"> </span><span class="n">\triangleright</span><span class="w"> </span><span class="mh">6</span><span class="n">\).</span><span class="w"> </span><span class="n">Compute</span><span class="w"> </span><span class="n">updated</span><span class="w"> </span><span class="n">global</span><span class="w"> </span><span class="n">attribute</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">\(\left(E^{\prime},</span><span class="w"> </span><span class="n">V</span><span class="o">^</span><span class="p">{</span><span class="n">\prime},</span><span class="w"> </span><span class="n">\mathbf{u}^{\prime}\right)\)</span>
<span class="k">end</span><span class="w"> </span><span class="k">function</span>
</code></pre></div>

<h1>3.2.2 Internal structure of a GN block</h1>
<p>A GN block contains three "update" functions, $\phi$, and three "aggregation" functions, $\rho$,</p>
<p>$$
\begin{array}{ll}
\mathbf{e}<em k="k">{k}^{\prime}=\phi^{e}\left(\mathbf{e}</em>}, \mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right) &amp; \overline{\mathbf{e}<em i="i">{i}^{\prime}=\rho^{e \rightarrow v}\left(E</em>\right) \
\mathbf{v}}^{\prime<em i="i">{i}^{\prime}=\phi^{v}\left(\overline{\mathbf{e}}</em>\right) \
\mathbf{u}^{\prime}=\phi^{u}\left(\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u}\right) &amp; \overline{\mathbf{v}}^{\prime}=\rho^{v \rightarrow u}\left(V^{\prime}\right)
\end{array}
$$}^{\prime}, \mathbf{v}_{i}, \mathbf{u}\right) &amp; \overline{\mathbf{e}}^{\prime}=\rho^{e \rightarrow u}\left(E^{\prime</p>
<p>where $E_{i}^{\prime}=\left{\left(\mathbf{e}<em k="k">{k}^{\prime}, r</em>\right)\right}}, s_{k<em k="k">{r</em>}=i, k=1: N^{e}}, V^{\prime}=\left{\mathbf{v<em N_v="N^{v" i="1:">{i}^{\prime}\right}</em>}}$, and $E^{\prime}=\bigcup_{i} E_{i}^{\prime}=\left{\left(\mathbf{e<em k="k">{k}^{\prime}, r</em>$.
The $\phi^{e}$ is mapped across all edges to compute per-edge updates, the $\phi^{v}$ is mapped across all nodes to compute per-node updates, and the $\phi^{u}$ is applied once as the global update. The $\rho$ functions each take a set as input, and reduce it to a single element which represents the aggregated information. Crucially, the $\rho$ functions must be invariant to permutations of their inputs, and should take variable numbers of arguments (e.g., elementwise summation, mean, maximum, etc.).}, s_{k}\right)\right}_{k=1: N^{e}</p>
<h3>3.2.3 Computational steps within a GN block</h3>
<p>When a graph, $G$, is provided as input to a GN block, the computations proceed from the edge, to the node, to the global level. Figure 3 shows a depiction of which graph elements are involved in each of these computations, and Figure 4a shows a full GN block, with its update and aggregation functions. Algorithm 1 shows the following steps of computation:</p>
<ol>
<li>$\phi^{e}$ is applied per edge, with arguments $\left(\mathbf{e}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right)$, and returns $\mathbf{e<em i="i">{k}^{\prime}$. In our springs example, this might correspond to the forces or potential energies between two connected balls. The set of resulting per-edge outputs for each node, $i$, is, $E</em>}^{\prime}=\left{\left(\mathbf{e<em k="k">{k}^{\prime}, r</em>\right)\right}}, s_{k<em k="k">{r</em>}=i, k=1: N^{e}}$. And $E^{\prime}=\bigcup_{i} E_{i}^{\prime}=\left{\left(\mathbf{e<em k="k">{k}^{\prime}, r</em>$ is the set of all per-edge outputs.}, s_{k}\right)\right}_{k=1: N^{e}</li>
<li>$\rho^{e \rightarrow v}$ is applied to $E_{i}^{\prime}$, and aggregates the edge updates for edges that project to vertex $i$, into $\overline{\mathbf{e}}_{i}^{\prime}$, which will be used in the next step's node update. In our running example, this might correspond to summing all the forces or potential energies acting on the $i^{\text {th }}$ ball.</li>
</ol>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 3: Updates in a GN block. Blue indicates the element that is being updated, and black indicates other elements which are involved in the update (note that the pre-update value of the blue element is also used in the update). See Equation 1 for details on the notation.
3. $\phi^{v}$ is applied to each node $i$, to compute an updated node attribute, $\mathbf{v}<em i="i">{i}^{\prime}$. In our running example, $\phi^{v}$ may compute something analogous to the updated position, velocity, and kinetic energy of each ball. The set of resulting per-node outputs is, $V^{\prime}=\left{\mathbf{v}</em>$.
4. $\rho^{v \rightarrow u}$ is applied to $E^{\prime}$, and aggregates all edge updates, into $\overline{\mathbf{e}}^{\prime}$, which will then be used in the next step's global update. In our running example, $\rho^{v \rightarrow u}$ may compute the summed forces (which should be zero, in this case, due to Newton's third law) and the springs' potential energies.
5. $\rho^{v \rightarrow u}$ is applied to $V^{\prime}$, and aggregates all node updates, into $\overline{\mathbf{v}}^{\prime}$, which will then be used in the next step's global update. In our running example, $\rho^{v \rightarrow u}$ might compute the total kinetic energy of the system.
6. $\phi^{u}$ is applied once per graph, and computes an update for the global attribute, $\mathbf{u}^{\prime}$. In our running example, $\phi^{u}$ might compute something analogous to the net forces and total energy of the physical system.}^{\prime}\right}_{i=1: N^{v}</p>
<p>Note, though we assume this sequence of steps here, the order is not strictly enforced: it is possible to reverse the update functions to proceed from global, to per-node, to per-edge updates, for example. Kearnes et al. (2016) computes edge updates from nodes in a similar manner.</p>
<h1>3.2.4 Relational inductive biases in graph networks</h1>
<p>Our GN framework imposes several strong relational inductive biases when used as components in a learning process. First, graphs can express arbitrary relationships among entities, which means the GN's input determines how representations interact and are isolated, rather than those choices being determined by the fixed architecture. For example, the assumption that two entities have a relationship - and thus should interact-is expressed by an edge between the entities' corresponding nodes. Similarly, the absence of an edge expresses the assumption that the nodes have no relationship and should not influence each other directly.</p>
<p>Second, graphs represent entities and their relations as sets, which are invariant to permutations. This means GNs are invariant to the order of these elements ${ }^{6}$, which is often desirable. For example, the objects in a scene do not have a natural ordering (see Sec. 2.2).</p>
<p>Third, a GN's per-edge and per-node functions are reused across all edges and nodes, respectively. This means GNs automatically support a form of combinatorial generalization (see Section 5.1): because graphs are composed of edges, nodes, and global features, a single GN can operate on graphs of different sizes (numbers of edges and nodes) and shapes (edge connectivity).</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>4 Design principles for graph network architectures</h1>
<p>The GN framework can be used to implement a wide variety of architectures, in accordance with the design principles listed above in Section 3.2, which also correspond to the sub-sections (4.1, 4.2 , and 4.3 ) below. In general, the framework is agnostic to specific attribute representations and functional forms. Here, however, we focus mainly on deep learning architectures, which allow GNs to act as learnable graph-to-graph function approximators.</p>
<h3>4.1 Flexible representations</h3>
<p>Graph networks support highly flexible graph representations in two ways: first, in terms of the representation of the attributes; and second, in terms of the structure of the graph itself.</p>
<h3>4.1.1 Attributes</h3>
<p>The global, node, and edge attributes of a GN block can use arbitrary representational formats. In deep learning implementations, real-valued vectors and tensors are most common. However, other data structures such as sequences, sets, or even graphs could also be used.</p>
<p>The requirements of the problem will often determine what representations should be used for the attributes. For example, when the input data is an image, the attributes might be represented as tensors of image patches; however, when the input data is a text document, the attributes might be sequences of words corresponding to sentences.</p>
<p>For each GN block within a broader architecture, the edge and node outputs typically correspond to lists of vectors or tensors, one per edge or node, and the global outputs correspond to a single vector or tensor. This allows a GN's output to be passed to other deep learning building blocks such as MLPs, CNNs, and RNNs.</p>
<p>The output of a GN block can also be tailored to the demands of the task. In particular,</p>
<ul>
<li>An edge-focused GN uses the edges as output, for example to make decisions about interactions among entities (Kipf et al., 2018; Hamrick et al., 2018).</li>
<li>A node-focused GN uses the nodes as output, for example to reason about physical systems (Battaglia et al., 2016; Chang et al., 2017; Wang et al., 2018b; Sanchez-Gonzalez et al., 2018).</li>
<li>A graph-focused GN uses the globals as output, for example to predict the potential energy of a physical system (Battaglia et al., 2016), the properties of a molecule (Gilmer et al., 2017), or answers to questions about a visual scene (Santoro et al., 2017).</li>
</ul>
<p>The nodes, edges, and global outputs can also be mixed-and-matched depending on the task. For example, Hamrick et al. (2018) used both the output edge and global attributes to compute a policy over actions.</p>
<h3>4.1.2 Graph structure</h3>
<p>When defining how the input data will be represented as a graph, there are generally two scenarios: first, the input explicitly specifies the relational structure; and second, the relational structure must be inferred or assumed. These are not hard distinctions, but extremes along a continuum.</p>
<p>Examples of data with more explicitly specified entities and relations include knowledge graphs, social networks, parse trees, optimization problems, chemical graphs, road networks, and physical systems with known interactions. Figures 2a-d illustrate how such data can be expressed as graphs.</p>
<p>Examples of data where the relational structure is not made explicit, and must be inferred or assumed, include visual scenes, text corpora, programming language source code, and multi-agent</p>
<p>systems. In these types of settings, the data may be formatted as a set of entities without relations, or even just a vector or tensor (e.g., an image). If the entities are not specified explicitly, they might be assumed, for instance, by treating each word in a sentence (Vaswani et al., 2017) or each local feature vector in a CNN's output feature map, as a node (Watters et al., 2017; Santoro et al., 2017; Wang et al., 2018c) (Figures 2e-f). Or, it might be possible to use a separate learned mechanism to infer entities from an unstructured signal (Luong et al., 2015; Mnih et al., 2014; Eslami et al., 2016; van Steenkiste et al., 2018). If relations are not available, the simplest approach is to instantiate all possible directed edges between entities (Figure 2f). This can be prohibitive for large numbers of entities, however, because the number of possible edges grows quadratically with the number of nodes. Thus developing more sophisticated ways of inferring sparse structure from unstructured data (Kipf et al., 2018) is an important future direction.</p>
<h1>4.2 Configurable within-block structure</h1>
<p>The structure and functions within a GN block can be configured in different ways, which offers flexibility in what information is made available as inputs to its functions, as well as how output edge, node, and global updates are produced. In particular, each $\phi$ in Equation 1 must be implemented with some function, $f$, where $f$ 's argument signature determines what information it requires as input; in Figure 4, the incoming arrows to each $\phi$ depict whether $\mathbf{u}, V$, and $E$ are taken as inputs. Hamrick et al. (2018) and Sanchez-Gonzalez et al. (2018) used the full GN block shown in Figure 4a. Their $\phi$ implementations used neural networks (denoted $\mathrm{NN}<em v="v">{e}, \mathrm{NN}</em>$ below, to indicate that they are different functions with different parameters). Their $\rho$ implementations used elementwise summation, but averages and max/min could also be used,}$, and $\mathrm{NN}_{u</p>
<p>$$
\begin{aligned}
&amp; \phi^{e}\left(\mathbf{e}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right):=f^{e}\left(\mathbf{e<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right)=\mathrm{NN<em k="k">{e}\left(\left[\mathbf{e}</em>}, \mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>\right]\right) \
&amp; \phi^{v}\left(\overline{\mathbf{e}}}}, \mathbf{u<em i="i">{i}^{\prime}, \mathbf{v}</em>}, \mathbf{u}\right):=f^{v}\left(\overline{\mathbf{e}<em i="i">{i}^{\prime}, \mathbf{v}</em>}, \mathbf{u}\right) \quad=\mathrm{NN<em i="i">{v}\left(\left[\overline{\mathbf{e}}</em>}^{\prime}, \mathbf{v<em u="u">{i}, \mathbf{u}\right]\right) \
&amp; \phi^{u}\left(\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u}\right):=f^{u}\left(\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u}\right) \quad=\mathrm{NN}</em>\right]\right) \
&amp; \rho^{e \rightarrow v}\left(E_{i}^{\prime}\right):=\quad=\sum_{\left{k: r_{k}=i\right}} \mathbf{e}}\left(\left[\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u<em i="i">{k}^{\prime} \
&amp; \rho^{v \rightarrow u}\left(V^{\prime}\right):=\quad=\sum</em>} \mathbf{v<em k="k">{i}^{\prime} \
&amp; \rho^{e \rightarrow u}\left(E^{\prime}\right):=\quad=\sum</em>
\end{aligned}
$$} \mathbf{e}_{k}^{\prime</p>
<p>where $[\mathbf{x}, \mathbf{y}, \mathbf{z}]$ indicates vector/tensor concatenation. For vector attributes, a MLP is often used for $\phi$, while for tensors such as image feature maps, CNNs may be more suitable.</p>
<p>The $\phi$ functions can also use RNNs, which requires an additional hidden state as input and output. Figure 4 b shows a very simple version of a GN block with RNNs as $\phi$ functions: there is no message-passing in this formulation, and this type of block might be used for recurrent smoothing of some dynamic graph states. Of course, RNNs as $\phi$ functions could also be used in a full GN block (Figure 4a).</p>
<p>A variety of other architectures can be expressed in the GN framework, often as different function choices and within-block configurations. The remaining sub-sections explore how a GN's within-block structure can be configured in different ways, with examples of published work which uses such configurations. See the Appendix for details.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4: Different internal GN block configurations. See Section 3.2 for details on the notation, and Section 4 for details about each variant. (a) A full GN predicts node, edge, and global output attributes based on incoming node, edge, and global attributes. (b) An independent, recurrent update block takes input and hidden graphs, and the $\phi$ functions are RNNs (Sanchez-Gonzalez et al., 2018). (c) An MPNN (Gilmer et al., 2017) predicts node, edge, and global output attributes based on incoming node, edge, and global attributes. Note that the global prediction does not include aggregated edges. (d) A NLNN (Wang et al., 2018c) only predicts node output attributes. (e) A relation network (Raposo et al., 2017; Santoro et al., 2017) only uses the edge predictions to predict global attributes. (f) A Deep Set (Zaheer et al., 2017) bypasses the edge update and predicts updated global attributes.</p>
<h1>4.2.1 Message-passing neural network (MPNN)</h1>
<p>Gilmer et al. (2017)'s MPNN generalizes a number of previous architectures and can be translated naturally into the GN formalism. Following the MPNN paper's terminology (see Gilmer et al. (2017), pages 2-4):</p>
<ul>
<li>the message function, $M_{t}$, plays the role of the GN's $\phi^{c}$, but does not take $\mathbf{u}$ as input,</li>
<li>elementwise summation is used for the GN's $\rho^{c \rightarrow v}$,</li>
<li>the update function, $U_{t}$, plays the role of the GN's $\phi^{v}$,</li>
</ul>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 5: NLNNs as GNs. A schematic showing how NLNNs (Wang et al., 2018c) are implemented by the $\phi^{e}$ and $\rho^{e \rightarrow v}$ under the GN framework. Typically, NLNNs assume that different regions of an image (or words in a sentence) correspond to nodes in a fully connected graph, and the attention mechanism defines a weighted sum over nodes during the aggregation step.</p>
<ul>
<li>the readout function, $R$, plays the role of the GN's $\phi^{u}$, but does not take $\mathbf{u}$ or $E^{\prime}$ as input, and thus an analog to the GN's $\rho^{e \rightarrow u}$ is not required;</li>
<li>$d_{\text {master }}$ serves a roughly similar purpose to the GN's $\mathbf{u}$, but is defined as an extra node connected to all others, and thus does not influence the edge and global updates directly. It can then be represented in the GN's $V$.</li>
</ul>
<p>Figure 4c shows how an MPNN is structured, according to the GN framework. For details and various MPNN architectures, see the Appendix.</p>
<h1>4.2.2 Non-local neural networks (NLNN)</h1>
<p>Wang et al. (2018c)'s NLNN, which unifies various "intra-/self-/vertex-/graph-attention" approaches (Lin et al., 2017; Vaswani et al., 2017; Hoshen, 2017; Veličković et al., 2018; Shaw et al., 2018), can also be translated into the GN formalism. The label "attention" refers to how the nodes are updated: each node update is based on a weighted sum of (some function of) the node attributes of its neighbors, where the weight between a node and one of its neighbors is computed by a scalar pairwise function between their attributes (and then normalized across neighbors). The published NLNN formalism does not explicitly include edges, and instead computes pairwise attention weights between all nodes. But various NLNN-compliant models, such as the vertex attention interaction network (Hoshen, 2017) and graph attention network (Veličković et al., 2018), are able to handle explicit edges by effectively setting to zero the weights between nodes which do not share an edge.</p>
<p>As Figures 4 d and 5 illustrate, the $\phi^{e}$ is factored into the scalar pairwise-interaction function which returns the unnormalized attention term, denoted $\alpha^{e}\left(\mathbf{v}<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}\right)=a_{k}^{\prime}$, and a vector-valued non-pairwise term, denoted $\beta^{e}\left(\mathbf{v<em k="k">{s</em>}}\right)=\mathbf{b<em k="k">{k}^{\prime}$. In the $\rho^{e \rightarrow v}$ aggregation, the $a</em>$, and elementwise summed:}^{\prime}$ terms are normalized across each receiver's edges, $\mathbf{b}_{k}^{\prime</p>
<p>$$
\begin{aligned}
\phi^{e}\left(\mathbf{e}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right) &amp; :=f^{e}\left(\mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}\right) &amp; =\left(\alpha^{e}\left(\mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}\right), \beta^{e}\left(\mathbf{v<em k="k">{s</em>}}\right)\right)=\left(a_{k}^{\prime}, \mathbf{b<em k="k">{k}^{\prime}\right)=\mathbf{e}</em> \
\phi^{v}\left(\hat{\mathbf{e}}}^{\prime<em i="i">{i}^{\prime}, \mathbf{v}</em>}, \mathbf{u}\right) &amp; :=f^{v}\left(\hat{\mathbf{e}<em i="i">{i}^{\prime}\right) &amp; \
\rho^{e \rightarrow v}\left(E</em>
\end{aligned}
$$}^{\prime}\right) &amp; :=\frac{1}{\sum_{\left{k: r_{k}=i\right}} a_{k}^{\prime}} \sum_{\left{k: r_{k}=i\right}} a_{k}^{\prime} \mathbf{b}_{k}^{\prime</p>
<p>In the NLNN paper's terminology (see Wang et al. (2018c), pages 2-4):</p>
<ul>
<li>
<p>their $f$ plays the role of the above $\alpha$,</p>
</li>
<li>
<p>their $g$ plays the role of the above $\beta$.</p>
</li>
</ul>
<p>This formulation may be helpful for focusing only on those interactions which are most relevant for the downstream task, especially when the input entities were a set, from which a graph was formed by adding all possible edges between them.</p>
<p>Vaswani et al. (2017)'s multi-headed self-attention mechanism adds an interesting feature, where the $\phi^{e}$ and $\rho^{e \rightarrow v}$ are implemented by a parallel set of functions, whose results are concatenated together as the final step of $\rho^{e \rightarrow v}$. This can be interpreted as using typed edges, where the different types index into different $\phi^{e}$ component functions, analogous to Li et al. (2016).</p>
<p>For details and various NLNN architectures, see the Appendix.</p>
<h1>4.2.3 Other graph network variants</h1>
<p>The full GN (Equation 2) can be used to predict a full graph, or any subset of $\left(\mathbf{u}^{\prime}, V^{\prime}, E^{\prime}\right)$, as outlined in Section 4.1.1. For example, to predict a global property of a graph, $V^{\prime}$ and $E^{\prime}$ can just be ignored. Similarly, if global, node, or edge attributes are unspecified in the inputs, those vectors can be zero-length, i.e., not taken as explicit input arguments. The same idea applies for other GN variants which do not use the full set of mapping $(\phi)$ and reduction $(\rho)$ functions. For instance, Interaction Networks (Battaglia et al., 2016; Watters et al., 2017) and the Neural Physics Engine (Chang et al., 2017) use a full GN but for the absence of the global to update the edge properties (see Appendix for details).</p>
<p>Various models, including CommNet (Sukhbaatar et al., 2016), structure2vec (Dai et al., 2016) (in the version of (Dai et al., 2017)), and Gated Graph Sequence Neural Networks (Li et al., 2016) have used a $\phi^{e}$ which does not directly compute pairwise interactions, but instead ignore the receiver node, operating only on the sender node and in some cases an edge attribute. This can be expressed by implementations of $\phi^{e}$ with the following signatures, such as:</p>
<p>$$
\begin{aligned}
&amp; \phi^{e}\left(\mathbf{e}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right):=f^{e}\left(\mathbf{v<em k="k">{s</em>\right) \
\text { or } &amp; \phi^{e}\left(\mathbf{e}}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right):=\mathbf{v<em k="k">{s</em>}}+f^{e}\left(\mathbf{e<em k="k">{k}\right) \
\text { or } &amp; \phi^{e}\left(\mathbf{e}</em>}, \mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right):=f^{e}\left(\mathbf{e<em s__k="s_{k">{k}, \mathbf{v}</em>\right) .
\end{aligned}
$$}</p>
<p>See the Appendix for further details.
Relation Networks (Raposo et al., 2017; Santoro et al., 2017) bypass the node update entirely and predict the global output from pooled edge information directly (see also Figure 4e),</p>
<p>$$
\begin{aligned}
\phi^{e}\left(\mathbf{e}<em r__k="r_{k">{k}, \mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>}}, \mathbf{u}\right):=f^{e}\left(\mathbf{v<em k="k">{r</em>}}, \mathbf{v<em k="k">{s</em>}}\right) &amp; =\mathrm{NN<em r__k="r_{k">{e}\left(\left[\mathbf{v}</em>}}, \mathbf{v<em k="k">{s</em>\right]\right) \
\phi^{u}\left(\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u}\right):=f^{u}\left(\overline{\mathbf{e}}^{\prime}\right) &amp; =\mathrm{NN}}<em k="k">{u}\left(\overline{\mathbf{e}}^{\prime}\right) \
\rho^{e \rightarrow u}\left(E^{\prime}\right):= &amp; =\sum</em>
\end{aligned}
$$} \mathbf{e}_{k}^{\prime</p>
<p>Deep Sets (Zaheer et al., 2017) bypass the edges update completely and predict the global output from pooled nodes information directly (Figure 4f),</p>
<p>$$
\begin{aligned}
\phi^{v}\left(\overline{\mathbf{e}}<em i="i">{i}, \mathbf{v}</em>}, \mathbf{u}\right):=f^{v}\left(\mathbf{v<em v="v">{i}, \mathbf{u}\right) &amp; =\mathrm{NN}</em>}\left(\left[\mathbf{v<em u="u">{i}, \mathbf{u}\right]\right) \
\phi^{u}\left(\overline{\mathbf{e}}^{\prime}, \overline{\mathbf{v}}^{\prime}, \mathbf{u}\right):=f^{u}\left(\overline{\mathbf{v}}^{\prime}\right) &amp; =\mathrm{NN}</em>\right) \
\rho^{v \rightarrow u}\left(V^{\prime}\right):= &amp; =\sum_{i} \mathbf{v}_{i}^{\prime}
\end{aligned}
$$}\left(\overline{\mathbf{v}}^{\prime</p>
<p>PointNet (Qi et al., 2017) use similar update rule, with a max-aggregation for $\rho^{v \rightarrow u}$ and a two-step node update.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 6: (a) An example composing multiple GN blocks in sequence to form a GN "core". Here, the GN blocks can use shared weights, or they could be independent. (b) The encode-process-decode architecture, which is a common choice for composing GN blocks (see Section 4.3). Here, a GN encodes an input graph, which is then processed by a GN core. The output of the core is decoded by a third GN block into an output graph, whose nodes, edges, and/or global attributes would be used for task-specific purposes. (c) The encode-process-decode architecture applied in a sequential setting in which the core is also unrolled over time (potentially using a GRU or LSTM architecture), in addition to being repeated within each time step. Here, merged lines indicate concatenation, and split lines indicate copying.</p>
<h1>4.3 Composable multi-block architectures</h1>
<p>A key design principle of graph networks is constructing complex architectures by composing GN blocks. We defined a GN block as always taking a graph comprised of edge, node, and global elements as input, and returning a graph with the same constituent elements as output (simply passing through the input elements to the output when those elements are not explicitly updated). This graph-to-graph input/output interface ensures that the output of one GN block can be passed as input to another, even if their internal configurations are different, similar to the tensor-to-tensor interface of the standard deep learning toolkit. In the most basic form, two GN blocks, $\mathrm{GN}<em 2="2">{1}$ and $\mathrm{GN}</em>}$, can be composed as $\mathrm{GN<em 2="2">{1} \circ \mathrm{GN}</em>}$ by passing the output of the first as input to the second: $G^{\prime}=\mathrm{GN<em 1="1">{2}\left(\mathrm{GN}</em>(G)\right)$.</p>
<p>Arbitrary numbers of GN blocks can be composed, as show in Figure 6a. The blocks can be unshared (different functions and/or parameters, analogous to layers of a CNN), $\mathrm{GN}<em 2="2">{1} \neq$ $\mathrm{GN}</em>} \neq \cdots \neq \mathrm{GN<em 1="1">{M}$, or shared (reused functions and parameters, analogous to an unrolled RNN), $\mathrm{GN}</em>}=\mathrm{GN<em M="M">{2}=\cdots=\mathrm{GN}</em>$ (which aggregates information from across the nodes and edges), the information that a node has access to after $m$ steps of propagation is determined by the set of nodes and edges that are at most $m$ hops away. This can be interpreted as breaking down a complex computation into smaller elementary steps. The steps can also be used to capture sequentiality in time. In our ball-spring example, if each propagation step predicts the physical dynamics over one time step of duration $\Delta t$, then the $M$ propagation steps result in a total simulation time of, $M \cdot \Delta t$.}$. The white box around the $\mathrm{GN}_{\text {core }}$ in Figure 6a represents $M$ repeated internal processing sub-steps, with either shared or unshared GN blocks. Shared configurations are analogous to message-passing (Gilmer et al., 2017), where the same local update procedure is applied iteratively to propagate information across the structure (Figure 7). If we exclude the global $\mathbf{u</p>
<p>A common architecture design is what we call the encode-process-decode configuration (Hamrick et al. (2018); also see Figure 6ba): an input graph, $G_{\text {inp }}$ is transformed into a latent representation, $G_{0}$, by an encoder, $\mathrm{GN}<em _core="{core" _text="\text">{\text {enc }}$; a shared core block, $\mathrm{GN}</em>$. For example, in our running example, the encoder might compute the initial forces and interaction energies between the balls, the core might}}$, is applied $M$ times to return $G_{M}$; and finally an output graph, $G_{\text {out }}$, is decoded by $\mathrm{GN}_{\text {dec }</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 7: Example of message passing. Each row highlights the information that diffuses through the graph starting from a particular node. In the top row, the node of interest is in the upper right; in the bottom row, the node of interest is in the bottom right. Shaded nodes indicate how far information from the original node can travel in $m$ steps of message passing; bolded edges indicate which edges that information has the potential to travel across. Note that during the full message passing procedure, this propagation of information happens simultaneously for all nodes and edges in the graph (not just the two shown here).
apply an elementary dynamics update, and the decoder might read out the final positions from the updated graph state.</p>
<p>Similar to the encode-process-decode design, recurrent GN-based architectures can be built by maintaining a hidden graph, $G_{\text {hid }}^{t}$, taking as input an observed graph, $G_{\text {inp }}^{t}$, and returning an output graph, $G_{\text {out }}^{t}$, on each step (see Figure 6c). This type of architecture can be particularly useful for predicting sequences of graphs, such as predicting the trajectory of a dynamical system over time (e.g. Sanchez-Gonzalez et al., 2018). The encoded graph, output by $\mathrm{GN}<em _hid="{hid" _text="\text">{\text {enc }}$, must have the same structure as $G</em>}}^{t}$, and they can be easily combined by concatenating their corresponding $\mathbf{e<em i="i">{k}, \mathbf{v}</em>}$, and $\mathbf{u}$ vectors (where the upward arrow merges into the left-hand horizontal arrow in Figure 6c), before being passed to $\mathrm{GN<em _hid="{hid" _text="\text">{\text {core }}$. For the output, the $G</em>}}^{t}$ is copied (where the right-hand horizontal arrow splits into the downward arrow in Figure 6c) and decoded by $\mathrm{GN<em _enc="{enc" _text="\text">{\text {dec }}$. This design reuses GN blocks in several ways: $\mathrm{GN}</em>}}, \mathrm{GN<em _core="{core" _text="\text">{\text {dec }}$, and $\mathrm{GN}</em>$ may perform multiple shared sub-steps.}}$ are shared across each step, $t$; and within each step, $\mathrm{GN}_{\text {core }</p>
<p>Various other techniques for designing GN-based architectures can be useful. Graph skip connections, for example, would concatenate a GN block's input graph, $G_{m}$, with its output graph, $G_{m+1}$, before proceeding to further computations. Merging and smoothing input and hidden graph information, as in Figure 6c, can use LSTM- or GRU-style gating schemes, instead of simple concatenation (Li et al., 2016). Or distinct, recurrent GN blocks (e.g. Figure 4b) can be composed before and/or after other GN blocks, to improve stability in the representations over multiple propagation steps (Sanchez-Gonzalez et al., 2018).</p>
<h1>4.4 Implementing graph networks in code</h1>
<p>Similar to CNNs (see Figure 1), which are naturally parallelizable (e.g. on GPUs), GNs have a natural parallel structure: since the $\phi^{e}$ and $\phi^{v}$ functions in Equation 1 are shared over the edges and nodes, respectively, they can be computed in parallel. In practice, this means that with respect</p>
<h1>Box 4: Graph Nets open-source software library: github.com/deepmind/graph_nets</h1>
<p>We have released an open-source library for building GNs in Tensorflow/Sonnet. It includes demos of how to create, manipulate, and train GNs to reason about graph-structured data, on a shortest path-finding task, a sorting task, and a physical prediction task. Each demo uses the same GN architecture, which highlights the flexibility of the approach.</p>
<h2>Shortest path demo: tinyurl.com/gn-shortest-path-demo</h2>
<p>This demo creates random graphs, and trains a GN to label the nodes and edges on the shortest path between any two nodes. Over a sequence of message-passing steps (as depicted by each step's plot), the model refines its prediction of the shortest path.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<h2>Sort demo: tinyurl.com/gn-sort-demo</h2>
<p>This demo creates lists of random numbers, and trains a GN to sort the list. After a sequence of message-passing steps, the model makes an accurate prediction of which elements (columns in the figure) come next after each other (rows).
<img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Physics demo: tinyurl.com/gn-physics-demo
This demo creates random mass-spring physical systems, and trains a GN to predict the state of the system on the next timestep. The model's next-step predictions can be fed back in as input to create a rollout of a future trajectory. Each subplot below shows the true and predicted mass-spring system states over 50 timesteps. This is similar to the model and experiments in (Battaglia et al., 2016)'s "interaction networks".
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ Note, an ordering can be imposed by encoding the indices in the node or edge attributes, or via the edges themselves (e.g. by encoding a chain or partial ordering).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>