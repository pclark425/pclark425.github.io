<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7138 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7138</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7138</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-134.html">extraction-schema-134</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-bf4810017b54e50354cccffd8966121c7166cb17</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/bf4810017b54e50354cccffd8966121c7166cb17" target="_blank">Iterative Translation Refinement with Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> European Association for Machine Translation Conferences/Workshops</p>
                <p><strong>Paper TL;DR:</strong> It is proposed iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language capability as well as a human-like translation approach, to suggest comparable or improved quality after two or more iterations.</p>
                <p><strong>Paper Abstract:</strong> We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language capability as well as a human-like translation approach. Interestingly, multi-turn querying reduces the output’s string-based metric scores, but neural metrics suggest comparable or improved quality after two or more iterations. Human evaluations indicate better fluency and naturalness compared to initial translations and even human references, all while maintaining quality. Ablation studies underscore the importance of anchoring the refinement to the source and a reasonable seed translation for quality considerations. We also discuss the challenges in evaluation and relation to human performance and translationese.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7138.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7138.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Iterative Refinement (Refine)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative Translation Refinement (Refine prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generate-then-reflect procedure where an LLM is prompted with the source sentence and the previous translation to produce an improved translation; the process is repeated for multiple rounds and the best iteration is selected by COMET_QE.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source autoregressive large language model from OpenAI, accessed via API; version used had training data up to Sep 2021 and was queried zero-shot with task prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Iterative Refinement (Refine)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>At each round the model is given the source and the previous translation and asked (zero-shot) to produce a better translation; the newly produced translation becomes the input for the next round. No explanatory text is requested from the model to encourage clean outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>4</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>WMT21/WMT22 news translation test sets (various language pairs)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Machine translation on WMT test sets across multiple language directions (en<->de, en<->zh, de->fr, en->ja, uk->cs), evaluated on held-out official test samples.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU, chrF++, COMET_DA (reference-based neural), COMET_QE (reference-free neural)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Example (from Table 3): Translate (de target row): BLEU 36.25, chrF++ 59.50, COMET_DA 0.8395, COMET_QE 0.0807 (seed GPT translation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Example (from Table 3): Refine: BLEU 32.47, chrF++ 55.83, COMET_DA 0.8353, COMET_QE 0.0851 (after iterative refinement; best iteration chosen by COMET_QE).</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Refinement often causes large drops in string-based metrics (BLEU, chrF++), while neural COMET metrics remain comparable or improve — demonstrating divergent signals across metrics. The method requires a reasonable seed translation (Refine_Random performs worse and never reaches Refine levels). Iterations were run up to four times due to API cost; best results often required >1 iteration but the optimal number varies by example and is selected by COMET_QE. Human evaluation shows improved fluency/naturalness, but automated reference-based metrics can penalize lexical/structural variation. Additional practical limitations: high API cost for multi-round querying, potential for semantic drift if the source is not provided, and sensitivity to prompt wording (anchoring to source is important).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Iterative Translation Refinement with Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7138.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7138.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Refine_Contrast</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Contrastive Iterative Refinement (Refine_Contrast prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of iterative refinement where the previous translation is prefaced as a 'bad translation' to steer the LLM toward producing a better alternative; used as an ablation to test effect of framing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source OpenAI LLM queried zero-shot with prompts; same access/setup as other experiments in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Contrastive Iterative Refinement (Refine_Contrast)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Same iterative generate-then-reflect loop but the prompt labels the previous translation explicitly as 'Bad translation:' to bias the model toward correcting it; repeated over multiple rounds with the source provided each time.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (contrast framing)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>4</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>WMT21/WMT22 news translation test sets (various language pairs)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same WMT translation test sets and language directions as the main Refine experiments; used for ablation comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU, chrF++, COMET_DA, COMET_QE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Example (from Table 3): Translate (en target row): BLEU 23.00, chrF++ 25.89, COMET_DA 0.8863, COMET_QE 0.1255.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Example (from Table 3): Refine_Contrast: BLEU 22.82, chrF++ 26.71, COMET_DA 0.8928, COMET_QE 0.1282 (first-round Refine_Contrast comparisons showed human-preferred fluency in many directions).</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Similar BLEU/chrF++ drops as Refine. Paper reports Refine_Contrast sometimes surpasses Refine in automatic scores, and human evaluation often prefers Refine_Contrast for fluency; however, framing as 'bad translation' is a heuristic and may be unstable. No evidence that contrast framing eliminates need for a reasonable seed; outcomes depend on language direction and seed quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Iterative Translation Refinement with Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7138.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7138.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Refine_Random</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random-seed Iterative Refinement (Refine_Random prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ablation where the first refinement iteration is fed a random (non-related) target sentence labeled as a 'bad translation' to simulate starting from a genuinely poor translation, then subsequent rounds continue as in Refine.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source OpenAI LLM used zero-shot; same API setup as other experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Random-seed Iterative Refinement (Refine_Random)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Iterative refinement where the initial 'previous translation' is a random unrelated sentence (marked as 'bad translation') to probe whether the model can recover from a poor starting point over multiple rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (random initial seed ablation)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>4</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>WMT21/WMT22 news translation test sets (various language pairs)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same WMT translation tasks; used as an ablation to test sensitivity to seed translation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU, chrF++, COMET_DA, COMET_QE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Initial (random-seed) performance starts low by design (not comparable to Translate seed).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Paper reports Refine_Random scores start low and gradually improve across iterations but generally do not reach the performance of Refine or Refine_Contrast that start from a reasonable seed translation.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Refine_Random fails to reach Refine performance: shows that iterative refinement depends strongly on a reasonable seed translation; random initialization leads to worse results and incomplete recovery within 4 iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Iterative Translation Refinement with Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7138.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7138.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Paraphrase (no source anchor)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Paraphrase Iteration (Paraphrase prompt without source)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ablation where the model is asked to paraphrase the previous translation (no source provided) across iterations, used to test the importance of anchoring to the source to avoid semantic drift.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source OpenAI LLM used zero-shot prompting; same access as other experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Iterative Paraphrase (no source anchor)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>At each round the model is asked to paraphrase the previous translation without being shown the source sentence, producing successive rephrasings (pure target-side re-generation).</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (paraphrase chain; no source)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>4</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>WMT21/WMT22 news translation test sets (various language pairs)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same WMT translation tasks; used as an ablation to test semantic drift when the source is omitted.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU, chrF++, COMET_DA, COMET_QE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Example (from Table 3): Translate (de row): BLEU 36.25, chrF++ 59.50, COMET_DA 0.8395, COMET_QE 0.0807.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Example (from Table 3): Paraphrase: BLEU 16.06, chrF++ 44.28, COMET_DA 0.7937, COMET_QE 0.0682 (scores decrease monotonically across iterations, indicating semantic drift).</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paraphrasing without the source causes monotonic score decline across both string and neural metrics, demonstrating semantic drift and loss of fidelity to source meaning. This ablation highlights the necessity of anchoring iterative edits to the source to maintain translation adequacy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Iterative Translation Refinement with Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Leveraging GPT-4 for automatic translation post-editing <em>(Rating: 2)</em></li>
                <li>Prompting PaLM for translation: Assessing strategies and performance <em>(Rating: 2)</em></li>
                <li>APE at scale and its implications on MT evaluation biases <em>(Rating: 2)</em></li>
                <li>Do GPTs produce less literal translations? <em>(Rating: 1)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7138",
    "paper_id": "paper-bf4810017b54e50354cccffd8966121c7166cb17",
    "extraction_schema_id": "extraction-schema-134",
    "extracted_data": [
        {
            "name_short": "Iterative Refinement (Refine)",
            "name_full": "Iterative Translation Refinement (Refine prompt)",
            "brief_description": "A generate-then-reflect procedure where an LLM is prompted with the source sentence and the previous translation to produce an improved translation; the process is repeated for multiple rounds and the best iteration is selected by COMET_QE.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo)",
            "model_description": "Closed-source autoregressive large language model from OpenAI, accessed via API; version used had training data up to Sep 2021 and was queried zero-shot with task prompts.",
            "model_size": null,
            "reflection_method_name": "Iterative Refinement (Refine)",
            "reflection_method_description": "At each round the model is given the source and the previous translation and asked (zero-shot) to produce a better translation; the newly produced translation becomes the input for the next round. No explanatory text is requested from the model to encourage clean outputs.",
            "iteration_type": "generate-then-reflect",
            "num_iterations": 4,
            "task_name": "WMT21/WMT22 news translation test sets (various language pairs)",
            "task_description": "Machine translation on WMT test sets across multiple language directions (en&lt;-&gt;de, en&lt;-&gt;zh, de-&gt;fr, en-&gt;ja, uk-&gt;cs), evaluated on held-out official test samples.",
            "evaluation_metric": "BLEU, chrF++, COMET_DA (reference-based neural), COMET_QE (reference-free neural)",
            "performance_before_reflection": "Example (from Table 3): Translate (de target row): BLEU 36.25, chrF++ 59.50, COMET_DA 0.8395, COMET_QE 0.0807 (seed GPT translation).",
            "performance_after_reflection": "Example (from Table 3): Refine: BLEU 32.47, chrF++ 55.83, COMET_DA 0.8353, COMET_QE 0.0851 (after iterative refinement; best iteration chosen by COMET_QE).",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Refinement often causes large drops in string-based metrics (BLEU, chrF++), while neural COMET metrics remain comparable or improve — demonstrating divergent signals across metrics. The method requires a reasonable seed translation (Refine_Random performs worse and never reaches Refine levels). Iterations were run up to four times due to API cost; best results often required &gt;1 iteration but the optimal number varies by example and is selected by COMET_QE. Human evaluation shows improved fluency/naturalness, but automated reference-based metrics can penalize lexical/structural variation. Additional practical limitations: high API cost for multi-round querying, potential for semantic drift if the source is not provided, and sensitivity to prompt wording (anchoring to source is important).",
            "uuid": "e7138.0",
            "source_info": {
                "paper_title": "Iterative Translation Refinement with Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Refine_Contrast",
            "name_full": "Contrastive Iterative Refinement (Refine_Contrast prompt)",
            "brief_description": "A variant of iterative refinement where the previous translation is prefaced as a 'bad translation' to steer the LLM toward producing a better alternative; used as an ablation to test effect of framing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo)",
            "model_description": "Closed-source OpenAI LLM queried zero-shot with prompts; same access/setup as other experiments in the paper.",
            "model_size": null,
            "reflection_method_name": "Contrastive Iterative Refinement (Refine_Contrast)",
            "reflection_method_description": "Same iterative generate-then-reflect loop but the prompt labels the previous translation explicitly as 'Bad translation:' to bias the model toward correcting it; repeated over multiple rounds with the source provided each time.",
            "iteration_type": "generate-then-reflect (contrast framing)",
            "num_iterations": 4,
            "task_name": "WMT21/WMT22 news translation test sets (various language pairs)",
            "task_description": "Same WMT translation test sets and language directions as the main Refine experiments; used for ablation comparisons.",
            "evaluation_metric": "BLEU, chrF++, COMET_DA, COMET_QE",
            "performance_before_reflection": "Example (from Table 3): Translate (en target row): BLEU 23.00, chrF++ 25.89, COMET_DA 0.8863, COMET_QE 0.1255.",
            "performance_after_reflection": "Example (from Table 3): Refine_Contrast: BLEU 22.82, chrF++ 26.71, COMET_DA 0.8928, COMET_QE 0.1282 (first-round Refine_Contrast comparisons showed human-preferred fluency in many directions).",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Similar BLEU/chrF++ drops as Refine. Paper reports Refine_Contrast sometimes surpasses Refine in automatic scores, and human evaluation often prefers Refine_Contrast for fluency; however, framing as 'bad translation' is a heuristic and may be unstable. No evidence that contrast framing eliminates need for a reasonable seed; outcomes depend on language direction and seed quality.",
            "uuid": "e7138.1",
            "source_info": {
                "paper_title": "Iterative Translation Refinement with Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Refine_Random",
            "name_full": "Random-seed Iterative Refinement (Refine_Random prompt)",
            "brief_description": "An ablation where the first refinement iteration is fed a random (non-related) target sentence labeled as a 'bad translation' to simulate starting from a genuinely poor translation, then subsequent rounds continue as in Refine.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo)",
            "model_description": "Closed-source OpenAI LLM used zero-shot; same API setup as other experiments.",
            "model_size": null,
            "reflection_method_name": "Random-seed Iterative Refinement (Refine_Random)",
            "reflection_method_description": "Iterative refinement where the initial 'previous translation' is a random unrelated sentence (marked as 'bad translation') to probe whether the model can recover from a poor starting point over multiple rounds.",
            "iteration_type": "generate-then-reflect (random initial seed ablation)",
            "num_iterations": 4,
            "task_name": "WMT21/WMT22 news translation test sets (various language pairs)",
            "task_description": "Same WMT translation tasks; used as an ablation to test sensitivity to seed translation quality.",
            "evaluation_metric": "BLEU, chrF++, COMET_DA, COMET_QE",
            "performance_before_reflection": "Initial (random-seed) performance starts low by design (not comparable to Translate seed).",
            "performance_after_reflection": "Paper reports Refine_Random scores start low and gradually improve across iterations but generally do not reach the performance of Refine or Refine_Contrast that start from a reasonable seed translation.",
            "improvement_observed": false,
            "limitations_or_failure_cases": "Refine_Random fails to reach Refine performance: shows that iterative refinement depends strongly on a reasonable seed translation; random initialization leads to worse results and incomplete recovery within 4 iterations.",
            "uuid": "e7138.2",
            "source_info": {
                "paper_title": "Iterative Translation Refinement with Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Paraphrase (no source anchor)",
            "name_full": "Paraphrase Iteration (Paraphrase prompt without source)",
            "brief_description": "An ablation where the model is asked to paraphrase the previous translation (no source provided) across iterations, used to test the importance of anchoring to the source to avoid semantic drift.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo)",
            "model_description": "Closed-source OpenAI LLM used zero-shot prompting; same access as other experiments.",
            "model_size": null,
            "reflection_method_name": "Iterative Paraphrase (no source anchor)",
            "reflection_method_description": "At each round the model is asked to paraphrase the previous translation without being shown the source sentence, producing successive rephrasings (pure target-side re-generation).",
            "iteration_type": "generate-then-reflect (paraphrase chain; no source)",
            "num_iterations": 4,
            "task_name": "WMT21/WMT22 news translation test sets (various language pairs)",
            "task_description": "Same WMT translation tasks; used as an ablation to test semantic drift when the source is omitted.",
            "evaluation_metric": "BLEU, chrF++, COMET_DA, COMET_QE",
            "performance_before_reflection": "Example (from Table 3): Translate (de row): BLEU 36.25, chrF++ 59.50, COMET_DA 0.8395, COMET_QE 0.0807.",
            "performance_after_reflection": "Example (from Table 3): Paraphrase: BLEU 16.06, chrF++ 44.28, COMET_DA 0.7937, COMET_QE 0.0682 (scores decrease monotonically across iterations, indicating semantic drift).",
            "improvement_observed": false,
            "limitations_or_failure_cases": "Paraphrasing without the source causes monotonic score decline across both string and neural metrics, demonstrating semantic drift and loss of fidelity to source meaning. This ablation highlights the necessity of anchoring iterative edits to the source to maintain translation adequacy.",
            "uuid": "e7138.3",
            "source_info": {
                "paper_title": "Iterative Translation Refinement with Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Leveraging GPT-4 for automatic translation post-editing",
            "rating": 2
        },
        {
            "paper_title": "Prompting PaLM for translation: Assessing strategies and performance",
            "rating": 2
        },
        {
            "paper_title": "APE at scale and its implications on MT evaluation biases",
            "rating": 2
        },
        {
            "paper_title": "Do GPTs produce less literal translations?",
            "rating": 1
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 1
        }
    ],
    "cost": 0.01175725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Iterative Translation Refinement with Large Language Models</h1>
<p>Pinzhen Chen ${ }^{1}$ Zhicheng Guo ${ }^{2}$ Barry Haddow ${ }^{1}$ Kenneth Heafield ${ }^{1}$<br>${ }^{1}$ School of Informatics, University of Edinburgh<br>${ }^{2}$ Dept. of Comp. Sci. \&amp; Tech., Institute for AI, Tsinghua University<br>{pinzhen.chen, bhaddow, kenneth.heafield}@ed.ac.uk<br>guo-zc21@mails.tsinghua.edu.cn</p>
<h4>Abstract</h4>
<p>We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language capability as well as a human-like translation approach. Interestingly, multi-turn querying reduces the output's string-based metric scores, but neural metrics suggest comparable or improved quality after two or more iterations. Human evaluations indicate better fluency and naturalness compared to initial translations and even human references, all while maintaining quality. Ablation studies underscore the importance of anchoring the refinement to the source and a reasonable seed translation for quality considerations. We also discuss the challenges in evaluation and relation to human performance and translationese.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs), e.g. generative pretrained Transformers (GPT), have made notable advancements in natural language processing (Radford et al., 2019; Brown et al., 2020; Kaplan et al., 2020; Ouyang et al., 2022). In machine translation (MT), where the convention is to use an encoderdecoder architecture to deal with source and target sentences respectively (Bahdanau et al., 2015; Vaswani et al., 2017), recent papers have examined the feasibility of LLM prompting for translation (Vilar et al., 2023; Zhang et al., 2023; Hendy et al., 2023; Agrawal et al., 2023).</p>
<p>With autoregressive decoding being the convention, machine translation models yield output in</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>a single attempt, and so do post-editing models. Rather, a human translator can read and edit translations repeatedly, or even pass the outcome to another translator for a second opinion. We explore such an iterative refinement process with LLMs, where the proposed method simply feeds a sourcetranslation pair into an LLM for an improved translation in multiple rounds. It is worth noting that this method can be applied to an initial translation from any model, not just LLM outputs. We further conduct a qualitative evaluation of the outputs. Our approach offers two insights from a fluency and naturalness perspective: 1) LLMs are pre-trained on natural texts that are orders of magnitude larger than traditional MT data, and 2) the method does not require complicated prompt engineering, yet allows for iterative and arbitrary rephrasing compared to automatic post-editing, which is limited to token-level error correction without style editing (Ive et al., 2020).</p>
<p>Empirical results show that the refinement procedure introduces significant textual changes reflected by the drop in BLEU and chrF++, but attains similar or higher COMET scores compared to initial translations. Native speakers prefer refined outputs in terms of fluency and naturalness when compared with GPT translations and even human references. Reference-based human evaluation confirms that such gains are made without sacrificing general quality. As corroborated by recent works, automatic metrics like BLEU and COMET are witnessed to move in opposite directions (Freitag et al., 2019; Freitag et al., 2022). Our human-like LLM prompting method contributes to translation naturalness which can enhance utility as perceived by the target language users. On a broader scope, this work touches on the concept of involving LLMs in a collaborative translation editing strategy.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Mode</th>
<th style="text-align: center;">Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">Source: \${source} <br> Please give me a translation in \${lang} without any explanation.</td>
</tr>
<tr>
<td style="text-align: center;">Refine</td>
<td style="text-align: center;">Source: \${source} <br> Translation: \${prev.translation} <br> Please give me a better \${lang} translation without any explanation.</td>
</tr>
<tr>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">Source: \${source} <br> Bad translation: \${prev.translation} <br> Please give me a better \${lang} translation without any explanation.</td>
</tr>
<tr>
<td style="text-align: center;">Refine $_{\text {Random }}$</td>
<td style="text-align: center;">Source: \${source} <br> Bad translation: \${random.target} if first-round, else \${prev.translation} <br> Please give me a better \${lang} translation without any explanation.</td>
</tr>
<tr>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">Sentence: \${prev.translation} <br> Please give me a paraphrase in \${lang} without any explanation.</td>
</tr>
</tbody>
</table>
<p>Table 1: Prompts used in our work, where a \${variable} is substituted with its corresponding content.</p>
<h2>2 Methodology</h2>
<p>Having an input source sentence $x$ and an optimizable model $\theta_{m t}$, the process to obtain a translation $y$ can be modelled as $y=\operatorname{argmax}<em m="m" t="t">{y} P\left(y \mid x ; \theta</em>}\right)$. Next, an automatic post-editor $\theta_{\text {ape }}$ creates a refined translation $y^{\prime}$ through modelling $y^{\prime}=$ $\operatorname{argmax<em _ape="{ape" _text="\text">{y^{\prime}} P\left(y^{\prime} \mid x, y ; \theta</em>\right)$ data pairs.}}\right)$. Conventional translation or automatic post-editing models are trained on $(x, y)$ or $\left(x, y, y^{\prime</p>
<p>Extending prior work on LLM prompting, our study uses zero-shot prompting by affixing a task description to form a prompt $p$ and querying an LLM $\theta_{L L M}$ to elicit a response (Brown et al., 2020). We introduce five prompts in our study:</p>
<ol>
<li>Translate: it queries for a translation of a source input, extending the translation process with a prompt $p: \quad y=$ $\operatorname{argmax}<em L="L" M="M">{y} P\left(y \mid p, x ; \theta</em>\right)$. This is vanilla LLM prompting for MT.</li>
<li>Refine: similar to post-editing, the LLM is given the source sentence and the previous translation to produce a better translation $y^{\prime}=$ $\operatorname{argmax}<em L="L" M="M">{y^{\prime}} P\left(y^{\prime} \mid p, x, y ; \theta</em>\right)$.</li>
<li>Refine $_{\text {Contrast }}$ : as a contrasting prompt to the above, we insert the word "bad" to hint that the previously translated text is unwanted, regardless of its actual quality.</li>
<li>Refine $<em _Contrast="{Contrast" _text="\text">{\text {Random }}$ : same prompt as Refine $</em>$, but in the first iteration, a random sentence is fed instead of a translation to imitate a genuinely "bad translation".}</li>
<li>Paraphrase: a contrasting experiment to translation prompting, we ask an LLM to rephrase a translation without feeding the source sentence $x: y^{\prime \prime}=\operatorname{argmax}<em L="L" M="M">{y^{\prime \prime}} P\left(y^{\prime \prime} \mid p, y ; \theta</em>\right)$.</li>
</ol>
<p>We propose to iteratively call the refinement prompts, where the source stays the same but the previous translation is updated each turn. To encourage a parsable model response, we ask the LLM to not give any explanation. Such prompting does not require model parameters $\theta_{L L M}$ to be accessible. Through ablation prompts, Refine $_{\text {Random }}$ and Paraphrase, we analyse to what degree the source input and seed translations are helpful. The exact prompt texts are displayed in Table 1.</p>
<h2>3 Experiments</h2>
<h3>3.1 Data and model details</h3>
<p>We select language pairs from the news and general domain translation tasks hosted at WMT 2021 and 2022 (Farhad et al., 2021; Kocmi et al., 2022), which are supported by COMET to obtain reliable scores. In total, we tested seven translation directions: English $\leftrightarrow$ German (en $\rightarrow$ de, de $\rightarrow$ en), English $\leftrightarrow$ Chinese (en $\rightarrow$ zh, zh $\rightarrow$ en), German $\rightarrow$ French (de $\rightarrow$ fr), English $\rightarrow$ Japanese (en $\rightarrow$ ja), and Ukrainian $\rightarrow$ Czech (uk $\rightarrow$ cs). We directly benchmark on the test sets, and in situations where multiple references are available, we use human reference "A" released by the WMT organizers as our reference.</p>
<p>We experiment with GPT-3.5, a powerful closedsource model from OpenAI that can be accessed by all users. ${ }^{1}$ As the API call tends to be slow, we randomly sample 200 instances from the official test set to form our in-house test. In the refinement and paraphrase experiments, we use the response from</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the LLM Translate query as the seed translation to be improved upon. We do not keep the query (multi-turn) history so as to prevent an LLM from seeing that the previous translation is produced by itself. In experiments later on, we also tested with translations from encoder-decoder systems that participated in WMT, human references, and online systems. Overall, translation refinement is iterated four times at maximum considering the API costs.</p>
<h3>3.2 Evaluation setup</h3>
<p>We consider four automatic metrics: string-based BLEU (Papineni et al., 2002) and chrF++ (Popović, 2017) as well as embedding-based $\operatorname{COMET}<em _mathrm_QE="\mathrm{QE">{\mathrm{DA}}$ and COMET $</em>}}$ (Rei et al., 2020). The difference between the DA and QE versions is that COMET ${ <em _mathrm_QE="\mathrm{QE">{\mathrm{DA}}$ requires a source, a translation, and a reference, whereas $\operatorname{COMET}</em>$}}$ is reference-free. BLEU and chrF++ are as implemented in the sacrebleu toolkit. ${ }^{2}$ We also use this toolkit to obtain test sets with references as well as past WMT systems' outputs. Specifically for tokenization in BLEU calculation, we use "zh" for Chinese, "ja-mecab" for Japanese, and " 13 a " for the rest. The BLEU and chrF++ signatures are footnoted. ${ }^{3,4}$ For COMET metrics, we used the official implementation released by the authors. ${ }^{5</p>
<h3>3.3 Refinement results</h3>
<p>WMT21 We first experiment with en $\leftrightarrow$ de and en $\leftrightarrow \mathrm{zh}$ from WMT21, which are high-resource languages in terms of both translation data and LLM training data. We run all five prompts and display results in Table 2. For iterative refinement and paraphrasing experiments, the best iteration is picked according to $\operatorname{COMET}<em _mathrm_DA="\mathrm{DA">{\mathrm{QE}}$. We observe that the refined translations record a drastic drop in string-based metrics compared to initial translations, indicating lexical and structural variations. In terms of $\operatorname{COMET}</em>$, the refinement strategy ends as the highest with substantial improvement for intoEnglish directions. As a contrasting experiment, Paraphrase sees a decline in all metrics, suggesting the importance of feeding the source input as an anchor during iterations to prevent semantic drift.}}$, refined outputs surpass initial GPT translations in three out of four cases, and in terms of $\operatorname{COMET}_{\mathrm{QE}</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Table 2: Automatic scores of different strategies with GPT on high-resource pairs from WMT 2021 news translation.</p>
<p>WMT22 Moving to lower-resourced languages with non-English translation, we gather numbers for three translation directions from WMT22 in Table 3. Since Refine $<em _mathrm_QE="\mathrm{QE">{\text {Random }}$ results are not desirable for WMT21, we omit experiments with this. The overall pattern remains the same as before: Refine works best, obtaining higher $\operatorname{COMET}</em>$. Also, the reduction in string-based scores becomes less obvious, which might be attributed to seed GPT translations in lesser-resourced languages being lower in quality in the beginning.}}$ than vanilla translations and Refine $_{\text {Contrast }</p>
<p>Online systems, encoder-decoder systems, and human translations In addition to translation refinement from GPT-3.5 itself, we also apply our refinement calls to outputs from conventional MT systems and human translators. These translations can represent genuine errors, if any, introduced during the translation process. Out of the seven WMT21 submissions, we select outputs from four models built by research labs that, based on human evaluation, have been ranked at significantly different positions on the German-to-English leaderboard: Tencent (Wang et al., 2021), Facebook AI (Tran et al., 2021), Edinburgh (Chen et al., 2021),</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">chrF++ COMET $<em _QE="{QE" _text="\text">{\text {DA }}$ COMET $</em>$}</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">de</td>
<td style="text-align: center;">Reference</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">.0772</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">36.25</td>
<td style="text-align: center;">59.50</td>
<td style="text-align: center;">.8395</td>
<td style="text-align: center;">.0807</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine</td>
<td style="text-align: center;">32.47</td>
<td style="text-align: center;">55.83</td>
<td style="text-align: center;">.8353</td>
<td style="text-align: center;">.0851</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">33.12</td>
<td style="text-align: center;">56.37</td>
<td style="text-align: center;">.8308</td>
<td style="text-align: center;">.0805</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">16.06</td>
<td style="text-align: center;">44.28</td>
<td style="text-align: center;">.7937</td>
<td style="text-align: center;">.0682</td>
</tr>
<tr>
<td style="text-align: center;">en</td>
<td style="text-align: center;">Reference</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">.1345</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">23.00</td>
<td style="text-align: center;">25.89</td>
<td style="text-align: center;">.8863</td>
<td style="text-align: center;">.1255</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine</td>
<td style="text-align: center;">22.63</td>
<td style="text-align: center;">27.30</td>
<td style="text-align: center;">.8941</td>
<td style="text-align: center;">.1305</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">22.82</td>
<td style="text-align: center;">26.71</td>
<td style="text-align: center;">.8928</td>
<td style="text-align: center;">.1282</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">17.69</td>
<td style="text-align: center;">23.18</td>
<td style="text-align: center;">.8592</td>
<td style="text-align: center;">.1086</td>
</tr>
<tr>
<td style="text-align: center;">uk</td>
<td style="text-align: center;">Reference</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">.1273</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">29.91</td>
<td style="text-align: center;">54.64</td>
<td style="text-align: center;">.9074</td>
<td style="text-align: center;">.1173</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine</td>
<td style="text-align: center;">28.60</td>
<td style="text-align: center;">53.06</td>
<td style="text-align: center;">.9040</td>
<td style="text-align: center;">.1183</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">28.90</td>
<td style="text-align: center;">54.29</td>
<td style="text-align: center;">.9036</td>
<td style="text-align: center;">.1151</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">13.59</td>
<td style="text-align: center;">40.04</td>
<td style="text-align: center;">.8625</td>
<td style="text-align: center;">.0969</td>
</tr>
</tbody>
</table>
<p>Table 3: Automatic scores of different strategies with GPT on low-resource and medium-resource pairs from WMT 2022 news translation.
and Huawei TSC (Wei et al., 2021). These are competitive systems built with data augmentation, multilingualism, ensembling, re-ranking, etc. We then include two online engines used in WMT 2021: Online-A and Online-Y. Finally, human reference "B" is added so that we can experiment with our refinement strategy on human translations. ${ }^{6}$ References "A" and "B" are sourced from different translation agencies (Farhad et al., 2021).</p>
<p>We report automatic scores from the refinement process in Table 4. A pattern similar to previous GPT translation refinement is noticed: for five out of seven WMT entries, the refinement strategy reaches a higher $\mathrm{COMET}<em _Contrast="{Contrast" _text="\text">{\mathrm{QE}}$ score, surprisingly, with up to one-third drop in BLEU. Refine $</em>$ in all but one system surpass Refine, and without the initial translation, Paraphrase iterations record the lowest scores compared to the original submissions and refinements.}</p>
<h2>4 Human Evaluation</h2>
<p>String-based and neural scores are observed to vary in opposite directions, which may suggest volatile changes in texts. Since it is questionable to conclude a quality degradation in this case, we set up human evaluations to measure two characteristics in the refined translations: text naturalness and overall quality. Human evaluators involved in this study</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 4: Automatic scores of refining WMT 2021 news shared task German-to-English submissions.
are practitioners in the field of natural language processing but are unaware of the goal of this study.</p>
<h3>4.1 Fluency and naturalness</h3>
<p>We mimic the human evaluation of fluency in (Lembersky et al., 2012, p819). Native speakers of the target language are with two translations but without the source sentence; then we ask "Please choose the translation that is more fluent, natural, and reflecting better use of \${language}", where \${language} is substituted with the target language name. The evaluator has three options: they can select one of the two translations, or a "tie" if they consider both equally (un)natural. We conduct such pairwise evaluation to compare the first-round output from Refine $_{\text {Contrast }}$ against human references, as well as against Translate separately.</p>
<p>We evaluate 50 samples from en $\leftrightarrow$ de and en $\leftrightarrow \mathrm{zh}$ experiments in Section 3.3, and report in Figure 1 (left). Native speakers prefer Refine $_{\text {Contrast }}$ to vanilla Translate in all four directions, and even favour</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 1: Human preferences on fluency and naturalness (source-free, left) and overall quality (source-based, right).</p>
<p>Refine $_{\text {Contrast }}$ over human references when translating into English. It demonstrates that our simple strategy enhances the naturalness of GPT outputs and that WMT human references could be less favourable than GPT outputs in some cases.</p>
<h3>4.2 Overall quality</h3>
<p>We also evaluate for general quality as a safeguard. In this setup, a source sentence and two translations are given to an evaluator who is fluent in both languages. They are asked to pick the translation with better quality or indicate a tie. We only evaluated two translation directions, English to and from Chinese, due to the limited availability of bilingual speakers. Similar to the previous evaluation, we compare Refine $<em _Contrast="{Contrast" _text="\text">{\text {Contrast }}$ against human references, as well as Refine $</em>$ against Translate separately.}</p>
<p>We report evaluator preferences in Figure 1 (right). It shows that GPT Refine attains slightly better performance in $\mathrm{zh} \rightarrow$ en and similar performance in en $\rightarrow \mathrm{zh}$ when compared with human references. On the other hand, it is more favourable than GPT Translate in terms of human judgements. Combining evaluation outcomes, we conclude that the refinement strategy could improve the target-side naturalness without undermining general quality.</p>
<h2>5 Analysis and Discussions</h2>
<h3>5.1 Performance through iterations</h3>
<p>To investigate the behaviour of refinement strategies through different iterations, we plot BLEU, $\mathrm{COMET}<em _mathrm_QE="\mathrm{QE">{\mathrm{DA}}$, and $\mathrm{COMET}</em>$ However, in almost all Paraphrase}}$ at different iterations in Figure 2 for four translation directions: en $\leftrightarrow$ de and en $\leftrightarrow \mathrm{zh}$. We find that Refine and Refine $_{\text {Contrast }}$ usually attain their best after undergoing more than one refinement iteration, showing superiority to one-off editing. ${ }^{7</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>experiments, scores decrease monotonically, indicating that semantics drift away as paraphrasing iterates. Moreover, Refine $<em _Contrast="{Contrast" _text="\text">{\text {Random }}$ results start low, gradually catch up, but never reach as high as Refine or Refine $</em>$. This means that iterative refinement is indeed useful in fixing translations, but starting with a reasonable translation is also crucial for obtaining a strong result.}</p>
<h3>5.2 Diverging automatic scores</h3>
<p>According to automatic string-based metrics, our queries deliver lower-quality translations through iterations, but $\mathrm{COMET}<em _mathrm_QE="\mathrm{QE">{\mathrm{DA}}$ scores remain comparable and $\mathrm{COMET}</em>$ scores mostly increase. We argue that the string-based metrics might not accurately indicate quality, but rather reflect text variations with respect to the reference. We further verified this via human evaluation that fluency and overall quality are not impacted.}</p>
<p>In Table 5 we show outputs from different strategies for a single source input, where a native speaker marked preference for Refine $_{\text {Contrast }}$. It illustrates that the word choice is diverse for both directions and specifically for Chinese $\rightarrow$ English, there are substantial structural changes. The huge variety in expressions across translations can result in low BLEU with respect to human references, but without much change in meaning, for instance, as in Table 2 where BLEU can decline up to one-third, but neural metric scores change little. In the field of MT, a leap in BLEU is usually associated with performance improvement; however, in our case, a drop cannot be simply interpreted as performance degradation. This can be attributed to the lexical and structural diversity in the refined translations.</p>
<h3>5.3 Human performance</h3>
<p>A human translator is deemed to be fluent in their native language, which intuitively is difficult for a model to compete with. In our human evalua-</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 2: BLEU, $\mathrm{COMET}<em _mathrm_QE="\mathrm{QE">{\mathrm{DA}}$, and $\mathrm{COMET}</em>$ at different refinement and paraphrase iterations for high-resource translation.
tion, GPT fluency can be as good or even better than reference translations-we offer two possible explanations. First, the WMT references might have been created by translators with varying expertise, which may not represent upper-bound human performance, especially when compared with advanced LLMs. More importantly, translations can exhibit awkwardness in word and syntax choices, potentially due to source language interference or "shining through" (Gellerstam, 1986; Teich, 2003).}</p>
<h3>5.4 Relation to translationese</h3>
<p>Both human and machine translations might be more explicit, language-normalized, and simpler (Baker, 1996; Koppel and Ordan, 2011). On a broader scope, translationese is regarded as the distinct features in translations to include influences from both the source and target sides. Although</p>
<p>MT normally learns from human translation data, researchers found that human and machine translation patterns do not fully overlap (Bizzoni et al., 2020). While translationese occurs in translations inevitably, consumers could prefer translations that are more natural in their native language, provided that the semantics and utility are preserved.</p>
<p>From a narrow aspect, our method relates to machine translationese mitigation in terms of reducing unnaturalness and literalness, instead of focusing on state-of-the-art metric scores. It may be viable to create diverse translations through iterations, as we observe huge changes in BLEU scores. Measuring these using automatic metrics at the moment is challenging, especially given that most translation metrics are reference-based, where the reference can be translationese-prone in the first place. $\mathrm{COMET}_{\mathrm{QE}}$ might be more robust to this end.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Source</th>
<th style="text-align: center;">Der 17-Jährige floh zunächst vom Tatort, seine Personalien konnten aber im Nachhinein ermittelt werden.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Reference</td>
<td style="text-align: center;">The 17 year-old proceeded to flee the crime scene, however, his personal details could be retrieved later.</td>
</tr>
<tr>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">The 17-year-old initially fled from the crime scene, but his personal information was later determined.</td>
</tr>
<tr>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">The 17-year-old initially fled from the scene of the crime, but his personal details could later be identified.</td>
</tr>
<tr>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">At first, the 17-year-old ran away from where the crime occurred, but eventually, the authorities were able to identify him by his personal details.</td>
</tr>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">酬法令规定，坎帕尼亚大区自即日起室内公共场所必须戴口罩，违者最高可处以 1000 欧元罚金。</td>
</tr>
<tr>
<td style="text-align: center;">Reference</td>
<td style="text-align: center;">According to a new decree, people must wear masks in indoor public places in Campania from now on, and offenders can be fined up to 1,000 euros.</td>
</tr>
<tr>
<td style="text-align: center;">Translate</td>
<td style="text-align: center;">A new regulation stipulates that in Campania, indoor public places must wear masks. Violators can be fined up to 1000 euros.</td>
</tr>
<tr>
<td style="text-align: center;">Refine $_{\text {Contrast }}$</td>
<td style="text-align: center;">A new regulation states that in the Campania region, masks must be worn in indoor public places, with a maximum fine of 1000 euros for those who violate the rule.</td>
</tr>
<tr>
<td style="text-align: center;">Paraphrase</td>
<td style="text-align: center;">A new rule in Campania requires people to wear masks in indoor public places, and those who don't follow this rule may be charged up to 1000 euros.</td>
</tr>
</tbody>
</table>
<p>Table 5: German $\rightarrow$ English and Chinese $\rightarrow$ English examples showing rich lexical variations across translation strategies.</p>
<h2>6 Related Work</h2>
<h3>6.1 Translation post-editing</h3>
<p>Closely related to our refinement prompting is automatic post-editing (APE), which trains a neural network to fix translation errors by learning from human correction data, that can be traced back to as early as (Knight and Chander, 1994). While it has shown advancements in statistical machine translation, it has been suspected to be less effective in the deep learning era due to original translations being high-quality and lack of post-editing data (Junczys-Dowmunt and Grundkiewicz, 2018; Chatterjee et al., 2018). Whilst one way to facilitate this is more data provision (Chollampatt et al., 2020; Ive et al., 2020), our workaround utilizes a large language model, which possesses the post-editing capability without the need for specific training or fine-tuning. Furthermore, post-editing models might have limited power to alleviate awkwardness, because human editing data is collected from annotators who are usually instructed to not make style improvements (Ive et al., 2020). Compared to APE, our method allows LLMs to re-generate an entirely different translation, which could escape the "post-editese" phenomenon, where Toral (2019) demonstrated that human-edited machine translations still exhibit translationese features.</p>
<p>Some post-editing models do not rely on the source translation or human editing data (Simard et al., 2007). For instance, Freitag et al. (2019) trained a post-editor solely on monolingual data by reconstructing the original text given its round-trip translation. In our work, we incorporate stronger natural language modelling into post-editing by employing LLMs. Other translation refinement research includes combining statistical and neural systems
(Novak et al., 2016; Niehues et al., 2016), merging APE into the NMT framework (Pal et al., 2020; Chen et al., 2022), and debiasing translationese in the latent embedding space (Dutta Chowdhury et al., 2022). The iterative editing mechanism mostly lies in non-autoregressive translation, where each output token is independent of other target positions and iterative decoding enhances output quality (Lee et al., 2018; Gu et al., 2019; Xu and Carpuat, 2021).</p>
<h3>6.2 Translation prompting with large language models</h3>
<p>Large language models have recently become highly effective tools for various NLP tasks (Radford et al., 2019; Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022). Nowadays, optimising LLMs directly for specific tasks becomes less important since they generalize to downstream tasks even without explicit supervision. With more parameters and training data, LLMs may offer stronger performance than dedicated translation or post-editing models. The method we use to elicit a response from GPT is zero-shot prompting (Brown et al., 2020), which means affixing a description to the original task input to form a query to the model. Researchers have benchmarked LLMs' capability to translate (Vilar et al., 2023; Zhang et al., 2023; Jiao et al., 2023; Hendy et al., 2023), and to interpret translation quality (Kocmi and Federmann, 2023; Lu et al., 2023; Xu et al., 2023).</p>
<p>Among the recent papers on LLM translation prompting, we identify the following to be most relevant to us. Previous findings show that GPT produces less literal translations, especially for out-ofEnglish translations (Raunak et al., 2023a), which to some extent stands in contrast with our later human evaluation results on naturalness and fluency.</p>
<p>Raunak et al. (2023b) formalized post-editing as a chain-of-thought process (Wei et al., 2022) with GPT-4 and achieved promising results. Different from their focus, our work features the iterative refinement process as a means to enhance naturalness and fluency. Our work reveals that iterated refinement is better than one-off editing. The observed improvement, especially for into-English, may be attributed to the abundant English pre-training data available for LLMs. To the best of our knowledge, although the concept of iterative refinement is not new, ours is the pioneering paper in applying such strategies to LLMs for translation.</p>
<h2>7 Conclusion and Future Work</h2>
<p>We presented a simple way to leverage an LLM for translation refinement, which greatly helps fluency and naturalness. It is shown that our method maintains translation quality and introduces lexical and structural changes, especially for high-resource into-English translation. We have also discussed the potential of using our work to obtain diverse, fluent translations that are less translationese, as well as the limitation in automatic metrics to measure this.</p>
<p>On a broader note, this work connects to the concept of using LLMs to imitate collaborative translation refinement. Yet, it is important to acknowledge the high cost of running a multi-round LLM refinement. Future work can explore sentence-level refinement decisions to reduce cost.</p>
<h2>Acknowledgement</h2>
<p>We express our gratitude to the reviewers of this paper for their detailed and invaluable feedback and suggestions. The work also benefited from discussions with Nikolay Bogoychev and Biao Zhang. We are grateful to Laurie Burchell, Ziqin Fang, Matthias Lindemann, and Jonas Waldendorf for their participation in the human evaluation.</p>
<p>This work is funded by UK Research and Innovation (UKRI) under the UK government's Horizon Europe funding guarantee [grant number 10052546].</p>
<h2>References</h2>
<p>Agrawal, Sweta, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan Ghazvininejad. 2023. Incontext examples selection for machine translation. In Findings of the Association for Computational Linguistics: ACL 2023.</p>
<p>Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations.</p>
<p>Baker, Mona, 1996. Corpus-based Translation Studies: The Challenges that Lie Ahead. Benjamins Translation Library. John Benjamins Publishing Company.</p>
<p>Bizzoni, Yuri, Tom S Juzek, Cristina España-Bonet, Koel Dutta Chowdhury, Josef van Genabith, and Elke Teich. 2020. How human is machine translationese? comparing human and machine translations of text and speech. In Proceedings of the 17th International Conference on Spoken Language Translation.</p>
<p>Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems.</p>
<p>Chatterjee, Rajen, Matteo Negri, Raphael Rubino, and Marco Turchi. 2018. Findings of the WMT 2018 shared task on automatic post-editing. In Proceedings of the Third Conference on Machine Translation.</p>
<p>Chen, Pinzhen, Jindřich Helcl, Ulrich Germann, Laurie Burchell, Nikolay Bogoychev, Antonio Valerio Miceli Barone, Jonas Waldendorf, Alexandra Birch, and Kenneth Heafield. 2021. The University of Edinburgh's English-German and English-Hausa submissions to the WMT21 news translation task. In Proceedings of the Sixth Conference on Machine Translation.</p>
<p>Chen, Kehai, Masao Utiyama, Eiichiro Sumita, Rui Wang, and Min Zhang. 2022. Synchronous refinement for neural machine translation. In Findings of the Association for Computational Linguistics: ACL 2022.</p>
<p>Chollampatt, Shamil, Raymond Hendy Susanto, Liling Tan, and Ewa Szymanska. 2020. Can automatic post-editing improve NMT? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.</p>
<p>Chowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. PaLM: Scaling language modeling with pathways. arXiv preprint.</p>
<p>Dutta Chowdhury, Koel, Rricha Jalota, Cristina EspañaBonet, and Josef Genabith. 2022. Towards debiasing translation artifacts. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</p>
<p>Farhad, Akhbardeh, Arkhangorodsky Arkady, Biesialska Magdalena, Bojar Ondřej, Chatterjee Rajen, Chaudhary Vishrav, Marta R Costa-jussa, EspañaBonet Cristina, Fan Angela, Federmann Christian,</p>
<p>et al. 2021. Findings of the 2021 conference on machine translation (WMT21). In Proceedings of the Sixth Conference on Machine Translation.</p>
<p>Freitag, Markus, Isaac Caswell, and Scott Roy. 2019. APE at scale and its implications on MT evaluation biases. In Proceedings of the Fourth Conference on Machine Translation.</p>
<p>Freitag, Markus, Ricardo Rei, Nitika Mathur, Chikiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022. Results of WMT22 metrics shared task: Stop using BLEU - neural metrics are better and more robust. In Proceedings of the Seventh Conference on Machine Translation.</p>
<p>Gellerstam, Martin. 1986. Translationese in Swedish novels translated from English. In Translation studies in Scandinavia: Proceedings from the Scandinavian Symposium on Translation Theory II. CWK Gleerup.</p>
<p>Gu, Jiatao, Changhan Wang, and Junbo Zhao. 2019. Levenshtein transformer. In Advances in Neural Information Processing Systems.</p>
<p>Hendy, Amr, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023. How good are GPT models at machine translation? a comprehensive evaluation. arXiv preprint.</p>
<p>Ive, Julia, Lucia Specia, Sara Szoc, Tom Vanallemeersch, Joachim Van den Bogaert, Eduardo Farah, Christine Maroti, Artur Ventura, and Maxim Khalilov. 2020. A post-editing dataset in the legal domain: Do we underestimate neural machine translation quality? In Proceedings of the Twelfth Language Resources and Evaluation Conference.</p>
<p>Jiao, Wenxiang, Wenxuan Wang, Jen tse Huang, Xing Wang, and Zhaopeng Tu. 2023. Is ChatGPT a good translator? Yes with GPT-4 as the engine. arXiv preprint.</p>
<p>Junczys-Dowmunt, Marcin and Roman Grundkiewicz. 2018. MS-UEdin submission to the WMT2018 APE shared task: Dual-source transformer for automatic post-editing. In Proceedings of the Third Conference on Machine Translation.</p>
<p>Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint.</p>
<p>Knight, Kevin and Ishwar Chander. 1994. Automated postediting of documents. In Proceedings of the Twelfth AAAI National Conference on Artificial Intelligence.</p>
<p>Kocmi, Tom and Christian Federmann. 2023. Large language models are state-of-the-art evaluators of translation quality. arXiv preprint.</p>
<p>Kocmi, Tom, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Thamme Gowda, Yvette Graham, Roman Grundkiewicz, Barry Haddow, et al. 2022. Findings of the 2022 conference on machine translation (WMT22). In Proceedings of the Seventh Conference on Machine Translation.</p>
<p>Koppel, Moshe and Noam Ordan. 2011. Translationese and its dialects. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.</p>
<p>Lee, Jason, Elman Mansimov, and Kyunghyun Cho. 2018. Deterministic non-autoregressive neural sequence modeling by iterative refinement. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.</p>
<p>Lembersky, Gennadi, Noam Ordan, and Shuly Wintner. 2012. Language Models for Machine Translation: Original vs. Translated Texts . Computational Linguistics.</p>
<p>Lu, Qingyu, Baopu Qiu, Liang Ding, Liping Xie, and Dacheng Tao. 2023. Error analysis prompting enables human-like translation evaluation in large language models: A case study on ChatGPT. arXiv preprint.</p>
<p>Niehues, Jan, Eunah Cho, Thanh-Le Ha, and Alex Waibel. 2016. Pre-translation for neural machine translation. In Proceedings of the 26th International Conference on Computational Linguistics.</p>
<p>Novak, Roman, Michael Auli, and David Grangier. 2016. Iterative refinement for machine translation. arXiv preprint.</p>
<p>Ouyang, Long, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems.</p>
<p>Pal, Santanu, Hongfei Xu, Nico Herbig, Sudip Kumar Naskar, Antonio Krüger, and Josef van Genabith. 2020. The transference architecture for automatic post-editing. In Proceedings of the 28th International Conference on Computational Linguistics.</p>
<p>Papineni, Kishore, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</p>
<p>Popović, Maja. 2017. chrF++: words helping character n-grams. In Proceedings of the Second Conference on Machine Translation.</p>
<p>Radford, Alec, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. openai.com.</p>
<p>Raunak, Vikas, Arul Menezes, Matt Post, and Hany Hassan. 2023a. Do GPTs produce less literal translations? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics.</p>
<p>Raunak, Vikas, Amr Sharaf, Hany Hassan Awadallah, and Arul Menezes. 2023b. Leveraging GPT-4 for automatic translation post-editing. arXiv preprint.</p>
<p>Rei, Ricardo, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020. COMET: A neural framework for MT evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.</p>
<p>Simard, Michel, Cyril Goutte, and Pierre Isabelle. 2007. Statistical phrase-based post-editing. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics.</p>
<p>Teich, Elke. 2003. Cross-Linguistic Variation in System and Text: A Methodology for the Investigation of Translations and Comparable Texts. De Gruyter Mouton.</p>
<p>Toral, Antonio. 2019. Post-editese: An exacerbated translationese. In Proceedings of Machine Translation Summit XVII.</p>
<p>Tran, Chau, Shruti Bhosale, James Cross, Philipp Koehn, Sergey Edunov, and Angela Fan. 2021. Facebook AI's WMT21 news translation task submission. In Proceedings of the Sixth Conference on Machine Translation.</p>
<p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems.</p>
<p>Vilar, David, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and George Foster. 2023. Prompting PaLM for translation: Assessing strategies and performance. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics.</p>
<p>Wang, Longyue, Mu Li, Fangxu Liu, Shuming Shi, Zhaopeng Tu, Xing Wang, Shuangzhi Wu, Jiali Zeng, and Wen Zhang. 2021. Tencent translation system for the WMT21 news translation task. In Proceedings of the Sixth Conference on Machine Translation.</p>
<p>Wei, Daimeng, Zongyao Li, Zhanglin Wu, Zhengzhe Yu, Xiaoyu Chen, Hengchao Shang, Jiaxin Guo, Minghan Wang, Lizhi Lei, Min Zhang, et al. 2021. HWTSC's participation in the WMT 2021 news translation shared task. In Proceedings of the Sixth Conference on Machine Translation.</p>
<p>Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems.</p>
<p>Xu, Weijia and Marine Carpuat. 2021. EDITOR: An edit-based transformer with repositioning for neural machine translation with soft lexical constraints. Transactions of the Association for Computational Linguistics.</p>
<p>Xu, Wenda, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag, William Yang Wang, and Lei Li. 2023. INSTRUCTSCORE: Towards explainable text generation evaluation with automatic feedback. arXiv preprint.</p>
<p>Zhang, Biao, Barry Haddow, and Alexandra Birch. 2023. Prompting large language model for machine translation: A case study. In Proceedings of the 40th International Conference on Machine Learning.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{7}$ The first iteration is equivalent to a one-off translation editing using an LLM.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>