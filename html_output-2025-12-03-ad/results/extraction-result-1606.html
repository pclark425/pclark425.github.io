<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1606 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1606</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1606</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-270703113</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.15976v1.pdf" target="_blank">Effective Adaptive Mutation Rates for Program Synthesis</a></p>
                <p><strong>Paper Abstract:</strong> The problem-solving performance of many evolutionary algorithms, including genetic programming systems used for program synthesis, depends on the values of hyperparameters including mutation rates. The mutation method used to produce some of the best results to date on software synthesis benchmark problems, Uniform Mutation by Addition and Deletion (UMAD), adds new genes into a genome at a predetermined rate and then deletes genes at a rate that balances the addition rate, producing no size change on average. While UMAD with a predetermined addition rate outperforms many other mutation and crossover schemes, we do not expect a single rate to be optimal across all problems or all generations within one run of an evolutionary system. However, many current adaptive mutation schemes such as self-adaptive mutation rates suffer from pathologies like the vanishing mutation rate problem, in which the mutation rate quickly decays to zero. We propose an adaptive bandit-based scheme that addresses this problem and essentially removes the need to specify a mutation rate. Although the proposed scheme itself introduces hyperparameters, we either set these to good values or ensemble them in a reasonable range. Results on software synthesis and symbolic regression problems validate the effectiveness of our approach.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1606.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1606.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PushGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Push Genetic Programming (PushGP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A linear-genome genetic programming system that evolves Push programs (a stack-based, Turing-complete language) to solve software synthesis and symbolic regression problems, evaluated by test cases and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PushGP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PushGP evolves populations of linear genomes encoding Push programs. Individuals are executed on test inputs; outputs are compared against target outputs to compute errors. Variation operators (mutation and historically crossover) produce offspring; selection (here lexicase selection) determines survivors. The paper uses PushGP as the substrate for program synthesis and symbolic regression experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>PushGP in this work is used with variant mutation operators (UMAD described below). The paper does not apply a specific crossover operator in its reported experiments; it focuses on mutation-only variation (UMAD). Mutation changes linear genomes that encode Push instructions/constants and code-block delimiters.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Program correctness/executability assessed by: (1) per-test-case errors aggregated via a symmetrical log scale-transformed error f(x)=sgn(x)*log(c+|x|) and averaged across cases; (2) immediate reward r = avg_i log(1+e_parent_i) - avg_i log(1+e_child_i) capturing fitness improvement; (3) success/solution counts (number of runs that found a program passing all training cases and meeting success criteria) reported as counts out of 50 runs; (4) best log-error in the population tracked across generations.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>The paper reports per-problem success counts (number of successful runs out of 50) and best-log-error traces (see Tables 2 and 3 and Figures 3–4). Summary: fixed UMAD (ρ=0.1) often attains the highest success rates on many benchmarks, the bandit adaptive UMAD frequently outperforms SAMR and GESMR baselines, and the bandit controller avoids vanishing mutation rates leading to better long-term search on rugged domains. (Exact per-problem counts are provided in Tables 2 and 3 of the paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>program synthesis (PSB1/PSB2 benchmarks), symbolic regression, and function minimization experiments</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Fixed UMAD (ρ=0.1), SAMR (self-adaptive mutation rates), GESMR (group/coevolutionary mutation-rate adaptation from Kumar et al.), LAMR-100 (oracle lookahead over mutation rates).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PushGP with UMAD mutation is a strong baseline for program synthesis. In this paper PushGP is used to demonstrate that adaptive control of the UMAD mutation rate (via a bandit + tile-coding controller) can avoid pathologies of SAMR (vanishing rates) and can match or exceed other adaptive schemes on many problems, particularly on rugged search landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1606.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Uniform Mutation by Addition and Deletion (UMAD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variable-length genome mutation operator that first inserts new genes at a specified addition rate and then deletes genes at a balancing deletion rate to be size-neutral on expectation, enabling flexible structural changes to linear genomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Program synthesis using uniform mutation by addition and deletion</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Uniform Mutation by Addition and Deletion (UMAD)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>UMAD decouples replacement into addition and deletion: during the addition step, for each locus the operator inserts a number of new instructions based on a per-locus addition rate ρ (the paper generalizes fractional insertion using probabilistic floor/ceil of ρ); during the deletion step it removes instructions at a rate chosen so the expected genome length is preserved (deletion probability = ρ / (1+ρ) in the size-neutral formulation). The UMAD rate ρ is the tunable parameter controlling mutation 'strength'.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Adds new genes (Push instructions/constants) to a linear genome with rate ρ via probabilistic insertion counts (⌊ρ⌋ with prob fractional part, else ⌊ρ⌋+1), then deletes genes from the augmented genome at the balancing deletion rate so expected length equals original. As ρ→0 small local edits; larger ρ yields larger structural edits, with extreme values approaching effectively random-replacement behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Same evaluation as PushGP: error on test cases (log-transformed), immediate reward as decrease in average log-error from parent to child, and solution/success counts (runs passing all training cases).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>UMAD with ρ=0.1 is cited as a strong baseline that outperforms or equals many other mutation/crossover combinations on PushGP software-synthesis benchmarks; reported success counts for fixed UMAD appear in Tables 2 and 3 (per-problem counts out of 50).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Paper discusses that larger UMAD rates are beneficial earlier (to explore new solution ideas) and smaller UMAD rates are beneficial later (careful refinement), implying a tradeoff between novelty (larger structural edits) and executability/stability (smaller edits) over evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>program synthesis, symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against other mutation/crossover schemes in prior work and used as the mutation operator optimized by adaptive controllers in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>UMAD provides more expressive mutation than simple replacement and performs strongly as a baseline; but a fixed ρ is suboptimal across problems and generations, motivating adaptive control. Larger ρ tends to produce rarer but larger-benefit mutations (helpful early), while small ρ helps late-stage refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1606.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bandit-Tile UMAD Controller</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Armed Bandit + Tile-Coding Adaptive UMAD Rate Controller (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive controller that uses ensemble multi-armed bandits with tile-coding value function approximation and an extreme-value (max-over-window) reward to select UMAD mutation rates dynamically during GP runs, designed to avoid vanishing mutation rates and exploit the continuous mutation-rate domain.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bandit + Tile-Coding Adaptive UMAD Controller</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The controller represents the log-UMAD rate continuous domain with multiple randomized tile codings. Rewards are immediate reductions in average log-transformed error from parent to child; the controller tracks the maximum reward over a sliding window (_h, set to 100) for each region. It uses an epsilon-greedy bandit policy (with Gaussian sampling noise around best tiles) and SGD updates with momentum on tile values; multiple bandit instances (ensemble) with randomized learning rates are maintained and all are updated with observed rewards.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Does not change the UMAD operator itself (mutation remains UMAD); it adaptively samples a UMAD addition rate ρ from a learned distribution (sampled via bandit/tile coding over log-ρ) and applies UMAD to selected parents to produce children.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Not an explicit novelty/creativity metric; instead optimizes 'expected maximum reward' (the expected maximum decrease in average log-error over _h sampled mutations) — an extreme-value statistic designed to prefer mutation rates that occasionally produce large beneficial innovations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td>The paper demonstrates via analysis (Figure 2) that immediate expected reward favors tiny mutation rates (leading to vanishing rates), whereas the max-over-window metric prefers larger rates early in runs; quantitative novelty/diversity numbers are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Immediate reward r = mean_i[log(1+e_parent_i)] - mean_i[log(1+e_child_i)]; tracked max over last _h samples per UMAD-rate region; also final success counts (number of successful runs out of 50) and best-log-error traces used to assess solution-finding performance.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Controller produces improved solution rates relative to SAMR and GESMR in many program-synthesis and symbolic-regression problems (see Tables 2–3); avoids vanishing mutation-rate pathology and adapts ρ over time (Figures 3–4). Exact per-problem counts and learning curves are provided in the paper's tables/figures.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Yes — central to the design: the controller uses max-over-window reward to prefer mutation rates that produce rare large improvements (novelty) while later shifting to lower rates for refinement (executability). Empirically, larger rates are favored early when best solutions are poor; smaller rates become favored as evolution proceeds (Figure 2).</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>function minimization, program synthesis (PSB1/PSB2), symbolic regression (Nguyen benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to Fixed UMAD (ρ=0.1), SAMR, GESMR, and LAMR-100 (in function-minimization experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The bandit+tile-coding controller: (1) leverages the continuous mutation-rate domain to get good sample complexity and precision, (2) optimizes an extreme-value statistic (max reward over a window) to avoid vanishing mutation rates, (3) often outperforms self-adaptive (SAMR) and coevolutionary (GESMR) mutation-rate schemes on rugged problems, and (4) sometimes is outperformed by a well-chosen fixed UMAD on particular problems — indicating per-problem sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1606.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Adaptive Mutation Rates (SAMR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-adaptive scheme where mutation rates are encoded with individuals and co-evolved: each individual carries its own mutation rate which is used to mutate its genome and itself is mutated by a meta-mutation operator.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-adaptation in genetic algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Self-Adaptive Mutation Rates (SAMR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>In SAMR each individual is associated with a mutation-rate gene; during variation the genome is mutated according to that individual's rate and the mutation-rate gene is itself altered by a meta-mutation operator (e.g., log-normal or multiplicative mutation). Selection acts on individuals (and their rates) together.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Mutation rate gene is mutated by a meta-mutation (e.g., multiplicative noise); the individual's genome is mutated using the decoded rate (in this paper, SAMR was a baseline applied to UMAD rates attached per-individual).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Same fitness/error measures via log-transformed error and success counts used to compare methods.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>SAMR frequently suffers from the 'vanishing mutation rate' problem on rugged GP domains, where rates decay toward zero and cause premature convergence; the paper reports lower solution rates for SAMR than the bandit controller on many benchmarks (see Tables 2–3 and Figures 3–4).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>Implicitly discussed: SAMR's short-term optimization tends to reduce mutation rates (favoring short-term execution stability) at the expense of long-term exploratory novelty; paper cites this as a pathology leading to premature convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Used as a baseline on program synthesis and symbolic regression experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared vs fixed UMAD, bandit controller, GESMR, LAMR-100.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>SAMR is elegant and biologically inspired but tends to reduce mutation rates prematurely on difficult/rugged landscapes, leading to poorer long-term search performance; limiting ranges or adding offsets can mitigate but do not fully solve pathology.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1606.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GESMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Group/Co-evolved Elite Selection Mutation-Rate Adaptation (GESMR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive mutation-rate scheme (from Kumar et al.) that co-evolves a meta-population of mutation rates alongside the main population and evaluates rates by assigning them to groups and measuring the maximum parent-to-child fitness improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Effective mutation rate adaptation through group elite selection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GESMR (coevolutionary mutation-rate adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GESMR maintains a meta-population of mutation rates; at each generation each mutation rate is assigned to a group of selected parents and used to produce children. The fitness of a mutation rate is computed as the best parent→child improvement in the group (a max-based credit), and evolutionary operators evolve the rates. This exploits the continuous nature of mutation strength via meta-evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs, continuous vectors (function minimization)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Mutation rates in the meta-population are evolved (e.g., multiplicative mutations like multiplying by 2^{U[-1,1]}); children in the main population are produced using the assigned mutation rates (e.g., Gaussian or other mutation operators depending on domain).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Rate fitness measured as maximum improvement (best parent→child) within groups of sampled individuals; main-system executability measured via problem-specific fitness/success counts.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>GESMR outperforms SAMR on some rugged continuous optimization problems by using max-based credit assignment; in this paper GESMR outperforms SAMR on many function-minimization problems but is outperformed by the bandit controller on several rugged domains due to the bandit's longer-scope optimization (the bandit used _h=100 vs GESMR's group size ~10).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>GESMR's local max-based credit tends to select higher mutation rates when they produce occasional large improvements but can get stuck in uninformative high-mutation regions (especially in symbolic regression) — noted in the paper as an empirical pathology.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Function minimization experiments (continuous landscapes) and symbolic regression comparisons as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against SAMR, bandit controller, LAMR-100.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GESMR's max-value credit assignment mitigates vanishing-rate issues relative to SAMR and performs well on rugged continuous domains, but can suffer from getting stuck in high-mutation uninformative regions in some domains; the bandit controller with a larger max-window can outperform GESMR by optimizing a longer-term statistic.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1606.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LAMR-100</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Look-Ahead Mutation-Rate Oracle (LAMR-100)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An oracle-like baseline which periodically 'looks ahead' over a set of mutation rates by running short trials and selecting the mutation rate that yields best future performance (here: lookahead 100 generations).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LAMR-100 (look-ahead mutation-rate oracle)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LAMR-100 searches over a preset log-spaced range of mutation rates (here 10^{-3} to 10^0) and, every 100 generations, evaluates each candidate rate by simulating its effect for 100 generations (or via lookahead) and selects the one with best projected performance. It is an expensive oracle used as an upper-bound baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>continuous vectors (function minimization)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Applies standard mutation operators with the chosen candidate rates during lookahead simulations; the scheme itself is a hyperparameter search/oracle rather than a new mutation operator.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Optimizes future performance over a long horizon (100 generations lookahead) and is evaluated by final fitness in function-minimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>LAMR-100 attains the best performance on some rugged continuous problems (Ackley, Rastrigin) because it optimizes over a long horizon, but is limited by its preset search range (10^{-3} to 10^0) and high computational cost; in domains requiring larger mutation rates it underperforms.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Function minimization (continuous test functions)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Serves as an oracle baseline compared to bandit controller, GESMR, SAMR.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>As an oracle with long lookahead, LAMR-100 can achieve top performance on some rugged problems but is computationally expensive and constrained by its candidate-rate search interval; it highlights the benefit of long-horizon optimization of mutation rate but is impractical as a general controller.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1606.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1606.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Lexicase</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lexicase Selection (and epsilon-lexicase)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A case-wise selection method that filters candidate parents through random orderings of training cases, favoring specialists that perform well on subsets of cases rather than aggregating fitness; used here as the selection operator in GP.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Lexicase Selection of Specialists</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Lexicase Selection</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Lexicase selection considers test cases individually in random order and filters the candidate pool to those that are elite on the current case; survivors are then filtered by subsequent cases, resulting in selection of individuals that excel on some cases (specialists). The epsilon variant allows a tolerance to consider near-elite performers.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Selection influences which individuals are chosen as parents; lexicase's operational effect is to preserve behavioral specialists and encourage diverse partial solutions. The paper uses lexicase selection to generate parents for mutation and to compute transformed error vectors case-wise.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Lexicase selection is stated as beneficial for program synthesis tasks and is used in all experiments, contributing to preservation of diverse specialists; quantitative effect on executability is shown indirectly via improved solution-finding when paired with UMAD and adaptive controllers.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td>Implicitly supports behavioral diversity by selecting specialists across different cases (behavioral diversity emphasis).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Program synthesis and symbolic regression experiments in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as the standard selection operator; not compared against other selection operators in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Lexicase selection is a core part of the evaluation pipeline; it supports maintaining specialists which, combined with max-reward mutation-rate adaptation, helps find rare beneficial mutations and avoids being dominated by aggregated fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective Adaptive Mutation Rates for Program Synthesis', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Program synthesis using uniform mutation by addition and deletion <em>(Rating: 2)</em></li>
                <li>Effective mutation rate adaptation through group elite selection <em>(Rating: 2)</em></li>
                <li>Extreme Value Based Adaptive Operator Selection <em>(Rating: 2)</em></li>
                <li>Self-adaptation in genetic algorithms <em>(Rating: 1)</em></li>
                <li>PSB2: the second program synthesis benchmark suite <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1606",
    "paper_id": "paper-270703113",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "PushGP",
            "name_full": "Push Genetic Programming (PushGP)",
            "brief_description": "A linear-genome genetic programming system that evolves Push programs (a stack-based, Turing-complete language) to solve software synthesis and symbolic regression problems, evaluated by test cases and generalization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "PushGP",
            "system_description": "PushGP evolves populations of linear genomes encoding Push programs. Individuals are executed on test inputs; outputs are compared against target outputs to compute errors. Variation operators (mutation and historically crossover) produce offspring; selection (here lexicase selection) determines survivors. The paper uses PushGP as the substrate for program synthesis and symbolic regression experiments.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "PushGP in this work is used with variant mutation operators (UMAD described below). The paper does not apply a specific crossover operator in its reported experiments; it focuses on mutation-only variation (UMAD). Mutation changes linear genomes that encode Push instructions/constants and code-block delimiters.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Program correctness/executability assessed by: (1) per-test-case errors aggregated via a symmetrical log scale-transformed error f(x)=sgn(x)*log(c+|x|) and averaged across cases; (2) immediate reward r = avg_i log(1+e_parent_i) - avg_i log(1+e_child_i) capturing fitness improvement; (3) success/solution counts (number of runs that found a program passing all training cases and meeting success criteria) reported as counts out of 50 runs; (4) best log-error in the population tracked across generations.",
            "executability_results": "The paper reports per-problem success counts (number of successful runs out of 50) and best-log-error traces (see Tables 2 and 3 and Figures 3–4). Summary: fixed UMAD (ρ=0.1) often attains the highest success rates on many benchmarks, the bandit adaptive UMAD frequently outperforms SAMR and GESMR baselines, and the bandit controller avoids vanishing mutation rates leading to better long-term search on rugged domains. (Exact per-problem counts are provided in Tables 2 and 3 of the paper.)",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "program synthesis (PSB1/PSB2 benchmarks), symbolic regression, and function minimization experiments",
            "comparison_baseline": "Fixed UMAD (ρ=0.1), SAMR (self-adaptive mutation rates), GESMR (group/coevolutionary mutation-rate adaptation from Kumar et al.), LAMR-100 (oracle lookahead over mutation rates).",
            "key_findings": "PushGP with UMAD mutation is a strong baseline for program synthesis. In this paper PushGP is used to demonstrate that adaptive control of the UMAD mutation rate (via a bandit + tile-coding controller) can avoid pathologies of SAMR (vanishing rates) and can match or exceed other adaptive schemes on many problems, particularly on rugged search landscapes.",
            "uuid": "e1606.0",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "UMAD",
            "name_full": "Uniform Mutation by Addition and Deletion (UMAD)",
            "brief_description": "A variable-length genome mutation operator that first inserts new genes at a specified addition rate and then deletes genes at a balancing deletion rate to be size-neutral on expectation, enabling flexible structural changes to linear genomes.",
            "citation_title": "Program synthesis using uniform mutation by addition and deletion",
            "mention_or_use": "use",
            "system_name": "Uniform Mutation by Addition and Deletion (UMAD)",
            "system_description": "UMAD decouples replacement into addition and deletion: during the addition step, for each locus the operator inserts a number of new instructions based on a per-locus addition rate ρ (the paper generalizes fractional insertion using probabilistic floor/ceil of ρ); during the deletion step it removes instructions at a rate chosen so the expected genome length is preserved (deletion probability = ρ / (1+ρ) in the size-neutral formulation). The UMAD rate ρ is the tunable parameter controlling mutation 'strength'.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "Adds new genes (Push instructions/constants) to a linear genome with rate ρ via probabilistic insertion counts (⌊ρ⌋ with prob fractional part, else ⌊ρ⌋+1), then deletes genes from the augmented genome at the balancing deletion rate so expected length equals original. As ρ→0 small local edits; larger ρ yields larger structural edits, with extreme values approaching effectively random-replacement behavior.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Same evaluation as PushGP: error on test cases (log-transformed), immediate reward as decrease in average log-error from parent to child, and solution/success counts (runs passing all training cases).",
            "executability_results": "UMAD with ρ=0.1 is cited as a strong baseline that outperforms or equals many other mutation/crossover combinations on PushGP software-synthesis benchmarks; reported success counts for fixed UMAD appear in Tables 2 and 3 (per-problem counts out of 50).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Paper discusses that larger UMAD rates are beneficial earlier (to explore new solution ideas) and smaller UMAD rates are beneficial later (careful refinement), implying a tradeoff between novelty (larger structural edits) and executability/stability (smaller edits) over evolution.",
            "frontier_characterization": null,
            "benchmark_or_domain": "program synthesis, symbolic regression",
            "comparison_baseline": "Compared against other mutation/crossover schemes in prior work and used as the mutation operator optimized by adaptive controllers in this paper.",
            "key_findings": "UMAD provides more expressive mutation than simple replacement and performs strongly as a baseline; but a fixed ρ is suboptimal across problems and generations, motivating adaptive control. Larger ρ tends to produce rarer but larger-benefit mutations (helpful early), while small ρ helps late-stage refinement.",
            "uuid": "e1606.1",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Bandit-Tile UMAD Controller",
            "name_full": "Multi-Armed Bandit + Tile-Coding Adaptive UMAD Rate Controller (this paper)",
            "brief_description": "An adaptive controller that uses ensemble multi-armed bandits with tile-coding value function approximation and an extreme-value (max-over-window) reward to select UMAD mutation rates dynamically during GP runs, designed to avoid vanishing mutation rates and exploit the continuous mutation-rate domain.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Bandit + Tile-Coding Adaptive UMAD Controller",
            "system_description": "The controller represents the log-UMAD rate continuous domain with multiple randomized tile codings. Rewards are immediate reductions in average log-transformed error from parent to child; the controller tracks the maximum reward over a sliding window (_h, set to 100) for each region. It uses an epsilon-greedy bandit policy (with Gaussian sampling noise around best tiles) and SGD updates with momentum on tile values; multiple bandit instances (ensemble) with randomized learning rates are maintained and all are updated with observed rewards.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "Does not change the UMAD operator itself (mutation remains UMAD); it adaptively samples a UMAD addition rate ρ from a learned distribution (sampled via bandit/tile coding over log-ρ) and applies UMAD to selected parents to produce children.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": "Not an explicit novelty/creativity metric; instead optimizes 'expected maximum reward' (the expected maximum decrease in average log-error over _h sampled mutations) — an extreme-value statistic designed to prefer mutation rates that occasionally produce large beneficial innovations.",
            "novelty_results": "The paper demonstrates via analysis (Figure 2) that immediate expected reward favors tiny mutation rates (leading to vanishing rates), whereas the max-over-window metric prefers larger rates early in runs; quantitative novelty/diversity numbers are not reported.",
            "executability_metric": "Immediate reward r = mean_i[log(1+e_parent_i)] - mean_i[log(1+e_child_i)]; tracked max over last _h samples per UMAD-rate region; also final success counts (number of successful runs out of 50) and best-log-error traces used to assess solution-finding performance.",
            "executability_results": "Controller produces improved solution rates relative to SAMR and GESMR in many program-synthesis and symbolic-regression problems (see Tables 2–3); avoids vanishing mutation-rate pathology and adapts ρ over time (Figures 3–4). Exact per-problem counts and learning curves are provided in the paper's tables/figures.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Yes — central to the design: the controller uses max-over-window reward to prefer mutation rates that produce rare large improvements (novelty) while later shifting to lower rates for refinement (executability). Empirically, larger rates are favored early when best solutions are poor; smaller rates become favored as evolution proceeds (Figure 2).",
            "frontier_characterization": null,
            "benchmark_or_domain": "function minimization, program synthesis (PSB1/PSB2), symbolic regression (Nguyen benchmarks)",
            "comparison_baseline": "Compared to Fixed UMAD (ρ=0.1), SAMR, GESMR, and LAMR-100 (in function-minimization experiments).",
            "key_findings": "The bandit+tile-coding controller: (1) leverages the continuous mutation-rate domain to get good sample complexity and precision, (2) optimizes an extreme-value statistic (max reward over a window) to avoid vanishing mutation rates, (3) often outperforms self-adaptive (SAMR) and coevolutionary (GESMR) mutation-rate schemes on rugged problems, and (4) sometimes is outperformed by a well-chosen fixed UMAD on particular problems — indicating per-problem sensitivity.",
            "uuid": "e1606.2",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SAMR",
            "name_full": "Self-Adaptive Mutation Rates (SAMR)",
            "brief_description": "A self-adaptive scheme where mutation rates are encoded with individuals and co-evolved: each individual carries its own mutation rate which is used to mutate its genome and itself is mutated by a meta-mutation operator.",
            "citation_title": "Self-adaptation in genetic algorithms",
            "mention_or_use": "use",
            "system_name": "Self-Adaptive Mutation Rates (SAMR)",
            "system_description": "In SAMR each individual is associated with a mutation-rate gene; during variation the genome is mutated according to that individual's rate and the mutation-rate gene is itself altered by a meta-mutation operator (e.g., log-normal or multiplicative mutation). Selection acts on individuals (and their rates) together.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": "Mutation rate gene is mutated by a meta-mutation (e.g., multiplicative noise); the individual's genome is mutated using the decoded rate (in this paper, SAMR was a baseline applied to UMAD rates attached per-individual).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Same fitness/error measures via log-transformed error and success counts used to compare methods.",
            "executability_results": "SAMR frequently suffers from the 'vanishing mutation rate' problem on rugged GP domains, where rates decay toward zero and cause premature convergence; the paper reports lower solution rates for SAMR than the bandit controller on many benchmarks (see Tables 2–3 and Figures 3–4).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "Implicitly discussed: SAMR's short-term optimization tends to reduce mutation rates (favoring short-term execution stability) at the expense of long-term exploratory novelty; paper cites this as a pathology leading to premature convergence.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Used as a baseline on program synthesis and symbolic regression experiments.",
            "comparison_baseline": "Compared vs fixed UMAD, bandit controller, GESMR, LAMR-100.",
            "key_findings": "SAMR is elegant and biologically inspired but tends to reduce mutation rates prematurely on difficult/rugged landscapes, leading to poorer long-term search performance; limiting ranges or adding offsets can mitigate but do not fully solve pathology.",
            "uuid": "e1606.3",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GESMR",
            "name_full": "Group/Co-evolved Elite Selection Mutation-Rate Adaptation (GESMR)",
            "brief_description": "An adaptive mutation-rate scheme (from Kumar et al.) that co-evolves a meta-population of mutation rates alongside the main population and evaluates rates by assigning them to groups and measuring the maximum parent-to-child fitness improvement.",
            "citation_title": "Effective mutation rate adaptation through group elite selection",
            "mention_or_use": "use",
            "system_name": "GESMR (coevolutionary mutation-rate adaptation)",
            "system_description": "GESMR maintains a meta-population of mutation rates; at each generation each mutation rate is assigned to a group of selected parents and used to produce children. The fitness of a mutation rate is computed as the best parent→child improvement in the group (a max-based credit), and evolutionary operators evolve the rates. This exploits the continuous nature of mutation strength via meta-evolution.",
            "input_type": "programs, continuous vectors (function minimization)",
            "crossover_operation": null,
            "mutation_operation": "Mutation rates in the meta-population are evolved (e.g., multiplicative mutations like multiplying by 2^{U[-1,1]}); children in the main population are produced using the assigned mutation rates (e.g., Gaussian or other mutation operators depending on domain).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Rate fitness measured as maximum improvement (best parent→child) within groups of sampled individuals; main-system executability measured via problem-specific fitness/success counts.",
            "executability_results": "GESMR outperforms SAMR on some rugged continuous optimization problems by using max-based credit assignment; in this paper GESMR outperforms SAMR on many function-minimization problems but is outperformed by the bandit controller on several rugged domains due to the bandit's longer-scope optimization (the bandit used _h=100 vs GESMR's group size ~10).",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "GESMR's local max-based credit tends to select higher mutation rates when they produce occasional large improvements but can get stuck in uninformative high-mutation regions (especially in symbolic regression) — noted in the paper as an empirical pathology.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Function minimization experiments (continuous landscapes) and symbolic regression comparisons as a baseline.",
            "comparison_baseline": "Compared against SAMR, bandit controller, LAMR-100.",
            "key_findings": "GESMR's max-value credit assignment mitigates vanishing-rate issues relative to SAMR and performs well on rugged continuous domains, but can suffer from getting stuck in high-mutation uninformative regions in some domains; the bandit controller with a larger max-window can outperform GESMR by optimizing a longer-term statistic.",
            "uuid": "e1606.4",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LAMR-100",
            "name_full": "Look-Ahead Mutation-Rate Oracle (LAMR-100)",
            "brief_description": "An oracle-like baseline which periodically 'looks ahead' over a set of mutation rates by running short trials and selecting the mutation rate that yields best future performance (here: lookahead 100 generations).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "LAMR-100 (look-ahead mutation-rate oracle)",
            "system_description": "LAMR-100 searches over a preset log-spaced range of mutation rates (here 10^{-3} to 10^0) and, every 100 generations, evaluates each candidate rate by simulating its effect for 100 generations (or via lookahead) and selects the one with best projected performance. It is an expensive oracle used as an upper-bound baseline.",
            "input_type": "continuous vectors (function minimization)",
            "crossover_operation": null,
            "mutation_operation": "Applies standard mutation operators with the chosen candidate rates during lookahead simulations; the scheme itself is a hyperparameter search/oracle rather than a new mutation operator.",
            "uses_literature": false,
            "uses_code": null,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Optimizes future performance over a long horizon (100 generations lookahead) and is evaluated by final fitness in function-minimization tasks.",
            "executability_results": "LAMR-100 attains the best performance on some rugged continuous problems (Ackley, Rastrigin) because it optimizes over a long horizon, but is limited by its preset search range (10^{-3} to 10^0) and high computational cost; in domains requiring larger mutation rates it underperforms.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Function minimization (continuous test functions)",
            "comparison_baseline": "Serves as an oracle baseline compared to bandit controller, GESMR, SAMR.",
            "key_findings": "As an oracle with long lookahead, LAMR-100 can achieve top performance on some rugged problems but is computationally expensive and constrained by its candidate-rate search interval; it highlights the benefit of long-horizon optimization of mutation rate but is impractical as a general controller.",
            "uuid": "e1606.5",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Lexicase",
            "name_full": "Lexicase Selection (and epsilon-lexicase)",
            "brief_description": "A case-wise selection method that filters candidate parents through random orderings of training cases, favoring specialists that perform well on subsets of cases rather than aggregating fitness; used here as the selection operator in GP.",
            "citation_title": "Lexicase Selection of Specialists",
            "mention_or_use": "use",
            "system_name": "Lexicase Selection",
            "system_description": "Lexicase selection considers test cases individually in random order and filters the candidate pool to those that are elite on the current case; survivors are then filtered by subsequent cases, resulting in selection of individuals that excel on some cases (specialists). The epsilon variant allows a tolerance to consider near-elite performers.",
            "input_type": "programs",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Selection influences which individuals are chosen as parents; lexicase's operational effect is to preserve behavioral specialists and encourage diverse partial solutions. The paper uses lexicase selection to generate parents for mutation and to compute transformed error vectors case-wise.",
            "executability_results": "Lexicase selection is stated as beneficial for program synthesis tasks and is used in all experiments, contributing to preservation of diverse specialists; quantitative effect on executability is shown indirectly via improved solution-finding when paired with UMAD and adaptive controllers.",
            "diversity_metric": "Implicitly supports behavioral diversity by selecting specialists across different cases (behavioral diversity emphasis).",
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Program synthesis and symbolic regression experiments in the paper.",
            "comparison_baseline": "Used as the standard selection operator; not compared against other selection operators in this paper.",
            "key_findings": "Lexicase selection is a core part of the evaluation pipeline; it supports maintaining specialists which, combined with max-reward mutation-rate adaptation, helps find rare beneficial mutations and avoids being dominated by aggregated fitness.",
            "uuid": "e1606.6",
            "source_info": {
                "paper_title": "Effective Adaptive Mutation Rates for Program Synthesis",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Program synthesis using uniform mutation by addition and deletion",
            "rating": 2,
            "sanitized_title": "program_synthesis_using_uniform_mutation_by_addition_and_deletion"
        },
        {
            "paper_title": "Effective mutation rate adaptation through group elite selection",
            "rating": 2,
            "sanitized_title": "effective_mutation_rate_adaptation_through_group_elite_selection"
        },
        {
            "paper_title": "Extreme Value Based Adaptive Operator Selection",
            "rating": 2,
            "sanitized_title": "extreme_value_based_adaptive_operator_selection"
        },
        {
            "paper_title": "Self-adaptation in genetic algorithms",
            "rating": 1,
            "sanitized_title": "selfadaptation_in_genetic_algorithms"
        },
        {
            "paper_title": "PSB2: the second program synthesis benchmark suite",
            "rating": 1,
            "sanitized_title": "psb2_the_second_program_synthesis_benchmark_suite"
        }
    ],
    "cost": 0.017779749999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Effective Adaptive Mutation Rates for Program Synthesis
23 Jun 2024</p>
<p>Lee Spector lspector@amherst.edu 
USA</p>
<p>Effective Adaptive Mutation Rates for Program Synthesis
23 Jun 20241AB2ABB4611FEFBD4CE1E0627C20CEF210.1145/3638529.3654135arXiv:2406.15976v1[cs.NE]Uniform Addition by Mutation and DeletionAdaptive Mutation RateMax K-armed BanditsGenetic ProgrammingSoftware Synthesis
The problem-solving performance of many evolutionary algorithms, including genetic programming systems used for program synthesis, depends on the values of hyperparameters including mutation rates.The mutation method used to produce some of the best results to date on software synthesis benchmark problems, Uniform Mutation by Addition and Deletion (UMAD), adds new genes into a genome at a predetermined rate and then deletes genes at a rate that balances the addition rate, producing no size change on average.While UMAD with a predetermined addition rate outperforms many other mutation and crossover schemes, we do not expect a single rate to be optimal across all problems or all generations within one run of an evolutionary system.However, many current adaptive mutation schemes such as self-adaptive mutation rates suffer from pathologies like the vanishing mutation rate problem, in which the mutation rate quickly decays to zero.We propose an adaptive bandit-based scheme that addresses this problem and essentially removes the need to specify a mutation rate.Although the proposed scheme itself introduces hyperparameters, we either set these to good values or ensemble them in a reasonable range.Results on software synthesis and symbolic regression problems validate the effectiveness of our approach.CCS CONCEPTS• Computing methodologies → Genetic programming.</p>
<p>INTRODUCTION</p>
<p>Genetic Programming (GP) is a problem-solving tool that uses concepts from biological evolution to find a program that solves a specific target problem.When applied to software synthesis, GP evolves a population of programs to satisfy a set of user-defined test cases, and successful individuals are then tested for generalization to a set of previously unseen test cases.</p>
<p>Many of the best results to date on benchmark program synthesis problems have been produced by PushGP, a stack-based GP system that uses linear genomes [6,12,13,17,30].While many mutation and crossover schemes have been tested for program synthesis with PushGP, the variation scheme that has produced the best results recently is Uniform Mutation by Addition and Deletion (UMAD) [13].In contrast to uniform mutation, which replaces genes with random genes with some probability, UMAD decouples the replacement step into an addition step and a deletion step.Genes are first added into a linear genome at a certain rate, and then deleted from the augmented genome at a rate that balances out the addition.This makes mutation more flexible compared to random replacement, and results in better problem solving performance.While the authors show that reasonable performance can be obtained with a relatively wide range of mutation rates, and that a UMAD rate of 0.1 generally works well for many problems, they find that doubling or halving the mutation rate can sometimes improve or greatly hinder the performance of the GP system.</p>
<p>Since the aim of software synthesis is to find a single solution to a set of test cases, in practice we expect end users to conduct a single, or at most a few PushGP runs until a single solution to their problem has been obtained.At that point the user will have no interest in conducting many more runs on the same problem in order to tune hyperparameters.Therefore, in order to tune hyperparameters to each individual problem, we must use an adaptive method to find optimal hyperparameter values as a run proceeds.</p>
<p>In the process of biological evolution, the mutation rate of organisms' DNA is evolved alongside the organisms themselves [26].Self-Adaptation of Mutation Rates (SAMR) is an adaptive technique inspired by the biological evolution of mutation rates.In its first formulation by Bäck [3], mutation rates were represented alongside the genome itself as a bitvector.During variation, the mutation rate section of the bitvector was decoded, and then the decoded rate was used to mutate the entire genome, including the mutation bitvector.While this scheme is directly analogous to the mutation of DNA and its repair mechanisms in biological evolution, recent research in real-coded systems have shifted to using real values to represent mutation rates, and using a special meta mutation rate to vary the mutation rate.</p>
<p>However, in contrast to the sheer diversity produced by biological evolution, these SAMR schemes often struggle with premature convergence due to the vanishing mutation rate problem [7,10,19].As most mutations in a difficult problem are deleterious, the only individuals which can survive for many generations in a row are those with very small mutation rates.</p>
<p>Here we propose an adaptive controller based on multi-armed bandits and tile-codings [34] to adapt the UMAD rate to each software synthesis problem.To address the vanishing mutation rate problem, we use extreme value-based credit assignment [9,36], which allows mutation operators to be mostly deleterious as long as they occasionally produce very beneficial mutations.The use of tile-codings enables us to take advantage of the continuous domain of mutation rates, generalizing the credit assignment to a range of mutation rates for improved sample complexity.While our work is mainly focused on the current best mutation operator for software synthesis in PushGP, this scheme is not tied to a specific genetic operator and can be used to adapt other hyperparameters beyond the UMAD rate.</p>
<p>This paper is organized as follows: In section 2, we give a brief overview of the PushGP system for software synthesis and the UMAD mutation operator, as well as various adaptive mutation rate schemes in the literature.In section 3, we present our adaptive mutation rate scheme.In section 4, we present our experiments building up from initial validation experiments to the final performance on software synthesis and symbolic regression problems.</p>
<p>BACKGROUND AND RELATED WORK</p>
<p>In this section, we give a brief overview of the PushGP system and the UMAD mutation operator, as well as a brief review on the strategies used for adaptive mutation rates.</p>
<p>PushGP</p>
<p>PushGP [29,30] is a linear-genome GP system that evolves Push programs for solving software synthesis problems.Push [29] is a stack-based language with a separate stack for each datatype, including one stack for the program code itself.Instructions in the program code will read off one or more values from the top of one or more datatype stacks, and push one or more values onto one or more datatype stacks.When there are not enough items on the required datatype stacks, instructions can no-op, producing no change to the program state.At the end of execution, the output of the program is simply the top one or more items from a predetermined datatype stack (e.g. the top integer for the Vector Average), or a special token if the requested stack does not have enough elements.With the addition of instructions for moving items from the middle of a stack to the top of the stack, as well as code-modifying commands to allow for complex control structures, the Push language becomes Turing-complete.While Push programs have a hierarchical structure, they are constructed from linear plushy genomes, where genes encode the instructions and constants in a Push program, as well as the opening and closing of nested Push code blocks.</p>
<p>UMAD</p>
<p>Uniform Mutation by Addition and Deletion (UMAD) [13] is a mutation operator for variable-length, symbolic, linear genomes such as those evolved using the PushGP system.The key concept of UMAD is to extend the expressibility of traditional replacement based mutation operators by separating the deletion of an existing gene from the addition of a new gene.In UMAD, more specifically size-neutral UMAD, new genes are first inserted into a genome at a predetermined rate, usually set to 0.1.Then, genes are deleted from this augmented genome at a rate that brings the expected length of the mutated genome back to the length of the starting genome.For an addition rate of , the deletion rate needed to balance the addition rate is  1+ .In general, when we refer to the UMAD rate, we mean the addition rate, and leave the deletion rate to be implicitly determined.In this paper, we extend UMAD to be defined for all positive-valued rates as follows: given a UMAD rate , during the addition step, for every instruction in the current genome we add ⌊⌋ new instructions with probability {} =  − ⌊⌋, and ⌊⌋ + 1 new instructions with probability 1 − {}.The deletion probability and deletion step remain the same as before.UMAD with a rate of 0.1 has been shown to outperform or equal a variety of other mutation operators and combinations of mutation and crossover operators on software synthesis problems using the PushGP system.However, even though Helmuth et al. [13] show that the UMAD rate is robust and performs well at different rate values, there is no single mutation rate that works optimally across all problems, and doubling or halving the default mutation rate can sometimes improve performance.We hypothesize that more "fundamentalsbased" problems, in which a clever solution idea is the crux of the problem, may require a larger UMAD rate to quickly search over the possible solution ideas.In contrast, more "implementation-based" problems, which have many tricky details and edge cases that need to be carefully considered, may require a lower UMAD rate for a slow, methodical descent to a solution.</p>
<p>Adaptive Mutation Rates</p>
<p>Research on mutation rates is an extensively studied subfield of genetic algorithms [1,3,4,21,24,25].As in Aleti et al. [1], we can classify mutation rate schemes into the fixed, self-adaptive, and adaptive categories.</p>
<p>In the fixed mutation rate scheme the mutation rate remains constant over all problems and all generations.While hyperparameter optimization can be used to find the optimal fixed mutation rate, research has also shown that the optimal mutation rate can change over the course of evolution [11,31], making any fixed mutation rate suboptimal.The current mutation scheme used in PushGP is that of a fixed UMAD mutation rate, with a default rate of 0.1.</p>
<p>The self-adaptive mutation rate (SAMR) scheme aims to simultaneously evolve both individuals and their mutation rates [27].In SAMR, each individual is associated with a mutation rate.During selection, individuals together with their mutation rates are chosen based on the individual's fitness function.During variation, each individual's genome is varied according to their mutation rate, and their mutation rate according to some preset meta-mutation rate.The SAMR scheme is attractive because of its elegance and its similarity to biological evolution [8].However, SAMR schemes often suffer from the vanishing mutation rate problem [7,10,19], in which mutation rates decay to 0 and cause premature convergence.This is often attributed to the observation that SAMR schemes are myopic, only optimizing in the short term [21].The extent to which this short-term optimization is beneficial or detrimental can be dependent on the problem domain, the selection strength, or the solution representation [10].However, in general SAMR struggles with more difficult problems that require optimizing for long-term improvement, often producing mutation rates which are far below optimal [7].Some strategies for alleviating this pathology include limiting the mutation rate to within a certain interval [4], adding a constant to the mutation rate during variation [19], or high selection pressure [25].</p>
<p>The adaptive mutation rate scheme attempts to explicitly optimize the mutation rate for better performance.Various adaptive mutation rate algorithms have been proposed to counteract the vanishing mutation rate problem.Fialho et al. [9] propose to select mutation rates based on their extreme value statistics, using a dynamic multi-armed bandit and the upper confidence bound algorithm [2] to balance exploration and exploitation.In contrast to the short-sightedness of SAMR, they directly optimize for the long-term effectiveness of mutation rates by choosing mutation rates with the best maximum improvement over many sampled individuals.On the other hand, Kumar et al. [21] propose to use a coevolutionary scheme to optimize the mutation rate, which enables them to exploit the continuous nature of mutation rates.At each generation, they assign each mutation rate to a group of selected parents, producing a set of children.From that set of parent-child pairs, they then calculate the fitness of the mutation rate as the best change in fitness from parent to child in the group.They show that this maximum value-based credit assignment is effective at avoiding premature convergence compared to SAMR, and is able to converge precisely to the optimal mutation rate.</p>
<p>Our work lies in the category of adaptive mutation rate schemes, and is adjacent to both the aforementioned adaptive schemes.Like Fialho et al. [9], we use a windowing method to track the maximum change in fitness obtained by a mutation rate over some number of sampled individuals, and also use a multi-armed bandit controller to balance exploration and exploitation.However, in order to take advantage of the continuous domain, we propose to use tile codings [34] to learn the bandit controller's weights.Similar to Kumar et al.'s [21] use of a meta-mutation rate to explore the range of possible mutation rates, we use sampling noise to choose mutation rates located around the current best rate.However, their meta-evolutionary scheme is tied to the underlying evolutionary scheme, as the suggested population size of the mutation rates approaches  3 4 at large  for an underlying population size  .This ties the sampling horizon of their max-improvement credit assignment to the population size, and makes their scheme less suited to algorithms that sample only a few individuals at a time, such as steady-state GAs or hill climbers.In contrast, our bandit scheme is able to optimize for maximum improvement over an arbitrary number of sampled individuals, and only needs the underlying scheme to repeatedly generate and evaluate children from selected parents.</p>
<p>METHODS</p>
<p>In this section, we present our adaptive scheme for controlling the UMAD rate.Our method uses multi-armed bandits and tile codings for better sample complexity, and optimizes for the expected maximum improvement in fitness over many mutations, which we find to be a better indicator of the problem-solving performance of a mutation rate.</p>
<p>Reward Function</p>
<p>Lexicase selection [18] is a selection algorithm for multiobjective genetic algorithms that has been shown to outperform selection methods based on aggregated fitness measures on program synthesis problems.The success of lexicase selection is commonly attributed to its ability to select "elites, " individuals which may have poor overall performance but which have excellent performance on a subset of the training cases [14,15].To encapsulate this idea of focusing on the individual's best performances, we optimize the UMAD rate with respect to the symmetrical log scale-transformed error function.For each error value   in an individual's error vector, we compute the transformed error on that test case as
𝑓 (𝑥 𝑖 ) = sgn(𝑥 𝑖 ) log(𝑐 + |𝑥 𝑖 |)(1)
We base our error transformation off of the log function so that very poor performances on certain test cases will not overwhelm good performances on other test cases, following the lexicase idea.The parameter  roughly represents the resolution of our proxy error function, as it behaves linearly in the region [−, ] and logarithmically outside.Therefore, we set it equal to the lowest nonnegative error we expect to see from the system.Since the function minimization problems have one-dimensional error vectors, we do not use this transformation in those experiments.For more details on the parameter values used, see appendix D.</p>
<p>Given a parent with errors
[𝑒 0 , • • • , 𝑒 𝑚 ] that was mutated to produce a child with errors [𝑒 ′ 0 , • • • , 𝑒 ′ 𝑚 ],
we compute the immediate reward obtained as the amount of improvement (decrease) in the average transformed error from parent to child
𝑟 = 1 𝑚 𝑚 ∑︁ 𝑖=0 log(1 + 𝑒 𝑖 ) − 1 𝑚 𝑚 ∑︁ 𝑖=0 log(1 + 𝑒 ′ 𝑖 )(2)
Similarly to Fialho et al. [9], we track the maximum reward  max obtained over the last _ℎ samples from the same UMAD rate range and use that value to update our adaptive controller.</p>
<p>Multi-Armed Bandits</p>
<p>Multi-armed bandits [34] are one commonly used controller for adaptive mutation rates [9].The (stationary) multi-armed bandit problem is formulated as such [5]: Given k slot machines, each with an unknown payout distribution, and a maximum number of pulls of a slot machine, how do we allocate pulls to each slot machine to maximize our expected total payout?In our case, the slot machines correspond to different UMAD rate ranges and the payouts to the reward function defined above.Different strategies have been devised for balancing exploration and exploitation in multi-armed bandits, including simple strategies like epsilon-greedy or boltzmann exploration as well as more complex strategies with better theoretical properties like upper confidence bound (UCB) based algorithms [20].In this work, we use an epsilon-greedy strategy combined with sampling noise for exploration.We anneal the epsilon value from 1 to 0.01 over the first 5 generations, at which point it is kept constant at 0.01 for the rest of the run.Our sampling noise takes the form of gaussian perturbation, where we sample UMAD rate intervals in the vicinity of the best rate interval according to a normal distribution.</p>
<p>Tile Codings</p>
<p>Current works using multi-armed bandits for adaptive mutation rate control do not take advantage of the continuous nature of this domain, instead partitioning possible rates into separate intervals [9,36].Intervals which are too large will mask the performance of good mutation rates with the poor performance of significantly different mutation rates.On the other hand, intervals which are too small suffer from poor sample complexity, as each interval needs to be sampled many times in order to obtain an accurate estimate of the expected reward.In order to combine generalization with precision, we use tile-codings [34] to learn the expected  max associated with different UMAD rates.In tile codings, we create many tilings of our desired parameter range with different tile offsets and widths.When we observe a reward associated with a specific point, we update all the tiles covering that point using that reward.Then, when we want to assess the value of a point, we average the values of all the tiles covering that point.With enough random tilings, we can distinguish between very small UMAD rate ranges with high precision, while each sampled reward will still update tiles covering a large range of UMAD rates for good generalization and low sample complexity.</p>
<p>Given the very stochastic rewards in our system, we use SGD with nesterov momentum [33] as well as ensembling to stabilize learning.A tile coding defined on the range [,  ] with tile offset  and width  will track the value (expected  max ) and momentum associated with the intervals
[𝑙, 𝑙 + 𝑜), [𝑙 + 𝑜, 𝑙 + 𝑜 + 𝑤), • • • , [𝑙 + 𝑜 + ⌊ 𝑟 −𝑙 −𝑜 𝑤 ⌋ • 𝑤, 𝑟 ). When a tile coding with values [𝑣 0 , • • • , 𝑣 𝑛 ] and momentum [𝑚 0 , • • • , 𝑚 𝑛 ]
observes a reward  at position , it will calculate the index of the tile that covers  as  = ⌊  − −  ⌋ + 1.Then, using the learning rate  and momentum factor , it will calculate the gradient  = 2(  − ), update the momentum   ←   +, and update the value using the updated momentum   ←   − (+  ).</p>
<p>In practice, we create multiple multi-armed bandits each with a randomized learning rate.During variation, a multi-armed bandit is chosen at random to sample for a mutation rate.Then, once we have computed the immediate reward  for that sampled mutation rate, all of the bandit controllers are updated with that information.</p>
<p>Adaptive UMAD Rate</p>
<p>We combine the previous sections into an adaptive controller for UMAD rates in problem synthesis.The algorithm for sampling a UMAD rate from a single bandit is given in Algorithm 1, and the algorithm for updating a single bandit is given in Algorithm 2. In practice, we have multiple bandits, updating them all with the same rewards and randomly choosing a bandit to sample from.</p>
<p>EXPERIMENTS</p>
<p>In this section we present our experiments validating the effectiveness our algorithm, exploring the fitness landscape of software synthesis problems, and demonstrating the performance of our controller on genetic programming and symbolic regression problems.</p>
<p>Function Minimization</p>
<p>We first validate the effectiveness of our algorithm on some function minimization problems.In these problems, a real-valued ndimensional vector is evolved to minimize a synthetic fitness function.We use the common test functions Ackley, Greiwank, Rastrigin, Rosenbrock, Sphere, and Linear [21,23,32].However, due to differences in genetic algorithm hyperparameters such as the truncation size, our results are not comparable to those in the literature.The test problem definitions can be found in appendix A. We run each problem with a 100-dimensional test function using a population size of 100 + 1 elite, and a generation limit of 1000.We initialize the GA population according to the normal distribution N (0,  2 I) where the standard deviation  is on roughly the same order of magnitude as the dimensions recommended in [32], or 1 if such a recommendation is not available.For specific details, see appendix A. The one exception is the Linear problem which is only run for 100 generations.We compare our adaptive bandit-based controller against the GESMR, SAMR, and LAMR-100 mutation rate schemes from Kumar et al. [21].GESMR is the the novel evolutionary mutation rate adaptation proposed in Kumar et al. [21], which coevolves a population of mutation rates alongside the main population.SAMR is a simple self-adaptive mutation rate scheme that attaches mutation rates to individuals and evolves mutation rates and genomes together.The LAMR-100 scheme, which is our "oracle, " determines the optimal mutation rate every 100 generations by "looking ahead, " running each mutation value in a preset range for 100 generations and choosing the best one.Therefore LAMR-100 is able to directly optimize for future behavior.For these experiments, LAMR-100 searches over a log-spaced range of values from 10 −3 to 10 0 .To showcase the sample efficiency of our controller, we let the bandit controller search over a very large log-range of mutation rates from −100 to 100.In addition, we use an amount of sampling noise roughly equal to the meta mutation strength of GESMR.For specific parameter details, see appendix D. All results are averaged over 50 runs.</p>
<p>The results of our experiment is displayed in figure 1.Despite the wide range of mutation standard deviations searched by our controller, we still have high precision and good sample complexity due  to our use of tile codings, which efficiently exploit the continuous nature of mutation rates.As we have set _ℎ to 100 in this paper, our bandit controller optimizes for more long-term performance than GESMR.This is because, following the trend reported in Kumar et al. [21], we have set the GESMR meta population size to 10.Therefore, the fitness function of a mutation rate is the maximum improvment in fitness of 10 sampled individuals for GESMR, whereas we choose mutations based on the expected maximum over 100 individuals.For this reason, our controller outperforms GESMR which outperforms SAMR on more rugged domains due to their better ability to ignore local minima in favor of global minima.However, since our bandit controller directly estimates this order statistic empirically, it requires more samples to learn and takes more time to adapt the mutation rate.This results in weaker performance on easier problems like Rosenbrock and Sphere.</p>
<p>Since the LAMR-100 oracle optimizes for performance over 100 generations, or 10,000 individuals, it is able to achieve the best performance on the rugged problems Ackley and Rastrigin.However, the limitations of the LAMR-100 method are also clear.Because LAMR-100 only searches over mutation rates from 10 −3 to 10 0 , it is unable to perform as well as the other methods on the Linear and Griewank problems, which both require higher mutation rates.In addition, the sampled mutation rates flatten out at later generations on the Ackley, Rastrigin, and Sphere problems at the minimum value available to LAMR-100, 10 −3 , whereas the optimal mutation rate likely continues decreasing according to the trend seen in earlier generations.</p>
<p>Out of the six problems tested, the Linear problem is unique in its unbounded and smooth fitness function.While GESMR and SAMR will eventually outperform our bandit controller on the Linear problem due to their unbounded growth of mutation rates, our bandit controller is able to learn much more quickly than GESMR or SAMR, essentially achieving its maximum mutation rate within the 5 exploration generations.</p>
<p>Software Synthesis</p>
<p>For our experiments in software synthesis, we use the propeller implementation of PushGP 1 and tackle several problems from the PSB1 and PSB2 benchmarks.These problems were chosen to represent a range of difficulties and consist of three problems from each benchmark suite.</p>
<p>Fitness Landscape.</p>
<p>Compared to the continuous test functions, software synthesis is a much less regular domain.There are fewer beneficial mutations, and the changes in total fitness from parent to child can vary significantly.We therefore expect SAMR to suffer from the vanishing mutation rate problem on this domain.Before conducting problem-solving expeirments, we first validate our choice of a max-value based credit assignment  max and show that it can help avoid the vanishing mutation rate problem.</p>
<p>In these experiments, we run PushGP on each software synthesis problem with the default UMAD rate of 0.1.We use the default settings [6,12,15], with a population size of 1000 and generation limit of 300, and lexicase selection [18] as the selection operator.At each generation, we additionally sample 1000 individuals using each UMAD rate  ∈ {0.01, 0.03, 0.1, 0.3, 1}.These additional individuals have no impact on the genetic algorithm, and are solely used to evaluate the performance of each mutation rate under our defined reward function.For each individual sampled this way, we compute its immediate reward as described in equation 2. For each UMAD rate, we combine all of these sampled rewards over the entire GP run into a linear array, apply 1-dimensional max pooling with kernel size _ℎ and stride 1 to transform it into the maximum reward  max , and then take an exponentially weighted average with a learning rate of 0.01 to smooth out the plot.We also do the same process without max-pooling, essentially plotting the immediate reward  .Finally, we also display the best log-error in the current population at each generation to get an idea of how far evolution has progressed.For all the experiments in this paper, we use _ℎ = 100.All problems were run for 3 runs each, and at each generation the average statistic was taken over all runs which had not yet found a solution.</p>
<p>The results are depicted in figure 2. If we naively consider only the immediate reward, it would appear that on all problems, the lower the mutation rate the better.In fact, these expected rewards are all negative throughout all generations of all problems, so all the mutation rates studied have a worse expected  than zero mutation.Therefore, we expect using the expected immediate reward as a metric to result in mutation rates converging to zero.However, if we instead consider the max-value based reward  max , we see that larger mutation rates are generally better when the best solution found is still poor, but as evolution proceeds and the solutions improve, lower mutation rates become better.We therefore expect the  max metric to be a much more realistic predictor of mutation rate performance, and we expect that controllers based on maximum value statistics will avoid the vanishing mutation rate problem.</p>
<p>Software Synthesis Performance.</p>
<p>As in the previous section, we use the propeller implementation of PushGP and run on the same software synthesis problems with the same settings.In this section, we compare the performance of a fixed UMAD rate of 0.1 with our adaptive bandit controller as well as a self-adaptive mutation rate scheme.Due to computational limitations, instead of  reporting the number of successes out of 100 as recommended in [12], we report the number of successes out of 50.</p>
<p>The results are shown in table 2. Although the bandit controller is not always able to perform as well as the fixed UMAD rate, it is often able to significantly outperform the SAMR scheme.To see why, we plotted the best log-error and average log-UMAD rate of each adaptive scheme for each problem over 300 generations.As  3.Although SAMR is able to increase the UMAD rate in the outset of evolution, the UMAD rate quickly decays to very low values, resulting in premature convergence and a low solution rate.On the other hand, our bandit controller is better able to avoid the vanishing mutation rates, chooses more optimal UMAD rates, and achieves better solution rates.</p>
<p>Symbolic Regression Performance</p>
<p>As in the previous section, we use the propeller implementation of PushGP.In this experiment, we run on the eight 1-dimensional synthetic regression problems from Nguyen et al. [35].The target functions are detailed in appendix B. As the details of our experiment differ from those in the literature, our results only serve to draw comparisons between the adaptive mutation rate schemes studied here.We define a successful function as one which completely replicates the given input-output pairs, to within some small constant.In addition, we use an instruction set composed of the input instruction input, the constant 1.0, basic arithmetic operations (+, -, ×, ÷), and the additional functions (Sin, Cos, Log).We protect Log and ÷ to return 0.0 for undefined inputs, and clamp all numbers in the execution of our program to the interval [−1.0×10 6 , 1.0×10 6 ].</p>
<p>For our test cases on problems Nguyen1 through Nguyen6, we use a range of evenly spaced inputs from -4 to 4 with a step size of 0.1.For Nguyen7 and Nguyen8, to avoid undefined regions of the domain, we shift the inputs to range from 0 to 8. We find that the larger range of inputs gives more information about the shape of the function, leading to higher quality runs.We use the epsilon-lexicase selection method [22] and run PushGP with a population size of 1000 for 300 generations.We report our results as the number of successful runs out of 50 total.</p>
<p>The results are displayed in table 3. The bandit based scheme consistently outperforms the SAMR and GESMR schemes on the symbolic regression problems, although it is not always able to perform as well as the preset UMAD rate.The best log-error and average log-UMAD rate sampled by these three adaptive methods are displayed in figure 4. As before, we average each statistic at each generation over all the runs that have not yet terminated.Therefore, for problems like Nguyen1 and Nguyen2 where the bandit method always terminates within 50 or 100 generations, there is no data for later generations.In all problems, the SAMR method results in continually decreasing mutation rates which often results in premature convergence, such as in the Nguyen3 and Nguyen4 problems.On the other hand, GESMR samples ever increasing UMAD rates.We hypothesize that this is due to the low degree of differentiation between large UMAD rates.As the UMAD rate tends towards infinity, UMAD mutation does not tend towards infinitely large mutations as with gaussian mutation, but rather towards completely random mutation.Therefore, the difference between mutation rates is much less pronounced, especially for large mutation rates, in the symbolic regression domain than it is in the function minimization domain.As GESMR only utilizes local information about mutation rates, we hypothesize that it gets stuck in this uninformative region of high mutation rates and is unable to realize when significant progress has been made and large mutation rates are no longer optimal.In contrast, the bandit controller is able to escape these pathologies and robustly determine a good, moderate UMAD rate at each generation.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>We have presented an adaptive scheme for controlling the rate of UMAD mutation in genetic programming problems.The proposed method uses multi-armed bandits to optimize the mutation rate, tile codings to improve generalization, and optimizes for the maximum improvement over many mutations, which is a more accurate predictor of the usefulness of a given mutation rate.</p>
<p>In the future, we could extend our adaptive controller to other mutation and selection operators in addition to the UMAD rate.For example, we could learn various combinations of tree-based mutation operators at various strengths for tree-based GP systems [28], or various bit mutation operators for systems with binary representations [9].One attractive domain for adaptive optimization is the genetic source [16].An effective adaptive scheme for genetic source optimization not only has the potential for greatly improved solution rates [16], but also can relieve the end user of the need to specify which datatypes and instructions are needed for each individual problem.</p>
<p>Beyond genetic programming, this system could also be used to adapt hyperparameters such as learning rate or weight decay over the course of training a neural network.To do this, we frame the task of choosing hyperparameters as the maximization of the expected improvement in the training loss, which can be estimated by the improvement in training loss from the current training batch to the next.While we could also use the expected improvement of the validation loss, this formulation does not require any additional forward passes, and has almost no overhead cost.Since we are interested in the continuous improvement of a single model in this domain, we would maximize the expected reward, and not the expected maximum reward over _ℎ samples as we have done in the evolutionary domains.</p>
<p>However, the scope of possible applications of our controller is limited by the curse of dimensionality, as the number of tiles to be evaluated grows exponentially with the number of parameters to be optimized.One simple fix would be to keep a separate bandit controller for each hyperparameter.However, this assumes that the hyperparameters can be optimized independently, ignoring the possible interplay between hyperparameters.In the future, we could extend our adaptive scheme to higher dimensions, such as by replacing the tile coding with a neural network.</p>
<p>A.1 Ackley
𝑓 (x) = −𝑎 exp −𝑏 1 𝑑 𝑑 ∑︁ 𝑖=1 𝑥 2 𝑖 − exp 1 𝑑 𝑑 ∑︁ 𝑖=1 cos(𝑐𝑥 𝑖 ) + 𝑎 + 𝑒(3)
where  = 20,  = 0.2, and  = 2.As Surjanovic et al. [32] recommend a search range of   ∈ [−32.768,32.768] for 1 ≤  ≤ , we initialize the population with a standard deviation of 10 for this problem.</p>
<p>A.2 Griewank
𝑓 (x) = 𝑑 ∑︁ 𝑖=1 𝑥 2 𝑖 4000 − 𝑑 𝑖=1 cos 𝑥 𝑖 √ 𝑖 + 1(4)
As Surjanovic et al. [32] recommend a search range of   ∈ [−600, 600] for 1 ≤  ≤ , we initialize the population with a standard deviation of 1000 for this problem.</p>
<p>A.3 Rastrigin
𝑓 (x) = 10𝑑 + 𝑑 ∑︁ 𝑖=1 <a href="5">𝑥 2 𝑖 − 10 cos(2𝜋𝑥 𝑖 )</a>
As Surjanovic et al. [32] recommend a search range of   ∈ [−5.12, 5.12] for 1 ≤  ≤ , we initialize the population with a standard deviation of 10 for this problem.</p>
<p>A.4 Rosenbrock
𝑓 (x) = 𝑑 −1 ∑︁ 𝑖=1 <a href="6">100(𝑥 𝑖+1 − 𝑥 2 𝑖 ) 2 + (𝑥 𝑖 − 1) 2 </a>
As Surjanovic et al. [32] recommend a search range of   ∈ [−2.048, 2.048] for 1 ≤  ≤ , we initialize the population with a standard deviation of 1 for this problem.</p>
<p>A.5 Sphere
𝑓 (x) = 𝑑 ∑︁ 𝑖=1 𝑥 2 𝑖 (7)
As Surjanovic et al. [32] recommend a search range of   ∈ [−5.12, 5.12] for 1 ≤  ≤ , we initialize the population with a standard deviation of 10 for this problem.</p>
<p>A.6 Linear
𝑓 (x) = 𝑑 ∑︁ 𝑖=1 𝑥 𝑖 (8)
This problem is not detailed in Surjanovic et al. [32], so we use a default standard deviation of 1.</p>
<p>B SYMBOLIC REGRESSION FUNCTION DEFINITIONS</p>
<p>In our Symbolic Regression experiments, we attempt to recover a known mathematical function  () using a genetic algorithm based on some example input-output pairs (  ,  (  )).In this section we detail the specific target functions and input ranges used, following the format of White et al. [37].</p>
<p>C PARAMETER SETTINGS</p>
<p>The parameter settings used by our adaptive controller are shown in Table 5.We use an epsilon-greedy strategy with sampling noise for exploration.Each bandit has a randomized learning rate.For each bandit, we create 20 tile codings, each with tile width and tile offset sampled uniformly from the range of possible values.In order to be able to evaluate each tile in the base coding, we require the tile widths and offsets to all be multiples of the base coding tile width.</p>
<p>We use a value of 7 for our sampling noise in the function minimization problems.The corresponding noise parameter in GESMR is the meta-mutation strength, which they set to 2. In GESMR, mutation rates are mutated by multiplying by 2 U [−1 ,1] .Since the random variable log(2 U ( [−1,1] ) ) has standard deviation √︃ 2 log(2) 12 = 0.223, we set the standard deviation of our sampled UMAD rates to 0.223 as well.Since our base tile width is 0.03, this comes out to a standard deviation in terms of tile indices of 0.223 0.03 ≈ 7</p>
<p>Algorithm 2 :
2
Updating a single bandit Data: • Search range [,  ] • Search resolution  • Learning rate  • Momentum factor  • <em>ℎ the number of past rewards to max over • _ = Coding(, , , ) the tile coding •  = {  } the value of the  ℎ tile in the tile coding •  = {  } the momentum of the  ℎ tile in the tile coding •  = {  } the history of rewards obtained by tiles in the tile coding, represented as deques with max length _ℎ •  the sampled UMAD rate •  = {  } the parent error vector •  ′ = { ′  } the child error vector Result: • {  } the updated tile coding values • {  } the updated tile coding momentum /<em> Locate the tile containing the UMAD rate </em>/  ←− ⌊ log  − −  ⌋ + 1 /<em> Compute immediate reward </em>/  = (log(1 +  ′ ) − log(1 + )).mean()/<em> Compute max over reward history </em>/   .push()</em> ←− max(  [0], • • • ,   [<em>ℎ − 1]) /<em> Compute gradient and update parameters </em>/  ←− 2(  − </em>)   ←−  •   +    ←−   −  ( +  •   ) return {  }, {  }</p>
<p>Figure 2 :
2
Figure2: Rewards obtained by different UMAD rates on software synthesis problems.Naively considering only the expected reward makes the lowest UMAD rate appear to be the best.Considering the expected maximum reward over _ℎ samples paints a much more realistic picture.</p>
<p>Figure 3 :
3
Figure 3: Best error and average log-UMAD rate sampled by three different adaptive controllers on Software Synthesis problems.95% confidence intervals obtained by bootstrapping.The bandit controller is able to effectively avoid the vanishing mutation rate problem.</p>
<p>Figure 4 :
4
Figure 4: Best error and average log-UMAD rate sampled by three different adaptive controllers on SR problems.95% confidence intervals obtained by bootstrapping.SAMR suffers from a vanishing mutation rate, while GESMR suffers from an exploding mutation rate.</p>
<p>𝑓 (𝑥) = 𝑥 3 +
3
 2 +  (9) For this problem our input is a range of evenly spaced floats from −4 to 4 with step size 0.1:  [−4.0, 4.0, 0.1] B.2 Nguyen2  () =  4 +  3 +  2 +  (10) For this problem our input is  [−4.0, 4.0, 0.1] B.3 Nguyen3  () =  5 +  4 +  3 +  2 +  (11) For this problem our input is  [−4.0, 4.0, 0.1] B.4 Nguyen4  () =  6 +  5 +  4 +  3 +  2 +  (12) For this problem our input is  [−4.0, 4.0, 0.1] B.5 Nguyen5  () = sin( 2 ) cos() − 1 (13) For this problem our input is  [−4.0, 4.0, 0.1] B.6 Nguyen6  () = sin() + sin( +  2 ) (14) For this problem our input is  [−4.0, 4.0, 0.1] B.7 Nguyen7  () = log( + 1) + log( 2 + 1) (15) As this function is undefined for inputs smaller than −1, we use  [0.0, 8.0, 0.1] as inputs.B.8 Nguyen8  () = √  (16) As this function is undefined for negative inputs, we use  [0.0, 8.0, 0.1] as inputs.</p>
<p>Algorithm 1 :
1
Sampling UMAD rate from a single bandit Data: • Search range [,  ] • Search resolution  • Exploration noise  • Epsilon-greedy exploration rate  • Number of tile codings _ • Base coding _ = Coding(, , 0, ) • Tile codings _ = {Coding  (, ,   ,   )} •  = { , } the value of the  ℎ tile in the  ℎ tile coding
Result: 𝜌, the UMAD rate to use for mutation𝑤𝑒𝑖𝑔ℎ𝑡𝑠 ←− []𝑛𝑢𝑚_𝑏𝑎𝑠𝑒_𝑡𝑖𝑙𝑒𝑠 ←− ⌊ 𝑟 −𝑙 𝑟𝑒𝑠 ⌋/<em> Compute tile weights in the base coding</em>/for 𝑖 ← 0 to 𝑛𝑢𝑚_𝑏𝑎𝑠𝑒_𝑡𝑖𝑙𝑒𝑠 do/<em> Average the associated values in each tilecoding</em>/𝑡𝑜𝑡𝑎𝑙 ←− 0for 𝑗 ← 0 to 𝑛𝑢𝑚_𝑐𝑜𝑑𝑖𝑛𝑔𝑠 do𝑖𝑑𝑥 ←− ⌊𝑖 •𝑟𝑒𝑠 −𝑜 𝑗 𝑤 𝑗⌋ + 1𝑡𝑜𝑡𝑎𝑙+ = 𝑣 𝑗,𝑖𝑑𝑥end𝑤𝑒𝑖𝑔ℎ𝑡𝑠.append(𝑡𝑜𝑡𝑎𝑙 𝑛𝑢𝑚_𝑐𝑜𝑑𝑖𝑛𝑔𝑠 )endif (rand) &lt; 𝜖 then/<em> Sample a random tile</em>/𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒 ∼ ⌊U ([0, 𝑛𝑢𝑚_𝑏𝑎𝑠𝑒_𝑡𝑖𝑙𝑒𝑠])⌋else/<em> Sample around the best tile</em>/𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒 ∼ argmax(𝑤𝑒𝑖𝑔ℎ𝑡𝑠) +⌊N (0, 𝜎)⌋𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒 ←− max(min(𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒, 𝑛𝑢𝑚_𝑏𝑎𝑠𝑒_𝑡𝑖𝑙𝑒𝑠 −1), 0)end/<em> Uniformly sample a log UMAD rate from withinthe selected tile</em>/𝑙𝑜𝑔_𝑟𝑎𝑡𝑒 ∼ U ([𝑙 + 𝑟𝑒𝑠 • 𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒, 𝑙 + 𝑟𝑒𝑠 • (𝑏𝑒𝑠𝑡_𝑡𝑖𝑙𝑒 + 1)])/<em> Convert from log UMAD rate to UMAD rate</em>/return 𝑒 𝑙𝑜𝑔_𝑟𝑎𝑡𝑒</p>
<p>Table 2 :
2
Number of successes out of 50 runs of fixed and adaptive mutation rate schemes on Software Synthesis problems.The best performance among adaptive results is shown in bold.The performance of the fixed UMAD rate of 0.1 is bolded when best but does not prevent bolding of the adaptive schemes.Statistical significance was calculated using a two-proportion z-test.Results significantly worse than the bandit scheme with  &lt; 0.05 are underlined.No results from adaptive schemes were significantly better than the bandit scheme.
ProblemUMAD 0.1 Bandit SAMRVector Average452716Syllables10186Replace Space With Newline474323GCD612Fuel Cost212923Fizz Buzz8121</p>
<p>Table 3 :
3
Number of successes out of 50 runs of fixed and adaptive mutation rate schemes on Symbolic Regression problems.UMAD 0.1 is bolded when best but does not prevent bolding of the adaptive schemes.Statistical significance was calculated using a two-proportion z-test.Results significantly worse than the bandit scheme with  &lt; 0.05 are underlined.No results from adaptive schemes were significantly better than the bandit scheme.
Problem UMAD 0.1 Bandit GESMR SAMRNguyen150504747Nguyen250504834Nguyen34843129Nguyen43443142Nguyen550422423Nguyen65030623Nguyen78203Nguyen80000before, we average each statistic at each generation over all theruns which have not yet terminated. The results are shown in figure</p>
<p>Table 4 :
4
Hyperparameter values for bandit controller Uniform({0.18, 0.21, 0.24, 0.27, 0.3, 0.33, 0.36, 0.39}) Tile coding offsets   ∼ Uniform({0, 0.03, 0.06, 0.09, 0.12, 0.15}) Proxy error function  () = sgn() log(1 + | |) (software synthesis)  () = sgn() log(0.01+ | |) (symbolic regression)  () =  (function minimization)
ParameterValueNumber of Bandits in Ensemble5𝑙𝑒𝑛_ℎ𝑖𝑠𝑡𝑜𝑟𝑦100Learning Rate 𝛾𝛾 ∼ 10 U ( [−4,−3] )Momentum Factor 𝜇0.9Epsilon 𝜖Annealed linearly from 1 to 0.01 over 5 generationsSampling noise 𝜎3 (software synthesis and SR) 7 (function minimization)Number of tile codings20Log-UMAD interval[-10, 0] (software synthesis and SR)Log-𝜎 interval[-100, 100] (function minimization)Base coding tile width0.03Tile coding widths𝑤 𝑖 ∼</p>
<p>Table 5 :
5
Hyperparameter values for Function Minimization
ParameterValuePopulation size 𝑁100 + 1 eliteSelection operatorTruncation selectionTruncation size10GESMR meta selection operatorTruncation selectionGESMR meta truncation size4GESMR meta population size9 + 1 eliteGESMR meta mutation rate2SAMR meta mutation rate2GESMR rate initialization10 Log-spaced values from 10 −3 to 10 3SAMR rate initialization101 Log-spaced from 10 −3 to 10 3LAMR searched rates10 log-spaced values from 10 −3 to 10 0LAMR lookahead generation100
ACKNOWLEDGMENTSThis work was performed in part using high-performance computing equipment at Amherst College obtained under National Science Foundation Grant No. 2117377.Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the National Science Foundation.The authors would like to thank Ryan Boldi, Bill Tozier, Tom Helmuth, Edward Pantridge and other members of the PUSH lab for their insightful comments and suggestions.A TEST FUNCTION DEFINITIONSIn this section we describe the test functions used in our function minimization experiment as well as the standard deviation used to initialize our population.Aside from the Linear function, which is unbounded, and the Rosenbrock function, which achieves its minimum at x = 1, all test functions are constructed to have a global minimum of 0 at x = 0.In these definitions,  is the dimension of the vector x and the   are all 1-indexed.While we also have to specify the added constant  in the proxy error function for each problem, we set this to around the minimum absolute nonzero error.For software synthesis, errors are integer-valued, so we set the constant to 1.For symbolic regression, Nguyen et al.[35]considers any error below 0.01 a "hit, " so we set our constant to 0.01.Finally, since function minimization errors are 1-dimensional, we do not need to use this lexicase-like error transformation step.The hyperparameters used in the function minimization experiments are detailed in table 5. Following the recommendation in[21], we set the GESMR meta population size to be the largest divisor of  − 1 (the number of mutated individuals) that is less than  3 4 .Aside from the GA truncation size and the GESMR meta truncation size, which were not available in[21]and are therefore set to reasonable values, we take all other hyperparameters from Kumar et al.[21]
A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms. Aldeida Aleti, Irene Moser, 10.1145/2996355ACM Comput. Surv. 492016. Oct 2016</p>
<p>Finite-time Analysis of the Multiarmed Bandit Problem. Peter Auer, Nicolò Cesa-Bianchi, Paul Fischer, 10.1023/A:1013689704352Machine Learning. 472002. 01 May 2002</p>
<p>Self-adaptation in genetic algorithms. Thomas Bäck, Proceedings of the first european conference on artificial life. the first european conference on artificial lifeMIT press Cambridge1992</p>
<p>Intelligent mutation rate control in canonical genetic algorithms. Thomas Bäck, Martin Schütz, Foundations of Intelligent Systems. Zbigniew W Raś, Maciek Michalewicz, Berlin Heidelberg; Berlin, HeidelbergSpringer1996</p>
<p>Bandit problems: sequential allocation of experiments (Monographs on statistics and applied probability). A Donald, Bert Berry, Fristedt, 1995Springer</p>
<p>Informed Down-Sampled Lexicase Selection: Identifying Productive Training Cases for Efficient Problem Solving. Ryan Boldi, Martin Briesch, Dominik Sobania, Alexander Lalejini, Thomas Helmuth, Franz Rothlauf, Charles Ofria, Lee Spector, 10.1162/evco_a_00346Evolutionary Computation. 2024. 03 2024</p>
<p>Natural selection fails to optimize mutation rates for long-term adaptation on rugged fitness landscapes. Jeff Clune, Dusan Misevic, Charles Ofria, Richard E Lenski, Santiago F Elena, Rafael Sanjuán, PLoS Computational Biology. 4e10001872008. 2008</p>
<p>Runtime Analysis for Self-Adaptive Mutation Rates. Benjamin Doerr, Carsten Witt, Jing Yang, 10.1145/3205455.3205569Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceKyoto, Japan; New York, NY, USA2018Association for Computing Machinery</p>
<p>Extreme Value Based Adaptive Operator Selection. Álvaro Fialho, Luís Da Costa, Marc Schoenauer, Michèle Sebag, ; Ppsn, X , Günter Rudolph, Thomas Jansen, Parallel Problem Solving from Nature. Nicola Beume, Simon Lucas, Carlo Poloni, Berlin Heidelberg; Berlin, HeidelbergSpringer2008</p>
<p>Reasons for premature convergence of self-adapting mutation rates. M R Glickman, K Sycara, 10.1109/CEC.2000.870276Proceedings of the 2000 Congress on Evolutionary Computation. CEC00 (Cat. No.00TH8512). the 2000 Congress on Evolutionary Computation. CEC00 (Cat. No.00TH8512)20001</p>
<p>Meta-evolved empirical evidence of the effectiveness of dynamic parameters. Brian W Goldman, Daniel R Tauritz, 10.1145/2001858.2001945Proceedings of the 13th Annual Conference Companion on Genetic and Evolutionary Computation. the 13th Annual Conference Companion on Genetic and Evolutionary ComputationDublin, Ireland; New York, NY, USAAssociation for Computing Machinery2011</p>
<p>PSB2: the second program synthesis benchmark suite. Thomas Helmuth, Peter Kelly, 10.1145/3449639.3459285Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceLille, France; New York, NY, USAAssociation for Computing Machinery2021GECCO'21)</p>
<p>Program synthesis using uniform mutation by addition and deletion. Thomas Helmuth, Nicholas Freitag Mcphee, Lee Spector, 10.1145/3205455.3205603Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceKyoto, Japan; New York, NY, USAAssociation for Computing Machinery2018GECCO'18)</p>
<p>Lexicase Selection of Specialists. Thomas Helmuth, Edward Pantridge, Lee Spector, 10.1145/3321707.3321875Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferencePrague, Czech Republic; New York, NY, USAAssociation for Computing Machinery2019GECCO'19)</p>
<p>On the importance of specialists for lexicase selection. Thomas Helmuth, Edward Pantridge, Lee Spector, 10.1007/s10710-020-09377-2Genetic Programming and Evolvable Machines. 212020. 01 Sep 2020</p>
<p>Genetic Source Sensitivity and Transfer Learning in Genetic Programming. Thomas Helmuth, Edward Pantridge, Grace Woolson, Lee Spector, 10.1162/isal_a_00326Proceedings of ALIFE 2020: The 2020 Conference on Artificial Life. ALIFE 2020: The 2020 Conference on Artificial Life2020</p>
<p>General Program Synthesis Benchmark Suite. Thomas Helmuth, Lee Spector, 10.1145/2739480.2754769Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation. the 2015 Annual Conference on Genetic and Evolutionary ComputationMadrid, Spain; New York, NY, USAAssociation for Computing Machinery2015</p>
<p>Solving Uncompromising Problems With Lexicase Selection. Thomas Helmuth, Lee Spector, James Matheson, 10.1109/TEVC.2014.2362729IEEE Transactions on Evolutionary Computation. 192015. 2015</p>
<p>On the log-normal self-adaptation of the mutation rate in binary search spaces. Johannes W Kruisselbrink, Rui Li, Edgar Reehuis, Jeroen Eggermont, Thomas Bäck, 10.1145/2001576.2001699Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation. the 13th Annual Conference on Genetic and Evolutionary ComputationDublin, Ireland; New York, NY, USAAssociation for Computing Machinery2011</p>
<p>Algorithms for multi-armed bandit problems. Volodymyr Kuleshov, Doina Precup, arXiv:1402.6028[cs.AI]2014</p>
<p>Effective mutation rate adaptation through group elite selection. Akarsh Kumar, Bo Liu, Risto Miikkulainen, Peter Stone, 10.1145/3512290.3528706Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceBoston, Massachusetts; New York, NY, USAAssociation for Computing Machinery2022GECCO'22)</p>
<p>Epsilon-Lexicase Selection for Regression. La William, Lee Cava, Kourosh Spector, Danai, 10.1145/2908812.2908898Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceDenver, Colorado, USA; New York, NY, USAAssociation for Computing Machinery2016. 2016GECCO'16)</p>
<p>Quantifying ruggedness of continuous landscapes using entropy. Katherine M Malan, Andries P Engelbrecht, 10.1109/CEC.2009.4983112IEEE Congress on Evolutionary Computation. 2009. 2009</p>
<p>Adaptive mutation in genetic algorithms. Stefano Marsili, Libelli , P Alba, Soft computing. 42000. 2000</p>
<p>Intelligent Mutation Rate Control in an Economic Application of Genetic Algorithms. Kurtis Michael, Maschek, 10.1007/s10614-009-9190-6Computational Economics. 352010. 01 Jan 2010</p>
<p>Evidence for the adaptive evolution of mutation rates. David Metzgar, Christopher Wills, Cell. 1012000. 2000</p>
<p>Self-adaptation in evolutionary algorithms. Silja Meyer, -Nieberg , Hans-Georg Beyer, Parameter setting in evolutionary algorithms. Springer2007</p>
<p>A Field Guide to Genetic Programming. Ricardo Poli, William B Langdon, Nicholas F Mcphee, 2008Lulu Enterprises</p>
<p>Push 3.0 programming language description. Lee Spector, Chris Perry, Jon Klein, Maarten Keijzer, 2004. Jan 30</p>
<p>Genetic Programming and Autoconstructive Evolution with the Push Programming Language. Lee Spector, Alan Robinson, 10.1023/A:1014538503543Genetic Programming and Evolvable Machines. 312002. 01 Mar 2002</p>
<p>Self-Adaptation in Evolving Systems. C R Stephens, I García, J Mora Olmedo, H Vargas, Waelbroeck, 10.1162/106454698568512Artificial Life. 41998. 1998</p>
<p>Optimization Test Functions and Datasets. Sonja Surjanovic, Derek Bingham, 2013. Jan 28</p>
<p>On the importance of initialization and momentum in deep learning. Ilya Sutskever, James Martens, George Dahl, Geoffrey Hinton, Proceedings of the 30th International Conference on Machine Learning. Proceedings of Machine Learning Research. Sanjoy Dasgupta, David Mcallester, the 30th International Conference on Machine Learning201328</p>
<p>. Atlanta Pmlr, Georgia, Usa, </p>
<p>Reinforcement learning: An introduction. S Richard, Andrew G Sutton, Barto, 2018MIT press</p>
<p>Semantically-based crossover in genetic programming: application to real-valued symbolic regression. Nguyen Quang Uy, Xuan Nguyen, Hoai, O' Michael, R I Neill, Edgar Mckay, Galván-López, 10.1007/s10710-010-9121-2Genetic Programming and Evolvable Machines. 1222011. 01 Jun 2011</p>
<p>Use of statistical outlier detection method in adaptive evolutionary algorithms. James M Whitacre, Tuan Q Pham, Ruhul A Sarker, 10.1145/1143997.1144205Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation. the 8th Annual Conference on Genetic and Evolutionary ComputationSeattle, Washington, USA; New York, NY, USAAssociation for Computing Machinery2006GECCO'06)</p>
<p>Better GP benchmarks: community survey results and proposals. David R White, James Mcdermott, Mauro Castelli, Luca Manzoni, Brian W Goldman, Gabriel Kronberger, Wojciech Jaśkowski, Una-May O' Reilly, Sean Luke, 10.1007/s10710-012-9177-2Genetic Programming and Evolvable Machines. 1412013. 01 Mar 2013</p>            </div>
        </div>

    </div>
</body>
</html>