<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2417 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2417</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2417</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-64.html">extraction-schema-64</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <p><strong>Paper ID:</strong> paper-6c5c6f883604a3abaa829b83d2958de8c343beeb</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/6c5c6f883604a3abaa829b83d2958de8c343beeb" target="_blank">A Computational Inflection for Scientific Discovery</a></p>
                <p><strong>Paper Venue:</strong> Communications of the ACM</p>
                <p><strong>Paper TL;DR:</strong> Enabling researchers to leverage systems to overcome the limits of human cognitive capacity is a central challenge in the next generation of artificial intelligence.</p>
                <p><strong>Paper Abstract:</strong> Enabling researchers to leverage systems to overcome the limits of human cognitive capacity.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2417.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2417.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bridger</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bridger (novel author discovery system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An author-matching system that retrieves unfamiliar but relevant researchers to inspire new research directions by comparing extracted problem and method mentions from a user's papers to those of other authors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bridger</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Represents a researcher's inner knowledge by automatically extracting mentions of problems and methods from their papers (weighted by term frequency). It retrieves other authors (outer knowledge) using the same representation, ranking candidate authors by measures of relevance and novelty (authors who work on similar problems but with different methods). Presented author 'cards' surface salient problems, methods and papers to stimulate cross-domain transfer and break fixation.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>general scientific research (computer science exemplars)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>interdisciplinary synthesis / open-ended ideation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>User studies with CS researchers reported dramatic boosts in creative search and inspiration relative to a state-of-the-art neural model in the Semantic Scholar search engine; improvements described qualitatively but no numeric novelty/feasibility scores reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>State-of-art neural models employed by the Semantic Scholar search engine</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Described as dramatically boosting creative search and inspiration over the Semantic Scholar neural baseline; no quantitative effect sizes provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Example evidence: surfaced cross-area connections (e.g., connecting graph theory work to human-centered AI) that inspired new directions; system intended broadly but evaluated with computer science researchers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2417.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Analogy mining / Solvent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analogy mining (Solvent: mixed-initiative analogy-finding system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods that retrieve technological inventions or papers with partial structural similarity (mechanisms) to a user-provided invention description to enable analogical transfer and stimulate creative ideation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solvent: A mixed initiative system for finding analogies between research papers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Analogy mining (Solvent / structural-mechanism retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extracts mechanism-level or functional representations from invention/paper texts and performs structural similarity retrieval across a corpus of inventions/technical literature, returning candidate inspirations with partial structural alignment to the query to facilitate transfer of solutions across distant domains.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>engineering / technological invention / general scientific research</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>interdisciplinary synthesis / open-ended ideation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Ideation experiments reported significant boosts in human creativity measures when users viewed inspirations retrieved by the analogy method versus baseline IR methods; specific numerical creativity metrics are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Baseline information retrieval methods</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Method produced a significant boost over baseline IR in human ideation experiments (no numeric effect sizes reported here).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Examples include a polymer stretching/folding lab finding inspiration in civil engineering literature (web crippling in steel beams), illustrating cross-domain transfer potential.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2417.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hierarchical problem graph retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hierarchical problem-graph based perspective retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval method that extracts problem mentions across a corpus to build a hierarchical problem graph and traverses neighboring problems to surface diverse problem perspectives for a focal user-described problem, aiming to inspire abstraction and reformulation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling creative inspiration with fine-grained functional facets of product ideas</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hierarchical problem-graph retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses NLP to extract problem mentions from a corpus of technological invention texts, mines co-occurrence to build a hierarchical graph of related problems, and automatically traverses neighboring nodes around a focal user-provided problem description to retrieve diverse perspectives and potential reformulations.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>product design / engineering / technological invention</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended ideation / problem reformulation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Human judgments of usefulness and novelty for retrieved 'inspirations' (binary/annotated judgments aggregated as proportions).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td>Over 60% of retrieved 'inspirations' were judged useful and novel; reported as a relative boost of 50-60% compared to the best-performing baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Human study where more than 60% of inspirations were rated both useful and novel, representing a 50-60% improvement over the best baselines in those measures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Best-performing baseline retrieval methods (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Relative boost of 50-60% on the proportion of inspirations judged useful+novel versus baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Example: for the problem 'reminding patients to take medication', retrieved related problems (patient health tracking/alerting) provided useful inspiration; suggests method generalizes across consumer/biomedical adjacent problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2417.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Challenges/discovery search engine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Search engine for discovery of scientific challenges and directions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prototype search engine that retrieves statements of uncertainties, open questions and hypotheses from the literature to help researchers identify problem areas and guide attention to challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A search engine for discovery of scientific challenges and directions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Challenges / directions discovery search engine</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Searches literature to extract and surface phrases/statements that express difficulties, uncertainties, open questions and hypotheses relevant to user queries, prioritizing content that highlights gaps or promising directions rather than established knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biomedicine (demonstrated), general scientific research</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>problem identification & prioritization / guiding attention</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>User experiments (including medical doctors) showed the prototype outperformed PubMed at discovering important and interesting areas of challenges and directions; qualitative examples include surfacing hypotheses relating ACE2 to liver damage in COVID-19 that PubMed search did not emphasize.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>PubMed</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Described as dramatically outperforming PubMed in discovery of challenge/direction statements for query topics; no numeric performance metrics provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Demonstrated in the biomedical domain (e.g., COVID-19 literature), effective at surfacing statements of uncertainty and nascent hypotheses rather than well-studied results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2417.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PPI attention-bias analysis & reprioritization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bias-debiasing methods for prioritizing protein-protein interactions (PPI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An analytical and reprioritization approach that studies temporal attention biases in the growth of confirmed PPI graphs and proposes methods to reprioritize candidate PPIs to surface overlooked but promising interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On biases of attention in scientific discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PPI attention-bias analysis and reprioritization</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Constructs a temporal dataset of confirmed PPIs, analyzes patterns (e.g., 'bias of locality' where studies focus near recently-studied proteins), and applies reprioritization heuristics based on protein properties to recommend underexplored candidate PPIs that might have been discovered earlier with debiasing.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biology / molecular biology (protein interaction discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted exploration / prioritization of experiments</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Analysis of 'blindspots' in databases (qualitative/structural); prioritization evaluated by simulated earlier discovery (temporal simulation) rather than explicit novelty scores.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td>Reprioritization based on properties of proteins (proxy for likelihood of discovery/feasibility); evaluation via demonstration that earlier discoveries could have been made under reprioritized rankings.</td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Reprioritization heuristics informed by protein properties to counter locality bias</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td>Actual historical exploration/prioritization (temporal baseline reflecting locality-driven research)</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td>Study showed that debiasing/reprioritization mechanisms could have led to earlier discovery of certain PPIs compared to the historically observed sequence of exploration; specific numeric comparisons are not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Identified a strong 'bias of locality' in PPI discovery that creates systematic blindspots; demonstrates potential for computational reprioritization to surface overlooked biological interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2417.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot scientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientist (automated hypothesis generation and experimentation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of laboratory automation systems that formulate hypotheses, design and run experiments in the physical lab, and close the loop by incorporating experimental results to refine hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional genomic hypothesis generation and experimentation by a robot scientist</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot scientist (automated experimental loop)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines curated domain knowledge (e.g., gene regulatory networks), hypothesis-induction methods, and robotic lab automation to generate hypotheses from data, design experiments to test them, execute experiments, and update models in a closed loop.</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>biology / genomics / laboratory science</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>targeted hypothesis generation and automated experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Cited as prior work demonstrating closed-loop automated discovery in biology; presented as an exemplar of machines not only formulating hypotheses but also executing experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2417.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2417.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that automatically generate research hypotheses or research ideas, including how novelty and feasibility are measured, quantified, or traded off against each other.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 / LLM-based hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (large language model) and LLM-based generation of hypotheses/directions</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large language models (LLMs) such as GPT-4 are described as capable of formulating hypotheses, recommending research directions, and critiquing studies when coupled with retrieval over scientific corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sparks of artificial general intelligence: Early experiments with GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LLM-based hypothesis generation (GPT-4 + retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses large pretrained transformer models (GPT-4 and successors) possibly augmented with retrieval over scientific papers to synthesize, compose, and generate candidate hypotheses, critiques, and research directions via neural text generation and reasoning in natural language (and structured forms via code/logic).</td>
                        </tr>
                        <tr>
                            <td><strong>research_domain</strong></td>
                            <td>general scientific research / biomedical examples mentioned</td>
                        </tr>
                        <tr>
                            <td><strong>problem_type</strong></td>
                            <td>open-ended ideation / hypothesis formulation / critique</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>feasibility_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimization_strategy</strong></td>
                            <td>Retrieval-augmented generation (suggested) and training on scientific corpora to ground outputs</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluation_results</strong></td>
                            <td>Authors report early experiments showing GPT-4 can formulate hypotheses and recommend directions, but no detailed human-evaluation results or numeric metrics are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparative_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparative_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_findings</strong></td>
                            <td>Authors speculate LLMs could synthesize original scientific concepts when trained and retrieval-augmented with millions of scientific papers, but note limitations in interpretability and control.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Computational Inflection for Scientific Discovery', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery <em>(Rating: 2)</em></li>
                <li>Solvent: A mixed initiative system for finding analogies between research papers <em>(Rating: 2)</em></li>
                <li>Scaling creative inspiration with fine-grained functional facets of product ideas <em>(Rating: 2)</em></li>
                <li>A search engine for discovery of scientific challenges and directions <em>(Rating: 2)</em></li>
                <li>On biases of attention in scientific discovery <em>(Rating: 2)</em></li>
                <li>Functional genomic hypothesis generation and experimentation by a robot scientist <em>(Rating: 1)</em></li>
                <li>Sparks of artificial general intelligence: Early experiments with GPT-4 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2417",
    "paper_id": "paper-6c5c6f883604a3abaa829b83d2958de8c343beeb",
    "extraction_schema_id": "extraction-schema-64",
    "extracted_data": [
        {
            "name_short": "Bridger",
            "name_full": "Bridger (novel author discovery system)",
            "brief_description": "An author-matching system that retrieves unfamiliar but relevant researchers to inspire new research directions by comparing extracted problem and method mentions from a user's papers to those of other authors.",
            "citation_title": "Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery",
            "mention_or_use": "use",
            "system_name": "Bridger",
            "system_description": "Represents a researcher's inner knowledge by automatically extracting mentions of problems and methods from their papers (weighted by term frequency). It retrieves other authors (outer knowledge) using the same representation, ranking candidate authors by measures of relevance and novelty (authors who work on similar problems but with different methods). Presented author 'cards' surface salient problems, methods and papers to stimulate cross-domain transfer and break fixation.",
            "research_domain": "general scientific research (computer science exemplars)",
            "problem_type": "interdisciplinary synthesis / open-ended ideation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "User studies with CS researchers reported dramatic boosts in creative search and inspiration relative to a state-of-the-art neural model in the Semantic Scholar search engine; improvements described qualitatively but no numeric novelty/feasibility scores reported in this paper.",
            "comparative_baseline": "State-of-art neural models employed by the Semantic Scholar search engine",
            "comparative_results": "Described as dramatically boosting creative search and inspiration over the Semantic Scholar neural baseline; no quantitative effect sizes provided here.",
            "domain_specific_findings": "Example evidence: surfaced cross-area connections (e.g., connecting graph theory work to human-centered AI) that inspired new directions; system intended broadly but evaluated with computer science researchers.",
            "uuid": "e2417.0",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Analogy mining / Solvent",
            "name_full": "Analogy mining (Solvent: mixed-initiative analogy-finding system)",
            "brief_description": "Methods that retrieve technological inventions or papers with partial structural similarity (mechanisms) to a user-provided invention description to enable analogical transfer and stimulate creative ideation.",
            "citation_title": "Solvent: A mixed initiative system for finding analogies between research papers",
            "mention_or_use": "use",
            "system_name": "Analogy mining (Solvent / structural-mechanism retrieval)",
            "system_description": "Extracts mechanism-level or functional representations from invention/paper texts and performs structural similarity retrieval across a corpus of inventions/technical literature, returning candidate inspirations with partial structural alignment to the query to facilitate transfer of solutions across distant domains.",
            "research_domain": "engineering / technological invention / general scientific research",
            "problem_type": "interdisciplinary synthesis / open-ended ideation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "Ideation experiments reported significant boosts in human creativity measures when users viewed inspirations retrieved by the analogy method versus baseline IR methods; specific numerical creativity metrics are not provided in this paper.",
            "comparative_baseline": "Baseline information retrieval methods",
            "comparative_results": "Method produced a significant boost over baseline IR in human ideation experiments (no numeric effect sizes reported here).",
            "domain_specific_findings": "Examples include a polymer stretching/folding lab finding inspiration in civil engineering literature (web crippling in steel beams), illustrating cross-domain transfer potential.",
            "uuid": "e2417.1",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Hierarchical problem graph retrieval",
            "name_full": "Hierarchical problem-graph based perspective retrieval",
            "brief_description": "A retrieval method that extracts problem mentions across a corpus to build a hierarchical problem graph and traverses neighboring problems to surface diverse problem perspectives for a focal user-described problem, aiming to inspire abstraction and reformulation.",
            "citation_title": "Scaling creative inspiration with fine-grained functional facets of product ideas",
            "mention_or_use": "use",
            "system_name": "Hierarchical problem-graph retrieval",
            "system_description": "Uses NLP to extract problem mentions from a corpus of technological invention texts, mines co-occurrence to build a hierarchical graph of related problems, and automatically traverses neighboring nodes around a focal user-provided problem description to retrieve diverse perspectives and potential reformulations.",
            "research_domain": "product design / engineering / technological invention",
            "problem_type": "open-ended ideation / problem reformulation",
            "novelty_metric": "Human judgments of usefulness and novelty for retrieved 'inspirations' (binary/annotated judgments aggregated as proportions).",
            "novelty_score": "Over 60% of retrieved 'inspirations' were judged useful and novel; reported as a relative boost of 50-60% compared to the best-performing baselines.",
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "Human study where more than 60% of inspirations were rated both useful and novel, representing a 50-60% improvement over the best baselines in those measures.",
            "comparative_baseline": "Best-performing baseline retrieval methods (unspecified)",
            "comparative_results": "Relative boost of 50-60% on the proportion of inspirations judged useful+novel versus baselines.",
            "domain_specific_findings": "Example: for the problem 'reminding patients to take medication', retrieved related problems (patient health tracking/alerting) provided useful inspiration; suggests method generalizes across consumer/biomedical adjacent problems.",
            "uuid": "e2417.2",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Challenges/discovery search engine",
            "name_full": "Search engine for discovery of scientific challenges and directions",
            "brief_description": "A prototype search engine that retrieves statements of uncertainties, open questions and hypotheses from the literature to help researchers identify problem areas and guide attention to challenges.",
            "citation_title": "A search engine for discovery of scientific challenges and directions",
            "mention_or_use": "use",
            "system_name": "Challenges / directions discovery search engine",
            "system_description": "Searches literature to extract and surface phrases/statements that express difficulties, uncertainties, open questions and hypotheses relevant to user queries, prioritizing content that highlights gaps or promising directions rather than established knowledge.",
            "research_domain": "biomedicine (demonstrated), general scientific research",
            "problem_type": "problem identification & prioritization / guiding attention",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": true,
            "human_evaluation_results": "User experiments (including medical doctors) showed the prototype outperformed PubMed at discovering important and interesting areas of challenges and directions; qualitative examples include surfacing hypotheses relating ACE2 to liver damage in COVID-19 that PubMed search did not emphasize.",
            "comparative_baseline": "PubMed",
            "comparative_results": "Described as dramatically outperforming PubMed in discovery of challenge/direction statements for query topics; no numeric performance metrics provided in the paper.",
            "domain_specific_findings": "Demonstrated in the biomedical domain (e.g., COVID-19 literature), effective at surfacing statements of uncertainty and nascent hypotheses rather than well-studied results.",
            "uuid": "e2417.3",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "PPI attention-bias analysis & reprioritization",
            "name_full": "Bias-debiasing methods for prioritizing protein-protein interactions (PPI)",
            "brief_description": "An analytical and reprioritization approach that studies temporal attention biases in the growth of confirmed PPI graphs and proposes methods to reprioritize candidate PPIs to surface overlooked but promising interactions.",
            "citation_title": "On biases of attention in scientific discovery",
            "mention_or_use": "use",
            "system_name": "PPI attention-bias analysis and reprioritization",
            "system_description": "Constructs a temporal dataset of confirmed PPIs, analyzes patterns (e.g., 'bias of locality' where studies focus near recently-studied proteins), and applies reprioritization heuristics based on protein properties to recommend underexplored candidate PPIs that might have been discovered earlier with debiasing.",
            "research_domain": "biology / molecular biology (protein interaction discovery)",
            "problem_type": "targeted exploration / prioritization of experiments",
            "novelty_metric": "Analysis of 'blindspots' in databases (qualitative/structural); prioritization evaluated by simulated earlier discovery (temporal simulation) rather than explicit novelty scores.",
            "novelty_score": null,
            "feasibility_metric": "Reprioritization based on properties of proteins (proxy for likelihood of discovery/feasibility); evaluation via demonstration that earlier discoveries could have been made under reprioritized rankings.",
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "Reprioritization heuristics informed by protein properties to counter locality bias",
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": "Actual historical exploration/prioritization (temporal baseline reflecting locality-driven research)",
            "comparative_results": "Study showed that debiasing/reprioritization mechanisms could have led to earlier discovery of certain PPIs compared to the historically observed sequence of exploration; specific numeric comparisons are not reported in this paper.",
            "domain_specific_findings": "Identified a strong 'bias of locality' in PPI discovery that creates systematic blindspots; demonstrates potential for computational reprioritization to surface overlooked biological interactions.",
            "uuid": "e2417.4",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Robot scientist",
            "name_full": "Robot Scientist (automated hypothesis generation and experimentation)",
            "brief_description": "A class of laboratory automation systems that formulate hypotheses, design and run experiments in the physical lab, and close the loop by incorporating experimental results to refine hypotheses.",
            "citation_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "mention_or_use": "mention",
            "system_name": "Robot scientist (automated experimental loop)",
            "system_description": "Combines curated domain knowledge (e.g., gene regulatory networks), hypothesis-induction methods, and robotic lab automation to generate hypotheses from data, design experiments to test them, execute experiments, and update models in a closed loop.",
            "research_domain": "biology / genomics / laboratory science",
            "problem_type": "targeted hypothesis generation and automated experimentation",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": null,
            "human_evaluation": null,
            "human_evaluation_results": null,
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Cited as prior work demonstrating closed-loop automated discovery in biology; presented as an exemplar of machines not only formulating hypotheses but also executing experiments.",
            "uuid": "e2417.5",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "GPT-4 / LLM-based hypothesis generation",
            "name_full": "GPT-4 (large language model) and LLM-based generation of hypotheses/directions",
            "brief_description": "Large language models (LLMs) such as GPT-4 are described as capable of formulating hypotheses, recommending research directions, and critiquing studies when coupled with retrieval over scientific corpora.",
            "citation_title": "Sparks of artificial general intelligence: Early experiments with GPT-4",
            "mention_or_use": "use",
            "system_name": "LLM-based hypothesis generation (GPT-4 + retrieval)",
            "system_description": "Uses large pretrained transformer models (GPT-4 and successors) possibly augmented with retrieval over scientific papers to synthesize, compose, and generate candidate hypotheses, critiques, and research directions via neural text generation and reasoning in natural language (and structured forms via code/logic).",
            "research_domain": "general scientific research / biomedical examples mentioned",
            "problem_type": "open-ended ideation / hypothesis formulation / critique",
            "novelty_metric": null,
            "novelty_score": null,
            "feasibility_metric": null,
            "feasibility_score": null,
            "tradeoff_evidence": null,
            "optimization_strategy": "Retrieval-augmented generation (suggested) and training on scientific corpora to ground outputs",
            "human_evaluation": null,
            "human_evaluation_results": "Authors report early experiments showing GPT-4 can formulate hypotheses and recommend directions, but no detailed human-evaluation results or numeric metrics are reported in this paper.",
            "comparative_baseline": null,
            "comparative_results": null,
            "domain_specific_findings": "Authors speculate LLMs could synthesize original scientific concepts when trained and retrieval-augmented with millions of scientific papers, but note limitations in interpretability and control.",
            "uuid": "e2417.6",
            "source_info": {
                "paper_title": "A Computational Inflection for Scientific Discovery",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery",
            "rating": 2
        },
        {
            "paper_title": "Solvent: A mixed initiative system for finding analogies between research papers",
            "rating": 2
        },
        {
            "paper_title": "Scaling creative inspiration with fine-grained functional facets of product ideas",
            "rating": 2
        },
        {
            "paper_title": "A search engine for discovery of scientific challenges and directions",
            "rating": 2
        },
        {
            "paper_title": "On biases of attention in scientific discovery",
            "rating": 2
        },
        {
            "paper_title": "Functional genomic hypothesis generation and experimentation by a robot scientist",
            "rating": 1
        },
        {
            "paper_title": "Sparks of artificial general intelligence: Early experiments with GPT-4",
            "rating": 1
        }
    ],
    "cost": 0.014521,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Computational Inflection for Scientific Discovery</h1>
<p>Tom Hope<br>tomh@allenai.org<br>The Allen Institute for AI<br>The Hebrew University of Jerusalem</p>
<p>Doug Downey<br>dougd@allenai.org<br>The Allen Institute for AI<br>Northwestern University</p>
<h2>Oren Etzioni</h2>
<p>oren@allenai.org
The Allen Institute for AI</p>
<h2>Daniel S. Weld</h2>
<p>danw@allenai.org
The Allen Institute for AI
The University of Washington</p>
<h2>Eric Horvitz</h2>
<p>horvitz@microsoft.com
Office of the Chief Scientific Officer
Microsoft
of possibility. The way we search through and reflect about information across the vast space-the areas we select to explore, and how we explore them-is hindered by cognitive biases [26] and lacks principled and scalable tools for guiding our attention [32]. "Unknowns" are not just holes in science, but important gaps in personal knowledge about the broader knowns across the sciences.</p>
<p>We thus face an imbalance between the treasure trove of scholarly information and our limited ability to reach into it. Despite technological advances, we require new paradigms and capabilities to address this widening gap. We see promise in developing new foundational capabilities that address the cognitive bottleneck, aimed at extending human performance on core tasks of researche.g., keeping abreast with developments, forming and prioritizing ideas, conducting experiments, reading and understanding papers (see Table 1). We focus on a research agenda we call task-guided scientific knowledge retrieval, in which systems counter humans' bounded capacity by ingesting corpora of scientific knowledge and retrieving inspirations, explanations, solutions and evidence synthesized to directly serve task-specific utility. We present key concepts of task-guided scientific knowledge retrieval, including work on prototypes that highlight the promise of the direction and bring into focus concrete steps forward for novel representations, tools, and services. In Section 4 we review systems that help researchers discover novel perspectives and inspirations [8, 9, 11, 29], help guide the attention of researchers toward opportunity areas rife with uncertainties and unknowns [18, 32], and models that leverage retrieval and synthesis of scientific knowledge as part of machine learning and prediction [6, 24]. We conclude in Section 5 with a discussion of opportunities ahead with computational approaches that have the potential to revolutionize science.</p>
<p>To set the stage, in the following section we begin by discussing some fundamental concepts and background for our research agenda.</p>
<h2>3 HUMAN-CENTRIC PERSPECTIVE</h2>
<p>Extraordinary developments at the convergence of AI and scientific discovery have emerged in specific areas, including new kinds of analytical tools, with the prominent example of AlphaFold, which harnesses deep neural models to dramatically improve the prediction of protein structure from amino acid sequence information [15]. Large language models (LLMs) have very recently made stellar progress in the ability to reason about complex tasks, including in the medical domain [25]. The most advanced LLM at presentemerging before the ink has dried on this paper-is GPT-4, which</p>
<table>
<thead>
<tr>
<th>Task/Activity</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Attention to areas of interest</td>
<td>A background process of keeping track of latest developments in relevant scientific communities.</td>
</tr>
<tr>
<td></td>
<td>Involves applying selective attention, perceiving relevance and utility.</td>
</tr>
<tr>
<td>Problem identification &amp; prioritization</td>
<td>Identifying new research questions and deciding on which ones to work. Involves factors such as</td>
</tr>
<tr>
<td></td>
<td>subjective preferences and assessment of feasibility.</td>
</tr>
<tr>
<td>Forming directions</td>
<td>Given a problem/question, forming ideas to address it. Involves cognitive processes such as</td>
</tr>
<tr>
<td></td>
<td>constructing mental models of a problem, problem reformulation, abstraction and decomposition,</td>
</tr>
<tr>
<td></td>
<td>adaptation of relevant knowledge to new scenarios, and assessing likelihood of success.</td>
</tr>
<tr>
<td>Literature search &amp; review</td>
<td>Accessing and ingesting knowledge in the literature. Involves many processes such as query</td>
</tr>
<tr>
<td></td>
<td>formulation, skimming and assessing relevance, positioning ideas with relations and contrasts to</td>
</tr>
<tr>
<td></td>
<td>existing work, and reading and summarization strategies.</td>
</tr>
<tr>
<td>Learning, understanding, sense-making</td>
<td>The cognitive processes and activities involved in assimilating new knowledge and concepts, and</td>
</tr>
<tr>
<td></td>
<td>making sense of complex scientific information spaces.</td>
</tr>
<tr>
<td>Experimentation, analysis, action</td>
<td>A broad category referring to the many processes and activities involved in formulating and</td>
</tr>
<tr>
<td></td>
<td>conducting experiments (e.g., planning data collection and measurements), performing analyses</td>
</tr>
<tr>
<td></td>
<td>(e.g., understanding a set of data points, modeling and extrapolation, prediction, evaluation), and</td>
</tr>
<tr>
<td></td>
<td>producing artifacts, techniques, theories, decisions, policies, actions.</td>
</tr>
<tr>
<td>Research communication</td>
<td>Writing research documents (papers, proposals, analyses), communicating with peers (feedback</td>
</tr>
<tr>
<td></td>
<td>and review, collaboration, presentation).</td>
</tr>
</tbody>
</table>
<p>Table 1: Research may be decomposed into salient tasks that are prime targets for computational augmentation ( 4).</p>
<p>has exhibited jaw-dropping skill at handling clinical questions, mathematical problems and computer coding tasks [1].</p>
<p>We view these developments as tremendous research opportunities for building computational approaches that accelerate scientific discovery. We take a human-centered, cognitive perspective: augmenting researchers by taking into account the diversity of tasks, contexts, and cognitive processes involved in consuming and producing scientific knowledge. Collectively, we refer to these as the inner cognitive world of a researcher (see Figure 1). The researcher interacts with the scientific ecosystemliterature, resources, discussionsin order to inform decisions and actions. Researchers have different uses for scholarly information, depending on the task at hand and the stage of exploration (see Table 1 and discussion in Section 4). We pursue a research agenda around assisting researchers in their tasks, guided by two main desiderata:</p>
<p>(1) Systems for augmenting human capabilities in the sciences need to enhance the effective flow of knowledge from the outer world of scientific information and discourse to the researchers inner cognitive worldcountering humans bounded capacity by retrieving and synthesizing information targeted to enhance performance on tasks. Achieving this goal requires methods that build and leverage rich representations of scientific content and that can align computational representations with human representations, in the context of specific tasks and backgrounds of researchers.</p>
<p>(2) Research on such systems should be rooted in conceptual models of the inner cognitive world of a researcher. Shining a spotlight on this inner world brings numerous factors and questions to the fore. How do researchers form ideas? How do they decide which problems to look into? How do they find and assimilate new information in the process of making decisions? What cognitive representations and bottlenecks are involved? What computing services would best augment these processes?</p>
<p>Figure 1: Information flows from the outer world into the inner cognitive world of researchers, constrained by cognitive capacity and biases. We see opportunities to support researchers by retrieving knowledge that helps with tasks across multiple phases of the scientific process (Table 1).</p>
<p>Background and Related Themes. We leverage research in natural language processing, information retrieval, data mining and human-computer interaction and draw concepts from multiple disciplines. For example, efforts in metascience focus on sociological factors that influence the evolution of science [17], e.g., analyses of information silos that impede mutual understanding and interaction [38], analyses of macro-scale ramifications of the rapid growth in scholarly publications [4], and of current metrics for measuring impact [5]  work enabled by digitization of scholarly corpora (see Section 3.1). Metascience research makes important observations about human biases (desideratum 2) but generally does not engage in building computational interventions to augment researchers (desideratum 1). Conversely, work in literature-based discovery [33] mines information from literature to generate new predictions (e.g., functions of materials or drug targets) but is typically done in isolation from cognitive considerations; however, these techniques have great promise in being used as part of human-augmentation</p>
<p>(2) Research on such systems should be rooted in conceptual models of the inner cognitive world of a researcher. Shining a spotlight on this inner world brings numerous factors and questions to the fore. How do researchers form ideas? How do they decide which problems to look into? How do they find and assimilate new information in the process of making decisions? What cognitive representations and bottlenecks are involved? What computing services would best augment these processes?</p>
<p>systems (see Sections 4-5). Other work uses machines to automate aspects of science. Pioneering work from Herbert Simon and Pat Langley automated discovery of empirical laws from data, with models inspired by cognitive mechanisms of discovery (see Section 3.2). More recent work has focused on developing robot scientists [16, 30] that run certain experiments in biology or chemistry-not only formulating hypotheses but "closing the loop" by automated tests in a physical laboratory-where robots may use narrow curated background knowledge (e.g., of a specific gene regulatory network) and machine learning to guide new experiments. Related work explores automating scientific data analysis [6], which we discuss in Section 4 as a case of retrieval from scientific repositories to augment aspects of experimentation and analysis (see Table 1).</p>
<p>We now turn to a discussion of central concepts: the ecosystem of science, and the cognitive world. This presentation lays the foundations for our exposition of task-guided retrieval in Section 4 and the research opportunities in Section 5.</p>
<h3>3.1 Outer World: Scientific Ecosystem</h3>
<p>We collectively name the scientific ecosystem and the digital representations of scientific knowledge as the outer world (see Figure 1). The outer world is comprised of scientific communities, a complex and shifting web of peers, concepts, methodologies, problems and directions revolving around shared interests, understandings and paradigms. This ecosystem generates digital information-digital "traces" of scientific thought and behavior-lying at the center of our attention as computer scientists interested in boosting human capacity to "reach into" the pool of scientific knowledge. This knowledge includes scholarly publications that appear in journals, conference proceedings, and online preprint repositories. Online publications are a main case of digital research artifacts; other examples of products of research include software, datasets, knowledge bases. Research artifacts are also associated typically with signals of quality and interest, such as citations to a specific paper or downloads of a dataset. The specific context of why a paper or resource was cited or used is often reflected in natural language descriptions. Different types of signals include peer review prior to publication (mostly not shared publicly), and social media discussions such as on Twitter, which has become a major virtual platform for academic dissemination and conversation. Along with the trend in society, private communication channels among researchers are also digital-mails, online calls and messages. Similarly, note taking and writing-important activities across the scientific workflow-are done in digital form. This information is siloed in different platforms under privacy restrictions, yet represents a treasure trove for tools for the augmentation of scientific reasoning and exploration.</p>
<h3>3.2 Inner World: Human Cognition in Science</h3>
<p>The way researchers decide to interact with information in the outer world and the way they process and use this information is governed by a complex array of cognitive processes, personal knowledge and preferences, biases and limitations, which are only partially understood. We collectively name these the inner world, and briefly discuss several salient aspects.</p>
<p>Early work in AI by Herbert Simon and Alan Newell and later efforts by Pat Langley and Paul Thagard focused on cognitive and
computational aspects of problem solving, creativity, decision making and scientific reasoning and discovery, seeking algorithmic representations to help understand and mimic human intelligence [19, 36]. Cognitive mechanisms that play important roles in scientific discovery include inductive and abductive reasoning, mental modeling of problems and situations, abstraction, decomposition, reformulation, analogical transfer and recombination; for example, in analogical transfer, given a situation or problem being considered in our working memory, we retrieve from our long-term memory prior analogous problems or situations.</p>
<p>This cognitive machinery powers humans' ingenuity. However, the human mind also has severe limitations-bounded rationality in the words of Simon-that impede these powerful mechanisms. Our limitations and capabilities have been studied for over a hundred years with cognitive psychology. Our limitations manifest in bounded cognitive capacity and knowledge, and biases that govern our behaviors and preferences. These limitations are all tightly interrelated. The ability to generate ideas, for instance, directly relies on prior knowledge; but, when a large volume of information from the outer world of science is met by insufficient cognitive capacity for processing and assimilating it, the result is information overload-a ubiquitous hindrance for researchers [29]. Information overload in science strains the attentional resources of researchers, and forces researchers to allocate attention to increasingly narrow areas. This effect, in turn, amplifies a host of biases which researchers, just like all humans, suffer from [26, 32]. For example, scientists can be limited by confirmation bias, aversion to information from novel domains, homophily, and fixation on specific directions and perspectives without consideration of alternative views [11, 26]. More broadly, selection of directions and areas to work on is a case of decision-making, and as such personal preference and subjective utility play fundamental roles. Our research decisions rely on subjective assessment of feasibility, long-term or short-term goals and interests, and even psychological factors (e.g., tendencies for risk aversion). These factors are of course also impacted by biases [26].</p>
<p>Clearly, the inner world of researchers is dauntingly complex. However, in the next section, we present encouraging results of applying computational methods to augment cognition in the sciences, helping to mitigate biases and limitations and enabling researchers to make better use of their powerful creative mechanisms.</p>
<h2>4 TASK-GUIDED RETRIEVAL</h2>
<p>How might we widen and deepen the connection between the outer world of science and researchers' limited cognitive worlds? We see a key bridge and research opportunity with developing tools for scientific task-guided knowledge retrieval. In this section, we discuss our vision and present initial work toward achieving it.</p>
<p>Drawing from discussions in literature on the process of scientific discovery, we enumerate in Table 1 salient scientific tasks and activities, such as problem identification, forming directions, learning, literature search and review, experimentation. These tasks could benefit from augmentation of human capabilities but remain underexplored in computer science. Existing computational technologies for assisting humans in discovering scientific knowledge are underinvested in important aspects of the intricate cognitive processes and goal-oriented contexts involved in scholarly endeavors.</p>
<p>The dominant approach to information retrieval research and systems can be summarized as "relevance first"-focusing on results that answer user queries as accurately as possible. Academic search engines assume users know what queries to explore and how to formulate them. For pinpointed literature search in familiar areas, this assumption may often suffice; but a broad array of other scholarly tasks, such as ideation or learning about a new topic, are very much underserved [9-11, 18, 29]. At the same time, many voices in the information retrieval community have discussed a different, broader view of utility-driven search situated in a wider context of information seeking by users with specific intents and tasks [31]. Here, we adapt ideas and principles from this general paradigm.</p>
<p>We envision methods for task-guided scientific knowledge retrieval: systems that retrieve and synthesize outer knowledge in a manner that directly serves a task-guided utility of a researcher, while taking into consideration the researcher's goals, state of inner knowledge, and preferences.</p>
<p>Consider the tasks in Table 1. For researchers engaged in experimentation or analysis, we envision systems that help users identify experiments and analyses in the literature to guide design choices and decisions. For researchers in early stages of selecting problems to work on, we picture systems that support this decision with information from literature and online discussions, synthesized to obtain estimated impact and feasibility. As part of forming directions to address a problem, systems will help users find inspirations for solutions. Researchers who are learning about a new topic will be provided with retrieved texts and discussions that explain the topic in a manner personally tailored to personal knowledge. Importantly, task-guided knowledge retrieval follows the two desiderata introduced in Section 3; namely, systems should enable users to find knowledge that directly assists them in core research tasks by augmenting their cognitive capacity and mitigating their biases, and computational representations and services should align with salient cognitive aspects of the inner world of researchers.</p>
<h3>4.1 Prototypes of Task-Guided Retrieval</h3>
<p>We present work on initial steps and prototypes, including representative work that we have done and the work of others, framed in alignment with task-guided knowledge retrieval and tasks enumerated in Table 1. The main aim of this brief review is to stimulate discussion in the computer science community on tools for extending human capabilities in the sciences. Existing methods are far from able to realize our vision. For example, we see major challenges in representation and inferences about the inner world of knowledge and preferences, and aligning these with representations and inferences drawn from the outer world knowledge. Today's prototypes are limited examples of our vision, using very rough proxies of inner knowledge and interest based on papers and documents written or read by the user, or in some cases only a set of keywords. We discuss these research challenges and others in Section 5.</p>
<p>Forming Directions. We have developed methods for helping researchers generate new directions. A fundamental pattern in the cognitive process of creativity involves detecting abstract connections across ideas and transferring ideas from one problem to another [36]. Grounded in this cognitive understanding, we have pursued several approaches for stimulating creativity powered by
retrieving outer knowledge. We developed and studied a system named Bridger that connects researchers to peers who inspire novel directions for research [29]. Bridger identifies matches among authors based on commonalities and contrasts, identifying peers who are both relevant and novel-working on similar problems but using very different methods, potentially inspiring new solutions. By doing so, Bridger helps mitigate the cognitive bias of fixation [11].</p>
<p>In this setting, inner knowledge is represented as mentions of problems and methods extracted automatically from a researcher's papers and weighted by term frequency. The outer knowledge being retrieved takes the form of other authors in computer science, following the same representation. For each retrieved author, the system displays salient problems, methods and papers, ranked by measures of relevance to the user. In studies with CS researchers, we found that Bridger dramatically boosted creative search and inspiration over state-of-art neural models employed by the Semantic Scholar search engine, surfacing useful connections across diverse areas; for example, one researcher drew novel connections between the mathematical area of graph theory and their own area of human-centered AI, by exploring a recommended author who applies graph theory to decision making. The studies also surfaced important challenges, discussed in Section 5.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: Matching researchers to authors with whom they are unfamiliar, to help in generating directions. Author cards show key problems and methods extracted from their papers.</p>
<p>We have also explored retrieving outer knowledge to enhance the human ability to find opportunities for analogical transfer [3, 8]. Extensive work in cognitive studies has highlighted the human knack for "analogical retrieval" as a central function in creativitybringing together structurally related ideas and adapting them to a task at hand [36]. We developed a search method that enables researchers to search through a database of technological inventions and find mechanisms that can be transferred from distant domains to solve a given problem. Given as input from the user a textual description of an invention, we retrieve ideas (inventions, papers) that have partial structural similarity to the input (e.g., inventions with similar mechanisms), to facilitate discovery of analogical transfer opportunities. We found that the method could significantly boost measures of human creativity in ideation experiments, in which users were asked to formulate new ideas after viewing inspirations retrieved with our approach versus baseline information retrieval methods. For example, a biomechanical engineering lab working on polymer stretching/folding for creating novel structures found useful inspiration in a civil engineering paper on web crippling in steel beams-abstractly related to stretching and folding.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Using an extracted hierarchy of problems to retrieve new perspectives on a focal problem of interest.</p>
<p>Innovation may also involve traversing multiple levels of abstraction around a problem to "break out" of fixation on the details of a specific problem by exploring novel perspectives. Given as input a problem description written by the user (as a proxy summary of the user's inner world of knowledge and purpose), we have pursued mechanisms that can retrieve diverse problem perspectives that are related to the focal problem, with the goal of inspiring new ideas for problem abstraction and reformulation [11] (see Figure 3). Using NLP models to extract mentions of problems, we mine a corpus of technological invention texts to discover problems that often appear together, and use this information to form a hierarchical problem graph that supports automatic traversal of neighboring problems around a focal problem, surfacing novel inspirations to users. In a study of the efficacy of the methods, over $60 \%$ of "inspirations" retrieved this way were found to be useful and novel-a relative boost of $50-60 \%$ over the best-performing baselines. For example, given an input problem of reminding patients to take medication, our system retrieves related problems such as in patient health tracking and alerting devices.</p>
<p>Guiding attention and problem identification. We see great opportunity in developing methods for guiding the attention of researchers to important areas in the space of ideas where there exists less knowledge or certainty [18, 32] (Figure 4). In one direction, we built a search engine that allows users to retrieve outer knowledge in the form of difficulties, uncertainties and hypotheses in the literature. The key goals of this mode of search are to bolster attention to rising and standing challenges of relevance to the user so as to help overall with identification and selection of problems. We performed experiments with participants with diverse research backgrounds, including medical doctors working in a large hospital. Using query topics as a proxy for the inner world of participants' interests, we found the system could dramatically outperform PubMed search, the go-to biomedical search engine, at discovering important and interesting areas of challenges and directions. For example, while searching PubMed for the ACE2 receptor in the context of COVID19 returns well-studied results, the prototype system by contrast focuses on finding statements of uncertainty, open questions and initial hypotheses, like a paper noting the possibility that ACE2 plays a role in liver damage in COVID-19 patients.</p>
<p>Another direction on biases and blindspots considers the longterm effort to identify protein-protein interactions (PPIs). A dataset of the growing graph of confirmed PPIs over decades was constructed and leveraged to identify patterns of scientific attention [32]. A temporal analysis revealed a significant "bias of locality," where explorations of PPIs are launched more frequently from those that were most recently studied, rather than following more general prioritization of exploration. While locality reflects an understandable focus on adjacent and connected problems in the biosciences, the pattern of attention leads to systematic blindspots in large,</p>
<p>Input:
Items of interest (concepts, entities, topics...)
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Suggesting research opportunities for query concepts (e.g., medical topics) by identifying blindspots, gaps in collective knowledge and promising areas for exploration.
widely used PPI databases that are likely unappreciated-further exacerbating attentional biases. The study further demonstrated mechanisms for reprioritizing candidate PPIs based on properties of proteins, and showed how earlier discoveries could be made with use of the debiasing methods. The findings underscore the promise of tools that retrieve existing outer world knowledge to guide attention to worthwhile directions. In this case, the outer knowledge source is a PPI database, and a user-selected sub-graph provides a proxy for inner world knowledge and interests.</p>
<p>Literature search and review. A great body of work on literature search and review has deep relevance to task-guided retrieval in the sciences. In particular, we see great opportunity with building on recent advances in information retrieval to (1) help biomedical researchers with domain-specific representations and (2) enhance scientific search by building new neural models.</p>
<p>Specialized search systems have been developed for the biomedical domain, with the overall vision of harnessing natural language understanding technologies to help researchers discover relevant evidence and expedite the costly process of systematic literature review [27]. For example, Nye et al. [27] build a search and synthesis system based on automated extraction of biomedical treatmentoutcome relations from clinical trial reports. The system is found to assist in identification of drug repurposing opportunities. As another recent example, the SPIKE system enables researchers to extract and retrieve facts from a corpus using an expressive query language with biomedical entity types and new term classes that the user can define interactively [34]. Together, this work underscores the importance of extracting a semantically meaningful representation of outer world knowledge that aligns with core aspects of inner world reasoning by researchers (see Section 5).</p>
<p>In separate work, neural language models built via self-supervision on large corpora of biomedical publications have recently led to performance boosts and new features in literature search systems [39], such as support for natural language queries that provide users with a more natural way to formulate their informational goals. Neural models have also been trained to match abstract discourse aspects of pairs of papers (e.g., sentences referring to methodologies) and</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Leveraging medical corpora to enhance the precision of AI models for inference about patient outcomes.
automatically retrieve documents that are aspectually similar [23]. By employing a representation that aligns with scientific reasoning across areas, this method achieves state-of-art results across biomedical and computer science literature.</p>
<p>Experimentation, analysis, and action. Beyond helping researchers via awareness and knowledge, we see great opportunities to use scientific corpora to construct task-centric inferential systems with automated models and tools for assisting with analysis, prediction and decisions. We demonstrate these ideas by casting two different lines of work as cases of task-guided retrieval.
(1) Workflows are multi-step computational pipelines used as part of scientific experimentation for data preparation, analysis and simulation [6]. Technically this includes execution of code scripts, services and tools, querying databases and submitting jobs to the cloud. In the life sciences, in areas such as genomics, there are specialized workflow management systems to help researchers find and use workflows, enabled by a community that creates and publicly shares repositories of workflows with standardised interfaces, metadata and functional annotations of tools and data. As discussed in Gil [6], machine learning algorithms can potentially use these resources to automate workflow construction, learning to retrieve and synthesize data analysis pipelines. In this setting, outer world knowledge takes the form of workflow repositories, from which systems retrieve and synthesize modular building blocks; users' inner world is reflected via analysis objectives and constraints.
(2) In our work on clinical predictions [24], the goal is to enhance prediction of medical outcomes of patients hospitalized in the intensive care unit (ICU), such as in-hospital mortality or prolonged length of stay. Our system, named BEEP (biomedical evidence enhanced prediction), learns to perform predictions by retrieving medical papers that are relevant to each specific ICU patient, and to synthesize this outer knowledge in combination with internal EMR knowledge to form a final prediction. The primary envisaged user is a practice-oriented researcher-a medical doctor, whose inner knowledge is given by a rough proxy in the form of internal clinical notes from which we extract "queries" issued over medical papers. We find BEEP to provide large improvements over state-of-art models that do not use retrieval from the literature. BEEP's output can
be aligned with inner world representations, e.g., matches between patient aspects and related cohorts in papers (see Figure 5).</p>
<p>Learning and understanding. We introduced a system [22] for helping users learn about new concepts by showing definitions grounded in familiar concepts; e.g., a new algorithm is explained as a variant of an algorithm familiar to the user. Cognitive studies have asserted that effective descriptions of a new concept ground it within the network of known concepts. Our system takes as input a list of source concepts reflecting the user's inner knowledge as obtained from papers that they have written or read. When the user seeks a definition of a new target concept, we retrieve outer knowledge in the form of definitions appearing in scientific papers in which the target concept is explained in terms of the source concepts; a neural text generation model then re-writes the text in a structured, template form that relates the target to the source.</p>
<h2>5. OPPORTUNITIES AHEAD</h2>
<p>The challenges of task-guided retrieval in support of researchers frame a host of problems and opportunities. We discuss select challenges and directions (see also Table 2). We begin with an illustrative example, imagining a futuristic system to motivate the discussion.</p>
<h3>5.1. Aspirations</h3>
<p>We envision tools that flow outer world knowledge to researchers based on inferences about their inner world-users' knowledge, past and present goals and difficulties, and the tasks from Table 1 they are engaged in. The systems would use multiple signals for making inferences, including users' papers, data, experiments and communication channels, and also converse with the user to understand needs and suggest solutions, hypotheses and experiments.</p>
<p>We foresee systems powered by rich representations of both inner and outer scientific knowledge. For a given concept, e.g., a certain algorithm or organism, an aspirational system would ingest all papers on the subject to form a multi-faceted representation of concepts as objects with associated properties and functions. Using this representation, the system could assist in literature search and review, enabling expressive queries to outer world information that target abstract aspects like functionalities, mechanisms, behaviors and designs in a manner that transcends field-specific jargon, abstracting away lexical differences that hindered historical search engines (e.g., Google Scholar). To help users learn and understand new concepts they encounter, the system would explain them in relation to other concepts the user already knows. A future system might also assist in automating experimentation, analysis and action and in forming directions, by forming compositions of concepts and predicting the resultant affordances; for example, matching a certain algorithm with a suitable problem based on the algorithm's properties and the problem's requirements, matching an organism with a specific method of measurement or modification, or recombining parts of two devices to form a new device. The system could help identify related problems in the literature, synthesizing from them useful suggestions for problem reformulations. Considering the huge combinatorial space of potential suggestions, a system could assist in prioritization using estimated measures of interestingness, feasibility and value by synthesizing historical and current signals in literature, online discussions and knowledge bases.</p>
<p>Envisioned systems would be designed as human-centric, focusing on the individual researcher. The systems would enable users to convey preferences, goals and interests, and mediate the presentation of suggested directions and problem solutions based on personal prior knowledge, proposing concrete new directions grounded in representations that researchers can follow, and assisting users in reading complex retrieved texts by editing their language to conform with concepts that users are familiar with.</p>
<h3>5.2 Research Directions</h3>
<p>While we have witnessed remarkable strides in AI, the journey towards actualizing our vision requires further advancement. Envisioning such capabilities, however, can serve as a compass for directing research endeavors. An encouraging development can be seen in the recent developments with large language models, which have demonstrated surprising capabilities with interpreting and generating complex texts and tackling technical tasks. The proficiencies demonstrated by these models instills confidence that many of the possibilities that we discussed are attainable. We now elaborate on challenges and directions ahead, including limitations in representing scientific knowledge and making inferences about the inner worlds of researchers (see Table 2).</p>
<p>Task-aligned representations and scientific NLP. Paul Thagard writes: "thinking can best be understood in terms of representational structures in the mind and computational procedures that operate on those structures". We seek representations that can be aligned with human thinking-for insight-building, decision making and communication. Can we go beyond textual representation toward representations that support such cognitive processes?</p>
<p>The quest for a universal schema representing scientific ideas goes back hundreds of years. Gottfried Leibniz and Ren Descartes were intrigued by the prospects of a universal codification of knowledge. Leibniz proposed the characteristica universalis, a hypothesized formal language of ideas enabling inferences with algebraic operators. While such a representation is not within reach, envisioning its existence-and how to even roughly approximate it-points to important research directions. One exciting direction is obtaining representations that support a "computational algebra of ideas"e.g., modeling compositions of concepts and the affordances that would be formed as a result. Early work on learning vector representations of natural language concepts supported rudimentary forms of addition, subtraction, and analogy (e.g., the Word2vec model).</p>
<p>Recently, large language models (LLM) [28] have made striking progress in generating new content and coherently combining concepts. Emerging evidence on GPT-4's ability to reason not only in unstructured language but also with logical structures grounded in code, suggests strong potential for generating novel ideas via compositionality and relational reasoning [1]. Our early experiments with GPT-4 have revealed a constellation of promising abilities to assist with the scientific process, such as formulating hypotheses, recommending future research directions, and critiquing studies. Equipped with training and retrieval with access to millions of scientific papers, descendants of today's models may have an ability to synthesize original scientific concepts with the in-depth technical detail at a level reported in high-quality scientific papers. We see great opportunity ahead to leverage LLMs to augment human scientific reasoning along the lines described in this paper.</p>
<p>One limitation with LLMs is that representations learned by these models are currently far from understood and lack "hooks" for control and interpretability, which are important in human-AI collaboration. In line with our focus on grounding representations of outer world knowledge with inner world cognitive aspects, we have pursued methods that "reverse engineer" scientific papers to automatically extract, using NLP, structured representations that balance three desiderata:
(1) Semantically meaningful representations, aligned with a salient task from the tasks in Table 1, grounded in cognitive research to guide us toward useful structures.
(2) Representations with sufficient level of abstraction to generalize across areas and topics.
(3) Representations expressive enough for direct utility in helping researchers as measured in human studies.</p>
<p>For example, we have extracted representations of causal mechanisms and hierarchical graphs of functional relationships. This kind of decomposition of ideas has enabled us to perform basic analogical inference in the space of technological and scientific ideas, helping researchers discover inspirations (see Section 4). However, many richer structures should be explored (e.g., of experimentation processes and methodologies, to enable tasks in Table 1).</p>
<p>A central challenge is that current models' extraction accuracy is limited, and the diversity of scientific language leads to problems in generalization and normalization of terms and concepts. We have pursued construction of new datasets, models and evaluations for identifying similarity between concepts and aspects across papers [2, 23], with fundamental problems in resolving diversity, ambiguity and hierarchy of language. As our results have highlighted, models tend to focus on surface-level lexical patterns, rather than deeper semantic relationships. Generally, substantial advances are needed to handle challenges posed by scientific documents. We require NLP models with full-document understanding, not only of text but of tables, equations, figures, and reference links. Open access corpora (e.g., S2ORC [20]) provide a foundation to address this challenge.</p>
<p>New modes of writing and reading. Perhaps the way we write can be dramatically different, using machine-actionable representations? Beyond reporting and documentation, writing represents a channel between the inner and outer worlds, forcing us to communicate ideas in concrete language; this process often begets new questions and perspectives. Can systems accompany different phases of writing, suggesting new ideas? In parallel, there is the task of reading what others have written; a recent interactive PDF reader offers, for example, customized concept definitions [7]. We imagine a future where every reader will see a different form of the same paper, re-written to align with readers' knowledge; e.g., our personalized concept definitions system [22] (4) will insert new wording and explanations grounded in readers' knowledge.</p>
<p>Internal world of researchers. Grounding new concepts in readers' knowledge, suggests a wider and highly challenging problem. How can we enable researchers to specify their knowledge and preferences to direct systems to carry out tasks? Directly querying for these aspects burdens the researcher and may be prone to reporting biases. Digital traces present an opportunity for automatically estimating a researcher's knowledge, objectives, needs and interests-based on data. We are interested in using researchers'</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Challenge</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Task-aligned representations, scientific NLP</td>
<td style="text-align: left;">How can we automatically and accurately extract conceptual representations of scientific <br> knowledge, that are aligned with tasks that comprise the endeavor of science (Table 1)? How <br> can we build NLP models that understand full scientific papers?</td>
</tr>
<tr>
<td style="text-align: left;">Computational algebra of ideas</td>
<td style="text-align: left;">Can we build representations of scientific knowledge that support composition of ideas? e.g., <br> inferring the result of recombining two concepts.</td>
</tr>
<tr>
<td style="text-align: left;">Identifying conceptual relationships across <br> literature</td>
<td style="text-align: left;">How do we detect important relationships across scientific ideas, across related discussions <br> in different communities and areas? How can we resolve challenges of diversity, ambiguity, <br> and multiple levels of detail in scientific language?</td>
</tr>
<tr>
<td style="text-align: left;">Estimation of personal knowledge</td>
<td style="text-align: left;">How can we estimate the knowledge of a given researcher? What are useful, practical models <br> of this knowledge? What concepts does a researcher know, which of their aspects, and to <br> what technical extent? How do we account for latent knowledge?</td>
</tr>
<tr>
<td style="text-align: left;">Addressing gaps in knowledge</td>
<td style="text-align: left;">Given an estimated model of a researcher's knowledge, and given a specific task in Table 1, <br> what new knowledge would be useful for the task at hand?</td>
</tr>
<tr>
<td style="text-align: left;">Estimation of preferences, goals, interests</td>
<td style="text-align: left;">How can we estimate key latent preferences, interests and subjective utilities of researchers? <br> Using information in papers and discussions to infer factors behind researchers' choices.</td>
</tr>
<tr>
<td style="text-align: left;">Prediction and prioritization</td>
<td style="text-align: left;">How might we identify promising sparse/unexplored areas in large "spaces of ideas" and <br> prioritize directions that are novel, plausible and valuable?</td>
</tr>
<tr>
<td style="text-align: left;">Developing new representations for learning <br> and communicating</td>
<td style="text-align: left;">Might the way we read and write papers change to be more effective? Might we communicate <br> with machine-actionable, interlinked representations of scholarly knowledge. Might we <br> create personalized "living" documents that tailor their content to readers' backgrounds.</td>
</tr>
</tbody>
</table>
<p>Table 2: Directions with formulating and leveraging computational representations of scientific knowledge.
papers to estimate what concepts users know and to what extent. We envision mixed-initiative interfaces [12] in which approximations of the inner world are presented to researchers and refined in human-machine collaboration, to identify and fill personal gaps in knowledge for a specific task. Representations of interest and preference are central in web commerce based on user activity histories. We are encouraged by results highlighting the feasibility of rich user models, e.g., in search personalization [31, 35] and dynamic inferences [14]. Paul Samuelson wrote of "revealed preferences"preferences revealed indirectly by the economic price people are willing to pay; while not equivalent, researchers' digital traces may reveal preferences, e.g., by working on one problem and not another.</p>
<p>Prediction and prioritization of directions. Whenever we decide to work on a research direction, we are implicitly making a prediction about an area in "idea space". Can automated systems help make these predictions? This involves identifying promising areas and generating directions-hypotheses, ideas-in either natural or structured language, under constraints on users' background knowledge; directions should be ranked by estimated likelihood (feasibility, plausibility), utility and novelty. Despite the great challenges involved, we are encouraged by advances in models trained for predicting specific targets (e.g., protein structures [15]); we see potential in building on these advances as part of our wider agenda that considers the inner world of cognitive aspects and tasks, and the outer world outside the context of a narrow dataset.</p>
<p>Pursuing challenges of translation. Finally, we note challenges for introducing new technologies into scientific workflows. In the context of systems for discovery, researchers interviewed in our studies [29] reported being limited in time and resources, making them less likely to enter new areas and learn unfamiliar concepts, preventing them discovering potentially promising ideas. More broadly, the sociotechnical environment in which AI models
are deployed has critical impact on their success [13, 21]. A pertinent example comes via reports on difficulties with translating IBM's Watson Health systems into practice. The vision of the effort included systems providing insights about patients by mining research papers to suggest, e.g., therapies or diagnostics [21]. A prototype system faced difficulties ranging from data processing and availability problems to deeper perceived gaps between the system's understanding of literature and that of physicians [37]. Challenges such as these are fundamental to the fielding of new applications not only in healthcare but in any setting where humans are required to interact with AI systems [40]. While issues such as data quality and privacy are orthogonal to our agenda, we see directions in modeling of human needs and limitations to inform the design of human-AI experiences within scientific workflows.</p>
<h2>6 SUMMARY</h2>
<p>As the terrain of science widens at a fast pace, researchers are constrained by the limits of human cognition, and lack principled methods to follow developments, guide attention, and formulate and prioritize directions. For the first time in history, essentially all of scientific knowledge and discourse has moved into the digital space. At the time of this writing, dramatic advances in AI with large language models are taking place at breathtaking speed. These shifts present tremendous opportunities for leveraging scientific corpora as databases from which solutions, insights, and inspirations can be gleaned. We see opportunity ahead for systems that can address the imbalance between the treasure trove of scholarly information and researchers' limited ability to reach into it, harnessing humankind's collective knowledge to revolutionize the scientific process. Numerous challenges stand in the way of the vision we have laid out. However, even small steps forward will unlock vast opportunities for making advances at the frontiers of science.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>We thank the members of the Semantic Scholar team for stimulating discussions. Projects were supported by NSF Convergence Accelerator Grant 2132318, NSF RAPID grant 2040196, and ONR grant N00014-18-1-2193.</p>
<h2>REFERENCES</h2>
<p>[1] Sbastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with GPT-4. arXiv preprint arXiv:2303.12712, 2023.
[2] Arie Cattan, Sophie Johnson, Daniel Weld, Ido Dagan, Iz Beltagy, Doug Downey, and Tom Hope. Scico: Hierarchical cross-document coreference for scientific concepts. Automated Knowledge Base Construction (AKBC) 2021, 2021.
[3] Joel Chan, Joseph Chee Chang, Tom Hope, Dafna Shahaf, and Aniket Kittur. Solvent: A mixed initiative system for finding analogies between research papers. Proceedings of the ACM on Human-Computer Interaction, 2(CSCW):1-21, 2018.
[4] Johan SG Chu and James A Evans. Slowed canonical progress in large fields of science. Proceedings of the National Academy of Sciences, 118(41), 2021.
[5] Cristina Garca-Villar. A critical review on altmetrics: can we measure the social impact factor? Insights into Imaging, 12(1):1-10, 2021.
[6] Yolanda Gil. Will AI write scientific papers in the future? AI Magazine, 2022.
[7] Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S. Weld, and Marti A. Hearst. Augmenting scientific papers with just-in-time, position-sensitive definitions of terms and symbols. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, 2021.
[8] Tom Hope, Joel Chan, Aniket Kittur, and Dafna Shahaf. Accelerating innovation through analogy mining. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2017.
[9] Tom Hope, Jason Portenoy, Kishore Vasan, Jonathan Borchardt, Eric Horvitz, Daniel S Weld, Marti A Hearst, and Jevin West. Scisight: Combining faceted navigation and research group detection for covid-19 exploratory scientific search. In EMNLP, 2020.
[10] Tom Hope, Asla Amini, David Wadden, Madeleine van Zuylen, Sravanthi Parasa, Eric Horvitz, Daniel S Weld, Roy Schwartz, and Hannaneh Hajishirzi. Extracting a knowledge base of mechanisms from covid-19 papers. In NAACL, 2021.
[11] Tom Hope, Ronen Tamari, Hyeomu Kang, Daniel Hershcovich, Joel Chan, Aniket Kittur, and Dafna Shahaf. Scaling creative inspiration with fine-grained functional facets of product ideas. In CHI, 2022.
[12] Eric Horvitz. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conference on Human Factors in Computing Systems, pages 159-166, 1999.
[13] Eric Horvitz. The future of biomedical informatics: Bottlenecks and opportunities. In Biomedical Informatics: Computer Applications in Health Care and Biomedicine, E.H. Shortliffe, J.J. Cimino, et. al. Springer, 2021.
[14] Eric J Horvitz, John S Breese, David Heckerman, David Hovel, and Koos Rommelse. The Lumiere project: Bayesian user modeling for inferring the goals and needs of software users. In Proceedings of the Conference on Uncertainty in AI, pages 256-263, 1998.
[15] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin idek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583-589, 2021.
[16] Ross D King, Kenneth E Whelan, Ffion M Jones, Philip GK Reiser, Christopher H Bryant, Stephen H Muggleton, Douglas B Kell, and Stephen G Oliver. Functional genomic hypothesis generation and experimentation by a robot scientist. Nature, 427(6971):247-252, 2004.
[17] Thomas S Kuhn. The structure of scientific revolutions, volume 111. Chicago University of Chicago Press, 1970.
[18] D Lahav, JS Falcon, B Kuehl, S Johnson, S Parasa, N Shomron, DH Chau, D Yang, E Horvitz, DS Weld, and T Hope. A search engine for discovery of scientific challenges and directions. In AAAL 2022.
[19] Pat Langley, Herbert A Simon, Gary L Bradshaw, and Jan M Zytkow. Scientific discovery: Computational explorations of the creative processes. MIT press, 1987.
[20] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel S. Weld. S2ORC: The Semantic Scholar Open Research Corpus. In Proceedings of ACL, 2020.
[21] Steve Lohr. What ever happened to ibm's watson. The New York Times, 16(7):21, 2021.
[22] Sonia Murthy, Kyle Lo, Chandra Bhagavatula, Daniel King, Bailey Kuehl, Sophie Johnson, Jonathan Borchardt, Daniel S. Weld, Tom Hope, and Doug Downey. Accord: A multi-document approach to generating diverse descriptions of scientific concepts. In EMNLP, 2022.
[23] Sheshera Mysore, Arman Cohan, and Tom Hope. Multi-vector models with textual guidance for fine-grained scientific document similarity. NAACL, 2022.
[24] Aakanksha Naik, Sravanthi Parasa, Sergey Feldman, Lucy Lu Wang, and Tom Hope. Literature-augmented clinical outcome prediction. NAACL, 2022.
[25] Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz. Capabilities of GPT-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023.
[26] Regina Nuzzo et al. How scientists fool themselves-and how they can stop. Nature, 526(7572):182-185, 2015.
[27] Benjamin Nye, Jay DeYoung, Eric Lehman, Ani Nenkova, Iain J Marshall, and Byron C Wallace. Understanding clinical trial reports: Extracting medical entities and their relations. In AMIA Annual Symposium Proceedings, volume 2021, page 485. American Medical Informatics Association, 2021.
[28] OpenAI. Gpt-4 technical report, 2023.
[29] Jason Portenoy, Marissa Radensky, Jevin West, Eric Horvitz, Daniel Weld, and Tom Hope. Bridger: Toward bursting scientific filter bubbles and boosting innovation via novel author discovery. CHI, 2022.
[30] Edward O Pyser-Knapp, Jed W Pitera, Peter WJ Staar, Seiji Takeda, Teodoro Laino, Daniel P Sanders, James Sexton, John R Smith, and Alessandro Curioni. Accelerating materials discovery using artificial intelligence, high performance computing and robotics. npj Computational Materials, 8(1):1-9, 2022.
[31] Chirag Shah and Emily M Bender. Situating search. In ACM SIGIR Conference on Human Information Interaction and Retrieval, pages 221-232, 2022.
[32] Uriel Singer, Kira Radinsky, and Eric Horvitz. On biases of attention in scientific discovery. Bioinformatics, 12 2020. URL https://doi.org/10.1093/bioinformatics/ btaa1036.
[33] D. R. Swanson. Fish oil, raynaud's syndrome, and undiscovered public knowledge. Perspectives in Biology and Medicine, 30(1):7-18, 1986.
[34] Hillel Taub Tabib, Micali Shl aim, Shoval Sadde, Dan Lahav, Matan Eyal, Yaara Cohen, and Yoav Goldberg. Interactive extractive search over biomedical corpora. In Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing, pages 28-37, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1:2020.biomlp-1.3. URL https://aclanthology.org/2020.biomlp-1.3.
[35] Jaime Teevan, Susan T Dumais, and Eric Horvitz. Personalizing search via automated analysis of interests and activities. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 449-456, 2005.
[36] Paul Thagard. The cognitive science of science: Explanation, discovery, and conceptual change. Mit Press, 2012.
[37] Aish Thamba and Richard B Gunderman. For watson, solving cancer wasn't so elementary: Prospects for artificial intelligence in radiology. Academic Radiology, 29(2):312-314, 2022.
[38] Daril A Vilhena, Jacob G Foster, Martin Rosvall, Jevin D West, James Evans, and Carl T Bergstrom. Finding cultural holes: How structure and culture diverge in networks of scholarly communication. Sociological Science, 1:221, 2014.
[39] Yu Wang, Jinchao Li, Tristan Naumann, Chenyan Xiong, Hao Cheng, Robert Tinn, Cliff Wong, Naoto Usuyama, Richard Rogahn, Zhihong Shen, et al. Domainspecific pretraining for vertical search: Case study on biomedical literature. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining, pages 3717-3725, 2021.
[40] Daniel S Weld and Gagan Bansal. The challenge of crafting intelligible intelligence. Communications of the ACM, 62(6):70-79, 2019.</p>            </div>
        </div>

    </div>
</body>
</html>