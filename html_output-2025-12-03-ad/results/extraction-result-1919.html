<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1919 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1919</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1919</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-41.html">extraction-schema-41</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <p><strong>Paper ID:</strong> paper-280422066</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2508.02194v1.pdf" target="_blank">Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot</a></p>
                <p><strong>Paper Abstract:</strong> Bipedal locomotion is a key challenge in robotics, particularly for robots like Bolt, which have a point-foot design. This study explores the control of such underactuated robots using constrained reinforcement learning, addressing their inherent instability, lack of arms, and limited foot actuation. We present a methodology that leverages Constraints-as-Terminations and domain randomization techniques to enable sim-to-real transfer. Through a series of qualitative and quantitative experiments, we evaluate our approach in terms of balance maintenance, velocity control, and responses to slip and push disturbances. Additionally, we analyze autonomy through metrics like the cost of transport and ground reaction force. Our method advances robust control strategies for point-foot bipedal robots, offering insights into broader locomotion. Videos and code are available at https://gepetto.github.io/BoltLocomotion/.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1919.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1919.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer experiments for robotic manipulation that report details about actuator dynamics modeling, parameter fidelity, task characteristics, and transfer performance.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bolt sim-to-real locomotion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zero-shot sim-to-real transfer of constrained RL locomotion policy on the Bolt point-foot biped</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sim-to-real experiment where constrained PPO-based RL policies (CaT framework) trained in IsaacLab were transferred zero-shot to the open-source Bolt point-foot biped; training used domain randomization of dynamics (notably joint friction and actuation delay) and a high-frequency PD inner loop on the real robot.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Dynamic bipedal locomotion (walking, slip recovery, jumping)</td>
                        </tr>
                        <tr>
                            <td><strong>task_timescale</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_contact_ratio</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_precision_requirement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_modeled</strong></td>
                            <td>joint friction (randomized), actuation delay (command latency randomized), actuator torque/velocity/acceleration limits (used as safety constraints), inertia and mass of links (mass scale, inertia scale randomized), base center-of-mass displacement, PD inner-loop tracking (high-frequency PD at 10 kHz modeled as low-level controller), joint positions/velocities (initial state randomization).</td>
                        </tr>
                        <tr>
                            <td><strong>actuator_parameters_simplified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level_description</strong></td>
                            <td>Domain-randomized dynamics with specified uniform ranges for mass/inertia (±20%), joint friction coefficient randomized (U(0.01,0.1)), base CoM perturbation (±0.02 m), actuation delay randomized (U(0,2) simulation steps); low-level PD controller assumed for tracking (10 kHz) while policy outputs at 50 Hz; zero-shot transfer (no fine-tuning) to real hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>parameter_specific_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Multiple: steady-state velocity tracking error (ε = v* - mean steady-state v), maximum steady-state velocity (normalized by √(gL); forward Froude Fr = 0.54), cost of transport (CoT) vs velocity, estimated ground reaction force (mean GRF = 90% ± 6.2% of robot weight), maximum impulse before falling from push experiments (presented as normalized %weight·s per push angle). Also reported normalized min/max velocities per axis (x: vmin=-0.34, vmax=0.54; y: vmin=-0.31, vmax=0.30).</td>
                        </tr>
                        <tr>
                            <td><strong>sim_vs_real_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_performed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>sensitivity_analysis_results</strong></td>
                            <td>Informal sensitivity finding: joint friction variations and actuator delays were identified as particularly critical for successful sim-to-real transfer — without modeling joint friction the robot collapses on deployment; actuator delays (latency) must be accounted for to avoid unstable execution. Other randomized parameters (masses, inertia, terrain, sensor noise) improved robustness but were less critical.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_reported</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td>Extensive domain randomization per Table II: terrain friction U(0.4,1.5), terrain height noise U(0,0.02)m; mass scale U(0.8,1.2); inertia scale U(0.8,1.2); base CoM displacement U(-0.02,0.02)m; joint friction coefficient U(0.01,0.1); base position U(-0.5,0.5)m; initial base yaw U(-π,π), initial linear velocity U(-0.3,0.3)m/s, angular velocity U(-0.1,0.1)rad/s; joint pos/vel scale U(0.9,1.1); actuation delay U(0,2) simulation steps; push events randomized U ranges; observation noise: projected gravity noise, joint position noise (Gaussian + bias), joint velocity noise U(-1.5,1.5) rad/s.</td>
                        </tr>
                        <tr>
                            <td><strong>robot_type</strong></td>
                            <td>Point-foot bipedal robot (Bolt) — open-source ODRI platform; 3 torque-controlled DOF per leg, no arms; external high-level computer sending target joint positions at 50 Hz; onboard PD low-level controller at 10 kHz.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_failure_analysis</strong></td>
                            <td>Yes — authors report that omitting accurate modeling/randomization of joint friction or actuator delay leads to immediate collapse or unstable behavior on the real robot; these were identified as primary causes of failed transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding_for_theory</strong></td>
                            <td>For dynamic point-foot bipedal locomotion, actuator-level friction and command latency (actuation delay) dominate sim-to-real transfer fidelity: explicitly modeling/randomizing joint friction and actuator delays (in addition to mass/inertia and sensor noise) is indispensable for zero-shot transfer; other parameter randomizations improve robustness but are secondary.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Asap: Aligning simulation and real-world physics for learning agile humanoid whole-body skills <em>(Rating: 2)</em></li>
                <li>Bridging the sim-to-real gap for athletic loco-manipulation <em>(Rating: 2)</em></li>
                <li>RMA: Rapid motor adaptation for legged robots <em>(Rating: 2)</em></li>
                <li>Controlling the solo12 quadruped robot with deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Real-world humanoid locomotion with reinforcement learning <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1919",
    "paper_id": "paper-280422066",
    "extraction_schema_id": "extraction-schema-41",
    "extracted_data": [
        {
            "name_short": "Bolt sim-to-real locomotion",
            "name_full": "Zero-shot sim-to-real transfer of constrained RL locomotion policy on the Bolt point-foot biped",
            "brief_description": "A sim-to-real experiment where constrained PPO-based RL policies (CaT framework) trained in IsaacLab were transferred zero-shot to the open-source Bolt point-foot biped; training used domain randomization of dynamics (notably joint friction and actuation delay) and a high-frequency PD inner loop on the real robot.",
            "citation_title": "Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot",
            "mention_or_use": "use",
            "task_name": "Dynamic bipedal locomotion (walking, slip recovery, jumping)",
            "task_timescale": null,
            "task_contact_ratio": null,
            "task_precision_requirement": null,
            "actuator_parameters_modeled": "joint friction (randomized), actuation delay (command latency randomized), actuator torque/velocity/acceleration limits (used as safety constraints), inertia and mass of links (mass scale, inertia scale randomized), base center-of-mass displacement, PD inner-loop tracking (high-frequency PD at 10 kHz modeled as low-level controller), joint positions/velocities (initial state randomization).",
            "actuator_parameters_simplified": null,
            "fidelity_level_description": "Domain-randomized dynamics with specified uniform ranges for mass/inertia (±20%), joint friction coefficient randomized (U(0.01,0.1)), base CoM perturbation (±0.02 m), actuation delay randomized (U(0,2) simulation steps); low-level PD controller assumed for tracking (10 kHz) while policy outputs at 50 Hz; zero-shot transfer (no fine-tuning) to real hardware.",
            "parameter_specific_fidelity": null,
            "transfer_success_metric": "Multiple: steady-state velocity tracking error (ε = v* - mean steady-state v), maximum steady-state velocity (normalized by √(gL); forward Froude Fr = 0.54), cost of transport (CoT) vs velocity, estimated ground reaction force (mean GRF = 90% ± 6.2% of robot weight), maximum impulse before falling from push experiments (presented as normalized %weight·s per push angle). Also reported normalized min/max velocities per axis (x: vmin=-0.34, vmax=0.54; y: vmin=-0.31, vmax=0.30).",
            "sim_vs_real_performance": null,
            "sensitivity_analysis_performed": true,
            "sensitivity_analysis_results": "Informal sensitivity finding: joint friction variations and actuator delays were identified as particularly critical for successful sim-to-real transfer — without modeling joint friction the robot collapses on deployment; actuator delays (latency) must be accounted for to avoid unstable execution. Other randomized parameters (masses, inertia, terrain, sensor noise) improved robustness but were less critical.",
            "computational_cost_reported": false,
            "computational_cost_details": null,
            "fidelity_comparison": null,
            "domain_randomization_used": true,
            "domain_randomization_details": "Extensive domain randomization per Table II: terrain friction U(0.4,1.5), terrain height noise U(0,0.02)m; mass scale U(0.8,1.2); inertia scale U(0.8,1.2); base CoM displacement U(-0.02,0.02)m; joint friction coefficient U(0.01,0.1); base position U(-0.5,0.5)m; initial base yaw U(-π,π), initial linear velocity U(-0.3,0.3)m/s, angular velocity U(-0.1,0.1)rad/s; joint pos/vel scale U(0.9,1.1); actuation delay U(0,2) simulation steps; push events randomized U ranges; observation noise: projected gravity noise, joint position noise (Gaussian + bias), joint velocity noise U(-1.5,1.5) rad/s.",
            "robot_type": "Point-foot bipedal robot (Bolt) — open-source ODRI platform; 3 torque-controlled DOF per leg, no arms; external high-level computer sending target joint positions at 50 Hz; onboard PD low-level controller at 10 kHz.",
            "transfer_failure_analysis": "Yes — authors report that omitting accurate modeling/randomization of joint friction or actuator delay leads to immediate collapse or unstable behavior on the real robot; these were identified as primary causes of failed transfer.",
            "key_finding_for_theory": "For dynamic point-foot bipedal locomotion, actuator-level friction and command latency (actuation delay) dominate sim-to-real transfer fidelity: explicitly modeling/randomizing joint friction and actuator delays (in addition to mass/inertia and sensor noise) is indispensable for zero-shot transfer; other parameter randomizations improve robustness but are secondary.",
            "uuid": "e1919.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Asap: Aligning simulation and real-world physics for learning agile humanoid whole-body skills",
            "rating": 2
        },
        {
            "paper_title": "Bridging the sim-to-real gap for athletic loco-manipulation",
            "rating": 2
        },
        {
            "paper_title": "RMA: Rapid motor adaptation for legged robots",
            "rating": 2
        },
        {
            "paper_title": "Controlling the solo12 quadruped robot with deep reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Real-world humanoid locomotion with reinforcement learning",
            "rating": 2
        }
    ],
    "cost": 0.009129499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot
4 Aug 2025</p>
<p>Constant Roux 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Elliot Chane-Sane 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Ludovic De Matteïs 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Thomas Flayols 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Jérôme Manhes 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Olivier Stasse 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Artificial and Natural Intelligence Toulouse Institute
France, first</p>
<p>Philippe Souères 
LAAS
CNRS</p>
<p>Université de Toulouse
France, first</p>
<p>Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot
4 Aug 2025F2059B68CFFA9A8B0ECA5516097378FDarXiv:2508.02194v1[cs.RO]
Fig. 1: The Bolt robot walking forward.</p>
<p>I. INTRODUCTION</p>
<p>Traditionally, Model Predictive Control (MPC) has been the dominant method for controlling legged robots [1], [2].However, the emergence of advanced Reinforcement Learning (RL) algorithms [3] and the development of GPUaccelerated simulators [4], [5] have driven a significant shift toward learning-based policies [6], especially in the context of quadrupedal locomotion [7], [8].In recent years, such techniques have also demonstrated great success in controlling bipedal and humanoid robots [9], [10], [11], enabling these robots to perform in increasingly complex environments and often outperforming traditional MPC-based approaches.</p>
<p>Despite these advancements, sim-to-real transfer remains challenging for robots with unconventional morphological traits, such as limited ground contact or underactuated limbs [12], [13], [14], [15], [16].Among these, bipedal robots with point feet [17], [18], [19], [20] pose a unique challenge due to their inherently unstable structure and minimal support area.While some prior works have achieved point-foot bipedal walking using quadrupedal robots [21], [22], these systems benefit from additional limbs that contribute to balance through angular momentum [23]-a strategy unavailable to arm-less bipedal robots.The scientific interest in point-foot bipedal robots is considerable.</p>
<p>As noted by Westervelt et al., "a model of walking with a point contact is an integral part of an overall model of walking that is more anthropomorphic in nature than the current flat-footed walking paradigm" [24].Unlike rigid flatfooted robots-which often adopt overly simplified and nonanthropomorphic designs with stiff, unarticulated contact surfaces-point-foot systems better reflect the dynamics and control challenges seen in human locomotion.To explore this issue, we focus on the point-foot Bolt robot [25], a bipedal platform developed as part of the Open Dynamic Robot Initiative (ODRI).Bolt shares the same actuators as Solo, a quadrupedal robot from the same project, leveraging a modular and open-source design aimed at advancing torquecontrolled legged locomotion.Notably, while Solo has been extensively studied [26], [27], [28], there has been relatively little research on Bolt [29], making it an interesting plateform for our subject of interest.</p>
<p>In this paper, we address the control of bipedal pointfoot robots without arms, using the Bolt platform as a representative system.We analyze its dynamics and identify key challenges that must be tackled to enable robust locomotion.Our contributions are as follows:</p>
<p>• First Application of Constrained RL on Point-Foot Bipedal Locomotion: We apply constrained reinforcement learning to the problem of point-foot bipedal locomotion, demonstrating its feasibility on a setting that has received limited attention in prior work.We conduct a real-world evaluation of the approach on the Bolt robot, providing insights into its performance and practical deployment.The structure of the paper is as follows: Section II reviews related work on constrained RL and point-foot robots, Section III provides an in-depth description of the Bolt hardware, Section IV outlines the methodology, Section V presents experimental results, and Section VI concludes the paper.</p>
<p>II. RELATED WORK</p>
<p>Recent advances in GPU-accelerated simulators [4], [5] have enhanced the efficiency of RL for robotic locomotion by enabling massively parallel training, which reduces training times [7].RL has been successful in quadrupedal locomotion, with policies trained in simulation effectively transferring to real-world robots [30], [8], [27], [21].However, RL for bipedal locomotion remains more challenging due to the inherent instability of bipedal morphology [9], [10], [11], especially in point-foot bipedal robots, where the underactuated stance phase complicates the control [22].The absence of arms further increases the challenge by eliminating mechanisms to counteract angular momentum [18], [31], [32].The Bolt robot, a point-foot biped, embodies many of the fundamental challenges in dynamic legged locomotion.Previous work has leveraged MPC and whole-body MPC to achieve stable walking behaviors [33], [29], [34].In this work, we instead focus on RL to develop more robust and adaptable locomotion policies that can better handle uncertainty and disturbances.</p>
<p>Transferring RL policies to real-world bipedal robots is hindered by issues like unmodeled dynamics, sensor noise, and hardware limitations [9], [10], [11].Constrained RL frameworks enhance safety and robustness by incorporating constraints, such as joint position and torque limits, as termination conditions [26], [35], [28].One notable approach, CaT (Constraints as Terminations), enforces these constraints during training to ensure hardware-compliant locomotion [26].Alternative methods, such as [36], address similar challenges through different constraint-handling techniques.Furthermore, domain randomization techniques [12] expose policies to various training dynamics, such as variations in motor gains and friction coefficients, enhancing robustness to real-world discrepancies.Additionally, adaptive control strategies allow policies to adapt to real-world conditions by addressing discrepancies between simulation and reality [13], [14], [37].In this work, we employ the CaT framework along with domain randomization to bridge the sim-to-real gap for the Bolt robot, allowing us to develop robust locomotion policies that account for real-world uncertainties.</p>
<p>Evaluation metrics for bipedal locomotion encompass multiple aspects of performance.Velocity tracking accuracy assesses how well the robot follows commanded velocity profiles, ensuring precise motion control [38].Maximum achievable speed evaluates the robot's top velocity, reflecting its control limits [39], [40].Autonomy is quantified through the cost of transport (CoT), which measures energy efficiency by calculating the energy consumed per unit distance traveled [41], [42].Additionally, ground reaction force (GRF) profiles provide insights into balance, impact absorption, and adherence to physical constraints by analyzing force distribution during locomotion [43], [44].Robustness is assessed through push recovery, which tests the robot's ability to regain stability after external perturbations [45], [46], [47], and slippage recovery, which evaluates its ability to maintain balance when encountering unexpected loss of traction [38], [47].In this work, we comprehensively evaluate the Bolt robot's RL policies across all these metrics, analyzing its velocity tracking accuracy, maximum speed, energy efficiency, and robustness to external disturbances.This assessment offers insights into the behavior of the locomotion framework in real-world scenarios.</p>
<p>III. HARDWARE</p>
<p>A. Bolt Overview</p>
<p>Bolt (as shown in Fig. 1) is a bipedal robot developed by the ODRI [25].It adopts a fully open-source, modular design philosophy aimed at enhancing accessibility and reproducibility in robotic research.Built with low-cost, offthe-shelf components and 3D-printed parts, Bolt features three torque-controlled degrees of freedom per leg and point feet.The robot omits arms entirely, which contributes to its lightweight form factor.</p>
<p>The Bolt robot relies on an external system, connected via a wired interface, for high-level computation and power supply.Commands are transmitted in real time via an Ethernet link to low-level motor controllers, enabling agile, closedloop control while minimizing onboard complexity.</p>
<p>B. Locomotion Challenges</p>
<p>While Bolt's streamlined design facilitates experimentation, it introduces several critical challenges for dynamic locomotion:</p>
<p>• Limited Stability: Point feet provide no flat contact surface, significantly reducing the support polygon and making balance control more demanding, particularly during dynamic motions or on uneven terrain [19].</p>
<p>• Angular Momentum Regulation: The absence of arms limits the robot's ability to counterbalance body motion, placing a greater burden on the legs and torso to manage angular momentum during gait transitions and external disturbances [23].• Restricted Yaw Control: Without an active yaw mechanism, Bolt struggles to reorient itself efficiently, which complicates tasks such as turning in confined spaces or navigating sharp trajectories [48].• Reduced Kinematic Redundancy: Each leg's three actuators limit the robot's motion versatility, making agile behaviors such as running or adaptive stepping more complex to achieve and requiring sophisticated control strategies.</p>
<p>IV. METHOD</p>
<p>In order to train a locomotion policy for the point-foot robot, Bolt, we use a sim-to-real approach.We first train the policy in simulation with deep RL and then directly transfer it to the real robot.This section describes the main components used to support learning and sim-to-real transfer on the Bolt robot.</p>
<p>A. Constrained Reinforcement Learning</p>
<p>Consider a Constrained Markov Decision Process defined as (S, A, R, γ, T , {C i } i∈I ), where S and A represent the state and action spaces, respectively, γ is the discount factor, R : S×A → R + is the reward function, and T : S×A×S → R + defines the probabilistic transition dynamics.The system is subject to constraints {C i : S × A → R} i∈I , where each constraint C i yields a scalar penalty signal c i ∈ R + for a given state-action pair (s, a).We look for a policy π : S → A that maximizes the discounted sum of future rewards:
max π E τ ∼π,T ∞ t=0 γ t r (s t , a t ) ,(1)
while ensuring the constraints satisfaction:
P (s,a)∼ρ π,T γ c i (s, a) &gt; 0 ≤ ϵ i , ∀i ∈ I.(2)
We solve the problem defined by ( 1) and ( 2) using the CaT framework [26], built on Proximal Policy Optimization (PPO) [3], which incorporates constraints as termination conditions during training.</p>
<p>B. States and Actions</p>
<p>The state vector s ∈ S comprises the commanded base velocity v * ⊤ ω * ⊤ , where v * and ω * represents respectively the desired linear and angular velocities in the robot's base frame.It also includes the base angular velocity ω, the projected gravity, the joint positions q, the joint velocities q, and the previous actions.The six-dimensional action space corresponds to the angular position commands for the Bolt robot's joints.The policy outputs scaled delta actions, which are added to a predefined reference angular configuration and then tracked by a high-frequency proportional-derivative (PD) controller.</p>
<p>C. Rewards</p>
<p>The reward function is designed to promote precise tracking of the commanded base velocity, with separate terms for tracking the linear velocity in the xy-plane and the yaw velocity.The reward of the linear velocity is defined as:
R xy (s) = exp − ∥v * − v∥ 2 σ 2 1 (3)
where v denote the measured linear velocity expressed in the robot's base frame, and σ 1 represents a scaling factor.Similarly, the reward for the yaw velocity is defined as:
R yaw = exp − (ω * − ω) 2 σ 2 2 (4)
where σ 2 represents a scaling factor.</p>
<p>D. Constraints</p>
<p>To ensure safe and transferable locomotion, we define three categories of constraints during training: safety constraints, posture constraints, and gait constraints.These are detailed in Table I.</p>
<p>a) Safety Constraints: These constraints prevent critical failures that could damage the robot.They include prohibiting knee or base collisions with the ground, avoiding upsidedown states, and limiting excessive foot contact forces f footj of foot j with a threshold f lim .Actuator safety is ensured by limiting joint torques τ k , joint velocities qk , and accelerations qk , where k denotes the actuator index.These are constrained within limits τ lim , qlim , and qlim , respectively.b) Posture Constraints: Posture constraints regulate the robot's body configuration.The base orientation in the roll and pitch axes is constrained to prevent excessive tilting, with a limit defined by base lim .Similarly, the orientations of the hip joints hip l , and the knee joints knee l (where l indicates the leg index), are bounded by limits hip lim and knee lim , ensuring a consistent posture during movement.c) Gait Constraints: These constraints define the robot's locomotion gait.The walking constraint ensures that only one foot is in contact with the ground at any given time, expressed as |n foot contact − 1|, where n foot contact denotes the number of feet in contact with the ground.For jumping, the constraint enforces that either zero or two feet are in contact with the ground, represented by |n foot contact mod 2|.Foot air-time constraints ensure that each foot stays in the air for a sufficient amount of time during each locomotion cycle, defined by t des air time −t air timej , where t air timej is the actual time that foot j is in the air.</p>
<p>Switching between walking and jumping behaviors requires retraining the network due to the mutually exclusive nature of the constraints.</p>
<p>E. Domain Randomization</p>
<p>To ensure robust zero-shot sim-to-real transfer, we employ domain randomization during training, as summarized in Table II.We introduce variations in both the environment and the robot's dynamics, training the policy to generalize better to real-world uncertainties.Additionally, noise is injected into the observations to simulate sensor imperfections and further improve robustness.</p>
<p>a) Environment and Dynamics Randomization: First, we randomize terrain properties by varying the ground friction coefficient and introducing uneven terrain profiles.The robot's dynamics is also randomized by modifying joint friction, shifting the center of mass (CoM) of the base, and perturbing the masses and inertia tensors of the robot's links.By randomizing the physics parameters, we prevent the policy from overfitting to both the simulator and the specific URDF model of the robot, ensuring it remains robust to real-world variations rather than exploiting simulator-specific artifacts.</p>
<p>b) State and Command Perturbations: To prevent overfitting to a fixed initial condition, the robot's initial state is randomized by applying random offsets to joint positions and velocities at spawn.External forces are randomly applied to the base to simulate real-world disturbances, and additional latency effects are introduced by simulating actuator delays and command variations.</p>
<p>c) Observation Noise: To account for sensor imperfections, noise is added to the observations.This noise injection further enhances robustness by preventing the policy from relying on overly precise state estimates.</p>
<p>F. Key Factors for Sim-to-Real Transfer</p>
<p>Among all randomization parameters, joint friction variations and actuator delays are particularly critical for successful sim-to-real transfer.Without accurately modeling joint friction, the robot fails to maintain balance and collapses immediately upon deployment.Likewise, actuator delays introduce inherent latency that must be accounted for to ensure smooth and stable motion execution.While other randomization parameters enhance overall robustness, these two factors are found to be indispensable for achieving reliable real-world locomotion.</p>
<p>V. EXPERIMENTS</p>
<p>We conducted quantitative and qualitative experiments on the real robot to evaluate our controller, highlighting its strengths and identifying potential limitations.</p>
<p>A. Experimental Setup</p>
<p>The policies were trained using the IsaacLab framework [4], leveraging the PPO implementation from the CleanRL library [49], [3].Our approach is implemented within our CaT framework [26], available on GitHub1 .</p>
<p>After successful training in simulation, the learned policies were directly deployed on the real Bolt bipedal robot,</p>
<p>B. Evaluation Metrics</p>
<p>To quantitatively evaluate the performance of our approach, we introduce distinct evaluation metrics across three axes:</p>
<p>• Performance Axis: These metrics evaluate the robot's maximum velocity and the accuracy of its velocity control.• Autonomy Axis: These metrics evaluate the short-term autonomy by monitoring power consumption, and longterm autonomy based on the ground reaction force computed for each foot.• Robustness Axis: These metrics evaluate the controller's capacity to reject external disturbances.</p>
<p>Additionally, we conducted slip recovery and jumping experiments to further demonstrate the robustness and adaptability of the controller.1) Performance Metrics: a) Velocity Accuracy: To assess the accuracy of the velocity tracking of our controller, we computed the steadystate error for a set of velocity references along either the x-axis and the y-axis.The velocity tracking error ε is defined as the difference between the reference velocity v * and the robot's mean steady-state velocity v.</p>
<p>b) Maximum Velocity: The maximum velocity is defined as the highest steady-state mean velocity attained along the x or the y-axis, in both directions, as the velocity reference is progressively increased.The process continues until the robot ceases to accelerate.</p>
<p>2) Autonomy Metrics: a) Short-Term Autonomy: To assess the short-term autonomy of our controller, we measure the CoT for different velocity references along the x and y-axes.The CoT is defined as:
CoT = N −1 i=0 nu−1 k=0 P loss i,k N mg ∥v∥ 2(5)
where N is the total number of time steps during the experiment, n u is the number of joints, m is the robot's mass, g is the gravitational acceleration, and v denotes the robot's average velocity throughout the experiment.The power loss P loss i,k for actuator k at timestep i is:
P loss i,k = P J i,k + P f i,k(6)
where P J i,k and P f i,k are the Joule and friction power losses, respectively, as described by Fadini et al. [50].</p>
<p>b) Long-Term Autonomy: To evaluate the potential damage caused by foot impacts on the ground, we estimate the ground reaction force using the following equation of motion:
M (q)q + b(q, q) = τ (u) + J c (q) T f(7)
where q and q represent the measured joint positions and velocities, respectively, τ denotes the joint torques generated by the control inputs u, J c is the contact Jacobian of the feet, q is the joint acceleration, and f is the ground reaction force.This equation is solved using well-established algorithms from the literature [51], [52].The computed ground reaction forces are then analyzed as part of our benchmark to assess impact-related wear and long-term autonomy.</p>
<p>3) Robustness Criteria: a) Push Recovery: To quantify the robot's ability to reject external disturbances, an instrumented stick is used to apply controlled pushes to the robot's base.The pose of the stick and the force exerted on the robot are measured and the applied force is progressively increased in different directions until the robot loses stability and falls.The maximum impulse sustained before falling is recorded.The impulse is computed as the discrete integral:
λ = δt M −1 i=1 f i + f i−1 2(8)
where M denotes the total number of time steps during the push event, f i represents the measured force at time step i, and δt is the time step duration.</p>
<p>C. Results</p>
<p>1) Performance Criteria: a) Velocity Accuracy: Velocity commands range from −1 m/s to 1 m/s along the x and y-axes separately, with increments of 0.1 m/s.Each experiment is repeated at least three times per velocity reference.The steady-state velocity is determined by applying a moving average filter and extracting the stable segment of the signal.Results are presented in Fig. 3, where all velocities are normalized by √ gL (with L being the robot's leg length), corresponding to the Froude number normalization, as outlined in [53].This normalization enables meaningful comparisons across different locomotion speeds and morphologies.Overall, the robot successfully moves in the commanded direction (e.g., forward when instructed to do so).Along the x-axis, it achieves significantly higher forward velocities than backward ones but exhibits considerable drift, leading to poor velocity tracking.In contrast, along the y-axis, it demonstrates symmetric performance in both left and right directions.These results confirm that the robot is not only capable of balancing but also of following velocity commands.However, drift becomes more pronounced at higher velocity references.This drift can be attributed to the absence of linear velocity measurements in our setup, which eliminates direct feedback necessary for accurate reference tracking.As a result, the robot lacks immediate velocity feedback, making it harder to adjust movements in realtime for accurate control.This issue is compounded by the robot's inherently unstable morphology, further amplifying the challenge of maintaining precise control at higher speeds.</p>
<p>b) Maximum Velocity: Velocity references along the desired axis increase in increments of 0.1 m/s until the robot falls.The maximum steady-state velocity achieved is recorded.Table III summarizes the resulting performance, with all velocities normalized as before.</p>
<p>It is worth emphasizing that the robot achieves higher velocities in forward motion compared to backward, while exhibiting symmetric performance in lateral directions.When walking forward, the robot achieves a Froude number normalization of F r = 0.54, which is comparable to the typical human walking value of F r ≃ 0.5.Despite lower maximum velocities in the backward and lateral directions, the robot's performance remains competitive.Qualitative observations from video footage indicate that prior work [29] resulted in significantly lower velocities, highlighting the improved agility of our approach.2) Autonomy Criteria: a) Short-Term Autonomy: The CoT is evaluated at various steady-state velocities of the robot.Results are categorized based on the velocity command direction (forward/backward or left/right) and are presented in Fig. 4.</p>
<p>For velocity references along both the x and y-axes, the CoT decreases as the steady-state velocity norm increases.It can be used in future work to model battery consumption for an embedded version of the robot.Additionally, it establishes a useful benchmark for comparison in future studies.</p>
<p>b) Long-Term Autonomy: The mean ground reaction force (GRF) is found to be independent of the robot's velocity, remaining at 90% ± 6.2% of the robot's weight.This value being below 100% is explained by the presence of short double support phases-periods during which both feet briefly share the load.Since the robot primarily walks with single-foot support, the average GRF per foot remains below full body weight.This indicates reduced GRF during gait transitions, which contributes to mechanical longevity.Furthermore, it confirms that the contact force constraint imposed during training is maintained in practice.</p>
<p>3) Robustness Criteria: a) Push Recovery: The robot was subjected to over 300 pushes, covering a full range of directions around its base.Fig. 5 presents the maximum impulse, normalized as a percentage of the robot's weight, that the robot could withstand without falling, categorized in 45 • quadrants.</p>
<p>Overall, the robot exhibits greater robustness to recover from pushes applied to the back and sides.Conversely, it is generally less robust when pushed from the front or at the corners, except for the upper right corner.This anomaly can be attributed to insufficient data points recorded in that region.For comparison, an impulse of 4% of the robot's weight over one second is equivalent to a 70 kg human being struck by a 2.8 kg ball over the course of 1 second, demonstrating the robustness of our method.</p>
<p>D. Additional Results</p>
<p>To qualitatively demonstrate the robustness of the balancing process, we present additional results.Fig. 6 shows the robot recovering from a slip after the carpet was pulled out while it was walking on it.These images are extracted directly from the accompanying video, which provides a more dynamic visualization of the entire recovery sequence.Fig. 7 shows the robot performing jumps, enabled by modifying the gait constraint to allow ballistic phases (see Sec.IV-D).It successfully completed over 50 consecutive jumps, maintaining this behavior for more than 15 seconds, as demonstrated in the accompanying video.</p>
<p>VI. CONCLUSION</p>
<p>This work explored the control of a point-foot bipedal robot, emphasizing its significance in achieving anthropomorphic locomotion.Unlike flat-footed bipeds, point-foot robots face unique stability challenges, making their control an interesting research topic.</p>
<p>We developed a constrained RL approach and successfully transferred policies from simulation to the real robot without additional fine-tuning.Our experiments demonstrated that the robot can balance, track velocity commands, jump, and resist external disturbances, showcasing a high level of robustness.</p>
<p>Despite these achievements, real-world deployment remains challenging due to hardware fragility and external factors, such as the use of a wire connecting the robot  to an external computer.This setup, while necessary for communication and data processing, limits mobility and introduces additional complexities during operation.Future work will focus on refining robustness, exploring additional locomotion behaviors, and further improving real-world navigation capabilities.</p>
<p>Fig. 3 :
3
Fig. 3: Normalized steady-state velocity error versus normalized velocity command along the x-axis (left) and the y-axis (right).The solid line represents the mean, and the shaded area indicates the standard deviation.</p>
<p>Fig. 4 :
4
Fig. 4: Cost of transport as a function of the steady-state velocity norm.Blue represents velocity references along the x-axis, while red corresponds to those along the y-axis.</p>
<p>Fig. 5 :
5
Fig. 5: Maximum impulse before falling (expressed as % of weight × seconds) as a function of the push angle, where 0 • corresponds to a push applied to the back of the robot's base.</p>
<p>Fig. 6 :
6
Fig. 6: Motion capture sequence of the robot recovering from a slip after the carpet was pulled away.Captured at 20 Hz.</p>
<p>Fig. 7 :
7
Fig. 7: Motion capture of the robot jumping.Captured at 33 Hz.</p>
<p>We provide a fully open-source pipeline for training, inference, and logging on the low-cost, open-source Bolt robot, aiming to enhance reproducibility and support future benchmarking efforts.</p>
<p>• Open-Source Training and Inference Pipeline: • Real-World Evaluation:</p>
<p>TABLE I :
I
Constraints applied during training.A constraint is considered violated when its associated cost c i &gt; 0. knee/base contact = 1 knee/base contact Upside-down statec upsidedown = 1 upsidedown Foot contact force limit c foot contact j = f foot j 2 − f lim Torque limits ctorque k = |τ k | −τ lim Joint velocity limits c joint velocity k = | qk | − qlim Joint acceleration limits c joint acceleration k = |q k | − qlim Posture Constraints Base orientation c ori = ∥base orixy∥2 − base lim Hip orientation c hip l =| hip ori l | −hip lim Knee orientation c knee l =| knee ori l | −knee lim Gait Constraints Walking (single foot contact) c foot contact = |n foot contact − 1| Jumping (alternating zero or two foot contacts) c foot contact = |n foot contact mod 2| Foot air time c air time j = t des air time − t air time j
Safety ConstraintsKnee or base collisionc</p>
<p>TABLE II :
II
Domain randomization parameters for training.Key sim-to-real factors are in bold.
CategoryParameterDistributionTerrainGround friction coefficient U (0.4, 1.5) Height noise U (0.0, 0.02) m, step = 0.005 mMass scale factorU (0.8, 1.2)Robot DynamicsInertia scale factor Base CoM displacementU (0.8, 1.2) U (−0.02, 0.02) mJoint friction coefficientU (0.01, 0.1)Base position (x, y)U (−0.5, 0.5) mInitial StateBase yaw angleU (−π, π) radBase linear velocityU (−0.3, 0.3) m/sBase angular velocityU (−0.1, 0.1) rad/sJoint pos./vel. scale factorU (0.9, 1.1)Actuation delayU (0, 2) simulation stepsEventsPush linear velocity (x, y) Push linear velocity (z)U (−0.5, 0.5) m/s U (−0.1, 0.1) m/sPush angular velocityU (−0.5, 0.5) rad/sBase angular velocityU (−0.2, 0.2) rad/sObservation NoiseProjected gravity noise Joint position noiseN (0, 0.05 2 ) with bias U (0, 0.05) U (−0.01, 0.01) rad with bias U (0, 0.05) radJoint velocity noiseU (−1.5, 1.5) rad/sdescribed in Sec. III. The policy runs at a frequency of 50Hzon an Apple Mac M3 Max CPU. Target joint positions aretransmitted to the onboard PD controller, operating at a fre-quency of 10kHz. The complete inference pipeline, includingcode and logs, is available on GitHub 1 for reproducibility.</p>
<p>TABLE III :
III
Minimum and maximum normalized velocities achieved along the x and y axes.
v min / √gL vmax/ √gLx-axis-0.340.54y-axis-0.310.30
https:// gepetto.github.io/ BoltLocomotion/
AKNOWLEDGMENTWe thank the Fablaas and Electronics teams for their support in robot repairs, and the biomechanical team for constructing the force measurement stick.The Bolt platform was supported by ROBOTEX 2.0 (Grants ANR-10-EQPX-44-01, TIRREX-ANR-21-ESRE-0015) and AS2 (ANR-22-EXOD-0006), and ANR-19-PI3A-0004.This work was granted access to the HPC resources of IDRIS under the allocation 2025-AD011016104 made by GENCI.
Optimization-based control for dynamic legged robots. P M Wensing, M Posa, Y Hu, A Escande, N Mansard, A D Prete, IEEE Transactions on Robotics. 402024</p>
<p>Cafe-mpc: A cascaded-fidelity model predictive control framework with tuning-free whole-body control. H Li, P M Wensing, IEEE Transactions on Robotics. 412025</p>
<p>J Schulman, F Wolski, P Dhariwal, A Radford, O Klimov, arXiv:1707.06347Proximal policy optimization algorithms. 2017arXiv preprint</p>
<p>Orbit: A unified simulation framework for interactive robot learning environments. M Mittal, C Yu, Q Yu, J Liu, N Rudin, D Hoeller, J L Yuan, R Singh, Y Guo, H Mazhar, A Mandlekar, B Babich, G State, M Hutter, A Garg, IEEE Robotics and Automation Letters. 862023</p>
<p>Mujoco: A physics engine for model-based control. E Todorov, T Erez, Y Tassa, 2012. 2012</p>
<p>Learning-based legged locomotion: State of the art and future perspectives. S Ha, J Lee, M Van De Panne, Z Xie, W Yu, M Khadiv, The International Journal of Robotics Research. 4482025</p>
<p>Learning to walk in minutes using massively parallel deep reinforcement learning. N Rudin, D Hoeller, P Reist, M Hutter, Proceedings of the 5th Conference on Robot Learning, ser. Proceedings of Machine Learning Research. D Faust, G Hsu, Neumann, the 5th Conference on Robot Learning, ser. Machine Learning ResearchPMLRNov 2022164</p>
<p>Concurrent training of a control policy and a state estimator for dynamic and robust legged locomotion. G Ji, J Mun, H Kim, J Hwangbo, IEEE Robotics and Automation Letters. 72Apr. 2022</p>
<p>Humanoid parkour learning. Z Zhuang, S Yao, H Zhao, 2024</p>
<p>Reinforcement learning for versatile, dynamic, and robust bipedal locomotion control. Z Li, X B Peng, P Abbeel, S Levine, G Berseth, K Sreenath, 2024</p>
<p>Real-world humanoid locomotion with reinforcement learning. I Radosavovic, T Xiao, B Zhang, T Darrell, J Malik, K Sreenath, 2023</p>
<p>Reinforcement learning for blind stair climbing with legged and wheeled-legged robots. S Chamorro, V Klemm, M De La Iglesia, C Valls, R Pal, Siegwart, 2024 IEEE International Conference on Robotics and Automation (ICRA). 2024</p>
<p>Rma: Rapid motor adaptation for legged robots. A Kumar, Z Fu, D Pathak, J Malik, 2021</p>
<p>T He, J Gao, W Xiao, Y Zhang, Z Wang, J Wang, Z Luo, G He, N Sobanbab, C Pan, Z Yi, G Qu, K Kitani, J Hodgins, L J Fan, Y Zhu, C Liu, G Shi, Asap: Aligning simulation and real-world physics for learning agile humanoid whole-body skills. 2025</p>
<p>Zero dynamics, pendulum models, and angular momentum in feedback control of bipedal locomotion. Y Gong, J W Grizzle, Journal of Dynamic Systems, Measurement, and Control. 144122022</p>
<p>Cts: Concurrent teacherstudent reinforcement learning for legged locomotion. H Wang, H Luo, W Zhang, H Chen, IEEE Robotics and Automation Letters. 9112024</p>
<p>Legged robots that balance. M H Raibert, E R Tello, IEEE Expert. 141986</p>
<p>Tron 1. L Dynamics, 10-Mar-2025</p>
<p>Rabbit: a testbed for advanced control theory. C Chevallereau, G Abba, Y Aoustin, F Plestan, E Westervelt, C Canudas-De-Wit, J Grizzle, IEEE Control Systems Magazine. 2352003</p>
<p>Dynamic walking on highly underactuated point foot humanoids: Closing the loop between hzd and hlip. A B Ghansah, J Kim, K Li, A D Ames, 2024</p>
<p>Extreme parkour with legged robots. X Cheng, K Shi, A Agarwal, D Pathak, arXiv:2309.143412023arXiv preprint</p>
<p>Learning agile bipedal motions on a quadrupedal robot. Y Li, J Li, W Fu, Y Wu, 2024 IEEE International Conference on Robotics and Automation (ICRA). 2024</p>
<p>Hybrid momentum compensation control by using arms for bipedal dynamic walking. Z Gao, X Chen, Z Yu, L Han, J Zhang, G Huang, Biomimetics. 8131Jan. 2023</p>
<p>Feedback control of dynamic bipedal robot locomotion. E R Westervelt, J W Grizzle, C Chevallereau, J H Choi, B Morris, Oct. 2018</p>
<p>An open torque-controlled modular robot architecture for legged locomotion research. F Grimminger, A Meduri, M Khadiv, J Viereck, M Wuthrich, M Naveau, V Berenz, S Heim, F Widmaier, T Flayols, J Fiene, A Badri-Sprowitz, L Righetti, IEEE Robotics and Automation Letters. 52Apr. 2020</p>
<p>Cat: Constraints as terminations for legged locomotion reinforcement learning. E Chane-Sane, P.-A Leziart, T Flayols, O Stasse, P Souères, N Mansard, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2024</p>
<p>Controlling the solo12 quadruped robot with deep reinforcement learning. M Aractingi, P.-A Léziart, T Flayols, J Perez, T Silander, P Souères, Scientific Reports. 131July 2023</p>
<p>Reinforcement learning from wild animal videos. E Chane-Sane, C Roux, O Stasse, N Mansard, 2024</p>
<p>Variable horizon mpc with swing foot dynamics for bipedal walking control. E Daneshmand, M Khadiv, F Grimminger, L Righetti, IEEE Robotics and Automation Letters. 622021</p>
<p>A real-world quadrupedal locomotion benchmark for offline reinforcement learning. H Zhang, S Yang, D Wang, 2024 International Joint Conference on Neural Networks (IJCNN). IEEEJune 2024100</p>
<p>Using deep reinforcement learning to learn high-level policies on the atrias biped. T Li, H Geyer, C G Atkeson, A Rai, 2019 International Conference on Robotics and Automation (ICRA). IEEE2019</p>
<p>Stoch biro: Design and control of a low-cost bipedal robot. G Mothish, K Rajgopal, R Kola, M Tayal, S Kolathaya, 2024 10th International Conference on Control, Automation and Robotics (ICCAR). 2024</p>
<p>A unified framework for walking and running of bipedal robots. M G Boroujeni, E Daneshman, L Righetti, M Khadiv, 2021 20th International Conference on Advanced Robotics (ICAR). 2021</p>
<p>Whole-body mpc and sensitivity analysis of a real time foot step sequencer for a biped robot bolt. C Roux, C Perrot, O Stasse, 2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids). 2024</p>
<p>Soloparkour: Constrained reinforcement learning for visual locomotion from privileged experience. E Chane-Sane, J Amigo, T Flayols, L Righetti, N Mansard, Conference on Robot Learning (CoRL). 2024</p>
<p>Not only rewards but also constraints: Applications on legged robot locomotion. Y Kim, H Oh, J Lee, J Choi, G Ji, M Jung, D Youm, J Hwangbo, IEEE Transactions on Robotics. 402024</p>
<p>Bridging the sim-to-real gap for athletic loco-manipulation. N Fey, G B Margolis, M Peticco, P , arXiv:2502.108942025arXiv preprint</p>
<p>Imitating and finetuning model predictive control for robust and symmetric quadrupedal locomotion. D Youm, H Jung, H Kim, J Hwangbo, H.-W Park, S Ha, IEEE Robotics and Automation Letters. 8112023</p>
<p>Dynamics in the dynamic walk of a quadruped robot. I S Hiroshi Kimura, H Miura, Advanced Robotics. 431989</p>
<p>Dynamic locomotion in the mit cheetah 3 through convex model-predictive control. J Di Carlo, P M Wensing, B Katz, G Bledt, S Kim, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2018</p>
<p>Hexapod robot gait switching for energy consumption and cost of transport management using heuristic algorithms. M Luneckas, T Luneckas, J Kriaučiūnas, D Udris, D Plonis, R Damaševičius, R Maskeliūnas, Applied Sciences. 1131339Feb. 2021</p>
<p>Benchmarking the hrp-2 humanoid robot during locomotion. O Stasse, K Giraud-Esclasse, E Brousse, M Naveau, R Régnier, G Avrin, P Souères, Frontiers in Robotics and AI. 51222018</p>
<p>Force/torque-based compliance control for humanoid robot to compensate the landing impact force. W Xu, R Xiong, J Wu, 2010 First International Conference on Networking and Distributed Computing. 2010</p>
<p>Benchmarking bipedal locomotion: A unified scheme for humanoids, wearable robots, and humans. D Torricelli, J Gonzalez-Vargas, J F Veneman, K Mombaur, N Tsagarakis, A J Del Ama, A Gil-Agudo, J C Moreno, J L Pons, IEEE Robotics &amp; Automation Magazine. 2232015</p>
<p>On the emergence of wholebody strategies from humanoid robot push-recovery learning. D Ferigo, R Camoriano, P M Viceconte, D Calandriello, S Traversaro, L Rosasco, D Pucci, IEEE Robotics and Automation Letters. 642021</p>
<p>From centroidal to wholebody models for legged locomotion: a comparative analysis. E L Dantec, W Jallet, J Carpentier, Oct. 2024</p>
<p>Walking control based on step timing adaptation. M Khadiv, A Herzog, S A A Moosavian, L Righetti, IEEE Transactions on Robotics. 3632020</p>
<p>Yaw moment compensation for bipedal robots via intrinsic angular momentum constraint. B Ugurlu, J Saglia, N Tsagarakis, D Caldwell, International Journal of Humanoid Robotics. 92012</p>
<p>Cleanrl: High-quality single-file implementations of deep reinforcement learning algorithms. S Huang, R F J Dossa, C Ye, J Braga, D Chakraborty, K Mehta, J G Araújo, Journal of Machine Learning Research. 232742022</p>
<p>Computational design of energy-efficient legged robots: Optimizing for size and actuators. G Fadini, T Flayols, A Del Prete, N Mansard, P Souères, 2021 IEEE International Conference on Robotics and Automation (ICRA). 2021</p>
<p>Crocoddyl: An efficient and versatile framework for multi-contact optimal control. C Mastalli, R Budhiraja, W Merkt, G Saurel, B Hammoud, M Naveau, J Carpentier, L Righetti, S Vijayakumar, N Mansard, IEEE International Conference on Robotics and Automation (ICRA). 2020</p>
<p>Proximal and sparse resolution of constrained dynamic equations. J Carpentier, R Budhiraja, N Mansard, Robotics: Science and Systems. 2021</p>
<p>R M Alexander, Principles of Animal Locomotion, stu. Princeton University Press2003student edition ed.</p>            </div>
        </div>

    </div>
</body>
</html>