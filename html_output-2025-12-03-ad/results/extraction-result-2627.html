<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2627 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2627</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2627</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-554d3f58f62bfa76a5c8c55f597d62fcfa17ef9a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/554d3f58f62bfa76a5c8c55f597d62fcfa17ef9a" target="_blank">Efficient and Scalable Batch Bayesian Optimization Using K-Means</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a modification to K-Means Batch Bayesian Optimization by combining it with compressed sensing to project the optimization into a lower dimensional subspace and demonstrates empirically that this 2-step method outperforms algorithms where no dimensionality reduction has taken place.</p>
                <p><strong>Paper Abstract:</strong> We present K-Means Batch Bayesian Optimization (KMBBO), a novel batch sampling algorithm for Bayesian Optimization (BO). KMBBO uses unsupervised learning to efficiently estimate peaks of the model acquisition function. We show in empirical experiments that our method outperforms the current state-of-the-art batch allocation algorithms on a variety of test problems including tuning of algorithm hyper-parameters and a challenging drug discovery problem. In order to accommodate the real-world problem of high dimensional data, we propose a modification to KMBBO by combining it with compressed sensing to project the optimization into a lower dimensional subspace. We demonstrate empirically that this 2-step method outperforms algorithms where no dimensionality reduction has taken place.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2627.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2627.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KMBBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>K-Means Batch Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch Bayesian optimization algorithm that uses slice sampling on an acquisition function to collect candidate points and then fits K-Means to those samples to choose batch evaluation centroids, enabling direct control of batch size while promoting coverage of acquisition peaks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>K-Means Batch Bayesian Optimization (KMBBO)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KMBBO constructs batches by (1) fitting a Gaussian Process model and computing an acquisition function (Expected Improvement in the experiments), (2) drawing slice samples from the volume under the acquisition function (Batch Generalized Slice Sampling, BGSS), (3) clustering those slice samples with K-Means using the desired batch size k to obtain k centroids, and (4) evaluating the objective f at the centroids and adding results to the dataset. The approach thus approximates peaks/modes of the acquisition function efficiently and directly enforces a fixed batch size via the number of clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box optimization tasks; demonstrated on synthetic optimization (Branin, Camelback, Hartmann), machine-learning hyperparameter tuning (SVM), and drug discovery (malaria compound potency) — i.e., algorithm hyperparameter tuning and drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates a fixed number k of parallel evaluations per epoch by clustering slice samples from the acquisition function and selecting cluster centroids as batch candidates. This chooses points concentrated in high-acquisition-density regions while spreading remaining centroids over other high-density regions to utilize all k slots.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Empirical wall-clock runtime per sampling epoch (seconds per epoch) and asymptotic scaling of subroutines (e.g., K-Means runtime and slice sampling sampling cost). The paper reports seconds/epoch timings (Figure 7) and notes scaling behaviors: slice sampling O(2^d) and K-Means is relatively cheap.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses Expected Improvement (EI) as the acquisition function to guide sampling; slice sampling is performed under the EI surface so selection favors regions of high expected improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balances exploitation by sampling regions of high expected improvement (slice samples concentrate under high EI) and exploration/diversification via K-Means clustering which forces centroids to spread across distinct high-density regions; when fewer local optima exist than batch size, squared-distance objective of K-Means distributes extra centroids across sample space.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>K-Means clustering of slice samples produces centroids that are representative and spatially separated; the within-cluster-sum-of-squares objective induces spread when peaks < batch size, promoting diverse batch composition.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of parallel experiments per epoch (fixed batch size); implicit assumption that objective evaluations are expensive relative to batch-computation cost.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Directly enforces a fixed batch size by setting the number of K-Means clusters k; for high-dimensional tasks, uses CS-KMBBO (compressed sensing step) to reduce sampling/computational burden so that slice sampling and clustering remain tractable within the fixed-batch regime.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Instantaneous regret (distance from global optimum) and 'first encounter time' (epoch when global optimum first located); also domain-specific metrics such as RMSE for SVM tuning and PEC50 potency/regret for drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported final-performance after 10 epochs (Table 3): Branin-Hoo regret 0.00523 (std 0.000488); Camelback-6 regret 0.0354 (std 0.0616); Hartmann (6D) regret 0.922 (std 0.311); SVM RMSE 1.9416 (std 0.000577); Malaria (drug discovery) regret 2.3802 (std 1.4003). Also reported faster runtime per epoch than B3O in 2D and 6D (Figure 7).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against Naive qEI, Thompson sampling, Constant Liar (mean), Local Penalization (LP), Batch Predictive Entropy Search (Batch-PES), and B3O.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>KMBBO achieved the best or near-best performance across the tested tasks and the best normalized ranking Z for optimization performance (Figure 6). In Branin-Hoo it locates the optimum earlier and more consistently than others; in SVM tuning it achieves lowest RMSE among methods; in the Malaria task, KMBBO reaches lower regret than Thompson, qEI and Batch-PES after 10 epochs while sampling only 90 of ~19,000 candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Empirically lower runtime per sampling epoch than B3O (qualitative: 'generally significantly smaller' seconds/epoch in Fig.7); also achieves comparable or better optimization with limited numbers of objective evaluations (e.g., 90 evaluations on Malaria producing lower regret than baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Discusses tradeoffs between computation used to select batches and the cost of objective evaluations: asserts that expensive ground-truth evaluations dominate so more costly but higher-quality batch selection (e.g., KMBBO) is acceptable. Also analyzes dimensionality tradeoffs: slice sampling scales poorly with dimension (O(2^d)), motivating compressed sensing; KMBBO offers better per-epoch runtime than IGMM-based B3O.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>For fixed-batch scenarios, selecting batch members as cluster centroids of slice samples drawn under the acquisition function is an effective allocation strategy: it concentrates evaluations on high expected-improvement regions while ensuring diversity. For high-dimensional problems, compressing the input space before running KMBBO (CS-KMBBO) yields tractable sampling and maintains or improves performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2627.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CS-KMBBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Compressed Sensing K-Means Batch Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-dimensional variant of KMBBO that applies compressed sensing (TwIST) to reduce input dimensionality before performing slice sampling and K-Means batch construction, reducing the computational cost of sampling in high dimensions while retaining optimization performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CS-KMBBO (KMBBO with compressed sensing)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CS-KMBBO first samples a subset of the domain and uses Two-step Iterative Shrinkage/Thresholding (TwIST) to determine a sparse compressed basis and optimal compressed dimensionality under a reconstruction tolerance; the domain is compressed to this lower-dimensional subspace (using compressed sensing principles), then KMBBO (slice sampling + K-Means) is run in the compressed space and the chosen centroids are mapped back (decompressed) for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>High-dimensional black-box optimization problems; demonstrated on a drug-discovery task with 167-dimensional molecular descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Same batch-allocation mechanism as KMBBO (fixed k centroids from K-Means on slice samples) but operating in a compressed low-dimensional representation chosen to preserve relevant structure while drastically reducing sampling/computation required for slice sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock runtime per sampling epoch and sampling scalability; addresses the O(2^d) poor scaling of slice sampling by reducing d via compressed sensing. The compressed-space dimensionality M is governed by M ∝ μ^2 S log(N)^2 (Candès & Wakin formula).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Relies on the Expected Improvement acquisition function (same as KMBBO); slice samples drawn under EI in the compressed space approximate high-EI regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploitative focus preserved by slice sampling under EI in compressed space; exploration encouraged via K-Means centroid spread and the compressed representation which may emphasize salient, diverse signal components.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Indirect: K-Means clustering in compressed space yields centroids that cover distinct high-acquisition regions; compression may also filter noise and emphasize diverse informative directions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size with additional computational budget constraints due to high dimensionality (practical limits on number of slice samples and runtime).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handles computational budget by compressing the domain to the smallest dimension that meets a reconstruction tolerance ε (TwIST procedure on sampled points), thereby reducing the runtime and sample requirements for BGSS and clustering while enabling fixed-size batches.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same as KMBBO — regret and task-specific metrics (e.g., potency regret for drug discovery). Demonstrated ability to find low-regret compounds with few evaluations in high-dimensional space.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In the Malaria (167D) experiment CS-KMBBO is reported as one of the methods able to be used on the high-dimensional task and shows better performance than several other methods that failed or were intractable; specific numeric Malaria results for CS-KMBBO are given in figures and qualitative comparison (Table 3 shows KMBBO entry; CS-KMBBO discussed qualitatively as effective).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared implicitly/qualitatively against B3O, LP, Constant Liar, Thompson, qEI, and Batch-PES in the high-dimensional Malaria task; many baselines failed or were intractable.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>In the 167-dimensional Malaria task, CS-KMBBO (and KMBBO variants) outperform methods that could run (Thompson, qEI, Batch-PES) in terms of reaching lower regret with a small number of evaluations; other methods (B3O, LP, Constant Liar) were either intractable or failed to converge.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables tractable batch construction where slice sampling would otherwise be computationally infeasible (avoids exponential slice-sampling cost in original dimension); qualitative speedups reported as enabling the method to be used on a 167D problem with acceptable runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Analyzes tradeoff between dimensionality reduction loss and tractability: compressed sensing reduces computation (and slice-sampling sample requirements) at potential risk of losing some information; empirical results show CS-KMBBO can outperform methods run in full space, suggesting compression preserves relevant structure for allocation decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>For very high-dimensional problems, it is recommended to compress the domain using TwIST-based compressed sensing to a minimal dimension satisfying reconstruction tolerance and then run batch allocation (KMBBO) in the compressed space to achieve good tradeoffs between computational cost and information-directed sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2627.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>B3O</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Budgeted Batch Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dynamic batch selection method designed to build batches containing peaks of the acquisition function using generalized slice sampling followed by peak identification (Infinite Gaussian Mixture Model), with an emphasis on discovering peaks without costly optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Budgeted Batch Bayesian Optimization (B3O)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>B3O performs generalized slice sampling over the acquisition function to obtain samples concentrated in high-acquisition regions, then fits an Infinite Gaussian Mixture Model (IGMM) to identify peaks and assemble batches around the inferred modes. It is dynamic in the sense that batch sizes can adapt to the number of detected peaks.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box optimization and Bayesian optimization tasks (benchmark hyperparameter tuning and synthetic functions in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates batch members by identifying peaks of the acquisition function via slice sampling and IGMM peak picking; does not enforce a fixed batch size (dynamic), potentially allocating fewer or more points depending on the number of detected peaks.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Empirical runtime per sampling epoch (seconds) and scalability of BGSS + IGMM; slice sampling scales poorly with dimension (O(2^d)), and IGMM clustering has nontrivial computational cost and sensitivity to slice-sample count.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Indirect: focuses on locating acquisition-function peaks (e.g., high Expected Improvement locations) rather than an explicit information-theoretic metric; uses slice sampling to sample under the acquisition function surface.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploit by concentrating on modes of the acquisition function (peak-centric selection); exploration arises if multiple distinct peaks are found (IGMM allocates samples around distinct peaks).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via IGMM: multiple mixture components correspond to distinct acquisition peaks, producing batch members across different peaks; sensitivity to number of slice samples can affect diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Designed as budget-aware/dynamic batch method (allocates number of batch points based on detected peaks) but does not directly accommodate a fixed batch size constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Allocates according to detected peaks; the inability to enforce exact fixed batch sizes is noted as a limitation in contexts where a fixed number of experimental slots are available.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same optimization/regret metrics (e.g., regret after epochs); B3O was evaluated on synthetic functions and hyperparameter tuning tasks with regret metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3 reports B3O after 10 epochs: Branin-Hoo regret 0.00591 (std 0.00170); Camelback-6 regret 0.130 (std 0.338); Hartmann regret 0.882 (std 0.320); SVM RMSE 1.9422 (std 0.000580); Malaria task not run/intractable (X in table).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to KMBBO, LP, Constant Liar, Thompson sampling, Naive qEI, and Batch-PES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>B3O performs well on low-to-moderate dimensional tasks and comparably to KMBBO in several cases (e.g., similar regret on Hartmann), but is intractable or impractical in very high dimensions due to slice-sampling scalability and high sample requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No clear efficiency gain in high dimensions; on low-dimensional problems it can effectively identify multiple peaks, but runtime and sample requirements grow quickly with dimensionality compared to KMBBO (which uses K-Means instead of IGMM).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights B3O's tradeoff between adaptively determining batch size (which can be advantageous) and the practical inability to enforce fixed batch sizes; also emphasizes the high computational cost of slice sampling and IGMM in high dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>B3O is effective at identifying multiple acquisition peaks and assembling informative batches when slice sampling can produce sufficient samples, but for fixed-batch or high-dimensional settings, methods that enforce batch size and use cheaper clustering (such as KMBBO) are preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2627.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PPES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallel Predictive Entropy Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A non-greedy batch sampling approach that selects batches to maximize expected information gain about the location of the global maximizer, measured as expected reduction in differential entropy of the predictive distribution of the maximizer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallel predictive entropy search for batch global optimization of expensive objective functions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Parallel Predictive Entropy Search (PPES / Batch-PES)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PPES constructs batches by optimizing the expected reduction in entropy (differential entropy) of the posterior over the global optimizer induced by evaluating the batch; selection is explicitly information-theoretic and non-greedy, aiming to maximize mutual information between observations and the optimizer.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization for expensive black-box functions (general use; used in experiments as a baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects batches that maximize expected information gain about the location of the global maximizer (expected entropy reduction) subject to batch-size constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational complexity of estimating expected entropy reductions and optimizing over batch choices; practical runtime per epoch (reported in experiments as baseline runtimes and variance issues).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected reduction in differential entropy of the predictive distribution of the global maximizer (explicit information-theoretic metric).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Primarily exploration-oriented via information maximization about the maximizer; implicitly balances exploitation because information about high-performing areas is prioritized if it reduces uncertainty about the optimizer.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit through information-theoretic objective: selecting points that together maximize joint information encourages diversity to reduce posterior uncertainty maximally.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size (used as a baseline with batch-size constraint in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Optimizes expected entropy reduction for the specified batch size; computationally expensive and can have high variance in runs (paper notes large variance for batch-PES in SVM experiment).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Entropy reduction focused on identifying the global maximizer; performance measured via regret and final optimization results.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In Table 3 batch-PES results after 10 epochs: Branin-Hoo regret 0.5486 (std 0.3682); Camelback-6 regret 0.1619 (std 0.0967); Hartmann regret 1.4257 (std 0.4736); SVM RMSE 1.9406 (std 0.7322); Malaria regret 3.2626 (std 0.7322).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against KMBBO, B3O, LP, Constant Liar, Thompson, Naive qEI.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Batch-PES exhibited high variance and, in some tasks, inferior median performance compared to KMBBO and other baselines; however it is an explicit information-maximizing method and can be advantageous where computational cost is acceptable.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No explicit efficiency gains reported; computational cost can be high and variance large (noted as problematic in SVM experiment).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper contrasts non-greedy information-maximizing approaches (like PPES) with greedy or clustering-based batch construction; notes that information-theoretic methods can be computationally costly and high-variance in practice, making them sometimes less reliable when evaluations are very expensive or noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Maximizing expected information about the optimizer is principled for batch allocation, but practical application requires managing computational cost and variance; KMBBO is presented as a pragmatic alternative that approximates high-information regions while being computationally cheaper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2627.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Local Penalization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Batch Bayesian Optimization via Local Penalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sequential batch assembly method that penalizes the acquisition function locally around already-selected batch points using a penalization radius informed by an estimated Lipschitz constant, thereby pushing subsequent selections away from previously chosen points to encourage diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Batch bayesian optimization via local penalization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Local Penalization (LP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LP sequentially builds a batch by iteratively selecting the maximizer of a locally-penalized acquisition function: after picking a point, the acquisition function is multiplicatively penalized in a neighborhood (radius derived from an estimated Lipschitz constant) to reduce the utility of nearby points, encouraging spatially diverse batches.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization across various low-to-moderate dimensional tasks (benchmarked in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy sequential allocation within each batch: pick top acquisition candidate, apply local penalization around it, then pick next candidate from the penalized acquisition; repeat until batch filled.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost of estimating the Lipschitz constant across the domain (computationally expensive in high dimensions) and repeated maximization of penalized acquisition functions; asymptotic complexity noted as O(d^3) in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Operates on acquisition functions (e.g., EI) rather than explicit information-theoretic metrics; penalization indirectly drives diversity of information by forcing spatial separation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploitation via selecting high-acquisition points; exploration encouraged by local penalization which forces later batch members to occupy alternative regions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit via local penalization radii computed from Lipschitz constant estimates, ensuring selected batch members are separated.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch-size constraint (LP is used to fill fixed-size batches during experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Fills batch iteratively up to the desired size using the penalized acquisition function; relies on Lipschitz constant estimate to set penalization magnitude/radius.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Regret after epochs; LP's effectiveness depends on quality of Lipschitz constant estimate which affects allocation and hence discovery probability.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3: Branin-Hoo regret 0.637 (std 1.28); Camelback-6 regret 0.0292 (std 0.0947); Hartmann regret 0.916 (std 0.673); SVM RMSE 1.9441 (std 0.00105); Malaria task: not run/intractable (X).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to KMBBO, B3O, Constant Liar, Thompson, Naive qEI, Batch-PES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>LP performed poorly on some tasks (e.g., Branin-Hoo) due to poor Lipschitz constant estimates dominating the domain and being unsuited near optima; in high dimensions LP is hamstrung by the cost of approximating the Lipschitz constant.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No clear efficiency gains in high-dimensional settings; LP can be effective in moderate dimensions when Lipschitz estimates are accurate but computationally costly and sensitive to global estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The method trades the computational cost of global Lipschitz estimation for more diverse batch composition; poor Lipschitz estimates can lead to suboptimal allocation (insufficient local exploration or excessive penalization).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Local penalization is useful when reliable Lipschitz constants can be estimated; however, for problems where the Lipschitz constant is dominated by behavior far from optima or in high dimensions, alternative mechanisms (e.g., clustering-based KMBBO) are preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2627.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Constant Liar</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constant Liar (CL) batch method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sequential batch construction heuristic where, when constructing a batch, each newly chosen point is temporarily added to the GP training set with a 'lie' (a fixed assumed value, commonly the predictive mean), the GP is refit and the next point selected; after the batch is filled, true evaluations replace the lies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Kriging is well-suited to parallelize optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Constant Liar (sequential pseudo-evaluation batching)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CL builds a batch sequentially by iteratively selecting the maximizer of the single-point acquisition function, inserting a synthetic observation (the 'lie') for that point (commonly the GP mean), refitting the GP with the lie included, and repeating until k points are selected; the lies are placeholders that allow greedy batch construction without joint multi-point optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization across various tasks; used as a baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy sequential allocation under a surrogate model augmented by synthetic observations (lies) to account for batch members already chosen; the choice of lie influences exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost of repeated GP refitting per inserted lie (k refits per batch) and acquisition maximizations; sensitivity to GP hyperparameter convergence is noted as an issue.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses single-point acquisition functions (e.g., EI) in a greedy manner; does not explicitly optimize joint information but uses the lie to approximate batch effects.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Greedy exploitation of acquisition maxima; the behavior depends on the lie choice — using the GP mean can lead to over-exploration or erratic posterior shifts due to incorrect assumptions about future observations.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit and limited: the synthetic augmentation can cause spread if the lie induces posterior changes, but there is no explicit diversity-promoting step.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size per epoch (used to fill exactly k points).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Fills the batch greedily by sequential insertion of synthetic observations; no explicit global budget optimization beyond filling fixed batch slots.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Regret and number of evaluations to encounter global optimum; observed to be capable of quickly reducing regret in some tasks but also susceptible to poor behavior when GP hyperparameters or lies are inappropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3: Branin-Hoo regret 0.00584 (std 0.00129); Camelback-6 regret 0.0778 (std 0.207); Hartmann regret 1.70 (std 0.511); SVM RMSE 1.9430 (std 0.000802); Malaria: not run due to GP convergence failures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against KMBBO, B3O, LP, Thompson, Naive qEI, Batch-PES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>CL often approaches good performance quickly (e.g., Branin), but in some tasks it over-explores and selects suboptimal points due to the lie assumption; in high-dimensional Malaria experiments CL suffered GP convergence failures and many runs failed.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Simple to implement and can be computationally cheaper per-batch than full joint optimization, but requires repeated GP refitting; efficiency depends heavily on GP fitting stability.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>CL trades the complexity of joint batch optimization for repeated single-point optimizations with synthetic data; this reduces computational burden but at the cost of possible posterior distortion when lies are poor, causing suboptimal allocations.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>CL is a practical heuristic for constructing batches, but its performance depends strongly on the choice of lie and GP model quality; it is less robust than KMBBO in the experiments presented.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2627.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>qEI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-point Expected Improvement (q-EI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generalization of Expected Improvement to batches of q points (q-EI) that aims to choose a joint set of q evaluations to maximize the expected joint improvement; exact joint maximization is computationally challenging for increasing q.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A multi-points criterion for deterministic parallel global optimization based on kriging</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>qEI (multi-point Expected Improvement)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>qEI defines the expected improvement obtainable from evaluating a set of q points jointly and, in principle, selects the set that maximizes this joint expected improvement. Practical implementations use approximations or heuristics because exact evaluation and gradient computation scale poorly with q.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization for expensive black-box functions (used as baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate a batch by (ideally) maximizing the q-point Expected Improvement, which jointly accounts for correlations between batch points under the GP posterior; computational intractability usually forces heuristics (e.g., greedy picks, approximations).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost of evaluating qEI and its derivatives; cost scales poorly with batch size q, making exact joint optimization expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Improvement aggregated over q points (an expected utility metric oriented toward objective improvement rather than information-theoretic measures).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Tradeoff encoded in EI: favors points with high mean and/or high variance; joint qEI ideally balances exploration/exploitation across the batch but approximations (e.g., greedy) may reduce joint optimality.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit in joint formulation: qEI accounts for posterior covariances between points, so joint maximization tends to avoid redundant (highly correlated) batch members; practical heuristics may weaken this effect.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size q.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Sets batch size to q and seeks the joint maximizer of qEI; due to computational scaling, practical methods use approximations or sequential greedy procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Expected improvement (utility) and downstream regret metrics used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3: Naive qEI (reported as Naieve qEI) results after 10 epochs: Branin-Hoo regret 0.803 (std 1.47); Camelback-6 regret 0.0276 (std 0.0974); Hartmann regret 1.74 (std 0.700); SVM RMSE 1.9453 (std 0.00170); Malaria regret 3.1185 (std 0.8392).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared with KMBBO, B3O, LP, Constant Liar, Thompson, Batch-PES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Naive qEI can perform poorly if simply selecting closest q points to a peak (leading to local exploitation) as seen in toy example and some benchmarks; KMBBO and B3O generally outperform naive joint/approximate qEI in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Exact qEI is computationally expensive and often impractical for larger q; naive or greedy approximations are faster but can be much less effective.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Highlights computational tradeoff: exact joint optimization of qEI gives principled allocation but is computationally heavy (scales poorly with q), so practical tradeoffs favor heuristic or approximate approaches that sacrifice joint optimality for tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Joint expected-improvement is the correct objective for batch allocation but practical constraints (computational cost) require approximations; clustering-based approaches like KMBBO offer a tractable alternative that approximates targeting high-EI regions while enforcing diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2627.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2627.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Thompson</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallel Thompson Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fully parallel batch sampling technique where multiple posterior samples (a 'panel of experts') are drawn and each is used to propose a point to evaluate, enabling parallel selection by sampling from the posterior rather than optimizing acquisition functions jointly.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Parallel Thompson Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Parallel Thompson sampling samples functions from the GP posterior (or other surrogate posterior) to produce multiple instantiated 'hypotheses' (experts); each sampled function's maximizer is selected as a batch candidate, enabling fully-parallel batch construction without sequential dependency.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimization and large-scale exploration of chemical or other large search spaces (used as baseline in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate batch members by independently sampling posterior functions and selecting their maxima, thereby covering diverse plausible optima according to posterior uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cost of posterior sampling and maximization for each sampled function; overall runtime per epoch dominated by sampling and optimization of sampled functions but typically cheaper than joint acquisition optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not directly maximize an explicit information-theoretic metric; diversity arises from posterior variability — selections reflect posterior uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration is encouraged via randomness of posterior samples (diverse sampled functions); exploitation occurs when posterior concentrates around promising regions so sampled maxima cluster there.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit: independent posterior samples produce diverse candidate points reflecting epistemic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed batch size (number of posterior samples equals batch size).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Generates as many posterior samples as batch slots and picks each sampled-function maximizer to fill the batch; degree of parallelism limited by number of samples/compute resources.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured via regret and the speed of locating the global optimum; in experiments Thompson sampling finds optima reasonably but sometimes converges to local maxima.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 3: Thompson sampling after 10 epochs: Branin-Hoo regret 0.00619 (std 0.00186); Camelback-6 regret 0.0727 (std 0.179); Hartmann regret 1.33 (std 0.438); SVM RMSE 1.9430 (std 0.00125); Malaria regret 3.0000 (std 1.0888).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to KMBBO, B3O, LP, Constant Liar, Naive qEI, Batch-PES.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Thompson sampling performs competitively on several tasks, but KMBBO often finds optima earlier and with lower variance; in high-dimensional drug discovery Thompson converged to local maxima less effectively than KMBBO.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Parallelizable with modest computational cost per sampled function; avoids iterative batch-construction refits but may require many samples to explore complex posteriors.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Offers a tradeoff of simplicity and parallelism vs potentially noisy, high-variance selection: independent samples can provide diversity cheaply but lack explicit joint coordination to avoid redundant evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Parallel Thompson sampling is a scalable and simple method to fill fixed batch slots and captures posterior uncertainty, but clustering-based or information-aware batch methods (like KMBBO or PPES) can yield better coordinated allocations when computational budget for batch selection permits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient and Scalable Batch Bayesian Optimization Using K-Means', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Parallel predictive entropy search for batch global optimization of expensive objective functions <em>(Rating: 2)</em></li>
                <li>Batch bayesian optimization via local penalization <em>(Rating: 2)</em></li>
                <li>Parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space <em>(Rating: 2)</em></li>
                <li>A multi-points criterion for deterministic parallel global optimization based on kriging <em>(Rating: 2)</em></li>
                <li>Budgeted Batch Bayesian Optimization <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2627",
    "paper_id": "paper-554d3f58f62bfa76a5c8c55f597d62fcfa17ef9a",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "KMBBO",
            "name_full": "K-Means Batch Bayesian Optimization",
            "brief_description": "A batch Bayesian optimization algorithm that uses slice sampling on an acquisition function to collect candidate points and then fits K-Means to those samples to choose batch evaluation centroids, enabling direct control of batch size while promoting coverage of acquisition peaks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "K-Means Batch Bayesian Optimization (KMBBO)",
            "system_description": "KMBBO constructs batches by (1) fitting a Gaussian Process model and computing an acquisition function (Expected Improvement in the experiments), (2) drawing slice samples from the volume under the acquisition function (Batch Generalized Slice Sampling, BGSS), (3) clustering those slice samples with K-Means using the desired batch size k to obtain k centroids, and (4) evaluating the objective f at the centroids and adding results to the dataset. The approach thus approximates peaks/modes of the acquisition function efficiently and directly enforces a fixed batch size via the number of clusters.",
            "application_domain": "General black-box optimization tasks; demonstrated on synthetic optimization (Branin, Camelback, Hartmann), machine-learning hyperparameter tuning (SVM), and drug discovery (malaria compound potency) — i.e., algorithm hyperparameter tuning and drug discovery.",
            "resource_allocation_strategy": "Allocates a fixed number k of parallel evaluations per epoch by clustering slice samples from the acquisition function and selecting cluster centroids as batch candidates. This chooses points concentrated in high-acquisition-density regions while spreading remaining centroids over other high-density regions to utilize all k slots.",
            "computational_cost_metric": "Empirical wall-clock runtime per sampling epoch (seconds per epoch) and asymptotic scaling of subroutines (e.g., K-Means runtime and slice sampling sampling cost). The paper reports seconds/epoch timings (Figure 7) and notes scaling behaviors: slice sampling O(2^d) and K-Means is relatively cheap.",
            "information_gain_metric": "Uses Expected Improvement (EI) as the acquisition function to guide sampling; slice sampling is performed under the EI surface so selection favors regions of high expected improvement.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Balances exploitation by sampling regions of high expected improvement (slice samples concentrate under high EI) and exploration/diversification via K-Means clustering which forces centroids to spread across distinct high-density regions; when fewer local optima exist than batch size, squared-distance objective of K-Means distributes extra centroids across sample space.",
            "diversity_mechanism": "K-Means clustering of slice samples produces centroids that are representative and spatially separated; the within-cluster-sum-of-squares objective induces spread when peaks &lt; batch size, promoting diverse batch composition.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed number of parallel experiments per epoch (fixed batch size); implicit assumption that objective evaluations are expensive relative to batch-computation cost.",
            "budget_constraint_handling": "Directly enforces a fixed batch size by setting the number of K-Means clusters k; for high-dimensional tasks, uses CS-KMBBO (compressed sensing step) to reduce sampling/computational burden so that slice sampling and clustering remain tractable within the fixed-batch regime.",
            "breakthrough_discovery_metric": "Instantaneous regret (distance from global optimum) and 'first encounter time' (epoch when global optimum first located); also domain-specific metrics such as RMSE for SVM tuning and PEC50 potency/regret for drug discovery.",
            "performance_metrics": "Reported final-performance after 10 epochs (Table 3): Branin-Hoo regret 0.00523 (std 0.000488); Camelback-6 regret 0.0354 (std 0.0616); Hartmann (6D) regret 0.922 (std 0.311); SVM RMSE 1.9416 (std 0.000577); Malaria (drug discovery) regret 2.3802 (std 1.4003). Also reported faster runtime per epoch than B3O in 2D and 6D (Figure 7).",
            "comparison_baseline": "Compared against Naive qEI, Thompson sampling, Constant Liar (mean), Local Penalization (LP), Batch Predictive Entropy Search (Batch-PES), and B3O.",
            "performance_vs_baseline": "KMBBO achieved the best or near-best performance across the tested tasks and the best normalized ranking Z for optimization performance (Figure 6). In Branin-Hoo it locates the optimum earlier and more consistently than others; in SVM tuning it achieves lowest RMSE among methods; in the Malaria task, KMBBO reaches lower regret than Thompson, qEI and Batch-PES after 10 epochs while sampling only 90 of ~19,000 candidates.",
            "efficiency_gain": "Empirically lower runtime per sampling epoch than B3O (qualitative: 'generally significantly smaller' seconds/epoch in Fig.7); also achieves comparable or better optimization with limited numbers of objective evaluations (e.g., 90 evaluations on Malaria producing lower regret than baselines).",
            "tradeoff_analysis": "Discusses tradeoffs between computation used to select batches and the cost of objective evaluations: asserts that expensive ground-truth evaluations dominate so more costly but higher-quality batch selection (e.g., KMBBO) is acceptable. Also analyzes dimensionality tradeoffs: slice sampling scales poorly with dimension (O(2^d)), motivating compressed sensing; KMBBO offers better per-epoch runtime than IGMM-based B3O.",
            "optimal_allocation_findings": "For fixed-batch scenarios, selecting batch members as cluster centroids of slice samples drawn under the acquisition function is an effective allocation strategy: it concentrates evaluations on high expected-improvement regions while ensuring diversity. For high-dimensional problems, compressing the input space before running KMBBO (CS-KMBBO) yields tractable sampling and maintains or improves performance.",
            "uuid": "e2627.0",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "CS-KMBBO",
            "name_full": "Compressed Sensing K-Means Batch Bayesian Optimization",
            "brief_description": "A high-dimensional variant of KMBBO that applies compressed sensing (TwIST) to reduce input dimensionality before performing slice sampling and K-Means batch construction, reducing the computational cost of sampling in high dimensions while retaining optimization performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "CS-KMBBO (KMBBO with compressed sensing)",
            "system_description": "CS-KMBBO first samples a subset of the domain and uses Two-step Iterative Shrinkage/Thresholding (TwIST) to determine a sparse compressed basis and optimal compressed dimensionality under a reconstruction tolerance; the domain is compressed to this lower-dimensional subspace (using compressed sensing principles), then KMBBO (slice sampling + K-Means) is run in the compressed space and the chosen centroids are mapped back (decompressed) for evaluation.",
            "application_domain": "High-dimensional black-box optimization problems; demonstrated on a drug-discovery task with 167-dimensional molecular descriptors.",
            "resource_allocation_strategy": "Same batch-allocation mechanism as KMBBO (fixed k centroids from K-Means on slice samples) but operating in a compressed low-dimensional representation chosen to preserve relevant structure while drastically reducing sampling/computation required for slice sampling.",
            "computational_cost_metric": "Wall-clock runtime per sampling epoch and sampling scalability; addresses the O(2^d) poor scaling of slice sampling by reducing d via compressed sensing. The compressed-space dimensionality M is governed by M ∝ μ^2 S log(N)^2 (Candès & Wakin formula).",
            "information_gain_metric": "Relies on the Expected Improvement acquisition function (same as KMBBO); slice samples drawn under EI in the compressed space approximate high-EI regions.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploitative focus preserved by slice sampling under EI in compressed space; exploration encouraged via K-Means centroid spread and the compressed representation which may emphasize salient, diverse signal components.",
            "diversity_mechanism": "Indirect: K-Means clustering in compressed space yields centroids that cover distinct high-acquisition regions; compression may also filter noise and emphasize diverse informative directions.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size with additional computational budget constraints due to high dimensionality (practical limits on number of slice samples and runtime).",
            "budget_constraint_handling": "Handles computational budget by compressing the domain to the smallest dimension that meets a reconstruction tolerance ε (TwIST procedure on sampled points), thereby reducing the runtime and sample requirements for BGSS and clustering while enabling fixed-size batches.",
            "breakthrough_discovery_metric": "Same as KMBBO — regret and task-specific metrics (e.g., potency regret for drug discovery). Demonstrated ability to find low-regret compounds with few evaluations in high-dimensional space.",
            "performance_metrics": "In the Malaria (167D) experiment CS-KMBBO is reported as one of the methods able to be used on the high-dimensional task and shows better performance than several other methods that failed or were intractable; specific numeric Malaria results for CS-KMBBO are given in figures and qualitative comparison (Table 3 shows KMBBO entry; CS-KMBBO discussed qualitatively as effective).",
            "comparison_baseline": "Compared implicitly/qualitatively against B3O, LP, Constant Liar, Thompson, qEI, and Batch-PES in the high-dimensional Malaria task; many baselines failed or were intractable.",
            "performance_vs_baseline": "In the 167-dimensional Malaria task, CS-KMBBO (and KMBBO variants) outperform methods that could run (Thompson, qEI, Batch-PES) in terms of reaching lower regret with a small number of evaluations; other methods (B3O, LP, Constant Liar) were either intractable or failed to converge.",
            "efficiency_gain": "Enables tractable batch construction where slice sampling would otherwise be computationally infeasible (avoids exponential slice-sampling cost in original dimension); qualitative speedups reported as enabling the method to be used on a 167D problem with acceptable runtime.",
            "tradeoff_analysis": "Analyzes tradeoff between dimensionality reduction loss and tractability: compressed sensing reduces computation (and slice-sampling sample requirements) at potential risk of losing some information; empirical results show CS-KMBBO can outperform methods run in full space, suggesting compression preserves relevant structure for allocation decisions.",
            "optimal_allocation_findings": "For very high-dimensional problems, it is recommended to compress the domain using TwIST-based compressed sensing to a minimal dimension satisfying reconstruction tolerance and then run batch allocation (KMBBO) in the compressed space to achieve good tradeoffs between computational cost and information-directed sampling.",
            "uuid": "e2627.1",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "B3O",
            "name_full": "Budgeted Batch Bayesian Optimization",
            "brief_description": "A dynamic batch selection method designed to build batches containing peaks of the acquisition function using generalized slice sampling followed by peak identification (Infinite Gaussian Mixture Model), with an emphasis on discovering peaks without costly optimization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Budgeted Batch Bayesian Optimization (B3O)",
            "system_description": "B3O performs generalized slice sampling over the acquisition function to obtain samples concentrated in high-acquisition regions, then fits an Infinite Gaussian Mixture Model (IGMM) to identify peaks and assemble batches around the inferred modes. It is dynamic in the sense that batch sizes can adapt to the number of detected peaks.",
            "application_domain": "General black-box optimization and Bayesian optimization tasks (benchmark hyperparameter tuning and synthetic functions in the paper).",
            "resource_allocation_strategy": "Allocates batch members by identifying peaks of the acquisition function via slice sampling and IGMM peak picking; does not enforce a fixed batch size (dynamic), potentially allocating fewer or more points depending on the number of detected peaks.",
            "computational_cost_metric": "Empirical runtime per sampling epoch (seconds) and scalability of BGSS + IGMM; slice sampling scales poorly with dimension (O(2^d)), and IGMM clustering has nontrivial computational cost and sensitivity to slice-sample count.",
            "information_gain_metric": "Indirect: focuses on locating acquisition-function peaks (e.g., high Expected Improvement locations) rather than an explicit information-theoretic metric; uses slice sampling to sample under the acquisition function surface.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploit by concentrating on modes of the acquisition function (peak-centric selection); exploration arises if multiple distinct peaks are found (IGMM allocates samples around distinct peaks).",
            "diversity_mechanism": "Implicit via IGMM: multiple mixture components correspond to distinct acquisition peaks, producing batch members across different peaks; sensitivity to number of slice samples can affect diversity.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Designed as budget-aware/dynamic batch method (allocates number of batch points based on detected peaks) but does not directly accommodate a fixed batch size constraint.",
            "budget_constraint_handling": "Allocates according to detected peaks; the inability to enforce exact fixed batch sizes is noted as a limitation in contexts where a fixed number of experimental slots are available.",
            "breakthrough_discovery_metric": "Same optimization/regret metrics (e.g., regret after epochs); B3O was evaluated on synthetic functions and hyperparameter tuning tasks with regret metrics.",
            "performance_metrics": "Table 3 reports B3O after 10 epochs: Branin-Hoo regret 0.00591 (std 0.00170); Camelback-6 regret 0.130 (std 0.338); Hartmann regret 0.882 (std 0.320); SVM RMSE 1.9422 (std 0.000580); Malaria task not run/intractable (X in table).",
            "comparison_baseline": "Compared to KMBBO, LP, Constant Liar, Thompson sampling, Naive qEI, and Batch-PES.",
            "performance_vs_baseline": "B3O performs well on low-to-moderate dimensional tasks and comparably to KMBBO in several cases (e.g., similar regret on Hartmann), but is intractable or impractical in very high dimensions due to slice-sampling scalability and high sample requirements.",
            "efficiency_gain": "No clear efficiency gain in high dimensions; on low-dimensional problems it can effectively identify multiple peaks, but runtime and sample requirements grow quickly with dimensionality compared to KMBBO (which uses K-Means instead of IGMM).",
            "tradeoff_analysis": "Paper highlights B3O's tradeoff between adaptively determining batch size (which can be advantageous) and the practical inability to enforce fixed batch sizes; also emphasizes the high computational cost of slice sampling and IGMM in high dimensions.",
            "optimal_allocation_findings": "B3O is effective at identifying multiple acquisition peaks and assembling informative batches when slice sampling can produce sufficient samples, but for fixed-batch or high-dimensional settings, methods that enforce batch size and use cheaper clustering (such as KMBBO) are preferable.",
            "uuid": "e2627.2",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "PPES",
            "name_full": "Parallel Predictive Entropy Search",
            "brief_description": "A non-greedy batch sampling approach that selects batches to maximize expected information gain about the location of the global maximizer, measured as expected reduction in differential entropy of the predictive distribution of the maximizer.",
            "citation_title": "Parallel predictive entropy search for batch global optimization of expensive objective functions",
            "mention_or_use": "use",
            "system_name": "Parallel Predictive Entropy Search (PPES / Batch-PES)",
            "system_description": "PPES constructs batches by optimizing the expected reduction in entropy (differential entropy) of the posterior over the global optimizer induced by evaluating the batch; selection is explicitly information-theoretic and non-greedy, aiming to maximize mutual information between observations and the optimizer.",
            "application_domain": "Batch Bayesian optimization for expensive black-box functions (general use; used in experiments as a baseline).",
            "resource_allocation_strategy": "Selects batches that maximize expected information gain about the location of the global maximizer (expected entropy reduction) subject to batch-size constraints.",
            "computational_cost_metric": "Computational complexity of estimating expected entropy reductions and optimizing over batch choices; practical runtime per epoch (reported in experiments as baseline runtimes and variance issues).",
            "information_gain_metric": "Expected reduction in differential entropy of the predictive distribution of the global maximizer (explicit information-theoretic metric).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Primarily exploration-oriented via information maximization about the maximizer; implicitly balances exploitation because information about high-performing areas is prioritized if it reduces uncertainty about the optimizer.",
            "diversity_mechanism": "Implicit through information-theoretic objective: selecting points that together maximize joint information encourages diversity to reduce posterior uncertainty maximally.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size (used as a baseline with batch-size constraint in experiments).",
            "budget_constraint_handling": "Optimizes expected entropy reduction for the specified batch size; computationally expensive and can have high variance in runs (paper notes large variance for batch-PES in SVM experiment).",
            "breakthrough_discovery_metric": "Entropy reduction focused on identifying the global maximizer; performance measured via regret and final optimization results.",
            "performance_metrics": "In Table 3 batch-PES results after 10 epochs: Branin-Hoo regret 0.5486 (std 0.3682); Camelback-6 regret 0.1619 (std 0.0967); Hartmann regret 1.4257 (std 0.4736); SVM RMSE 1.9406 (std 0.7322); Malaria regret 3.2626 (std 0.7322).",
            "comparison_baseline": "Compared against KMBBO, B3O, LP, Constant Liar, Thompson, Naive qEI.",
            "performance_vs_baseline": "Batch-PES exhibited high variance and, in some tasks, inferior median performance compared to KMBBO and other baselines; however it is an explicit information-maximizing method and can be advantageous where computational cost is acceptable.",
            "efficiency_gain": "No explicit efficiency gains reported; computational cost can be high and variance large (noted as problematic in SVM experiment).",
            "tradeoff_analysis": "Paper contrasts non-greedy information-maximizing approaches (like PPES) with greedy or clustering-based batch construction; notes that information-theoretic methods can be computationally costly and high-variance in practice, making them sometimes less reliable when evaluations are very expensive or noisy.",
            "optimal_allocation_findings": "Maximizing expected information about the optimizer is principled for batch allocation, but practical application requires managing computational cost and variance; KMBBO is presented as a pragmatic alternative that approximates high-information regions while being computationally cheaper.",
            "uuid": "e2627.3",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Local Penalization",
            "name_full": "Batch Bayesian Optimization via Local Penalization",
            "brief_description": "A sequential batch assembly method that penalizes the acquisition function locally around already-selected batch points using a penalization radius informed by an estimated Lipschitz constant, thereby pushing subsequent selections away from previously chosen points to encourage diversity.",
            "citation_title": "Batch bayesian optimization via local penalization",
            "mention_or_use": "use",
            "system_name": "Local Penalization (LP)",
            "system_description": "LP sequentially builds a batch by iteratively selecting the maximizer of a locally-penalized acquisition function: after picking a point, the acquisition function is multiplicatively penalized in a neighborhood (radius derived from an estimated Lipschitz constant) to reduce the utility of nearby points, encouraging spatially diverse batches.",
            "application_domain": "Batch Bayesian optimization across various low-to-moderate dimensional tasks (benchmarked in the paper).",
            "resource_allocation_strategy": "Greedy sequential allocation within each batch: pick top acquisition candidate, apply local penalization around it, then pick next candidate from the penalized acquisition; repeat until batch filled.",
            "computational_cost_metric": "Cost of estimating the Lipschitz constant across the domain (computationally expensive in high dimensions) and repeated maximization of penalized acquisition functions; asymptotic complexity noted as O(d^3) in the paper.",
            "information_gain_metric": "Operates on acquisition functions (e.g., EI) rather than explicit information-theoretic metrics; penalization indirectly drives diversity of information by forcing spatial separation.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploitation via selecting high-acquisition points; exploration encouraged by local penalization which forces later batch members to occupy alternative regions.",
            "diversity_mechanism": "Explicit via local penalization radii computed from Lipschitz constant estimates, ensuring selected batch members are separated.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch-size constraint (LP is used to fill fixed-size batches during experiments).",
            "budget_constraint_handling": "Fills batch iteratively up to the desired size using the penalized acquisition function; relies on Lipschitz constant estimate to set penalization magnitude/radius.",
            "breakthrough_discovery_metric": "Regret after epochs; LP's effectiveness depends on quality of Lipschitz constant estimate which affects allocation and hence discovery probability.",
            "performance_metrics": "Table 3: Branin-Hoo regret 0.637 (std 1.28); Camelback-6 regret 0.0292 (std 0.0947); Hartmann regret 0.916 (std 0.673); SVM RMSE 1.9441 (std 0.00105); Malaria task: not run/intractable (X).",
            "comparison_baseline": "Compared to KMBBO, B3O, Constant Liar, Thompson, Naive qEI, Batch-PES.",
            "performance_vs_baseline": "LP performed poorly on some tasks (e.g., Branin-Hoo) due to poor Lipschitz constant estimates dominating the domain and being unsuited near optima; in high dimensions LP is hamstrung by the cost of approximating the Lipschitz constant.",
            "efficiency_gain": "No clear efficiency gains in high-dimensional settings; LP can be effective in moderate dimensions when Lipschitz estimates are accurate but computationally costly and sensitive to global estimates.",
            "tradeoff_analysis": "The method trades the computational cost of global Lipschitz estimation for more diverse batch composition; poor Lipschitz estimates can lead to suboptimal allocation (insufficient local exploration or excessive penalization).",
            "optimal_allocation_findings": "Local penalization is useful when reliable Lipschitz constants can be estimated; however, for problems where the Lipschitz constant is dominated by behavior far from optima or in high dimensions, alternative mechanisms (e.g., clustering-based KMBBO) are preferable.",
            "uuid": "e2627.4",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Constant Liar",
            "name_full": "Constant Liar (CL) batch method",
            "brief_description": "A sequential batch construction heuristic where, when constructing a batch, each newly chosen point is temporarily added to the GP training set with a 'lie' (a fixed assumed value, commonly the predictive mean), the GP is refit and the next point selected; after the batch is filled, true evaluations replace the lies.",
            "citation_title": "Kriging is well-suited to parallelize optimization",
            "mention_or_use": "use",
            "system_name": "Constant Liar (sequential pseudo-evaluation batching)",
            "system_description": "CL builds a batch sequentially by iteratively selecting the maximizer of the single-point acquisition function, inserting a synthetic observation (the 'lie') for that point (commonly the GP mean), refitting the GP with the lie included, and repeating until k points are selected; the lies are placeholders that allow greedy batch construction without joint multi-point optimization.",
            "application_domain": "Batch Bayesian optimization across various tasks; used as a baseline in experiments.",
            "resource_allocation_strategy": "Greedy sequential allocation under a surrogate model augmented by synthetic observations (lies) to account for batch members already chosen; the choice of lie influences exploration/exploitation.",
            "computational_cost_metric": "Cost of repeated GP refitting per inserted lie (k refits per batch) and acquisition maximizations; sensitivity to GP hyperparameter convergence is noted as an issue.",
            "information_gain_metric": "Uses single-point acquisition functions (e.g., EI) in a greedy manner; does not explicitly optimize joint information but uses the lie to approximate batch effects.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Greedy exploitation of acquisition maxima; the behavior depends on the lie choice — using the GP mean can lead to over-exploration or erratic posterior shifts due to incorrect assumptions about future observations.",
            "diversity_mechanism": "Implicit and limited: the synthetic augmentation can cause spread if the lie induces posterior changes, but there is no explicit diversity-promoting step.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed batch size per epoch (used to fill exactly k points).",
            "budget_constraint_handling": "Fills the batch greedily by sequential insertion of synthetic observations; no explicit global budget optimization beyond filling fixed batch slots.",
            "breakthrough_discovery_metric": "Regret and number of evaluations to encounter global optimum; observed to be capable of quickly reducing regret in some tasks but also susceptible to poor behavior when GP hyperparameters or lies are inappropriate.",
            "performance_metrics": "Table 3: Branin-Hoo regret 0.00584 (std 0.00129); Camelback-6 regret 0.0778 (std 0.207); Hartmann regret 1.70 (std 0.511); SVM RMSE 1.9430 (std 0.000802); Malaria: not run due to GP convergence failures.",
            "comparison_baseline": "Compared against KMBBO, B3O, LP, Thompson, Naive qEI, Batch-PES.",
            "performance_vs_baseline": "CL often approaches good performance quickly (e.g., Branin), but in some tasks it over-explores and selects suboptimal points due to the lie assumption; in high-dimensional Malaria experiments CL suffered GP convergence failures and many runs failed.",
            "efficiency_gain": "Simple to implement and can be computationally cheaper per-batch than full joint optimization, but requires repeated GP refitting; efficiency depends heavily on GP fitting stability.",
            "tradeoff_analysis": "CL trades the complexity of joint batch optimization for repeated single-point optimizations with synthetic data; this reduces computational burden but at the cost of possible posterior distortion when lies are poor, causing suboptimal allocations.",
            "optimal_allocation_findings": "CL is a practical heuristic for constructing batches, but its performance depends strongly on the choice of lie and GP model quality; it is less robust than KMBBO in the experiments presented.",
            "uuid": "e2627.5",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "qEI",
            "name_full": "Multi-point Expected Improvement (q-EI)",
            "brief_description": "A generalization of Expected Improvement to batches of q points (q-EI) that aims to choose a joint set of q evaluations to maximize the expected joint improvement; exact joint maximization is computationally challenging for increasing q.",
            "citation_title": "A multi-points criterion for deterministic parallel global optimization based on kriging",
            "mention_or_use": "use",
            "system_name": "qEI (multi-point Expected Improvement)",
            "system_description": "qEI defines the expected improvement obtainable from evaluating a set of q points jointly and, in principle, selects the set that maximizes this joint expected improvement. Practical implementations use approximations or heuristics because exact evaluation and gradient computation scale poorly with q.",
            "application_domain": "Batch Bayesian optimization for expensive black-box functions (used as baseline).",
            "resource_allocation_strategy": "Allocate a batch by (ideally) maximizing the q-point Expected Improvement, which jointly accounts for correlations between batch points under the GP posterior; computational intractability usually forces heuristics (e.g., greedy picks, approximations).",
            "computational_cost_metric": "Computational cost of evaluating qEI and its derivatives; cost scales poorly with batch size q, making exact joint optimization expensive.",
            "information_gain_metric": "Expected Improvement aggregated over q points (an expected utility metric oriented toward objective improvement rather than information-theoretic measures).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Tradeoff encoded in EI: favors points with high mean and/or high variance; joint qEI ideally balances exploration/exploitation across the batch but approximations (e.g., greedy) may reduce joint optimality.",
            "diversity_mechanism": "Implicit in joint formulation: qEI accounts for posterior covariances between points, so joint maximization tends to avoid redundant (highly correlated) batch members; practical heuristics may weaken this effect.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size q.",
            "budget_constraint_handling": "Sets batch size to q and seeks the joint maximizer of qEI; due to computational scaling, practical methods use approximations or sequential greedy procedures.",
            "breakthrough_discovery_metric": "Expected improvement (utility) and downstream regret metrics used in experiments.",
            "performance_metrics": "Table 3: Naive qEI (reported as Naieve qEI) results after 10 epochs: Branin-Hoo regret 0.803 (std 1.47); Camelback-6 regret 0.0276 (std 0.0974); Hartmann regret 1.74 (std 0.700); SVM RMSE 1.9453 (std 0.00170); Malaria regret 3.1185 (std 0.8392).",
            "comparison_baseline": "Compared with KMBBO, B3O, LP, Constant Liar, Thompson, Batch-PES.",
            "performance_vs_baseline": "Naive qEI can perform poorly if simply selecting closest q points to a peak (leading to local exploitation) as seen in toy example and some benchmarks; KMBBO and B3O generally outperform naive joint/approximate qEI in the experiments.",
            "efficiency_gain": "Exact qEI is computationally expensive and often impractical for larger q; naive or greedy approximations are faster but can be much less effective.",
            "tradeoff_analysis": "Highlights computational tradeoff: exact joint optimization of qEI gives principled allocation but is computationally heavy (scales poorly with q), so practical tradeoffs favor heuristic or approximate approaches that sacrifice joint optimality for tractability.",
            "optimal_allocation_findings": "Joint expected-improvement is the correct objective for batch allocation but practical constraints (computational cost) require approximations; clustering-based approaches like KMBBO offer a tractable alternative that approximates targeting high-EI regions while enforcing diversity.",
            "uuid": "e2627.6",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Thompson",
            "name_full": "Parallel Thompson Sampling",
            "brief_description": "A fully parallel batch sampling technique where multiple posterior samples (a 'panel of experts') are drawn and each is used to propose a point to evaluate, enabling parallel selection by sampling from the posterior rather than optimizing acquisition functions jointly.",
            "citation_title": "Parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space",
            "mention_or_use": "use",
            "system_name": "Parallel Thompson Sampling",
            "system_description": "Parallel Thompson sampling samples functions from the GP posterior (or other surrogate posterior) to produce multiple instantiated 'hypotheses' (experts); each sampled function's maximizer is selected as a batch candidate, enabling fully-parallel batch construction without sequential dependency.",
            "application_domain": "Batch Bayesian optimization and large-scale exploration of chemical or other large search spaces (used as baseline in experiments).",
            "resource_allocation_strategy": "Allocate batch members by independently sampling posterior functions and selecting their maxima, thereby covering diverse plausible optima according to posterior uncertainty.",
            "computational_cost_metric": "Cost of posterior sampling and maximization for each sampled function; overall runtime per epoch dominated by sampling and optimization of sampled functions but typically cheaper than joint acquisition optimization.",
            "information_gain_metric": "Does not directly maximize an explicit information-theoretic metric; diversity arises from posterior variability — selections reflect posterior uncertainty.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration is encouraged via randomness of posterior samples (diverse sampled functions); exploitation occurs when posterior concentrates around promising regions so sampled maxima cluster there.",
            "diversity_mechanism": "Implicit: independent posterior samples produce diverse candidate points reflecting epistemic uncertainty.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed batch size (number of posterior samples equals batch size).",
            "budget_constraint_handling": "Generates as many posterior samples as batch slots and picks each sampled-function maximizer to fill the batch; degree of parallelism limited by number of samples/compute resources.",
            "breakthrough_discovery_metric": "Measured via regret and the speed of locating the global optimum; in experiments Thompson sampling finds optima reasonably but sometimes converges to local maxima.",
            "performance_metrics": "Table 3: Thompson sampling after 10 epochs: Branin-Hoo regret 0.00619 (std 0.00186); Camelback-6 regret 0.0727 (std 0.179); Hartmann regret 1.33 (std 0.438); SVM RMSE 1.9430 (std 0.00125); Malaria regret 3.0000 (std 1.0888).",
            "comparison_baseline": "Compared to KMBBO, B3O, LP, Constant Liar, Naive qEI, Batch-PES.",
            "performance_vs_baseline": "Thompson sampling performs competitively on several tasks, but KMBBO often finds optima earlier and with lower variance; in high-dimensional drug discovery Thompson converged to local maxima less effectively than KMBBO.",
            "efficiency_gain": "Parallelizable with modest computational cost per sampled function; avoids iterative batch-construction refits but may require many samples to explore complex posteriors.",
            "tradeoff_analysis": "Offers a tradeoff of simplicity and parallelism vs potentially noisy, high-variance selection: independent samples can provide diversity cheaply but lack explicit joint coordination to avoid redundant evaluations.",
            "optimal_allocation_findings": "Parallel Thompson sampling is a scalable and simple method to fill fixed batch slots and captures posterior uncertainty, but clustering-based or information-aware batch methods (like KMBBO or PPES) can yield better coordinated allocations when computational budget for batch selection permits.",
            "uuid": "e2627.7",
            "source_info": {
                "paper_title": "Efficient and Scalable Batch Bayesian Optimization Using K-Means",
                "publication_date_yy_mm": "2018-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Parallel predictive entropy search for batch global optimization of expensive objective functions",
            "rating": 2
        },
        {
            "paper_title": "Batch bayesian optimization via local penalization",
            "rating": 2
        },
        {
            "paper_title": "Parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space",
            "rating": 2
        },
        {
            "paper_title": "A multi-points criterion for deterministic parallel global optimization based on kriging",
            "rating": 2
        },
        {
            "paper_title": "Budgeted Batch Bayesian Optimization",
            "rating": 2
        }
    ],
    "cost": 0.021790249999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Efficient and Scalable Batch Bayesian Optimization Using K-Means</h1>
<p>Matthew Groves<br>IBM Research UK<br>Sci-Tech Daresbury<br>Warrington, UK.<br>M.J.Groves@warwick.ac.uk</p>
<h4>Abstract</h4>
<p>We present K-Means Batch Bayesian Optimization (KMBBO), a novel batch sampling algorithm for Bayesian Optimization (BO). KMBBO uses unsupervised learning to efficiently estimate peaks of the model acquisition function. We show in empirical experiments that our method outperforms the current state-of-the-art batch allocation algorithms on a variety of test problems including tuning of algorithm hyper-parameters and a challenging drug discovery problem. In order to accommodate the real-world problem of high dimensional data, we propose a modification to KMBBO by combining it with compressed sensing to project the optimization into a lower dimensional subspace. We demonstrate empirically that this 2step method outperforms algorithms where no dimensionality reduction has taken place.</p>
<h2>Introduction</h2>
<p>Bayesian optimization (BO) is a popular framework for the optimization of black-box functions, where the analytic form of the function being optimized is unknown, or too expensive to evaluate. BO has found extensive use for the optimization of machine learning algorithms (Snoek, Larochelle, and Adams 2012), and for experimental design of complex systems.</p>
<p>In its native form, BO is a sequential optimization procedure, since new information is required to update the posterior, and therefore the acquisition function. For many of the emerging uses of BO, this is a severe limitation since, due to the size of the optimization problem, data must be acquired in a highly parallel manner in order for the optimization to be completed in a relevant time frame. Several methods for parallelizing the BO process have been proposed, and will be reviewed in Section . It is important to point out that there are two separate, yet complementary, approaches to the parallel BO problem. One is to minimize the strict number of function evaluations, typically achieved by a dynamically allocated batch size, and the other is to minimize the number of epochs for a given batch size. Whilst there are situations in which both are valid, the focus of this paper is to minimize the number of epochs, since there are a number of situations in which a fixed batch size is required; for example</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Edward O. Pyzer-Knapp*</h2>
<p>IBM Research UK
Sci-Tech Daresbury
Warrington, UK.
epyzerk3@uk.ibm.com
in the screening of potential pharmaceutical compounds in which there are a pre-determined number of 'slots' in which compounds can be tested.</p>
<h2>Related work</h2>
<p>Ginsbourger, Le Riche, and Carraro generalize the EI to the batch setting, proposing the qEI acquisition function for batches of q points. Unfortunately, identifying the points that jointly maximize qEI is difficult, as the computational cost of evaluating the function and its derivative scales poorly with increasing q.(Ginsbourger, Le Riche, and Carraro 2007) Several works have suggested heuristic approaches for approximating qEI, (see for example (Snoek, Larochelle, and Adams 2012), (Chevalier and Ginsbourger 2013), (Wang et al. 2016)). One popular qEI-based method is the Constant Liar (CL) approach of Ginsbourger, Le Riche, and Carraro.(Ginsbourger, Le Riche, and Carraro 2010) CL is a sequential batch building method, based on iteratively adding the point that maximizes the single point acquisition function, assuming that evaluating this point will return a particular constant 'lie' value, temporarily augmenting the model training set with this synthetic values and refitting the GP.</p>
<p>In recent work, González et al. propose an alternative batching method by approximating the repulsive effect when batching.(González et al. 2016) Under a Gaussian Process prior, target values of nearby points in sample space are expected to be highly correlated. Thus, when choosing a batch of samples, we may wish for the batch members to be sufficiently far apart to maximize the information gained. To do this, the authors propose the Local Penalization (LP) method that sequentially assembles batches of samples by successively penalizing the acquisition function around points previously selected, using a penalization radius based on the estimated Lipschitz constant of the acquisition function surface.</p>
<p>The above methods all take a greedy sequential approach to batch building, iteratively adding points to the batch that maximize a particular criterion, like the locally-penalized acquisition function. In contrast, Hernández-Lobato et al. propose a fully parallel batch sampling technique using Thompson Sampling,(Thompson 1933) in which the posterior is sampled to generate a 'panel of experts' which are then polled in parallel as to which data point should be acquired.(Hernández-Lobato et al. 2017)</p>
<p>Shah and Ghahramani suggest Parallel Predictive Entropy Search (PPES), a non-greedy batch sampling approach aiming to maximize the expected information gain from sampling the chosen batch in terms of the expected reduction in differential entropy of the predictive distribution of the global maximizer given the sampling data.(Shah and Ghahramani 2015)</p>
<p>Nguyen et al. propose a novel batch selection method called Budgeted Batch Bayesian Optimization (B3O), which aims to build sample batches containing peaks of the acquisition function.(Nguyen et al. 2017) To find these peaks, whilst avoiding costly optimization routines, the authors propose a generalized slice sampling procedure. Slice sampling preferentially accepts samples from high density regions of the acquisition function surface, allowing peaks to be reliably estimated even with modest numbers of samples. Peak picking is then done using an Infinite Gaussian Mixture Model (IGMM) (Rasmussen 2000). Nguyen et al. show empirically that B3O performs well on a variety of test functions and common BO applications, such as hyperparameter tuning. However, the inability of B3O to allow fixed batch sizes is a potential limitation, as real-world applications for batch BO can have an effective constraint on possible batch size, for example the number of available compute nodes (simulation), number of different molecules that a robotic assay can test simultaneously (drug discovery), or quantity of samples that can fit in a furnace (alloy hardening). Under-utilizing the available resources with smaller batch sizes costs information that could be gained at little additional cost, whereas choosing to allocate too many samples to a batch may be impossible.</p>
<h2>Proposed Method</h2>
<p>In the BO formalism, the target function is not directly optimized. In its place, an acquisition function is constructed using a probabilistic model based upon previously determined values for the function $f$. Typically this model is a Gaussian process (GP),(Rasmussen and Williams 2004) although other models including neural networks have been used.(Snoek et al. 2015)</p>
<p>There are many different versions of the acquisition function, depending upon the type of optimization task which is being performed, but the most commonly used is expected improvement, EL(Mockus 1974) which is determined as follows:</p>
<p>$E I(x)=\mu(x)-f^{*}\Phi(\gamma)+\sigma(x)\phi(\gamma)$ (1)</p>
<p>where $\Phi$ denotes the CDF (cumulative distribution function) of the standard normal distribution, $\phi$ denotes the PDF (probability density function) of the standard normal distribution, and $\gamma$ denotes the improvement, which can be expressed as:</p>
<p>$\gamma(x)=\frac{\mu(x)-f^{*}}{\sigma^{2}(x)}$ (2)</p>
<p>where $f^{*}$ is the best target value observed so far, $\mu(x)$ is the predicted mean and $\sigma^{2}(x)$ is the corresponding variance.</p>
<p>At its core, this procedure is inherently serial, as it is based upon the updating of a probablistic model, and thus limited</p>
<p>Table 1: K-Means Batch Bayesian Optimization (KMBBO)</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Input:</th>
<th style="text-align: left;">Sampling domain $\mathcal{X}$, Initial samples $\mathcal{D}_{0}$, Batch size $k$,</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">epochs $N$, slice samples $n_{s}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Batch size $k$,epochs $N$, slice samples $n_{s}$</td>
</tr>
<tr>
<td style="text-align: left;">For t = 1 to $N$ :</td>
<td style="text-align: left;">1. Fit GP model to training data $\mathcal{D}_{t-1}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">2. Collect slice samples: $\quad\left{s_{1},...,s_{n_{s}}\right}=B G S S(\mathcal{X})$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">3. Fit K-Means model to obtain centroids $\mu_{i}$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">4. Sample centroids: $\quad\left{y\right}<em 1="1">{t}=\left{f\left(\mu</em>\right)\right}$}\right),...,f\left(\mu_{k</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">5. Add newly observed values to dataset:</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\mathcal{D}<em t-1="t-1">{t}=\mathcal{D}</em>$} \cup\left{y\right}_{t</td>
</tr>
<tr>
<td style="text-align: left;">End for</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Return $\mathcal{D}_{N}$</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>by data acquisition. Our contribution is twofold, firstly we propose a novel parallel (or batch) Bayesian optimization procedure based upon K-means, K-means Batch Bayesian Optimization (KMBBO), and secondly we propose a modification for the use of this method with very high-dimensional data using a dimensionality reduction step based upon compressed sensing.</p>
<p>The central aim of KMBBO is to efficiently select a batch of high quality points to evaluate, i.e, during each sampling epoch, we would like our batch to contain points from high-density regions of the acquisition function. However, modeling the landscape of the acquisition function directly is generally intractable, except in very low dimensions. In order to approximately learn the locations of peaks, we fit a K-Means clustering model to the collection of points in our sample space, chosen using slice sampling. Slice sampling draws samples uniformly from the volume under the acquisition function, and so will preferentially select samples from regions where the acquisition function value is highest.</p>
<p>K-Means (MacQueen 1967) is one of the simplest and most commonly used clustering methods. Given a set of points $X$, and number of clusters $k$, the K-Means method will attempt to find a partition $P(X)=\left{X_{1}, \ldots, X_{k}\right}$ clustering the members of $X$ in order to minimize the within-cluster sum of squares distance between cluster members and the cluster centroid, i.e:</p>
<p>$$
\underset{P(X)}{\operatorname{argmax}} \sum_{i=1}^{k} \sum_{x \in X_{i}}\left|x-\mu_{i}\right|^{2}
$$</p>
<p>where $\mu_{i}$ represents the centroid of cluster $i$. Thus, KMBBO allows the user to specify the batch size directly as the number of clusters for the K-Means method.</p>
<p>To collect its slice samples, KMBBO utilizes the batch generalized slice sampling (BGSS) method described in (Nguyen et al. 2017) where the joint density is defined as</p>
<p>$$
p(u, u)=\left{\begin{array}{l}
\frac{1}{z}, \text { if } \alpha_{\min }&lt;u&lt;\alpha(x) \
0, \text { otherwise }
\end{array}\right.
$$</p>
<p>where $z=\int \alpha(x) d x$ and $\alpha_{\min }$ is obtained through minimization using a non-convex global optimizer, thus not requiring the function to be non-negative, or a proper distribution. However, like standard slice sampling, BGSS scales poorly with the dimensionality of the sampling domain (Neal 2003), making it impractical for use in high-dimensional settings.</p>
<p>Table 2: KMBBO with compressed sensing (CS-KMBBO)</p>
<table>
<thead>
<tr>
<th>Input:</th>
<th>Domain $\mathcal{X}$, compression error tolerance $\epsilon$,</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Draw $n_{\text {comp }}$ samples from $\mathcal{X}$ :</td>
<td>Batch size k,# epochs N, #slice samples $s$</td>
</tr>
<tr>
<td>2. Compress domain using TwIsT:</td>
<td>$S=\left{s_{1}, \ldots, s_{n_{\text {comp }}}\right}$</td>
</tr>
<tr>
<td>3. Run KMBBO:</td>
<td>$\mathcal{X}_{c s}=$ Compress $(\mathcal{X}, S, \epsilon)$</td>
</tr>
<tr>
<td>4. Decompress $\mathcal{D}_{N}$</td>
<td>$\mathcal{D}<em c="c" s="s">{N}=K M B B O\left(\mathcal{X}</em>, k, N, s\right)$</td>
</tr>
</tbody>
</table>
<p>To address this we add a dimensionality reduction step based upon compressed sensing. Our use of the compressed sensing methodology is based upon the observation that most high-dimensional data follows a sparse encoding and thus is compressible. In the compressed sensing scheme, the aim is to reconstruct a signal using the smallest number of observations (which are linear functions of the components of the signal) possible. This is achieved by solving the basis pursuit problem, where we search for the sparsest matrix $A$ which can reconstruct the full matrix $B$ :</p>
<p>$$
\min |A|<em i="i" j="j">{1} \text { subject to }\left(P A P^{T}\right)</em> \forall i, j \in W
$$}=B_{i j</p>
<p>where $P$ is the change-of-basis matrix and $W$ is a set of randomly measured entries in matrix B.</p>
<p>We apply this method to the original feature space of a high dimensional problem, but instead of using the sparse solution to reconstruct the original function, we instead use it as a compressed basis in which to perform the BO sampling.</p>
<p>The upper bound on the lossless dimensionality reduction which can be achieved using compressed sensing is thus equivalent to the number of samples which are required for compressed sensing to perfectly recover $B$ from $A$, which has been shown to scale as follows: Candès and Wakin (Candès and Wakin 2008):</p>
<p>$$
M \propto \mu^{2} S \log (N)^{2}
$$</p>
<p>where $N$ is the original number of features, $S$ is the number of non-zero elements and $\mu$ is the incoherency, which in general ranges from 1 to $\sqrt{N}$.</p>
<p>Whilst some other methods, such as REMBO,(Wang et al. 2013) have used a compressive scheme, the exact dimensionality of this compression was left as a parameter to tune. In CS-KMBBO, we instead use the Two-step Iterative Shrinkage/Thresholding (TwIsT)(Bioucas-Dias and Figueiredo 2007) optimization technique - a variant of the popular Iterative Shrinking Thresholding algorithm (IsT) which is more robust to ill defined measurements - to determine the optimal dimensionality of the compression step. Whilst it is possible in some discrete problems, such as the drug discovery challenge tackled within this paper, to know the entire space of inputs, we recognize that this is not always the case. Thus, we sample 1,000 data points to perform the TwIST-based dimensionality optimization procedure to create a process which is transferable between discrete and continuous spaces.</p>
<h2>Experiments</h2>
<h2>Comparison to Existing Methods</h2>
<p>For this study we compare the performance of KMBBO to a range of currently used parallel BO methods, the details of which have been described in Section , using the Expected Improvement acquisition function, which has been shown to have strong theoretical guarantees (Vazquez and Bect 2010)and empirical effectiveness (Snoek, Larochelle, and Adams 2012). In addition to Naieve qEI, the most basic parallel sampling method, we compare to Thompson sampling, Constant Liar (mean), Local Penalization, a batch predictive entropy search model to represent a non-greedy search strategy, and the dynamic batch method B3O. We investigate two metrics for success:</p>
<ol>
<li>The convergence of the search to the global minimum (where known) as a function of the number of epochs</li>
<li>The robustness of the search, as demonstrated through sampling 100 repeat runs of the sampling experiment.
For this study, a batch size of 8 was arbitrarily chosen. Throughout the study the Bayesian model was provided through the use of a Gaussian process, which was created using a squared-exponential kernel with automatic relevance determination (ARD) as implemented in the Scikit-Learn library Pedregosa et al. (Pedregosa et al. 2011),</li>
</ol>
<p>$$
k_{S E}=\sigma_{f} \exp \frac{-1}{2} \sum_{d=1}^{D} \frac{-\left(x_{d}-x_{d}^{*}\right)^{2}}{2 l_{d}^{2}}
$$</p>
<p>seeded with 10 randomly selected data points. The GP's hyperparameters were optimized using gradient descent on the marginal likelihood. Finally, both B3O and KMBBO selected 200 slice samples when generating each batch to maintain consistency with (Nguyen et al. 2017).</p>
<h2>Optimization Tasks</h2>
<p>Synthetic Functions We test the ability of KMBBO to find the global extremes of three synthetic functions commonly used for benchmarking machine learning algorithms: Branin-Hoo (2D), Camelback-6 (2D), and Hartmann (6D) as described on the Virtual Library of Simulation Experiments test function database (Surjanovic and Bingham).
SVM A common use for Bayesian optimization is for the tuning of hyperparmeters for machine learning models. In order to test the effectiveness of KMBBO for this task, we use it to determine optimal hyperparameters for a support vector machine for the Abalone regression task.(Nash and Laboratories 1994) In this context we tune three hyperparameters: $C$ (regularization parameter), $\epsilon$ (insensitive loss) for regression and $\gamma$ (RBF kernel function). The loss function is the root mean squared error of the prediction.</p>
<p>Drug Discovery This is a task taken to illustrate the utility of this procedure for lead identification in drug discovery - where rapid identification of desirable compounds at low cost is essential. The target for maximization is the PEC50; a value which describes the potency of the drug. The data was taken from hits from Plasmodium falciparum (P. falciparum) whole cell screening originates from the GlaxoSmithKline Tres Cantos Antimalarial Set (TCAMS), Novartis-GNF Malaria Box Data set and St. Jude Children's Research Hospital's Dataset (EC50 in $\mu \mathrm{M}$ against P. falciparum 3D7) as released through the Medicines for Malaria</p>
<p>Venture website (mmv.org ). Each molecule was described using MAACS keys (Durant et al. 2002)- a common cheminformatics descriptor, generated using the RDKit software (Landrum ) resulting in a 167 dimensional optimization problem.</p>
<h2>Results</h2>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The distribution of the 'first encounter time', i.e. when the global optimium is first located for the Branin-Hoo function. Statistics are generated from 100 repeats of the experiment.</p>
<h2>Synthetic Functions</h2>
<p>For the Branin-Hoo, we observe that both the Constant Liar and KMBBO methods are able to approach the minimum quickly, achieving low regret after only a few sampling epochs, with both B3O and Thompson sampling also reliably reaching finding the optimum before 8 sampling epochs. LP, however, performs poorly, achieving similar regret to Naieve qEI, with many iterations of each method failing to discover the minimum after 10 epochs. The performance of LP relies heavily on the quality of the Lipschitz constant estimate, which is calculated over the entire sampling domain. For the Branin-Hoo function, this is dominated by the quartic term away from the function minima, leading to a Lipschitz constant estimate poorly suited to the region around the optimum. Figure 1 shows the 'first encounter time' of the global optimum for each method. We see that, even though the initial reduction in regret between KMBBO and Constant Liar is similar, KMBBO is able to locate the optimal value earlier and more consistently than the other methods. All functions perform well for the Camelback task, although we observe that KMBBO converges to the true minimum faster than the other methods. The 6 dimensional Hartmann function is a more challenging optimization problem. We observe in Figure 2 that after 10 epochs are methods have still not yet managed to identify the global optimum. LP, B3O and KMBBO all performed well, achieving similar average regret values, but B3O and KMBBO performed more consistently, with lower variance on the regret obtained.</p>
<h2>Tuning of Hyperparameters</h2>
<p>KMBBO displays the best performance on the SVM hyperparameter tuning task, shown in Figure 4. With a low dimensional sampling space, the slice sampling method used by
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The optimization performance for the 6 dimensional Hartmann function. Statistics are generated from 100 repeats of the experiment, and confidence intervals are calculated to 1 sigma.</p>
<p>B3O and KMBBO performs particularly well at approximating high density regions of the acquisition function. Indeed, the violin plot in 4 shows that, not only are KMBBO and B3O the best performers at minimizing RMSE, they also perform most consistently, with smallest error variance.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3
Figure 4: Optimization performance for the tuning of the hyperparameters of an SVM, as displayed through the RMSD of the SVM for the abalone problem with respect to the number of epochs. Statistics are generated from 100 repeats of the experiment, and confidence intervals are bootstrapped to 1 sigma. Note that the batch-PES methodology is excluding from this plot, as its large variance over runs made interpretation of the performance other methodologies impossible. The results for this method can be seen in Table 3</p>
<h2>Drug Discovery</h2>
<p>The high dimensional nature of the drug discovery task presented significant challenges to several of the benchmark methods. In 167 dimensions, the slice sampling method used by B3O is unable to produce any reasonable approximation of the acquisition function surface with the original sampling</p>
<p>Table 3: Final performance after 10 sampling epochs for each method on each of the test problem cases over 100 repetitions. Best performance in each case is shown in bold. For the Malaria task, an X indicates that the method was not run, due to computational intractability or algorithmic instability.</p>
<p>Task Branin-Hoo Camelback-6 Hartman SVM Malaria Method Regret Std.Dev Regret Std.Dev Regret Std.Dev RMSE Std.Dev Regret Std.Dev Naieve qEI 0.803 1.47 0.0276 0.0974 1.74 0.700 1.9453 0.00170 3.1185 0.8392 Thompson 0.00619 0.00186 0.0727 0.179 1.33 0.438 1.9430 0.00125 3.0000 1.0888 Constant Liar 0.00584 0.00129 0.0778 0.207 1.70 0.511 1.9430 0.000802 X X LP 0.637 1.28 0.0292 0.0947 0.916 0.673 1.9441 0.00105 X X KMBBO 0.00523 0.000488 0.0354 0.0616 0.922 0.311 1.9416 0.000577 2.3802 1.4003 B3O 0.00591 0.00170 0.130 0.338 0.882 0.320 1.9422 0.000580 X X Batch PES 0.5486 0.3682 0.1619 0.0967 1.4257 0.4736 1.9406 0.7322 3.2626 0.7322 budget of 200 and we found the substantial increase in samples required lead to prohibitively long running times. The LP method was hamstrung by the computational cost of approximating the Lipschitz constant in this high dimensional space, Furthermore, the Constant Liar methodology is reliant upon a high quality model, and thus is very sensitive to hyperparameter selection, and the addition of reasonable quality psuedo-inputs. Unfortunately, during our testing of this method for the drug discovery problem, a large number of runs failed due to a failure for the GP model to converge during the fitting task, and thus it is excluded from the results.</p>
<p>Of the remaining methods, Thompson sampling, qEI, batch-PES and CS-KMBBO are able to be used for this task. Figure 5 shows that KMBBO displays strong performance, reaching low regret after 10 sampling epochs- having sampled only 90 out of a potential circa 19,000 candidate molecules. Thompson sampling, qEI and Batch-PES display similar behaviors, discovering a local maximum on the potency landscape, but neither are able to discover molecules with as low regret as KMBBO. It is worth noting that due to the discrete nature of the search space, here regret is not a continuous function, for example a regret of 2 places you within the top 0.7% of values for the task.</p>
<h2>Rankings</h2>
<p>One way to measure the robustness of a search method is to compare the rankings of the search method of the whole range of tasks performed in this study. Since raw rankings can be misleading (a close second ranks the same as a search in which the gap between methods was much wider) we instead use a normalized ranking, $Z$, proposed in jasrasaria2018semi:</p>
<p>$Z=\frac{s-s^{t}}{s_{max}-s_{min}}$ (8)</p>
<p>where $s$ represents the result of a particular strategy, $s t$ the result of the best strategy, and $s_{max}-s_{min}$ represent the range of results encountered in the study. This results in a score bounded $(0,1)$ where 0 represents a perfect performance across tasks.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: Optimization performance for the Malaria drug discovery problem, as displayed through instantaneous regret with respect to the number of epochs. Statistics are generated from 10 repeats of the experiment, and confidence intervals are bootstrapped to 1 sigma.</p>
<p>We calculate $Z$ for both the performance of the optimization task, as measured by regret or RMSE where appropriate, and the variance of the task as measured over multiple runs.</p>
<p>It can easily be seen from Figure 6 that KMBBO achieves a significantly better Z score than any other method for pure optimization performance, and also the best Z score, albeit by a smaller margin, than any other method for variance. This demonstrates both the class leading nature of KMBBO and also its strong reproducibility; a property which is key for Bayesian optimization, where each data point is expensive to acquire and thus reliability of a methodology is strongly desired.</p>
<h2>Computational Cost</h2>
<p>We have analyzed the complexity of the rate-limiting step for each of the methods used in this work, and performed additional empirical experiments looking at real-world running times. The poor dimensionality scaling of slice sampling</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: Z score calculated for each of the parallel optimization strategies investigated in this study.</p>
<p>(O(2<sup>d</sup>)) is common to the B3O method, and worse than the scaling of the LP method (O(d<sup>3</sup>)). We address this in CS-KMBBO through the incorporation of compressed sensing for dimensionality reduction. Even when compression is not required, our empirical timings, shown in Figure 7, indicate that the runtime per sampling epoch for KMBBO is generally significantly smaller than for B3O, which we attribute to the simplicity and scalability of the K-Means algorithm compared to the IGMM used in B3O. However, it is worth keeping in mind that in the Bayesian Optimization framework, it is generally assumed that obtaining ground truth values by sampling the black-box function f is substantially more expensive (in time/computational cost) than the calculation of the sampling batch, which somewhat mitigates concerns about the computational cost of the sampling methodology as an expensive, yet efficient, sampling scheme will have less real-world cost than an inefficient, yet fast, alternative.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: Runtimes of KMBBO and B3O in 2 and 6D. Runtime is calculated as seconds per sampling epoch.</p>
<h3>Algorithmic Insight</h3>
<p>In this section we discuss the different characteristics of the sampling methods through analyzing their sample selections</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: Points selected to form the next batch for each sampling method when minimizing f(x) = -xsin(x), given 5 initial random points. The activation function is shown in blue, with non-zero regions shaded. The blue histogram shows the samples taken by BGSS.</p>
<p>for an easy to visualize 1 dimensional optimization problem. Figure 8 shows the activation function curve and subsequent samples chosen by each of the sampling algorithms while minimizing the function f(x) = -xsin(x), after 5 randomly chosen initial samples. This gives some visual insight into the behavior of each of the methods. We observe that all of the methods are able to identify the main peak of the acquisition function and allocate at least one sample nearby. Naieve qEI simply chooses the q points from the sample space closest to this peak, leading to highly local sampling, and insufficient exploration of other areas of density in the acquisition function. LP also does a good job of identifying the main acquisition function peak, and the local penalization factor ensures somewhat more exploration than with the Naieve qEI method. However, this still seems insufficient to cause exploration of other areas of density in the acquisition function. In contrast, Constant Liar is susceptible to over exploration and selects several low quality points. We posit that this is due to the assumption that the true value for each sample added to the batch is represented by the mean value of the GP prediction. Since the violation of this assumption can lead to large movements in the GP posterior, this can cause erratic behavior, and lead to these poor selections. In our toy example, B3O successfully identifies two of the acquisition function peaks, but does not represent the third. The IGMM used by B3O seems to be sensitive to the number of slice samples provided, as experiments with different numbers of slice samples lead to substantial variations in the number and location of the points chosen.</p>
<p>KMBBO is able to achieve a good balance between exploration and exploitation, with all three maxima in the acquisition function represented, with the remaining samples well distributed over the non-zero areas of the curve. When the number of local optima of the acquisition function is lower than the batch size, the quadratic penalization for within cluster distance used by K-Means ensures that the remaining cluster centroids will spread out over the set of slice sample values.</p>
<h2>Summary</h2>
<p>We propose a novel batch sampling algorithm for Bayesian optimization based upon K-means, K-means Batch Bayesian Optimization (KMBBO). KMBBO was tested in a variety of tasks, from common synthetic functions to the tuning of a machine learning algorithm, to a high-dimensional drug discovery problem. Over these tasks KMBBO displays superior sampling behaviors than other common Bayesian optimization methods, such as LP, Thompson sampling, Constant Liar, and B3O, delivering either optimal or close to optimal behavior in all tasks. It also delivered this performance more reliably than any other method, consistently showing the smallest standard deviation in results over 100 repetitions across tasks. This is a very important result since the major utility of Bayesian optimization is when each sample is expensive or difficult to collect, and thus reliability in optimization performance is strongly desirable. We also propose a modification to KMBBO, CS-KMBBO, for use in high dimensional problems, where the slice sampling in KMBBO adds significant computational overhead. In this adaptation, the optimal dimensionality is achieved through the use of the TWiST technique on a sampled subset of the problem space. CS-KMBBO shows better performance than all methods despite operating on a reduced dimensional data set. Finally, we discuss insights into the performance of KMBBO through the visualization of the batching process for a toy problem, and comparison to the other methods studied within this paper. Over a wide variety of tasks, it is inevitable that for any specific task, a particular sampling technique will have optimal performance, but the strong performance of KMBBO over the whole range of tasks and dimensions, makes it a reliable choice.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by the STFC Hartree Centre’s Innovation Return on Research programme, funded by the Department for Business, Energy \&amp; Industrial Strategy.</p>
<h2>References</h2>
<p>[Bioucas-Dias and Figueiredo 2007] Bioucas-Dias, J. M., and Figueiredo, M. A. 2007. A new twist: Two-step iterative shrinkage/thresholding algorithms for image restoration. IEEE Transactions on Image processing 16(12):2992-3004.
[Candès and Wakin 2008] Candès, E. J., and Wakin, M. B. 2008. An introduction to compressive sampling. IEEE signal processing magazine 25(2):21-30.
[Chevalier and Ginsbourger 2013] Chevalier, C., and Ginsbourger, D. 2013. Fast computation of the multi-points expected improvement with applications in batch selection. In International Conference on Learning and Intelligent Optimization, 59-69. Springer.
[Durant et al. 2002] Durant, J. L.; Leland, B. A.; Henry, D. R.; and Nourse, J. G. 2002. Reoptimization of mdl keys for use in drug discovery. Journal of Chemical Information and Computer Sciences 42(6):1273-1280. PMID: 12444722.
[Ginsbourger, Le Riche, and Carraro 2007] Ginsbourger, D.; Le Riche, R.; and Carraro, L. 2007. A multi-points criterion for deterministic parallel global optimization based on kriging. In NCP07.
[Ginsbourger, Le Riche, and Carraro 2010] Ginsbourger, D.; Le Riche, R.; and Carraro, L. 2010. Kriging is well-suited to parallelize optimization. In Computational Intelligence in Expensive Optimization Problems. Springer. 131-162.
[González et al. 2016] González, J.; Dai, Z.; Hennig, P.; and Lawrence, N. 2016. Batch bayesian optimization via local penalization. In Artificial Intelligence and Statistics, 648-657.
[Hernández-Lobato et al. 2017] Hernández-Lobato, J. M.; Requeima, J.; Pyzer-Knapp, E. O.; and Aspuru-Guzik, A. 2017. Parallel and distributed thompson sampling for large-scale accelerated exploration of chemical space. In Proceedings of the 34th International Conference on Machine Learning.
[Jasrasaria and Pyzer-Knapp 2018] Jasrasaria, D., and Pyzer-Knapp, E. O. 2018. Dynamic Control of Explore/Exploit Trade-Off In Bayesian Optimization. arXiv:1807.01279 [cs, stat]. arXiv: 1807.01279.
[Landrum ] Landrum, G. RDKit: Open-source cheminformatics. bibtex: rdkit.
[MacQueen 1967] MacQueen, J. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics, 281-297. Berkeley, Calif.: University of California Press.
[mmv.org ] mmv.org. Malaria Box supporting information I MMV.
[Mockus 1974] Mockus, J. 1974. On bayesian methods for seeking the extremum. In Optimization Techniques IFIP Technical Conference Novosibirsk, July 1-7, 1974, 400-404. Springer, Berlin, Heidelberg.
[Nash and Laboratories 1994] Nash, W. J., and Laboratories, T. M. R. 1994. The Population biology of abalone (Haliotis species) in Tasmania. 1, Blacklip abalone (H. rubra) from the north coast and the islands of Bass Strait.
[Neal 2003] Neal, R. M. 2003. Slice sampling. Annals of statistics 705-741.
[Nguyen et al. 2017] Nguyen, V.; Rana, S.; Gupta, S.; Li, C.; and Venkatesh, S. 2017. arXiv preprint arXiv:1703.04842v2.
[Pedregosa et al. 2011] Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss, R.; Dubourg, V.; Vanderplas, J.; Passos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825-2830.
[Rasmussen and Williams 2004] Rasmussen, C. E., and Williams, C. K. I. 2004. Gaussian Processes for Machine Learning. MIT Press.
[Rasmussen 2000] Rasmussen, C. E. 2000. The infinite gaussian mixture model. In Advances in neural information processing systems, 554-560.
[Shah and Ghahramani 2015] Shah, A., and Ghahramani, Z. 2015. Parallel predictive entropy search for batch global optimization of expensive objective functions. In Proceedings of the 28th International Conference on Neural Information Processing Systems Volume 2, NIPS'15, 3330-3338. Cambridge, MA, USA: MIT Press.
[Snoek et al. 2015] Snoek, J.; Rippel, O.; Swersky, K.; Kiros, R.; Satish, N.; Sundaram, N.; Patwary, M.; Prabhat, M.; and Adams, R. 2015. Scalable bayesian optimization using deep neural networks. In International Conference on Machine Learning, 2171-2180.
[Snoek, Larochelle, and Adams 2012] Snoek, J.; Larochelle, H.; and Adams, R. P. 2012. Practical bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, 2951-2959.</p>
<p>[Surjanovic and Bingham ] Surjanovic, S., and Bingham, D. Virtual library of simulation experiments: Test functions and datasets. Retrieved May 16, 2018, from http://www.sfu.ca/ $\sim$ ssurjano.
[Thompson 1933] Thompson, W. R. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika 25(3/4):285-294.
[Vazquez and Bect 2010] Vazquez, E., and Bect, J. 2010. Convergence properties of the expected improvement algorithm with fixed mean and covariance functions. Journal of Statistical Planning and Inference 140(11):3088-3095.
[Wang et al. 2013] Wang, Z.; Zoghi, M.; Hutter, F.; Matheson, D.; De Freitas, N.; et al. 2013. Bayesian optimization in high dimensions via random embeddings. In IJCAI, 1778-1784.
[Wang et al. 2016] Wang, J.; Clark, S. C.; Liu, E.; and Frazier, P. I. 2016. Parallel bayesian global optimization of expensive functions. arXiv preprint arXiv:1602.05149.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Corresponding author</p>
<p>Copyright (c) 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>