<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6689 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6689</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6689</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-128.html">extraction-schema-128</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <p><strong>Paper ID:</strong> paper-47baad35896702c96ffcdd879bdaf387f5c59853</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/47baad35896702c96ffcdd879bdaf387f5c59853" target="_blank">A Machine With Human-Like Memory Systems</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work explicitly model an agent with both semantic and episodic memory systems, and shows that it is better than having just one of the two memory systems.</p>
                <p><strong>Paper Abstract:</strong> Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one of the two memory systems. In order to show this, we have designed and released our own challenging environment,"the Room", compatible with OpenAI Gym, where an agent has to properly learn how to encode, store, and retrieve memories to maximize its rewards. The Room environment allows for a hybrid intelligence setup where machines and humans can collaborate. We show that two agents collaborating with each other results in better performance than one agent acting alone.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6689.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6689.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Handcrafted-1</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted Policy 1: Only Episodic Memory (forget oldest, answer latest)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Rule-based agent that maintains only an episodic memory store of observed RDF-like quadruples, forgetting the oldest entry when full and answering questions using the most recent relevant episodic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>A Machine With Human-Like Memory Systems</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 1 (Only Episodic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted, rule-based agent with a bounded episodic memory that stores observations as RDF-like quadruples (entity, relation, location, timestamp). When full it discards the oldest episodic memory (FIFO). On queries it returns the most recent relevant episodic memory if available.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>The Room (OpenAI-Gym-compatible environment)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic buffer (explicit episodic memory store)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>RDF-triple-like quadruples: (entity, relation, location, timestamp)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Rule-based FIFO: store new episodic quadruple; when full, forget the oldest episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Rule-based retrieval: find relevant episodic entries and choose the latest (most recent) one</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Handcrafted rule-based policy (no learned training)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative: Outperforms uniform-random baselines; performs best among agents at very low memory capacity (text presents this trend but no numeric score provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Episodic-only policy performs better than others when total memory capacity is very low because episodic recency matters more than generalization in that regime.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Bounded capacity forces forgetting; handcrafted policy not learned; environment simplified (only AtLocation relation); no numeric breakdown of gains provided.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Use episodic storage to capture recent, person-specific events; in low-capacity settings prioritize recency (FIFO/most-recent retrieval).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6689.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6689.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Handcrafted-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted Policy 2: Only Semantic Memory (forget weakest, answer strongest)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Rule-based agent that maintains only a semantic memory store of aggregated commonsense counts (entity, relation, location, strength) and answers queries using the strongest semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>A Machine With Human-Like Memory Systems</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 2 (Only Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A handcrafted, rule-based agent with a bounded semantic memory that stores aggregated semantic quadruples (entity-type, relation, location, strength/count). When full it removes the weakest semantic memory; on queries it returns the strongest relevant semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>The Room (OpenAI-Gym-compatible environment)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>semantic memory store (aggregated counts / strengths)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>RDF-like quadruples without person names: (object-type, relation, location, strength/count)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Rule-based aggregation: increment counts/strengths on observations; when full, forget the weakest semantic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Rule-based retrieval: select relevant semantic memories and pick the one with highest strength/count</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Handcrafted rule-based policy (no learned training)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative: Outperforms random baselines; performs better as memory capacity increases because it can generalize commonsense from multiple observations (no numeric scores provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Semantic memory becomes more useful as capacity increases since it captures general world knowledge; pretrained semantic memory (Handcrafted 4) further boosts performance.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Semantic memories are non-person-specific and may miss recent person-specific changes; bounded capacity requires forgetting weakest entries which may remove useful generalizations.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Aggregate repeated observations into semantic entries and prioritize strong (high-count) semantic memories; use semantic memory to answer when no relevant episodic memory exists.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6689.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6689.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Handcrafted-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted Policy 3: Combined Episodic and Semantic (learn to compress)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Agent with both episodic and semantic memory systems that compresses similar episodic memories into semantic ones, uses recency-first episodic retrieval then strongest semantic fallback.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>A Machine With Human-Like Memory Systems</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 3 (Episodic + Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Handcrafted agent with bounded episodic and semantic stores of equal capacity; when episodic store is full it removes episodic memories that can be summarized into semantic memories (rule-based compression); on query it first attempts to answer using the latest episodic memory, otherwise uses the strongest semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>The Room (OpenAI-Gym-compatible environment)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>hybrid explicit memory: episodic buffer + semantic aggregated store</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Episodic: (entity-with-person, relation, location, timestamp); Semantic: (object-type, relation, location, strength/count)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Rule-based: store episodic observations; when episodic capacity reached, forget episodic memories that are similar and can be compressed into semantic memories; semantic forgetting removes weakest entries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Hierarchical rule-based retrieval: use most recent relevant episodic memory if present; otherwise use strongest relevant semantic memory</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Handcrafted rule-based policy (no learned training)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative: Outperforms single-memory-type agents in regimes where both personal events and generalization matter; overall better than single-memory systems as capacity increases (no numeric values provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Hybrid (episodic+semantic) outperforms single memory systems for moderate-to-large memory capacity; compression from episodic to semantic helps summarize repeated patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Handcrafted compression rules may be suboptimal; choice of split between episodic and semantic capacities was heuristic; no learned policy to optimize storage.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Provide both episodic and semantic stores and explicit compression rules from episodic to semantic when patterns repeat; consult episodic (recency) first then semantic (strength) as fallback.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6689.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6689.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Handcrafted-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Handcrafted Policy 4: Episodic + Pretrained Semantic</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Agent with an episodic memory store plus a semantic store pre-populated with ConceptNet commonsense knowledge; it prioritizes recent episodic memories then strongest semantic ones.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>A Machine With Human-Like Memory Systems</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Handcrafted 4 (Episodic + Pretrained Semantic)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Handcrafted agent that starts each episode with semantic memory pre-populated from ConceptNet commonsense knowledge and maintains an episodic store for person-specific observations; when episodic is full it forgets oldest episodic memories, and answers using latest episodic then strongest semantic.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>The Room (OpenAI-Gym-compatible environment)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>hybrid: episodic buffer + pretrained semantic memory (commonsense knowledge)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Episodic: (entity-with-person, relation, location, timestamp); Semantic: (object-type, relation, location, strength/count) seeded from ConceptNet</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Semantic prefilled at start of episode; episodic stores new observations and forgets oldest when full; semantic forgetting removes weakest if full</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Hierarchical: use latest relevant episodic memory if present; otherwise use strongest relevant semantic memory (including pretrained commonsense)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Handcrafted rule-based policy (no learned training); semantic memory prefilled via ConceptNet data (no learning)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative: Best-performing handcrafted agent in reported experiments; pretraining semantic memory with commonsense allows focusing episodic capacity and improves overall reward (no numeric scores provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Prepopulating semantic memory with commonsense (ConceptNet) leads to improved performance compared to agents that must learn semantic counts from observations; balance of semantic/episodic capacity affects performance.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Relies on quality and coverage of external commonsense KB; fixed pretrained semantics may be mismatched to episode-specific exceptions.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Preload semantic memory with commonsense knowledge when available to improve performance and free episodic capacity for person-specific events; prioritize episodic recency then semantic strength.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6689.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6689.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‑based games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multiple Agent Policies (Collaborative Memory Sharing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Setup where multiple agents each maintain their own memories and can combine their memories to answer questions; collaboration increases environmental coverage and improves question-answering performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>A Machine With Human-Like Memory Systems</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Multiple Agents (combined memory)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Multiple agents run the same handcrafted policies in parallel, each with its own bounded memory; combined memory (the union of each agent's stored entries) is used to answer queries, enabling greater coverage of room observations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>The Room (OpenAI-Gym-compatible environment)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>distributed per-agent episodic/semantic stores, combined at query time</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Per-agent RDF-like quadruples (episodic and/or semantic as per each agent policy)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Each agent updates its own memory per its policy (FIFO, forget weakest, compression rules); no centralized learning-based update</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Combine per-agent memories and apply same retrieval rules (e.g., choose most recent among relevant episodic memories across agents, or strongest semantic across agents)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Handcrafted rule-based policies run on multiple agents (no learned training)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Qualitative: Two agents with half the per-agent capacity (but same total capacity) outperform one agent with full capacity because they explore different parts of the room and thus cover more observations; reported as comparative improvement in Figure 3 but without numeric values in text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Given equal total memory capacity, distributing memory across multiple agents that explore different trajectories increases coverage and improves QA performance relative to a single agent.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Collaboration model is simplistic (union of memories); trust/conflict resolution and communication costs not modeled; experiments limited to two-agent case with uniform memory splits.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Use multiple agents to increase coverage when memories are bounded; split memory across agents to encourage diverse exploration; combine recent episodic memories across agents with strongest semantic memories as fallbacks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Machine With Human-Like Memory Systems', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data <em>(Rating: 2)</em></li>
                <li>Integrating Episodic and Semantic Information in Memory for Natural Scenes <em>(Rating: 2)</em></li>
                <li>ConceptNet 5.5: An Open Multilingual Graph of General Knowledge <em>(Rating: 1)</em></li>
                <li>The Soar Cognitive Architecture <em>(Rating: 1)</em></li>
                <li>Discovering skill <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6689",
    "paper_id": "paper-47baad35896702c96ffcdd879bdaf387f5c59853",
    "extraction_schema_id": "extraction-schema-128",
    "extracted_data": [
        {
            "name_short": "Handcrafted-1",
            "name_full": "Handcrafted Policy 1: Only Episodic Memory (forget oldest, answer latest)",
            "brief_description": "Rule-based agent that maintains only an episodic memory store of observed RDF-like quadruples, forgetting the oldest entry when full and answering questions using the most recent relevant episodic memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "A Machine With Human-Like Memory Systems",
            "agent_name": "Handcrafted 1 (Only Episodic)",
            "agent_description": "A handcrafted, rule-based agent with a bounded episodic memory that stores observations as RDF-like quadruples (entity, relation, location, timestamp). When full it discards the oldest episodic memory (FIFO). On queries it returns the most recent relevant episodic memory if available.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": "The Room (OpenAI-Gym-compatible environment)",
            "memory_used": true,
            "memory_type": "episodic buffer (explicit episodic memory store)",
            "memory_representation": "RDF-triple-like quadruples: (entity, relation, location, timestamp)",
            "memory_update_mechanism": "Rule-based FIFO: store new episodic quadruple; when full, forget the oldest episodic memory",
            "memory_retrieval_method": "Rule-based retrieval: find relevant episodic entries and choose the latest (most recent) one",
            "training_method": "Handcrafted rule-based policy (no learned training)",
            "evaluation_metric": "Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)",
            "performance_with_memory": "Qualitative: Outperforms uniform-random baselines; performs best among agents at very low memory capacity (text presents this trend but no numeric score provided).",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Episodic-only policy performs better than others when total memory capacity is very low because episodic recency matters more than generalization in that regime.",
            "reported_limitations": "Bounded capacity forces forgetting; handcrafted policy not learned; environment simplified (only AtLocation relation); no numeric breakdown of gains provided.",
            "best_practices_recommendations": "Use episodic storage to capture recent, person-specific events; in low-capacity settings prioritize recency (FIFO/most-recent retrieval).",
            "uuid": "e6689.0",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Handcrafted-2",
            "name_full": "Handcrafted Policy 2: Only Semantic Memory (forget weakest, answer strongest)",
            "brief_description": "Rule-based agent that maintains only a semantic memory store of aggregated commonsense counts (entity, relation, location, strength) and answers queries using the strongest semantic memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "A Machine With Human-Like Memory Systems",
            "agent_name": "Handcrafted 2 (Only Semantic)",
            "agent_description": "A handcrafted, rule-based agent with a bounded semantic memory that stores aggregated semantic quadruples (entity-type, relation, location, strength/count). When full it removes the weakest semantic memory; on queries it returns the strongest relevant semantic memory.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": "The Room (OpenAI-Gym-compatible environment)",
            "memory_used": true,
            "memory_type": "semantic memory store (aggregated counts / strengths)",
            "memory_representation": "RDF-like quadruples without person names: (object-type, relation, location, strength/count)",
            "memory_update_mechanism": "Rule-based aggregation: increment counts/strengths on observations; when full, forget the weakest semantic memory",
            "memory_retrieval_method": "Rule-based retrieval: select relevant semantic memories and pick the one with highest strength/count",
            "training_method": "Handcrafted rule-based policy (no learned training)",
            "evaluation_metric": "Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)",
            "performance_with_memory": "Qualitative: Outperforms random baselines; performs better as memory capacity increases because it can generalize commonsense from multiple observations (no numeric scores provided).",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Semantic memory becomes more useful as capacity increases since it captures general world knowledge; pretrained semantic memory (Handcrafted 4) further boosts performance.",
            "reported_limitations": "Semantic memories are non-person-specific and may miss recent person-specific changes; bounded capacity requires forgetting weakest entries which may remove useful generalizations.",
            "best_practices_recommendations": "Aggregate repeated observations into semantic entries and prioritize strong (high-count) semantic memories; use semantic memory to answer when no relevant episodic memory exists.",
            "uuid": "e6689.1",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Handcrafted-3",
            "name_full": "Handcrafted Policy 3: Combined Episodic and Semantic (learn to compress)",
            "brief_description": "Agent with both episodic and semantic memory systems that compresses similar episodic memories into semantic ones, uses recency-first episodic retrieval then strongest semantic fallback.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "A Machine With Human-Like Memory Systems",
            "agent_name": "Handcrafted 3 (Episodic + Semantic)",
            "agent_description": "Handcrafted agent with bounded episodic and semantic stores of equal capacity; when episodic store is full it removes episodic memories that can be summarized into semantic memories (rule-based compression); on query it first attempts to answer using the latest episodic memory, otherwise uses the strongest semantic memory.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": "The Room (OpenAI-Gym-compatible environment)",
            "memory_used": true,
            "memory_type": "hybrid explicit memory: episodic buffer + semantic aggregated store",
            "memory_representation": "Episodic: (entity-with-person, relation, location, timestamp); Semantic: (object-type, relation, location, strength/count)",
            "memory_update_mechanism": "Rule-based: store episodic observations; when episodic capacity reached, forget episodic memories that are similar and can be compressed into semantic memories; semantic forgetting removes weakest entries",
            "memory_retrieval_method": "Hierarchical rule-based retrieval: use most recent relevant episodic memory if present; otherwise use strongest relevant semantic memory",
            "training_method": "Handcrafted rule-based policy (no learned training)",
            "evaluation_metric": "Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)",
            "performance_with_memory": "Qualitative: Outperforms single-memory-type agents in regimes where both personal events and generalization matter; overall better than single-memory systems as capacity increases (no numeric values provided).",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Hybrid (episodic+semantic) outperforms single memory systems for moderate-to-large memory capacity; compression from episodic to semantic helps summarize repeated patterns.",
            "reported_limitations": "Handcrafted compression rules may be suboptimal; choice of split between episodic and semantic capacities was heuristic; no learned policy to optimize storage.",
            "best_practices_recommendations": "Provide both episodic and semantic stores and explicit compression rules from episodic to semantic when patterns repeat; consult episodic (recency) first then semantic (strength) as fallback.",
            "uuid": "e6689.2",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Handcrafted-4",
            "name_full": "Handcrafted Policy 4: Episodic + Pretrained Semantic",
            "brief_description": "Agent with an episodic memory store plus a semantic store pre-populated with ConceptNet commonsense knowledge; it prioritizes recent episodic memories then strongest semantic ones.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "A Machine With Human-Like Memory Systems",
            "agent_name": "Handcrafted 4 (Episodic + Pretrained Semantic)",
            "agent_description": "Handcrafted agent that starts each episode with semantic memory pre-populated from ConceptNet commonsense knowledge and maintains an episodic store for person-specific observations; when episodic is full it forgets oldest episodic memories, and answers using latest episodic then strongest semantic.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": "The Room (OpenAI-Gym-compatible environment)",
            "memory_used": true,
            "memory_type": "hybrid: episodic buffer + pretrained semantic memory (commonsense knowledge)",
            "memory_representation": "Episodic: (entity-with-person, relation, location, timestamp); Semantic: (object-type, relation, location, strength/count) seeded from ConceptNet",
            "memory_update_mechanism": "Semantic prefilled at start of episode; episodic stores new observations and forgets oldest when full; semantic forgetting removes weakest if full",
            "memory_retrieval_method": "Hierarchical: use latest relevant episodic memory if present; otherwise use strongest relevant semantic memory (including pretrained commonsense)",
            "training_method": "Handcrafted rule-based policy (no learned training); semantic memory prefilled via ConceptNet data (no learning)",
            "evaluation_metric": "Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)",
            "performance_with_memory": "Qualitative: Best-performing handcrafted agent in reported experiments; pretraining semantic memory with commonsense allows focusing episodic capacity and improves overall reward (no numeric scores provided).",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Prepopulating semantic memory with commonsense (ConceptNet) leads to improved performance compared to agents that must learn semantic counts from observations; balance of semantic/episodic capacity affects performance.",
            "reported_limitations": "Relies on quality and coverage of external commonsense KB; fixed pretrained semantics may be mismatched to episode-specific exceptions.",
            "best_practices_recommendations": "Preload semantic memory with commonsense knowledge when available to improve performance and free episodic capacity for person-specific events; prioritize episodic recency then semantic strength.",
            "uuid": "e6689.3",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Multi-Agent",
            "name_full": "Multiple Agent Policies (Collaborative Memory Sharing)",
            "brief_description": "Setup where multiple agents each maintain their own memories and can combine their memories to answer questions; collaboration increases environmental coverage and improves question-answering performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "A Machine With Human-Like Memory Systems",
            "agent_name": "Multiple Agents (combined memory)",
            "agent_description": "Multiple agents run the same handcrafted policies in parallel, each with its own bounded memory; combined memory (the union of each agent's stored entries) is used to answer queries, enabling greater coverage of room observations.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": "The Room (OpenAI-Gym-compatible environment)",
            "memory_used": true,
            "memory_type": "distributed per-agent episodic/semantic stores, combined at query time",
            "memory_representation": "Per-agent RDF-like quadruples (episodic and/or semantic as per each agent policy)",
            "memory_update_mechanism": "Each agent updates its own memory per its policy (FIFO, forget weakest, compression rules); no centralized learning-based update",
            "memory_retrieval_method": "Combine per-agent memories and apply same retrieval rules (e.g., choose most recent among relevant episodic memories across agents, or strongest semantic across agents)",
            "training_method": "Handcrafted rule-based policies run on multiple agents (no learned training)",
            "evaluation_metric": "Total reward (sum of +1 per correctly answered question) over an episode (max 1000 steps)",
            "performance_with_memory": "Qualitative: Two agents with half the per-agent capacity (but same total capacity) outperform one agent with full capacity because they explore different parts of the room and thus cover more observations; reported as comparative improvement in Figure 3 but without numeric values in text.",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Given equal total memory capacity, distributing memory across multiple agents that explore different trajectories increases coverage and improves QA performance relative to a single agent.",
            "reported_limitations": "Collaboration model is simplistic (union of memories); trust/conflict resolution and communication costs not modeled; experiments limited to two-agent case with uniform memory splits.",
            "best_practices_recommendations": "Use multiple agents to increase coverage when memories are bounded; split memory across agents to encourage diverse exploration; combine recent episodic memories across agents with strongest semantic memories as fallbacks.",
            "uuid": "e6689.4",
            "source_info": {
                "paper_title": "A Machine With Human-Like Memory Systems",
                "publication_date_yy_mm": "2022-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data",
            "rating": 2
        },
        {
            "paper_title": "Integrating Episodic and Semantic Information in Memory for Natural Scenes",
            "rating": 2
        },
        {
            "paper_title": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
            "rating": 1
        },
        {
            "paper_title": "The Soar Cognitive Architecture",
            "rating": 1
        },
        {
            "paper_title": "Discovering skill",
            "rating": 1
        }
    ],
    "cost": 0.010238999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Machine With Human-Like Memory Systems</h1>
<p>Taewoon KIM ${ }^{\mathrm{a}}$, Michael COCHEZ ${ }^{\mathrm{a}}$, Vincent FRANÇOIS-LAVET ${ }^{\mathrm{a}}$, Mark NEERINCX ${ }^{\text {b }}$, and Piek VOSSEN ${ }^{\text {a }}$<br>${ }^{a}$ Vrije Universiteit Amsterdam<br>${ }^{\mathrm{b}}$ Technische Universiteit Delft<br>{t.kim, m.cochez, vincent.francoislavet, p.t.j.m.vossen}@vu.nl<br>m.a.neerincx@tudelft.nl</p>
<h4>Abstract</h4>
<p>Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one of the two memory systems. In order to show this, we have designed and released our own challenging environment, "the Room", compatible with OpenAI Gym, where an agent has to properly learn how to encode, store, and retrieve memories to maximize its rewards. The Room environment allows for a hybrid intelligence setup where machines and humans can collaborate. We show that two agents collaborating with each other results in better performance than one agent acting alone. The code is open-sourced at https://github.com/humemai/agent-room-env-v0.</p>
<p>Keywords. explicit memory, episodic memory, semantic memory, hybrid intelligence</p>
<h2>1. Introduction</h2>
<p>In cognitive science, it is thought that humans have an explicit memory system, which is composed of semantic and episodic memory systems. Semantic memory has to do with general world knowledge, while episodic has to do with one's personal memory. For example, when one asks you a question, "In general, where are laptops located?" you might be able to answer it, if you have successfully encoded and stored a relevant memory in your brain. Let's assume that you have, and your answer is "On the desks". However, it is likely that you do not know when and where you have encoded and stored the memory. Nonetheless, you were able to retrieve it. This is because this type of memory is semantic. When your brain deals with such factual (general) knowledge memories, it does not store the information regarding when and where. Let's ask you another question, "Where is Karen's laptop?" Let's again assume that you have observed where Karen's laptop was. To answer this question, one revisits when and where this memory was encoded and stored. Retrieval of such a memory is a reconstruction process of it. This type of memory is called episodic. It is more personal to you than semantic [1-3].</p>
<p>Motivated by this, we have explicitly modeled an agent that has both semantic and episodic memory systems. An agent interacts with the environment and has to answer questions to maximize the rewards. Our hypothesis is that if it can successfully encode</p>
<p>and store relevant observations in its brain as either semantic or episodic memories, then it can also answer the questions more successfully than using only one of the two memory systems.</p>
<p>The contributions of this paper are as follows. (1) Inspired by the cognitive science theory, we explicitly model an agent with both semantic and episodic memory systems, and show that it is better than having just one memory system in our experiments. (2) We designed and released our own challenging environment, compatible with OpenAI Gym [4], where an agent has to properly learn how to encode, store, and retrieve memories to maximize rewards. (3) We demonstrate that when an agent collaborates with another agent or human, it leads to better performance.</p>
<h1>2. Methodology</h1>
<h3>2.1. The Room Environment</h3>
<p>The OpenAI-Gym-compatible Room environment is one big room with $N_{\text {people }}$ number of people who can freely move around. Each of them selects one object, among $N_{\text {objects }}$, and places it in one of the $N_{\text {locations }}$ locations. $N_{\text {agents }}$ number of agent(s) are also in this room. They can only observe one human placing an object, one at a time; $\boldsymbol{x}^{(t)}$. At the same time, they are given one question about the location of an object; $\boldsymbol{q}^{(t)} \cdot \boldsymbol{x}^{(t)}$ is given as a quadruple, $\left(\boldsymbol{h}^{(t)}, \boldsymbol{r}^{(t)}, \boldsymbol{t}^{(t)}, t\right)$, For example, <James's laptop, AtLocation, James's desk, 42> accounts for an observation where an agent sees James placing his laptop on his desk at $t=42 . \boldsymbol{q}^{(t)}$ is given as a double, $(\boldsymbol{h}, \boldsymbol{r})$. For example, <Karen's cat, AtLocation> is asking where Karen's cat is located. If the agent answers the question correctly, it gets a reward of +1 , and if not, it gets 0 .</p>
<p>The reason why the observations and questions are given as RDF-triple-like format is two folds. One is that this structured format is easily readable / writable by both humans and machines. Second is that we can use existing knowledge graphs, such as ConceptNet [5].</p>
<p>To simplify the environment, the agents themselves are not actually moving, but the room is continuously changing. There are several random factors in this environment to be considered:</p>
<ol>
<li>With the chance of $p_{\text {commonsense }}$, a human places an object in a commonsense location (e.g., a laptop on a desk). The commonsense knowledge we use is from ConceptNet. With the chance of $1-p_{\text {commonsense }}$, an object is placed at a noncommonsense random location (e.g., a laptop on the tree).</li>
<li>With the chance of $p_{\text {new_location }}$, a human changes object location.</li>
<li>With the chance of $p_{\text {new_object }}$, a human changes his/her object to another one.</li>
<li>With the chance of $p_{\text {switch_person }}$, two people switch their locations. This is done to mimic an agent moving around the room.</li>
</ol>
<p>All of the four probabilities account for the Bernoulli distributions.</p>
<h1>2.2. Episodic and Semantic Memory Systems</h1>
<p>Each agent partially observes the environment (i.e., they cannot see the entire room at once, but one human at a time). This means that it should keep the history of its observations. This can be done by having memory systems. In our work, we model our agent to have a human-like explicit memory system. This means that it has both episodic and semantic memory systems. For example, at current time $t=23$, a question given by the environment is <Karen's cat, AtLocation>. If the agent has an episodic memory <Karen's cat, AtLocation, Karen's office, 21>, which it has seen two time steps ago, this episodic memory will likely be a "correct" memory to be retrieved to answer the question.</p>
<p>Not every observation has to be saved in the episodic memory system. Using our commonsense, we know that laptops are mostly placed on the desk. So for example, at current time $t=23$, let's say that a question <James's laptop, AtLocation> is given. If the agent has an episodic memory of this event, then it can use it. But if not, then it can use a commonsense knowledge <laptop, AtLocation, desk, 10>. This commonsense knowledge forms the semantic memory of the agent, since semantic memory has to do with the general knowledge of the world. Similar to episodic memories, semantic memories are also quadruples. However, the last element of a semantic memory is not a timestamp, but the strength of the semantic memory. For example, <laptop, AtLocation, desk, 10> is a stronger semantic memory than <laptop, AtLocation, garage, 5>, since the agent has seen laptops being placed on desk 10 times, while it has only seen them in a garage five times. Notice that semantic memories do not include the names of people, since this type of memory is not person-specific.</p>
<p>Both episodic and semantic memory systems, $\boldsymbol{M}<em S="S">{E}$ and $\boldsymbol{M}</em>$, respectively, are bounded in size. Since an agent can not store all of its observations, it should learn what to store and what to forget. It should also learn that some of its episodic memories can be summarized into one semantic memory. For example, if it always sees humans placing their laptops on their desks, then perhaps one semantic memory <laptop, AtLocation, desk> is enough to answer the related questions.</p>
<h3>2.3. Hybrid Intelligence</h3>
<p>The Room environment does not restrict the number of agents. It allows for humanmachine or machine-machine collaboration. For example, at current time $t=23$, a question given by the environment is <Karen's cat, AtLocation>. If agent ${ }<em 2="2">{1}$ has an episodic memory <Karen's cat, AtLocation, Karen's office, 21> and agent ${ }</em>$ has an episodic memory <Karen's cat, AtLocation, Karen's desk, 22>, then it is more likely that the memory of agent $<em 1="1">{2}$ can answer the question more accurately since its memory is more recent than that of agent $</em>$. Or, it is also possible for them to use commonsense knowledge that "Cats are often found on the lap of their owners.", if the agents have encoded such a thing in their semantic memory system.</p>
<h1>3. Experimental Setup</h1>
<h3>3.1. Data Collection and the Environment Hyperparameters</h3>
<p>In order to simplify the experiment setup, we decided to use a subset of the ConceptNet. To be more specific, we restricted the number of objects to 10 , where the commonsense locations of every object is also restricted to be one. 10 random human names were used to mimic humans in the room. The relation $\boldsymbol{r}^{[t]}$ is always AtLocation. The four probabilities $p_{\text {commonsense }}, p_{\text {new_location }}, p_{\text {new_object }}$, and $p_{\text {switch_person }}$ were set to $0.7,0.1$, 0.1 , and 0.5 , respectively. We have tuned these values to mimic a realistic environment. We have also set the maximum steps of the environment to 1,000 . This means that the environment terminates after an agent has taken 1,000 steps.</p>
<h3>3.2. Single Agent Policies</h3>
<p>Inspired by the theories on the explicit human memory, we have designed the following four handcrafted policies (models).</p>
<p>Handcrafted 1: Only episodic, forget the oldest and answer the latest. This agent only has an episodic memory system. When the episodic memory system is full, it will forget the oldest episodic memory. When a question is asked and there are more than one relevant episodic memories found, it will use the latest relevant episodic memory to answer the question.</p>
<p>Handcrafted 2: Only semantic, forget the weakest and answer the strongest. This agent only has a semantic memory system. When the semantic memory system is full, it will forget the weakest semantic memory. When a question is asked and there are more than one relevant semantic memories found, it will use the strongest relevant semantic memory to answer the question.</p>
<p>Handcrafted 3: Both episodic and semantic. This agent has both episodic and semantic memory systems. When the episodic memory system is full, it will forget similar episodic memories that can be compressed into one semantic memory. When the semantic memory system is full, it will forget the weakest semantic memory. When a question is asked, it will first try to use the latest episodic memory to answer it, if it can not, it will use the strongest relevant semantic memory to answer the question.</p>
<p>Handcrafted 4: Both episodic and pretrained semantic. From the beginning of an episode, the semantic memory system is populated with the ConceptNet commonsense knowledge. When the episodic memory system is full, it will forget the oldest episodic memory. When a question is asked, it will first try to use the latest episodic memory to answer it, if it can not, it will use the strongest relevant semantic memory to answer the question.</p>
<p>For a fair comparison, every agent has the same total memory capacity. As for the Handcrafted 3 agent, the episodic and semantic memory systems have the same capacity, since this agent does not know which one is more important a priori. As for the Handcrafted 4 agent, if there is space left in the semantic memory system after filling it up, it will give the rest of the space to the episodic memory system. In order to show the validity of our handcrafted agents, we compare them with the agents that forget and answer uniform-randomly.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Handcrafted vs. random policies</p>
<h1>3.3. Multiple Agent Policies</h1>
<p>The multiple agent policies work in the same manner as the single agent policies, except that they can use their combined memory systems to answer questions.</p>
<h2>4. Results</h2>
<p>Figure 1 shows that our handcrafted forgetting and answering policies outperform random policies. Obviously, when both forgetting memories and answering questions are done randomly, it performs the worst.</p>
<p>Figure 2 shows the results after one episode, with their best handcrafted policies. It shows that when the memory capacity is low, having only episodic memory system is better than the others. This is because when there are not enough memories in the system, it is not enough to learn the general world knowledge. As the memory capacity increases, however, it shows that having a semantic memory system helps, as it learns to generalize the world. It is especially interesting to see the Handcrafted 4 agent, which has an episodic system and a pretrained semantic system. Since it already knows the general world knowledge, it could focus more on the episodic part, leading to better performance.</p>
<p>Figure 3 compares the performance between single-agent and double-agent setups. For a fair comparison, memory capacity was kept the same (i.e., as for the two agent setup, each agent can store 16 memories, while the agent in the single-agent setup can store 32). It shows that two agents working together were able to answer more questions than one agent working alone. This is due to the fact that the two agents were exploring the room in different directions. This led them to cover more area than one agent acting alone.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Total rewards with respect to different handcrafted policies and memory capacities.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Total rewards with respect to the number of agents. The lighter and narrower bars account for the single agent.</p>
<h1>5. Related work</h1>
<p>After studying related literature, we observed that papers that are theoretically similar to ours are mostly cognitive science papers. ACT-R [6] and Soar [7] put a big emphasis on theories, but they lack of computational experiments, which makes it hard to compare. There was a work [8] that studied how episodic and semantic memory systems play a role in recall of objects, but their experiments were human-based empirical results, which does not scale as well as our computational method.</p>
<p>Second is that although some computer science based papers do computational experiments that are a bit similar to ours, they often do not study episodic and semantic memory systems together. For example, Episodic Memory Reader [9] also learns what to forget in their memory system, and they also use question-answering to evaluate their</p>
<p>method. However, this work only focuses on episodic memory. Also, their memory system is not composed of RDF-like data, but rather numeric embeddings, which are hard to interpret what they have captured.</p>
<h1>6. Conclusions</h1>
<p>We have created our own OpenAI-Gym-compatible environment, where agents with both episodic and semantic memory systems can be tested. We showed that when a machine is explicitly given both semantic and episodic memory systems, it outperforms the ones that only have one of the two memory systems. We also showed that when an agent is pretrained with commonsense knowledge, it outperforms the one that is not pretrained. Multiple agents collaborating with each other were better at question answering, since they can complement each other's memories.</p>
<p>In the future, we want to see if reinforcement learning agents can perform as good as the handcrafted ones, to see if such data-driven agents can lead to better generalization. We also hope to make the Room environment even closer to the real human environment (e.g., adding images, voices, more entities and relations, etc.). As for the collaboration, the current setup is limited to only agents working together. We would like to extend this to different collaboration setups (e.g., multiple humans and multiple agents). It would be especially interesting to encourage agents to ask humans questions, when it is not sure how to answer them. Collaboration will not always be straightforward, especially if there are conflicts and different degrees of trust among humans and agents. Dealing them elegantly will be another future challenge.</p>
<h2>Acknowledgements</h2>
<p>This research was (partially) funded by the Hybrid Intelligence Center, a 10-year program funded by the Dutch Ministry of Education, Culture and Science through the Netherlands Organization for Scientific Research, https://www.hybrid-intelligencecentre.nl/.</p>
<h2>References</h2>
<p>[1] Tulving E. Elements of Episodic Memory. Oxford University Press; 1983.
[2] Tulving E. Memory and consciousness. Canadian Psychology/Psychologie canadienne. 1985;26(1):1.
[3] Tulving E, Thomson DM. Encoding specificity and retrieval processes in episodic memory. Psychological Review. 1973;80:352-73.
[4] Brockman G, Cheung V, Pettersson L, Schneider J, Schulman J, Tang J, et al.. OpenAI Gym; 2016. Cite arxiv:1606.01540. Available from: http://arxiv.org/abs/1606.01540.
[5] Speer R, Chin J, Havasi C. ConceptNet 5.5: An Open Multilingual Graph of General Knowledge. Proceedings of the AAAI Conference on Artificial Intelligence. 2017 Feb;31(1). Available from: https://ojs.aaai.org/index.php/AAAI/article/view/11164.
[6] Anderson JR, Betts S, Bothell D, Lebiere C. Discovering skill. Cognitive Psychology. 2021;129:101410. Available from: https://www.sciencedirect.com/science/article/pii/ S0010028521000335.
[7] Laird JE. The Soar Cognitive Architecture. The MIT Press; 2012.</p>
<p>[8] Hemmer P, Steyvers M. Integrating Episodic and Semantic Information in Memory for Natural Scenes; 2009. .
[9] Han M, Kang M, Jung H, Hwang SJ. Episodic Memory Reader: Learning What to Remember for Question Answering from Streaming Data. In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence, Italy: Association for Computational Linguistics; 2019. p. 4407-17. Available from: https://aclanthology.org/P19-1434.</p>            </div>
        </div>

    </div>
</body>
</html>