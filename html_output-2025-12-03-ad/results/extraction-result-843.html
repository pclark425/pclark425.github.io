<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-843 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-843</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-843</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-23.html">extraction-schema-23</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <p><strong>Paper ID:</strong> paper-245353941</p>
                <p><strong>Paper Title:</strong> <a href="https://www.aclanthology.org/2022.tacl-1.19.pdf" target="_blank">Towards General Natural Language Understanding with Probabilistic Worldbuilding</a></p>
                <p><strong>Paper Abstract:</strong> We introduce the Probabilistic Worldbuilding Model (PWM), a new fully symbolic Bayesian model of semantic parsing and reasoning, as a first step in a research program toward more domain- and task-general NLU and AI. Humans create internal mental models of their observations that greatly aid in their ability to understand and reason about a large variety of problems. In PWM, the meanings of sentences, acquired facts about the world, and intermediate steps in reasoning are all expressed in a human-readable formal language, with the design goal of interpretability. PWM is Bayesian, designed specifically to be able to generalize to new domains and new tasks. We derive and implement an inference algorithm that reads sentences by parsing and abducing updates to its latent world model that capture the semantics of those sentences, and evaluate it on two out-of-domain question-answering datasets: (1) ProofWriter and (2) a new dataset we call FictionalGeoQA, designed to be more representative of real language but still simple enough to focus on evaluating reasoning ability, while being robust against heuristics. Our method outperforms baselines on both, thereby demonstrating its value as a proof-of-concept.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e843.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e843.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PWM/PWL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Worldbuilding Model (PWM) / Probabilistic Worldbuilding from Language (PWL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PWM is a fully symbolic Bayesian generative model that represents meaning, facts, and reasoning steps in higher-order logic as a probabilistic 'theory' (a belief over axioms and proofs); PWL is the implemented inference algorithm that parses sentences, abduces axioms (world model updates), and performs abductive reasoning using MCMC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Probabilistic Worldbuilding Model (PWM) / PWL inference</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PWM defines a Bayesian generative model over a latent theory T (a collection of higher-order logical axioms) and per-observation natural-deduction proofs π_i whose conclusions are the logical forms x_i that generate observed sentences y_i. The prior over theories is exchangeable and nonparametric (Dirichlet process over axioms, with structured base distributions for predicates/constants/events and light-tailed name distributions). The language module is a probabilistic semantic parser that outputs k-best logical forms p(x|y,T). The reasoning module performs abductive inference to find axioms that explain observed logical forms. PWL implements inference by initializing abductive proofs and then running Metropolis–Hastings MCMC proposals (mutations to proofs/axioms such as replacing grounded atoms with induced universal rules, changing set sizes, resampling choices at proof nodes, merge/split of events) to sample from the posterior p(T,π|x). It enforces global consistency constraints (e.g., set sizes, distinct constants) and supports both classical and intuitionistic logic. For question answering, PWL approximates probabilities for a query (and its negation) by summing over sampled theory/proof states and compares log-probabilities to return true/false/unknown.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Logic-based probabilistic world model (higher-order logic theory with a Dirichlet-process prior; a belief over axioms/proofs)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>The world model is a probabilistic, symbolic 'theory' T consisting of higher-order logical axioms (neo-Davidsonian representation for events). States are represented implicitly as the set of axioms in T and what is provable from them; observations are logical forms x_i whose proofs π_i conclude the x_i. The model is explicitly probabilistic: a nonparametric DP prior generates axioms, and proofs are sampled from a Poisson-length generative process conditioned on using axioms in T. Uncertainty is represented as a posterior distribution over theories and proofs; inference approximates this posterior via Metropolis–Hastings MCMC (Monte Carlo sampling). There are hard global consistency constraints (e.g., set sizes, distinct constants) that prune invalid theories. The model is not a state-transition planner in the classical PDDL sense, but it is a probabilistic symbolic belief-state model used for abductive inference and downstream question-answering.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>Epistemic uncertainty over the latent theory and proofs; parsing/interpretation uncertainty (ambiguous logical forms)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Explicit probability distributions (Dirichlet-process prior over axioms, generative prior for proofs), Monte Carlo sampling (Metropolis–Hastings MCMC) to approximate posterior over theories/proofs; the language module is probabilistic and scores k-best logical forms p(x|y,T).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Abductive inference via Metropolis–Hastings MCMC over proof/theory space (no classical planner like MCTS/A*; decision for QA compares posterior probabilities of query vs its negation)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>ProofWriter; FictionalGeoQA</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>ProofWriter: templated rule-based natural-language statements and queries (logic-focused synthetic dataset). FictionalGeoQA: a new small QA dataset of short paragraphs (fictionalized geography) designed for out-of-domain, realistic-language reasoning with distractors; contexts are sets of declarative sentences (no cross-sentential anaphora in this version). Neither is an interactive text-adventure environment; both are text-based QA/reading comprehension benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Zero-shot question-answering accuracy (true/false/unknown labels) on evaluation splits</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported to outperform baselines on both ProofWriter and FictionalGeoQA in zero-shot settings; paper reports qualitative and tabulated zero-shot accuracy but numeric values are presented in the paper's tables (not verbatim in the body text).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against T5-based baselines (trained on other parts of ProofWriter), UnifiedQA (large neural QA model), Boxer + Vampire/E theorem provers, and variants combining PWL's language module with Vampire/E; PWL outperformed baselines on zero-shot QA overall, with UnifiedQA strong on some subsets but weaker on negation/subjective definitions and lexical-ambiguity resolving.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>No explicit ablation isolating the effect of uncertainty modeling vs. non-probabilistic symbolic representations is reported; comparisons are mainly between full PWL and baselines (neural or theorem-prover pipelines).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PWM/PWL demonstrates a fully symbolic probabilistic world model (belief over higher-order logical theories) applied to natural-language understanding via abductive inference; uncertainty is explicitly represented as a posterior over theories and proofs and approximated with MCMC, enabling principled handling of conflicting/ambiguous observations and improving zero-shot QA generalization. The system does not use LLMs, and it is not a planner in the classical PDDL/PPDDL sense, but it provides a probabilistic symbolic belief-state that could serve as a world model for downstream decision-making or planning in text-based tasks if extended.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e843.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e843.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Probabilistic ILP / Stochastic Logic Programs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Inductive Logic Programming languages / Stochastic Logic Programs (e.g., Muggleton, Cussens, Sato/PRISM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Family of methods that combine logic programming with probability, enabling learning and inference over symbolic rules with uncertainty (e.g., PRISM, stochastic logic programs, probabilistic ILP). They typically restrict to Horn-clause-like fragments for tractability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Probabilistic ILP / Stochastic Logic Programs</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Probabilistic ILP languages place probability distributions over logical clauses or programs and aim to learn rules/theories from observations; representative systems include PRISM-style generative modeling and stochastic logic programs. The paper cites these as prior art that can learn 'theory' from observations but notes typical restrictions (Horn clause fragment) that limit expressivity compared to PWM's higher-order logic approach.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Probabilistic logic programs / stochastic logic programs (logic-based probabilistic models)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Representations are sets of first-order Horn clauses with probabilities (parameterized clause weights or generative processes). These models are probabilistic and capture uncertainty over which rules/facts hold, but often are limited to particular fragments of logic; they can be used to infer beliefs over states via probabilistic logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>Epistemic uncertainty over rule existence/weights and probabilistic outcomes of logical consequences</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Probability distributions over clauses/parameters (e.g., EM, Bayesian priors), generative modeling (PRISM), parameter estimation for stochastic logic programs</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as related work: such languages can learn theories from observations but are typically restricted to Horn-clause form for tractability, limiting coverage of natural language phenomena that PWM targets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e843.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e843.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Probabilistic Knowledge Bases / Tractable Probabilistic KBs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Knowledge Bases and Tractable Probabilistic Knowledge Bases (e.g., Niepert & Domingos; Jain et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that model knowledge bases probabilistically to handle uncertainty in facts and rules, often trading expressivity for tractability (graph-based representations, tractable probabilistic models, scalable rule learning).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Probabilistic Knowledge Bases / Tractable PKBs</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>These methods encode facts and relations with probabilistic semantics (e.g., weights/confidences, tractable inference schemes) to support uncertain inference at scale; some focus on scalable rule learning and inference with approximations/tractable representations. The paper cites them as examples of probabilistic approaches to model uncertainty in KBs and cognitive-architecture-like systems.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Probabilistic KBs (graph-based probabilistic representations; tractable probabilistic graphical/logical models)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World modeled as graph of entities/relations with probabilistic weights or as a tractable probabilistic logical model; typically probabilistic (represents uncertainty over facts/relations) and optimized for scalable inference (sometimes at the cost of expressivity).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>Uncertainty over facts/relations (epistemic), probabilistic rule confidences</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Weighted facts/rules, tractable probabilistic graphical/logical models, approximate inference, MCMC or specialized tractable inference methods</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as related work; these systems handle uncertainty in symbolic KBs but often simplify representations (e.g., graph edges) for tractability and may not support the full higher-order logic expressivity PWM uses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e843.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e843.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Theorem Provers / Differentiable Provers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural theorem provers / end-to-end differentiable proving (e.g., Rocktäschel & Riedel 2017)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neuro-symbolic approaches that learn differentiable representations for proving/inference; typically apply backward-chaining style proof search and are often restricted to Horn-clause fragments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Theorem Provers / Differentiable Provers</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>These hybrid systems learn embeddings or differentiable mechanisms to perform logical inference (sometimes end-to-end), enabling gradient-based learning of rules or proofs. The paper references them as neuro-symbolic work that combines symbolic proofs with neural components but notes restrictions: backward chaining and Horn-clause-limited semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Logic-based (learned/differentiable) symbolic representations (usually first-order Horn-clause fragment)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World is encoded as rules/facts (often Horn clauses) with learned vector representations used to guide inference; uncertainty often encoded via soft scores or probabilities from neural components.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td>Soft / learned scoring uncertainty from neural components (prediction uncertainty over proofs/rules)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Differentiable scoring, learned embeddings, soft attention; not typically Bayesian posterior over explicit symbolic theories</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as prior hybrid work; constrained proof-search (backward chaining) limits expressivity relative to PWM's abductive higher-order approach.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e843.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e843.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UnifiedQA (baseline LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>UnifiedQA (large-scale neural question-answering model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art neural QA system based on large pretrained transformers that can be applied to many QA formats; used as a baseline in the FictionalGeoQA evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>UnifiedQA</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A large pre-trained transformer-based QA model that is applied end-to-end to answer questions from text; in the paper it is used purely as a baseline (no integration with symbolic world model).</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>End-to-end question answering (direct model that maps context+question to answer)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>UnifiedQA (T5-family based ensemble of QA fine-tuned models)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>FictionalGeoQA (baseline comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Short paragraphs with factual and distractor sentences; fictionalized geography QA dataset used to test out-of-domain reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>QA accuracy on FictionalGeoQA subsets</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported to perform relatively well overall, but worse on negation and subjective-definition examples compared to PWL; exact figures appear in paper tables.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to PWL, Boxer+theorem-provers, and PWL-language-module + theorem-provers.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Used as a neural baseline; demonstrates that large LMs do well on some QA subsets but struggle with certain logical phenomena (negation, definitions) that PWL handles via explicit symbolic world modeling and abduction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e843.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e843.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boxer + Vampire/E (theorem-prover pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Boxer semantic parser combined with Vampire or E first-order theorem provers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pipelines that parse natural language into logical forms (Boxer) and attempt deductive proofs with classical first-order theorem provers (Vampire, E); used as baselines and discussed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Boxer + Vampire/E</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Boxer produces wide-coverage semantic representations (Parallel Meaning Bank style) from text; Vampire and E are automated first-order theorem provers used to attempt deductions/proofs given parsed axioms and queries. The paper used these pipelines as baselines and observed coverage and precision trade-offs: Boxer had high coverage but lower precision on the FictionalGeoQA semantics, and theorem-prover search exploded on some examples due to required set-theoretic axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Deterministic logic-based KB (first-order logical axioms produced by parsing; classical theorem proving)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World model is the set of axioms produced by Boxer; provability via theorem provers determines entailment. Representations are symbolic and deductive (not probabilistic by default); provers operate deterministically (search-based deduction) and may require additional axioms for set reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Deductive theorem proving (no probabilistic planning)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>FictionalGeoQA (baseline comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Short, independent declarative sentences designed to test reading+reasoning; these pipelines served as deductive baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Coverage and QA accuracy / precision</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Boxer had higher coverage (~100%) but lower precision compared to PWL; PWL coverage was lower (~79.8%) but higher precision on the dataset (exact numeric comparisons are shown in paper tables). Theorem provers often struggled (search explosion) when supplied with the full set-theoretic axioms required by the semantic representation.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively and quantitatively to PWL and UnifiedQA in FictionalGeoQA experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pure deductive pipelines (Boxer + theorem provers) suffer from combinatorial explosion and representational mismatches when handling rich set-theoretic or higher-order semantics; PWL's abductive probabilistic approach avoids some of these issues by creating axioms during abduction and using probabilistic search to find plausible theories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Towards General Natural Language Understanding with Probabilistic Worldbuilding', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning and inference in tractable probabilistic knowledge bases <em>(Rating: 2)</em></li>
                <li>Scalable rule learning in probabilistic knowledge bases <em>(Rating: 2)</em></li>
                <li>Parameter estimation in stochastic logic programs <em>(Rating: 1)</em></li>
                <li>Generative modeling with failure in PRISM <em>(Rating: 1)</em></li>
                <li>End-to-end differentiable proving <em>(Rating: 1)</em></li>
                <li>Transformers as soft reasoners over language <em>(Rating: 1)</em></li>
                <li>Unifiedqa: Crossing format boundaries with a single QA system <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-843",
    "paper_id": "paper-245353941",
    "extraction_schema_id": "extraction-schema-23",
    "extracted_data": [
        {
            "name_short": "PWM/PWL",
            "name_full": "Probabilistic Worldbuilding Model (PWM) / Probabilistic Worldbuilding from Language (PWL)",
            "brief_description": "PWM is a fully symbolic Bayesian generative model that represents meaning, facts, and reasoning steps in higher-order logic as a probabilistic 'theory' (a belief over axioms and proofs); PWL is the implemented inference algorithm that parses sentences, abduces axioms (world model updates), and performs abductive reasoning using MCMC.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Probabilistic Worldbuilding Model (PWM) / PWL inference",
            "system_description": "PWM defines a Bayesian generative model over a latent theory T (a collection of higher-order logical axioms) and per-observation natural-deduction proofs π_i whose conclusions are the logical forms x_i that generate observed sentences y_i. The prior over theories is exchangeable and nonparametric (Dirichlet process over axioms, with structured base distributions for predicates/constants/events and light-tailed name distributions). The language module is a probabilistic semantic parser that outputs k-best logical forms p(x|y,T). The reasoning module performs abductive inference to find axioms that explain observed logical forms. PWL implements inference by initializing abductive proofs and then running Metropolis–Hastings MCMC proposals (mutations to proofs/axioms such as replacing grounded atoms with induced universal rules, changing set sizes, resampling choices at proof nodes, merge/split of events) to sample from the posterior p(T,π|x). It enforces global consistency constraints (e.g., set sizes, distinct constants) and supports both classical and intuitionistic logic. For question answering, PWL approximates probabilities for a query (and its negation) by summing over sampled theory/proof states and compares log-probabilities to return true/false/unknown.",
            "world_model_type": "Logic-based probabilistic world model (higher-order logic theory with a Dirichlet-process prior; a belief over axioms/proofs)",
            "world_model_description": "The world model is a probabilistic, symbolic 'theory' T consisting of higher-order logical axioms (neo-Davidsonian representation for events). States are represented implicitly as the set of axioms in T and what is provable from them; observations are logical forms x_i whose proofs π_i conclude the x_i. The model is explicitly probabilistic: a nonparametric DP prior generates axioms, and proofs are sampled from a Poisson-length generative process conditioned on using axioms in T. Uncertainty is represented as a posterior distribution over theories and proofs; inference approximates this posterior via Metropolis–Hastings MCMC (Monte Carlo sampling). There are hard global consistency constraints (e.g., set sizes, distinct constants) that prune invalid theories. The model is not a state-transition planner in the classical PDDL sense, but it is a probabilistic symbolic belief-state model used for abductive inference and downstream question-answering.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "Epistemic uncertainty over the latent theory and proofs; parsing/interpretation uncertainty (ambiguous logical forms)",
            "uncertainty_method": "Explicit probability distributions (Dirichlet-process prior over axioms, generative prior for proofs), Monte Carlo sampling (Metropolis–Hastings MCMC) to approximate posterior over theories/proofs; the language module is probabilistic and scores k-best logical forms p(x|y,T).",
            "planning_algorithm": "Abductive inference via Metropolis–Hastings MCMC over proof/theory space (no classical planner like MCTS/A*; decision for QA compares posterior probabilities of query vs its negation)",
            "planning_integrates_uncertainty": true,
            "text_environment_name": "ProofWriter; FictionalGeoQA",
            "text_environment_description": "ProofWriter: templated rule-based natural-language statements and queries (logic-focused synthetic dataset). FictionalGeoQA: a new small QA dataset of short paragraphs (fictionalized geography) designed for out-of-domain, realistic-language reasoning with distractors; contexts are sets of declarative sentences (no cross-sentential anaphora in this version). Neither is an interactive text-adventure environment; both are text-based QA/reading comprehension benchmarks.",
            "performance_metric": "Zero-shot question-answering accuracy (true/false/unknown labels) on evaluation splits",
            "performance_value": "Reported to outperform baselines on both ProofWriter and FictionalGeoQA in zero-shot settings; paper reports qualitative and tabulated zero-shot accuracy but numeric values are presented in the paper's tables (not verbatim in the body text).",
            "baseline_comparison": "Compared against T5-based baselines (trained on other parts of ProofWriter), UnifiedQA (large neural QA model), Boxer + Vampire/E theorem provers, and variants combining PWL's language module with Vampire/E; PWL outperformed baselines on zero-shot QA overall, with UnifiedQA strong on some subsets but weaker on negation/subjective definitions and lexical-ambiguity resolving.",
            "has_ablation_uncertainty": false,
            "ablation_results": "No explicit ablation isolating the effect of uncertainty modeling vs. non-probabilistic symbolic representations is reported; comparisons are mainly between full PWL and baselines (neural or theorem-prover pipelines).",
            "key_findings": "PWM/PWL demonstrates a fully symbolic probabilistic world model (belief over higher-order logical theories) applied to natural-language understanding via abductive inference; uncertainty is explicitly represented as a posterior over theories and proofs and approximated with MCMC, enabling principled handling of conflicting/ambiguous observations and improving zero-shot QA generalization. The system does not use LLMs, and it is not a planner in the classical PDDL/PPDDL sense, but it provides a probabilistic symbolic belief-state that could serve as a world model for downstream decision-making or planning in text-based tasks if extended.",
            "uuid": "e843.0",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Probabilistic ILP / Stochastic Logic Programs",
            "name_full": "Probabilistic Inductive Logic Programming languages / Stochastic Logic Programs (e.g., Muggleton, Cussens, Sato/PRISM)",
            "brief_description": "Family of methods that combine logic programming with probability, enabling learning and inference over symbolic rules with uncertainty (e.g., PRISM, stochastic logic programs, probabilistic ILP). They typically restrict to Horn-clause-like fragments for tractability.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Probabilistic ILP / Stochastic Logic Programs",
            "system_description": "Probabilistic ILP languages place probability distributions over logical clauses or programs and aim to learn rules/theories from observations; representative systems include PRISM-style generative modeling and stochastic logic programs. The paper cites these as prior art that can learn 'theory' from observations but notes typical restrictions (Horn clause fragment) that limit expressivity compared to PWM's higher-order logic approach.",
            "world_model_type": "Probabilistic logic programs / stochastic logic programs (logic-based probabilistic models)",
            "world_model_description": "Representations are sets of first-order Horn clauses with probabilities (parameterized clause weights or generative processes). These models are probabilistic and capture uncertainty over which rules/facts hold, but often are limited to particular fragments of logic; they can be used to infer beliefs over states via probabilistic logical inference.",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "Epistemic uncertainty over rule existence/weights and probabilistic outcomes of logical consequences",
            "uncertainty_method": "Probability distributions over clauses/parameters (e.g., EM, Bayesian priors), generative modeling (PRISM), parameter estimation for stochastic logic programs",
            "planning_algorithm": null,
            "planning_integrates_uncertainty": null,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Mentioned as related work: such languages can learn theories from observations but are typically restricted to Horn-clause form for tractability, limiting coverage of natural language phenomena that PWM targets.",
            "uuid": "e843.1",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Probabilistic Knowledge Bases / Tractable Probabilistic KBs",
            "name_full": "Probabilistic Knowledge Bases and Tractable Probabilistic Knowledge Bases (e.g., Niepert & Domingos; Jain et al.)",
            "brief_description": "Approaches that model knowledge bases probabilistically to handle uncertainty in facts and rules, often trading expressivity for tractability (graph-based representations, tractable probabilistic models, scalable rule learning).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Probabilistic Knowledge Bases / Tractable PKBs",
            "system_description": "These methods encode facts and relations with probabilistic semantics (e.g., weights/confidences, tractable inference schemes) to support uncertain inference at scale; some focus on scalable rule learning and inference with approximations/tractable representations. The paper cites them as examples of probabilistic approaches to model uncertainty in KBs and cognitive-architecture-like systems.",
            "world_model_type": "Probabilistic KBs (graph-based probabilistic representations; tractable probabilistic graphical/logical models)",
            "world_model_description": "World modeled as graph of entities/relations with probabilistic weights or as a tractable probabilistic logical model; typically probabilistic (represents uncertainty over facts/relations) and optimized for scalable inference (sometimes at the cost of expressivity).",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "Uncertainty over facts/relations (epistemic), probabilistic rule confidences",
            "uncertainty_method": "Weighted facts/rules, tractable probabilistic graphical/logical models, approximate inference, MCMC or specialized tractable inference methods",
            "planning_algorithm": null,
            "planning_integrates_uncertainty": null,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Mentioned as related work; these systems handle uncertainty in symbolic KBs but often simplify representations (e.g., graph edges) for tractability and may not support the full higher-order logic expressivity PWM uses.",
            "uuid": "e843.2",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Neural Theorem Provers / Differentiable Provers",
            "name_full": "Neural theorem provers / end-to-end differentiable proving (e.g., Rocktäschel & Riedel 2017)",
            "brief_description": "Neuro-symbolic approaches that learn differentiable representations for proving/inference; typically apply backward-chaining style proof search and are often restricted to Horn-clause fragments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Neural Theorem Provers / Differentiable Provers",
            "system_description": "These hybrid systems learn embeddings or differentiable mechanisms to perform logical inference (sometimes end-to-end), enabling gradient-based learning of rules or proofs. The paper references them as neuro-symbolic work that combines symbolic proofs with neural components but notes restrictions: backward chaining and Horn-clause-limited semantics.",
            "world_model_type": "Logic-based (learned/differentiable) symbolic representations (usually first-order Horn-clause fragment)",
            "world_model_description": "World is encoded as rules/facts (often Horn clauses) with learned vector representations used to guide inference; uncertainty often encoded via soft scores or probabilities from neural components.",
            "uses_llm": null,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": true,
            "uncertainty_type": "Soft / learned scoring uncertainty from neural components (prediction uncertainty over proofs/rules)",
            "uncertainty_method": "Differentiable scoring, learned embeddings, soft attention; not typically Bayesian posterior over explicit symbolic theories",
            "planning_algorithm": null,
            "planning_integrates_uncertainty": null,
            "text_environment_name": null,
            "text_environment_description": null,
            "performance_metric": null,
            "performance_value": null,
            "baseline_comparison": null,
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Cited as prior hybrid work; constrained proof-search (backward chaining) limits expressivity relative to PWM's abductive higher-order approach.",
            "uuid": "e843.3",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "UnifiedQA (baseline LLM)",
            "name_full": "UnifiedQA (large-scale neural question-answering model)",
            "brief_description": "A state-of-the-art neural QA system based on large pretrained transformers that can be applied to many QA formats; used as a baseline in the FictionalGeoQA evaluation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "UnifiedQA",
            "system_description": "A large pre-trained transformer-based QA model that is applied end-to-end to answer questions from text; in the paper it is used purely as a baseline (no integration with symbolic world model).",
            "world_model_type": null,
            "world_model_description": null,
            "uses_llm": true,
            "llm_role": "End-to-end question answering (direct model that maps context+question to answer)",
            "llm_model_name": "UnifiedQA (T5-family based ensemble of QA fine-tuned models)",
            "uncertainty_modeling": null,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": null,
            "planning_integrates_uncertainty": null,
            "text_environment_name": "FictionalGeoQA (baseline comparison)",
            "text_environment_description": "Short paragraphs with factual and distractor sentences; fictionalized geography QA dataset used to test out-of-domain reasoning.",
            "performance_metric": "QA accuracy on FictionalGeoQA subsets",
            "performance_value": "Reported to perform relatively well overall, but worse on negation and subjective-definition examples compared to PWL; exact figures appear in paper tables.",
            "baseline_comparison": "Compared to PWL, Boxer+theorem-provers, and PWL-language-module + theorem-provers.",
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Used as a neural baseline; demonstrates that large LMs do well on some QA subsets but struggle with certain logical phenomena (negation, definitions) that PWL handles via explicit symbolic world modeling and abduction.",
            "uuid": "e843.4",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "Boxer + Vampire/E (theorem-prover pipelines)",
            "name_full": "Boxer semantic parser combined with Vampire or E first-order theorem provers",
            "brief_description": "Pipelines that parse natural language into logical forms (Boxer) and attempt deductive proofs with classical first-order theorem provers (Vampire, E); used as baselines and discussed in the paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Boxer + Vampire/E",
            "system_description": "Boxer produces wide-coverage semantic representations (Parallel Meaning Bank style) from text; Vampire and E are automated first-order theorem provers used to attempt deductions/proofs given parsed axioms and queries. The paper used these pipelines as baselines and observed coverage and precision trade-offs: Boxer had high coverage but lower precision on the FictionalGeoQA semantics, and theorem-prover search exploded on some examples due to required set-theoretic axioms.",
            "world_model_type": "Deterministic logic-based KB (first-order logical axioms produced by parsing; classical theorem proving)",
            "world_model_description": "World model is the set of axioms produced by Boxer; provability via theorem provers determines entailment. Representations are symbolic and deductive (not probabilistic by default); provers operate deterministically (search-based deduction) and may require additional axioms for set reasoning.",
            "uses_llm": false,
            "llm_role": null,
            "llm_model_name": null,
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Deductive theorem proving (no probabilistic planning)",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "FictionalGeoQA (baseline comparison)",
            "text_environment_description": "Short, independent declarative sentences designed to test reading+reasoning; these pipelines served as deductive baselines.",
            "performance_metric": "Coverage and QA accuracy / precision",
            "performance_value": "Boxer had higher coverage (~100%) but lower precision compared to PWL; PWL coverage was lower (~79.8%) but higher precision on the dataset (exact numeric comparisons are shown in paper tables). Theorem provers often struggled (search explosion) when supplied with the full set-theoretic axioms required by the semantic representation.",
            "baseline_comparison": "Compared qualitatively and quantitatively to PWL and UnifiedQA in FictionalGeoQA experiments.",
            "has_ablation_uncertainty": null,
            "ablation_results": null,
            "key_findings": "Pure deductive pipelines (Boxer + theorem provers) suffer from combinatorial explosion and representational mismatches when handling rich set-theoretic or higher-order semantics; PWL's abductive probabilistic approach avoids some of these issues by creating axioms during abduction and using probabilistic search to find plausible theories.",
            "uuid": "e843.5",
            "source_info": {
                "paper_title": "Towards General Natural Language Understanding with Probabilistic Worldbuilding",
                "publication_date_yy_mm": "2022-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning and inference in tractable probabilistic knowledge bases",
            "rating": 2,
            "sanitized_title": "learning_and_inference_in_tractable_probabilistic_knowledge_bases"
        },
        {
            "paper_title": "Scalable rule learning in probabilistic knowledge bases",
            "rating": 2,
            "sanitized_title": "scalable_rule_learning_in_probabilistic_knowledge_bases"
        },
        {
            "paper_title": "Parameter estimation in stochastic logic programs",
            "rating": 1,
            "sanitized_title": "parameter_estimation_in_stochastic_logic_programs"
        },
        {
            "paper_title": "Generative modeling with failure in PRISM",
            "rating": 1,
            "sanitized_title": "generative_modeling_with_failure_in_prism"
        },
        {
            "paper_title": "End-to-end differentiable proving",
            "rating": 1,
            "sanitized_title": "endtoend_differentiable_proving"
        },
        {
            "paper_title": "Transformers as soft reasoners over language",
            "rating": 1,
            "sanitized_title": "transformers_as_soft_reasoners_over_language"
        },
        {
            "paper_title": "Unifiedqa: Crossing format boundaries with a single QA system",
            "rating": 1,
            "sanitized_title": "unifiedqa_crossing_format_boundaries_with_a_single_qa_system"
        }
    ],
    "cost": 0.01787325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Towards General Natural Language Understanding with Probabilistic Worldbuilding</p>
<p>Abulhair Saparov asaparov@cs.cmu.edu 
Machine Learning Department
Carnegie Mellon University
USA</p>
<p>Tom M Mitchell tom.mitchell@cs.cmu.edu 
Machine Learning Department
Carnegie Mellon University
USA</p>
<p>Towards General Natural Language Understanding with Probabilistic Worldbuilding
10.1162/tacl
We introduce the Probabilistic Worldbuilding Model (PWM), a new fully symbolic Bayesian model of semantic parsing and reasoning, as a first step in a research program toward more domain-and task-general NLU and AI. Humans create internal mental models of their observations that greatly aid in their ability to understand and reason about a large variety of problems. In PWM, the meanings of sentences, acquired facts about the world, and intermediate steps in reasoning are all expressed in a human-readable formal language, with the design goal of interpretability. PWM is Bayesian, designed specifically to be able to generalize to new domains and new tasks. We derive and implement an inference algorithm that reads sentences by parsing and abducing updates to its latent world model that capture the semantics of those sentences, and evaluate it on two out-of-domain question-answering datasets:(1) ProofWriter and (2) a new dataset we call FictionalGeoQA, designed to be more representative of real language but still simple enough to focus on evaluating reasoning ability, while being robust against heuristics. Our method outperforms baselines on both, thereby demonstrating its value as a proof-of-concept.325</p>
<p>Introduction</p>
<p>Despite recent progress in AI and NLP producing algorithms that perform well on a number of NLP tasks, it is still unclear how to move forward and develop algorithms that understand language as well as humans do. In particular, large-scale language models such as BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), GPT-3 (Brown et al., 2020), XLNet (Yang et al., 2019), and others were trained on a very large amount of text and can then be applied to perform many different NLP tasks after some fine-tuning. In the case of GPT-3, some tasks require very few additional training examples to achieve state-of-the-art performance.</p>
<p>As a result of training on text from virtually every domain, these models are domain-general. This is in contrast with NLP algorithms that are largely trained on one or a small handful of domains, and as such, are not able to perform well on new domains outside of their training. Despite this focus on domain-generality, there are still a large number of tasks on which these large-scale language models perform poorly (Dunietz et al., 2020). Many limitations of today's state-of-the-art methods become evident when comparing with the human ability to understand language (Lake et al., 2016;Tamari et al., 2020;Bender and Koller, 2020;Gardner et al., 2019;Linzen, 2020). Many cognitive scientists posit that humans create rich mental models of the world from their observations which provide superior explainability, reasoning, and generalizability to new domains and tasks. How do we, as a field, move from today's state-of-the-art to more general intelligence? What are the next steps to develop algorithms that can generalize to new tasks at the same level as humans? The lack of interpretability in many of these models makes these questions impossible to answer precisely. One promising direction is to change the evaluation metric: Brown et al. (2020), Linzen (2020), and many others have suggested zero-shot or few-shot accuracy to measure the performance of algorithms (i.e., the algorithm is evaluated with a new dataset, wholly separate from its training; or in the case of few-shot learning, save for a few examples). While this shift is welcome, it alone will not solve the above issues.</p>
<p>We introduce the Probabilistic Worldbuilding Model (PWM), a probabilistic generative model of reasoning and semantic parsing. Like some past approaches, PWM explicitly builds an internal mental model, which we call the theory (Tamari et al., 2020;Hogan et al., 2021;Mitchell et al., 2018;Charniak and Goldman, 1993). The theory constitutes what the algorithm believes to Figure 1: The generative process and inference in our model, with an example of a theory, generating a proof of a logical form which itself generates the sentence ''Bob is a mammal.'' During inference, only the sentences are observed, whereas the theory and proofs are latent. Given sentence y i , the language module outputs the logical form. The reasoning module then infers the proof π i of the logical form and updates the posterior of the theory T . be true. PWM is fully symbolic and Bayesian, using a single unified human-readable formal language to represent all meaning, and is therefore inherently interpretable. This is in contrast to systems that use subsymbolic representations of meaning for some or all of their components. Every random variable in PWM is well-defined with respect to other random variables and/or grounded primitives. Prior knowledge such as the rules of deductive inference, the structure of English grammar, and knowledge of basic physics and mathematics can be incorporated by modifying the prior distributions of the random variables in PWM. Incorporating prior knowledge can greatly reduce the amount of training data required to achieve sufficient generalizability, as we will demonstrate. Extensibility is key to future research that could enable more general NLU and AI, as it provides a clearer path forward for future exploration.</p>
<p>We present an implementation of inference under the proposed model, called the Probabilistic Worldbuilding from Language (PWL). While PWM is an abstract mathematical description of the underlying distribution of axioms, proofs, logical forms, and sentences, PWL is the algorithm that reads sentences, computes logical form representations of their meaning, and updates the axioms and proofs in the theory accordingly. See Figure 1 for a high-level schematic diagram of PWM and PWL. PWM describes the process depicted by the red arrows, whereas PWL is the algorithm depicted by the green arrows. We emphasize that the reasoning in PWL is not a theorem prover and is not purely deductive. Instead, PWL solves a different problem of finding satisfying abductive proofs, which is computationally easier than deductive inference: Given a set of observations, work backwards to find a set of axioms that deductively explain the observations. It is these abduced axioms that constitute the internal ''mental model.'' Humans often rely on abductive reasoning, for example in commonsense reasoning (Bhagavatula et al., 2020;Furbach et al., 2015).</p>
<p>A core principle of our approach is to ensure generality by design. Simplifying assumptions often trade away generality for tractability, such as by restricting the representation of the meanings of sentences, or number of steps during reasoning. PWM is designed to be domain-and task-general, and to this end, uses higher-order logic (i.e., lambda calculus) (Church, 1940) as the formal language, which we believe is sufficiently expressive to capture the meaning of declarative and interrogative sentences in natural language. Furthermore, PWM uses natural deduction for reasoning, which is complete in that if a logical form φ is true, there is a proof of φ (Henkin, 1950).</p>
<p>In Section 3, we describe PWM and PWL more precisely. In Section 4, as a proof-of-concept of the value of further research, we run experiments on two question-answering datasets: ProofWriter (Tafjord et al., 2021) and a new dataset, called FictionalGeoQA, which we specifically created to evaluate the ability to reason over short paragraphs while being robust against simpler heuristic strategies. Unlike ProofWriter, the text in Fic-tionalGeoQA was not template-generated and is more realistic, but is still simple enough to focus the evaluation on reasoning rather than parsing, with many sentences having semantics that go beyond the Horn clause fragment of first-order logic. PWL outperforms the baselines with respect to zero-shot accuracy (i.e., without looking at any training examples). Our code and data is freely available at github.com/asaparov/PWL and github.com/asaparov/fictionalgeoqa.</p>
<p>In summary, the primary contributions of this paper are the following:</p>
<p>• PWM, a new model for more general NLU, and PWL, the implementation that reads sentences, computes their logical forms, and updates its theory accordingly.</p>
<p>• Introducing FictionalGeoQA, a new questionanswering dataset designed to evaluate the ability to reason over language.</p>
<p>• Experiments on ProofWriter and Fictional-GeoQA demonstrating that PWL outperforms baseline methods on question-answering.</p>
<p>Related Work</p>
<p>Fully symbolic methods were commonplace in earlier AI research (Newell and Simon, 1976;Dreyfus, 1985). However, they were oftentimes brittle: A new observation would contradict the internal theory or violate an assumption, and it was not clear how to resolve the impasse in a principled manner and proceed. But they do have some key advantages: Symbolic approaches that use well-studied human-readable formal languages such as first-order logic, higher-order logic, type theory, etc. enable humans to readily inspect and understand the internal processing of these algorithms, effecting a high degree of interpretability (Dowty, 1981;Gregory, 2015;Cooper et al., 2015). Symbolic systems can be made general by design, by using a sufficiently expressive formal language and ontology. Hybrid methods have been explored to alleviate the brittleness of formal systems while engendering their strengths, such as interpretability and generalizability; for example, the recent work in neuro-symbolic methods (Yi et al., 2020;Saha et al., 2020;Tafjord et al., 2021). Neural theorem provers are in this vein (Rocktäschel and Riedel, 2017). However, the proofs considered in these approaches are based on backward chaining (Russell and Norvig, 2010), which restricts the semantics to the Horn clause fragment of first-order logic. Sun et al. (2020), Ren et al. (2020), and Arakelyan et al. (2021) extend coverage to the existential positive fragment of first-order logic. In natural language, sentences express more complex semantics such as negation, nested universal quantification, and higher-order structures. Our work explores the other side of the tradeoff between tractability and expressivity/generality. Theorem provers attempt to solve the problem of deduction: finding a proof of a given formula, given a set of axioms. In contrast, the reasoning component of PWM is abductive, and the abduced axioms can be used in downstream tasks, such as question-answering, and to better read new sentences in the context of the world model, as we will demonstrate. We posit that abduction is sufficient for more general NLU (Hobbs, 2006;Hobbs et al., 1993). PWM combines Bayesian statistical machine learning with symbolic representations in order to handle uncertainty in a principled manner, ''smoothing out'' or ''softening'' the rigidity of a purely symbolic approach. In PWM, the internal theory is a random variable, so if a new observation is inconsistent with the theory, there may be other theories in the probability space that are consistent with the observation. The probabilistic approach provides a principled way to resolve these impasses. PWM is certainly not the first to combine symbolic and probabilistic methods. There is a rich history of inductive logic programming (ILP) (Muggleton, 1991;Cropper and Morel, 2021) and probabilistic ILP languages (Muggleton, 1996;Cussens, 2001;Sato et al., 2005;Bellodi and Riguzzi, 2015). These languages could be used to learn a ''theory'' from a collection of observations, but they are typically restricted to learning rules in the form of first-order Horn clauses, for tractability. In natural language, it is easy to express semantics beyond the Horn clause fragment of first-order logic.</p>
<p>Knowledge bases (KBs) and cognitive architectures (Kotseruba and Tsotsos, 2020;Hogan et al., 2021;Laird et al., 1987;Mitchell et al., 2018) have attempted to explicitly model domaingeneral knowledge in a form amenable to reasoning. Cognitive architectures aim to more closely replicate human cognition. Some approaches use probabilistic methods to handle uncertainty (Niepert et al., 2012;Niepert and Domingos, 2015;Jain et al., 2019). However, many of these approaches make strong simplifying assumptions that restrict the expressive power of the formal language that expresses facts in the KB. For example, many KBs can be characterized as graphs, where each entity corresponds to a vertex and every fact corresponds to a labeled edge. For example, the belief plays sport(s williams, tennis) is representable as a directed edge connecting the vertex s williams to the vertex tennis, with the edge label plays sport. While this assumption greatly aids tractability and scalability, allowing many problems in reasoning to be solved by graph algorithms, it greatly hinders expressivity and generality, and there are many kinds of knowledge that simply cannot be expressed and represented in such KBs. PWM does not make such restrictions on logical forms in the theory, allowing for richer semantics, such as definitions, universally quantified statements, conditionals, etc.</p>
<p>Model</p>
<p>In this section, we provide a mathematical description of PWM. At a high level, the process for generating a sentence sampled from this probability distribution is:</p>
<ol>
<li>
<p>Sample the theory T from a prior distribution p(T ). T is a collection of logical forms in higher-order logic that represent what PWL believes to be true.</p>
</li>
<li>
<p>For each observation i, sample a proof π i from p(π i | T ). The conclusion of the proof is the logical form x i , which represents the meaning of the i th sentence.</p>
</li>
<li>
<p>Sample the i th sentence y i from p(y i | x i ).</p>
</li>
</ol>
<p>Inference is effectively the inverse of this process, and is implemented by PWL. During inference, PWL is given a collection of observed sentences y 1 , . . . , y n and the goal is to discern the value of the latent variables: the logical form of each sentence x {x 1 , . . . , x n }, the proofs for each logical form π {π 1 , . . . , π n }, and the underlying theory T . Both the generative process and inference algorithm naturally divide into two modules:</p>
<p>• Language module: During inference, this module's purpose is to infer the logical form of each observed sentence. That is, given the input sentence y i , this module outputs the k most-probable values of the logical form x i (i.e., semantic parsing).</p>
<p>• Reasoning module: During inference, this module's purpose is to infer the underlying theory that logically entails the observed logical forms (and their proofs thereof). That is, given an input collection of logical forms x, this module outputs the posterior distribution of the underlying theory T and the proofs π of those logical forms.</p>
<p>Note that the y i need not necessarily be sentences, and PWM can easily be generalized to other kinds of data. For example, if a generative model of images is available for p(y i | x i ), then an equivalent ''vision module'' may be defined. This module may be used either in place of, or together with, the language module. In the above generative process, PWM assumes each sentence to be independent. A model of context is required to properly handle inter-sentential anaphora or conversational settings. This can be done by allowing the distribution on y i to depend on previous logical forms or sentences:
p(y i | x 1 , . . . , x i ) (i.e.,
relaxing the i.i.d. assumption). For simplicity of this proof-of-concept, this is left to future work. There is a vast design space for symbolic representations of meaning. We are unable to comprehensively list all of our design choices, but we describe two important ones below.</p>
<p>Neo-Davidsonian semantics (Parsons, 1990) is used to represent meaning in all logical forms (both in the theory and during semantic parsing). As a concrete example, a straightforward way to represent the meaning of ''Jason traveled to New York'' could be with the logical form travel(jason, nyc). In neo-Davidsonian semantics, this would instead be represented with three distinct atoms: travel(c 1 ), arg1(c 1 ) = jason, and arg2(c 1 ) = nyc. Here, c 1 is a constant that represents the ''traveling event,'' whose first argument is the constant representing Jason, and whose second argument is the constant representing New York City. This representation allows the event to be more readily modified by other logical expressions, such as in ''Jason quickly traveled to NYC before nightfall.''</p>
<p>In addition, PWM defers named entity linking to the reasoning module (it is not done during parsing). That is, the semantic parser does not parse ''Jason'' directly into the constant jason. Rather, named entities are parsed into existentially quantified expressions, for example, ∃j(name(j) = ''Jason'' ∧ . . .). This simplifies the parser's task and allows reasoning to aid in entity linking. Table 1 details these design options.</p>
<p>Reasoning Module</p>
<p>Generative Process for the Theory p(T)</p>
<p>The theory T is a collection of axioms a 1 , a 2 , . . . represented in higher-order logic. We choose a fairly simple prior p(T ) for rapid prototyping, but it is straightforward to substitute with a more complex prior. Specifically a 1 , a 2 , . . . are distributed according to a distribution G a which is sampled from a Dirichlet process (DP) (Ferguson, 1973), an exchangeable non-parametric distribution.
G a ∼ DP(H a , α), (1) a 1 , a 2 , . . . ∼ G a ,(2)
where H a is the base distribution and α = 0.1 is the concentration parameter. An equivalent perspective of the DP that better illustrates how the samples are generated is the Chinese restaurant process (Aldous, 1985):
a i ∼ H a with probability α α + i − 1 ,(3)a i = a j with probability i−1 k=1 1{a k = a j } α + i − 1 .(4)
That is, the i th sample is drawn from H a with probability proportional to α, or it is set to a previous sample with probability proportional to the number of times that sample has been drawn. The base distribution H a recursively generates logical forms in higher-order logic. Because any formula can be written as a tree, they can be gen-erated top-down, starting from the root. The type of each node (conjunction ∧, disjunction ∨, negation ¬, quantification ∀x, etc.) is sampled from a categorical distribution. If the type of the node is selected to be an atom (e.g., book(c 1 )), then its predicate is sampled from a non-parametric distribution of predicate symbols H p . The atom's argument(s) are each sampled as follows: If n V is the number of available variables (from earlier generated quantifiers), then sample a variable uniformly at random with probability 1 n V +1 ; otherwise, with probability 1 n V +1 , sample a constant from a non-parametric distribution of constant symbols H c . For brevity, we refer the reader to our code for the specific forms of H p and H c .</p>
<p>Since PWM uses a neo-Davidsonian representation, another node type that H a can generate is an event argument (e.g., arg1(c 1 ) = jason). When this is selected, the event constant (c 1 in the example) is sampled in the same way an atom's argument is sampled, as described above: first by trying to sample a variable, and otherwise sampling a constant from H c . The right side of the equality (jason in the example) can either be a variable, constant, string, or number, so PWM first selects its type from a categorical distribution. If the type is chosen to be a number, string, or variable, its value is sampled uniformly. If the type is chosen to be a constant, it is sampled from H c .</p>
<p>Names of entities are treated specially in this prior: The number of names available to each entity is sampled according to a very light-tailed distribution i.i.d.: for entity c i the number of names
n N (c i ) #{s : name(c i ) = s} is distributed according to p(n N (c i ) = k) ∝ λ k 2 .
This ensures that entities tend not to have too many names.</p>
<p>Sets are also treated specially in this prior: One kind of axiom that can be generated is one that declares the size of a set-for example, size(λx.planet(x)) = 8 denotes that the size of the set of planets is 8. In the prior, the size of each set is distributed according to a geometric distribution with parameter 10 −4 . Sets can have arity not equal to 1, in which case their elements are tuples.</p>
<p>Deterministic Constraints: We also impose hard constraints on the theory T . Most importantly, T is required to be globally consistent. While this is a conceptually simple requirement, it is computationally expensive (generally undecideable even in first-order logic). PWL enforces this constraint by keeping track of the known sets in the theory (i.e., a set is known if its set size axiom is used in a proof, or if the set appears as a subset/superset in a universally-quantified axiom,
such as in ∀x(cat(x) → mammal(x)) where the set λx.cat(x) is a subset of λx.mammal(x)).
For each set, PWL computes which elements are provably members of that set. If the number of provable members of a set is greater than its size, or if an element is both provably a member and not a member of a set, the theory is inconsistent. Relaxing this constraint would be valuable in future research, perhaps instead by only considering the relevant sets rather than all sets in the theory, or deferring consistency checks altogether. We place a handful of other constraints on the theory T : The name of an entity must be a string (and not a number or a constant). All constants are distinct; that is, c i = c j for all i = j. This helps to alleviate identifiability issues, as otherwise, there would be a much larger number of logically equivalent theories. No event can be an argument of itself (e.g., there is no constant c i such that arg1(c i ) = c i ). If a theory T satisfies all constraints, we write ''T valid.'' These constraints do slightly complicate computation of the prior, since the generative process for generating T is conditioned on T being valid:
p(T | T valid) = p(T )/p(T valid),(5)where p(T valid) = T :T valid p(T ),(6)
and the denominator is intractable to compute. However, we show in Section 3.1.3 that for inference, it suffices to be able to efficiently compute the ratio of prior probabilities:
p(T 1 |T 1 valid) p(T 2 |T 2 valid) = p(T 1 )p(T 2 valid) p(T 2 )p(T 1 valid) = p(T 1 ) p(T 2 ) .(7)
Additionally note that because the above constraints do not depend on the order of the axioms, constants, and so forth (i.e., the constraints themselves are exchangeable), the distribution of T conditioned on T being valid is exchangeable.</p>
<p>Properties of the Prior p(T ):</p>
<p>We emphasize that these distributions were chosen for simplicity and ease of implementation, and they worked well enough in experiments. However, there are likely many distributions that would work just as well. The parameters in the above distributions are not learned; they were set and fixed a priori. Nevertheless, this prior does exhibit useful properties for a domain-and task-general model of reasoning:</p>
<p>• Occam's razor: Smaller/simpler theories are given higher probability than larger and more complex theories.</p>
<p>• Consistency: Inconsistent theories are discouraged or impossible.</p>
<p>• Entities tend to have a unique name. Our prior above encodes one direction of this prior belief: Each entity is unlikely to have many names. However, the prior does not discourage one name from referring to multiple entities.</p>
<p>• Entities tend to have a unique type. Note, however, that this does not discourage types provable by subsumption. For example, if the theory has the axioms novel(c 1 ) and ∀x(novel(x) → book(x)), even though book(c 1 ) is provable, it is not an axiom in this example and the prior only applies to axioms.</p>
<p>Generative Process for Proofs p(π i | T )</p>
<p>PWM uses natural deduction, a well-studied proof calculus, for the proofs (Gentzen, 1935(Gentzen, , 1969. Pfenning (2004) provides an accessible introduction. Figure 2 illustrates a simple example of a natural deduction proof. Each horizontal line is a deduction step, with the (zero or more) formulas above the line being its premises, and the one formula below the line being its conclusion. Each deduction step has a label to the right of the line. For example, the ''∧I'' step denotes conjunction introduction: given that A and B are true, this step concludes that A ∧ B is true, where A and B can be any formula. A natural deduction proof can rely on axioms (denoted by ''Ax''). We can write any natural deduction proof π i as a sequence of deduction steps π i (π i,1 , . . . , π i,k ) by traversing the proof tree in prefix order. We define a simple generative process for π i :</p>
<ol>
<li>
<p>First sample the length of the proof k from a Poisson distribution with parameter 20.</p>
</li>
<li>
<p>For each j = 1, . . . , k: Select a deduction rule from the proof calculus with a categorical distribution. If the Ax rule is selected, then simply take the next available axiom from the theory T = a 1 , a 2 , . . . If the deduction rule requires premises, then each premise is selected uniformly at random from π i,1 , . . . , π i,j−1 . 1</p>
</li>
</ol>
<p>The above generative process may produce a forest rather than a single proof tree. Thus, π i is sampled conditioned on π i being a valid proof. Just as with p(T ) in equation 5, this conditioning causes p(π i | T ) to be intractable to compute. However, only the ratio of the prior probability is needed for inference, which can be computed efficiently:
p(π i | T, π i valid) p(π i | T, π i valid) = p(π i | T )p(π i valid | T ) p(π i | T )p(π i valid | T ) = p(π i | T ) p(π i | T ) .(8)
Although PWL was initially implemented assuming classical logic, it is easy to adapt PWL to use other logics, such as intuitionistic logic. Intuitionistic logic is identical to classical logic except that the law of the excluded middle A ∨ ¬A is not a theorem (see Figure 3 for an example where the two logics disagree). The interpretable nature of the reasoning module makes it easy to adapt it to other kinds of logic or proof calculi. PWL supports both classical and intuitionistic logic. Figure 3: An example from the Electricity1 section in the ProofWriter dataset. Its label is unknown. Under classical logic, the query is provably true from the information in the 1st, 3rd, and 4th sentences.</p>
<p>Inference</p>
<p>Having described the generative process for the theory T and proofs π, we now describe inference. Given logical forms x, the goal is to compute the posterior distribution of T and π such that the conclusion of the each proof π i is x i . That is, PWL aims to recover the latent theory and proofs that explain/entail the given observed logical forms. To this end, PWL uses Metropolis-Hastings (MH) (Hastings, 1970;Robert and Casella, 2004). PWL performs inference in a streaming fashion, starting with the case n = 1 to obtain MH samples from p(π 1 , T |x 1 ). Then, for every new logical form x n , PWL uses the last sample from p(π 1 , . . . , π n−1 , T |x 1 , . . . , x n−1 ) as a starting point and then obtains MH samples from p(π 1 , . . . , π n , T |x 1 , . . . , x n ). This warm-start initialization serves to dramatically reduce the number of iterations needed to mix the Markov chain. To obtain the MH samples, the proof of each new logical form π (0) n is initialized using Algorithm 1, whereas the proofs of previous logical forms are kept from the last MH sample. The axioms in these proofs constitute the theory sample T (0) . Then, for each iteration t = 1, . . . , N iter , MH proposes a mutation to one or more proofs in π (t) . The possible mutations are listed in Table 2. This may change axioms in T (t) . Let T , π i be the newly proposed theory and proofs. Then, compute the acceptance probability:
p(T ) p(T (t) ) n i=1 p(π i |T ) p(π (t) i |T (t) ) g(T (t) , π (t) |T , π ) g(T , π |T (t) , π (t) ) ,(9)
where g(T , π |T (t) , π (t) ) is the probability of proposing the mutation from T (t) , π (t) to T , π , and g(T (t) , π (t) |T , π ) is the probability of the inverse of this mutation. Because this quantity depends only on the ratio of probabilities, it can be computed efficiently (see equations 3.1.1 and 8). Once this quantity is computed, sample from a Bernoulli with this quantity as its parameter. If it succeeds, MH accepts the proposed theory and proofs as the next sample: T (t+1) = T and π (t+1) i = π i . Otherwise, reject the proposal and keep the old sample:
T (t+1) = T (t) and π (t+1) i = π (t)
i . If every possible theory and proof is reachable from the initial theory by a sequence of mutations, then with sufficiently many iterations, the samples T (t) and π (t) i will be distributed according to the true posterior p(T, π|x). If only a subset of possible theories and proofs are reachable from the initial theory, the MH samples will be distributed according to the true posterior conditioned on that subset. This may suffice for many applications, particularly if the theories in the subset have desirable properties such as better tractability. But the subset cannot be too small because then PWL would lose generality.</p>
<p>The function init proof in Algorithm 1 recursively calls init disproof. Due to space limitations, we refer the reader to our code for this function; it closely mirrors the structure of init proof. The purpose of init proof is to find some proof of a given higher-order formula, or return null if none exists. Its task is finding a satisfying abductive proof, which is easier than theorem proving, since it can create new axioms as needed. The returned proof need not be ''optimal'' because it serves as the initial state for MH, which will further refine the proof. The validity of the proofs is guaranteed by the fact that init proof only returns valid proofs and the MH proposals preserve validity. 2 swap randomly selects an element in its input list to swap with the first element. The probability of moving an element c to the front of the list is computed as follows: Recursively inspect the atoms in the formula f (c) and count the number of ''matching'' atoms: The atoms t(c) or c(t) is considered ''matching'' if it is provable in T . Next, count the number of ''mismatching'' axioms: for each atom t(c) in the formula f (c), an axiom t (c) is ''mismatching'' if t = t . And similarly for each atom c(t) in the formula f (c), an axiom c(t ) is ''mismatching'' if t = t . Let n be the number of ''matching'' atoms and m be the number of ''mismatching'' axioms, then the probability of moving c to the front of the list is proportional to exp{n − 2m}. This greatly increases the chance of finding a high-probability proof in the first iteration of the loop on line 31, and since this function is also used in an MH proposal, it dramatically improves the acceptance rate. This reduces the number of MH iterations needed to sufficiently mix the Markov chain.</p>
<p>Algorithm 1: Pseudocode for proof initialization. If any new axiom violates the deterministic constraints in Section 3.1.1, the function returns null.<br />
1 function init proof(formula A) 2 if A is a conjunction B 1 ∧ . . . ∧ B n 3 for i = 1 to n do 4 φ i = init proof(B i ) 5 return φ 1 . . . φ n ∧I B 1 ∧ . . . ∧ B n 6 else if A is a disjunction B 1 ∨ . . . ∨ B n 7 I = shuffle(1, . . . , n) 8 for i ∈ I do 9 φ i = init proof(B i ) 10 if φ i = null 11 return φ i ∨I B 1 ∨ . . . ∨ B n 12 else if A is a negation ¬B 13 return init disproof(B) 14 else if A is an implication B 1 → B 2 15 if using classical logic 16 I = shuffle(1,2) 17 for i ∈ I do 18 if i = 1 19 φ 1 = init disproof(B 1 ) 20 if φ 1 = null continue 21 return φ 1 Ax B 1 ¬E ⊥ ⊥E B 2 →I B 1 → B 2 22 else 23 φ 2 = init proof(B 2 ) 24 if φ 2 = null continue 25 return φ 2 →I B 1 → B 2φ c = init proof(f (c)) 33 if φ c = null 34 return φ c ∃I ∃x.f (x) 35 else if A is a universal quantification ∀x.f (x) 36 return Ax ∀x.f (x) 37 else if A is an equality B 1 = B 2 38 return Ax B 1 = B 2 39 else if A</p>
<p>Language Module</p>
<p>For the language module, PWM uses the probabilistic model of Saparov et al. (2017). The generative nature of their semantic parsing model allows it to fit seamlessly into PWM and PWL.</p>
<p>Probability</p>
<p>Proposal of selecting proposal</p>
<p>Select a grounded atomic axiom (e.g., square(c 1 )) and propose to replace it with an instantiation 1 N of a universal quantification (e.g., ∀x(rectangle(x) ∧ rhombus(x) → square(x))), where the antecedent conjuncts are selected uniformly at random from the other grounded atomic axioms for the constant c 1 : rectangle(c 1 ), rhombus(c 1 ), etc. The inverse of the above proposal: select an instantiation of a universal quantification and replace it 1 N with a grounded atomic axiom. Select an axiom that declares the size of a set (e.g., of the form size(us states) = 50), and propose 1 N to change the size of the set by sampling from the prior distribution, conditioned on the maximum and minimum consistent set size. Select a node from a proof tree of type ∨I, → I, or ∃I. 3 These nodes were created in Algorithm 1 on 1 N lines 7, 16, and 30, respectively, where for each node, a single premise was selected out of a number of possible premises. This proposal naturally follows from the desire to explore other selections by re-sampling the proof: it simply calls init proof again on the formula at this proof node. Merge: Select a ''mergeable'' event; that is, three constants
(c i , c j , c k ) such that arg1(c i ) = c j , α N
arg2(c i ) = c k , and t(c i ) for some constant t are axioms, and there also exist constants (c i , c j , c k ) such that i &gt; i, arg1(c i ) = c j , arg2(c i ) = c k , and t(c i ) are axioms. Next, propose to merge c i with c i by replacing all instances of c i with c i in the proof trees, c j with c j , and c k with c k . This proposal is not necessary in that these changes are reachable with other proposals, but those proposals may have low probability, and so this can help to more easily escape local maxima.</p>
<p>Split: The inverse of the above proposal.</p>
<p>β N Table 2: A list of the Metropolis-Hastings proposals implemented in PWL thus far. N , here, is a normalization term: N = |A| + |U | + |C| + |P | + α|M | + β|S| where: A is the set of grounded atomic axioms in T (e.g., square(c 1 )), U is the set of universally-quantified axioms that can be eliminated by the second proposal, C is the set of axioms that declare the size of a set (e.g., size(A) = 4), P is the set of nodes of type ∨I, → I, or ∃I 3 in the proofs π, M is the set of ''mergeable'' events (described above), and S is the set of ''splittable'' events. In our experiments, α = 2 and β = 0.001.</p>
<p>The logical forms in their model are distributed according to a semantic prior, which we replace with our distribution of logical forms conditioned on the theory p(π i |T ). Their parser is probabilistic and finds the k-best logical forms that maximize p(y i |x i , T ) for a given input sentence. Combined with our reasoning module's ability to compute the probability of a logical form, the parser can resolve ambiguous interpretations of sentences by exploiting acquired knowledge. We will demonstrate the utility of this property in resolving lexical ambiguity. However, the semantic grammar in Saparov et al. (2017) was designed for a DATALOG representation of logical forms. Thus, we designed and implemented a new grammar for our more domain-general formalism in higher-order logic. Though their model induces preterminal production rules from data (e.g., N → ''cat''), we must manually specify the nonterminal production rules (e.g., NP → ADJP NP). This allows 3 Also disproofs of conjunctions, if using classical logic. us to encode prior knowledge of the English language into PWM, dramatically improving its statistical efficiency and obviating the need for massive training sets to learn English syntax. It is nonetheless tedious to design these rules while maintaining domain-generality. Once specified, however, these rules can be re-used in new tasks and domains with minimal or no changes. We also improved their model to generalize over inflected forms of words. In the generative process, instead of generating sentence tokens directly (e.g., ''I am sleeping''), PWM generates word roots with flags indicating their inflection (e.g., ''I be[1ST,SG] sleep[PRS,PTCP]''). During parsing, this has the effect of performing morphological and semantic parsing jointly. We extracted the necessary comprehensive morphology information from Wiktionary (Wikimedia Foundation 2020).</p>
<p>We train this new grammar to learn the parameters that govern the conditional distributions and the preterminal production rules. To do so, we construct a small seed training set consisting of 55 labeled sentences, 47 nouns, 55 adjectives, and 20 verbs. 4 We wrote and labeled these sentences by hand, largely in the domain of astronomy, with the aim to cover a diverse range of English syntactic constructions. This small training set was sufficient thanks to the statistical efficiency of PWM.</p>
<p>While PWL uses the same parsing algorithm of Saparov et al. (2017), we provide an easier-to-understand presentation. Given an input sentence y i , the parser aims to find the logical form(s) x i and derivation trees t i that maximize the posterior probability p(x i , t i |y i , T ). This discrete optimization is performed using branch-and-bound (Land and Doig, 1960): The algorithm starts by considering the set of all derivation trees and partitions it into a number of subsets (the ''branch'' step). For each subset S, the parser computes an upper bound on the log probability of any derivation in S (the ''bound'' step). Having computed the bound for each subset, the parser puts them into a priority queue, prioritized by the bound. The parser then dequeues the subset with the highest bound and repeats this process, further subdividing this set, computing the bound for each subdivision, and adding them to the queue. Eventually, the parser will dequeue a subset containing a single derivation whose log probability is at least the highest priority in the queue. This derivation is optimal. The algorithm can be continued to obtain the top-k derivations/logical forms. Because this algorithm operates over sets of logical forms (where each set is possibly infinite), we implemented a data structure to sparsely represent such sets of higher-order formulas, as well as algorithms to perform set operations, such as intersection and subtraction.</p>
<p>Experiments</p>
<p>ProofWriter</p>
<p>To demonstrate our implementation as a proofof-concept, we evaluate it on two questionanswering tasks. The first is the ProofWriter dataset (Tafjord et al., 2021), which itself is based on the earlier RuleTaker dataset . To evaluate and demonstrate the out-of-domain language understanding and reasoning ability of PWL, we use the Birds-Electricity ''open-world'' 5 portion of the dataset, as the authors evaluated their method on this portion zero-shot, just as we do (i.e., the algorithm did not see any example from this portion during training). This portion of the data is subdivided into 6 sections, each with varying degrees of difficulty. An example from this dataset is shown in Figure 3. For each example, PWL reads the context and abduces a theory. Next, it parses the query sentence y n+1 into a logical form x n+1 and estimates its unnormalized probability:
p(x n+1 | x) ∝ p(x 1 , . . . , x n+1 ),(10)= T,π i proof of x i p(T ) n+1 i=1 p(π i | T ),(11)≈ T (t) ,π (t) i ∼T,π|x p(T (t) ) n+1 i=1 p(π (t) i | T (t) )
. (12) Here, x are the previously read logical forms (the context). Since the quantity in equation 11 is intractable to compute, PWL approximates it by sampling from the posterior T, π 1 , . . . , π n+1 | x 1 , . . . , x n+1 and summing over distinct samples. Although this approximation seems crude, the sum is dominated by a small number of the most probable theories and proofs, and MH is an effective way to find them, as we observe in experiments. MH is run for 400 iterations, and at every 100 th iteration, PWL re-initializes the Markov chain by performing 20 ''exploratory'' MH steps (i.e., consisting of only the third and fourth proposals in Table 2 and accepting every proposal). This re-initialization is analogous to a random restart and can help to escape from local maxima. However, it may be promising to explore other approaches to compute this quantity, such as Luo et al. (2020). Once PWL has computed this probability for the query sentence, it does the same for the negation of the sentence. These unnormalized probabilities are compared, and if they are within 2000 in log probability, PWL returns the label unknown. If the first probability is sufficiently larger than the second, PWL returns true, and otherwise, returns false. The parameters in the prior were set by hand initially by choosing values that we thought were reasonable (e.g., the average length of a natural deduction proof for a sentence containing a simple subject noun phrase, object noun phrase, and transitive verb is around 20 steps, which is why the Poisson parameter for the proof length is set to 20). The values were tweaked as necessary by running the algorithm on toy examples during debugging. Note that the sentences ''Bill is a bird'' and ''Bill is not a bird'' can still both be true if each ''Bill'' refers to distinct entities. To avoid this, we chose an extreme value of the prior parameter such that the log prior probability of a theory with two entities having the same name is 2000 less than that of a theory where the name is unique. It is for this reason 2000 was chosen as the threshold for determining whether a query is true/false vs unknown. This prior worked well enough in our experiments, but the goal is to have a single prior work well with any task, so further work to explore which priors work better across a wider variety of tasks is welcome. We evaluated PWL using both classical and intuitionistic logic, even though the ground truth labels in the dataset were generated using intuitionistic logic. Table 3 lists the zero-shot accuracy of PWL, comparing with baselines based on the T5 transformer (Raffel et al., 2020). We emphasize here that PWL is not perfectly comparable to the baseline, because they aim to demonstrate that their method can learn to reason. We instead aim to demonstrate that PWL's ability to parse and reason end-to-end generalizes to an out-of-domain question-answering task. The baseline is trained on other portions of the ProofWriter data, whereas PWL is trained only on its seed training set. PWL performed much better using intuitionistic logic than classical logic, as expected since the ground truth labels were generated using intuitionistic semantics. However, most real-world reasoning tasks would take the law of the excluded middle to be true, and classical logic would serve as a better default. Although the task is relatively simple, it nevertheless demonstrates the proof-of-concept and the promise of further research.</p>
<p>FictionalGeoQA</p>
<p>The sentences in the ProofWriter experiment are template-generated and have simple semantics. For the sake of evaluation more representative of real-world language, we introduce a new question-answering dataset called Fictional-GeoQA. 6 To create this dataset, we took questions from GeoQuery (Zelle and Mooney, 1996), and for each question, we wrote a paragraph context containing the information necessary to answer the question. We added distractor sentences to make the task more robust against heuristics. Whenever possible, the sentences in this paragraph were taken from Simple English Wikipedia. However, some facts, such as the lengths of rivers, are not expressed in sentences in Wikipedia (they typically appear in a table on the right side of the page), so we wrote those sentences by hand: We took questions from GEOQUERY that expressed the desired fact in interrogative form (e.g., ''What is the length of <river name>?'') and converted them into declarative form (e.g., ''The length of <river name> is <length>.''). The resulting dataset contains 600 examples, where 67.4% of the sentences are from Simple English Wikipedia, and 90% of the examples contain at least one sentence not from Wikipedia. We replaced all place names with fictional ones to remove any confounding effects from pretraining. To keep the focus of the evaluation on reasoning ability, we chose to restrict the complexity of the language. In particular, each sentence is independent and can be   understood in isolation (e.g., no cross-sentential anaphora). The sentences are more complex than those in ProofWriter, having more of the complexities of real language, such as synonymy, lexical ambiguity (e.g., what is the semantics of ''has'' in ''a state has city'' vs ''a state has area''; or whether ''largest state'' refers to area or population), and syntactic ambiguity. This increased difficulty is evident in the results. This dataset is meant to evaluate out-of-domain generalizability, so we do not provide a separate training set for fine-tuning. An example is shown in Figure 4.</p>
<p>We compare PWL (using classical logic) with a number of baselines: (1) UnifiedQA (Khashabi et al., 2020), a QA system based on large-scale neural language models, (2) Boxer (Bos, 2015), a wide-coverage semantic parser, combined with Vampire 4.5.1 (Kovács and Voronkov, 2013), a theorem prover for full first-order logic, (3) Boxer combined with E 2.6 (Schulz et al., 2019), another theorem prover for full first-order logic, (4) the language module of PWL combined with Vampire, and (5) the language module of PWL combined with E. The results are shown in Table 4, along with a breakdown across multiple subsets of the dataset. UnifiedQA performs relatively well but fares more poorly on questions with negation and subjective concept definitions (e.g., ''Every river longer than 500km is major. . . What are the major rivers?''). Humans are easily able to understand and utilize such definitions, and the ability to do so is instrumental in learning about new concepts or words in new domains. PWL is able to fare better than UnifiedQA in examples with lexical ambiguity, as a result of the language module's ability to exploit acquired knowledge to resolve ambiguities. We find that Boxer has significantly higher coverage than PWL (100% vs 79.8%) but much lower precision. For instance, Boxer uses the semantic representation in the Parallel Meaning Bank (Abzianidze et al., 2017) which has a simpler representation of superlatives, and is thus unable to capture the correct semantics of superlatives in examples of this dataset. We also find that for most examples, Boxer produces different semantics for the question vs. the context sentences, oftentimes predicting the incorrect semantic role for the interrogative words, which leads to the theorem provers being unable to find a proof for these extra semantic roles. We also experimented with replacing our reasoning module with a theorem prover and found that for almost all examples, the search of the theorem prover would explode combinatorially. This was due to the fact that our semantic representation relies heavily on sets, so a number of simple set theoretic axioms are required for the theorem provers, but this quickly causes the deduction problem to become undecideable. Our reasoning module instead performs abduction, and is able to create axioms to more quickly find an initial proof, and then refine that proof using MH. Despite our attempt to maximize the generalizability of the grammar in PWL, there are a number of linguistic phenomena that we did not yet implement, such as interrogative subordinate clauses, wh-movement, spelling or grammatical mistakes, and so forth, and this led to the lower coverage on this dataset. Work remains to be done to implement these missing production rules in order to further increase the coverage of the parser.</p>
<p>Conclusions and Future Work</p>
<p>We introduced PWM, a fully symbolic Bayesian model of semantic parsing and reasoning, which we hope serves as a compelling first step in a research program toward more domain-and task-general NLU. We derived PWL, an efficient inference algorithm that reads sentences by parsing and abducing updates to its latent world model that capture the semantics of those sentences, and empirically demonstrated its ability to generalize to two out-of-domain question-answering tasks. To do so, we created a new question-answering dataset, FictionalGeoQA, designed specifically to evaluate reasoning ability while capturing more of the complexities of real language and being robust against heuristic strategies. PWL is able to read and understand sentences with richer semantics, such as definitions of new concepts. In contrast with past deductive reasoning approaches, PWL performs abduction, which is computationally easier. The highly underspecified nature of the problem of abduction is alleviated by the probabilistic nature of PWL, as it gives a principled way to find the most probable theories. We present an inference strategy where Metropolis-Hastings (MH) is performed on each sentence, in sequence, where the previous sample of the theory and proofs provides a warm-start for inference of the next sentence, reducing the number of MH iterations.</p>
<p>There are many avenues for future work: A simple prior was used for proofs p(π i |T ), and an alternative is to use a compositional exchangeable prior such as adaptor grammars (Johnson et al., 2006).</p>
<p>The first MH proposal in Table 2 is simple but restrictive: The antecedent conjuncts and the consequent are restricted to be atomic. MH would be able to explore a much larger and semantically richer set of theories if the antecedent or consequent could contain more complex formulas, including quantified formulas. In addition, the inference algorithm sometimes becomes stuck in local maxima. One way to improve the efficiency of inference is to add a new MH proposal that specifically proposes to split or merge types. For example, if the theory has the axioms cat(c 1 ) and dog(c 1 ), this proposal would split c 1 into two concepts: cat(c 1 ) and dog(c 2 ). This kind of type-based Markov chain Monte Carlo is similar in principle to Liang et al. (2010).</p>
<p>As mentioned earlier, a model of context is necessary in the language module to properly handle cross-sentential anaphora and conversational contexts. Real language very rarely consists of sentences that are independent of context. There are also many research questions on the issue of scalability. Although PWL is able to scale to examples in FictionalGeoQA with more than 100 sentences, there are two main bottlenecks currently preventing it from scaling to significantly larger theories: (1) the maintenance of global consistency, and (2) the unfocused nature of the current MH proposals. When checking for consistency of a new axiom, rather than considering all other axioms/sets in the theory, it would be preferable to only consider the portion of the theory relevant to the new axiom. Additionally, the current MH proposals do not take into account the goal of reasoning. For example, if the current task is to answer a question about geography, then MH proposals for proofs unrelated to geography are wasteful, and would increase the number of MH steps needed. A more clever goal-aware approach for selecting proofs to mutate would help to alleviate this problem and improve scalability. PWM provides a path to incorporate information from additional modalities in principled fashion: for example by adding a generative model of images, which would serve as a separate ''vision module.'' In addition, even though PWL is fully-symbolic, non-symbolic methods could be used for expressive prior/proposal distributions or approximate inference. There are many fascinating research paths to pursue from here.</p>
<p>Figure 2 :
2An example of a proof of ¬(A ∧ ¬A).</p>
<p>if A is an existential quantification ∃x.f (x) 29 let C be the set of known constants, numbers, and strings in T , and the new constant c * 30 I = swap 2 (shuffle(C)) 31 for c ∈ I do 32</p>
<p>superlative The subset of the dataset with examples that require reasoning over superlatives, i.e., ''longest river.'' subjective concept def. Subset with definitions of ''subjective'' concepts, i.e., ''Every river longer than 500 km is major.'' objective concept def. Subset with definitions of ''objective'' concepts, i.e., the population of a location is the number of people living there. lexical ambiguity Subset with lexical ambiguity, i.e., ''has'' means different things in ''a state has a city named'' vs ''a state has an area of...'' negation Subset with examples that require reasoning with classical negation (negation-as-failure is insufficient). large context Subset of examples where there are at least 100 sentences in the context. arithmetic Subset with examples that require simple arithmetic. counting Subset with examples that require counting. n subset(s) Examples that belong to exactly n of the above subsets (no example is a member of more than 4 subsets).</p>
<p>Figure 4 :
4An example from FictionalGeoQA, a new fictional geography question-answering dataset that we created to evaluate reasoning in natural language understanding.</p>
<p>Table 1 :
1Design choices in the representation of the meaning of ''Alex wrote a book.''</p>
<p>is an atom (e.g. book(great gatsby))40 </p>
<p>return 
Ax 
A </p>
<p>41 </p>
<p>else return null </p>
<p>Table 3 :
3Zero-shot accuracy of PWL and baselines on the ProofWriter dataset.</p>
<p>Table 4 :
4Zero-shot accuracy of PWL and baselines on the FictionalGeoQA dataset.
Some deduction rules require additional parameters, and we refer the reader to our code for details on how these parameters are sampled.
The grammar, morphology data, code, as well as the seed training set are available in our Github repository.
The dataset comes in two flavors: one that makes the closed-world assumption, and one that does not.
Available at github.com/asaparov/fictionalgeoqa.
AcknowledgmentsWe thank the anonymous reviewers and the Action Editor for their invaluable feedback. We also thank Peter Clark, William W. Cohen, Rik van Noord, Johan Bos, and Emmanouil A. Platanios for their insightful and helpful discussion. This research was funded in part by the Air Force Office of Scientific Research under AFOSR grant FA95502010118.
The parallel meaning bank: Towards a multilingual corpus of translations annotated with compositional meaning representations. Lasha Abzianidze, Johannes Bjerva, Kilian Evang, Hessel Haagsma, Rik Van Noord, Pierre Ludmann, Duc-Duy Nguyen, Johan Bos, 10.18653/v1/E17-2039Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. the 15th Conference of the European Chapter of the Association for Computational LinguisticsSpainShort Papers2017ValenciaAssociation for Computational LinguisticsLasha Abzianidze, Johannes Bjerva, Kilian Evang, Hessel Haagsma, Rik van Noord, Pierre Ludmann, Duc-Duy Nguyen, and Johan Bos. 2017. The parallel meaning bank: Towards a multilingual corpus of translations annotated with compositional meaning representations. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017, Valen- cia, Spain, April 3-7, 2017, Volume 2: Short Papers, pages 242-247. Association for Com- putational Linguistics. https://doi.org /10.18653/v1/E17-2039</p>
<p>Exchangeability and related topics. David J Aldous, 10.1007/BFb0099421Lecture Notes in Mathematics. Berlin HeidelbergSpringerDavid J. Aldous. 1985. Exchangeability and related topics. In Lecture Notes in Mathemat- ics, pages 1-198, Springer Berlin Heidelberg. https://doi.org/10.1007/BFb0099421</p>
<p>Complex query answering with neural link predictors. Erik Arakelyan, Daniel Daza, Pasquale Minervini, Michael Cochez, International Conference on Learning Representations. Erik Arakelyan, Daniel Daza, Pasquale Minervini, and Michael Cochez. 2021. Com- plex query answering with neural link predic- tors. In International Conference on Learning Representations.</p>
<p>Structure learning of probabilistic logic programs by searching the clause space. Theory and Practice of Logic Programming. Elena Bellodi, Fabrizio Riguzzi, 10.1017/S147106841300068915Elena Bellodi and Fabrizio Riguzzi. 2015. Structure learning of probabilistic logic programs by searching the clause space. Theory and Practice of Logic Program- ming, 15(2):169-212. https://doi.org /10.1017/S1471068413000689</p>
<p>Climbing towards NLU: On meaning, form, and understanding in the age of data. Emily M Bender, Alexander Koller, 10.18653/v1/2020.acl-main.463Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online. the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, OnlineAssociation for Computational LinguisticsEmily M. Bender and Alexander Koller. 2020. Climbing towards NLU: On meaning, form, and understanding in the age of data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguis- tics, ACL 2020, Online, July 5-10, 2020, pages 5185-5198. Association for Computa- tional Linguistics. https://doi.org/10 .18653/v1/2020.acl-main.463</p>
<p>Abductive commonsense reasoning. Chandra Bhagavatula, Chaitanya Ronan Le Bras, Keisuke Malaviya, Ari Sakaguchi, Hannah Holtzman, Doug Rashkin, Wen-Tau Downey, Yejin Yih, Choi, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen-tau Yih, and Yejin Choi. 2020. Abductive commonsense reasoning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.</p>
<p>Open-domain semantic parsing with boxer. Johan Bos, Proceedings of the 20th Nordic Conference of Computational Linguistics, NODALIDA 2015, Institute of the Lithuanian Language. the 20th Nordic Conference of Computational Linguistics, NODALIDA 2015, Institute of the Lithuanian LanguageVilnius, LithuaniaLinköping University Electronic Press / Association for Computational Linguistics109of Linköping Electronic Conference ProceedingsJohan Bos. 2015. Open-domain semantic parsing with boxer. In Proceedings of the 20th Nordic Conference of Computational Linguistics, NODALIDA 2015, Institute of the Lithuanian Language, Vilnius, Lithuania, May 11-13, 2015, volume 109 of Linköping Electronic Confer- ence Proceedings, pages 301-304. Linköping University Electronic Press / Association for Computational Linguistics.</p>
<p>. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskeverand Dario Amodei. 2020. Language models are few-shot learners. CoRR, abs/2005.14165v4Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. CoRR, abs/2005.14165v4.</p>
<p>A Bayesian model of plan recognition. Eugene Charniak, Robert P Goldman, Artificial Intelligence. 641Eugene Charniak and Robert P. Goldman. 1993. A Bayesian model of plan recognition. Artificial Intelligence, 64(1):53-79.</p>
<p>A formulation of the simple theory of types. Alonzo Church, Journal of Symbolic Logic. 52Alonzo Church. 1940. A formulation of the simple theory of types. Journal of Symbolic Logic, 5(2):56-68.</p>
<p>Transformers as soft reasoners over language. Peter Clark, Oyvind Tafjord, Kyle Richardson, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. the Twenty-Ninth International Joint Conference on Artificial Intelligence2020Peter Clark, Oyvind Tafjord, and Kyle Richardson. 2020. Transformers as soft reasoners over lan- guage. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3882-3890. ijcai.org.</p>
<p>Probabilistic type theory and natural language semantics. Robin Cooper, Simon Dobnik, Shalom Lappin, Staffan Larsson, 10.33011/lilt.v10i.1357Linguistic Issues in Language Technology. CSLI Publications10Robin Cooper, Simon Dobnik, Shalom Lappin, and Staffan Larsson. 2015. Probabilistic type theory and natural language seman- tics. In Linguistic Issues in Language Technology, Volume 10, 2015. CSLI Pub- lications. https://doi.org/10.33011 /lilt.v10i.1357</p>
<p>Learning programs by learning from failures. Andrew Cropper, Rolf Morel, 10.1007/s10994-020-05934-zMachine Learning. 110Andrew Cropper and Rolf Morel. 2021. Learning programs by learning from failures. Machine Learning, 110(4):801-856. https://doi .org/10.1007/s10994-020-05934-z</p>
<p>Parameter estimation in stochastic logic programs. James Cussens, 10.1023/A:1010924021315Machine Learning. 44James Cussens. 2001. Parameter estimation in stochastic logic programs. Machine Learning, 44(3):245-271. https://doi.org/10.1023 /A:1010924021315</p>
<p>BERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for lan- guage understanding. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171-4186. Association for Computational Linguistics.</p>
<p>Introduction to Montague Semantics. D R Dowty, 10.1007/978-94-009-9065-4_1Studies in Linguistics and Philosophy. 11Springer1st edD. R. Dowty. 1981. Introduction to Montague Semantics, 1st ed. Studies in Linguistics and Philosophy, 11. Springer Netherlands, Dordrecht. https://doi.org/10.1007 /978-94-009-9065-4_1</p>
<p>From micro-worlds to knowledge representation: AI at an impasse. H L Dreyfus, Readings in Knowledge Representation. R. J. Brachman and H. J. LevesqueLos Altos, CAKaufmannH. L. Dreyfus. 1985. From micro-worlds to knowl- edge representation: AI at an impasse. In R. J. Brachman and H. J. Levesque, editors, Readings in Knowledge Representation, pages 71-93. Kaufmann, Los Altos, CA.</p>
<p>To test machine comprehension, start by defining comprehension. Jesse Dunietz, Gregory Burnham, Akash Bharadwaj, Owen Rambow, Jennifer Chu-Carroll, David A Ferrucci, 10.18653/v1/2020.acl-main.701Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline2020Association for Computational LinguisticsJesse Dunietz, Gregory Burnham, Akash Bharadwaj, Owen Rambow, Jennifer Chu- Carroll, and David A. Ferrucci. 2020. To test machine comprehension, start by defining com- prehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 7839-7859. Association for Computa- tional Linguistics. https://doi.org/10 .18653/v1/2020.acl-main.701</p>
<p>A Bayesian analysis of some nonparametric problems. S Thomas, Ferguson, 10.1214/aos/1176342360The Annals of Statistics. 12Thomas S. Ferguson. 1973. A Bayesian analysis of some nonparametric problems. The Annals of Statistics, 1(2):209-230. https://doi .org/10.1214/aos/1176342360.</p>
<p>Tackling benchmark problems of commonsense reasoning. Ulrich Furbach, Andrew S Gordon, Claudia Schon, Proceedings of the Workshop on Bridging the Gap between Human and Automated Reasoning -A workshop of the 25th International Conference on Automated Deduction (CADE-25). the Workshop on Bridging the Gap between Human and Automated Reasoning -A workshop of the 25th International Conference on Automated Deduction (CADE-25)Berlin, Germany1412CEUR-WS.orgCEUR Workshop ProceedingsUlrich Furbach, Andrew S. Gordon, and Claudia Schon. 2015. Tackling benchmark problems of commonsense reasoning. In Proceedings of the Workshop on Bridging the Gap between Human and Automated Reasoning -A work- shop of the 25th International Conference on Automated Deduction (CADE-25), Berlin, Germany, August 1, 2015, volume 1412 of CEUR Workshop Proceedings, pages 47-59. CEUR-WS.org.</p>
<p>On making reading comprehension more comprehensive. Matt Gardner, Jonathan Berant, Hannaneh Hajishirzi, Alon Talmor, Sewon Min, 10.18653/v1/D19-5815Proceedings of the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019. the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019Hong Kong, ChinaAssociation for Computational LinguisticsMatt Gardner, Jonathan Berant, Hannaneh Hajishirzi, Alon Talmor, and Sewon Min. 2019. On making reading comprehension more comprehensive. In Proceedings of the 2nd Work- shop on Machine Reading for Question An- swering, MRQA@EMNLP 2019, Hong Kong, China, November 4, 2019, pages 105-112. Association for Computational Linguistics. https://doi.org/10.18653/v1/D19 -5815</p>
<p>Untersuchungenüber das logische schließen i. G Gentzen, 10.1007/BF01201363Mathematische Zeitschrift. 39G. Gentzen. 1935. Untersuchungenüber das logische schließen i. Mathematische Zeitschrift, 39:176-210. https://doi.org/10.1007 /BF01201363</p>
<p>The Collected Papers of Gerhard Gentzen. G Gentzen, 10.1016/S0049-237X(08)70822-XM. E. SzaboNorth-Holland, AmsterdamInvestigations into Logical DeductionG. Gentzen. 1969. Investigations into Logical De- duction. In M. E. Szabo, editor, The Collected Papers of Gerhard Gentzen, pages 68-213. North-Holland, Amsterdam. https://doi .org/10.1016/S0049-237X(08)70822-X</p>
<p>Language and Logics: An Introduction to the Logical Foundations of Language. Howard Gregory, Edinburgh University PressHoward Gregory. 2015. Language and Logics: An Introduction to the Logical Foundations of Language. Edinburgh University Press.</p>
<p>Monte Carlo sampling methods using markov chains and their applications. W K Hastings, 10.1093/biomet/57.1.97Biometrika. 571W. K. Hastings. 1970. Monte Carlo sampling methods using markov chains and their appli- cations. Biometrika, 57(1):97-109. https:// doi.org/10.1093/biomet/57.1.97</p>
<p>Completeness in the theory of types. Leon Henkin, 10.2307/2266967Journal of Symbolic Logic. 152Leon Henkin. 1950. Completeness in the theory of types. Journal of Symbolic Logic, 15(2):81-91. https://doi.org/10.2307/2266967</p>
<p>Abduction in Natural Language Understanding, chapter 32. R Jerry, Hobbs, John Wiley &amp; Sons, LtdJerry R. Hobbs. 2006. Abduction in Natural Lan- guage Understanding, chapter 32. John Wiley &amp; Sons, Ltd.</p>
<p>Interpretation as abduction. Jerry R Hobbs, Mark E Stickel, Douglas E Appelt, Paul A Martin, 10.1016/0004-3702(93)90015-4Artificial Intelligence. 631-2Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt, and Paul A. Martin. 1993. Inter- pretation as abduction. Artificial Intelligence, 63(1-2):69-142. https://doi.org/10 .1016/0004-3702(93)90015-4</p>
<p>Knowledge graphs. Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia Amato, Gerard De Melo, Claudio Gutiérrez, Sabrina Kirrane, José Emilio Labra, Roberto Gayo, Sebastian Navigli, Axel-Cyrille Ngonga Neumaier, Axel Ngomo, Polleres, M Sabbir, Anisa Rashid, Lukas Rula, Juan F Schmelzeisen, Steffen Sequeda, Antoine Staab, Zimmermann, 10.1145/344777271:1-71:37ACM Computing Surveys. 544Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia d'Amato, Gerard de Melo, Claudio Gutiérrez, Sabrina Kirrane, José Emilio Labra Gayo, Roberto Navigli, Sebastian Neumaier, Axel-Cyrille Ngonga Ngomo, Axel Polleres, Sabbir M. Rashid, Anisa Rula, Lukas Schmelzeisen, Juan F. Sequeda, Steffen Staab, and Antoine Zimmermann. 2021. Knowl- edge graphs. ACM Computing Surveys, 54(4):71:1-71:37. https://doi.org/10 .1145/3447772</p>
<p>Scalable rule learning in probabilistic knowledge bases. Arcchit Jain, Tal Friedman, Ondrej Kuzelka, Guy Van Den, Luc De Broeck, Raedt, 1st Conference on Automated Knowledge Base Construction, AKBC 2019. Amherst, MA, USAArcchit Jain, Tal Friedman, Ondrej Kuzelka, Guy Van den Broeck, and Luc De Raedt. 2019. Scalable rule learning in probabilistic knowl- edge bases. In 1st Conference on Automated Knowledge Base Construction, AKBC 2019, Amherst, MA, USA, May 20-22, 2019.</p>
<p>Adaptor grammars: A framework for specifying compositional nonparametric bayesian models. Mark Johnson, Thomas L Griffiths, Sharon Goldwater, Proceedings of the Twentieth Annual Conference on Neural Information Processing Systems. the Twentieth Annual Conference on Neural Information Processing SystemsVancouver, British Columbia, CanadaMIT Press19Advances in Neural Information Processing SystemsMark Johnson, Thomas L. Griffiths, and Sharon Goldwater. 2006. Adaptor grammars: A frame- work for specifying compositional nonparam- etric bayesian models. In Advances in Neural Information Processing Systems 19, Proceed- ings of the Twentieth Annual Conference on Neural Information Processing Systems, Vancouver, British Columbia, Canada, De- cember 4-7, 2006, pages 641-648. MIT Press.</p>
<p>Unifiedqa: Crossing format boundaries with a single QA system. Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, Hannaneh Hajishirzi, 10.18653/v1/2020.findings-emnlp.171Findings of the Association for Computational Linguistics: EMNLP 2020. Trevor Cohn, Yulan He, and Yang LiuAssociation for Computational LinguisticsEMNLP 2020 of Findings of ACLDaniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh Hajishirzi. 2020. Unifiedqa: Crossing format boundaries with a single QA system. Trevor Cohn, Yulan He, and Yang Liu, editors, In Findings of the Association for Com- putational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 of Findings of ACL, pages 1896-1907. Association for Computational Linguistics. https://doi.org/10.18653/v1/2020 .findings-emnlp.171</p>
<ol>
<li>40 years of cognitive architectures: Core cognitive abilities and practical applications. Iuliia Kotseruba, John K Tsotsos, 10.1007/s10462-018-9646-yArtificial Intelligence Review. 531Iuliia Kotseruba and John K. Tsotsos. 2020. 40 years of cognitive architectures: Core cognitive abilities and practical applications. Artificial Intelligence Review, 53(1):17-94. https://doi.org/10.1007/s10462-018 -018-9646-y</li>
</ol>
<p>First-order theorem proving and vampire. Laura Kovács, Andrei Voronkov, Computer Aided Verification -25th International Conference, CAV 2013. Saint Petersburg, RussiaSpringer8044ProceedingsLaura Kovács and Andrei Voronkov. 2013. First-order theorem proving and vampire. In Computer Aided Verification -25th Interna- tional Conference, CAV 2013, Saint Petersburg, Russia, July 13-19, 2013. Proceedings, volume 8044 of Lecture Notes in Computer Science, pages 1-35. Springer.</p>
<p>SOAR: An architecture for general intelligence. John E Laird, Allen Newell, Paul S Rosenbloom, Artificial Intelligence. 331John E. Laird, Allen Newell, and Paul S. Rosenbloom. 1987. SOAR: An architecture for general intelligence. Artificial Intelligence, 33(1):1-64.</p>
<p>Building machines that learn and think like people. CoRR, abs/1604.00289v3. M Brenden, Lake, D Tomer, Joshua B Ullman, Samuel J Tenenbaum, Gershman, 10.1016/0004-3702(87)90050-6Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. 2016. Building machines that learn and think like peo- ple. CoRR, abs/1604.00289v3. https://doi .org/10.1016/0004-3702(87)90050-6</p>
<p>An automatic method of solving discrete programming problems. A H Land, A G Doig, 10.2307/1910129Econometrica. 283497A. H. Land and A. G. Doig. 1960. An automatic method of solving discrete programming prob- lems. Econometrica, 28(3):497. https:// doi.org/10.2307/1910129</p>
<p>Type-based MCMC. Percy Liang, Michael I Jordan, Dan Klein, Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings. Los Angeles, California, USAAssociation for Computational LinguisticsPercy Liang, Michael I. Jordan, and Dan Klein. 2010. Type-based MCMC. In Human Lan- guage Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 2-4, 2010, Los Angeles, California, USA, pages 573-581. Association for Computational Linguistics.</p>
<p>How can we accelerate progress towards human-like linguistic generalization?. Tal Linzen, 10.18653/v1/2020.acl-main.465Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online. the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, OnlineAssociation for Computational LinguisticsTal Linzen. 2020. How can we accelerate progress towards human-like linguistic generalization? In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, ACL 2020, Online, July 5-10, 2020, pages 5210-5217. Association for Computa- tional Linguistics. https://doi.org/10 .18653/v1/2020.acl-main.465</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, RoBERTa: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692v1. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A robustly op- timized BERT pretraining approach. CoRR, abs/1907.11692v1.</p>
<p>SUMO: Unbiased estimation of log marginal probability for latent variable models. Yucen Luo, Alex Beatson, Mohammad Norouzi, Jun Zhu, David Duvenaud, Ryan P Adams, Ricky T Q Chen, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020OpenReview.netYucen Luo, Alex Beatson, Mohammad Norouzi, Jun Zhu, David Duvenaud, Ryan P. Adams, and Ricky T. Q. Chen. 2020. SUMO: Unbiased estimation of log marginal probability for latent variable models. In 8th International Confer- ence on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>. Tom M Mitchell, William W Cohen, Estevam R HruschkaJr, P Partha, Bo Talukdar, Justin Yang, Andrew Betteridge, Carlson, Matt Bhavana Dalvi Mishra, Bryan Gardner, Jayant Kisiel, Ni Krishnamurthy, Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil A. Platanios, Alan Ritter, Mehdi Samadi, Burr SettlesRichard CTom M. Mitchell, William W. Cohen, Estevam R. Hruschka Jr., Partha P. Talukdar, Bo Yang, Justin Betteridge, Andrew Carlson, Bhavana Dalvi Mishra, Matt Gardner, Bryan Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil A. Platanios, Alan Ritter, Mehdi Samadi, Burr Settles, Richard C.</p>
<p>Never-ending learning. Derry Wang, Abhinav Wijaya, Xinlei Gupta, Abulhair Chen, Malcolm Saparov, Joel Greaves, Welling, 10.1145/3191513Communications of ACM. 615Wang, Derry Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm Greaves, and Joel Welling. 2018. Never-ending learn- ing. Communications of ACM, 61(5):103-115. https://doi.org/10.1145/3191513</p>
<p>Inductive logic programming. Stephen Muggleton, 10.1007/BF03037089New Generation Computing. 84Stephen Muggleton. 1991. Inductive logic programming. New Generation Computing, 8(4):295-318. https://doi.org/10.1007 /BF03037089</p>
<p>Stochastic logic programs. Stephen Muggleton, Advances in Inductive Logic Programming. Stephen Muggleton. 1996. Stochastic logic programs. In Advances in Inductive Logic Programming, pages 254-264.</p>
<p>Computer science as empirical inquiry: Symbols and search. Allen Newell, Herbert A Simon, 10.1145/360018.360022Commun. ACM. 193Allen Newell and Herbert A. Simon. 1976. Com- puter science as empirical inquiry: Symbols and search. Commun. ACM, 19(3):113-126. https://doi.org/10.1145/360018 .360022</p>
<p>Learning and inference in tractable probabilistic knowledge bases. Mathias Niepert, Pedro M Domingos, Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence, UAI 2015. the Thirty-First Conference on Uncertainty in Artificial Intelligence, UAI 2015Amsterdam, The NetherlandsAUAI PressMathias Niepert and Pedro M. Domingos. 2015. Learning and inference in tractable probabilis- tic knowledge bases. In Proceedings of the Thirty-First Conference on Uncertainty in Arti- ficial Intelligence, UAI 2015, July 12-16, 2015, Amsterdam, The Netherlands, pages 632-641. AUAI Press.</p>
<p>Towards distributed MCMC inference in probabilistic knowledge bases. Mathias Niepert, Christian Meilicke, Heiner Stuckenschmidt, AKBC- WEKEX@NAACL-HLT 2012Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction. the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge ExtractionMontrèal, CanadaAssociation for Computational LinguisticsMathias Niepert, Christian Meilicke, and Heiner Stuckenschmidt. 2012. Towards distributed MCMC inference in probabilistic knowledge bases. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, AKBC- WEKEX@NAACL-HLT 2012, Montrèal, Canada, June 7-8, 2012, pages 1-6. Association for Computational Linguistics.</p>
<p>Events in the Semantics of English. Terence Parsons, MIT PressCambridge, MATerence Parsons. 1990. Events in the Semantics of English. MIT Press, Cambridge, MA.</p>
<p>Natural deduction. Lecture notes in 15-815 Automated Theorem Proving. Frank Pfenning, Frank Pfenning. 2004. Natural deduction. Lecture notes in 15-815 Automated Theorem Proving.</p>
<p>. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, MichaelColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Yanqi Matena, Wei Zhou, Peter J Li, Liu, Journal of Machine Learning Research. 2167Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former. Journal of Machine Learning Research, 21:140:1-140:67.</p>
<p>Query2box: Reasoning over knowledge graphs in vector space using box embeddings. Weihua Hongyu Ren, Jure Hu, Leskovec, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020OpenReview.netHongyu Ren, Weihua Hu, and Jure Leskovec. 2020. Query2box: Reasoning over knowledge graphs in vector space using box embeddings. In 8th International Conference on Learn- ing Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.</p>
<p>. P Christian, George Robert, Casella, 10.1007/978-1-4757-4145-2Monte Carlo Statistical Methods. Springer Texts in Statistics. SpringerChristian P. Robert and George Casella. 2004. Monte Carlo Statistical Methods. Springer Texts in Statistics, Springer. https://doi .org/10.1007/978-1-4757-4145-2</p>
<p>End-to-end differentiable proving. Tim Rocktäschel, Sebastian Riedel, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Long Beach, CA, USATim Rocktäschel and Sebastian Riedel. 2017. End-to-end differentiable proving. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Informa- tion Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 3788-3800.</p>
<p>Artificial Intelligence -A Modern Approach, Third International Edition. J Stuart, Peter Russell, Norvig, Pearson EducationStuart J. Russell and Peter Norvig. 2010. Artifi- cial Intelligence -A Modern Approach, Third International Edition. Pearson Education.</p>
<p>Prover: Proof generation for interpretable reasoning over rules. Swarnadeep Saha, Sayan Ghosh, Shashank Srivastava, Mohit Bansal, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingOnlineAssociation for Computational Linguistics2020Swarnadeep Saha, Sayan Ghosh, Shashank Srivastava, and Mohit Bansal. 2020. Prover: Proof generation for interpretable reasoning over rules. In Proceedings of the 2020 Con- ference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 122-136. Asso- ciation for Computational Linguistics.</p>
<p>A probabilistic generative grammar for semantic parsing. Abulhair Saparov, Vijay A Saraswat, Tom M Mitchell, 10.18653/v1/K17-1026Proceedings of the 21st Conference on Computational Natural Language Learning. the 21st Conference on Computational Natural Language LearningVancouver, CanadaAssociation for Computational LinguisticsAbulhair Saparov, Vijay A. Saraswat, and Tom M. Mitchell. 2017. A probabilistic generative grammar for semantic parsing. In Proceed- ings of the 21st Conference on Computa- tional Natural Language Learning (CoNLL 2017), Vancouver, Canada, August 3-4, 2017, pages 248-259. Association for Computational Linguistics. https://doi.org/10.18653 /v1/K17-1026</p>
<p>Generative modeling with failure in PRISM. Taisuke Sato, Yoshitaka Kameya, Neng-Fa Zhou, IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence. Edinburgh, Scotland, UKProfessional Book CenterTaisuke Sato, Yoshitaka Kameya, and Neng-Fa Zhou. 2005. Generative modeling with fail- ure in PRISM. In IJCAI-05, Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence, Edinburgh, Scotland, UK, July 30 -August 5, 2005, pages 847-852. Professional Book Center,</p>
<p>Faster, higher, stronger: E 2.3. Stephan Schulz, Simon Cruanes, Petar Vukmirovic, 10.1007/978-3-030-29436-6_29Automated Deduction -CADE 27 -27th International Conference on Automated Deduction. Natal, BrazilSpringer11716ProceedingsStephan Schulz, Simon Cruanes, and Petar Vukmirovic. 2019. Faster, higher, stronger: E 2.3. In Automated Deduction -CADE 27 - 27th International Conference on Automated Deduction, Natal, Brazil, August 27-30, 2019, Proceedings, volume 11716 of Lecture Notes in Computer Science, pages 495-507. Springer. https://doi.org/10.1007/978-3-030 -29436-6 29</p>
<p>. Haitian Sun, Andrew O Arnold, Tania Bedrax-Weiss, Fernando Pereira, William W , Haitian Sun, Andrew O. Arnold, Tania Bedrax- Weiss, Fernando Pereira, and William W.</p>
<p>Faithful embeddings for knowledge base queries. Cohen, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. NeurIPSvirtualCohen. 2020. Faithful embeddings for knowl- edge base queries. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.</p>
<p>Proofwriter: Generating implications, proofs, and abductive statements over natural language. Oyvind Tafjord, Bhavana Dalvi, Peter Clark, 10.18653/v1/2021.findings-acl.317Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021. Association for Computational LinguisticsOyvind Tafjord, Bhavana Dalvi, and Peter Clark. 2021. Proofwriter: Generating implications, proofs, and abductive statements over natu- ral language. In Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021, vol- ume ACL/IJCNLP 2021 of Findings of ACL, pages 3621-3634. Association for Computa- tional Linguistics. https://doi.org/10 .18653/v1/2021.findings-acl.317</p>
<p>Language (re)modelling: Towards embodied language understanding. Ronen Tamari, Chen Shani, Tom Hope, R L Miriam, Omri Petruck, Dafna Abend, Shahaf, 10.18653/v1/2020.acl-main.559Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online. the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, OnlineAssociation for Computational LinguisticsRonen Tamari, Chen Shani, Tom Hope, Miriam R. L. Petruck, Omri Abend, and Dafna Shahaf. 2020. Language (re)modelling: To- wards embodied language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguis- tics, ACL 2020, Online, July 5-10, 2020, pages 6268-6281. Association for Computa- tional Linguistics. https://doi.org/10 .18653/v1/2020.acl-main.559</p>
<p>Wikimedia Foundation. 2020. Wiktionary data dumps. Wikimedia Foundation. 2020. Wiktionary data dumps.</p>
<p>Xlnet: Generalized autoregressive pretraining for language understanding. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G Carbonell, Ruslan Salakhutdinov, V Quoc, Le, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. NeurIPS; Vancouver, BC, CanadaZhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. Xlnet: Generalized autoregres- sive pretraining for language understanding. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural In- formation Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 5754-5764.</p>
<p>CLEVRER: Collision events for video representation and reasoning. Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, Joshua B Tenenbaum, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B. Tenenbaum. 2020. CLEVRER: Collision events for video representation and reasoning. In 8th International Conference on Learn- ing Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.</p>
<p>Learning to parse database queries using inductive logic programming. M John, Raymond J Zelle, Mooney, Proceedings of the Thirteenth National Conference on Artificial Intelligence and Eighth Innovative Applications of Artificial Intelligence Conference, AAAI 96, IAAI 96. the Thirteenth National Conference on Artificial Intelligence and Eighth Innovative Applications of Artificial Intelligence Conference, AAAI 96, IAAI 96Portland, Oregon, USAAAAI Press / The MIT Press2John M. Zelle and Raymond J. Mooney. 1996. Learning to parse database queries using induc- tive logic programming. In Proceedings of the Thirteenth National Conference on Artificial Intelligence and Eighth Innovative Applica- tions of Artificial Intelligence Conference, AAAI 96, IAAI 96, Portland, Oregon, USA, August 4-8, 1996, Volume 2, pages 1050-1055. AAAI Press / The MIT Press.</p>            </div>
        </div>

    </div>
</body>
</html>