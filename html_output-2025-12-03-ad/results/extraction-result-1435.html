<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1435 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1435</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1435</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-ae6a4cd221684be6ca3082b6f526a7901281490b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ae6a4cd221684be6ca3082b6f526a7901281490b" target="_blank">Emergent autonomous scientific research capabilities of large language models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper presents an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments and showcases the Agent's scientific research capabilities with three distinct examples.</p>
                <p><strong>Paper Abstract:</strong> Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1435.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1435.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based Intelligent Agent (IA) system</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-module intelligent agent that composes GPT-3.5/GPT-4 LLMs with web/documentation search, a code-execution sandbox, and automation APIs to autonomously design, plan, and execute chemical experiments (synthesis planning, liquid-handler protocol generation, and multi-instrument experiment orchestration).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Intelligent Agent (Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A modular system driven by a Planner LLM coordinating components: Web searcher (Google API + BROWSE), Docs searcher (vectorized hardware API docs via ada embeddings), Code execution (isolated Docker container), and Automation (hardware/cloud-lab executors). The Planner issues actions (GOOGLE, DOCUMENTATION, PYTHON, EXPERIMENT) and uses GPT-3.5/GPT-4 for browsing, planning, and synthesis of protocols; the system executes code on a sandbox or runs hardware protocols on a liquid handler and heater-shaker and integrates analytical outputs (UV-Vis, GC-MS).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry (experimental synthetic chemistry / automated experimentation)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>The Agent autonomously searched literature and documentation, planned reagent stoichiometry and reaction conditions, generated runnable automation code, corrected its own code after runtime errors, and executed physical experiments on a liquid handler (including heater-shaker) to perform Suzuki and Sonogashira cross-coupling reactions; post-reaction GC-MS analysis indicated formation of the target products. Additional demonstrations included synthesis planning for ibuprofen and aspirin (executed planning and stoichiometry calculations) and a cloud-lab-correctable aspartame synthesis (initially incorrect but amendable). The Agent also performed UV-Vis data analysis and mechanistic computational exercises (e.g., mechanistic study of Suzuki reaction) and proposed a novel anticancer drug candidate (design step performed but synthesis not executed).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper does not apply explicit labels such as 'incremental', 'transformational', 'breakthrough', or 'paradigm-shifting' to the discoveries; instead it frames results as demonstrating 'emergent autonomous scientific research capabilities' and 'exceptional reasoning and experimental design capabilities'. No formal categorization of discovery novelty level is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation combined computational and experimental checks: (1) Code-level verification by executing generated Python in an isolated Docker container and inspecting runtime outputs/tracebacks (used to detect missing packages and logical errors); (2) Documentation cross-checks using Docs searcher and web search to verify reagent choices and hardware API usage; (3) Instrument-level validation by running generated protocols on a liquid handler/heater-shaker and collecting analytical results (UV-Vis arrays and GC-MS of reaction mixtures); (4) Outcome assessment by comparing analytical outputs to expected signals/products (GC-MS detection of target cross-coupling products; UV-Vis peak analysis to solve color identification task); (5) Safety behavior evaluation via a dual-use test set of 11 controlled or hazardous compounds, tracking whether the Agent produced synthesis plans (reported as counts/percentages). No formal statistical benchmarks (ROC/AUC etc.) or yield percentages for synthetic reactions are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental validation: physical execution of protocols on robotic liquid-handler and heater-shaker with subsequent GC-MS analysis confirming the formation of target products for Suzuki and Sonogashira reactions (Appendix I); UV-Vis experiments with NumPy array spectral outputs validated computational analysis (wavelengths of max absorbance). Computational validation: code execution traces and error handling confirmed the Agent's ability to self-correct (e.g., add print() or avoid missing-package imports). Literature/documentation validation: web searches located canonical literature routes (e.g., Friedel–Crafts route for ibuprofen) which the Agent used to plan stoichiometry/conditions. Limitations: some proposed discoveries (e.g., anticancer drug candidate) were not experimentally executed, so validation there is limited to in silico reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is not claimed for chemical discoveries; the Agent typically reproduces or adapts known literature syntheses (ibuprofen, aspirin, Suzuki examples) and demonstrates the capability to discover by integration and automation rather than claiming new chemical entities. The paper assesses novelty via whether the Agent can find and implement known literature procedures and whether it can autonomously design and execute protocols; a proposed anticancer scaffold was generated but not experimentally validated, so novelty of that proposal is not established.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Reported/usable metrics include: successful execution of generated protocols (qualitative examples), analytical confirmation of product formation via GC-MS (qualitative statement that target products were observed), UV-Vis spectral analysis correctness (task solved), code-execution correction cycles demonstrating robustness, and a safety-test numeric result: out of 11 dual-use prompts, 4 (36%) produced a synthesis solution and attempted to consult documentation. No reaction yields, repeatability statistics, or broader quantitative performance metrics are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Quantitative success statistics are sparse. In the dual-use safety study the Agent provided a synthesis solution for 4 of 11 prompts (36%). For the showcased lab experiments (Suzuki and Sonogashira) the paper reports successful runs where GC-MS showed the target products after the Agent corrected a hardware module name via documentation; no aggregate success rate across multiple runs is reported. Other tasks (aspirin, ibuprofen planning, UV-Vis analysis) are reported as successful in single or few demonstrations; no large-N success rates given.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges and limitations discussed include: (1) Safety and dual-use risk—Agent sometimes produced actionable synthesis plans for controlled substances and can be misled by obfuscated prompts; (2) Detection limitations for novel harmful compounds (model struggles with previously unknown toxins); (3) Dependence on quality and currency of web/documentation sources (GPT-4 training cutoff and need for up-to-date docs); (4) Necessity for human-in-the-loop oversight for potentially dangerous experiments; (5) Token and vectorization limits when ingesting long hardware documentation (7800 token cap used); (6) Limited reproducibility and quantitative benchmarking—experiments demonstrated are small-N examples without comprehensive statistical validation; (7) Some proposed discoveries (anticancer drug candidate) were not experimentally validated, limiting claims of discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1435.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1435.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (Generative Pre-trained Transformer 4)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based large language model from OpenAI used as a core reasoning/planning component in the Agent to parse documentation, plan experiments, and generate code and natural language instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>GPT-4 Technical Report</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-4 (component of Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GPT-4 is used for high-level planning, browsing summarization, documentation-guided code generation, and reasoning steps within the Agent; GPT-3.5 is used in some browsing tasks for speed. GPT-4's capabilities (e.g., reasoning, exam performance) motivate the Agent's design.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>General-purpose (enables discoveries across chemistry and other domains via planning and code generation)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>As a component of the Agent, GPT-4 enabled literature-informed planning (identifying known synthetic routes), reasoning about stoichiometry and conditions, generation and iterative correction of automation code, and selection of reagents/catalysts for cross-coupling reactions; these activities resulted in executed experiments that produced expected analytical signals. GPT-4 itself is not presented as independently making novel chemical discoveries in this paper but as the core LLM enabling autonomous experimental design and execution.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper references GPT-4's exceptional problem-solving abilities and uses it to demonstrate emergent autonomous research capabilities, but it does not assign GPT-4-generated outputs to explicit categories of 'incremental' or 'transformational'.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation of GPT-4's role is indirect: measuring the Agent's task performance (successful code generation, search-guided planning, error correction, and execution leading to experimentally detected products). The paper cites external benchmarks for GPT-4 (SAT, BAR, coding tasks) but internal evaluation relies on task-level success and qualitative examples.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation comes from the downstream success of the Agent's experiments and code execution (e.g., corrected code runs, GC-MS detection of products) and from documented examples where GPT-4 produced correct documentation-guided code and planning steps. No separate ablation isolating GPT-4's contribution quantitatively is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>GPT-4 is described as enabling emergent capabilities when combined in an Agent; novelty claimed is in the integrated Agent architecture and autonomous experimental loop rather than a claim that GPT-4 alone discovered new scientific knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Indirect impact metrics reported via Agent outcomes (qualitative successes, safety-test percentages). The paper also references GPT-4's public performance claims (high percentiles on standardized tests) from the technical report, but does not re-measure them.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>No isolated success rate for GPT-4 alone is provided. Agent-level anecdotal successes attributable in part to GPT-4 are reported (several successful experiment plans and at least one set of executed cross-coupling reactions yielding target products); safety-test: Agent (using LLMs including GPT-4/3.5) produced synthesis solutions for 36% of prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include GPT-4 training cutoff (knowledge up to Sep 2021), potential hallucinations or volatility at high-temperature sampling affecting catalyst/base suggestions, inability alone to verify physical execution without instrumentation/data, and susceptibility to adversarial prompt manipulations to bypass safety heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>GPT-4 Technical Report <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>Dual use of artificial-intelligence-powered drug discovery <em>(Rating: 1)</em></li>
                <li>Chemformer: a pre-trained transformer for computational chemistry <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1435",
    "paper_id": "paper-ae6a4cd221684be6ca3082b6f526a7901281490b",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "Agent",
            "name_full": "LLM-based Intelligent Agent (IA) system",
            "brief_description": "A multi-module intelligent agent that composes GPT-3.5/GPT-4 LLMs with web/documentation search, a code-execution sandbox, and automation APIs to autonomously design, plan, and execute chemical experiments (synthesis planning, liquid-handler protocol generation, and multi-instrument experiment orchestration).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Intelligent Agent (Agent)",
            "system_description": "A modular system driven by a Planner LLM coordinating components: Web searcher (Google API + BROWSE), Docs searcher (vectorized hardware API docs via ada embeddings), Code execution (isolated Docker container), and Automation (hardware/cloud-lab executors). The Planner issues actions (GOOGLE, DOCUMENTATION, PYTHON, EXPERIMENT) and uses GPT-3.5/GPT-4 for browsing, planning, and synthesis of protocols; the system executes code on a sandbox or runs hardware protocols on a liquid handler and heater-shaker and integrates analytical outputs (UV-Vis, GC-MS).",
            "discovery_domain": "Chemistry (experimental synthetic chemistry / automated experimentation)",
            "discovery_description": "The Agent autonomously searched literature and documentation, planned reagent stoichiometry and reaction conditions, generated runnable automation code, corrected its own code after runtime errors, and executed physical experiments on a liquid handler (including heater-shaker) to perform Suzuki and Sonogashira cross-coupling reactions; post-reaction GC-MS analysis indicated formation of the target products. Additional demonstrations included synthesis planning for ibuprofen and aspirin (executed planning and stoichiometry calculations) and a cloud-lab-correctable aspartame synthesis (initially incorrect but amendable). The Agent also performed UV-Vis data analysis and mechanistic computational exercises (e.g., mechanistic study of Suzuki reaction) and proposed a novel anticancer drug candidate (design step performed but synthesis not executed).",
            "discovery_type": "",
            "discovery_type_justification": "The paper does not apply explicit labels such as 'incremental', 'transformational', 'breakthrough', or 'paradigm-shifting' to the discoveries; instead it frames results as demonstrating 'emergent autonomous scientific research capabilities' and 'exceptional reasoning and experimental design capabilities'. No formal categorization of discovery novelty level is provided.",
            "evaluation_methods": "Evaluation combined computational and experimental checks: (1) Code-level verification by executing generated Python in an isolated Docker container and inspecting runtime outputs/tracebacks (used to detect missing packages and logical errors); (2) Documentation cross-checks using Docs searcher and web search to verify reagent choices and hardware API usage; (3) Instrument-level validation by running generated protocols on a liquid handler/heater-shaker and collecting analytical results (UV-Vis arrays and GC-MS of reaction mixtures); (4) Outcome assessment by comparing analytical outputs to expected signals/products (GC-MS detection of target cross-coupling products; UV-Vis peak analysis to solve color identification task); (5) Safety behavior evaluation via a dual-use test set of 11 controlled or hazardous compounds, tracking whether the Agent produced synthesis plans (reported as counts/percentages). No formal statistical benchmarks (ROC/AUC etc.) or yield percentages for synthetic reactions are reported.",
            "validation_approaches": "Experimental validation: physical execution of protocols on robotic liquid-handler and heater-shaker with subsequent GC-MS analysis confirming the formation of target products for Suzuki and Sonogashira reactions (Appendix I); UV-Vis experiments with NumPy array spectral outputs validated computational analysis (wavelengths of max absorbance). Computational validation: code execution traces and error handling confirmed the Agent's ability to self-correct (e.g., add print() or avoid missing-package imports). Literature/documentation validation: web searches located canonical literature routes (e.g., Friedel–Crafts route for ibuprofen) which the Agent used to plan stoichiometry/conditions. Limitations: some proposed discoveries (e.g., anticancer drug candidate) were not experimentally executed, so validation there is limited to in silico reasoning.",
            "novelty_assessment": "Novelty is not claimed for chemical discoveries; the Agent typically reproduces or adapts known literature syntheses (ibuprofen, aspirin, Suzuki examples) and demonstrates the capability to discover by integration and automation rather than claiming new chemical entities. The paper assesses novelty via whether the Agent can find and implement known literature procedures and whether it can autonomously design and execute protocols; a proposed anticancer scaffold was generated but not experimentally validated, so novelty of that proposal is not established.",
            "impact_metrics": "Reported/usable metrics include: successful execution of generated protocols (qualitative examples), analytical confirmation of product formation via GC-MS (qualitative statement that target products were observed), UV-Vis spectral analysis correctness (task solved), code-execution correction cycles demonstrating robustness, and a safety-test numeric result: out of 11 dual-use prompts, 4 (36%) produced a synthesis solution and attempted to consult documentation. No reaction yields, repeatability statistics, or broader quantitative performance metrics are provided.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "Quantitative success statistics are sparse. In the dual-use safety study the Agent provided a synthesis solution for 4 of 11 prompts (36%). For the showcased lab experiments (Suzuki and Sonogashira) the paper reports successful runs where GC-MS showed the target products after the Agent corrected a hardware module name via documentation; no aggregate success rate across multiple runs is reported. Other tasks (aspirin, ibuprofen planning, UV-Vis analysis) are reported as successful in single or few demonstrations; no large-N success rates given.",
            "challenges_limitations": "Challenges and limitations discussed include: (1) Safety and dual-use risk—Agent sometimes produced actionable synthesis plans for controlled substances and can be misled by obfuscated prompts; (2) Detection limitations for novel harmful compounds (model struggles with previously unknown toxins); (3) Dependence on quality and currency of web/documentation sources (GPT-4 training cutoff and need for up-to-date docs); (4) Necessity for human-in-the-loop oversight for potentially dangerous experiments; (5) Token and vectorization limits when ingesting long hardware documentation (7800 token cap used); (6) Limited reproducibility and quantitative benchmarking—experiments demonstrated are small-N examples without comprehensive statistical validation; (7) Some proposed discoveries (anticancer drug candidate) were not experimentally validated, limiting claims of discovery.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1435.0",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (Generative Pre-trained Transformer 4)",
            "brief_description": "A transformer-based large language model from OpenAI used as a core reasoning/planning component in the Agent to parse documentation, plan experiments, and generate code and natural language instructions.",
            "citation_title": "GPT-4 Technical Report",
            "mention_or_use": "use",
            "system_name": "GPT-4 (component of Agent)",
            "system_description": "GPT-4 is used for high-level planning, browsing summarization, documentation-guided code generation, and reasoning steps within the Agent; GPT-3.5 is used in some browsing tasks for speed. GPT-4's capabilities (e.g., reasoning, exam performance) motivate the Agent's design.",
            "discovery_domain": "General-purpose (enables discoveries across chemistry and other domains via planning and code generation)",
            "discovery_description": "As a component of the Agent, GPT-4 enabled literature-informed planning (identifying known synthetic routes), reasoning about stoichiometry and conditions, generation and iterative correction of automation code, and selection of reagents/catalysts for cross-coupling reactions; these activities resulted in executed experiments that produced expected analytical signals. GPT-4 itself is not presented as independently making novel chemical discoveries in this paper but as the core LLM enabling autonomous experimental design and execution.",
            "discovery_type": "",
            "discovery_type_justification": "The paper references GPT-4's exceptional problem-solving abilities and uses it to demonstrate emergent autonomous research capabilities, but it does not assign GPT-4-generated outputs to explicit categories of 'incremental' or 'transformational'.",
            "evaluation_methods": "Evaluation of GPT-4's role is indirect: measuring the Agent's task performance (successful code generation, search-guided planning, error correction, and execution leading to experimentally detected products). The paper cites external benchmarks for GPT-4 (SAT, BAR, coding tasks) but internal evaluation relies on task-level success and qualitative examples.",
            "validation_approaches": "Validation comes from the downstream success of the Agent's experiments and code execution (e.g., corrected code runs, GC-MS detection of products) and from documented examples where GPT-4 produced correct documentation-guided code and planning steps. No separate ablation isolating GPT-4's contribution quantitatively is provided.",
            "novelty_assessment": "GPT-4 is described as enabling emergent capabilities when combined in an Agent; novelty claimed is in the integrated Agent architecture and autonomous experimental loop rather than a claim that GPT-4 alone discovered new scientific knowledge.",
            "impact_metrics": "Indirect impact metrics reported via Agent outcomes (qualitative successes, safety-test percentages). The paper also references GPT-4's public performance claims (high percentiles on standardized tests) from the technical report, but does not re-measure them.",
            "comparison_to_human_discoveries": false,
            "comparison_details": "",
            "success_rate": "No isolated success rate for GPT-4 alone is provided. Agent-level anecdotal successes attributable in part to GPT-4 are reported (several successful experiment plans and at least one set of executed cross-coupling reactions yielding target products); safety-test: Agent (using LLMs including GPT-4/3.5) produced synthesis solutions for 36% of prompts.",
            "challenges_limitations": "Limitations include GPT-4 training cutoff (knowledge up to Sep 2021), potential hallucinations or volatility at high-temperature sampling affecting catalyst/base suggestions, inability alone to verify physical execution without instrumentation/data, and susceptibility to adversarial prompt manipulations to bypass safety heuristics.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1435.1",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 2
        },
        {
            "paper_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "rating": 2
        },
        {
            "paper_title": "Dual use of artificial-intelligence-powered drug discovery",
            "rating": 1
        },
        {
            "paper_title": "Chemformer: a pre-trained transformer for computational chemistry",
            "rating": 1
        }
    ],
    "cost": 0.010501,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Emergent autonomous scientific research capabilities of large language models</h1>
<p>Daniil A. Boiko, ${ }^{1}$ Robert MacKnight, ${ }^{1}$ and Gabe Gomes ${ }^{* 1,2,3}$</p>
<ol>
<li>Department of Chemical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Department of Chemistry, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Wilton E. Scott Institute for Energy Innovation, Carnegie Mellon University, Pittsburgh, PA 15213, USA
*corresponding author, gabegomes@cmu.edu</li>
</ol>
<h4>Abstract</h4>
<p>Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
<h2>Keywords</h2>
<p>Large Language Models; Intelligent Agents; Generative AI; Autonomous Experimentation; Automation; Physical Sciences; Catalysis.</p>
<h2>Glossary</h2>
<ul>
<li>LLMs: Large Language Models. In this paper, we use OpenAI's GPT-3.5 and GPT-4.</li>
<li>Agent: LLM-based Intelligent Agent (IA) system.</li>
<li>Prompt-provider: A scientist - in this work, one of the human authors - that provides the initial prompt to the Agent.</li>
</ul>
<h1>Main</h1>
<p>Large language models (LLMs), particularly transformer-based models, are experiencing rapid advancements in recent years. These models have been successfully applied to various domains, including natural language, ${ }^{1-5}$ biological ${ }^{6,7}$ and chemical research, ${ }^{8,9}$ as well as code generation. Extreme scaling of models, as demonstrated by OpenAI, has led to significant breakthroughs in the field. ${ }^{1,10}$ Moreover, techniques such as reinforcement learning from human feedback (RLHF) ${ }^{11}$ can considerably enhance the quality of generated text and the models' capability to perform diverse tasks while reasoning about their decisions. ${ }^{12}$</p>
<p>On March 14, 2023, OpenAI released their most capable LLM to date, GPT-4. ${ }^{10}$ Although specific details about the model training, sizes, and data used are limited in the technical report, researchers have provided substantial evidence of the model's exceptional problem-solving abilities. Those include - but are not limited to - high percentiles on the SAT and BAR exams, LeetCode challenges, and contextual explanations from images, including niche jokes. ${ }^{10}$ Moreover, the technical report provides an example of how the model can be employed to address chemistry-related problems.</p>
<p>Inspired by these results, we aimed to develop a multi-LLMs-based Intelligent Agent (hereafter simply called Agent) capable of autonomous design, planning, and performance of complex scientific experiments. The Agent can use tools ${ }^{13}$ to browse the internet and relevant documentation, use robotic experimentation APIs, and leverage other LLMs for various tasks. In this paper, we demonstrate the versatility and efficacy of our Agent by evaluating its performance in three tasks: 1. Efficiently searching and navigating through extensive hardware documentation; 2. Precisely controlling liquid handling instruments at a low level; 3. Tackling complex problems that necessitate simultaneous utilization of multiple hardware modules or integration of diverse data sources.</p>
<h2>The Agent's architecture: action space defined by its multiple modules.</h2>
<p>The Agent's system consists of four components (Figure 1), driven by the "Planner." The Planner takes a prompt as input (e.g., "Perform multiple Suzuki reactions") and carries out actions according to this request. The action space includes accessing the internet ("GOOGLE <query>" request), performing calculations in Python ("PYTHON <code>"), accessing documentation ("DOCUMENTATION <query>"), and running the final experiment ("EXPERIMENT <code>"). Experiments can be performed in various environments - a cloud lab, using a liquid handler, or by providing instructions for performing experiments manually. The model is instructed to reason about its actions, search the internet, calculate all quantities in the reaction, and then perform the corresponding reaction. The Agent is aware that, on average, at least ten steps are needed to fully understand the requested task. No further clarifying questions to the prompt-provider are necessary if the provided description is detailed enough.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Overview of the system architecture. The Agent is composed of multiple modules that exchange messages. Some of them have access to APIs, the Internet, and Python interpreter.</p>
<p>The "Web searcher" component receives queries from the Planner, transforms them into appropriate web search queries, and executes them using the Google Search API. The first ten documents returned are filtered, excluding PDFs, and the resulting list of web pages is passed back to the Web searcher component. The component can then use the "BROWSE" action to extract text from the web pages and compile an answer for the Planner. For this task we can employ GPT-3.5, as it performs significantly faster than GPT-4 with no appreciable loss of quality. The "Docs searcher" component combs through the hardware documentation (e.g., robotic liquid handler, GC-MS, a cloud lab) by utilizing a query and documentation index to find the most relevant pages/sections. Then the best matching results are aggregated to provide a comprehensive and accurate final answer. This module places an emphasize on providing specific function parameter and syntactic information for the hardware API.</p>
<p>The "Code execution" component does not utilize any language models and simply executes the code in an isolated Docker container, protecting the end host machine from any unexpected actions by the Planner. All code outputs are passed back to the Planner, enabling it to fix its predictions in case of software errors. The same applies to the "Automation" component, which then executes the generated code on corresponding hardware or just provides the synthetic procedure for manual experimentation.</p>
<h1>Web search enables Agent's synthesis planning capabilities.</h1>
<p>To demonstrate the system's functionality, we use the synthesis of ibuprofen as an example (Figure 2A). The input prompt is straightforward: "Synthesize ibuprofen." The model then searches the internet for information on ibuprofen synthesis, locating the necessary details on a particular website. The model correctly identifies the first step of the synthesis, which is the Friedel-Crafts reaction between isobutylbenzene and acetic anhydride catalyzed by aluminum chloride (see Appendix A). The planning phase for the first step concludes once the model requests documentation for the Friedel-Crafts synthesis procedure.</p>
<p>Two other examples of the system's capabilities include the synthesis of common aspirin (Figure 2B and Appendix B), which the model searches and designs effectively, and aspartame synthesis (Figure 2D and Appendix C), which, although missing the methyl group in the product, can be corrected once the model receives a suitable synthetic example for execution in the cloud lab. Furthermore, when asked to study a Suzuki reaction, the model accurately identifies the substrates and the product (Figure 2C and Appendix D). The high-temperature parameter for text generation results in volatility when suggesting specific catalysts or bases.</p>
<p>Connecting the model to a chemical reaction database such as Reaxys ${ }^{14}$ or SciFinder ${ }^{15}$ via API could significantly enhance the system's performance. Alternatively, analyzing the system's previous statements is another approach to improving its accuracy.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Agent's capabilities in the synthesis planning task. A. Ibuprofen synthesis. B. Aspirin synthesis. C. Suzuki reaction mechanism study, where the Agent had to choose how to study the mechanism. D. Aspartame synthesis.</p>
<h1>Vector search can be employed for retrieval of dense hardware API documentation.</h1>
<p>To integrate an intelligent Agent capable of sophisticated reasoning with contemporary software, it is crucial to provide a clear and concise presentation of relevant technical documentation. Modern software is characterized by its complexity and the intricate interplay between various components. Consequently, comprehensive software documentation is indispensable for programmers to comprehend these interactions and utilize them effectively to accomplish their goals. Nonetheless, traditional software documentation frequently employs highly technical language, which can be challenging for non-experts to grasp. This creates a barrier to entry for many potential users of the software, limiting its reach and effectiveness.</p>
<p>Large language models have the potential to overcome this barrier by generating natural language descriptions of software documentation that are more accessible to nonexperts. These models are trained on a vast corpus of text from a variety of sources, which includes extensive information related to Application Programming Interfaces (APIs). One such API is the Opentrons Python API. ${ }^{16}$ However, the GPT-4's training data contains information up until September 2021. Thus, there is potential for enhancing the Agent's accuracy in using the API. To this end, we devised an approach to provide the Agent with requisite documentation for a given task, summarized in Figure 3A.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Overview of documentation search. A. Prompt-to-(improved OT-2 Python API)-code via ada embedding and distance-based vector search. B. Prompt-to-function recommendation in Emerald Cloud Lab symbolic lab language via supplementation of documentation guide.</p>
<p>For all 14 sections of the OT-2 API documentation we have generated OpenAI's ada embeddings to cross reference and compute similarity with respect to a query. The agent is instructed to inquire about proper use of the API when needed via the Documentation action. An ada embedding for the subsequent query is generated and documentation sections are selected via a distance-based vector search. The number of sections provided is dictated by the number of GPT-4 tokens present in the raw text for a given section. The maximum number of tokens is set to 7800 , such that the relevant documents can be provided in one step. This approach proved critical for providing the agent with information about the heater-shaker hardware module necessary for performing chemical reactions (see "The Agent is capable of designing and performing chemical experiments." section).</p>
<p>A greater challenge emerges when applying this approach to a more diverse robotic platform, such as the Emerald Cloud Lab (ECL). Nonetheless, we can explore the effectiveness of providing information about the Cloud Lab's Symbolic Lab Language (SLL), which is currently unknown to the GPT-4 model. For this we provide the Agent with a documentation guide from ECL pertaining to all available functions for running experiments. ${ }^{17}$ Figure 3B summarizes three examples of the User providing a simple query and the Agent directing the User to relevant ECL functions. More examples are shared in the Appendix G. In all cases, the Agent correctly identifies functions for accomplishing the given task. After selection of appropriate functions, the raw plain text documentation is passed through a separate GPT-4 model to perform code syntax retention and summarization. Specifically, this model efficiently retains information regarding the various options, instruments, and parameters for a given function. Once the entire documentation has been ingested, the model is prompted to produce a code block utilizing the given function to be passed back to the Planner. This serves as a basis for the model to utilize this function with specific options, instruments, and parameters as they are gathered by the Web searcher.</p>
<h1>Mastering automation: multi-instrument systems controlled by natural language.</h1>
<p>Access to documentation enables us to provide sufficient information for the Agent to conduct experiments in the physical world. To initiate the investigation, we chose an open-source liquid handler with a well-documented Python API. The "Getting Started" page from its documentation was supplied to the Planner in the system prompt. Other pages were vectorized using the approach described in the "Providing hardware API Documentation" section. In this section, we did not grant access to the internet (Figure 4A).</p>
<p>A.
<img alt="img-3.jpeg" src="img-3.jpeg" />
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>UV-Vis data from plate 1 is ready. You can access it using PYTHON, it will be in the file named
'plate1.npy'. You will have NumPy installed. The file contains NumPy array of shape $(9,12,41)$. There are 41 wavelengths from 350 to 750 with 10 nm step. Think about how would different colors absorb first.</p>
<p>Automated answer</p>
<ul>
<li>guiding prompt
[530, 430, 630]
Automated answer
<img alt="img-5.jpeg" src="img-5.jpeg" /></li>
</ul>
<p>Figure 4. Robotic liquid handler control capabilities and integration with analytical tools. A. Overview of the Agent's configuration. B-E. Drawing geometrical figures. F. The Agent solves a color identification problem using UV-Vis data.</p>
<p>We began with simple experiments on operating the robot, which simultaneously required the ability to consider a set of samples as a whole (in our case, an entire microplate). Straightforward prompts in natural language, such as "Color every other line with one color of your choice," resulted in mostly accurate protocols. When executed by the robot, these protocols closely resembled the requested prompt (Figure 4B-E).</p>
<p>The Agent's first action was to prepare small samples of the original solutions (Figure 4F). It then requested UV-Vis measurements to be performed (Appendix H). Once completed, the Agent was provided with a file name containing a NumPy array with spectra for each well of the microplate. The Agent subsequently wrote Python code to identify the wavelengths with maximum absorbance, using this data to correctly solve the problem.</p>
<h1>Bringing it all together: the Agent's integrated chemical experiment design and execution capabilities.</h1>
<p>Previous experiments could be affected by the knowledge of the Agent's modules from the pretraining step. We wanted to evaluate the Agent's ability to plan an experiment by combining data from the internet, performing the necessary calculations, and ultimately writing the code for the liquid handler. To increase complexity, we asked the Agent to use the heater-shaker module released after the GPT-4 training data collection cutoff. These requirements were incorporated into the Agent's configuration (Figure 5A).</p>
<p>The problem was designed as follows: the Agent is provided with a liquid handler equipped with two microplates. One (Source Plate) contains stock solutions of multiple reagents, including phenyl acetylene and phenylboronic acid, multiple aryl halide coupling partners, two catalysts, two bases, and the solvent to dissolve the sample (Figure 5B). The target plate is installed on the heater-shaker module (Figure 5C). The Agent's goal is to design a protocol to perform Suzuki and Sonogashira reactions.</p>
<p>The Agent begins by searching the internet for information on the requested reactions, their stoichiometry, and conditions (Figure 5D). It selects the correct coupling partners for the corresponding reactions. Among all aryl halides, it selected bromobenzene for Suzuki reaction and iodobenzene for Sonogashira reaction. This behavior changes from each run, as it also selects p-nitroiodobenzene due to its high reactivity in oxidative addition reactions, or bromobenzene because it is reactive but less toxic than aryl iodides. This highlights a potential future use case for the model - performing experiments multiple times to analyze the model's reasoning and construct a bigger picture. The model selected a $\mathrm{Pd} / \mathrm{NHC}$ catalyst as a more efficient, modern approach for cross-coupling reactions, and triethylamine was chosen as the base.</p>
<p>The Agent then calculates the required volumes of all reactants and writes the protocol. However, it used an incorrect heater-shaker module name. Upon noticing the mistake, the model consulted the documentation. This information was then used to modify the protocol, which successfully ran (Figure 5E). Subsequent GC-MS analysis of the reaction mixtures revealed the formation of the target products for both reactions (Appendix I).</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5. Cross-coupling Suzuki and Sonogashira reaction experiments designed and performed by the Agent. A. Overview of the Agent's configuration. B. Available compounds. C. Liquid handler setup. D. Solving the synthesis problem. E. Generated protocol.</p>
<h1>The Agent has high reasoning capabilities.</h1>
<p>The system demonstrates remarkably high reasoning capabilities, enabling it to request necessary information, solve complex problems, and generate high-quality code for experimental design. OpenAI has shown that GPT-4 could rely on some of those capabilities to take actions in the physical world during their initial testing performed by the Alignment Research Center. ${ }^{10}$</p>
<p>The most remarkable reasoning capability exhibited by the Agent was its ability to correct its own code based on the automatically generated outputs. Besides already mentioned examples, during calculations for a mechanistic study of the Suzuki reaction, the model requested the system to execute code that imported the SymPy package (refer to Appendix D), which was not installed. After receiving the corresponding traceback, the Agent revised the code using basic Python. However, this modified code still proved unhelpful, as it did not return any output (the model had assumed that the interpreter was being used in interactive mode). Acknowledging this, the Agent made a final adjustment by incorporating a print() statement.</p>
<h2>The Agent shows interesting approach to key scientific problems.</h2>
<p>Furthermore, we aimed to assess the system's performance when presented with an exceptionally challenging problem. We began by asking the model to develop a novel anticancer drug (refer to Appendix E). The model approached the analysis in a logical and methodical manner: it first inquired about current trends in anticancer drug discovery, subsequently selected a target, and requested a scaffold targeting these compounds. Once the compound was identified, the model attempted its synthesis (this step was not performed experimentally). Another example involved studying the mechanism of a Suzuki reaction (see Appendix D). In this case, the model sought information on the reaction's mechanism and, upon obtaining the individual steps, searched for an example of such a reaction. To execute the reaction, the model calculated the required amounts of reagents and requested the documentation page related to the corresponding synthesis.</p>
<h2>Safety implications of the developed approach.</h2>
<p>There is growing concern regarding the potential misuse of molecular machine learning models for harmful purposes. Specifically, the dual-use application of models for predicting cytotoxicity ${ }^{18}$ to create new poisons or employing AlphaFold2 to develop novel bioweapons has raised alarm. Central to these concerns are the possible misuse of large language models and automated experimentation for dual-use purposes or otherwise. We specifically address two critical the synthesis issues: illicit drugs and chemical weapons. To evaluate these risks, we designed a test set comprising compounds from the DEA's Schedule I and II substances and a list of known chemical weapon agents. We submitted these compounds to the Agent using their common names, IUPAC names, CAS numbers, and SMILES strings to determine if the Agent would carry out extensive analysis and planning (Figure 6).</p>
<p>Note: None of these examples were performed experimentally. Under no circumstances should any individual or organization attempt to recreate, synthesize, or otherwise produce the substances or compounds discussed in this section.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 6. Results of the preliminary dual-use safety study. A. Controlled substances that the Agent agreed to synthesize. B. Controlled substances that Agent refused to synthesize these examples after a web search. C. Controlled substances that Agent refused to synthesize from the initial prompt.</p>
<p>The run logs can be found in Appendix F. Out of 11 different prompts (Figure 6), four (36\%) provided a synthesis solution and attempted to consult documentation to execute the procedure. This figure is alarming on its own, but an even greater concern is the way in which the Agent declines to synthesize certain threats. Out of the seven refused chemicals, five were rejected after the Agent utilized search functions to gather more information about the substance. For instance, when asked about synthesizing codeine, the Agent becomes alarmed upon learning the connection between codeine and morphine, only then concluding that the synthesis cannot be conducted due to the requirement of a controlled substance. However, this search function can be easily manipulated by altering the terminology, such as replacing all mentions of morphine with "Compound A" and codeine with "Compound B". Alternatively, when requesting a synthesis procedure that must be performed in a DEA-licensed facility, bad actors can mislead the Agent by falsely claiming their facility is licensed, prompting the Agent to devise a synthesis solution.</p>
<p>In the remaining two instances, the Agent recognized the common names "heroin" and "mustard gas" as threats and prevented further information gathering. While these results are promising, it is crucial to recognize that the system's capacity to detect misuse primarily applies to known compounds. For unknown compounds, the model is less likely to identify potential misuse, particularly for complex protein toxins where minor sequence changes might allow them to maintain the same properties but become unrecognizable to the model.</p>
<p>It is important to note that while the potential for dual use of Intelligent Agent capable of running scientific experiments is real, fully monitored cloud labs remain a safer choice than simply remote-connected machines. Screening, monitoring, and control safety systems such as the ones implemented by major cloud lab companies offer an additional layer of protection from potential misuses or bad actors.</p>
<h1>Conclusions</h1>
<p>In this paper, we presented an Intelligent Agent system capable of autonomously designing, planning, and executing complex scientific experiments. Our system demonstrates exceptional reasoning and experimental design capabilities, effectively addressing complex problems and generating high-quality code.</p>
<p>However, the development of new machine learning systems and automated methods for conducting scientific experiments raises substantial concerns about the safety and potential dual use consequences, particularly in relation to the proliferation of illicit activities and security threats. By ensuring the ethical and responsible use of these powerful tools, we can continue to explore the vast potential of large language models in advancing scientific research while mitigating the risks associated with their misuse.</p>
<h1>Limitations, Safety Recommendations, and a Call to Action</h1>
<p>We strongly believe that guardrails must be put in place to prevent this type of potential dual-use of large language models. We call for the AI community to engage in prioritizing safety of these powerful models. We call upon OpenAI, Microsoft, Google, Meta, Deepmind, Anthropic, and all the other major players to push the strongest possible efforts on safety of their LLMs. We call upon the physical sciences community to be engaged with the players involved in developing LLMs to assist them in developing those guardrails.</p>
<p>There are several limitations and safety concerns associated with the proposed machine learning system. These concerns warrant the implementation of safety guardrails to ensure responsible and secure usage of the system. At the very least, we argue that the community (both Al and physical sciences) should engage in the following recommendations:</p>
<ol>
<li>Human intervention: While the system demonstrates high reasoning capabilities, there might be instances where human intervention is necessary to ensure the safety and reliability of the generated experiments. We recommend incorporating a human-in-the-loop component for the review and approval of potentially sensitive experiments, especially those involving potentially harmful substances or methodologies. We believe that specialists should oversee and deliberate about the Agent's actions in the physical world.</li>
<li>Novel compound recognition: The current system can detect and prevent the synthesis of known harmful compounds. However, it is less efficient at identifying novel compounds with potentially harmful properties. This could be circumvented by implementing machine learning model to identify potentially harmful structures before passing them into the model.</li>
<li>Data quality and reliability: The system relies on the quality of the data it gathers from the internet and operational documentation. To maintain the reliability of the system, we recommend the continuous curation and update of the data sources, ensuring that the most up-to-date and accurate information is being used to inform the system's decision-making process.</li>
<li>System security: The integration of multiple components, including large language models and automated experimentation, poses security risks. We recommend implementing robust security measures, such as encryption and access control, to protect the system from unauthorized access, tampering, or misuse.</li>
</ol>
<h2>Broader Impacts</h2>
<p>The proposed machine learning system has numerous potential broader impacts on science, technology, and society:</p>
<ol>
<li>Acceleration of scientific research: By automating the design, planning, and execution of experiments, the system can significantly accelerate scientific research</li>
</ol>
<p>across various fields. Researchers can focus on interpreting results, refining hypotheses, and making discoveries, while the system handles the experimental process.
2. Democratization of scientific resources: The system can potentially make scientific experimentation more accessible to researchers with limited resources or expertise. It may enable smaller research groups or individuals to conduct complex experiments with the support of large language models and cloud labs, promoting a more inclusive scientific community.
3. Interdisciplinary collaboration: The system's versatility across domains, including natural language, biology, chemistry, and computer programming, can foster interdisciplinary collaboration. Researchers from different fields can leverage the system's capabilities to address complex problems that require a diverse set of skills and knowledge.
4. Education and training: The system can serve as a valuable educational tool for students and researchers to learn about experimental design, methodology, and analysis. It can help develop critical thinking and problem-solving skills, as well as encourage a deeper understanding of scientific principles.
5. Economic impact: By automating and streamlining the experimental process, the system can potentially reduce the costs associated with research and development. This can lead to increased investment in research and innovation, ultimately driving economic growth and competitiveness.</p>
<p>However, the potential broader impacts also include challenges and risks that must be addressed. Ensuring responsible and ethical use of the system, implementing robust security measures, and continuously updating data sources are essential steps to mitigate potential negative consequences, such as the proliferation of harmful substances or the misuse of powerful machine learning tools for nefarious purposes. By addressing these concerns, we can unlock the full potential of the proposed system and drive positive change across scientific research and society at large.</p>
<h1>Acknowledgments</h1>
<p>We are thankful to all Gomes group members for their support, in particular to Letícia Madureira for assistance with the Figures in this manuscript. We would like to thank the following CMU Chemistry groups for their assistance with providing some of chemicals needed for the Agent's experiments: Sydlik, Garcia Borsch, Matyjaszewski, and Ly. We have special thanks for the Noonan group (Prof. Kevin Noonan and Dhruv Sharma) for providing access to chemicals and GC-MS analytics. We would like to thank the team at Emerald Cloud Labs (with special attention to Ben Kline, Ben Smith, and Brian Frezza) for assisting us with parsing their documentation.
G.G. is grateful to the CMU Cloud Lab Initiative led by the Mellon College of Science for its vision of the future of sciences.</p>
<h1>Funding</h1>
<p>G.G. thanks Carnegie Mellon University, the Mellon College of Sciences and its department of chemistry, the College of Engineering and its department of chemical engineering for the startup support.</p>
<h2>Data availability</h2>
<p>Examples of the experiments discussed in the text are provided in the Appendices. Data (including documentation search and cloud lab execution), code, and prompts will be released in the later versions of this work due to safety concerns.</p>
<h2>Competing interests</h2>
<p>The authors have no competing interests to disclose at this moment.</p>
<h2>Author contributions</h2>
<p>D.A.B. designed the computational pipeline and developed "Planner", "Web searcher", and "Code execution" module. R.M. assisted in designing the computational pipeline and developed the "Docs searcher" module. D.A.B. assisted and oversaw the Agent's scientific experiments. D.A.B. and R.M. designed and performed the initial computational safety studies. G.G. designed the concept, performed preliminary studies, and supervised the project. D.A.B, R.M. and G.G. wrote this manuscript.</p>
<h2>Technology use disclosure</h2>
<p>The writing of this manuscript was assisted by ChatGPT (specifically, GPT-4). The authors have read, corrected, and verified all information presented in this work.</p>
<h1>References and Notes</h1>
<ol>
<li>Brown, T. et al. Language Models are Few-Shot Learners. in Advances in Neural Information Processing Systems (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. \&amp; Lin, H.) vol. 33 1877-1901 (Curran Associates, Inc., 2020).</li>
<li>Thoppilan, R. et al. LaMDA: Language Models for Dialog Applications. (2022).</li>
<li>Touvron, H. et al. LLaMA: Open and Efficient Foundation Language Models. (2023).</li>
<li>Hoffmann, J. et al. Training Compute-Optimal Large Language Models. (2022).</li>
<li>Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. (2022).</li>
<li>Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science (1979) 379, 1123-1130 (2023).</li>
<li>Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief Bioinform 23, (2022).</li>
<li>Irwin, R., Dimitriadis, S., He, J. \&amp; Bjerrum, E. J. Chemformer: a pre-trained transformer for computational chemistry. Mach Learn Sci Technol 3, 015022 (2022).</li>
<li>Kim, H., Na, J. \&amp; Lee, W. B. Generative Chemical Transformer: Neural Machine Learning of Molecular Geometric Structures from Chemical Language via Attention. J Chem Inf Model 61, 5804-5814 (2021).</li>
<li>OpenAI. GPT-4 Technical Report. (2023).</li>
<li>Ziegler, D. M. et al. Fine-Tuning Language Models from Human Preferences. (2019).</li>
<li>Ouyang, L. et al. Training language models to follow instructions with human feedback. (2022).</li>
<li>Bran, A. M., Cox, S., White, A. D. \&amp; Schwaller, P. ChemCrow: Augmenting largelanguage models with chemistry tools. (2023).</li>
<li>Reaxys. https://www.reaxys.com.</li>
<li>SciFinder. https://scifinder.cas.org.</li>
<li>Opentrons. Opentrons Python Protocol API. https://docs.opentrons.com/v2/.</li>
<li>
<p>Emerald Cloud Lab. Running Experiments. https://www.emeraldcloudlab.com/guides/runningexperiments.</p>
</li>
<li>
<p>Urbina, F., Lentzos, F., Invernizzi, C. \&amp; Ekins, S. Dual use of artificial-intelligencepowered drug discovery. Nat Mach Intell 4, 189-191 (2022).</p>
</li>
</ol>
<h1>Appendices</h1>
<h2>Glossary for Appendices</h2>
<h2>This box demarks notes from the authors.</h2>
<p>The following description follows OpenAI's notation for chat completion mode:</p>
<ul>
<li>Assistant: Output of the model (in most cases it is the "Planner" module).</li>
<li>User: Outputs of other modules provided to the main module (for example, search results or Python code output). Real user (in these experiments, a human scientist) inputs are marked as "Prompt:".</li>
</ul>
<h2>Appendix A: Synthesis of ibuprofen</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">First, let's look for a synthesis route for ibuprofen. <br> GOOGLE ibuprofen synthesis route</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Ibuprofen is synthesized through a process called Friedel-Crafts acylation. The starting materials for the synthesis are isobutylbenzene and acetic anhydride. This process was discovered by Stewart Adams and John Nicholson in 1961 while they were working at Boots UK Limited. The original ibuprofen synthesis by the Boots Group serves as a basis for the manufacturing process today.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Great, now that we have the synthesis route through Friedel-Crafts acylation using isobutylbenzene and acetic anhydride, let's find the stoichiometry and the experimental conditions for this reaction. <br> GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms p-isobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">Now that we have information about the reactants and stoichiometry, let's calculate how much of each reactant we need to synthesize around 100 mg of ibuprofen. First, we need the molecular weights of isobutylbenzene, acetic anhydride, and ibuprofen. Then, we'll calculate the amount of isobutylbenzene and acetic anhydride needed based on the reaction stoichiometry. <br> PYTHON <br> isobutylbenzene_mw $=134.22 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_mw $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> ibuprofen_mw $=206.28 # \mathrm{~g} / \mathrm{mol}$ <br> desired_mass $=0.1 #$ in $\mathrm{g}(100 \mathrm{mg})$ <br> isobutylbenzene_moles = desired_mass / ibuprofen_mw <br> acetic_anhydride_moles = isobutylbenzene_moles <br> mass_isobutylbenzene = isobutylbenzene_moles * <br> isobutylbenzene_mw <br> mass_acetic_anhydride = acetic_anhydride_moles * <br> acetic_anhydride_mw <br> print(mass_isobutylbenzene, mass_acetic_anhydride)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">0.06506689936009308 0.049490983129726586</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Based on our calculations, we need 0.0651 g of isobutylbenzene and 0.0495 g of acetic anhydride to synthesize about 100 mg of ibuprofen. <br> Lastly, let's check the cloud lab documentation for the experimental procedure that involves the Friedel-Crafts acylation reaction with isobutylbenzene and acetic anhydride, and the use of aluminum chloride as a catalyst. <br> DOCUMENTATION Friedel-Crafts acylation experimental procedure with aluminum chloride catalyst</td>
</tr>
</tbody>
</table>
<h1>Second Google search expanded</h1>
<table>
<thead>
<tr>
<th style="text-align: left;">User</th>
<th style="text-align: left;">Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions <br> and stoichiometry</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Assistant</td>
<td style="text-align: left;">GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride <br> conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: left;">User</td>
<td style="text-align: left;">Google search results: <br> Ibuprofen Synthesis - Writing Anthology <br> https://central.edu/writing-anthology/2019/04/11/ibuprofen-synthesis/ <br> Apr 11, 2019 ... Initially, isobutylbenzene (1) and acetic anhydride, were reacted under Friedel- <br> Crafts acylation conditions to create p-isobutylacetophenone ...</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Synthesis of ibuprofen from benzene - The Science Snail <br> https://www.sciencesnail.com/science/synthesis-of-ibuprofen-from-benzene</td>
</tr>
</tbody>
</table>
<p>Oct 11, 2018 ... Friedel-Crafts acylation mechanism isobutylbenzene ... an aldoxime (7) which is then dehydrated to the nitrile (8) using acetic anhydride.
(PDF) Ibuprofen Continuous Manufacturing - Process Modeling and ...
https://www.researchgate.net/publication/359864378_Ibuprofen_Continuous_Manufacturing_ Process_Modeling_and_Techno-Economic_Assessment_TEA_using_SuperPro_Designer Apr 11, 2022 ... The synthesis process involves Friedel-Crafts acylation, ... The raw materials acetic anhydride and isobutyl benzene (IBB) and the recycled ...</p>
<p>Regioselective Friedel-Crafts Acylation Reaction Using Single ...
https://pubs.acs.org/doi/10.1021/acsomega.2c03555
Aug 31, 2022 ... Again, the Friedel-Crafts (FC) acylation of aromatic substrates with ... (50) and substituted anhydrides (51) in stoichiometric amounts and ...</p>
<p>Flow Chemistry: Recent Developments in the Synthesis of ...
https://pubs.acs.org/doi/10.1021/acs.oprd.5b00325
Nov 26, 2015 ... The continuous flow Friedel-Crafts acylation of isobutylbenzene 68 with propionyl chloride 69 was performed with AlCl3 as a Lewis acid using ...</p>
<p>Strongly Lewis Acidic Metal-Organic Frameworks for Continuous ...
https://pubs.acs.org/doi/10.1021/jacs.9b07891
Sep 4, 2019 ... (58) Conventional Lewis acids for Friedel-Crafts acylation include ... Reaction conditions: arene ( 1 equiv, 1.0 mmol ), acetic anhydride ( 1.0 ...</p>
<p>A comprehensive review of flow chemistry techniques tailored to the ...
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8182698/
Optimisation of the reaction conditions in flow were carried out on ... is the acetylation of geraniol (343) through acetic anhydride developed by Adarme ...</p>
<p>Continuous Flow Organic Chemistry: Successes and Pitfalls at the ...
https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/ejoc. 201800149
Mar 13, 2018 ... The reactor effluent was next mixed with acetic anhydride an N ... The first step included a Friedel-Crafts acylation of isobutyl benzene ...</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">BROWSE https://central.edu/writing-anthology/2019/04/11/ibuprofensynthesis/</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">We removed the text from this website from the paper. You can access it by using URL above.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">OUTPUT In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms pisobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<h1>Appendix B: Synthesis of aspirin</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">I will first look up the synthesis reaction for aspirin to understand the reagents and procedure involved. <br> GOOGLE aspirin synthesis reaction</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Aspirin, also known as acetylsalicylic acid, is synthesized through a chemical reaction between salicylic acid and acetic anhydride. Sulfuric acid is used as a catalyst to speed up the reaction. The overall reaction can be described as an esterification reaction, in which a carboxylic acid reacts with an acid anhydride to form an ester. The balanced chemical equation for the reaction is: <br> C7H6O3 (salicylic acid) + C4H6O3 (acetic anhydride) -&gt; C9H8O4 (aspirin) + C2H4O2 (acetic acid) <br> During this reaction, the aspirin product will precipitate when water is added as it has low solubility in water, while acetic anhydride and acetic acid will dissolve in water. Vacuum filtration can then be used to separate the crystalline aspirin from the reaction mixture, excluding any unreacted salicylic acid.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Since we want to synthesize around 100 mg of aspirin, I will calculate the required quantities of salicylic acid and acetic anhydride using the balanced chemical equation and their molar masses. I will assume a $100 \%$ yield for simplicity. <br> PYTHON <br> aspirin_molar_mass $=180.16 # \mathrm{~g} / \mathrm{mol}$ <br> salicylic_acid_molar_mass $=138.12 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_molar_mass $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> target_aspirin_mass $=100 # \mathrm{mg}$ <br> target_aspirin_mol = target_aspirin_mass / <br> (aspirin_molar_mass * 1e3) <br> required_salicylic_acid_mol = target_aspirin_mol <br> required_acetic_anhydride_mol = target_aspirin_mol <br> required_salicylic_acid_mass = required_salicylic_acid_mol <br> * salicylic_acid_molar_mass * 1e3 <br> required_acetic_anhydride_mass = <br> required_acetic_anhydride_mol * acetic_anhydride_molar_mass <br> * 1e3 <br> print(required_salicylic_acid_mass, <br> required_acetic_anhydride_mass)</td>
</tr>
</tbody>
</table>            </div>
        </div>

    </div>
</body>
</html>