<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1987 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1987</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1987</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-45.html">extraction-schema-45</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <p><strong>Paper ID:</strong> paper-280561003</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.18602v2.pdf" target="_blank">LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts. In this paper, we propose a meta learning framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms. We first identify two key limitations in existing LLM-based algorithm evolution techniques: a lack of semantic guidance and code bloat. The absence of semantic awareness can lead to ineffective exchange of useful code components, and bloat results in unnecessarily complex components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress. To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: a complementary, semantics-aware selection operator and bloat control. Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators. Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance. Moreover, the evolved operator can further improve the state-of-the-art symbolic regression algorithm, achieving the best performance among 26 symbolic regression and machine learning algorithms across 116 regression datasets. This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1987.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1987.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Omni</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Omni selection operator (LLM-evolved)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A selection operator discovered by LLM-Meta-SR via meta-evolution; it integrates semantics (per-instance score vectors), interpretability (model size/height), stage-aware pressure, complementarity, and vectorized operations to select parents for GP.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Omni selection operator</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>selection</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>A Python program (generated by an LLM) that selects parents in genetic programming by (1) computing subset MSEs over structured+random subsets to prioritize specificity, (2) measuring complexity via node count and tree height to bias towards interpretability, (3) selecting the first parent by ranking on subset MSE then complexity, and (4) selecting the second parent by computing absolute cosine similarity between residuals (semantic complementarity) combined with a stage-dependent complexity penalty; the operator receives per-individual vectors (case-errors, predictions, tree nodes/height) and the evolutionary stage and outputs promising parent individuals. It is vectorized (NumPy-friendly) and includes stage-aware linear/nonlinear weighting to trade off exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution using an LLM (in-context learning): outer evolutionary loop evolves operators via LLM-based crossover/mutation guided by historical performance vectors; inner GP loop evaluates operators on SR tasks to compute fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>program (Python function / code fragment generated by an LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>numerical / symbolic regression (programs as symbolic expressions)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>average test R^2 (validation/test R^2 across datasets), model size (tree node count), training time, diversity (cosine-distance-based), and code length</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Meta-evolution best objective score reported: median historical best average test R^2 ≈ 0.86 (LLM-Meta-SR run reported in Table 1); produced selection code length ≈ 48 lines (median historical best). Omni (when applied within GP/RAG-SR) yielded top median test R^2 across 116 SRBench datasets and dominated in Pareto comparisons (accuracy vs model size).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Compared against nine expert-designed selection operators and many baselines (e.g., AutoLex, CPS, PLex, DALex, Boltzmann sampling variants); baselines produced lower median R^2s (examples in ablation: alternative settings show drops to ~0.84, 0.79 etc.), and many baselines were statistically indistinguishable from each other while Omni was significantly better in Wilcoxon tests (Benjamini-Hochberg corrected). Exact per-baseline numeric R^2s are provided in figures/tables in the paper but not enumerated for every baseline in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Reported as statistically significant improvements over expert-designed baselines; meta-evolution objective score improved to 0.86 vs ablated variants (e.g., W/O semantics or W/O knowledge often 0.84→0.79), and Omni produced better median R^2 and smaller models when integrated into RAG-SR (best among 26 methods across 116 datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Population diversity measured via cosine distance between residuals; complementarity score µ_i = (1/d) sum_j max(s_a,j, s_i,j) used to retrieve complementary parents; code similarity for survival selection measured with CodeBLEU and used to penalize dominated operators.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td>Applied Omni to RAG-SR (a transformer-assisted SR algorithm) producing RAG-SR-Omni; RAG-SR-Omni outperformed the original RAG-SR and other SOTA methods across 116 datasets (median R^2 and Pareto-optimal on accuracy vs model size), demonstrating the operator transfers to a different algorithmic context.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Omni incurs slightly higher selection time (multi-criteria computations) compared to simpler operators, but reduces overall evaluation/deployment cost by biasing toward smaller models; bloat control reduces LLM token costs. No absolute FLOPS/time-per-evaluation table for Omni vs each baseline is given, but figures show training time marginally higher for Omni while deployment inference cost lower due to smaller models.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Meta-evolution population size N=20; inner GP population size λ=100 (experiments use population size 100 and 100 generations for benchmark runs).</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td>Yes — semantic analysis and t-SNE of per-dataset score vectors show operators specialize (top-3 per-dataset solutions varied across datasets); Omni favors solutions that perform well on complementary subsets and maintains diverse population behaviors across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>An LLM-evolved selection operator (Omni) that leverages per-instance semantic feedback, stage-awareness, and complexity regularization can outperform multiple hand-designed selection operators on symbolic regression, producing better accuracy and more parsimonious models and improving downstream algorithms when integrated (e.g., RAG-SR).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>LLM-generated code is prone to bloat (excessive length) and occasional logical bugs on small datasets (structured division producing empty subsets); domain knowledge in prompts is important — absence causes largest performance drops; Omni has slightly higher selection runtime.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1987.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Omni-Zero</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Omni-Zero (Omni evolved without domain knowledge)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A selection operator evolved by LLM-Meta-SR when domain-knowledge guidance is removed; it demonstrates that LLMs can produce viable operators from internal priors but lacks some specialized components.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Omni-Zero selection operator</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>selection</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>LLM-generated Python selection operator that implements diversity-awareness (cosine-distance-based novelty), stage-awareness (a non-linear weighting function to trade off error vs novelty), and interpretability-awareness (nodes+height complexity metric), but it does not model specificity (subset-based selection) nor explicit complementarity between two parents; selection is largely dominated by mean squared error under some conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution with LLM in-context learning, but prompts omit domain knowledge principles (i.e., 'evolve from scratch' or 'AutoML-Zero'-style).</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>program (Python function)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>average R^2, diversity (cosine-distance novelty), code length</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Per ablation results, Omni-Zero achieves reasonable performance but is worse than Omni with domain knowledge; ablation shows removing domain knowledge causes the largest performance drop (examples in Table 1 show lower objective scores e.g., 0.79 vs 0.86 for the full method).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Compared against expert-designed operators in the ablation suite; Omni-Zero is generally inferior to Omni and to some baselines in aggregate metrics, though still competitive on certain tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Novelty defined via cosine-distance-based novelty score over per-case errors (Equation 3 in appendix); stage-weighted trade-off function 0.35+0.3*(1 - t/T_max^0.8) is used.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Similar token and runtime behavior as other LLM-generated operators; bloat control reduces token costs significantly versus uncontrolled runs.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Meta-evolution N=20; inner GP population size 100</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td>Partially — shows stage-aware and diversity mechanisms, but lacks complementarity and specificity components so specialization is weaker compared to Omni.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLMs can generate competent selection operators without domain-specific prompts (Omni-Zero), demonstrating intrinsic priors, but domain knowledge inclusion materially improves final performance and reduces pathological behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Omni-Zero does not consider complementarity or specificity and can be overly dominated by mean squared error; less robust on some tasks and misses components that boost cross-task generalization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1987.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Holo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Holo selection operator (LLM-discovered variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An alternative LLM-discovered selection operator (distinct from Omni) that emphasizes interpretability and obtains strong performance with smaller resulting models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Holo selection operator</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>selection</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>A discovered Python selection operator differing in implemented heuristics from Omni; detailed code in supplementary (Code 4). Holo emphasizes interpretability and produces competitive or smaller model sizes while achieving high R^2, implementing vectorized operations and multi-criteria selection.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution via LLM in-context learning (same outer/inner loop as LLM-Meta-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>program (Python function)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>test R^2, model tree size</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Reported to outperform expert-designed baselines on SRBench test R^2; complexity (tree size) is competitive and slightly smaller than Omni in reported figures.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Outperforms multiple expert-designed selection operators in reported comparisons (Wilcoxon tests presented); exact numeric baselines not exhaustively listed in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Statistically significant improvement compared to several baselines (figures show Holo > many expert operators), and Holo yields slightly smaller trees than Omni.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Competitive; complexity smaller so deployment cost reduced; selection time comparable to Omni.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Evaluated under same GP experimental settings (inner population 100, generations 100 for benchmark runs).</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Multiple distinct high-performing selection operators can be discovered by LLM-Meta-SR; Holo trades off slightly differently from Omni to produce smaller models while preserving or improving accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No specific failure case beyond general LLM bloat/bug risks; fewer details provided in main text about small-dataset behavior.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1987.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM Crossover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based crossover operator (meta-level)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-evolution crossover operator implemented via an LLM prompt that generates offspring selection-operator code by combining code fragments and performance vectors of two parent operators.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>LLM Crossover</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>crossover</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Given two parent selection-operator programs and their per-dataset score vectors, the LLM is prompted (crossover prompt) to synthesize a new operator by retrieving/composing complementary building blocks; semantic feedback (full score vectors) and complementarity retrieval (µ_i complementarity measure) guide parent pairing and prompt content. The LLM aims to produce concise, vectorized Python code that integrates effective components from both parents.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution where offspring generation is performed by an LLM using in-context learning (few-shot examples + parent code + performance vectors); outer evolution selects best operators based on their evaluated fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>program (text/code) generated by LLM</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>meta-evolution of selection operators for symbolic regression (code-as-operators)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>fitness of resulting selection operator measured by average validation/test R^2 on inner SR datasets; also code length and token count for bloat considerations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Crossover combining complementary parents produced offspring that performed well across multiple datasets (example in paper: parent1 strong on dataset4 and parent2 on dataset3 → offspring strong on both), demonstrating directional search vs random mutation; quantitative per-case numbers are shown in figures but not summarized as a single scalar improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Parent complementarity µ_i = (1/d) sum_j max(s_a,j, s_i,j) used to retrieve complementary parent; offspring code similarity penalized during survival selection with CodeBLEU.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Generative LLM calls per offspring (N−M per generation) incur token and compute costs; bloat control and line limits are used to reduce token counts. Meta-evolution used N=20 population, generating 19 crossover candidates and 1 mutation candidate per generation in the main experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Meta-evolution: N=20 (19 crossover-generated per generation, 1 mutation-generated).</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td>Yes — semantics-aware pairing encourages combining complementary behaviors producing offspring specialized to broader instance coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-based crossover can synthesize semantically meaningful intermediate programs (not mere concatenations), allowing directional recombination of capabilities and producing offspring that cover complementary strengths of parents.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>LLM crossover can produce overly long or subtly buggy code if not constrained; requires semantic feedback and domain-knowledge prompts to be most effective.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1987.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM Mutate</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based mutation operator (meta-level)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A meta-evolution mutation operator implemented by prompting an LLM to produce variants of the current elite selection operator, intended to explore novel code variants in the neighborhood of the elite.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>LLM Mutate</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>mutation</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Given the elite operator O* (best in current generation), the LLM is prompted (mutation prompt) to produce a mutated variant O_mut by making localized or structural code modifications; mutation uses in-context examples and the elite code as baseline to guide generation, aiming at novelty while retaining useful components.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution using LLM in-context learning; mutation prompt supplies baseline code and asks for variant.</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>program (Python code)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>meta-evolution over selection operators for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>fitness of mutated operator (average validation R^2 across inner SR datasets), code length, token count</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Mutation explores local neighborhood around elite; experiments investigated different crossover/mutation ratios and found performance depends on presence/absence of domain knowledge (smaller mutation rate better when domain knowledge present; larger mutation helpful when domain knowledge absent).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Each mutation requires an LLM call; main experiments used M=1 mutated individual per generation (cost small relative to crossover-heavy generation but still nontrivial); cost sensitive to token count and bloat.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Meta-evolution N=20 with M=1 mutated candidate per generation in main setup (other experiments varied ratios e.g., 15 crossover + 5 mutation).</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td>Mutation encourages local refinement of elite behaviors; ablation shows different mutation ratios affect exploration vs exploitation depending on prompt/domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLM-based mutation can generate useful local variants, but optimal mutation rate depends on prompt/domain knowledge; with domain knowledge a low mutation rate sufficed, while without it a higher mutation ratio improved exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>LLM mutation can still produce bloated or noncompliant code; relies on careful prompt design and bloat control to avoid token/cost explosion.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1987.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bloat Control</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bloat control (prompt-based length limit + multi-objective survival selection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-pronged strategy to reduce code bloat in LLM-generated operators: (1) instruct the LLM to produce code within a target maximum number of non-empty lines via the prompt, and (2) apply a multi-objective survival selection that trades off operator fitness and code length while penalizing code similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Bloat control (prompt-based + survival selection)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Prompt-based constraint: prompts embed a target maximum line count ℓ_target (line-based limit preferred to token counts). Multi-objective survival: operators represented as tuples (fitness, length); weak Pareto dominance is computed (f_i >= f_j and ℓ_i <= ℓ_j), and dominated operators are penalized by code similarity (CodeBLEU) to compute a dominance score s(O_j) = Σ_{O_i ⪰ O_j} - sim(O_i,O_j); top-N by score survive. This encourages concise, diverse operators.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>explicit constraint via prompting plus multi-objective selection within meta-evolution (Pareto-based survival using CodeBLEU similarity as penalty).</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>policy over generation via prompt constraints and an evolutionary survival selection mechanism (not a neural model representation)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>code (selection operator programs)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>code length (lines), token count, operator fitness (validation R^2), and cost (LLM token usage)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Applying bloat control led to substantially reduced token counts and more interpretable code; in experiments bloat control produced programs that stabilized (reported around ~50 lines in one analysis) and achieved faster improvements in objective score compared to uncontrolled runs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Bloat control materially reduced token counts and improved meta-evolution convergence and interpretability; objective scores improved faster with bloat control versus no bloat control (figures in paper show faster objective score increase).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Code similarity measured by CodeBLEU used in survival selection; novelty implicitly encouraged by penalizing similarity from dominating operators.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Bloat control reduces LLM token consumption substantially and thus lowers monetary/compute cost of meta-evolution; exact token reductions shown in Figure 12 but not given as a single scalar in text.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Applies to meta-evolution population (N=20) and offspring sets; survival picks top-N from combined parent+offspring.</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prompt-based length constraints combined with Pareto-based survival selection (using CodeBLEU) effectively reduce LLM code bloat, lower token costs, maintain diversity, and accelerate objective improvements during meta-evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Line-based limits are advisory (LLMs may not always obey); evolved code still occasionally exceeded intended brevity and required survival selection to enforce trade-offs; bloat control cannot prevent all subtle logical bugs that arise from limited exposure to small datasets.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1987.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1987.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantics-Aware Selection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantics-aware selection / complementarity-based pairing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A strategy to select parents for meta-level crossover by using per-dataset performance vectors to compute complementarity, favoring pairs that have complementary strengths rather than merely high average performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Semantics-aware selection (complementarity retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>selection / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Given an operator population P with per-dataset score vectors s_i (length d), randomly sample the first parent O_a and compute for each candidate O_i the complementarity score µ_i = (1/d) ∑_j max(s_a,j, s_i,j). The candidate with maximum µ_i is chosen as the second parent O_b (i* = argmax µ_i). Additionally, the full per-dataset score vectors (not aggregates) are provided to the LLM as semantic feedback during offspring generation so the LLM can reason about behavior across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>meta-evolution with semantic feedback guiding LLM prompts and complementarity-driven parent retrieval (retrieval-augmented generation idea).</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>analytic complementarity score + programmatic prompt usage for LLM generation</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>meta-evolution of selection operators for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>meta-evolution objective (average validation R^2 of generated operator across training datasets), semantic diversity (t-SNE visualizations of per-dataset score vectors)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Semantic-aware selection substantially improved meta-evolution outcomes vs random selection: ablation removing semantics reduced objective scores (figures and t-SNE visualizations show fewer diverse/complementary parent pairings and slower improvement).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Complementarity µ_i; t-SNE visualizations of 4-dimensional score vectors; counting of solutions achieving top-3 per-dataset performance used to demonstrate semantic diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Computing complementarity scores and providing full score vectors to LLMs adds modest overhead relative to standard aggregate-score evolution; overall meta-evolution cost dominated by LLM generation/evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>Meta-evolution N=20 (complementarity computed across population of 20 each generation).</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td>Yes — semantics-aware pairing leads to combining complementary behaviors and producing offspring that cover multiple datasets; analysis shows offspring perform well on datasets where parents individually excelled.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using per-instance semantic feedback and complementarity-aware parent selection helps the LLM synthesize operators that combine complementary strengths, improving generalization across tasks compared to average-score-guided evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires per-dataset evaluation history (semantic vectors) which increases evaluation bookkeeping; purely random parent selection (baseline) can still avoid premature convergence but is inferior to semantics-aware retrieval.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mathematical discoveries from program search with large language models <em>(Rating: 2)</em></li>
                <li>Language model crossover: Variation through few-shot prompting <em>(Rating: 2)</em></li>
                <li>Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model <em>(Rating: 2)</em></li>
                <li>Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems <em>(Rating: 1)</em></li>
                <li>Automl-zero: Evolving machine learning algorithms from scratch <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1987",
    "paper_id": "paper-280561003",
    "extraction_schema_id": "extraction-schema-45",
    "extracted_data": [
        {
            "name_short": "Omni",
            "name_full": "Omni selection operator (LLM-evolved)",
            "brief_description": "A selection operator discovered by LLM-Meta-SR via meta-evolution; it integrates semantics (per-instance score vectors), interpretability (model size/height), stage-aware pressure, complementarity, and vectorized operations to select parents for GP.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Omni selection operator",
            "operator_type": "selection",
            "operator_description": "A Python program (generated by an LLM) that selects parents in genetic programming by (1) computing subset MSEs over structured+random subsets to prioritize specificity, (2) measuring complexity via node count and tree height to bias towards interpretability, (3) selecting the first parent by ranking on subset MSE then complexity, and (4) selecting the second parent by computing absolute cosine similarity between residuals (semantic complementarity) combined with a stage-dependent complexity penalty; the operator receives per-individual vectors (case-errors, predictions, tree nodes/height) and the evolutionary stage and outputs promising parent individuals. It is vectorized (NumPy-friendly) and includes stage-aware linear/nonlinear weighting to trade off exploration/exploitation.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution using an LLM (in-context learning): outer evolutionary loop evolves operators via LLM-based crossover/mutation guided by historical performance vectors; inner GP loop evaluates operators on SR tasks to compute fitness.",
            "operator_representation": "program (Python function / code fragment generated by an LLM)",
            "domain_type": "numerical / symbolic regression (programs as symbolic expressions)",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "average test R^2 (validation/test R^2 across datasets), model size (tree node count), training time, diversity (cosine-distance-based), and code length",
            "performance_learned_operator": "Meta-evolution best objective score reported: median historical best average test R^2 ≈ 0.86 (LLM-Meta-SR run reported in Table 1); produced selection code length ≈ 48 lines (median historical best). Omni (when applied within GP/RAG-SR) yielded top median test R^2 across 116 SRBench datasets and dominated in Pareto comparisons (accuracy vs model size).",
            "performance_fixed_operator": "Compared against nine expert-designed selection operators and many baselines (e.g., AutoLex, CPS, PLex, DALex, Boltzmann sampling variants); baselines produced lower median R^2s (examples in ablation: alternative settings show drops to ~0.84, 0.79 etc.), and many baselines were statistically indistinguishable from each other while Omni was significantly better in Wilcoxon tests (Benjamini-Hochberg corrected). Exact per-baseline numeric R^2s are provided in figures/tables in the paper but not enumerated for every baseline in the main text.",
            "performance_improvement": "Reported as statistically significant improvements over expert-designed baselines; meta-evolution objective score improved to 0.86 vs ablated variants (e.g., W/O semantics or W/O knowledge often 0.84→0.79), and Omni produced better median R^2 and smaller models when integrated into RAG-SR (best among 26 methods across 116 datasets).",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Population diversity measured via cosine distance between residuals; complementarity score µ_i = (1/d) sum_j max(s_a,j, s_i,j) used to retrieve complementary parents; code similarity for survival selection measured with CodeBLEU and used to penalize dominated operators.",
            "transfer_learning": true,
            "transfer_results": "Applied Omni to RAG-SR (a transformer-assisted SR algorithm) producing RAG-SR-Omni; RAG-SR-Omni outperformed the original RAG-SR and other SOTA methods across 116 datasets (median R^2 and Pareto-optimal on accuracy vs model size), demonstrating the operator transfers to a different algorithmic context.",
            "computational_cost": "Omni incurs slightly higher selection time (multi-criteria computations) compared to simpler operators, but reduces overall evaluation/deployment cost by biasing toward smaller models; bloat control reduces LLM token costs. No absolute FLOPS/time-per-evaluation table for Omni vs each baseline is given, but figures show training time marginally higher for Omni while deployment inference cost lower due to smaller models.",
            "population_size": "Meta-evolution population size N=20; inner GP population size λ=100 (experiments use population size 100 and 100 generations for benchmark runs).",
            "cold_start_addressed": true,
            "operator_specialization": "Yes — semantic analysis and t-SNE of per-dataset score vectors show operators specialize (top-3 per-dataset solutions varied across datasets); Omni favors solutions that perform well on complementary subsets and maintains diverse population behaviors across tasks.",
            "key_findings": "An LLM-evolved selection operator (Omni) that leverages per-instance semantic feedback, stage-awareness, and complexity regularization can outperform multiple hand-designed selection operators on symbolic regression, producing better accuracy and more parsimonious models and improving downstream algorithms when integrated (e.g., RAG-SR).",
            "limitations_or_failures": "LLM-generated code is prone to bloat (excessive length) and occasional logical bugs on small datasets (structured division producing empty subsets); domain knowledge in prompts is important — absence causes largest performance drops; Omni has slightly higher selection runtime.",
            "uuid": "e1987.0"
        },
        {
            "name_short": "Omni-Zero",
            "name_full": "Omni-Zero (Omni evolved without domain knowledge)",
            "brief_description": "A selection operator evolved by LLM-Meta-SR when domain-knowledge guidance is removed; it demonstrates that LLMs can produce viable operators from internal priors but lacks some specialized components.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Omni-Zero selection operator",
            "operator_type": "selection",
            "operator_description": "LLM-generated Python selection operator that implements diversity-awareness (cosine-distance-based novelty), stage-awareness (a non-linear weighting function to trade off error vs novelty), and interpretability-awareness (nodes+height complexity metric), but it does not model specificity (subset-based selection) nor explicit complementarity between two parents; selection is largely dominated by mean squared error under some conditions.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution with LLM in-context learning, but prompts omit domain knowledge principles (i.e., 'evolve from scratch' or 'AutoML-Zero'-style).",
            "operator_representation": "program (Python function)",
            "domain_type": "symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "average R^2, diversity (cosine-distance novelty), code length",
            "performance_learned_operator": "Per ablation results, Omni-Zero achieves reasonable performance but is worse than Omni with domain knowledge; ablation shows removing domain knowledge causes the largest performance drop (examples in Table 1 show lower objective scores e.g., 0.79 vs 0.86 for the full method).",
            "performance_fixed_operator": "Compared against expert-designed operators in the ablation suite; Omni-Zero is generally inferior to Omni and to some baselines in aggregate metrics, though still competitive on certain tasks.",
            "performance_improvement": null,
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Novelty defined via cosine-distance-based novelty score over per-case errors (Equation 3 in appendix); stage-weighted trade-off function 0.35+0.3*(1 - t/T_max^0.8) is used.",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Similar token and runtime behavior as other LLM-generated operators; bloat control reduces token costs significantly versus uncontrolled runs.",
            "population_size": "Meta-evolution N=20; inner GP population size 100",
            "cold_start_addressed": true,
            "operator_specialization": "Partially — shows stage-aware and diversity mechanisms, but lacks complementarity and specificity components so specialization is weaker compared to Omni.",
            "key_findings": "LLMs can generate competent selection operators without domain-specific prompts (Omni-Zero), demonstrating intrinsic priors, but domain knowledge inclusion materially improves final performance and reduces pathological behaviors.",
            "limitations_or_failures": "Omni-Zero does not consider complementarity or specificity and can be overly dominated by mean squared error; less robust on some tasks and misses components that boost cross-task generalization.",
            "uuid": "e1987.1"
        },
        {
            "name_short": "Holo",
            "name_full": "Holo selection operator (LLM-discovered variant)",
            "brief_description": "An alternative LLM-discovered selection operator (distinct from Omni) that emphasizes interpretability and obtains strong performance with smaller resulting models.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Holo selection operator",
            "operator_type": "selection",
            "operator_description": "A discovered Python selection operator differing in implemented heuristics from Omni; detailed code in supplementary (Code 4). Holo emphasizes interpretability and produces competitive or smaller model sizes while achieving high R^2, implementing vectorized operations and multi-criteria selection.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution via LLM in-context learning (same outer/inner loop as LLM-Meta-SR)",
            "operator_representation": "program (Python function)",
            "domain_type": "symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "test R^2, model tree size",
            "performance_learned_operator": "Reported to outperform expert-designed baselines on SRBench test R^2; complexity (tree size) is competitive and slightly smaller than Omni in reported figures.",
            "performance_fixed_operator": "Outperforms multiple expert-designed selection operators in reported comparisons (Wilcoxon tests presented); exact numeric baselines not exhaustively listed in main text.",
            "performance_improvement": "Statistically significant improvement compared to several baselines (figures show Holo &gt; many expert operators), and Holo yields slightly smaller trees than Omni.",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Competitive; complexity smaller so deployment cost reduced; selection time comparable to Omni.",
            "population_size": "Evaluated under same GP experimental settings (inner population 100, generations 100 for benchmark runs).",
            "cold_start_addressed": false,
            "operator_specialization": null,
            "key_findings": "Multiple distinct high-performing selection operators can be discovered by LLM-Meta-SR; Holo trades off slightly differently from Omni to produce smaller models while preserving or improving accuracy.",
            "limitations_or_failures": "No specific failure case beyond general LLM bloat/bug risks; fewer details provided in main text about small-dataset behavior.",
            "uuid": "e1987.2"
        },
        {
            "name_short": "LLM Crossover",
            "name_full": "LLM-based crossover operator (meta-level)",
            "brief_description": "A meta-evolution crossover operator implemented via an LLM prompt that generates offspring selection-operator code by combining code fragments and performance vectors of two parent operators.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "LLM Crossover",
            "operator_type": "crossover",
            "operator_description": "Given two parent selection-operator programs and their per-dataset score vectors, the LLM is prompted (crossover prompt) to synthesize a new operator by retrieving/composing complementary building blocks; semantic feedback (full score vectors) and complementarity retrieval (µ_i complementarity measure) guide parent pairing and prompt content. The LLM aims to produce concise, vectorized Python code that integrates effective components from both parents.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution where offspring generation is performed by an LLM using in-context learning (few-shot examples + parent code + performance vectors); outer evolution selects best operators based on their evaluated fitness.",
            "operator_representation": "program (text/code) generated by LLM",
            "domain_type": "meta-evolution of selection operators for symbolic regression (code-as-operators)",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "fitness of resulting selection operator measured by average validation/test R^2 on inner SR datasets; also code length and token count for bloat considerations.",
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": "Crossover combining complementary parents produced offspring that performed well across multiple datasets (example in paper: parent1 strong on dataset4 and parent2 on dataset3 → offspring strong on both), demonstrating directional search vs random mutation; quantitative per-case numbers are shown in figures but not summarized as a single scalar improvement.",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Parent complementarity µ_i = (1/d) sum_j max(s_a,j, s_i,j) used to retrieve complementary parent; offspring code similarity penalized during survival selection with CodeBLEU.",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Generative LLM calls per offspring (N−M per generation) incur token and compute costs; bloat control and line limits are used to reduce token counts. Meta-evolution used N=20 population, generating 19 crossover candidates and 1 mutation candidate per generation in the main experiment.",
            "population_size": "Meta-evolution: N=20 (19 crossover-generated per generation, 1 mutation-generated).",
            "cold_start_addressed": false,
            "operator_specialization": "Yes — semantics-aware pairing encourages combining complementary behaviors producing offspring specialized to broader instance coverage.",
            "key_findings": "LLM-based crossover can synthesize semantically meaningful intermediate programs (not mere concatenations), allowing directional recombination of capabilities and producing offspring that cover complementary strengths of parents.",
            "limitations_or_failures": "LLM crossover can produce overly long or subtly buggy code if not constrained; requires semantic feedback and domain-knowledge prompts to be most effective.",
            "uuid": "e1987.3"
        },
        {
            "name_short": "LLM Mutate",
            "name_full": "LLM-based mutation operator (meta-level)",
            "brief_description": "A meta-evolution mutation operator implemented by prompting an LLM to produce variants of the current elite selection operator, intended to explore novel code variants in the neighborhood of the elite.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "LLM Mutate",
            "operator_type": "mutation",
            "operator_description": "Given the elite operator O* (best in current generation), the LLM is prompted (mutation prompt) to produce a mutated variant O_mut by making localized or structural code modifications; mutation uses in-context examples and the elite code as baseline to guide generation, aiming at novelty while retaining useful components.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution using LLM in-context learning; mutation prompt supplies baseline code and asks for variant.",
            "operator_representation": "program (Python code)",
            "domain_type": "meta-evolution over selection operators for symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "fitness of mutated operator (average validation R^2 across inner SR datasets), code length, token count",
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": "Mutation explores local neighborhood around elite; experiments investigated different crossover/mutation ratios and found performance depends on presence/absence of domain knowledge (smaller mutation rate better when domain knowledge present; larger mutation helpful when domain knowledge absent).",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Each mutation requires an LLM call; main experiments used M=1 mutated individual per generation (cost small relative to crossover-heavy generation but still nontrivial); cost sensitive to token count and bloat.",
            "population_size": "Meta-evolution N=20 with M=1 mutated candidate per generation in main setup (other experiments varied ratios e.g., 15 crossover + 5 mutation).",
            "cold_start_addressed": false,
            "operator_specialization": "Mutation encourages local refinement of elite behaviors; ablation shows different mutation ratios affect exploration vs exploitation depending on prompt/domain knowledge.",
            "key_findings": "LLM-based mutation can generate useful local variants, but optimal mutation rate depends on prompt/domain knowledge; with domain knowledge a low mutation rate sufficed, while without it a higher mutation ratio improved exploration.",
            "limitations_or_failures": "LLM mutation can still produce bloated or noncompliant code; relies on careful prompt design and bloat control to avoid token/cost explosion.",
            "uuid": "e1987.4"
        },
        {
            "name_short": "Bloat Control",
            "name_full": "Bloat control (prompt-based length limit + multi-objective survival selection)",
            "brief_description": "A two-pronged strategy to reduce code bloat in LLM-generated operators: (1) instruct the LLM to produce code within a target maximum number of non-empty lines via the prompt, and (2) apply a multi-objective survival selection that trades off operator fitness and code length while penalizing code similarity.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Bloat control (prompt-based + survival selection)",
            "operator_type": "other",
            "operator_description": "Prompt-based constraint: prompts embed a target maximum line count ℓ_target (line-based limit preferred to token counts). Multi-objective survival: operators represented as tuples (fitness, length); weak Pareto dominance is computed (f_i &gt;= f_j and ℓ_i &lt;= ℓ_j), and dominated operators are penalized by code similarity (CodeBLEU) to compute a dominance score s(O_j) = Σ_{O_i ⪰ O_j} - sim(O_i,O_j); top-N by score survive. This encourages concise, diverse operators.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "explicit constraint via prompting plus multi-objective selection within meta-evolution (Pareto-based survival using CodeBLEU similarity as penalty).",
            "operator_representation": "policy over generation via prompt constraints and an evolutionary survival selection mechanism (not a neural model representation)",
            "domain_type": "code (selection operator programs)",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": null,
            "performance_metric": "code length (lines), token count, operator fitness (validation R^2), and cost (LLM token usage)",
            "performance_learned_operator": "Applying bloat control led to substantially reduced token counts and more interpretable code; in experiments bloat control produced programs that stabilized (reported around ~50 lines in one analysis) and achieved faster improvements in objective score compared to uncontrolled runs.",
            "performance_fixed_operator": null,
            "performance_improvement": "Bloat control materially reduced token counts and improved meta-evolution convergence and interpretability; objective scores improved faster with bloat control versus no bloat control (figures in paper show faster objective score increase).",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Code similarity measured by CodeBLEU used in survival selection; novelty implicitly encouraged by penalizing similarity from dominating operators.",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Bloat control reduces LLM token consumption substantially and thus lowers monetary/compute cost of meta-evolution; exact token reductions shown in Figure 12 but not given as a single scalar in text.",
            "population_size": "Applies to meta-evolution population (N=20) and offspring sets; survival picks top-N from combined parent+offspring.",
            "cold_start_addressed": false,
            "operator_specialization": null,
            "key_findings": "Prompt-based length constraints combined with Pareto-based survival selection (using CodeBLEU) effectively reduce LLM code bloat, lower token costs, maintain diversity, and accelerate objective improvements during meta-evolution.",
            "limitations_or_failures": "Line-based limits are advisory (LLMs may not always obey); evolved code still occasionally exceeded intended brevity and required survival selection to enforce trade-offs; bloat control cannot prevent all subtle logical bugs that arise from limited exposure to small datasets.",
            "uuid": "e1987.5"
        },
        {
            "name_short": "Semantics-Aware Selection",
            "name_full": "Semantics-aware selection / complementarity-based pairing",
            "brief_description": "A strategy to select parents for meta-level crossover by using per-dataset performance vectors to compute complementarity, favoring pairs that have complementary strengths rather than merely high average performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Semantics-aware selection (complementarity retrieval)",
            "operator_type": "selection / hybrid",
            "operator_description": "Given an operator population P with per-dataset score vectors s_i (length d), randomly sample the first parent O_a and compute for each candidate O_i the complementarity score µ_i = (1/d) ∑_j max(s_a,j, s_i,j). The candidate with maximum µ_i is chosen as the second parent O_b (i* = argmax µ_i). Additionally, the full per-dataset score vectors (not aggregates) are provided to the LLM as semantic feedback during offspring generation so the LLM can reason about behavior across tasks.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "meta-evolution with semantic feedback guiding LLM prompts and complementarity-driven parent retrieval (retrieval-augmented generation idea).",
            "operator_representation": "analytic complementarity score + programmatic prompt usage for LLM generation",
            "domain_type": "meta-evolution of selection operators for symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": false,
            "performance_metric": "meta-evolution objective (average validation R^2 of generated operator across training datasets), semantic diversity (t-SNE visualizations of per-dataset score vectors)",
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": "Semantic-aware selection substantially improved meta-evolution outcomes vs random selection: ablation removing semantics reduced objective scores (figures and t-SNE visualizations show fewer diverse/complementary parent pairings and slower improvement).",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Complementarity µ_i; t-SNE visualizations of 4-dimensional score vectors; counting of solutions achieving top-3 per-dataset performance used to demonstrate semantic diversity.",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Computing complementarity scores and providing full score vectors to LLMs adds modest overhead relative to standard aggregate-score evolution; overall meta-evolution cost dominated by LLM generation/evaluation.",
            "population_size": "Meta-evolution N=20 (complementarity computed across population of 20 each generation).",
            "cold_start_addressed": false,
            "operator_specialization": "Yes — semantics-aware pairing leads to combining complementary behaviors and producing offspring that cover multiple datasets; analysis shows offspring perform well on datasets where parents individually excelled.",
            "key_findings": "Using per-instance semantic feedback and complementarity-aware parent selection helps the LLM synthesize operators that combine complementary strengths, improving generalization across tasks compared to average-score-guided evolution.",
            "limitations_or_failures": "Requires per-dataset evaluation history (semantic vectors) which increases evaluation bookkeeping; purely random parent selection (baseline) can still avoid premature convergence but is inferior to semantics-aware retrieval.",
            "uuid": "e1987.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mathematical discoveries from program search with large language models",
            "rating": 2
        },
        {
            "paper_title": "Language model crossover: Variation through few-shot prompting",
            "rating": 2
        },
        {
            "paper_title": "Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model",
            "rating": 2
        },
        {
            "paper_title": "Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems",
            "rating": 1
        },
        {
            "paper_title": "Automl-zero: Evolving machine learning algorithms from scratch",
            "rating": 1
        }
    ],
    "cost": 0.0217825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression</p>
<p>Hengzhe Zhang hengzhe.zhang@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Qi Chen qi.chen@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Bing Xue bing.xue@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>Wolfgang Banzhaf banzhafw@msu.edu 
Department of Computer Science and Engineering
Michigan State University
48824East LansingMIUSA</p>
<p>Mengjie Zhang mengjie.zhang@ecs.vuw.ac.nz 
Centre for Data Science and Artificial Intelligence &amp; School of Engineering and Computer Science
Victoria University of Wellington
PO Box 6006140WellingtonNew Zealand</p>
<p>LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression
51E7499141BBDBD5B93357566D110BE5
Large language models (LLMs) have revolutionized algorithm development, yet their application in symbolic regression, where algorithms automatically discover symbolic expressions from data, remains constrained and is typically designed manually by human experts.In this paper, we propose a meta learning framework that enables LLMs to automatically design selection operators for evolutionary symbolic regression algorithms.We first identify two key limitations in existing LLM-based algorithm evolution techniques: a lack of semantic guidance and code bloat.The absence of semantic awareness can lead to ineffective exchange of useful code components, and bloat results in unnecessarily complex components, both of which can reduce the interpretability of the designed algorithm or hinder evolutionary learning progress.To address these issues, we enhance the LLM-based evolution framework for meta symbolic regression with two key innovations: a complementary, semantics-aware selection operator and bloat control.Additionally, we embed domain knowledge into the prompt, enabling the LLM to generate more effective and contextually relevant selection operators.Our experimental results on symbolic regression benchmarks show that LLMs can devise selection operators that outperform nine expert-designed baselines, achieving state-of-the-art performance.Moreover, the evolved operator can further improve the state-of-the-art symbolic regression algorithm, achieving the best performance among 26 symbolic regression and machine learning algorithms across 116 regression datasets.This demonstrates that LLMs can exceed expert-level algorithm design for symbolic regression.</p>
<p>Introduction</p>
<p>Symbolic regression (SR) is the task of discovering mathematical expressions that accurately model a given dataset.It is widely used in domains such as finance (Shi et al. 2025), education (Shen et al. 2024),chemistry (Chen et al. 2025), andphysics (Feng et al. 2025), due to its interpretability and ability to uncover underlying relationships.Formally, given a dataset D = {x (i) , y (i) } N i=1 , where x (i) ∈ R d are input features and y (i) ∈ R are target values, the goal is to find a symbolic expression f * ∈ F from a space of candidate expressions F that minimizes a loss function L:</p>
<p>f * = arg min f ∈F L(f (x), y).</p>
<p>(1)</p>
<p>Many SR algorithms have been proposed, including evolutionary (Jiang and Xue 2024;Fong and Motani 2024b), neural (Biggio et al. 2021;Kamienny et al. 2022), and searchbased (Kahlmeyer, Fischer, and Giesen 2025;Yu et al. 2025) approaches.In recent years, there has been growing interest in hybrid methods that combine the flexibility of evolutionary algorithms with the learning capabilities of neural networks (Landajuela et al. 2022;Grayeli et al. 2024;Zhang et al. 2025).</p>
<p>In both evolutionary (Jiang and Xue 2024;Fong and Motani 2024b) and neural-evolutionary (Landajuela et al. 2022;Grayeli et al. 2024;Zhang et al. 2025) symbolic regression algorithms, the system follows an iterative optimization process in which solutions are progressively refined by selecting promising candidates.In this process, the selection operator responsible for identifying candidate solutions worth refining, plays a key role in system effectiveness.However, current selection operators are typically manually designed by experts, requiring significant effort and trial-and-error, which can limit the pace of progress.Ideally, an automated algorithm design framework capable of generating effective selection operators for symbolic regression would substantially enhance research and development efficiency in this area.</p>
<p>Large language models (LLMs) have recently emerged as powerful tools for automated heuristic design in various optimization tasks (Romera-Paredes et al. 2024;Liu et al. 2024a;Ye et al. 2024).However, most existing frameworks primarily focus on generating heuristic rules for specific combinatorial optimization tasks.In this paper, we pursue a more ambitious goal: to automatically design a core algorithmic component-specifically, the selection operator-in evolutionary symbolic regression, with the aim of achieving strong performance across a wide range of regression tasks.While frameworks such as FunSearch (Romera-Paredes et al. 2024), EoH (Liu et al. 2024a), and ReEvo (Ye et al. 2024) lay groundwork for algorithm evolution, two challenges remain underexplored in LLM-driven algorithm evolution.The first is the underutilization of semantic information in the generated code.Here, we define semantic information as the performance of an algorithm on individual task instances.Typically, only the average performance across all training instances is provided to the LLM to guide code generation (Huang et al. 2025a), which overlooks fine-grained behavior.As illustrated in Figure 1, consider a scenario with three algorithms: the first two perform well on the first dataset but poorly on the second, while the third shows the opposite pattern.Despite their contrasting behaviors, all three algorithms may exhibit similar average performance.However, presenting the first two algorithms together to the LLM offers limited benefit, as they exhibit redundant patterns-both succeeding and failing on the same datasets.In contrast, combining the first and third algorithms allows the LLM to integrate complementary strengths, potentially generating an algorithm that performs well on both datasets.Thus, incorporating semantic information is crucial for effective algorithm evolution.</p>
<p>The second challenge is complexity bias, illustrated in Figure 2. LLMs tend to generate overly long or intricate code during optimization, similar to code bloat in genetic programming (Banzhaf et al. 1998).This results in the accumulation of redundant or non-functional logic, which impairs interpretability, wastes a large number of tokens, and slows optimization.As shown in Figure 2, such complexity can lead to performance stagnation, ultimately limiting the effectiveness of evolution.</p>
<p>In this paper, we propose an LLM-driven method for meta symbolic regression to automatically design selection operators1 .The main contributions are as follows:</p>
<p>• We propose an LLM-driven meta symbolic regression framework to automatically design selection operators using in-context learning.The LLM learns from design and evaluation history to automatically discover generalizable operators that consistently outperform human-designed counterparts across a wide range of unseen datasets.• We identify the issue of bloat in LLM-based code generation and introduce a bloat control strategy that improves both the interpretability of the evolved code and the effectiveness of the evolutionary process.• We propose semantic-based feedback and complementary selection mechanisms to fully leverage semantic information during LLM-driven generation, explicitly guiding algorithm evolution by integrating effective building blocks and enhancing learning performance.• We design ideal properties of selection operators based on domain knowledge to craft more effective prompts that guide LLMs in generating high-quality selection operators.</p>
<p>2 Background and Related Work</p>
<p>Selection Operators in Symbolic Regression</p>
<p>There has been significant research on designing selection operators for symbolic regression, including tournament selection (Xie and Zhang 2012), Boltzmann sampling (Shojaee et al. 2025;Romera-Paredes et al. 2024)</p>
<p>LLMs for Symbolic Regression</p>
<p>Early work on LLMs for symbolic regression focused on specialized language models (Kamienny et al. 2022;Biggio et al. 2021), often assisted by Monte Carlo Tree Search (Kamienny et al. 2023;Shojaee et al. 2024) or evolutionary algorithms (Zhang et al. 2025).With the advent of generalpurpose LLMs, their use in symbolic regression has attracted increasing attention (Shojaee et al. 2025), either through the FunSearch framework (Romera-Paredes et al. 2024) or via integration with evolutionary algorithm frameworks (Grayeli et al. 2024).In these studies, LLMs effectively replace traditional crossover and mutation operators to generate candidate solutions, but selection operators are still manually designed.This motivates the exploration of automated selection operator design using LLMs.Some recent work incorporates dataset descriptions into symbolic regression, referring to this as "semantics" (Liu, Huynh, and van der Schaar 2025).However, this differs from the concept of semantics in genetic programming (Moraglio, Krawiec, and Johnson 2012), where it refers to the behavior of a program.In LLM-based program evolution, the finegrained behavior of candidate programs is often overlooked and reduced to aggregate scores, which can obscure meaningful information and hinder evolutionary progress.</p>
<p>Solution Representation</p>
<p>Each solution is a piece of code representing a selection operator.The input to the selection operator is a list of individuals.Each individual contains a list representing squared error, a list of predicted values, and a list of nodes, which can be used to compute the height and depth of the symbolic tree.The evolutionary status, specifically the ratio between the current and total generations, is also provided.The expected output of the selection operator is a list of promising symbolic trees.The structure of the selection operator is presented in Code 7 of the supplementary material.</p>
<p>Meta-Evolution Workflow</p>
<p>The meta-evolution algorithm consists of two nested loops: an outer meta-evolution loop and an inner symbolic regression loop.The outer loop generates new selection operators, while the inner loop evaluates their performance.An overview of the workflow is shown in Figure 3.</p>
<p>Let
P (t) = {O (t) 1 , O (t) 2 , . . . , O(t)
N } denote the population of selection operators at generation t, where N is the population size and each
O (t) i is a selection operator. The fitness of each operator O (t) i , denoted f (O (t)
i ), is evaluated based on its performance in the symbolic regression loop.The metaevolution process includes the following components:</p>
<p>• Population Initialization: The initial population P (0)  is generated by prompting the LLM to produce N random selection operators.The details of the initialization prompts are provided in Appendix K of the supplementary material.∈ P (t) , its fitness is computed as f (O -Operator Crossover: For each pair (O
(t) i ) = 1 T T j=1 SR(O (t) i , D j ),(t) a , O (t) b ), a new operator is generated as O (t+1) new = LLM Crossover O (t) a , O (t) b
. The goal is to generate a new piece of code that combines effective building blocks from the selected parent operators, guided by their performance scores on the evaluated datasets.</p>
<p>-Operator</p>
<p>Mutation:
Let O * = arg max O (t) i ∈P (t) f (O (t)
i ) be the best-performing operator in generation t (Ye et al. 2024).Mutated variants are then generated as
O (t+1) mut = LLM Mutate(O * ),
with the objective of generating novel code based on the elite operator.The prompts used for crossover and mutation are provided in Appendix K. Solution generation leverages the in-context learning capability of LLMs (Gao and Das 2024), expecting that LLMs can generate better solutions by analyzing historical execution results.This process continues until a predefined number of generations T max is reached.The operator with the highest fitness value across all generations is selected as the final selection operator.</p>
<p>Semantics-Aware Evolution</p>
<p>Semantic-based Selection: In the meta-evolution scenario, the goal of the crossover operator is to combine the strengths of two LLM-generated selection operators.As introduced in Section 1, crossover benefits more from combining solutions with complementary strengths than from pairing generalists.</p>
<p>To this end, we propose a semantics-aware selection strategy, with the pseudocode provided in Algorithm 1.Because each selection operator O i ∈ P (t) has been evaluated across d datasets and is associated with a score vector s i = [s i,1 , . . ., s i,d ], we can compute a complementarity score for each candidate in the population.The process begins by randomly selecting the first parent O a ∈ P (t) .Random selection, as used in ReEvo (Ye et al. 2024) and HSEvo (Dat, Doan, and Binh 2025), helps mitigate premature convergence (Dat, Doan, and Binh 2025).Then, for each candidate O i ∈ P (t) , we compute a complementarity score:
µ i = 1 d d j=1 max(s a,j , s i,j ),(2)Compute µ i ← 1 d d j=1 max(s a,j , s i,j ) 4: end for 5: i * ← arg max i µ i 6: O b ← O i * // Retrieve Complement Operator 7: return O b
Semantic Feedback: The semantic selection strategy ensures that crossover is guided by semantically diverse behaviors.Furthermore, to enhance semantic awareness, we provide the full score vector s i of dataset-specific scores to the LLM in the solution generation stage, rather than averaging them into a single aggregate value.This enables the LLM to reason explicitly about behavioral differences across tasks.</p>
<p>Bloat Control</p>
<p>Prompt-based Length Limit: To mitigate code bloat in the evolution of selection operators, we incorporate a length constraint in the prompt during solution generation.For any operator O i ∈ P (t) , its code length is denoted by ℓ(O i ), measured as the number of non-empty, non-comment lines in the implementation.We choose to constrain the number of lines, rather than the number of tokens, because line count is less sensitive to variations in variable name length.Rather than enforcing a hard upper bound ℓ(O i ) ≤ L max , which is difficult to control during LLM generation, we embed the maximum length ℓ target directly into the prompt.For instance, the LLM is instructed: "Write a selection operator with code length ≤ ℓ target ."This prompt-guided strategy encourages the model to produce more concise programs.</p>
<p>Multi-Objective Survival Selection: Beyond promptbased constraints, we employ a multi-objective survival selection strategy based on both operator fitness and code length to further control bloat, since LLMs do not always follow instructions to generate code within a specified length.Each operator O i is represented as a tuple (f (O i ), ℓ(O i )), where f (O i ) denotes its average task performance across T tasks, and ℓ(O i ) denotes its code length.The parents for generating the next generation P (t+1) are selected from the combined set P (t) ∪ P offspring using a dominance-dissimilarity selection mechanism (Yao et al. 2025).</p>
<p>The key idea is to compute a dominance score for each operator based on weak Pareto dominance (Lin et al. 2022) and code similarity.An operator O i is said to weakly Pareto dominate another operator O j , denoted
O i ⪰ O j , if and only if f (O i ) ≥ f (O j ) and ℓ(O i ) ≤ ℓ(O j ).
For each such pair (O i , O j ), the score of O j is penalized by the code similarity sim(O i , O j ), computed using the CodeBLEU metric (Ren et al. 2020).The total dominance score of O j is then defined as s(O j ) = Oi⪰Oj −sim(O i , O j ).Operators are then ranked, and the top-N operators with higher scores are selected, as they are less frequently dominated and exhibit greater dissimilarity from dominating counterparts.This selection strategy encourages a trade-off between maximizing task performance and minimizing code complexity, effectively reducing operator bloat while maintaining diversity and effectiveness.</p>
<p>Incorporating Domain Knowledge into Prompts</p>
<p>Algorithm evolution requires deep domain expertise, which general-purpose LLMs often lack.To compensate, domain knowledge is commonly incorporated into prompts to enhance LLM-based algorithm evolution (Romera-Paredes et al. 2024;Liu et al. 2024a).For the design of selection operators, we embed the following principles into the prompt to guide the LLM toward generating more effective solutions: Diversity-aware: Purely objective-driven selection can cause premature convergence.To counter this, it is desirable to select models that perform well on different training instances to maintain population diversity.</p>
<p>Interpretability-aware: Interpretability, often measured by the number of nodes in a symbolic expression, is a critical criterion.Let n i denote the number of nodes in solution p i .The selection operator should favor solutions with smaller n i to promote simpler, more interpretable models.</p>
<p>Stage-aware: Selection pressure should adapt over time.In early generations (t ≪ T max ), it should favor exploration.In later stages (t ≈ T max ), it should prioritize exploitation of high-fitness solutions to encourage convergence.</p>
<p>Complementarity-aware: To effectively recombine useful traits, crossover should favor solutions with complementary strengths.Given performance vectors s i and s j over d instances, complementarity means selecting pairs with low correlation.Such combinations integrate distinct capabilities and can yield offspring that perform well across a broader range of instances.</p>
<p>Vectorization-aware: Vectorized operations are preferred, as they can be efficiently accelerated using NumPy or GPU computation.This improves the runtime efficiency of the evolved operator and reduces evaluation overhead during meta-evolution.</p>
<p>The prompt incorporating these domain knowledge principles is provided in Figure 34 of the supplementary material.</p>
<p>Experimental Settings</p>
<p>Meta-Evolution: The experiments are conducted using GPT-4.1 Mini.For the outer loop, the population size N is set to 20, the number of solutions generated by mutation M is set to 1, and the number of solutions generated by crossover is 19.The total number of generations is set to 20.A length limit of 30 lines is imposed to control operator complexity.For the inner loop, four datasets are selected to evaluate the quality of the generated selection operators.These datasets have OpenML IDs 505, 4544, 588, and 650, corresponding to the four highest-dimensional datasets in the contemporary symbolic regression benchmark (SRBench) (La Cava et al. 2021).High-dimensional datasets pose greater challenges for symbolic regression algorithms, and optimizing on these is likely to generalize well to both easy and hard problems.The number of generations in the inner loop is set to 30, and the population size is 100.More detailed experimental settings for the inner symbolic regression loop are provided in Appendix A of the supplementary material.All experiments are repeated three times (Yao et al. 2025) with random seeds set to 0, 1, and 2, to report the median and confidence intervals.</p>
<p>Symbolic Regression: For symbolic regression, experiments are conducted on 116 out of the 120 datasets in SRBench, excluding the 4 datasets used during the metaevolution phase to prevent potential data leakage.Each algorithm is evaluated using 10 independent runs per dataset to ensure statistically robust comparisons.The symbolic regression algorithm used is standard genetic programming with linear scaling, which is a widely adopted framework in symbolic regression research (Virgolin et al. 2021;Kronberger et al. 2022).The parameter settings are the same as those used in the inner symbolic regression loop, except that the number of generations is increased to 100.</p>
<p>Experimental Results</p>
<p>Meta-Evolution Results</p>
<p>In this section, we evaluate our meta-evolution framework (LLM-Meta-SR) against several ablated variants, including: without semantic evolution (W/O Semantics), without semantic evolution and bloat control (W/O SE+BC), without domain knowledge (W/O Knowledge), without domain knowledge and semantic evolution (W/O DK+SE), and without domain knowledge, semantic evolution, and bloat control (W/O DK+SE+BC).Since domain knowledge is not always available in practice, we include ablation studies under the setting without domain knowledge to evaluate how the proposed strategy performs in entirely new domains.In the W/O Semantics setting, random selection with identical objective prevention from ReEvo (Ye et al. 2024) is used as the baseline.In the W/O SE+BC setting, survival selection is replaced with direct population replacement and elitism, following the strategy used in ReEvo (Ye et al. 2024).In the W/O Knowledge setting, semantic evolution and bloat control are retained, but the domain knowledge prompt is removed.</p>
<p>Objective Score: The objective score is measured by the average test R 2 score of each selection operator across the four training datasets.For the W/O DK+SE+BC setting, only one run completed within 24 hours and is thus reported.The results in Figure 4, along with the numerical values presented in Table 1, show that the absence of domain knowledge causes the largest performance drop, highlighting the importance of domain knowledge introduced in Section 3.5 in guiding algorithm evolution.This is consistent with findings from FunSearch (Romera-Paredes et al. 2024) and EoH (Liu et al. 2024a) that LLMs often require external knowledge for guidance.</p>
<p>However, domain knowledge alone is insufficient to discover high-performing operators.As shown in Figure 4, semantic evolution plays a critical role in achieving higher objective scores, both with and without domain knowledge.To investigate the role of semantics, we visualize the semantic distribution of solutions over the first five generations in Figure 6.Each point represents a solution, colored by its average score across the four tasks.Positions are computed via t-SNE based on the four-dimensional score vector.The figure reveals that the number of solutions achieving top-3 performance on at least one dataset consistently exceeds three, indicating that top individuals by average score do not dominate all tasks.Additionally, the final subplot in Figure 6 shows that some solutions, marked with stars, achieve top-3 performance on at least one dataset despite having modest average scores.This illustrates that relying solely on average performance may overlook individuals with strong task-specific capabilities.To further understand how semantic-aware selection works, a real example of parent crossover is provided in Appendix D of the supplementary material, which further confirms the importance of semantic-aware selection for generating better offspring.These findings highlight the importance of semantics-based algorithm evolution in capturing diverse and task-specific behaviors that aggregate metrics may obscure.</p>
<p>Code Length: Figure 5 shows the evolution of code length for the best-performing solutions.Without bloat control, code length grows excessively throughout the optimization process when domain knowledge is absent.Incorporating domain knowledge helps shape the basic structure and mitigates excessive growth, but the code length still remains substantial.In contrast, when bloat control is applied, it directly curbs the complexity bias of LLMs, resulting in smaller generated programs that stabilize at a length of around 50, while simultaneously achieving faster improvements in objective scores.</p>
<p>Discovered Operators</p>
<p>In this section, we present experiments on datasets from contemporary symbolic regression benchmarks to evaluate the performance of the discovered operators.
P Q L ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH Figure 7: Test R 2 scores of different3 / H [ 2 P Q L $ X WR / H [ 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV
Figure 9: Tree sizes of selection operators on symbolic regression benchmarks.2025).All of these operators were manually designed by domain experts.This section only presents results for a single LLM-discovered operator.Additional results for other LLM-discovered operators are presented in Appendix E of the supplementary material.
% R OW ] P D Q Q ' $ / H [ $ X WR / H [ 7 R X U 7 R X U ' 6 S OL W 5 ' 6 7 R X U 3 / H [ &amp; 3 6 2 P Q L 7UDLQLQJ7LPHV
Test Accuracy: The results in Figure 7 show that the LLMgenerated selection operator outperforms the expert-designed baselines in terms of R 2 scores and achieves the best overall performance.A Wilcoxon signed-rank test with Benjamini-Hochberg correction is presented in Figure 8.These results demonstrate that the evolved Omni selection operator performs significantly better than existing expert-designed operators, many of which cannot be statistically distinguished from one another.This confirms that LLMs can effectively discover selection operators that surpass those created by domain experts.</p>
<p>Tree Size: The distribution of model sizes is presented in Figure 9.The results show that the evolved operator produces smaller models compared to top-performing selection operators like AutoLex and CPS.This is primarily because the evolved operator incorporates model size into the selection process, biasing the search toward regions where symbolic expressions are more compact.As shown in Figure 9 and Fig- Training Time: As shown in Figure 10, the proposed Omni selection operator is efficient, even though it integrates multiple criteria into the selection process, which makes it slightly more time-consuming than some other operators in terms of overall symbolic regression time.However, it is important to consider not only the training phase but also the cost of evaluating and deploying candidate models.Since Omni selection tends to favor smaller models with fewer nodes, it reduces computational cost during evaluation and deployment, especially on resource-constrained devices.Thus, despite its multi-faceted design leading to a slight increase in selection time, Omni remains an efficient and practical selection operator.</p>
<p>Analysis on State-of-the-Art Symbolic Regression Algorithms</p>
<p>Experimental Settings In this section, we apply the evolved operator to a state-of-the-art Transformer-assisted symbolic regression algorithm, namely retrieval-augmentationgeneration-based symbolic regression (RAG-SR) (Zhang et al. 2025) Recall that RAG-SR uses automatic-lexicase selection, which only considers diversity-awareness.These results suggest that even for a state-of-the-art symbolic regression algorithm, it is still desirable to consider multiple aspects, such as diversity, stage-awareness, complementarity, and interpretability, during selection to achieve stronger performance.Nonetheless, manually designing such an operator is challenging, which highlights the value of leveraging LLMs in this context.</p>
<p>Conclusions and Limitations</p>
<p>In this paper, we propose an LLM-driven framework for automatically designing selection operators in symbolic regression, and design several strategies to enhance its effectiveness.First, we highlight the challenges of limited semantic awareness and bloat in LLM-driven evolution.To enhance semantic awareness, we propose a semantic-based selection operator and a semantic feedback mechanism.To mitigate bloat, we introduce a prompt-based length control and a multi-objective survival selection strategy.Additionally, we define a set of design principles derived from domain knowledge to guide LLM for operator generation.Ablation studies confirm that addressing these three factors significantly enhances the effectiveness of the evolved algorithms.Next, we evaluate an LLM-generated selection operator against expert-designed baselines across a wide range of symbolic regression datasets, and also apply the evolved operator to state-of-the-art symbolic regression algorithms.The results show that the evolved operator outperforms expert-designed selection operators and can boost the performance of SR algorithms, achieving the best performance among 26 SR and ML algorithms, demonstrating that LLMs can discover selection operators that outperform those crafted by domain experts.For future work, it is worth exploring the automatic design of crossover and mutation operators in symbolic regression to further reduce the effort required for developing novel SR algorithms.</p>
<p>A Evolutionary Symbolic Regression</p>
<p>A.1 Solution Representation</p>
<p>The symbolic regression model is represented as a symbolic expression tree with linear scaling (Nadizar et al. 2024).For a given expression Φ, the prediction is computed as Ŷ = α • Φ(X) + β, where the coefficients α ∈ R and β ∈ R are fitted using ridge regression by minimizing the regularized squared error between Ŷ and the targets Y .</p>
<p>A.2 Algorithm Workflow</p>
<p>The symbolic regression algorithm is implemented using the genetic programming framework (Banzhaf et al. 1998).Let F (t) = {Φ 1 , Φ 2 , . . ., Φ λ } denote the population of λ symbolic expressions at generation t.The evolutionary process proceeds as follows:</p>
<p>• Population Initialization: The initial population F (0) is generated using the ramped half-and-half method (Banzhaf et al. 1998).</p>
<p>• Fitness Evaluation:
Each expression Φ i ∈ F (t) is eval- uated on the dataset (X, Y ). Let z i = Φ i (X) ∈ R n
denote the vector of symbolic outputs.The linear coefficients α i and β i are computed by fitting a ridge regression model of the form Ŷi = α i • z i + β i .The leave-oneout cross-validation (LOOCV) (Allen 1974) squared error is computed efficiently as
E i = n j=1 rij 1−Hijj 2 ,
where r i = Y − Ŷi is the residual vector, and
H i = Z i (Z ⊤ i Z i + λI) −1 Z ⊤ i is the hat matrix for ridge regres- sion with input Z i = [z i 1] ∈ R n×2 .
The full error vector is retained for use in selection.</p>
<p>• Elitism: The best-performing expression Φ * = arg min Φi∈F (t) E i is preserved in an external archive and used for solution selection to maintain historical performance.</p>
<p>• Solution Selection: The LLM-evolved selection operator is invoked to select a set of promising parent expressions from the current population and the elite archive.</p>
<p>• Solution Generation: A new population F (t+1) is generated from the selected parents using standard genetic programming operators:</p>
<p>-Subtree Crossover: Given two parent expressions Φ a and Φ b , offspring are generated by exchanging randomly selected subtrees.-Subtree Mutation: A randomly selected subtree of an expression Φ i is replaced with a newly generated subtree.</p>
<p>During solution generation, all solutions generated in the evolutionary process are stored in a hash set.If an offspring is identical to any historical solution, it is discarded and a new solution is generated.The hash set is used because it maintains O(1) query complexity.This mechanism prevents symbolic regression from wasting resources by evaluating the same solution multiple times.</p>
<p>A.3 Parameter Settings</p>
<p>The parameters for symbolic regression follow conventional settings.The population size and number of generations are set to match those used in D-Split (Imai Aldeia, De Franc ¸a, and La Cava 2024).To prevent division-by-zero errors, we use the analytical quotient (AQ(x, y) =</p>
<p>x √ 1+y 2 ) (Ni, Drieberg, and Rockett 2012) in place of the standard division operator.</p>
<p>B Analysis of Token Count of Generated Code</p>
<p>The token count directly impacts the cost of algorithm evolution, as language service providers typically charge based on the number of tokens.In this section, we analyze how bloat influences the token count of generated code.Token counting is performed using the cl100k base tokenizer, which is employed by OpenAI models.The experimental results are shown in Figure 12.It is evident that when no bloat control strategy is applied, the token count of the generated code is significantly higher.In contrast, the application of a bloat control strategy substantially reduces the token count in both the LLM-Meta-SR and LLM-Meta-SR without domain knowledge settings.This indicates that the bloat control strategy is not only helpful for improving the interpretability of generated code, but also beneficial for reducing the cost of algorithm evolution.</p>
<p>C Analysis of an Evolved Selection Operator</p>
<p>C.1 Code Evolved by LLM-Meta-SR Static Analysis Code 1 shows the best evolved selection operator among all runs.The code has been simplified by removing logically redundant parts.In selecting the first parent (parent a), the operator evaluates two key criteria: specificity-quantified as the lowest error achieved on any subset of the dataset, with lower values indicating superior performance in specialized regions-and a complexity measure that jointly considers the number of nodes in the symbolic expression tree and the height of the tree, thereby reflecting the interpretability of the solution.Candidate solutions are ranked such that subset error is prioritized, with model complexity serving as a secondary criterion when the subset error alone does not sufficiently differentiate candidates.This approach encourages the identification of solutions that balance high accuracy with interpretability.</p>
<p>For the selection of the second parent (parent b), the operator computes the absolute cosine similarity between the residuals of each candidate in the population and the residual of the previously selected first parent.The second parent is then chosen based on a combination of semantic complementarity, as measured by cosine similarity, and model complexity.The trade-off between complementarity and complexity is controlled by a linear function related to the evolutionary stage.In the early stages, the pressure toward parsimony is intentionally relaxed to promote broader exploration of the search space.In contrast, in later stages, the pressure increases to favor models that are both accurate and concise, thus facilitating interpretability.</p>
<p>Overall, the selection operator satisfies all the desired properties, including interpretability, diversity, complementarity, stage-awareness, and vectorization, as defined in Section 3.5.13.The diversity of the population is shown in Figure 14, and the tree size is shown in Figure 15.</p>
<p>Test R 2 Scores: The test R 2 scores demonstrate that the Omni selection operator achieves an advantage at the beginning of the search, indicating that it is an effective selection operator for anytime performance (Ye et al. 2022).</p>
<p>Population Diversity: To understand why the Omni selection operator achieves this performance, we plot the population diversity trajectory in Figure 14.Diversity is measured by the cosine distance between individuals, which is preferred over Euclidean distance because the latter can be trivially large if some solutions have very large errors.The results show that population diversity is well maintained across generations and is better than the baseline.In other words, the Omni selection operator maintains a more diverse population, with individuals making errors on different subsets of instances.This helps explain the superior performance of the Omni selection operator compared to the baseline.</p>
<p>Tree Size: Finally, we plot the tree size trajectory in Figure 15.The results show that Omni selection not only achieves better performance but also suffers less from rapid growth in tree size compared to other selection operators throughout the entire evolution process.This suggests that the Omni selection operator explores regions of the search space containing parsimonious solutions more exhaustively than other operators, which is an ideal behavior for finding effective and parsimonious solutions in symbolic regression.</p>
<p>C.2 Code Evolved by LLM-Meta-SR without Domain Knowledge</p>
<p>In this section, we analyze the code evolved by LLM-Meta-SR without domain knowledge to understand how an LLM can generate algorithms based solely on its internal knowledge.The evolved code is shown in Code 2. We refer to the resulting algorithm as Omni-Zero, as it evolves the model from scratch, similar to AutoML-Zero (Real et al. 2020).</p>
<p>Static Analysis Based on the code in Code 2, the LLM can evolve selection operators with desirable properties even without domain-specific guidance.These properties include diversity-awareness, stage-awareness, and interpretabilityawareness. For diversity-awareness, the selection operator uses cosine similarity to measure pairwise distances between individuals.Formally, it defines the novelty score as:
nov i = 1 − 1 n n k=1 xi−xi ∥xi−xi∥2+ϵ , x k −x k ∥x k −x k ∥2+ϵ max j 1 − 1 n n k=1 xj −xj ∥xj −xj ∥2+ϵ , x k −x k ∥x k −x k ∥2+ϵ
(3)</p>
<p>This cosine-distance-based novelty score is better suited for symbolic regression than Euclidean-distance-based novelty scores, as it is more robust to outliers and cannot be easily manipulated by increasing the distance with some outlier, as discussed in Appendix C.1.For stage-awareness, the selection operator applies a non-linear weighting function to control the trade-off between error and novelty.The function is defined as 0
.35 + 0.3 1 − t Tmax 0.8
, where t is the current generation and T max is the maximum number of generations, as described in Code 2. This function gradually decreases over time, promoting exploration in early generations and exploitation in later ones.This dynamic trade-off satisfies the stage-awareness criterion defined in Section 3.5.</p>
<p>For interpretability-awareness, the selection operator uses both the number of nodes and the height of the tree to measure solution complexity.A linear weighting function is used to balance interpretability and accuracy during selection.</p>
<p>A limitation of this operator is that it does not consider diversity from the perspective of specificity, the selection of each individual is largely dominated by the mean squared error of each individual, nor does it account for the complementarity between two parents.
$ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 2 P Q L = H UR 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH</p>
<p>C.3 A Repaired Version of Omni Selection for Small Datasets</p>
<p>Problem Analysis Upon closely analyzing the code generated by the LLM in Code 1, we identified a logical bug that can lead to poor performance of the selection operator on small datasets.When the dataset is small, the structured division in line 10 of Code 1 does not yield enough samples to form sufficient subsets, which can result in some
3 / H [ $ X WR / H [ 2 P Q L = H UR 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV
Figure 18: Tree sizes of different selection operators on symbolic regression benchmarks, including Omni-Zero.subsets being empty.These empty subsets cause the subsequent selection process to rely solely on complexity when selecting individuals, without considering their predictive performance.This issue arises because the datasets used during meta-evolution generally contain a relatively large number of training instances, as shown in Table 3.Consequently, the bug has limited impact during training but becomes problematic when applied to smaller datasets.
% R OW ] P D Q Q 2 P Q L = H UR ' $ / H [ $ X WR / H [ 7 R X U 7 R X U ' 6 S OL W 5 ' 6 7 R X U 3 / H [ &amp;3
Solution To address this issue, we propose a repaired version of the Omni selection operator, as shown in Code 3. In this version, random subsets are used to replace any empty subsets generated during structured division.All other parts of the code remain unchanged.</p>
<p>Benchmark Analysis We compare the performance of the repaired and original versions on datasets with no more than 100 training instances.The results, presented in Figure 20, show that the repaired version outperforms the original, indicating that the logical bug in the original version is indeed problematic.Regarding model size, as shown in Figure 21, the repaired version results in an increased tree size, which is reasonable because it corrects the previous behavior of selecting individuals solely based on complexity by also con-
2 P Q L 5 2 P Q L ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W % R OW ] P D Q Q 5 ' 6 7 R X U 7 R X U 7 R X U 3 / H [ R 2 6FRUH
Figure 20: Test R 2 scores of different selection operators on small-scale symbolic regression benchmarks, including the repaired omni selection.sidering the error on subsets.Nonetheless, the increase in tree size is not substantial and still leads to a competitive model size compared to other selection operators.This failure highlights that, when using LLMs for metaevolution, it is important that the LLM is exposed to a wide range of instances.Otherwise, the generated code may contain subtle logical bugs that are not easily detected.
3 / H [ 2 P Q L 2 P Q L 5 5 ' 6 7 R X U $ X WR / H [ &amp; 3 6 ' $ / H [ 7 R X U ' 6 S OL W % R OW ] P D Q Q 7 R X U 1XPEHURI1RGHV</p>
<p>D Further Analysis of the Semantic-Aware Evolution</p>
<p>In this paper, we propose a semantic-aware evolutionary approach that explicitly selects complementary pairs of individuals for crossover.To illustrate how two complementary codes work together to generate improved solutions, we provide a concrete example in this section.In the existing literature, the most common approach to combining the capabilities of two selection operators is to embed them within a dynamic algorithm selection framework (Xue et al. 2022), allowing each operator to be applied under different conditions.While this strategy permits both operators to contribute, it does so sequentially and without integrating their underlying semantics.Moreover, repeatedly combining two code fragments over multiple generations can lead to exponential code growth (Martins et al. 2018), impairing interpretability and maintainability.In contrast, our approach enables a more meaningful integration by combining semantically complementary code fragments through crossover.As shown in Code 4 and its parent codes in Code 5 and Code 6, the resulting offspring code fragments are not simply concatenations but structured combinations of meaningful components from both parents, as detailed in Table 4. Compared to the mutation operator, which performs a random search around a single solution, crossover provides a directional search by explicitly fusing different capabilities.Thus, the generated code is expected to perform well across multiple datasets.As shown in Figure 22, parent 1 and parent 2 excel on dataset 4 and dataset 3, respectively.By combining their complementary strengths through the mixing strategy performed by the LLM in Table 4, the offspring operator achieves strong performance on both datasets 3 and 4, thereby yielding better average performance.Unlike random subtree crossover in tree-based genetic programming (Banzhaf et al. 1998) or one-point crossover in linear genetic programming (Huang et al. 2024), LLM-based crossover can synthesize code that semantically resembles an intermediate between the two parent programs by leveraging its code understanding capability.This highlights the importance of semantic diversity: if both parents are highly similar, even if performant, the resulting offspring would be nearly identical to the parents, leading to redundant evaluations and wasted computation.Therefore, semantic-aware evolution is vital for automated algorithm design.</p>
<p>E Results on More Discovered Operators</p>
<p>The proposed LLM-Meta-SR method can discover various selection operators.For example, Code 4 presents a selection operator discovered by the LLM-Meta-SR algorithm, which differs from the operator shown in Code 1.To avoid confusion, we refer to the discovered operator in Code 4 as "Holo".The results of the test R 2 scores are shown in Figure 23 and Figure 24, which demonstrate that the Holo selection operator outperforms expert-designed selection operators.Additionally, the complexity size, shown in Figure 25, indicates that the discovered operator is competitive in terms of model complexity.A direct comparison with the tree sizes evolved using the Omni selection, reported in Figure 9, shows that the discovered operator is even slightly smaller.Therefore, the "Holo" selection operator is preferred when interpretability is a key concern.
+ R OR ' $ / H [ $ X WR / H [ &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U 7 R X U 7 R X U % R OW ] P D Q Q 3 / H [ R 2 6FRUH</p>
<p>F Test Cases for Synthetic Evaluation</p>
<p>For the synthetic evaluation in Section 3.2, two synthetic test cases are designed to reveal implementation flaws and inefficiencies early in the evaluation process, prior to applying each evolved selection operator to real symbolic regression tasks.The first case consists of 100 solutions whose predicted values and training errors are independently sampled from 100 random integers in the range [1,10].The second case also
/ H [ + R OR $ X WR / H [ 7 R X U &amp; 3 6 ' 6 S OL W 5 ' 6 7 R X U % R OW ] P D Q Q ' $ / H [ 7 R X U 1XPEHURI1RGHV</p>
<p>G More Analysis on Symbolic Regression Benchmark</p>
<p>The results of the top-5 performing algorithms are shown in Figure 26 for better clarity, and the Pareto front of the ranks of test R 2 scores and model sizes across different algorithms is shown in Figure 27.These results demonstrate that RAG-SR-Omni is a Pareto-optimal algorithm on SRBench.Specifically, RAG-SR-Omni dominates retrievalaugmentation-generation-based symbolic regression (RAG-SR) (Zhang et al. 2025) as well as transformer-based planning for symbolic regression (Shojaee et al. 2024).Overall, these results show the effectiveness of the LLM-evolved selection operator.</p>
<p>H Baseline Selection Operators</p>
<p>The hyperparameters for the baseline selection operators follow the default settings specified in their respective original papers.For RDS-Tour, the sampling ratio is set to 10% and the tournament size to 7 (Geiger et al. 2025).For PLex selection, the temperature parameter is set to 1.0 (Ding, Pantridge, and Spector 2023).For DALex, a particularity pressure of 3 is used (Ni, Ding, and Spector 2024).For CPS, the first parent is selected via tournament, with the tournament size set to 7 (Xu et al. 2022).</p>
<p>For Boltzmann sampling with temperature scheduling (Shojaee et al. 2025;Romera-Paredes et al. 2024), a temperature decay rule is applied to balance exploration and exploitation over time, similar to the approaches used in LLM-SR (Shojaee et al. 2025) andFunSearch (Romera-Paredes et al. 2024).The sampling probability for individual i is defined as:
P i = exp si τc i ′ exp s i ′ τc , τ c = τ 0 1 − t mod T max T max ,(4)
where s i denotes the score of individual i, τ 0 = 0.1 is the initial temperature (Shojaee et al. 2025), t is the current generation, and T max is the total number of generations.This scheduling rule linearly decays the temperature over generations and gradually shifts the selection pressure from exploration (high temperature) to exploitation (low temperature) as evolution progresses in evolutionary symbolic regression.</p>
<p>I Further Investigation on Crossover and Mutation Ratio</p>
<p>In the main paper, the number of individuals in the population generated by crossover is 19, and the number generated by mutation is 1.In this section, we investigate the proposed method under different settings of crossover and mutation ratios to examine how these ratios affect its performance.Specifically, in this section, the number of individuals generated by crossover is 15 and by mutation is First, the experimental results in Figure 28 and Figure 29 show that the conclusions from the ablation studies in Section 5.2 generalize to different settings of crossover and mutation ratios.This includes the effectiveness of semantics-based evolution, bloat control, and domain-knowledge-based operators.</p>
<p>Second, the results in Figure 28 as well as the numerical values in Table 5 indicate that the optimal crossover and mutation ratios vary depending on the prompts.When domain knowledge is available, a smaller mutation rate, as used in Section 5.2, achieves slightly better performance than the larger mutation rate used in this section.In contrast, when Code 9: Default code used when no code can be extracted from the LLM response.</p>
<p>L Computing Infrastructure</p>
<p>All experiments are run on AMD Milan CPUs.The software packages used in our experiments are listed in Table 6.</p>
<p>Figure 1: Illustration of the importance of fine-grained semantic differences between solutions during algorithm evolution.</p>
<p>where D 1 , . . ., D T are symbolic regression datasets, and SR(O (t) i , D j ) denotes the symbolic regression performance of O (t) i on dataset D j .In brief, each dataset is split into a training and validation set.Symbolic regression is performed on the training set, and the fitness of the selection operator is computed based on its performance on the validation set.Details of the solution evaluation procedure are provided in Appendix A of the supplementary material.• Survival Selection: A subset of operators is retained to form the next generation P (t+1) .To control bloat, a multiobjective survival selection strategy is employed, as described in Section 3.4.• Solution Selection: Two parent operators O (t) a , O (t) b ∈ P (t) are selected for recombination.The selection strat-egy incorporates semantic information, as detailed in Section 3.3.• Solution Generation: Based on the selected parents, N candidate operators are generated per generation.Of these, N − M are generated via crossover and M via mutation:</p>
<p>Figure 4 :Figure 5 :Figure 6
456
Figure 4: Validation R 2 of the best solution across generations for different LLMdriven search strategies.</p>
<p>2</p>
<p>Figure 10 :
10
Figure 10: Training times of selection operators on symbolic regression benchmarks.</p>
<p>, to evaluate the effectiveness of the proposed operator in the context of modern symbolic regression.The only modification is the replacement of the automatic epsilon lexicase selection(La Cava et al. 2019)  with the Omni selection operator described in Code 3 in the supplementary material.All other components remain unchanged.The resulting algorithm is referred to as RAG-SR-Omni.For the experimental datasets, following the setup in Section 4, we use 116 out of 120 regression problems, excluding the four used during meta-evolution.Experimental ResultsThe results are presented in Figure 11.The figure show that RAG-SR-Omni outperforms RAG-SR in terms of median R 2 scores, model sizes, and training time, achieving the best performance among 26 symbolic regression and machine learning algorithms.These results indicate that the LLM-evolved selection operator can be seamlessly integrated into state-of-the-art symbolic regression methods to further enhance their performance.</p>
<p>Figure 12 :
12
Figure 12: Average token count of generated code across generations for different LLM-driven search strategies.</p>
<p>Figure 13 :
13
Figure 13: Test R 2 scores across generations.</p>
<p>'</p>
<p>Figure 17: Pairwise statistical comparison of selection operators using the Wilcoxon signed-rank test with Benjamini-Hochberg correction.</p>
<p>6 7UDLQLQJ7LPHVFigure 19 :
619
Figure 19: Training times of different selection operators on symbolic regression benchmarks, including Omni-Zero.</p>
<p>Figure 21 :
21
Figure 21: Tree sizes of different selection operators on small-scale symbolic regression benchmarks, including the repaired omni selection.</p>
<p>Figure 24: Pairwise statistical comparison of selection operators using the Wilcoxon signed-rank test with Benjamini-Hochberg correction.</p>
<p>Figure 25 :Figure 26 :
2526
Figure 25: Tree sizes of different selection operators on symbolic regression benchmarks, including the Holo selection operator.</p>
<p>Figure 27 :
27
Figure 27: Pareto front of the ranks of test R 2 scores and model sizes for different algorithms.</p>
<ol>
<li>The results related to validation score and code length are shown in Figure 28 and Figure 29, respectively.</li>
</ol>
<p>Evolutionary Symbolic Regression Meta Evolution Test Score Synthetic Evaluation Synthetic Evaluation Bloat Control Bloat Control Semantics Aware Evolution Semantics Aware Evolution Bloat Control Semantics Aware Evolution</p>
<p>P (t) = {O 1 , . . ., O N }: population where each O i has score vector s i 1: O a ← Random sample from P (t) 2: for each O i ∈ P (t) do
NoPopulation Initialization Population Initialization Solution Evaluation Solution EvaluationSelection OperatorPopulation Initialization Population Initialization Solution Evaluation Solution EvaluationEnd End Termination? Yes NoTermination?Survival Selection Survival SelectionYesSolution Selection Solution SelectionEnd EndSolution Selection Solution SelectionSolution GenerationSolution Generation Solution GenerationElitism ElitismFigure 3: Workflow of LLM-driven selection operator evolution.Algorithm 1: Semantics-Aware SelectionRequire: 3:which measures the potential combined performance of O aand O i across all datasets. The second parent O b is retrievedas the operator with the highest complementarity score, i.e.,O b = O i  *  where i  *  = arg max i µ i . This process can beviewed as retrieval-augmented generation (RAG), where com-plementarity serves as the similarity function to retrieve themost complementary code from the population to guide gen-eration.</p>
<p>Table 1 :
1
Median historical best scores and the corresponding code lengths for each algorithm over three runs.LLM-Meta-SR W/O Semantics W/O SE+BC W/O Knowledge W/O DK+SE W/O DK+SE+BC
Score0.860.840.840.790.750.75Lines of Code48438055412220.8Best Score0.6 0.70 2 4 6 8 10 12 14 16 18 20 GenerationLLM-Meta-SR W/O Semantics W/O SE+BCW/O Knowledge W/O DK+SE W/O DK+SE+BC</p>
<p>Median R 2 scores, model sizes, and training time of 26 algorithms on the symbolic regression benchmark.ure 7, model size and performance are not always in conflict.By carefully designing the selection operator, it is possible to evolve symbolic models that achieve both high accuracy and small model size, indicating high interpretability.
R 2 7HVW0RGHO6L]H7UDLQLQJ7LPHV5$<em>652PQL 5$</em>65 367UHH 7365 2SHURQ 6%3<em>3 )($7 61,3 (3/(; ;</em>% /<em>%0 </em>3<em>20($ $GD%RRVW 5DQGRP)RUHVW ,7($ $)3B)( $)3 )); .HUQHO5LGJH JSOHDUQ '65 05</em>3 0/3 /LQHDU %65 $,)H\QPDQíFigure 11:</p>
<p>Table 2 :
2
Parameter settings
ParameterValuePopulation size100Maximum generations 100Maximum tree depth10Initialization methodRamped half-and-half (depth 0-6)+, −, ×, AQ, | • |,Function setlog(1 + | • |), | • |, (•) 2 , sin π (•),cos π (•), Max, Min, NegCrossover rate0.9Mutation rate0.1For the experiment evaluating the evolved selection operatoron SRBench, the dataset is randomly split into a trainingset and a test set with an 80:20 ratio (La Cava et al. 2021).Subsampling is applied to limit the maximum number oftraining instances to 10,000, consistent with the SRBenchprotocol (La Cava et al. 2021). Symbolic regression is runon the training set and evaluated on the test set. All featuresare standardized, as this has been shown to be beneficialfor symbolic regression (Owen, Dick, and Whigham 2022).Standardization parameters are learned from the training dataand applied to both the training and test sets. All symbolicregression experiments are conducted on an AMD Milan7713 CPU.
Cava et al. 2021rotocol in Meta-EvolutionIn the evaluation of selection operators generated by the LLM, all other algorithmic components-including solution initialization, evaluation, generation, and elitism-follow standard practices commonly used in evolutionary symbolic regression.For each dataset D j , the data is split into training and validation subsets with an 80:20 ratio (LaCava et al. 2021).The regression model is optimized to maximize the training R 2 score, while the validation R 2 score is used as the final score of the selection operator.This encourages the selection of operators with implicit regularization capabilities.A.5 Evaluation Protocol for Discovered Operators</p>
<p>Benchmark AnalysisTo further analyze the behavior of the Omni selection operator, we plot the test R 2 scores on five representative datasets in Figure
])parent_b.append(population[b_idx1 def omni_selection(population, k=100,47 48return [ind for pair in zip(parent_a2status={}): stage = np.clip(status.get("49, parent_b) for ind in pair][:k]3 4evolutionary_stage", 0), 0, 1) n = len(population) half_k = k // 2Code 1: Omni Selection5y = population[0].y6n_cases = y.size78ssize = max(7, n_cases // max(1, 2 <em>half_k))9half_struct = half_k // 210structured = [11np.arange(i * ssize, min((i + 1)</em> ssize, n_cases)) for i in range(half_struct)12]13random_ = [14np.random.choice(n_cases, ssize,replace=False)15for _ in range(half_k -half_struct)16]17subsets = structured + random_1819residuals = np.vstack([ind.y -ind.predicted_values for ind inpopulation])20complexity = np.array([len(ind) +ind.height for ind in population],float)21complexity /= max(1, complexity.max())22subset_mse = np.array(23[24[((residuals[i, s]) ** 2).mean() if s.size else np.inf for s insubsets]25for i in range(n)26]27)28comp_factor = 0.25 + 0.25 * stage2930parent_a = [31population[np.lexsort((complexity, subset_mse[:, i]))[0]]32for i in range(len(subsets))33]3435idx_map = {ind: i for i, ind inenumerate(population)}36norms = np.linalg.norm(residuals,axis=1) + 1e-123738parent_b = []39for a in parent_a:40i_a = idx_map[a]41res_a = residuals[i_a]42cors = (residuals @ res_a) / (norms * norms[i_a])43cors[i_a] = 144comp_score = np.abs(cors) +comp_factor * complexity45b_idx = np.argmin(comp_score)</p>
<p>Table 3 :
3
Summary of datasets used in meta-evolution.
Datasetn observations n featuresOPENML 505240124OPENML 45441059117OPENML 5881000100OPENML 65050050</p>
<p>Table 4 :
4
Fusion of key selection components.Here s = sizes, h = heights, n c is the number of cases, comp pen is the complexity penalty, and corr denotes the normalized residual correlation.
6FRUH'DWDVHW'DWDVHW'DWDVHW'DWDVHW$YHUDJH3DUHQW3DUHQW2IIVSULQJFigure 22: Validation R 2 scores of parent and offspring se-lection operators on different datasets.1 def omni_selection(population, k=100,status={}):2stage = status.get("evolutionary_stage", 0)3n = len(population)4half_k = k // 25rng = np.random.default_rng(12345)67errs = np.array([ind.case_values forind in population])# (n,n_cases)8residuals = np.array([ind.y -ind.predicted_values for ind inpopulation])9sizes = np.array([len(ind) for indin population])10heights = np.array([ind.height forind in population])1112n_cases = errs.shape[1]13comp_pen = (sizes + heights) * (0.4+ 0.6 * stage) / (40 + 60 * stage) #adaptive comp penalty1415subset_size = max(8, n_cases // (half_k + 2))16max_tries = 15 * half_k</p>
<p>Table 6 :
6
Software used for experiments.
TypeName
Source Code: https://anonymous.4open.science/r/LLM-Meta-SR/
CodeDEAP(Fortin et al. 2012) Code CodeBLEU (Ren et al. 2020) Benchmark SRBench(La Cava et al. 2021)domain knowledge is not available, a larger mutation rate appears to be more beneficial.One possible reason is that when domain knowledge is available, the search space is more confined and a large mutation rate does not provide additional benefit.Conversely, when domain knowledge is not available, the search space is larger and a higher mutation rate is needed to effectively explore the space.J Related WorkJ.1 Recent Advancements in Selection OperatorsIn recent years, lexicase selection has shown strong empirical performance and is widely adopted in modern symbolic regression systems(Cava et al. 2019;Zhang et al. 2025).Inspired by lexicase selection, several variants have been developed, including probabilistic lexicase selection(Ding, Pantridge, and Spector 2023), lexicase-like selection via diverse aggregation (DALex)(Ni, Ding, and Spector 2024), ϵlexicase selection with dynamic split (D-Split) (Imai Aldeia, De Franc ¸a, and LaCava 2024), down-sampled lexicase selection(Boldi et al. 2024), and random down-sampled tournament selection(Geiger, Sobania, and Rothlauf 2025).These methods share the core idea of emphasizing performance on subsets of training instances to encourage specialization, and they demonstrate advantages in various scenarios(Geiger, Sobania, and Rothlauf 2025).However, these operators are manually designed and do not fully satisfy all the desired properties outlined in Section 3.5, highlighting the need for further exploration of selection operators.J.2 Automated Evolutionary Algorithm DesignBefore the LLM era, genetic programming had been widely used for automated evolutionary algorithm design, including the design of fitness functions (Fong and Motani 2024a), parameter adaptation techniques(Stanovov, Akhmedova, and Semenkin 2022), and update strategies(Lones 2021).More recently, reinforcement learning has also been applied to designing update rules in differential evolution(Chen et al. 2024a).However, these approaches are typically limited to generating only small code segments, as exploring large program spaces remains challenging.The emergence of LLMs has made automated algorithm design more feasible.For example, LLMs have been used to design a differential evolution algorithm competitive with state-of-the-art continu-ous optimization methods(Stein and Bäck 2024).Similarly, LLMs have been employed to improve the self-organizing migrating algorithm(Pluhacek et al. 2024).This growing interest in LLMs motivates the development of efficient LLMbased approaches for automated algorithm design, where semantic awareness and code bloat are two key issues that remain underexplored and warrant further investigation.J.3 Large Language Models for OptimizationLLMs have been employed as optimization tools across various domains(Meyerson et al. 2024;Song et al. 2024)Exploring the potential of LLMs in automating the design of improved evolutionary search strategies is a worthwhile direction.However, evaluating LLM-based evolutionary search in automated algorithm design is computationally expensive.In comparison, genetic programming is a relatively inexpensive and historically dominant method for code generation prior to the LLM era(Peabody and Seitzer 2015;Chen et al. 2023;Maudet and Danoy 2025).Therefore, leveraging LLMs for the automated design of genetic programming algorithms presents a relevant and cost-effective avenue for investigation.K Prompt for Algorithm EvolutionSystem Prompt: Figure30shows the system prompt used for algorithm evolution, which is added before the specific prompt in all three phases of the automated algorithm design process, including initialization, crossover, and mutation.The system prompt is designed to guide the LLM in generating efficient selection operators by preferring NumPy vectorized operations and avoiding explicit Python for-loops unless absolutely necessary.Python is chosen for its simplicity and strong support in LLMs, but standard for-loops are timeconsuming.In contrast, NumPy vectorized operations are implemented in C++ and offer better computational speed.The system prompt also specifies the maximum number of lines of code that the LLM can generate.This constraint helps control bloat, as discussed in Section 3.4.Initialization/Mutation Prompt: Figure31presents the prompts used for initialization and mutation.The main goal of these prompts is to encourage the LLM to generate a novel selection operator to explore the search space.The key difference between the prompts used for the two phases is that in the initialization phase, no baseline code is provided to the LLM.In the mutation phase, the elite solution is provided as the baseline code.The prompt format for wrapping the baseline code is shown in Figure32, which aims to encourage the LLM to generate a novel selection operator based on the provided code.Crossover Prompt: Figure33shows the crossover prompt used for algorithm evolution.The goal is specified as "selection operator," and its plural form, "selection operators".The crossover prompt takes the code of two existing selection operators as input and aims to generate a better operator by combining effective building blocks from both.To support semantic awareness and concise code generation, the prompt includes the score vector and the corresponding line of code.The properties describe the desired characteristics of the selection operator based on domain knowledge from Section 3.5.The specific prompt is shown in Figure34.The template provides a function signature to ensure that the generated operator can be integrated into the automatic evaluation pipeline as shown in Code 7. When domain knowledge is not provided, the properties are left empty and a simplified template without knowledge guidance for the selection operator, as shown in Code 8, is used.Fallback Selection Operator: In rare cases where the LLM fails to generate valid Python code, a simple tournament selection operator, as shown in Code 9, is used to fill the population.When writing code, prefer NumPy vectorized operations and avoid explicit Python for-loops unless absolutely necessary.Please implement code within {max code lines} lines.Your task is to develop an innovative and novel {goal} for symbolic regression using genetic programming in Python.{Baseline} {Properties}Ensure that your newly designed function adheres to the following signature: {Template} You do not need to provide a usage example.Embrace creativity, novelty, and bold experimentation to push the boundaries of the state of the art in {goals} for genetic programming.-Encourage specialization to maintain a diverse population.2. Crossover-Aware Pairing -Promote complementarity between parents.Stage-Specific Pressure-Vary selection pressure based on the current stage of evolution.Interpretability-Prefer individuals with fewer nodes and lower tree height to improve model interpretability.Efficiency &amp; Scalability-Include clear stopping conditions to avoid infinite loops.Code Simplicity-Favor clear, concise logic with minimal complexity.Reproducibility Checklist Instructions for Authors:This document outlines key aspects for assessing reproducibility.Please provide your input by editing this .texfile directly.For each question (that applies), replace the "Type your response here" text with your answer.Example: If a question appears as \question{Proofs of all novel claims are included} {(yes/partial/no)} Type your response here you would change it to:\question{Proofs of all novel claims are included} {(yes/partial/no)} yes Please make sure to:• Replace ONLY the "Type your response here" text and nothing else.• Use one of the options listed for that question (e.g., yes, no, partial, or NA).• Not modify any other part of the \question command or any other lines in this document.You can \input this .texfile right before \end{document} of your main file or compile it as a stand-alone document.Check the instructions on your conference's website to see if you will be asked to provide this checklist with your paper or separately.General
The relationship between variable selection and data agumentation and a method for prediction. D M Allen, Technometrics. 1611974</p>
<p>Genetic programming: an introduction: on the automatic evolution of computer programs and its applications. W Banzhaf, P Nordin, R E Keller, F D Francone, 1998Morgan Kaufmann Publishers Inc</p>
<p>Informed Down-Sampled Lexicase Selection: Identifying productive training cases for efficient problem solving. L Biggio, T Bendinelli, A Neitz, A Lucchi, G Parascandolo, Pmlr, R Boldi, M Briesch, D Sobania, A Lalejini, T Helmuth, F Rothlauf, C Ofria, L Spector, International Conference on Machine Learning. 2021. 202432Neural symbolic regression that scales</p>
<p>Learning concise representations for regression by evolving networks of trees. W L Cava, T R Singh, J Taggart, S Suri, J Moore, International Conference on Learning Representations. 2019</p>
<p>J S Chan, N Chowdhury, O Jaffe, J Aung, D Sherburn, E Mays, G Starace, K Liu, L Maksin, T Patwardhan, MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering. 2025In ICLR. Open-Review.net</p>
<p>Evoprompting: Language models for code-level neural architecture search. A Chen, D Dohan, D So, Advances in Neural Information Processing Systems. 202336</p>
<p>SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning. J Chen, Z Ma, H Guo, Y Ma, J Zhang, Y.-J Gong, The Twelfth International Conference on Learning Representations. 2024a</p>
<p>. J Chen, J Tian, L Wu, Chenxinwei, </p>
<p>KinFormer: Generalizable Dynamical Symbolic Regression for Catalytic Organic Reaction Kinetics. X Yang, Y Jin, Y Xu, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Symbolic discovery of optimization algorithms. X Chen, C Liang, D Huang, E Real, K Wang, H Pham, X Dong, T Luong, C.-J Hsieh, Y Lu, Advances in Neural Information Processing Systems. 202336</p>
<p>Z Chen, Z Zhou, Y Lu, R Xu, L Pan, Z Lan, arXiv:2412.20694QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty Balanced Evolution. 2024barXiv preprint</p>
<p>Hsevo: Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using llms. P V T Dat, L Doan, H T T Binh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>MetaSR: A Meta-Learning Approach to Fitness Formulation for Frequency-Aware Symbolic Regression. L Ding, E Pantridge, L Spector, B Dolin, M G Arenas, J J Merelo, Springer, M Feng, Y Huang, Y Liu, B Jiang, J Yan, Parallel Problem Solving from Nature-PPSN VII: 7th International Conference Granada. K S Fong, M Motani, Spain2023. 2002. September 7-11. 2002. 20257Proceedings of the Genetic and Evolutionary Computation Conference</p>
<p>Symbolic regression enhanced decision trees for classification tasks. K S Fong, M Motani, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2024b38</p>
<p>DEAP: Evolutionary algorithms made easy. F.-A Fortin, F.-M De Rainville, M.-A G Gardner, M Parizeau, C Gagné, The Journal of Machine Learning Research. 1312012</p>
<p>Customizing language model responses with contrastive in-context learning. X Gao, K Das, Proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence202438</p>
<p>A Performance Analysis of Lexicase-Based and Traditional Selection Methods in GP for Symbolic Regression. A Geiger, M Briesch, D Sobania, F Rothlauf, Springer, A Geiger, D Sobania, F Rothlauf, European Conference on Genetic Programming. 2025. 2025Was Tournament Selection All We Ever Needed? A Critical Reflection on Lexicase Selection</p>
<p>Evolutionary large language model for automated feature transformation. N Gong, C K Reddy, W Ying, H Chen, Y Fu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Autonomous multi-objective optimization using large language model. A Grayeli, A Sehgal, O Costilla-Reyes, M Cranmer, S Chaudhuri, Y Huang, S Wu, W Zhang, J Wu, L Feng, K C Tan, arXiv:2409.09359IEEE Transactions on Evolutionary Computation. 2024. 2025aarXiv preprintSymbolic regression with a learned concept library</p>
<p>Toward evolving dispatching rules with flow control operations by grammar-guided linear genetic programming. Z Huang, Y Mei, F Zhang, M Zhang, IEEE Transactions on Evolutionary Computation. 2024</p>
<p>CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design. Z Huang, W Wu, K Wu, J Wang, W.-B Lee, arXiv:2505.12285Proceedings of the Genetic and Evolutionary Computation Conference. La Cava, W G , the Genetic and Evolutionary Computation Conference2025barXiv preprintImai Aldeia, G. S.; De Franc ¸a</p>
<p>LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch. C Jiang, X Shu, H Qian, X Lu, J Zhou, A Zhou, Y Yu, Proceedings of the Thirteenth International Conference on Learning Representations (ICLR). the Thirteenth International Conference on Learning Representations (ICLR)Singapore, Singapore2025</p>
<p>Racing Control Variable Genetic Programming for Symbolic Regression. N Jiang, Y Xue, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Dimension Reduction for Symbolic Regression. P Kahlmeyer, M Fischer, J Giesen, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>End-to-end symbolic regression with transformers. P Kamienny, S -A.; D'ascoli, G Lample, F Charton, Advances in Neural Information Processing Systems. 202235</p>
<p>Deep generative symbolic regression with Monte-Carlo-tree-search. P.-A Kamienny, G Lample, S Lamprier, M Virgolin, International Conference on Machine Learning. PMLR2023</p>
<p>Shape-constrained symbolic regression-improving extrapolation with prior knowledge. G Kronberger, F O De Franc ¸a, B Burlacu, C Haider, M Kommenda, Evolutionary Computation. 3012022</p>
<p>Contemporary symbolic regression methods and their relative performance. Advances in neural information processing systems. La Cava, W Burlacu, B Virgolin, M Kommenda, M Orzechowski, P De Franc ¸a, F O Jin, Y Moore, J H , 202120211</p>
<p>. La Cava, W Helmuth, T Spector, L Moore, J , </p>
<p>A probabilistic and multi-objective analysis of lexicase selection and ε-lexicase selection. Evolutionary Computation. 273</p>
<p>A unified framework for deep symbolic regression. M Landajuela, C S Lee, J Yang, R Glatt, C P Santiago, I Aravena, T Mundhenk, G Mulcahy, B K Petersen, Advances in Neural Information Processing Systems. 202235</p>
<p>Efficiently evolving programs through the search for novelty. J Lehman, K O Stanley, Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation. the 12th Annual Conference on Genetic and Evolutionary Computation2010</p>
<p>Pareto set learning for expensive multi-objective optimization. X Lin, Z Yang, X Zhang, Q Zhang, Advances in Neural Information Processing Systems. 202235</p>
<p>Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model. F Liu, T Xialiang, M Yuan, X Lin, F Luo, Z Wang, Z Lu, Q Zhang, International Conference on Machine Learning. PMLR2024a</p>
<p>Decision Tree Induction Through LLMs via Semantically-Aware Evolution. S Liu, C Chen, X Qu, K Tang, Y.-S Ong, The Thirteenth International Conference on Learning Representations. 2024b. 2024Large language models as evolutionary optimizers</p>
<p>Evolving continuous optimisers from scratch. Genetic Programming and Evolvable Machines. M A Lones, 202122</p>
<p>Eureka: Human-Level Reward Design via Coding Large Language Models. Y J Ma, W Liang, G Wang, D.-A Huang, O Bastani, D Jayaraman, Y Zhu, L Fan, A Anandkumar, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Solving the exponential growth of symbolic regression trees in geometric semantic genetic programming. J F B Martins, L O V Oliveira, L F Miranda, F Casadei, G L Pappa, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation Conference2018</p>
<p>Search Strategy Generation for Branch and Bound Using Genetic Programming. G Maudet, G Danoy, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Language model crossover: Variation through few-shot prompting. E Meyerson, M J Nelson, H Bradley, A Gaier, A Moradi, A K Hoover, J Lehman, ACM Transactions on Evolutionary Learning. 442024</p>
<p>AutoS-GNN: automatic propagation mechanism discovery for spectral graph neural networks. S Mo, K Wu, Q Gao, X Teng, J Liu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Geometric semantic GP with linear scaling: Darwinian versus Lamarckian evolution. A Moraglio, K Krawiec, C G Johnson, G Nadizar, B Sakallioglu, F Garrow, S Silva, L Vanneschi, Parallel Problem Solving from Nature-PPSN XII: 12th International Conference. Taormina, ItalyGenetic Programming and Evolvable Machines2012. September 1-5, 2012. 20241217Geometric semantic genetic programming</p>
<p>The use of an analytic quotient operator in genetic programming. A Ni, L Ding, L Spector, Springer, J Ni, R H Drieberg, P I Rockett, European Conference on Genetic Programming. 2024. 201217Dalex: Lexicase-like selection via diverse aggregation</p>
<p>Standardization and data augmentation in genetic programming. C A Owen, G Dick, P A Whigham, IEEE Transactions on Evolutionary Computation. 2662022</p>
<p>Using LLM for automatic evolvement of metaheuristics from swarm algorithm SOMA. C Peabody, J Seitzer, M Kovac, J Viktorin, A Janku, P Kadavy, T Senkerik, R , Proceedings of the Genetic and Evolutionary Computation Conference Companion. the Genetic and Evolutionary Computation Conference Companion2015. 2024. 2018-202229Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Automl-zero: Evolving machine learning algorithms from scratch. E Real, C Liang, D So, Q Le, S Pmlr. Ren, D Guo, S Lu, L Zhou, S Liu, D Tang, N Sundaresan, M Zhou, A Blanco, S Ma, arXiv:2009.10297International Conference on Machine Learning. 2020. 2020arXiv preprintCodebleu: a method for automatic evaluation of code synthesis</p>
<p>Mathematical discoveries from program search with large language models. B Romera-Paredes, M Barekatain, A Novikov, M Balog, M P Kumar, E Dupont, F J Ruiz, J S Ellenberg, P Wang, O Fawzi, Nature. 62579952024</p>
<p>Symbolic cognitive diagnosis via hybrid optimization for intelligent education systems. J Shen, H Qian, W Zhang, A Zhou, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors. H Shi, W Song, X Zhang, J Shi, C Luo, X Ao, H Arian, L A Seco, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>. P Shojaee, K Meidani, A Barati Farimani, C Reddy, </p>
<p>Transformer-based planning for symbolic regression. Advances in Neural Information Processing Systems. 36</p>
<p>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Position: leverage foundational models for blackbox optimization. X Song, Y Tian, R T Lange, C Lee, Y Tang, Y Chen, Proceedings of the 41st International Conference on Machine Learning. the 41st International Conference on Machine Learning2024</p>
<p>The automatic design of parameter adaptation techniques for differential evolution with genetic programming. V Stanovov, S Akhmedova, E Semenkin, Knowledge-Based Systems. 2391080702022</p>
<p>Llamea: A large language model evolutionary algorithm for automatically generating metaheuristics. N V Stein, T Bäck, IEEE Transactions on Evolutionary Computation. 2024</p>
<p>Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning. A Šurina, A Mansouri, A Seddas, M Viazovska, E Abbe, C Gulcehre, Scaling Self-Improving Foundation Models. 2025without Human Supervision</p>
<p>Improving model-based genetic programming for symbolic regression of small expressions. M Virgolin, T Alderliesten, C Witteveen, P A Bosman, Evolutionary computation. 2922021</p>
<p>Efficient Heuristics Generation for Solving Combinatorial Optimization Problems Using Large Language Models. X Wu, D Wang, C Wu, L Wen, C Miao, Y Xiao, Y Zhou, H Xie, M Zhang, M Xu, Y Mei, F Zhang, M Zhang, arXiv:2505.12627Proceedings of the Genetic and Evolutionary Computation Conference Companion. the Genetic and Evolutionary Computation Conference Companion2025. 2012. 202217arXiv preprintGenetic programming with diverse partner selection for dynamic flexible job shop scheduling</p>
<p>Multi-agent dynamic algorithm configuration. K Xue, J Xu, L Yuan, M Li, C Qian, Z Zhang, Y Yu, Advances in Neural Information Processing Systems. 202235</p>
<p>Large Language Models as Optimizers. C Yang, X Wang, Y Lu, H Liu, Q V Le, D Zhou, X Chen, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Multi-objective evolution of heuristic using large language model. S Yao, F Liu, X Lin, Z Lu, Z Wang, Q Zhang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202539</p>
<p>Automated configuration of genetic algorithms by tuning for anytime performance. F Ye, C Doerr, H Wang, T Bäck, IEEE Transactions on Evolutionary Computation. 2662022</p>
<p>Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems. H Ye, J Wang, Z Cao, F Berto, C Hua, H Kim, J Park, G Song, H Xu, A Yan, Y Cheng, The Thirtyeighth Annual Conference on Neural Information Processing Systems. Ye, H2024. 2025Forty-second International Conference on Machine Learning</p>
<p>Symbolic regression via MDLformer-guided search: from minimizing prediction error to minimizing description length. Z Yu, J Ding, Y Li, Jin , D Zhang, H Chen, Q Xue, B Banzhaf, W Zhang, M , The Thirteenth International Conference on Learning Representations. 2025. 2025The Thirteenth International Conference on Learning Representations</p>
<p>Understanding the importance of evolutionary search in automated heuristic design with large language models. R Zhang, F Liu, X Lin, Z Wang, Z Lu, Q Zhang, Springer, Z Zhao, H Wen, P Wang, Y Wei, Z Zhang, X Lin, F Liu, B An, H Xiong, Y Wang, arXiv:2503.10721From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution. 2024. 2025arXiv preprintInternational Conference on Parallel Problem Solving from Nature</p>            </div>
        </div>

    </div>
</body>
</html>