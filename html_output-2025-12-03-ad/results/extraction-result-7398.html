<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7398 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7398</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7398</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-274514800</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.03930v2.pdf" target="_blank">GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model</a></p>
                <p><strong>Paper Abstract:</strong> Anomaly detection on text-rich graphs is widely prevalent in real life, such as detecting incorrectly assigned academic papers to authors and detecting bots in social networks. The remarkable capabilities of large language models (LLMs) pave a new revenue by utilizing rich-text information for effective anomaly detection. However, simply introducing rich texts into LLMs can obscure essential detection cues and introduce high fine-tuning costs. Moreover, LLMs often overlook the intrinsic structural bias of graphs which is vital for distinguishing normal from abnormal node patterns. To this end, this paper introduces GuARD, a text-rich and graph-informed language model that combines key structural features from graph-based methods with fine-grained semantic attributes extracted via small language models for effective anomaly detection on text-rich graphs. GuARD is optimized with the progressive multimodal multi-turn instruction tuning framework in the task-guided instruction tuning regime tailed to incorporate both rich-text and structural modalities. Extensive experiments on four datasets reveal that GuARD outperforms graph-based and LLM-based anomaly detection methods, while offering up to 5× speedup in training and 10× speedup in inference over vanilla long-context LLMs on the large-scale WhoIsWho dataset.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7398.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7398.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GuARD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GuARD: Text-Rich and Graph-Informed Language Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A progressive, multi-turn instruction-tuned language-model framework that fuses key textual inputs, summarized semantic embeddings (from a small PLM), and structural embeddings (from a GNN) to detect anomalies in text-rich graphs (e.g., incorrect paper assignments, bot detection).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama3-8B (backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only large language model backbone (Llama3-8B) that is instruction-tuned with a multi-turn question-answering template; uses parameter-efficient fine-tuning (LoRA) and progressive addition of semantic and structural projector modules.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Supervised instruction-tuning / fine-tuning (parameter-efficient LoRA) with progressive multimodal fusion: (1) multi-turn instruction QA over key textual attributes, (2) semantic embeddings from a small PLM projected into a special <text> token, (3) structural embeddings from a GNN projected into a special <graph> token; final prediction via generated <label_token> logits.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Multi-turn instruction template: for each target node (stacked turns) include optional sampled global-context key attributes and the node's key attributes, then ask "Determine whether the following inputs are abnormal nodes and answer 'Yes' or 'No'." individual example form: "<node-key-info> is an outlier.<label_token>". A special <text> token and <graph> token are replaced with projected embeddings per node.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Supervised labeled node-level anomaly datasets: WhoIsWho (incorrect author assignment), MAG (incorrect assignment), TwiBot-20 (bot detection), SemEval-23F (propaganda-technique multi-label); training uses the datasets' train/valid/test splits as described in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text-rich graph node records (long textual attributes per node), with optional global-context lists (e.g., an author's paper list) sampled as context; non-tabular but list-like contexts are used (stacked node queries).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WhoIsWho, MAG, TwiBot-20, SemEval-23F</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC (area under ROC) and MAP (mean average precision)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>GuARD variants outperform baselines; example (Llama3-8B backbone reported in ablations): WhoIsWho AUC progression: base 0.757 -> +semantic projector 0.771 -> +graph projector 0.789; TwiBot-20 AUC progression: base 0.916 -> +sem 0.943 -> +graph 0.945. Full multi-dataset results reported in Table 2 of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to GNN methods (GCN, GCCAD, HGT) and LM baselines (RoBERTa, DeBERTa, vanilla Llama3-8B and Qwen2.5-7B), GuARD (with semantic and graph modules) yields higher AUC/MAP on the evaluated benchmarks; specific baselines used: GCN, GCCAD, HGT, RoBERTa-base, DeBERTa-v3-large, Llama3-8B, Qwen2.5-7B.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fully supervised fine-tuning (LoRA). The multi-turn causal decoding provides an internal 'soft' few-shot demonstration effect at inference (earlier turns serve as contextual demonstrations) but training is supervised.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported limitations include LLM context-length constraints ('lost in the middle' for very long node attributes), high fine-tuning/inference costs for vanilla long-context LLMs (addressed by multi-turn and projectors), and that LLMs alone overlook intrinsic graph structural biases (motivating the structural embedding module). Ablations show that naive long full-text inputs degrade efficiency/accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported efficiency gains over vanilla long-context LLM fine-tuning: 1.15×–5× speedup in training and 3×–10× speedup in inference versus LoRA fine-tuned long-context LLMs. Example timings (WhoIsWho): GuARD-base training ~29.4 min / inference ~6.0 min; full Llama3-8B fine-tune baseline training ~592.8 min / inference ~130.2 min (numbers from Tables 5 and 7).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7398.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7398.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama3-8B (baseline/backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 3 (8B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source decoder-only LLM used both as a baseline for direct prompting/fine-tuning and as the backbone for GuARD instruction-tuning experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama3-8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only large language model used with instruction templates and LoRA fine-tuning; in this paper it serves as the GuARD backbone.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Instruction-tuning / fine-tuning (LoRA) with multi-turn QA prompts over key node textual attributes; used within GuARD progressive pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same multi-turn QA template as GuARD: stacked node queries with optional global context, asking binary 'Is this an outlier? Yes/No' with <label_token> target.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Same anomaly-labeled datasets (WhoIsWho, MAG, TwiBot-20, SemEval-23F) when used as GuARD backbone; also evaluated as a baseline consuming text features directly.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text-rich graph node attributes and sampled global-context lists (author paper lists etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WhoIsWho, MAG, TwiBot-20, SemEval-23F</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC, MAP</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>When used as GuARD backbone (ablation Table 3): WhoIsWho AUC: base 0.757 -> +sem 0.771 -> +graph 0.789; TwiBot-20 AUC: base 0.916 -> +sem 0.943 -> +graph 0.945 (these numbers reflect the progressive improvements when Llama3-8B is backbone of GuARD).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against Qwen2.5-7B backbone and other baselines; provides strong performance that improves further when semantic and graph modules are added.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised fine-tuning with LoRA; multi-turn decoding provides in-context demonstrations during generation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same LLM long-context limitations and structure-blindness discussed; direct full-text fine-tuning is computationally expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>As reported: full vanilla Llama3-8B fine-tuning is far more expensive than GuARD variants (e.g., hundreds of minutes vs. <1 hour for GuARD-base on WhoIsWho). See Table 5 and Table 7 for exact run-times.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7398.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7398.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2.5-7B (baseline/backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2.5 (7B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-sourced decoder-only LLM evaluated as a backbone in ablations and compared as an LLM baseline for anomaly detection in text-rich graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2.5-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only instruction-capable LLM (7B) used with LoRA fine-tuning in the GuARD progressive pipeline and as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Instruction-tuning / LoRA fine-tuning with multi-turn QA prompts over key textual attributes; also backbone for GuARD semantic+graph modules in ablation experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same multi-turn instruction template (stacked 'Is this an outlier? Yes/No' queries with <label_token>).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>WhoIsWho, MAG, TwiBot-20, SemEval-23F (same supervised datasets as other models in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text-rich graph node attributes and optional global-context lists</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WhoIsWho, MAG, TwiBot-20, SemEval-23F</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC, MAP</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Ablation progression (Table 3, Qwen2.5-7B backbone): WhoIsWho AUC: base 0.724 -> +sem 0.773 -> +graph 0.780; TwiBot-20 AUC: base 0.907 -> +sem 0.947 -> +graph 0.946.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with Llama3-8B backbone and other baselines; shows similar stepwise gains from the semantic and structural modules.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised fine-tuning (LoRA); internal multi-turn demonstrations at inference provide few-shot-like context.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same context-length and structural-awareness limitations as other LLMs; gains depend on effective projector training and progressive integration.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Reported in ablations as less efficient to fully fine-tune than GuARD progressive approach; specific timing numbers for GuARD variants reported in Tables 5 and 7.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7398.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7398.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa (as semantic encoder / baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa-base</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A small pre-trained Transformer encoder (RoBERTa-base) used in this work both as a baseline classifier (fine-tuned) and as the small PLM for the semantic embedding module to summarize rich textual attributes per node.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa-base</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-only Transformer pre-trained model; used to produce token-level embeddings for node rich-text attributes, with mean-pooling + 2-layer FFN projector to align into LLM hidden space; also used as a fine-tuned baseline classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>base (~110M parameters typical for RoBERTa-base)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Fine-tuning for node-level classification (baseline) and as semantic-embedding encoder feeding projected summarized embeddings into the LLM (<text> token replacement).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Not applicable for RoBERTa when used as encoder; when used as baseline it is fine-tuned for binary classification on node text.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Used on the same supervised anomaly datasets (WhoIsWho, MAG, TwiBot-20, SemEval-23F) as either a baseline classifier or as the semantic-embedding PLM.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Node textual attributes (token sequences); not an LLM prompt consumer when used as encoder.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WhoIsWho, MAG, TwiBot-20, SemEval-23F</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC, MAP</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported as a baseline in Table 2 (paper reports baseline results for RoBERTa fine-tuned for node classification on the datasets); (example approximate values in Table 2 for WhoIsWho appear as AUC ~0.649, MAP ~0.550).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Underperforms LLM-based approaches in the paper's evaluations; used mainly to produce compact semantic embeddings to augment GuARD.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised fine-tuning for baseline classification; used frozen or fixed as PLM encoder when producing semantic embeddings in GuARD pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>SLM-based methods (including RoBERTa) consistently underperformed LLM-based methods on the evaluated text-rich graph tasks according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7398.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7398.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM-IND</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGLM-IND (author-IND formulation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior LLM-based approach that frames an author's paper list as the global context and trains an LLM to detect incorrectly attributed papers by comparing local and global contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGLM family (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned LLM variant applied to incorrect assignment detection by treating an author's paper list as global context for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>LLM-based contextual comparison: present global paper list and local paper attributes to LLM; detect anomalies by similarity/semantic coherence checks.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Defines an author's paper list as global context and asks the LLM to assess whether a candidate paper is anomalous compared to that global context (paper references this prior work's framing).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Lists of papers per author (textual list context)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>referenced in related work (cited as [54] in paper) — used for incorrect assignment detection tasks</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not reported in this paper (referenced work contains details).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Mentioned as prior LLM-based work; performance numbers are not reproduced in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Cited as an example LLM approach that uses global lists as context; GuARD compares conceptually and addresses scale/context limitations described in such works.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Described as instruction-tuning approach in referenced work; classification likely supervised in referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes that such LLM-based approaches can struggle with massive global-context lists (e.g., prolific authors with >1,000 papers) due to long-context limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7398.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7398.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LMBot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LMBot</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced method that distills GNN knowledge into a small language model so that GNN and SLM mutually enhance bot-detection capabilities; cited in related work as hybrid graph+LM approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LMBot (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Iterative distillation between a Graph Neural Network and a small language model to transfer structural knowledge into an LM for graph-less deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>small language model (not specified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Knowledge distillation between GNN and SLM to improve bot-detection; hybrid structural + textual modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Social network user metadata and text (node attributes, ego-network structure)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>TwiBot-style bot detection datasets (referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not reported in this paper (referenced work contains details).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Mentioned in related work; no experimental numbers reproduced here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Cited to motivate approaches that jointly leverage structure and textual models; GuARD similarly aims to combine structural GNN features with LLM semantic features.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed in this paper (referenced work contains details).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ChatGLM-IND <em>(Rating: 2)</em></li>
                <li>LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection <em>(Rating: 2)</em></li>
                <li>GCCAD: Graph contrastive coding for anomaly detection <em>(Rating: 2)</em></li>
                <li>LogLLM: Log-based anomaly detection using large language models <em>(Rating: 2)</em></li>
                <li>DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection <em>(Rating: 1)</em></li>
                <li>AD-LLM: Benchmarking Large Language Models for Anomaly Detection <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7398",
    "paper_id": "paper-274514800",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "GuARD",
            "name_full": "GuARD: Text-Rich and Graph-Informed Language Model",
            "brief_description": "A progressive, multi-turn instruction-tuned language-model framework that fuses key textual inputs, summarized semantic embeddings (from a small PLM), and structural embeddings (from a GNN) to detect anomalies in text-rich graphs (e.g., incorrect paper assignments, bot detection).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama3-8B (backbone)",
            "model_description": "Decoder-only large language model backbone (Llama3-8B) that is instruction-tuned with a multi-turn question-answering template; uses parameter-efficient fine-tuning (LoRA) and progressive addition of semantic and structural projector modules.",
            "model_size": "8B",
            "anomaly_detection_approach": "Supervised instruction-tuning / fine-tuning (parameter-efficient LoRA) with progressive multimodal fusion: (1) multi-turn instruction QA over key textual attributes, (2) semantic embeddings from a small PLM projected into a special &lt;text&gt; token, (3) structural embeddings from a GNN projected into a special &lt;graph&gt; token; final prediction via generated &lt;label_token&gt; logits.",
            "prompt_template": "Multi-turn instruction template: for each target node (stacked turns) include optional sampled global-context key attributes and the node's key attributes, then ask \"Determine whether the following inputs are abnormal nodes and answer 'Yes' or 'No'.\" individual example form: \"&lt;node-key-info&gt; is an outlier.&lt;label_token&gt;\". A special &lt;text&gt; token and &lt;graph&gt; token are replaced with projected embeddings per node.",
            "training_data": "Supervised labeled node-level anomaly datasets: WhoIsWho (incorrect author assignment), MAG (incorrect assignment), TwiBot-20 (bot detection), SemEval-23F (propaganda-technique multi-label); training uses the datasets' train/valid/test splits as described in the paper.",
            "data_type": "Text-rich graph node records (long textual attributes per node), with optional global-context lists (e.g., an author's paper list) sampled as context; non-tabular but list-like contexts are used (stacked node queries).",
            "dataset_name": "WhoIsWho, MAG, TwiBot-20, SemEval-23F",
            "evaluation_metric": "AUC (area under ROC) and MAP (mean average precision)",
            "performance": "GuARD variants outperform baselines; example (Llama3-8B backbone reported in ablations): WhoIsWho AUC progression: base 0.757 -&gt; +semantic projector 0.771 -&gt; +graph projector 0.789; TwiBot-20 AUC progression: base 0.916 -&gt; +sem 0.943 -&gt; +graph 0.945. Full multi-dataset results reported in Table 2 of the paper.",
            "baseline_comparison": "Compared to GNN methods (GCN, GCCAD, HGT) and LM baselines (RoBERTa, DeBERTa, vanilla Llama3-8B and Qwen2.5-7B), GuARD (with semantic and graph modules) yields higher AUC/MAP on the evaluated benchmarks; specific baselines used: GCN, GCCAD, HGT, RoBERTa-base, DeBERTa-v3-large, Llama3-8B, Qwen2.5-7B.",
            "zero_shot_or_few_shot": "Fully supervised fine-tuning (LoRA). The multi-turn causal decoding provides an internal 'soft' few-shot demonstration effect at inference (earlier turns serve as contextual demonstrations) but training is supervised.",
            "limitations_or_failure_cases": "Reported limitations include LLM context-length constraints ('lost in the middle' for very long node attributes), high fine-tuning/inference costs for vanilla long-context LLMs (addressed by multi-turn and projectors), and that LLMs alone overlook intrinsic graph structural biases (motivating the structural embedding module). Ablations show that naive long full-text inputs degrade efficiency/accuracy.",
            "computational_cost": "Reported efficiency gains over vanilla long-context LLM fine-tuning: 1.15×–5× speedup in training and 3×–10× speedup in inference versus LoRA fine-tuned long-context LLMs. Example timings (WhoIsWho): GuARD-base training ~29.4 min / inference ~6.0 min; full Llama3-8B fine-tune baseline training ~592.8 min / inference ~130.2 min (numbers from Tables 5 and 7).",
            "uuid": "e7398.0",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "Llama3-8B (baseline/backbone)",
            "name_full": "Llama 3 (8B)",
            "brief_description": "An open-source decoder-only LLM used both as a baseline for direct prompting/fine-tuning and as the backbone for GuARD instruction-tuning experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama3-8B",
            "model_description": "Decoder-only large language model used with instruction templates and LoRA fine-tuning; in this paper it serves as the GuARD backbone.",
            "model_size": "8B",
            "anomaly_detection_approach": "Instruction-tuning / fine-tuning (LoRA) with multi-turn QA prompts over key node textual attributes; used within GuARD progressive pipeline.",
            "prompt_template": "Same multi-turn QA template as GuARD: stacked node queries with optional global context, asking binary 'Is this an outlier? Yes/No' with &lt;label_token&gt; target.",
            "training_data": "Same anomaly-labeled datasets (WhoIsWho, MAG, TwiBot-20, SemEval-23F) when used as GuARD backbone; also evaluated as a baseline consuming text features directly.",
            "data_type": "Text-rich graph node attributes and sampled global-context lists (author paper lists etc.)",
            "dataset_name": "WhoIsWho, MAG, TwiBot-20, SemEval-23F",
            "evaluation_metric": "AUC, MAP",
            "performance": "When used as GuARD backbone (ablation Table 3): WhoIsWho AUC: base 0.757 -&gt; +sem 0.771 -&gt; +graph 0.789; TwiBot-20 AUC: base 0.916 -&gt; +sem 0.943 -&gt; +graph 0.945 (these numbers reflect the progressive improvements when Llama3-8B is backbone of GuARD).",
            "baseline_comparison": "Compared against Qwen2.5-7B backbone and other baselines; provides strong performance that improves further when semantic and graph modules are added.",
            "zero_shot_or_few_shot": "Supervised fine-tuning with LoRA; multi-turn decoding provides in-context demonstrations during generation.",
            "limitations_or_failure_cases": "Same LLM long-context limitations and structure-blindness discussed; direct full-text fine-tuning is computationally expensive.",
            "computational_cost": "As reported: full vanilla Llama3-8B fine-tuning is far more expensive than GuARD variants (e.g., hundreds of minutes vs. &lt;1 hour for GuARD-base on WhoIsWho). See Table 5 and Table 7 for exact run-times.",
            "uuid": "e7398.1",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "Qwen2.5-7B (baseline/backbone)",
            "name_full": "Qwen2.5 (7B)",
            "brief_description": "An open-sourced decoder-only LLM evaluated as a backbone in ablations and compared as an LLM baseline for anomaly detection in text-rich graphs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2.5-7B",
            "model_description": "Decoder-only instruction-capable LLM (7B) used with LoRA fine-tuning in the GuARD progressive pipeline and as a baseline.",
            "model_size": "7B",
            "anomaly_detection_approach": "Instruction-tuning / LoRA fine-tuning with multi-turn QA prompts over key textual attributes; also backbone for GuARD semantic+graph modules in ablation experiments.",
            "prompt_template": "Same multi-turn instruction template (stacked 'Is this an outlier? Yes/No' queries with &lt;label_token&gt;).",
            "training_data": "WhoIsWho, MAG, TwiBot-20, SemEval-23F (same supervised datasets as other models in paper).",
            "data_type": "Text-rich graph node attributes and optional global-context lists",
            "dataset_name": "WhoIsWho, MAG, TwiBot-20, SemEval-23F",
            "evaluation_metric": "AUC, MAP",
            "performance": "Ablation progression (Table 3, Qwen2.5-7B backbone): WhoIsWho AUC: base 0.724 -&gt; +sem 0.773 -&gt; +graph 0.780; TwiBot-20 AUC: base 0.907 -&gt; +sem 0.947 -&gt; +graph 0.946.",
            "baseline_comparison": "Compared with Llama3-8B backbone and other baselines; shows similar stepwise gains from the semantic and structural modules.",
            "zero_shot_or_few_shot": "Supervised fine-tuning (LoRA); internal multi-turn demonstrations at inference provide few-shot-like context.",
            "limitations_or_failure_cases": "Same context-length and structural-awareness limitations as other LLMs; gains depend on effective projector training and progressive integration.",
            "computational_cost": "Reported in ablations as less efficient to fully fine-tune than GuARD progressive approach; specific timing numbers for GuARD variants reported in Tables 5 and 7.",
            "uuid": "e7398.2",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "RoBERTa (as semantic encoder / baseline)",
            "name_full": "RoBERTa-base",
            "brief_description": "A small pre-trained Transformer encoder (RoBERTa-base) used in this work both as a baseline classifier (fine-tuned) and as the small PLM for the semantic embedding module to summarize rich textual attributes per node.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RoBERTa-base",
            "model_description": "Encoder-only Transformer pre-trained model; used to produce token-level embeddings for node rich-text attributes, with mean-pooling + 2-layer FFN projector to align into LLM hidden space; also used as a fine-tuned baseline classifier.",
            "model_size": "base (~110M parameters typical for RoBERTa-base)",
            "anomaly_detection_approach": "Fine-tuning for node-level classification (baseline) and as semantic-embedding encoder feeding projected summarized embeddings into the LLM (&lt;text&gt; token replacement).",
            "prompt_template": "Not applicable for RoBERTa when used as encoder; when used as baseline it is fine-tuned for binary classification on node text.",
            "training_data": "Used on the same supervised anomaly datasets (WhoIsWho, MAG, TwiBot-20, SemEval-23F) as either a baseline classifier or as the semantic-embedding PLM.",
            "data_type": "Node textual attributes (token sequences); not an LLM prompt consumer when used as encoder.",
            "dataset_name": "WhoIsWho, MAG, TwiBot-20, SemEval-23F",
            "evaluation_metric": "AUC, MAP",
            "performance": "Reported as a baseline in Table 2 (paper reports baseline results for RoBERTa fine-tuned for node classification on the datasets); (example approximate values in Table 2 for WhoIsWho appear as AUC ~0.649, MAP ~0.550).",
            "baseline_comparison": "Underperforms LLM-based approaches in the paper's evaluations; used mainly to produce compact semantic embeddings to augment GuARD.",
            "zero_shot_or_few_shot": "Supervised fine-tuning for baseline classification; used frozen or fixed as PLM encoder when producing semantic embeddings in GuARD pipeline.",
            "limitations_or_failure_cases": "SLM-based methods (including RoBERTa) consistently underperformed LLM-based methods on the evaluated text-rich graph tasks according to the paper.",
            "computational_cost": null,
            "uuid": "e7398.3",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "ChatGLM-IND",
            "name_full": "ChatGLM-IND (author-IND formulation)",
            "brief_description": "A prior LLM-based approach that frames an author's paper list as the global context and trains an LLM to detect incorrectly attributed papers by comparing local and global contexts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "ChatGLM family (referenced)",
            "model_description": "Instruction-tuned LLM variant applied to incorrect assignment detection by treating an author's paper list as global context for anomaly detection.",
            "model_size": "not specified in this paper",
            "anomaly_detection_approach": "LLM-based contextual comparison: present global paper list and local paper attributes to LLM; detect anomalies by similarity/semantic coherence checks.",
            "prompt_template": "Defines an author's paper list as global context and asks the LLM to assess whether a candidate paper is anomalous compared to that global context (paper references this prior work's framing).",
            "training_data": null,
            "data_type": "Lists of papers per author (textual list context)",
            "dataset_name": "referenced in related work (cited as [54] in paper) — used for incorrect assignment detection tasks",
            "evaluation_metric": "Not reported in this paper (referenced work contains details).",
            "performance": "Mentioned as prior LLM-based work; performance numbers are not reproduced in this paper.",
            "baseline_comparison": "Cited as an example LLM approach that uses global lists as context; GuARD compares conceptually and addresses scale/context limitations described in such works.",
            "zero_shot_or_few_shot": "Described as instruction-tuning approach in referenced work; classification likely supervised in referenced work.",
            "limitations_or_failure_cases": "Paper notes that such LLM-based approaches can struggle with massive global-context lists (e.g., prolific authors with &gt;1,000 papers) due to long-context limitations.",
            "computational_cost": null,
            "uuid": "e7398.4",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "LMBot",
            "name_full": "LMBot",
            "brief_description": "A referenced method that distills GNN knowledge into a small language model so that GNN and SLM mutually enhance bot-detection capabilities; cited in related work as hybrid graph+LM approach.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LMBot (referenced)",
            "model_description": "Iterative distillation between a Graph Neural Network and a small language model to transfer structural knowledge into an LM for graph-less deployment.",
            "model_size": "small language model (not specified in this paper)",
            "anomaly_detection_approach": "Knowledge distillation between GNN and SLM to improve bot-detection; hybrid structural + textual modeling.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "Social network user metadata and text (node attributes, ego-network structure)",
            "dataset_name": "TwiBot-style bot detection datasets (referenced work)",
            "evaluation_metric": "Not reported in this paper (referenced work contains details).",
            "performance": "Mentioned in related work; no experimental numbers reproduced here.",
            "baseline_comparison": "Cited to motivate approaches that jointly leverage structure and textual models; GuARD similarly aims to combine structural GNN features with LLM semantic features.",
            "zero_shot_or_few_shot": "Not specified here.",
            "limitations_or_failure_cases": "Not detailed in this paper (referenced work contains details).",
            "computational_cost": null,
            "uuid": "e7398.5",
            "source_info": {
                "paper_title": "GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model",
                "publication_date_yy_mm": "2025-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ChatGLM-IND",
            "rating": 2,
            "sanitized_title": "chatglmind"
        },
        {
            "paper_title": "LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection",
            "rating": 2,
            "sanitized_title": "lmbot_distilling_graph_knowledge_into_language_model_for_graphless_deployment_in_twitter_bot_detection"
        },
        {
            "paper_title": "GCCAD: Graph contrastive coding for anomaly detection",
            "rating": 2,
            "sanitized_title": "gccad_graph_contrastive_coding_for_anomaly_detection"
        },
        {
            "paper_title": "LogLLM: Log-based anomaly detection using large language models",
            "rating": 2,
            "sanitized_title": "logllm_logbased_anomaly_detection_using_large_language_models"
        },
        {
            "paper_title": "DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection",
            "rating": 1,
            "sanitized_title": "dell_generating_reactions_and_explanations_for_llmbased_misinformation_detection"
        },
        {
            "paper_title": "AD-LLM: Benchmarking Large Language Models for Anomaly Detection",
            "rating": 2,
            "sanitized_title": "adllm_benchmarking_large_language_models_for_anomaly_detection"
        }
    ],
    "cost": 0.0181995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model
7 Aug 2025</p>
<p>Yunhe Pang 
Bo Chen 
Fanjin Zhang fanjinz@tsinghua.edu.cn 
Yanghui Rao raoyangh@mail.sysu.edu.cn 
Evgeny Kharlamov evgeny.kharlamov@de.bosch.com 
Jie Tang jietang@tsinghua.edu.cn </p>
<p>School of Computer Science
Engineering Sun Yat-Sen University
GuangzhouChina</p>
<p>Department of Computer Science
Technology Tsinghua University
BeijingChina</p>
<p>Department of Computer Science
Technology Tsinghua University
BeijingChina</p>
<p>School of Computer Science
Engineering Sun Yat-Sen University
GuangzhouChina</p>
<p>Bosch Center for Artificial Intelligence
Robert Bosch GmbH
RenningenGermany</p>
<p>Department of Computer Science
Technology Tsinghua University
BeijingChina</p>
<p>August 3-7, 12 pages2025Toronto, New YorkON, NYCanada. ACM, USA</p>
<p>GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model
7 Aug 20253C02A54821CD1EA6DAA2284AC83879F210.1145/3711896.3736993arXiv:2412.03930v2[cs.CL]CCS ConceptsComputing methodologies → Neural networks; Information extraction Anomaly detectionAuthor name disambiguationLarge language model
Anomaly detection on text-rich graphs is widely prevalent in real life, such as detecting incorrectly assigned academic papers to authors and detecting bots in social networks.The remarkable capabilities of large language models (LLMs) pave a new revenue by utilizing rich-text information for effective anomaly detection.However, simply introducing rich texts into LLMs can obscure essential detection cues and introduce high fine-tuning costs.Moreover, LLMs often overlook the intrinsic structural bias of graphs which is vital for distinguishing normal from abnormal node patterns.To this end, this paper introduces GuARD, a text-rich and graphinformed language model that combines key structural features from graph-based methods with fine-grained semantic attributes extracted via small language models for effective anomaly detection on text-rich graphs.GuARD is optimized with the progressive multimodal multi-turn instruction tuning framework in the task-guided instruction tuning regime tailed to incorporate both rich-text and structural modalities.Extensive experiments on four datasets reveal that GuARD outperforms graph-based and LLM-based anomaly detection methods, while offering up to 5× speedup in training and 10× speedup in inference over vanilla long-context LLMs on the large-scale WhoIsWho dataset.</p>
<p>Introduction</p>
<p>Anomaly detection in text-rich graphs arises in many real-world applications, ranging identifying incorrectly assigned academic papers to authors with ambiguous names [5,53], to the detection of bots and misinformation in social networks [7,31].These scenarios are becoming increasingly common due to the substantial proliferation of research papers and the influx of abundant AI-generated content on the web.Taking academic networks [43,52,53] as an example (Figure 1(a)), detecting incorrect assignment papers in the academic network requires not only a nuanced understanding of the semantic coherence between papers and authors, but also the structural roles emphasized by graph topology.Other applications like bot detection and misinformation detection (Figure 1(b,c)) face similar challenges.</p>
<p>Existing endeavors commonly focus on either detecting outliers purely based on the structural traits or discerning abnormal signals from informative text spans [41,42,50], which pays less attention to anomaly detection on real-world text-rich graphs.Among these attempts, GCCAD [6] contrasts each node with the global context to learn discriminative node embeddings.LMBot [4] iteratively distills knowledge from graph neural network(GNN) to small language model (SLM) to allow GNN and SLM to mutually enhance each other.However, these graph-based methods focus more on key structural features and implicitly incorporate short textual features via input node features, but lack characterizing the fine-grained semantic features embodied in node attributes.</p>
<p>Recently, large language models (LLMs) [3,56] have shown remarkable performance across a wide range of natural language understanding and generation tasks, underpinned by their ability to capture fine-grained correlations through self-attention.Several efforts [47,54,55] employ LLMs as the backbone and design specialized instruction templates for anomaly detection tasks.Despite these advances, LLM-based methods may struggle when confronted with massive input texts.For example, in the realm of detecting incorrect paper assignments within academic networks, a productive author can have over 1,000 papers and each paper possesses rich attributes (e.g., title, venue, author list, etc.).For fake news detection, some news articles can be thousands of words long.Processing such long context input can dilute critical detection signals and greatly increase fine-tuning costs.Moreover, LLMs typically do not capture intrinsic structural biases in graph topologies.Therefore, a holistic model that can effectively harness both the long-text attributes and structural relations in text-rich graphs is in great demand.Present Work.Inspired by the aforementioned insights, we propose GuARD, a text-rich and graph-informed language model for anomaly detection that combines the strengths of key structural feature extraction endowed by graph-based methods and the finegrained semantic features characterized by language models via effective multi-modal fusion.Practically, we adopt a multi-modallike multi-turn instruction tuning framework to incorporate each modality step by step as follows:</p>
<p>(1) Task-Guided Multi-Turn Instruction Tuning: In the first stage, we aim to align the language model backbone to tackle the anomaly detection task via an instruction-tuning regime.Specifically, we design a task-specific instruction template, as shown in Figure 3, which takes the optional global context and target nodes as input and asks the LLMs to generate the label token supervised by ground truths.To foster context sharing and improve training/inference efficiency, we further design a multiturn chat instruction template, which significantly improves the accuracy and efficiency of our model.(2) Semantic Embedding Module with Rich Attributes: Limited by the context length, LLMs can only take nodes' key features as input.To incorporate more informative nodal textual attributes into our framework, we employ a semantic embedding module that extracts and summarizes rich textual attributes through a small pre-trained language model, and then utilize a text projector to obtain a special text token that serves as the summarized semantic feature of each node.(3) Structural Embedding Module: To endow LLMs with the capacity to capture structural information, we employ a structural embedding module that extracts and summarizes structural features from the graph-based methods, and then utilizes a graph projector to obtain a special graph token that acts as the structural feature of each node.</p>
<p>Through these three successive stages of multi-modal-like instruction tuning, both structural features and rich semantic characteristics are dynamically and effectively fused for robust anomaly detection.Extensive experimental results on four datasets highlight the superiority of our proposed method.Compared to advanced fine-tuned LLMs, GuARD achieves better or comparable anomaly detection accuracy, while significantly improving fine-tuning and inference time efficiency (1.15×-5× speedup in training and 3×-10× speedup in inference w.r.t.LoRA fine-tuned LLMs).</p>
<p>Related Work</p>
<p>Anomaly detection includes a variety of forms, including time-series anomaly detection, graph anomaly detection, and text/log anomaly detection.This work primarily focuses on anomaly detection in scenarios with rich-text data and underlying graph structures.</p>
<p>LM-based Anomaly Detection</p>
<p>Language model-based approaches for anomaly detection leverage the semantic distributional differences in textual data to identify anomalous attributes or outlying instances.These methods have been successfully applied in tasks such as spam detection, fraud detection [1,46], bot detection [12], and log analysis [15].ChatGLM-IND [54] defines an author's paper list as the global context.It trains LLMs to detect anomalies by assessing the similarity between the global and local contexts to determine whether a paper is anomalously attributed to an author.LMBot [4] enhances the capabilities of language models by iteratively fine-tuning a combination of language models and graph neural networks.This joint optimization improves the model's ability to differentiate between human and bot-generated text effectively.BotSay [13] adopts an in-context learning (ICL) paradigm with LLMs.By incorporating information from a user's ego-networks, the model becomes better informed and guided in the task of bot detection.DELL [45] employs a language model-based framework to enhance textual data via relevance analysis.It utilizes the outputs of a large language model to augment the original text and then fine-tunes the DeBERTa [17] model for text representation learning.</p>
<p>Graph-based Anomaly Detection</p>
<p>Graph anomaly detection [6,11,33], compared to text-based anomaly detection, places greater emphasis on identifying structural anomalies within graph data.Graph anomaly detection has been widely applied in scenarios with a large number of nodes and complex connections, such as social networks and citation networks.GCCAD [6] introduces a contrastive learning framework for nodes and edges, which enhances network representation learning by identifying and removing incorrectly connected edges.This approach has demonstrated effectiveness in tasks such as financial fraud detection and identifying anomalous paper assignments.In the task of bot detection in social networks, node classification models based on heterogeneous graph neural networks, such as HGT and RGCN [19,32,38], have shown strong performance by effectively leveraging the heterogeneity and structural dependencies in the graph.Moreover, certain text-based anomaly detection methods construct graph structures via data augmentation techniques, either by modeling relationships between samples or within samples.These graph-based representations are often employed to provide additional signals for detecting anomalies in textual sequences.In addition, some studies [45] construct comment networks and employ structural representation learning methods to incorporate non-textual features into the misinformation detection task.Leveraging graph structures alongside textual content improves the model's effectiveness in identifying misinformation.</p>
<p>Despite extensive studies on anomaly detection, existing graphbased and small pre-trained language model-based methods have been found to lag behind LLM-based approaches [54].However, recent LLM-based methods struggle to efficiently and effectively utilize long-text information and graph structure information.In this paper, we propose GuARD, a text-rich and graph-informed language model that effectively combines key textual features, rich textual attributes, and structural features in a progressive manner.</p>
<p>Problem Definition</p>
<p>In this section, we introduce the problem formulation of anomaly detection in text-rich graphs.Definition 3.1.Text-Rich Graphs.A text-rich graph is a graph  = (V, E, S), where each node   ∈ V is associated with multiple attributes that make up a long text sequence   ∈ S and E represents the set of edges between nodes.</p>
<p>Problem 1. Anomaly Detection on Text-Rich Graphs.Given a text-rich graph  = (V, E, S, Y), where Y is the set of node labels with   ∈ Y be equal to 1 if node   is abnormal and 0 otherwise, the goal is to find a function  : V → {0, 1} to determine whether a given node is an anomaly or not.</p>
<p>Model Framework</p>
<p>Previous anomaly detection methods on text-rich graphs typically adopt pre-trained language model-based methods or graph-based methods.Graph-based methods fall short of capturing the semantic coherence across text-rich nodes.Although large language models [29,34], which formalize the anomaly detection problem as a question-answering task, excel in capturing intricate semantic correlations between nodes, they usually cannot extract crucial detection information among the massive input text effectively (e.g.&gt; 10K).Furthermore, the intrinsic capacity of LLMs struggles to capture structural patterns of graphs.</p>
<p>In view these challenges, we propose GuARD, a text-rich and graph-informed language model to detect anomalies on text-rich graphs.Firstly, GuARD introduces an effective LLM-based multiturn instruction tuning framework, which takes the key textual information of multiple nodes as input, enabling the basic capacity of detecting anomalies (see Section 4.1).After that, we enhance this by introducing other rich attributes into the LLM through a semantic embedding module.This module summarizes the rich text attributes of each node, projecting them as semantic tokens into the LLM (see Section 4.2).Subsequently, we employ a graph embedding module to integrate structural features, converting them into structural tokens for ingestion by the LLM (see Section 4.3).Lastly, we adopt a progressive training algorithm to ensure these modalities-key textual, semantic, and graph-based-are effectively combined (see Section 4.4).In the following sections, we delve into the details of each component.</p>
<p>Text Encoder</p>
<p>Graph Encoder</p>
<p>Determine whether the following inputs are abnormal nodes and answer 'Yes' or 'No`."</p>
<p>" is an outlier.<label_token>.</p>
<p>"</p>
<p>" is an outlier.<label_token>.</p>
<p>Optional Global Context</p>
<p>Figure 3: The entire workflow of GuARD in detecting anomalies on text-rich graphs.The entire instruction template comprises three parts of input: 1) key information (e.g.title) from each node (e.g.paper) is used as direct input tokens of the LLM; 2) textual embedding provided by the semantic embedding module serves as a summarized embedding of the rich attributes of each node by replacing the token <text>; 3) structural embedding from the structural embedding module is incorporated into the LLM by replacing the token <graph> in LLM input.Our framework trains different modules progressively in each modality to predict a special token <label_token>.</p>
<p>Task-Guided Multi-Turn Instruction Tuning</p>
<p>Prior arts [6,54] usually adopt graph-based methods for the anomaly detection problem.However, recent attempts [50,54] leverage the LLMs as the backbone, holding the promise that it can capture semantic coherence among rich attributes to distinguish the anomaly patterns, which demonstrate the strong capacity of detecting anomalies.Inspired by this, we formalize the anomaly detection problem as a question-answering task, define an instruction template by incorporating the node attributes and its global contexts (if any), and then ask the LLM to answer whether the given node is an anomaly or not.Noted that, the global context of the text-rich graph is not always necessary.In certain scenarios, the anomaly can be distinguished by contrast it with the surrounding global context [6].Taking the academic network as an example, a paper is detected as incorrectly assigned when it has a topic discrepant from the assigned author's profile, while for social bot detection, each node does not possess a global context.</p>
<p>To convert the anomaly detection task into question-answering instructions, a straightforward idea is to feed all textual attributes of each node and then ask whether this node is an anomaly or not.However, this solution raises the following concerns.On the one hand, the long-context LLMs still struggle to identify relevant information and face the "lost in the middle" issue [28].On the other hand, fine-tuning and inference of long-context LLMs incur significant time costs and memory costs.</p>
<p>To this end, we choose key textual attributes of each node as the LLM input.For different scenarios, where the textual information varies, we also select different information as the key attributes (described in section 5.2).If a node's anomaly depends on its global context, we randomly sample a fixed number of nodes in the global context from the graph and prepend their key attributes to the instruction template.We then append the target node's attributes, prompting the LLM to determine the anomaly via a custom token, <label_token>.However, due to the inefficiency of predicting anomalies one node at a time, we design a multi-turn instruction template that utilizes the shared contextual information across different nodes to be detected.Figure 3 illustrates the corresponding instruction template.By stacking multiple local queries into the input, we generate multiple predictive results for multiple nodes in a single auto-regressive decoding step.This significantly reduces the model training and inference time, with only a minor computational overhead from limited key contextual inputs.The training objective is defined as:
L = − 𝑁 ∑︁ 𝑖=1 log 𝑝 (𝑤 𝑖 | context 𝑖 )(1)
where  denotes the number of stacking target nodes and   denotes the logits of the ground-truth label of <label_token>.</p>
<p>Note that LLMs typically use a causal masking format in their selfattention, allowing subsequent queries to incorporate information from earlier ones and thus providing richer context.Consequently, the detection information of earlier queries can serve as few-shot examples for the prediction of label tokens in latter queries.This mechanism leverages both the correlation between the target node and its global context and the relevance of preceding queries, enhancing the prediction accuracy for latter queries.</p>
<p>During the inference phase, we directly take the normalized logit of token "Yes" and token "No" as the final logit of <label_token>.The final logit is calculated by:
𝑦 𝑖 = 𝑧 𝑦 𝑖 𝑧 𝑦 𝑖 + 𝑧 𝑛 𝑖 (2)
where    and    denote the logit of "Yes" and "No" for the -th query, respectively.</p>
<p>Semantic Embedding Module</p>
<p>Due to the context-length limitation of LLMs, it is infeasible to incorporate all rich textual attributes of each node into LLMs.Principally, longer context lengths demand substantially increased GPU memory and computational cost.As as result, only the key features can be selected as the basic detection information into LLMs as detailed in Section 4.1.To comprehensively leverage the remaining rich textual information, we propose a semantic embedding module.Specifically, it adopts a small pre-trained language model to convert textual attributes into a sequence of embeddings.Additionally, an adaptive pooling module is used to summarize these embeddings, and a text projector is employed to align the feature space of the semantic embedding module with that of LLMs.</p>
<p>For each input node, a pre-trained language model (PLM) [10,29] is leveraged as a text encoder to derive token-level representations of these nodes.Specifically, let   denote the -th node in the graph, and   = { 0  ,  1  , ...,    }, where    denotes the -th token in the text sequence.We obtain the textual embedding by applying mean pooling to the PLM-embedded text sequence and further use a two-layer feed-forward network (FFN) with a Swish activation function [36,39] as the projector to align the dimension of the PLM's token representation with the input dimension of the LLM.The entire process of the semantic embedding module and the alignment can be represented as follows:
{ℎ 0 𝑖 , ℎ 1 𝑖 , ..., ℎ 𝑛 𝑖 } = PLM({𝑥 0 𝑖 , 𝑥 1 𝑖 , ..., 𝑥 𝑛 𝑖 })(3)𝐻 𝑖 = mean-pooling({ℎ 0 𝑖 , ℎ 1 𝑖 , ..., ℎ 𝑛 𝑖 })(4)𝐻 ′ 𝑖 = FFN Swish (𝐻 𝑖 )(5)
where ℎ   denotes the hidden representation of token    and  ′  is the summarized semantic embedding.</p>
<p>To integrate the summarized semantic features into the LLM input, an external token <text> is introduced and strategically positioned at the beginning of each node's input text.By replacing the original embedding of this token in the LLM with the embedding  ′  projected from the semantic embedding module, the supplementary textual features are effectively incorporated into the LLM input.</p>
<p>Structural Embedding Module</p>
<p>Existing attempts [6,54] demonstrate that graph neural networks (GNNs) excel at detecting anomalies through a comprehensive understanding of the node features and graph topology.However, the existing LLMs are not adept at capturing structural information.To address this gap, we train a state-of-the-art GNN-based anomaly detection method such as GCCAD [6] or HGT [19] to obtain the structural-enhanced node and graph embeddings.Then the node and graph representations are concatenated to form the structural features of each node.Finally, a graph projector is utilized to align the structural features with the hidden space of LLMs.</p>
<p>Let A denote the adjacency matrix of the input graph and  nd denote the node input features.The procedure of the structural embedding module can be formalized as follows:
𝑍 𝑔 , {𝑍 0 , 𝑍 1 , ..., 𝑍 𝑚 } = GNN(A, 𝑋 nd )(6)𝑍 ′ 𝑖 = FFN Swish (concat(𝑍 𝑖 , 𝑍 𝑔 ))(7)
where   and   denotes the learned graph embedding and the -th node's hidden embedding, respectively.Then the concatenated node and graph embedding are fed into a 2-layer FFN projector to obtain the input graph embedding for the LLM.Correspondingly, we define a similar special graph token <graph>, which is positioned prior to <text> and added into the input of LLM.The original embedding of <graph> is replaced by the embedding  ′  .</p>
<p>Progressive Instruction-tuning</p>
<p>To effectively intergrate the three modalities features-key textual, semantic, and graph-into our framework, we employ a three-phase progressive instruction-tuning procedure.In the first phase as detailed in Section 4.1, we begin with training the base LLM utilizing parameter-efficient fine-tuning [16,18,26], endowing it with basic anomaly detection capabilities.</p>
<p>In the second phase, we freeze the parameters of the previously trained LLM and further introduce the semantic embedding module.As the pre-trained language model can yield meaningful semantic features through the 1st-phase fine-tuning, we fix its parameter here and focus on optimizing the text projector at this stage.</p>
<p>In the third phase, we freeze all parameters from the preceding stages and concentrate solely on training the parameters of the graph projector.Noted that we also freeze the parameter of the graph encoder.</p>
<p>This progressive training approach ensures a coherent and incremental integration of diverse features.At each stage, as the model parameters of previous stages are already optimized to incorporate existing modality features, we freeze its parameter in the next phase with the aim of integrating the new modality more effectively.Extensive experiments also reveal the superiority of our training recipe over other alternatives.</p>
<p>At the inference stage of GuARD, for each instruction encompassing potential global contextual nodes and multiple target nodes to predict, our framework integrates the outputs of the semantic embedding module and structural embedding module for each node into the LLM input, and utilize the logit of <label_token> after decoding as the final prediction score.</p>
<p>Experiments</p>
<p>In this section, we conduct comprehensive experiments to validate the effectiveness of the design choices in our framework.</p>
<p>Experimental Setup</p>
<p>Datasets.We evaluate GuARD and baselines across four datasets from diverse domains: (1) WhoIsWho [54] , (2) MAG [37], (3) TwiBot-20 [12], and (4) SemEval-23F [35].Both WhoIsWho and MAG originate from the task of incorrect assignment detection in author disambiguation.TwiBot-20 is a bot detection dataset built on the social graph of Twitter.SemEval-23F, on the other hand, focuses on identifying propaganda tactics used in [45].The first three datasets are structured as binary classification tasks aimed at anomaly detection.In contrast, SemEval-23F is a multi-label classification task targeting fine-grained identification of specific propaganda techniques.Detailed statistics for all datasets are provided in Table 1.</p>
<p>Baselines.We conduct a comparative analysis of our model against the popular GNN-based methods and LM-based methods:</p>
<p>• GCN [23]: A two-layer GCN model is used to learn node features, followed by a classifier to categorize the nodes.• SOTA-GNNs [6,19]: We use GCCAD [6] (node-edge contrastive learning for anomaly detection) for WhoIsWho and MAG datasets, and HGT [19] (heterogeneous social network representation learning) for the TwiBot-20 dataset.We further conduct additional experiments to find the best-performing GNNs, with results detailed in the Appendix D. • RoBERTa [29]: We finetune a RoBERTa-base model followed by a trainable head for node classification.• DeBERTa [17]: We further leverage a pretrained DeBERTa-v3large model for sequence classification.Given the challenges of fully fine-tuning the DeBERTa model on long contexts, we apply LoRA [18] fine-tuning for the DeBERTa model.• Llama3-8B [34] and Qwen2.5-7B[49]: We adopt widely used open-sourced LLM models, Llama3-8B and Qwen2.5-7B.These models directly take all textual features as inputs, and use the generated logits of each <label_token> to obtain the final prediction results.</p>
<p>Our model has three variants, corresponding to the three sequential training phases: (1) GuARD-base represents the base version of the model, where only key textual features are used as LLM input, as described in Section 4.1; (2) GuARD+sem indicates the integration of the semantic embedding module on top of the base model, as described in Section 4.2; (3) GuARD+graph represents the addition of the structural embedding module after the semantic embedding module has been incorporated, as described in Section 4.3.</p>
<p>Evaluation Metrics.We adopt AUC and MAP as the evaluation metrics, which are widely used in related anomaly detection tasks [5,6].For the IND task (i.e., WhoIsWho and MAG), we follow the approach in [54] to compute the final results by weighting the outliers across all authors.Specifically, the weight for each author is determined by the proportion of their incorrect instances relative to the total number of incorrect instances.For the multi-label classification task (i.e., SemEval-23F), the overall score is calculated by weighting each category based on the number of anomalies in the specific category.</p>
<p>Implementation Details</p>
<p>As for our framework, we utilize the Llama3-8B [34,44] to train a base model.For the semantic embedding module, we utilize the full information of each sample as raw input text, and feed it into small language models (RoBERTa or DeBERTa) to get the summarized input embeddings.For the structural embedding module, we utilize the SOTA GNNs in each task as graph encoder to obtain the structural embedding.</p>
<p>For the WhoIsWho, MAG, TwiBot, and SemEval-23F datasets, the number of turns is set to 10, 10, 8, and 6, respectively.We select the key attribute based on experimental observations or knowledge derived from existing works.For the WhoIsWho and MAG datasets, we conduct experiments on different features (as shown in Figure 4 and Figure 9), to identify the key features for the corresponding datasets.We use Title and Author as the key attributes for the WhoIsWho dataset.For the TwiBot-20 dataset, inspired by [4], we use metadata as the key feature.For the SemEval-23F dataset, we select the first 512 tokens of the full text as the key attribute.Further implementation details are shown in Appendix A.</p>
<p>Main Results</p>
<p>Table 2 provides a holistic comparison of different anomaly detection methods on four datasets.Generally speaking, LLM-based methods (Llama3-8B, Qwen2.5-7B, and our model GuARD) outperform small language model (SLM)-based methods and GNN-based methods.GNN-based methods are competitive on WhoIsWho and TwiBot-20 datasets due to the importance of structural relationships like coauthor links and social connections, while semantic features play a more crucial role in MAG and SemEval-23F datasets.We observe that SLM-based methods consistently underperform LLM-based methods on all datasets, demonstrating the remarkable fitting and generalization ability of LLMs.</p>
<p>Although fine-tuned LLMs yield satisfactory performance, they face challenges including limited context utilization and high computational costs.GuARD-base achieves similar results to Llama3-8B using only key textual features and multi-turn instruction templates for improved training and inference efficiency.Further integration of the semantic embedding module (GuARD-sem) achieves stateof-the-art performance while being more compute-efficient than traditional LLM fine-tuning approaches.Ultimately, incorporating the structural embedding module further enhances the model's efficacy by addressing LLMs' limitations in capturing graph structural features.The main results validate the effectiveness of our framework, and we conduct extensive ablation studies to verify the rationality of our design choices.</p>
<p>Ablation Studies</p>
<p>Effect of different foundation models.We examine the effect of different backbone LLMs in our framework, including Qwen2.5-7B [48] and Llama3-8B [44].As shown in Table 3, For all backbone models in the WhoIsWho dataset, a consistent stepwise outperformance is observed in each stage, demonstrating the effectiveness of our three-stage training strategy, which robustly integrates multisource features in a progressive manner.In the TwiBot-20 dataset, the integration of graph features yields only minor improvements, possibly because the impact of textual features overshadows the graph features.Effect of different paper attributes.Figure 4 illustrates the impact of paper attributes used in our framework in the WhoIsWho dataset.We first alter the input paper attributes in the first stage of our framework (without semantic embedding and structural embedding module).We observe that "paper title" is the best-performing attribute, followed by paper venues.The reason may lie in that titles and venues encompass rich domain-specific information, which can be well-captured by the LLM.In contrast, organization and author attributes are ad-hoc personal features, often used as effective co-occurred structural features, which are arduous to be utilized by the LLMs.Furthermore, the superiority of the title attribute over the venue is also partly attributed to the finer-grained topical information conveyed in titles.To further investigate the synergistic effects between attributes, we conduct the complete training stages by employing the best single attribute (i.e., title) and another paper attribute."Title+venue" has a small edge over the single usage of the paper title (+0.3% in terms of AUC), possibly due to that titles and venues embody similar domain-specific features.By contrast, both "Title+org" and "Title+author" each deliver significant improvements over the single title attribute, showing +1.6% and +1.4% increase in terms of AUC, respectively.These improvements are likely due to the complementary nature of the title attribute when combined with either "org" or "author".
$8&amp; $ 2 9 7 7 $ E D V H 7 $ V H P 7 $ J U D S K 7 2 E D V H 7 2 V H P 7 2 J U D S K 7 9 E D V H 7 9 V H P 7 9 J U D S K
Figure 4: Ablation studies on different paper attributes as the LLM input for WhoIsWho dataset."A", "O", "V", and "T" denote using the author, organization, venue, or title attribute from a paper as key information input into the LLM, respectively.Similarly, "TA", "TO", and "TV" represent combinations of two of these features as the key input.</p>
<p>We also conducted in-depth experimental analyses of various features on the MAG dataset, as referenced in Appendix B.</p>
<p>Effect of different text projectors.We try several types of text projectors with increased model complexity, including a single linear layer, a two-layer feed-forward network FFN Swish , and Q-Former [25].The Q-Former is frequently used in multi-modal LLMs to align multimodal information (such as text and vision).Here Q-Former is parameterized by a single-layer Transformer decoder with a cross-attention structure.The experimental results on WhoIsWho are presented in Figure 5.Among the three projectors, only FFN Swish exhibits noticeable improvements over GuARD-base.Linear projector impairs performance owing to its lack of expressive power.Unexpectedly, Q-Former is inferior to FFN Swish .The reason might be that the Q-former has an excessive number of parameters as a projector, making it difficult to train.We observe that an increasing number of multi-turns inversely correlates with training and inference time, leading to improved speed as the number of turns grows.This is because the multiturn mechanism enhances the reuse efficiency of global contextual information by sharing it across turns, thereby resulting in speed gains.Additionally, it can be observed that the AUC metric of the model reaches its optimal value when #turn is set to 8 in the WhoIsWho dataset.The accuracy improvement of multi-turns over single-turn validates the effectiveness of the "soft" demonstration mechanism in providing additional semantic demonstrations for decoding subsequent papers.</p>
<p>For the TwiBot-20 dataset, even in the absence of shared global context, notable training and inference speed improvements are still observed.This indicates that the multi-turn strategy remains effective in such scenarios.These speed gains are similar to those achieved by an efficient sequence packing strategy [2,24].As shown in Figure 6, the experimental results indicate that concurrently training the text projector and graph projector yields suboptimal improvement over GuARD-base, but underperforms both progressive and reverse strategies.We speculate that it is difficult to achieve optimal parameters for the two projectors simultaneously in from-scratch training.In addition, reserve of two-modal training yields stable performance improvements over GuARD-base, but it is slightly less effective than first adding the semantic embedding module followed by the structural module.</p>
<p>Model Efficiency</p>
<p>In this subsection, we compare the time efficiency of the GuARD model with LLM-based approaches.All the experiments utilize the Llama3-8B model.To unlock the potential of our framework, we further perform model ensemble by using different paper attributes.As shown in Figure 8, the best two-model ensemble results are obtained by combining the title attribute (T) with the title and organization attributes (T+TO), resulting in a 0.8% AUC improvement compared the single title attribute baseline.The combination of title and author attributes (T+TA) also yields decent results with a 0.7% AUC increase, indicating that incorporating raw organization texts into the LLM inputs exhibits preferable performance compared with injecting these information into the semantic embedding module.Ultimately, by integrating the best three models (T+TO+TA), we achieve the optimal performance.We further compare our method with the top three winning solutions from KDD Cup 2024.Our approach demonstrates advantages in both performance and efficiency compared to LLM-based methods, while the GCN+LGBM solution shows speed advantages due to smaller model scale but requires substantial feature engineering effort.</p>
<p>Conclusion</p>
<p>The proposed text-rich and graph-informed language model GuARD effectively addresses the anomaly detection problem by integrating both structural and semantic features.GuARD is a multi-modallike multi-turn instruction tuning framework, which includes taskguided multi-turn instruction tuning, semantic embedding module with rich attributes, and a structural embedding module.Extensive experiments reveal that our model outperforms previous state-ofthe-art graph-based methods and fine-tuned language methods, and demonstrate significant training efficiency and inference efficiency compared with previous LLM-based methods.Our idea of task-guided instruction tuning on the text-rich and graph-informed language model exhibits the potential to foster future research toward addressing downstream tasks of text-rich graphs.</p>
<p>Figure 9: Ablation studies on different paper attributes as the LLM input for MAG dataset."A", "O", "V", and "T" denote using the author, organization, venue, or title attributes from a paper as key information input into the LLM, respectively.Similarly, "TA", "TO", and "TV" represent combinations of two of these features as the key input.</p>
<p>to convey finer-grained topical information through specialized terminology and precise phrasing.For the combination of different feature, "Title+author" achieves the best base model, this is because both the author and title features demonstrate strong performance on their own, contributing significantly to the model's predictive capabilities.On the other hand, even though the organization (org) and venue features individually do not perform particularly well, incorporating them into the model alongside the title feature still brings marginal improvements.These slight gains indicate that org and venue provide complementary information that helps the model capture additional nuances in the data, leading to an overall enhancement in performance.</p>
<p>C Experiment on Scaling Law</p>
<p>We further explored the scaling law of the Qwen2.5 model on two representative datasets (3B, 7B, 14B).For all three models, we adopted the same LoRA configuration with a rank of 8 and an alpha of 16, and keeping other hyperparameters consistent.The experimental results are shown in the table below.We observed that the 7B model performed the best on both tasks, while the 14B model only slightly outperformed the 3B model.</p>
<p>Figure 1 :
1
Figure 1: Illustration about typical anomaly detection in textrich graph: (a) shows the anomaly detection in authors' multirelation graph (i.e.Incorrect Assignment Detection, IND); (b) showcases the bot detection on social networks; (c) depicts the misinformation detection of news articles on comment networks.</p>
<p>Figure 2 :
2
Figure 2: AUC vs. inference time of different models on the WhoIsWho dataset.GNN: Graph Neural Network, SLM: Small Language Model, LLM: Large Language Model.</p>
<p>Figure 5 :
5
Figure 5: Ablation studies on the different text projectors on the WhoIsWho dataset.The gray dashed line represents the performance of GuARD-base, which serves as the foundation for training the text predictors.</p>
<p>Effect of three-stage training strategy We compare our progressive training strategy with several alternative strategies to inject multi-modal information.(1) Reverse of two-modal training: injecting the structural embedding module first followed by the semantic embedding module; (2) From-scratch training of all projectors: injecting semantic embedding module and structural embedding module simultaneously and training text projector and graph projector jointly.</p>
<p>Figure 6 :
6
Figure 6: The AUC comparison of different training strategies on two datasets: WhoIsWho (left) and TwiBot-20 (right).</p>
<p>Figure 7 :
7
Figure 7: Comparison between individually trained models and joint training models in terms of training loss and AUC.</p>
<p>Figure 8 :
8
Figure 8: Performance comparison of different ensemble models by utilizing various paper attributes.</p>
<p>Table 1 :
1
Dataset statistics.
StatisticsWhoIsWho MAGTwiBot-20SemEval-23F#Graphs1,6642,3161516#AvgNodes1965311,82610%Anomaly11.79%12.43%55.72%28.42%#AvgLen8345631860#MaxLen10,7742762,1907,571#Train148,30984,5108,278361#Valid62,229-2,365103#Test116,26238,0551,18352</p>
<p>Table 2 :
2
Overall results of anomaly detection across four datasets.Statistically significant improvements (p&lt;0.05) over last stage are marked with <em>.
DatasetMetricGCNSOTARoBERTa DeBERTa Llama3-Qwen2.5-GuARDGuARDGuARDGNNs8B7B-base+sem+graphWhoIsWhoAUC MAP0.655 0.5790.741 0.6610.649 0.5500.654 0.5520.741 0.6960.751 0.7040.757 0.6900.771</em> 0.696<em>0.789</em> 0.709<em>MAGAUC MAP0.670 0.5450.839 0.7650.899 0.8310.873 0.7950.958 0.9230.960 0.9240.949 0.9100.961</em> 0.932<em>0.963</em> 0.931TwiBot-20AUC MAP0.847 0.8330.932 0.9280.925 0.9270.907 0.9180.943 0.9420.944 0.9430.916 0.9120.943<em> 0.942</em>0.945<em> 0.945</em>SemEval-23FAUC MAP0.815 0.7480.815 0.7480.805 0.7400.843 0.7840.874 0.8090.875 0.7920.867 0.7960.875<em> 0.811</em>0.875 0.815*</p>
<p>Table 3 :
3
Ablation studies on different foundation models in WhoIsWho and TwiBot-20 datasets.
DatasetWhoIsWhoTwiBot-20ModelModality AUC MAP AUC MAPbase0.724 0.664 0.907 0.903Qwen2.5-7B+sem0.773 0.696 0.947 0.950+graph0.780 0.702 0.946 0.949base0.757 0.690 0.916 0.912Llama3-8B+sem0.771 0.696 0.943 0.942+graph0.789 0.709 0.945 0.945</p>
<p>Table 4 :
4
Influence of the number of turns in the multi-turn instruction template on two datasets.The best values for training and inference time (min), and AUC are highlighted in bold.Effect of # in each instruction.We further study how many target nodes to predict in each multi-turn instruction (#: i.e., the number of turns) is the best in terms of model accuracy and efficiency.In this part, we take the WhoIsWho and TwiBot-20 datasets as examples to analyze the scenarios with and without the global context, respectively.Table4shows the accuracy (i.e., AUC) and efficiency performance with # in the range of {1, 2, 4, 8, 16}.</p>
<h1>𝑡𝑢𝑟𝑛𝑠WhoIsWhoTwiBot-20Train Inf AUC Train Inf AUC1315.0 56.4 0.7443.320.21 0.9112169.8 28.8 0.7441.760.11 0.916491.815.0 0.7511.130.08 0.912849.87.8 0.7630.970.07 0.9131625.24.2 0.7370.93 0.07 0.915</h1>
<p>Table 5 :
5
The efficiency performance of our model variants and the full-text fine-tuned counterparts (in minutes).
WhoIsWhoTwiBot-20Time CostTrain Inference Train InferenceGuARD-base29.406.000.900.07+sem (stage 2)37.2010.800.900.07+graph (stage 3) 39.0012.000.910.07Llama3-8B592.80130.203.110.21steps. However, from-scratch training, in terms of both AUC andtraining loss, appears to have learned predominantly from a singlesource of graph features.</p>
<p>Table 5 presents the detailed time costs for training and inference.The training and inference time are defined as the time required to perform a single full pass of training (or inference) over the training and validation datasets, respectively.Compared to vanilla Llama, our base model leverages a shorter input length as well as multi-turn instructions, achieving both fast training and inference speed on both the WhoIsWho and TwiBot-20 datasets.Notably, on the WhoIsWho dataset, our model achieves over a 10× speedup in inference and a 5× speedup in training.
Even without shared global context, our method still achieves a 3×speedup in inference on the TwiBot-20 dataset.5.6 Model Ensemble$8&amp;7 72 7$ 797 7 2 7 7 $7 7 97 7 2 7 $</p>
<p>Table 6 :
6
Performance comparison of models using different categories of features: Top-3 on the Whoiswho-IND test leaderboard in KDD Cup 2024.
Man-Text-Struc-AUCTestRankModelualualtural(%)Time (h)1 [55] GLM3 [14, 51]-✓-83.45&gt;102 [40]GCN [23]✓✓✓LGBM [22]✓✓-82.49&lt;0.1GLM3 [14, 51]-✓-3 [47]GLM4 [14, 51]-✓-81.35&gt;10Mistral [20]-✓-LGBM [22]✓✓--GuARD-✓✓83.511.3</p>
<p>Table 7 :
7
The efficiency performance of our model variants and the best baseline (in hours).
TrainingConvergenceInferenceMethodtime/epochtimetimeGuARD-base0.490.810.10+sem (stage 2)0.621.820.18+graph (stage 3)0.650.630.20Total0.653.250.20ChatGLM-IND17.768.881.95
AcknowledgmentsThis work has been supported by the NSFC for Distinguished Young Scholar (62425601) and New Cornerstone Science Foundation through the XPLORER PRIZE.Yanghui Rao was supported by the National Natural Science Foundation of China (62372483).This work is also supported by the Natural Science Foundation of China (NSFC) 62406164, the Postdoctoral Fellowship Program of CPSF under Grant Number GZB20240358 and 2024M761680.Authors named as "Li Chen"Eye-Tracking study of ...A Implementation DetailsDuring the training of the LLaMA3-8B and Qwen 2.5-7B models, we set the maximum input length to 8K, and use FlashAttention[8,9]to reduce the memory consumption during training and inference.We consistently adopted LoRA[18]with a rank of 8, LoRA alpha value of 16, and a dropout rate of 0.05.On the WhoIsWho dataset, the per-device batch size was set to 1, with a gradient accumulation step of 16, resulting in a global batch size of 128 for 8-card training.All experiments were conducted using Nvidia A100 GPUs, each with 80GB of memory.Except for the SemEval-23F dataset, which, due to its relatively small size, was trained using 2 GPUs, all other experiments utilized the full set of GPUs available.We used AdamW[30]as the optimizer with a weight decay of 1e-3.A cosine learning rate scheduler with a linear warm-up was employed for the GuARD-base model, with a warm-up ratio of 0.1 and a peak learning rate of 1e-4.In contrast, a constant learning rate of 5e-5 was applied for the "+sem" and "+graph" models.The "base", "+sem", and "+graph" models were trained for 6, 10, and 4 epochs, respectively, with evaluations conducted every 25 global steps throughout the training process.Each phase of the training procedure leveraged the best-performing parameters from the evaluation of the prior phase.For the FFN layer in the semantic/structural embedding module, the intermediate hidden size was set to twice the hidden size of the following LLM.B Effect of different feature on MAG datasetIn contrast, the MAG dataset exhibits a distinct pattern where author information performs best, followed by titles, while organizational affiliations show the weakest results.This discrepancy may arise from two factors: the MAG dataset's partial absence of certain metadata features, and the inherent challenges for LLMs to effectively utilize structural features like author co-occurrence patterns and organizational relationships.Across both datasets, titles consistently outperform venues, likely due to their abilityD Selection of SOTA-GNN ModelsWe further compared various GNN baselines[21,57]and language model[27,29]as node feature encoder on each dataset and adopted the best-performing model as the SOTA-GNNs for each section.We present the models we compared in Table8, and evaluated the embeddings from both pre-trained models and large language models.Among them, the GCCAD and HGT models were meticulously fine-tuned on each dataset, thus yielding robust results.
Learning textual features for Twitter spam detection: A systematic literature review. Sepideh Bazzaz Abkenar, Mostafa Haghi Kashani, Mohammad Akbari, Ebrahim Mahdipour, Expert Systems with Applications. 2282023. 2023</p>
<p>LongAlign: A recipe for long context alignment of large language models. Yushi Bai, Xin Lv, Jiajie Zhang, Yuze He, Ji Qi, Lei Hou, Jie Tang, Yuxiao Dong, Juanzi Li, Findings of the 2024 Conference on Empirical Methods in Natural Language Processing. 2024</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in Neural Information Processing Systems. 332020. 2020</p>
<p>LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. Zijian Cai, Zhaoxuan Tan, Zhenyu Lei, Zifeng Zhu, Hongrui Wang, Qinghua Zheng, Minnan Luo, Proceedings of the 17th ACM International Conference on Web Search and Data Mining. the 17th ACM International Conference on Web Search and Data Mining2024</p>
<p>Web-scale academic name disambiguation: the WhoIsWho benchmark, leaderboard, and toolkit. Bo Chen, Jing Zhang, Fanjin Zhang, Tianyi Han, Yuqing Cheng, Xiaoyan Li, Yuxiao Dong, Jie Tang, Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2023</p>
<p>GCCAD: Graph contrastive coding for anomaly detection. Bo Chen, Jing Zhang, Xiaokang Zhang, Yuxiao Dong, Jian Song, Peng Zhang, Kaibo Xu, Evgeny Kharlamov, Jie Tang, IEEE Transactions on Knowledge and Data Engineering. 352022. 2022</p>
<p>Can LLM-Generated misinformation be detected. Canyu Chen, Kai Shu, Proceeding of the 12th International Conference on Learning Representations. eeding of the 12th International Conference on Learning Representations2024</p>
<p>Flashattention-2: Faster attention with better parallelism and work partitioning. Tri Dao, arXiv:2307.086912023. 2023arXiv preprint</p>
<p>Flashattention: Fast and memory-efficient exact attention with io-awareness. Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, Christopher Ré, Advances in Neural Information Processing Systems. 352022. 2022</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018. 2018arXiv preprint</p>
<p>Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters. Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, Philip S Yu, Proceeding of the 29th ACM International Conference on Information and Knowledge Management. eeding of the 29th ACM International Conference on Information and Knowledge Management2020</p>
<p>Twibot-20: A comprehensive twitter bot detection benchmark. Shangbin Feng, Herun Wan, Ningnan Wang, Jundong Li, Minnan Luo, Proceedings of the 30th ACM international conference on information and knowledge management. the 30th ACM international conference on information and knowledge management2021</p>
<p>What does the bot say? Opportunities and risks of large language models in social media bot detection. Shangbin Feng, Herun Wan, Ningnan Wang, Zhaoxuan Tan, Minnan Luo, Yulia Tsvetkov, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. the 62nd Annual Meeting of the Association for Computational Linguistics2024</p>
<p>Glm Team, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, arXiv:2406.12793ChatGLM: A family of large language models from GLM-130B to GLM-4 all tools. 2024. 2024arXiv preprint</p>
<p>LogLLM: Log-based anomaly detection using large language models. Wei Guan, Jian Cao, Shiyou Qian, Jianqi Gao, arXiv:2411.085612024. 2024arXiv preprint</p>
<p>Zeyu Han, Chao Gao, Jinyang Liu, Qian Sai, Zhang, arXiv:2403.14608Parameterefficient fine-tuning for large models: A comprehensive survey. 2024. 2024arXiv preprint</p>
<p>Deberta: decoding-Enhanced Bert with Disentangled Attention. Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, Proceeding of the 9th International Conference on Learning Representations. eeding of the 9th International Conference on Learning Representations2021</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685LoRA: Low-rank adaptation of large language models. 2021. 2021arXiv preprint</p>
<p>Heterogeneous Graph Transformer. Ziniu Hu, Yuxiao Dong, Kuansan Wang, Yizhou Sun, Proceedings of the Web Conference. the Web Conference2020. 2020</p>
<p>. Alexandre Albert Q Jiang, Arthur Sablayrolles, Chris Mensch, Devendra Bamford, Diego Singh Chaplot, Florian De Las Casas, Gianna Bressand, Guillaume Lengyel, Lucile Lample, Saulnier, arXiv:2310.068252023. 2023Mistral 7B. arXiv preprint</p>
<p>Hypergraph-enhanced Dual Semisupervised Graph Classification. Wei Ju, Zhengyang Mao, Siyu Yi, Yifang Qin, Yiyang Gu, Zhiping Xiao, Yifan Wang, Xiao Luo, Ming Zhang, Proceeding of the 41st International Conference on Machine Learning. eeding of the 41st International Conference on Machine Learning2024</p>
<p>Lightgbm: A highly efficient gradient boosting decision tree. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu, Advances in Neural Information Processing Systems. 302017. 2017</p>
<p>Semi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, 2017. 2017</p>
<p>Efficient sequence packing without cross-contamination: Accelerating large language models without impacting performance. Mario Michael Krell, Matej Kosec, Sergio P Perez, Andrew Fitzgibbon, arXiv:2107.020272021. 2021arXiv preprint</p>
<p>Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi, Proceedings of the 40th International Conference on Machine Learning. the 40th International Conference on Machine Learning2023. 19730-19742</p>
<p>Prefix-tuning: optimizing continuous prompts for generation. Lisa Xiang, Percy Li, Liang, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing2021</p>
<p>Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, arXiv:2308.03281Towards general text embeddings with multi-stage contrastive learning. 2023. 2023arXiv preprint</p>
<p>Lost in the middle: How language models use long contexts. Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang, Transactions of the Association for Computational Linguistics. 122024. 2024</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019. 2019arXiv preprint</p>
<p>Fixing weight decay regularization in adam. Ilya Loshchilov, Frank Hutter, CoRR abs/1711.051012017. 2017</p>
<p>Shaurya Rohatgi, and Dongwon Lee. 2023. Fighting fire with fire: The dual role of LLMs in crafting and detecting elusive disinformation. Jason Samuel, Lucas , Adaku Uchendu, Michiharu Yamashita, Jooyoung Lee, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing</p>
<p>Are we really making much progress?: Revisiting, benchmarking and refining heterogeneous graph neural networks. Qingsong Lv, Ming Ding, Qiang Liu, Yuxiang Chen, Wenzheng Feng, Siming He, Chang Zhou, Jianguo Jiang, Yuxiao Dong, Jie Tang, Proceeding of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. eeding of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2021</p>
<p>A Comprehensive Survey on Graph Anomaly Detection With Deep Learning. Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Z Quan, Hui Sheng, Leman Xiong, Akoglu, IEEE Transactions on Knowledge and Data Engineering. 352023. 2023</p>
<p>Introducing meta llama 3: The most capable openly available llm to date. Ai Meta, Meta AI. 2024. 2024</p>
<p>Semeval-2023 task 3: Detecting the category, the framing, and the persuasion techniques in online news in a multi-lingual setup. Jakub Piskorski, Nicolas Stefanovitch, Giovanni Da San, Preslav Martino, Nakov, Proceedings of the 17th International Workshop on Semantic Evaluation. the 17th International Workshop on Semantic Evaluation2023</p>
<p>Prajit Ramachandran, Barret Zoph, Quoc V Le, arXiv:1710.05941Searching for activation functions. 2017. 2017arXiv preprint</p>
<p>The microsoft academic search dataset and kdd cup. Senjuti Basu, Roy , Martine De Cock, Vani Mandava, Swapna Savanna, Brian Dalessandro, Claudia Perlich, William Cukierski, Ben Hamner, Proceedings of the 2013 KDD cup 2013 workshop. the 2013 KDD cup 2013 workshop2013. 2013</p>
<p>Modeling Relational Data with Graph Convolutional Networks. Sejr Michael, Thomas N Schlichtkrull, Peter Kipf, Rianne Bloem, Van Den, Ivan Berg, Max Titov, Welling, The semantic web: 15th international conference. 201810843</p>
<p>Noam Shazeer, arXiv:2002.05202Glu variants improve transformer. 2020. 2020arXiv preprint</p>
<p>An ensemble model with multi-scale features for incorrect assignment detection. Ming Shen, KDD 2024 OAG-Challenge Cup. 2024</p>
<p>GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection. Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li, Advances in Neural Information Processing Systems. 202336</p>
<p>Rethinking Graph Neural Networks for Anomaly Detection. Jianheng Tang, Jiajin Li, Ziqi Gao, Jia Li, Proceeding of the 39th International Conference on Machine Learning. eeding of the 39th International Conference on Machine Learning2022162</p>
<p>Arnetminer: extraction and mining of academic social networks. Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, Zhong Su, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. the 14th ACM SIGKDD international conference on Knowledge discovery and data mining2008</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023. 2023arXiv preprint</p>
<p>DELL: Generating Reactions and Explanations for LLM-Based Misinformation Detection. Herun Wan, Shangbin Feng, Zhaoxuan Tan, Heng Wang, Yulia Tsvetkov, Minnan Luo, Findings of the. Association for Computational Linguistics2024</p>
<p>Twitter spam detection: Survey of new approaches and comparative study. Tingmin Wu, Sheng Wen, Yang Xiang, Wanlei Zhou, Computers and Security. 762018. 2018</p>
<p>Synergizing large language models and tree-based algorithms for author name disambiguation. Qiang Yan, Asirasir , KDD 2024 OAG-Challenge Cup. 2024</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, arXiv:2407.10671Qwen2 technical report. 2024. 2024arXiv preprint</p>
<p>. An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, abs/2412.151152024. 2024Technical Report. CoRR</p>
<p>AD-LLM: Benchmarking Large Language Models for Anomaly Detection. Tiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang Li, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan A Rossi, Kaize Ding, Xiaohu You, Yue Zhao, CoRR abs/2412.111422024. 2024</p>
<p>Glm-130b: An open bilingual pre-trained model. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Proceedings of the 5th International Conference on Learning Representations. the 5th International Conference on Learning Representations2022. 2022</p>
<p>OAG: Linking Entities across Large-scale Heterogeneous Knowledge Graphs. Fanjin Zhang, Xiao Liu, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, Xiaotao Gu, Yan Wang, Evgeny Kharlamov, Bin Shao, IEEE Transactions on Knowledge and Data Engineering. 352023. 2023</p>
<p>OAG: Toward linking large-scale heterogeneous entity graphs. Fanjin Zhang, Xiao Liu, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, Xiaotao Gu, Yan Wang, Bin Shao, Rui Li, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining2019</p>
<p>OAG-Bench: A humancurated benchmark for academic graph mining. Fanjin Zhang, Shijie Shi, Yifan Zhu, Bo Chen, Yukuo Cen, Jifan Yu, Yelin Chen, Lulu Wang, Qingfei Zhao, Yuqing Cheng, Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2024</p>
<p>Enhanced name disambiguation via iterative self-refining with LLMs. Xiaocheng Zhang, Yang Zhou, Haoru Chen, Mengjiao Bao, Peng Yan, KDD 2024 OAG-Challenge Cup. 2024</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023. 2023arXiv preprint</p>
<p>Partitioning Message Passing for Graph Fraud Detection. Wei Zhuo, Zemin Liu, Bryan Hooi, Bingsheng He, Guang Tan, Rizal Fathony, Jia Chen, Proceeding of the 12th International Conference on Learning Representations. eeding of the 12th International Conference on Learning Representations2024</p>            </div>
        </div>

    </div>
</body>
</html>