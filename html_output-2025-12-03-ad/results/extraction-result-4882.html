<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4882 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4882</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4882</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-104.html">extraction-schema-104</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <p><strong>Paper ID:</strong> paper-eaa7853facb9b49444b48a96192cb4be66b62671</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/eaa7853facb9b49444b48a96192cb4be66b62671" target="_blank">Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> Synapse, a computer agent featuring three key components: state abstraction, which filters out task-irrelevant information from raw states, allowing more exemplars within the limited context, and trajectory-as-exemplar prompting, which prompts the LLM with complete trajectories of the abstracted states and actions to improve multi-step decision-making.</p>
                <p><strong>Paper Abstract:</strong> Building agents with large language models (LLMs) for computer control is a burgeoning research area, where the agent receives computer states and performs actions to complete complex tasks. Previous computer agents have demonstrated the benefits of in-context learning (ICL); however, their performance is hindered by several issues. First, the limited context length of LLMs and complex computer states restrict the number of exemplars, as a single webpage can consume the entire context. Second, the exemplars in current methods, such as high-level plans and multi-choice questions, cannot represent complete trajectories, leading to suboptimal performance in long-horizon tasks. Third, existing computer agents rely on task-specific exemplars and overlook the similarity among tasks, resulting in poor generalization to novel tasks. To address these challenges, we introduce Synapse, a computer agent featuring three key components: i) state abstraction, which filters out task-irrelevant information from raw states, allowing more exemplars within the limited context, ii) trajectory-as-exemplar prompting, which prompts the LLM with complete trajectories of the abstracted states and actions to improve multi-step decision-making, and iii) exemplar memory, which stores the embeddings of exemplars and retrieves them via similarity search for generalization to novel tasks. We evaluate Synapse on MiniWoB++, a standard task suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, Synapse achieves a 99.2% average success rate (a 10% relative improvement) across 64 tasks using demonstrations from only 48 tasks. Notably, Synapse is the first ICL method to solve the book-flight task in MiniWoB++. Synapse also exhibits a 56% relative improvement in average step success rate over the previous state-of-the-art prompting scheme in Mind2Web.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4882.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4882.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SynAPSE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SynAPSE (Trajectory-as-Exemplar Prompting with Memory for Computer Control)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-powered computer-control agent combining (i) few-shot state abstraction to compress raw HTML/screenshots into task-relevant observations, (ii) trajectory-as-exemplar (TaE) prompting that uses full successful trajectories as few-shot exemplars, and (iii) an exemplar memory (embedding-based key-value store) to retrieve relevant exemplars for new tasks via similarity search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SynAPSE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Three-component agent that prompts an LLM to (1) abstract raw states into concise observations, (2) generate actions using trajectory-level exemplars (interleaved observation-action sequences) as few-shot prompts, and (3) select which exemplars to prompt from an external exemplar memory. The LLM is used both for state-abstraction (few-shot or code-generation) and for action generation (direct code/natural-language action outputs).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo variants) and CodeLlama-7B used in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>MiniWoB++ (64 tasks) and Mind2Web (real-world web navigation benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Interactive computer-control / web navigation tasks: MiniWoB++ tasks such as terminal/file operations, form filling, UI interactions (64 tasks tested); Mind2Web open-domain website tasks (element selection, typing, selecting across cross-task, cross-website, cross-domain test splits).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Retrieval-augmented exemplar memory implemented as a fixed-size key-value store (embedding-based retrieval); effectively an episodic/exemplar memory keyed by embeddings of task metadata.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Keys: dense embeddings of task metadata (e.g., task descriptions concatenated with initial states, website name/domain); Values: corresponding state-abstraction prompts and full successful trajectories (observation-action sequences). Embedding model used: text-embedding-ada-002.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>Memory is constructed offline from the training set (encode metadata and store exemplars). During evaluation it is treated as static (no online updates during an episode are reported).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td>Similarity search (top-n) over embedding vectors using Faiss; Euclidean distance used as similarity metric; retrieved top-3 exemplars, then a majority-rule over retrieved metadata to pick exemplar group and then fetch all exemplars for that metadata for prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>MiniWoB++: SynAPSE achieves 99.2% average success rate across 64 tasks using demonstrations from only 48 tasks; exemplar memory enables generalization so that 16 unseen tasks are solved (average ~100% success on unseen tasks). Mind2Web (CodeLlama-7B section): adding memory to state-abstraction+TaE increases Cross-Task Ele. Acc to 29.4, Step SR to 26.4, SR to 3.2 (vs without memory Ele. Acc 27.0, Step SR 24.5, SR 1.2). Mind2Web (GPT-3.5 section): with memory Cross-Task Ele. Acc 34.0, Step SR 30.6, SR 2.4 versus without-memory (state abstraction + TaE) Ele. Acc 32.8, Step SR 29.2, SR 2.0. Overall, memory yields measurable improvements in step success rate and task generalization (e.g., cited relative improvements up to +56% Step SR over MindAct when all components are added).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>When SynAPSE uses only state abstraction + TaE (static exemplars but no exemplar memory) performance is lower: e.g., Mind2Web (CodeLlama) state abstraction + TaE: Cross-Task Ele. Acc 27.0, Step SR 24.5, SR 1.2; with memory Ele. Acc 29.4, Step SR 26.4, SR 3.2. In MiniWoB++ SynAPSE without exemplar memory (i.e., using only task-specific exemplars) would require more task-specific exemplars and fails to generalize as efficiently; prior ICL baselines (RCI) solved 54 tasks (90.6% average) while SynAPSE with memory solved 64 tasks (99.2%).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Comprehensive ablations: (1) State abstraction: reduces token length per state and consistently improves performance (e.g., enables solving book-flight). (2) Trajectory-as-exemplar (TaE): large gains in long-horizon / repeated-action tasks (examples: guess-number, use-spinner, use-autocomplete: SynAPSE ≈ 98–100% vs RCI much lower). (3) Exemplar memory: improves generalization across similar tasks and layouts; in Mind2Web memory yields additional Step SR gains (example: ~6% improvement in Step SR for cross-task and cross-website when adding memory to state-abstraction+TaE). The paper quantifies incremental improvements (state abstraction +32% Step SR over baseline, +TaE +50%, +memory +56% relative to MindAct in aggregate) and reports numeric pre/post-memory entries in Table 1 for each generalization split.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Reported issues: (i) Memory can be less helpful or even harmful for cross-domain generalization because retrieved exemplars may come from unrelated domains and bias the LLM; paper notes marginal or no improvement in cross-domain tests and attributes this to larger embedding distances between retrieved exemplars and target tasks. (ii) Exemplar mismatches: rare but present (e.g., ~2% failure in click-tab-2-hard due to exemplar mismatch). (iii) Dependence on exemplar quality and coverage; (iv) high inference latency due to repeated LLM calls; (v) retrieval strategy and memory structure require further study for improved generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Authors recommend combining three components: (1) state abstraction to compress states (few-shot LLM abstraction or element-ranking pretrained models) so more exemplars fit in context, (2) trajectory-as-exemplar prompting (use full observation-action trajectories) to reduce error accumulation and enable temporal abstraction, and (3) embedding-based exemplar memory with similarity search (encode metadata including task description and initial states; use text-embedding-ada-002 and Faiss) to automatically select exemplars and exploit task similarity. Practical heuristics used: retrieve top-3 exemplars then use majority metadata to fetch full exemplar set; reduce element-ranking k (e.g., to 3/5 instead of 50) to lower token usage even at some recall loss because it improved step SR; combine memory with human intervention for customization; consider distillation to a smaller agent to reduce latency.</td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Memory is implemented as an explicit external component (D = (K,V)) and is central to the paper's claims about generalization. The memory is offline-constructed from training exemplars and retrieved via embedding similarity; no online incremental updates during episodes are described.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4882.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4882.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MindAct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MindAct (baseline agent from Mind2Web)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ICL computer agent for web navigation that uses an element-ranking model to propose candidates and prompts an LLM with MCQ-formatted exemplars to select the next action, querying the LLM recursively until one action is chosen.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mind2Web: Towards a generalist agent for the web</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MindAct</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Baseline ICL agent that filters page elements using an element-ranking model (top-K elements), then generates a fixed set of candidate actions and uses the LLM in a multi-choice question (MCQ) prompting format to pick an action; recursive querying is used to handle ambiguity.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Evaluated in paper with CodeLlama-7B and GPT-3.5 (as baselines in comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>Mind2Web (real-world web navigation benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Pick the correct element and action (click/type/select) to accomplish high-level website tasks across cross-task, cross-website, and cross-domain splits.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Reported baseline numbers in the paper: e.g., MindAct (CodeLlama-7B) Cross-Task Ele. Acc 11.2, Step SR 7.7, SR 0.4; MindAct (GPT-3.5) Cross-Task Ele. Acc 20.3, Step SR 17.4, SR 0.8 (see paper Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Paper compares MindAct to SynAPSE variants; finds MindAct's MCQ recursive selection performs worse than SynAPSE's direct generation combined with state abstraction and TaE prompting. MindAct uses top-50 elements as observation whereas SynAPSE reduced top-K (3/5) to reduce tokens and found better step SR despite lower recall.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Authors note MindAct struggles to choose the correct element and that its MCQ approach and large top-K observations are expensive in context tokens; recursive MCQ queries lead to lower step success rates in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>By comparison the paper recommends direct generation with state abstraction and using trajectories as exemplars rather than MCQ-style recursive selection; also recommends reducing top-K element lists and using embedding-based exemplar retrieval to leverage cross-task similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4882.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4882.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games, with a focus on how memory is used, the type of memory mechanisms, comparative performance with and without memory, and any recommendations or challenges regarding memory usage.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RCI (Recursive self-correction ICL agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ICL computer-control agent that prompts LLMs to generate high-level plans and uses recursive self-correction and task-specific exemplars to ground actions at each step.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models can solve computer tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>RCI</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An ICL method that prompts LLMs to produce a high-level plan and grounds each action step-by-step; uses task-specific exemplars and recursive self-correction to mitigate errors that accumulate across steps.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-family models used in original RCI work (as cited); treated as baseline here</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>MiniWoB++ (standard computer-control benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Various MiniWoB++ UI tasks (terminal, form-filling, clicking, etc.), where RCI generates stepwise plans and uses self-correction to handle errors.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>RCI reported in paper: solved 54 MiniWoB++ tasks with average success rate ≈ 90.6% (as a SOTA ICL baseline prior to SynAPSE).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_analysis</strong></td>
                            <td>Paper contrasts RCI's high-level-plan exemplars with SynAPSE's trajectory-as-exemplar prompting; finds RCI suffers from error accumulation when querying LLM at each step and relies heavily on self-correction; SynAPSE's TaE reduces such accumulation.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>RCI needs task-specific exemplars (hard-coded mapping from tasks to exemplars), limited context prevents many exemplars, high multi-step error accumulation compensated by self-correction; RCI performance drops substantially if components of its self-correction pipeline are removed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mind2Web: Towards a generalist agent for the web <em>(Rating: 2)</em></li>
                <li>Language models can solve computer tasks <em>(Rating: 2)</em></li>
                <li>A data-driven approach for learning to control computers <em>(Rating: 1)</em></li>
                <li>Lost in the middle: How language models use long contexts <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4882",
    "paper_id": "paper-eaa7853facb9b49444b48a96192cb4be66b62671",
    "extraction_schema_id": "extraction-schema-104",
    "extracted_data": [
        {
            "name_short": "SynAPSE",
            "name_full": "SynAPSE (Trajectory-as-Exemplar Prompting with Memory for Computer Control)",
            "brief_description": "An LLM-powered computer-control agent combining (i) few-shot state abstraction to compress raw HTML/screenshots into task-relevant observations, (ii) trajectory-as-exemplar (TaE) prompting that uses full successful trajectories as few-shot exemplars, and (iii) an exemplar memory (embedding-based key-value store) to retrieve relevant exemplars for new tasks via similarity search.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "SynAPSE",
            "agent_description": "Three-component agent that prompts an LLM to (1) abstract raw states into concise observations, (2) generate actions using trajectory-level exemplars (interleaved observation-action sequences) as few-shot prompts, and (3) select which exemplars to prompt from an external exemplar memory. The LLM is used both for state-abstraction (few-shot or code-generation) and for action generation (direct code/natural-language action outputs).",
            "llm_model_name": "GPT-3.5 (gpt-3.5-turbo variants) and CodeLlama-7B used in experiments",
            "game_or_benchmark_name": "MiniWoB++ (64 tasks) and Mind2Web (real-world web navigation benchmark)",
            "task_description": "Interactive computer-control / web navigation tasks: MiniWoB++ tasks such as terminal/file operations, form filling, UI interactions (64 tasks tested); Mind2Web open-domain website tasks (element selection, typing, selecting across cross-task, cross-website, cross-domain test splits).",
            "memory_used": true,
            "memory_type": "Retrieval-augmented exemplar memory implemented as a fixed-size key-value store (embedding-based retrieval); effectively an episodic/exemplar memory keyed by embeddings of task metadata.",
            "memory_representation": "Keys: dense embeddings of task metadata (e.g., task descriptions concatenated with initial states, website name/domain); Values: corresponding state-abstraction prompts and full successful trajectories (observation-action sequences). Embedding model used: text-embedding-ada-002.",
            "memory_update_mechanism": "Memory is constructed offline from the training set (encode metadata and store exemplars). During evaluation it is treated as static (no online updates during an episode are reported).",
            "memory_retrieval_mechanism": "Similarity search (top-n) over embedding vectors using Faiss; Euclidean distance used as similarity metric; retrieved top-3 exemplars, then a majority-rule over retrieved metadata to pick exemplar group and then fetch all exemplars for that metadata for prompting.",
            "performance_with_memory": "MiniWoB++: SynAPSE achieves 99.2% average success rate across 64 tasks using demonstrations from only 48 tasks; exemplar memory enables generalization so that 16 unseen tasks are solved (average ~100% success on unseen tasks). Mind2Web (CodeLlama-7B section): adding memory to state-abstraction+TaE increases Cross-Task Ele. Acc to 29.4, Step SR to 26.4, SR to 3.2 (vs without memory Ele. Acc 27.0, Step SR 24.5, SR 1.2). Mind2Web (GPT-3.5 section): with memory Cross-Task Ele. Acc 34.0, Step SR 30.6, SR 2.4 versus without-memory (state abstraction + TaE) Ele. Acc 32.8, Step SR 29.2, SR 2.0. Overall, memory yields measurable improvements in step success rate and task generalization (e.g., cited relative improvements up to +56% Step SR over MindAct when all components are added).",
            "performance_without_memory": "When SynAPSE uses only state abstraction + TaE (static exemplars but no exemplar memory) performance is lower: e.g., Mind2Web (CodeLlama) state abstraction + TaE: Cross-Task Ele. Acc 27.0, Step SR 24.5, SR 1.2; with memory Ele. Acc 29.4, Step SR 26.4, SR 3.2. In MiniWoB++ SynAPSE without exemplar memory (i.e., using only task-specific exemplars) would require more task-specific exemplars and fails to generalize as efficiently; prior ICL baselines (RCI) solved 54 tasks (90.6% average) while SynAPSE with memory solved 64 tasks (99.2%).",
            "has_performance_comparison": true,
            "ablation_or_analysis": "Comprehensive ablations: (1) State abstraction: reduces token length per state and consistently improves performance (e.g., enables solving book-flight). (2) Trajectory-as-exemplar (TaE): large gains in long-horizon / repeated-action tasks (examples: guess-number, use-spinner, use-autocomplete: SynAPSE ≈ 98–100% vs RCI much lower). (3) Exemplar memory: improves generalization across similar tasks and layouts; in Mind2Web memory yields additional Step SR gains (example: ~6% improvement in Step SR for cross-task and cross-website when adding memory to state-abstraction+TaE). The paper quantifies incremental improvements (state abstraction +32% Step SR over baseline, +TaE +50%, +memory +56% relative to MindAct in aggregate) and reports numeric pre/post-memory entries in Table 1 for each generalization split.",
            "challenges_or_limitations": "Reported issues: (i) Memory can be less helpful or even harmful for cross-domain generalization because retrieved exemplars may come from unrelated domains and bias the LLM; paper notes marginal or no improvement in cross-domain tests and attributes this to larger embedding distances between retrieved exemplars and target tasks. (ii) Exemplar mismatches: rare but present (e.g., ~2% failure in click-tab-2-hard due to exemplar mismatch). (iii) Dependence on exemplar quality and coverage; (iv) high inference latency due to repeated LLM calls; (v) retrieval strategy and memory structure require further study for improved generalization.",
            "best_practices_or_recommendations": "Authors recommend combining three components: (1) state abstraction to compress states (few-shot LLM abstraction or element-ranking pretrained models) so more exemplars fit in context, (2) trajectory-as-exemplar prompting (use full observation-action trajectories) to reduce error accumulation and enable temporal abstraction, and (3) embedding-based exemplar memory with similarity search (encode metadata including task description and initial states; use text-embedding-ada-002 and Faiss) to automatically select exemplars and exploit task similarity. Practical heuristics used: retrieve top-3 exemplars then use majority metadata to fetch full exemplar set; reduce element-ranking k (e.g., to 3/5 instead of 50) to lower token usage even at some recall loss because it improved step SR; combine memory with human intervention for customization; consider distillation to a smaller agent to reduce latency.",
            "notes": "Memory is implemented as an explicit external component (D = (K,V)) and is central to the paper's claims about generalization. The memory is offline-constructed from training exemplars and retrieved via embedding similarity; no online incremental updates during episodes are described.",
            "uuid": "e4882.0",
            "source_info": {
                "paper_title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "MindAct",
            "name_full": "MindAct (baseline agent from Mind2Web)",
            "brief_description": "An ICL computer agent for web navigation that uses an element-ranking model to propose candidates and prompts an LLM with MCQ-formatted exemplars to select the next action, querying the LLM recursively until one action is chosen.",
            "citation_title": "Mind2Web: Towards a generalist agent for the web",
            "mention_or_use": "use",
            "agent_name": "MindAct",
            "agent_description": "Baseline ICL agent that filters page elements using an element-ranking model (top-K elements), then generates a fixed set of candidate actions and uses the LLM in a multi-choice question (MCQ) prompting format to pick an action; recursive querying is used to handle ambiguity.",
            "llm_model_name": "Evaluated in paper with CodeLlama-7B and GPT-3.5 (as baselines in comparisons)",
            "game_or_benchmark_name": "Mind2Web (real-world web navigation benchmark)",
            "task_description": "Pick the correct element and action (click/type/select) to accomplish high-level website tasks across cross-task, cross-website, and cross-domain splits.",
            "memory_used": false,
            "memory_type": null,
            "memory_representation": null,
            "memory_update_mechanism": null,
            "memory_retrieval_mechanism": null,
            "performance_with_memory": null,
            "performance_without_memory": "Reported baseline numbers in the paper: e.g., MindAct (CodeLlama-7B) Cross-Task Ele. Acc 11.2, Step SR 7.7, SR 0.4; MindAct (GPT-3.5) Cross-Task Ele. Acc 20.3, Step SR 17.4, SR 0.8 (see paper Table 1).",
            "has_performance_comparison": true,
            "ablation_or_analysis": "Paper compares MindAct to SynAPSE variants; finds MindAct's MCQ recursive selection performs worse than SynAPSE's direct generation combined with state abstraction and TaE prompting. MindAct uses top-50 elements as observation whereas SynAPSE reduced top-K (3/5) to reduce tokens and found better step SR despite lower recall.",
            "challenges_or_limitations": "Authors note MindAct struggles to choose the correct element and that its MCQ approach and large top-K observations are expensive in context tokens; recursive MCQ queries lead to lower step success rates in practice.",
            "best_practices_or_recommendations": "By comparison the paper recommends direct generation with state abstraction and using trajectories as exemplars rather than MCQ-style recursive selection; also recommends reducing top-K element lists and using embedding-based exemplar retrieval to leverage cross-task similarity.",
            "uuid": "e4882.1",
            "source_info": {
                "paper_title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "RCI",
            "name_full": "RCI (Recursive self-correction ICL agent)",
            "brief_description": "An ICL computer-control agent that prompts LLMs to generate high-level plans and uses recursive self-correction and task-specific exemplars to ground actions at each step.",
            "citation_title": "Language models can solve computer tasks",
            "mention_or_use": "use",
            "agent_name": "RCI",
            "agent_description": "An ICL method that prompts LLMs to produce a high-level plan and grounds each action step-by-step; uses task-specific exemplars and recursive self-correction to mitigate errors that accumulate across steps.",
            "llm_model_name": "GPT-family models used in original RCI work (as cited); treated as baseline here",
            "game_or_benchmark_name": "MiniWoB++ (standard computer-control benchmark)",
            "task_description": "Various MiniWoB++ UI tasks (terminal, form-filling, clicking, etc.), where RCI generates stepwise plans and uses self-correction to handle errors.",
            "memory_used": false,
            "memory_type": null,
            "memory_representation": null,
            "memory_update_mechanism": null,
            "memory_retrieval_mechanism": null,
            "performance_with_memory": null,
            "performance_without_memory": "RCI reported in paper: solved 54 MiniWoB++ tasks with average success rate ≈ 90.6% (as a SOTA ICL baseline prior to SynAPSE).",
            "has_performance_comparison": true,
            "ablation_or_analysis": "Paper contrasts RCI's high-level-plan exemplars with SynAPSE's trajectory-as-exemplar prompting; finds RCI suffers from error accumulation when querying LLM at each step and relies heavily on self-correction; SynAPSE's TaE reduces such accumulation.",
            "challenges_or_limitations": "RCI needs task-specific exemplars (hard-coded mapping from tasks to exemplars), limited context prevents many exemplars, high multi-step error accumulation compensated by self-correction; RCI performance drops substantially if components of its self-correction pipeline are removed.",
            "uuid": "e4882.2",
            "source_info": {
                "paper_title": "Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mind2Web: Towards a generalist agent for the web",
            "rating": 2
        },
        {
            "paper_title": "Language models can solve computer tasks",
            "rating": 2
        },
        {
            "paper_title": "A data-driven approach for learning to control computers",
            "rating": 1
        },
        {
            "paper_title": "Lost in the middle: How language models use long contexts",
            "rating": 1
        }
    ],
    "cost": 0.0171915,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control</h1>
<p>Longtao Zheng Rundong Wang Xinrun Wang Bo An<br>NTU, Singapore<br>longtao001@e.ntu.edu.sg</p>
<h2>ABSTRACT</h2>
<h4>Abstract</h4>
<p>Building agents with large language models (LLMs) for computer control is a burgeoning research area, where the agent receives computer states and performs actions to complete complex tasks. Previous computer agents have demonstrated the benefits of in-context learning (ICL); however, their performance is hindered by several issues. First, the limited context length of LLMs and complex computer states restrict the number of exemplars, as a single webpage can consume the entire context. Second, the exemplars in current methods, such as high-level plans and multi-choice questions, cannot represent complete trajectories, leading to suboptimal performance in long-horizon tasks. Third, existing computer agents rely on task-specific exemplars and overlook the similarity among tasks, resulting in poor generalization to novel tasks. To address these challenges, we introduce SynAPSE, a computer agent featuring three key components: i) state abstraction, which filters out task-irrelevant information from raw states, allowing more exemplars within the limited context, ii) trajectory-as-exemplar prompting, which prompts the LLM with complete trajectories of the abstracted states and actions to improve multi-step decision-making, and iii) exemplar memory, which stores the embeddings of exemplars and retrieves them via similarity search for generalization to novel tasks. We evaluate SynAPSE on MiniWoB++, a standard task suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, SynAPSE achieves a $99.2 \%$ average success rate (a $10 \%$ relative improvement) across 64 tasks using demonstrations from only 48 tasks. Notably, SynAPSE is the first ICL method to solve the book-flight task in MiniWoB++. SynAPSE also exhibits a $56 \%$ relative improvement in average step success rate over the previous state-of-the-art prompting scheme in Mind2Web. ${ }^{1}$</p>
<h2>1 INTRODUCTION</h2>
<p>Creating agents capable of performing complex tasks to reduce human effort in routine operations is a long-standing goal in artificial intelligence (DeepMind Interactive Agents Team, 2021). A critical and pragmatic step towards this ambitious vision is to develop agents that are proficient in computer control (Shi et al., 2017; Liu et al., 2018). Such an agent perceives states of the computer, e.g., screenshots or webpage HTML, and performs actions via keyboard and mouse to complete tasks specified in natural language, such as flight booking and email management. Different from trainingbased methods (Humphreys et al., 2022) that rely on large-scale behavioral cloning (BC) (Pomerleau, 1989) and deep reinforcement learning (RL) (Sutton and Barto, 2018), recent studies highlight the advantages of in-context learning (ICL) (Brown et al., 2020; Wei et al., 2022a;b) in achieving general and data-efficient computer control (Yao et al., 2022a; Kim et al., 2023; Deng et al., 2023). Specifically, these computer agents utilize few-shot demonstrations, also termed exemplars, to prompt large language models (LLMs) (Brown et al., 2020; Chowdhery et al., 2022; OpenAI, 2023, inter alia) to generate actions. For example, RCI (Kim et al., 2023) prompts LLMs to generate a high-level plan and grounds each action based on the plan. Concurrent with our work, Deng et al. (2023) introduce Mind2Web as a benchmark for real-world web navigation and a computer agent, MindAct. It prompts LLMs to predict the next action using multi-choice questions (MCQ), with candidate choices generated by an element-ranking model.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: SYNAPSE consists of three main components. The process begins with state abstraction, where raw computer states (e.g., the HTML of webpages) are processed into concise task-relevant observations via few-shot learning of the LLM. This step reduces the number of tokens needed for each state, a prerequisite for the second component: trajectory-as-exemplar (TaE) prompting. In TaE prompting, the LLM is prompted with exemplary trajectories (a sequence of abstracted states and actions) and the current history to determine the next action. These prompts are retrieved from the exemplar memory using similarity search. The retrieval process utilizes the embeddings of task metadata, with each metadata mapped to the corresponding exemplars. Fig. 2 further shows an illustrative comparison of TaE prompting with the prompting schemes of other computer agents.</p>
<p>Despite the promising results of previous LLM-based computer agents, they still fail to solve some tasks within MiniWoB++ (Shi et al., 2017; Liu et al., 2018), a relatively simplified computer control task suite, mainly due to the following issues. First, the limited context length of LLMs, combined with complex computer states, poses challenges for few-shot learning. For example, the book-flight task in MiniWoB++ is particularly challenging due to the extensive length of the webpage displaying flight details. Also, the task-irrelevant information in raw states can distract LLMs from generating correct actions. Second, the exemplar structures used by existing computer agents can lead to error accumulation in multi-round LLM queries and struggle to capture the complete trajectory information. Specifically, existing computer agents query LLMs at each step, and neither high-level plans nor MCQs can represent full trajectories. For example, even when prompted with a correct step-by-step plan and previous actions, RCI may still incorrectly predict the next action. As a result, existing ICL methods struggle to solve long-horizon tasks. Even for simplified tasks, they still rely on self-correction. Third, current computer agents require task-specific exemplars within a predefined scope. For example, in MiniWoB++, both email-inbox and email-inbox-nl handle email-related tasks. Similarly, multi-orderings and multi-layouts share similar interfaces. However, existing methods overlook this task similarity and hard-code the mapping from tasks to exemplars.</p>
<p>To address these challenges, we present SYNAPSE, an LLM-powered computer agent featuring a novel prompting scheme and a memory mechanism. As illustrated in Fig. 1, SYNAPSE has three core components: i) state abstraction, which extracts task-relevant observations from raw states to reduce the token length per trajectory, ii) trajectory-as-exemplar (TaE) prompting, which utilizes full successful trajectories as few-shot exemplars to prompt the LLM for enhanced multi-step decision-making, and iii) exemplar memory, which stores successful trajectories and retrieves relevant ones via similarity search for generalization to novel tasks.</p>
<p>We thoroughly evaluate SYNAPSE on two benchmarks: MiniWoB++ (Shi et al., 2017; Liu et al., 2018), a standard research task suite, and Mind2Web (Deng et al., 2023), a dataset across diverse domains of real-world web navigation. In MiniWoB++, SYNAPSE is the first ICL method that achieves human-level performance (Fig. 3). Specifically, SYNAPSE solves 64 tasks with a success rate of 99.2% using demonstrations from only 48 tasks without relying on self-correction. In comparison, the current ICL state-of-the-art (SOTA) approach (Kim et al., 2023) is limited to handling 54 tasks, requiring task-specific demonstrations for each. Compared to BC+RL and fine-tuning SOTA baselines, SYNAPSE achieves superior performance while being simpler, more flexible, and</p>
<p>more sample-efficient. A notable achievement is its success on the book-flight task, which requires long-horizon decision-making under intricate states. We further demonstrate the effectiveness of our approach in Mind2Web by incrementally augmenting the LLM with three components of SYNAPSE, i.e., state abstraction, TaE prompting, and exemplar memory. When the underlying LLM is GPT-3.5, we achieve improvements of $32 \%, 50 \%$, and $56 \%$ in the step success rate over MindAct, the SOTA ICL method in this domain. When we use CodeLlama-7B (Roziere et al., 2023), SynAPSE also achieves an average $2.5 \times$ step success rate compared to MindAct. These experiments showcase the superiority of SYNAPSE over existing computer agents in both standard and real-world benchmarks.</p>
<h1>2 Related Work</h1>
<p>Building Agents with LLMs. There has been increasing attention on building autonomous agents with LLMs (Yang et al., 2023; Mialon et al., 2023; Xi et al., 2023; Park et al., 2023). Huang et al. (2022) and Brohan et al. (2023) combined the LLM-generated plan with an embedding and a value function to determine robot policies, respectively. Inner Monologue (Huang et al., 2023) incorporated environment feedback into a closed-loop system. These methods focused on prompting for better high-level semantic plans and relied on BC or RL for low-level motor control policies. Unlike robotics, low-level actions for computer control are highly semantic, and the effective prompting scheme for directly grounding actions remains unexplored. To address this, SYNAPSE proposes trajectory-as-exemplar prompting for directly grounding these actions. Recent efforts to improve the capabilities of reasoning, planning, and coding of LLMs, such as chain-of-thought (Wei et al., 2022a; Kojima et al., 2022), least-to-most (Zhou et al., 2022), ReAct (Yao et al., 2022a), tree-ofthoughts (Yao et al., 2023), Reflexion (Shinn et al., 2023), and self-debugging (Chen et al., 2023), can be combined with SYNAPSE to improve decision-making. The methods that leveraged external tools (Wu et al., 2023a; Shen et al., 2023; Schick et al., 2023; Lu et al., 2023; Xu et al., 2023) are also orthogonal to SYNAPSE. Code as Policies (Liang et al., 2023) and ProgPrompt (Singh et al., 2023) formulated agent policies as code generation. Similarly, SYNAPSE can be strengthened using code for both state abstraction and action generation. Voyager (Wang et al., 2023a) used a skill library for life-long skill acquisition, which also complements our framework. Wu et al. (2023b) also identified the issue of limited context, using a pretrained question-answering language model to filter states, similar to MindAct. In comparison, our state-abstraction principle can leverage both LLMs (few-shot learning) and pretrained state abstraction models.</p>
<p>Agents for Computer Control. In the pursuit of creating agents capable of human-like computer interactions, MiniWoB++ task suite (Shi et al., 2017; Liu et al., 2018) has become a standard benchmark. Early attempts to solve MiniWoB++ primarily used BC and RL (Shi et al., 2017; Liu et al., 2018; Gur et al., 2018; Jia et al., 2018; Gur et al., 2021), which were not sufficient to achieve human-level performance. A notable breakthrough came with CC-Net (Humphreys et al., 2022), which achieved human-level performance but required an extensive dataset of 2.4 million demonstrations, equivalent to 6,300 hours of human effort. However, it is challenging to generalize this approach for new tasks and user customization. WebN-T5 (Gur et al., 2023a), a fine-tuned variant of the pretrained T5 model (Raffel et al., 2020), was trained on 12,000 demonstrations across 56 tasks. Similarly, WebGUM used 346,827 demonstrations to solve them. However, these fine-tuned LLMs still demanded a large amount of data and fell short of human performance in MiniWoB++. WebGPT (Nakano et al., 2021) and WebShop (Yao et al., 2022b), which operated in web-browsing environments, focused more on refining search queries rather than on general computer control. Recently, RCI (Kim et al., 2023) employed recursive self-correction to solve MiniWoB++ with a success rate of $90.6 \%$ in 54 tasks. However, it relied on task-specific exemplars, which limited its generalization to novel scenarios. In contrast, SYNAPSE achieves better performance in MiniWoB++ without relying on self-correction, using demonstrations from fewer tasks. There is also a lot of concurrent work in building computer agents and benchmarks. AdaPlanner (Sun et al., 2023) utilized environment feedback for self-correction and achieved a success rate of $92.9 \%$ in 53 tasks, but it had similar issues to RCI. Pix2Act (Shaw et al., 2023) solved 59 MiniWoB++ tasks with tree search and BC on 1.3 million demonstrations. WebAgent (Gur et al., 2023b) employed a small elementranking model for HTML state filtering and an LLM for few-shot action generation, but it did not investigate the exemplar structure and memory. Among many sophisticated benchmarks, such as Mind2Web (Deng et al., 2023), AgentBench (Liu et al., 2023a), WebArena (Zhou et al., 2023), and Android in the Wild (Rawles et al., 2023), we choose Mind2Web for the real-world evaluation.</p>
<h1>3 SynAPSE</h1>
<p>As illustrated in Fig. 1, SynAPSE consists of three main components: state abstraction, trajectory-as-exemplar prompting, and exemplar memory. Here is the general pipeline of SynAPSE: when a task occurs, SynAPSE first retrieves relevant few-shot exemplars from memory by similarity search over the embedding space of task metadata, e.g., task descriptions and initial states. At each step, SynAPSE first prompts the LLM to convert raw states into clean, task-relevant observations. Exemplary trajectories and the current trajectory (a task description and a sequence of observation-action pairs) are subsequently fed into the LLM to generate the next action.</p>
<h3>3.1 Problem Setting</h3>
<p>In this work, we focus on computer control tasks, where an agent interacts with the environment to accomplish a task specified by natural language. The state and action space for a computer agent are consistent with how humans interact with computers. At each step, it receives a computer state, such as HTML of webpages or screenshots, and performs actions via keyboard and mouse. The actions can be either code or natural language, depending on the benchmarks. As the decisionmaking engine, LLMs are fed with few-shot exemplars to process raw states into clean observations and generate actions. When the task is completed, the trajectory is considered successful.</p>
<h3>3.2 State Abstraction</h3>
<p>The number of exemplars in few-shot learning can drastically influence the performance of LLMpowered computer agents (Wang et al., 2023b; Kim et al., 2023). However, the context limits of LLMs, combined with the intricacy of computer states, often restrict the number of exemplars. To illustrate, directly processing long HTML documents of real-world websites can be prohibitively costly because of many task-irrelevant elements. As a result, the performance of existing computer agents is hindered by the limited number of exemplars, and they often incorporate self-correction as a remedy. Moreover, many task-irrelevant elements in raw HTML states can potentially distract LLMs from accurate action generation. Even though some LLMs can handle longer inputs, their performance becomes worse as the input context grows longer (Liu et al., 2023b).
To reduce the length of each state, Synapse takes advantage of the few-shot learning ability of LLMs to extract task-relevant information from raw states and form clean observations for subsequent action generation, as shown in Fig. 1. Specifically, we propose few-shot state abstraction prompts in both explicit and implicit forms. For scenarios where the context can handle multiple states, such as email-inbox in MiniWoB++, we apply explicit abstraction through state-observation pairs, denoted as 〈state, observation〉. In this case, the LLM is prompted with these pairs as fewshot exemplars, followed by the current raw state, to generate the clean observation. Alternatively, in scenarios with complex states where explicit abstraction is not applicable, such as book-flight in MiniWoB++, we adopt implicit abstraction by pairing task descriptions and state-parsing code, denoted as 〈task, code〉. We feed these pairs as few-shot exemplars to the LLM, along with the current task, to produce the code. This code takes the task and the raw state as parameters and returns the clean observation. If the code execution raises an error, we ask the LLM to perform zero-shot state abstraction. Within Mind2Web, we further demonstrate that the state abstraction principle can aid in effectively utilizing existing state abstraction tools. Specifically, Mind2Web has a pretrained element-ranking model that ranks and filters HTML elements to obtain a clean observation comprising the top- $k$ elements. As a simplified implementation of state abstraction, we set $k$ to 3 and 5 for the previous and current observations, respectively. In comparison, the SOTA method set $k$ to 50 . Although this reduces the recall from $86 \%$ to $53 \%$, i.e., only $53 \%$ of the clean observations contain the target element, it achieves a higher step success rate (Sec. 4.4). State abstraction shrinks long-winded raw states into concise and shorter ones, enabling trajectory-as-exemplar prompting (Sec. 3.3), which is impossible for previous methods due to context limits.</p>
<h3>3.3 Trajectory-AS-EXEMPLAR Prompting</h3>
<p>The prompts for action generation in previous computer agents often overlook the sequential nature of decision-making. For example, each RCI exemplar consists of a high-level plan, while MindAct formulates exemplars as step-by-step MCQs, as illustrated in Fig. 2. Without considering the</p>
<p>complete trajectories, these methods struggle to capture previous environment interactions. Furthermore, these methods query LLMs for one action at each step, leading to error accumulation over time. Therefore, these methods require self-correction even for simplified scenarios in MiniWoB++, especially for tasks with many steps and repeated actions, such as use-autocomplete and use-spinner.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">RCI</th>
<th style="text-align: center;">MindAct</th>
<th style="text-align: center;">Trajectory-as-Exemplar</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Task: Use the terminal below to delete a file ending with the extension .gif <br> Plan: <br> 1. Type "ls" command to list all files in the terminal. <br> 2. Type "rm [filename]" command to delete the file ending with ".gif". <br> 3. Press "enter" key after typing each command to execute the command.</td>
<td style="text-align: center;">Task: Use the terminal below to delete a file ending with the extension .gif HTML state: <html> ... user\$ ls ... script.zip shark.gif ... </html> <br> Previous actions: <br> agent.type('ls'), agent.press('enter') <br> What should be the next action? <br> A. None of the above <br> B. agent.press('enter') <br> C. agent.type('rm shark.gif') <br> Answer: C</td>
<td style="text-align: center;">Task: Use the terminal below to delete a file ending with the extension .gif Observation: <html> ... user\$ ... </html> Action: <br> agent.type('ls') <br> agent.press('enter') <br> Observation: <html> ... user\$ ls ... <br> script.zip shark.gif ... </html> <br> Action: <br> agent.type('rm shark.gif') <br> agent.press('enter')</td>
</tr>
</tbody>
</table>
<p>Figure 2: Comparison of trajectory-as-exemplar prompting with other prompting schemes. The illustration is based on the terminal task in MiniWoB++, where the agent is asked to delete a file ending with a specific extension. To solve this task, RCI (Kim et al., 2023) prompts the LLM with a step-by-step plan combined with the current state and the previous actions to generate each action, while MindAct (Deng et al., 2023) prompts the LLM with MCQ-formatted exemplars at each step. In contrast, SYNAPSE uses a straightforward prompting scheme based on trajectory-level exemplars. This exemplar structure offers a consistent and interactive format, is more informative, and enables the LLM to produce temporally abstracted actions until a new state is required. As shown above, the LLM generates two consecutive actions: type(ls) and press(enter) without querying the new state. After executing these actions, it pauses to receive the new state for subsequent actions. We provide several complete trajectories in Appendix C for illustration.</p>
<p>To address this challenge, we introduce trajectory-as-exemplar (TaE) prompting, utilizing complete trajectories to prompt the LLM for action generation, formatted as $\langle$ task, observation, action, ..., observation, action $\rangle$. The first step of TaE prompting is to feed the LLM with successful trajectories. Subsequently, the LLM is prompted with the current trajectory (the task description and previous clean observations and actions) to produce the next action. Take Fig. 2 as an example, where the agent is asked to delete an item using the terminal. We pass a few successful trajectories to the LLM to illustrate how the problem is solved, followed by the current task description "Delete a file ending with the extension .gif" and the clean observation representing "the terminal is empty". We then execute the action returned by the LLM (agent.type(ls), agent.press(enter)) and construct the next prompt by appending the action and the next clean observation to the prompt. This process iterates until the agent completes the task or reaches the maximum number of steps. Similarly, in Mind2Web, we iteratively append states filtered by the element-ranking model and target actions to the prompt since it is a static dataset. This straightforward prompting scheme enhances the decision-making ability of the LLM for several reasons. First, the consistent format of interleaved observations and actions is well-suited for grounding actions, which allows conveniently parsing actions and setting stop tokens for LLM responses. Also, it provides more information for decision-making. More importantly, it implicitly prompts the LLM to generate temporally abstracted actions and query new states only when necessary. Temporal abstraction also results in lower cost and latency. Compared to human-crafted plans and MCQs, TaE exemplars can also be directly converted from human demonstrations. Therefore, TaE prompting improves the action accuracy in long-horizon tasks.</p>
<h1>3.4 Exemplar Memory</h1>
<p>Previous computer agents rely on task-specific exemplars. For example, the mapping from tasks to few-shot exemplars is hard-coded in the RCI agent. Therefore, it requires exemplars for each of the 54 tasks tested, despite analogous tasks and interfaces, such as email-inbox and email-inbox-nl-turk, click-checkboxes-large and click-checkboxes-transfer, etc. In other words, existing computer agents lack a mechanism that matches relevant exemplars and tasks automatically. As a result, these agents cannot leverage task similarity and struggle to generalize to new tasks.</p>
<p>To exploit task similarity and enable generalization, SYNAPSE introduces exemplar memory $\mathcal{D}=$ $(K, V)$, where $K$ is a fixed-sized array of embedding vectors of task metadata and $V$ is the cor-</p>
<p>responding state abstraction prompts and exemplary trajectories. This memory is constructed by encoding all the metadata using an embedding model and storing their corresponding exemplars in a vector database. As illustrated in Fig. 1, for a given task, SYNAPSE first encodes the task metadata and performs similarity search in the vector database, which retrieves relevant trajectories as fewshot exemplars. Formally, the retrieval process can be denoted as $\arg \operatorname{top}-n_{d \in \mathcal{D}} \operatorname{sim}(q, d)$ where $q$ is the query metadata and $\operatorname{sim}$ is the Euclidean distance in the embedding space. In MiniWoB++, the metadata consists of the task description concatenated with the initial state from five random seeds of the selected 48 tasks. We retrieve the top three exemplars from memory and use the most common one to retrieve its exemplars, for there is a clear task division. For example, if the retrieved exemplars belong to enter-date, enter-date, and click-button, we retrieve all exemplars of enter-date. In Mind2Web, we encode the website name, domain, and task description as metadata for trajectories in the training set, and retrieve the corresponding exemplars of matched metadata for few-shot learning. Using the exemplar memory, SYNAPSE can automatically determine which exemplars to prompt, which lays the foundation for a general-purpose and adaptive computer agent.</p>
<h1>4 Evaluation</h1>
<p>We evaluate our approach on two benchmarks, MiniWoB++ and Mind2Web. The MiniWoB++ task suite integrates diverse tasks that mirror the intricacies of real-world human-computer interactions (Shi et al., 2017; Liu et al., 2018). Although it is a relatively simplified environment, current computer agents struggle to solve several challenging tasks, such as book-flight, click-checkboxessoft, and use-autocomplete. Mind2Web (Deng et al., 2023) is a realistic dataset containing human demonstrations of open-domain tasks from various real-world websites, such as Airbnb and Twitter. It measures in-the-wild generalization across different tasks, websites, and domains.</p>
<h3>4.1 EXPERIMENTAL SETUP</h3>
<p>To ensure fair comparisons, we query the same APIs of LLMs as in the prior work. In the MiniWoB++ experiments, we query gpt-3.5-turbo-0301 and run 50 episodes to produce the results for each task. For Mind2Web, the default LLM is gpt-3.5-turbo-16k-0613. We configure the temperature to 0 , i.e., greedy decoding. We use text-embedding-ada-002 as the embedding model. For efficient retrieval in large-scale memory, we use Faiss (Johnson et al., 2019) to store embeddings and perform similarity search.</p>
<p>For the environment setup in MiniWoB++, we follow the configurations of RCI (Kim et al., 2023). The state space is the raw HTML code, while the action space includes click-xpath, move-mouse, type, press, and click-options. The main metric here is the success rate of the agent in accomplishing tasks. In Mind2Web, the observation space is the HTML provided in the dataset, and the action space includes click, type, and select. The metrics we measure include element selection accuracy (Ele. Acc), the success rate for each step in a task (Step SR), and the success rate for the whole task (SR) against the human-annotated ground truth. The Mind2Web dataset is split into a training set and three test sets: Cross-Task, Cross-Website, and Cross-Domain, to evaluate generalizability over tasks from the same websites, unseen websites from similar domains, and completely unseen domains in the training set, respectively. We only store the training set in the exemplar memory.</p>
<h3>4.2 BASELINES</h3>
<p>We conduct extensive experiments to evaluate the performance of SYNAPSE in comparison to the SOTA approaches on MiniWoB++. For BC+RL baselines, we use CC-Net (Humphreys et al., 2022) and Pix2Act (Shaw et al., 2023), both of which combine large-scale BC and RL. In terms of finetuning baselines, we compare with WebGUM (Furuta et al., 2023) and WebN-T5 (Gur et al., 2023a), two language models fine-tuned on a large number of demonstrations. As for ICL methods, the baselines are RCI (Kim et al., 2023) and AdaPlanner (Sun et al., 2023), both of which incorporate self-correction to solve 54 and 53 MiniWoB++ tasks, respectively. We also include human scores sourced from Humphreys et al. (2022) for additional benchmarking. In Mind2Web, we compare with MindAct (Deng et al., 2023), the current SOTA ICL method in this benchmark.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Synapse is the first ICL method that achieves human-level performance in MiniWoB++. It outperforms previous self-correction methods, including RCI and AdaPlanner. A comprehensive task-wise evaluation is shown in Appendix A. *Pix2Act and AdaPlanner are concurrent with our work. We excluded them from the right-side figure due to their overlap with CC-Net and RCI. The outlier tasks are determined with an interquartile range of 1.5 .</p>
<h1>4.3 ANALYSIS ON MiniWoB++</h1>
<p>Fig. 3 showcases the average performance of the various methods across tasks. With a mean success rate of $99.2 \%$, SynAPSE achieves human-level performance and outperforms all baselines on MiniWoB++. As shown in Fig. 4a, SynAPSE outperforms BC+RL SOTA, especially on textprocessing tasks, e.g., terminal and text-transform, while being more flexible. Compared to ICL (Fig. 4b) and fine-tuning SOTA (Fig. 4c), SynAPSE achieves better performance on all tasks. It is particularly noteworthy that its superiority does not rely on self-correction. In comparison, RCI and AdaPlanner, although equipped with self-correction, fail to achieve comparable performance.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Task-wise comparisons between SynAPSE and various SOTA methods. For clarity, the bars in each figure are arranged in ascending order based on the success rate differences. Tasks not reported by other methods and those with differences less than 0.05 are not included.</p>
<p>Compared to previous ICL methods, SynAPSE overcomes limitations related to context length, complicated states, and multi-step error accumulation (Fig. 4b). First, SynAPSE outperforms them on tasks requiring detailed state understanding, such as click-collapsible-2, click-tab-2-hard, and count-shape. These results highlight the effectiveness of SynAPSE in accurately capturing complex HTML states, while RCI consistently performs worse. Second, SynAPSE significantly improves performance on tasks involving many steps or repeated actions by reducing the error accumulation in multi-round LLM queries, such as use-autocomplete, use-spinner, etc. Third, SynAPSE can solve tasks that these approaches cannot handle due to the limited context length, such as book-flight and click-pie (Fig. 5). Moreover, it can generalize from existing exemplars to unseen tasks because it does not rely on task-specific exemplars. Therefore, SynAPSE can solve 64 tasks, more than all previous ICL methods, using exemplars from only 48 tasks.</p>
<p>Most of the observed failure cases are due to incorrect reasoning by LLMs. For example, in some cases of the count-shape task, the LLM miscounts the number of target items, leading to the selection of an incorrect answer. Similarly, in the text-transform task, the LLM occasionally produces actions with characters similar to, but different from, those in the HTML (e.g., recognizing jrpf as jrfp).</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Cross-Task</th>
<th></th>
<th></th>
<th>Cross-Website</th>
<th></th>
<th></th>
<th>Cross-Domain</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Ele. Acc</td>
<td>Step SR</td>
<td>SR</td>
<td>Ele. Acc</td>
<td>Step SR</td>
<td>SR</td>
<td>Ele. Acc</td>
<td>Step SR</td>
<td>SR</td>
</tr>
<tr>
<td>MindAct (CodeLlama-7B)</td>
<td>11.2</td>
<td>7.7</td>
<td>0.4</td>
<td>12.4</td>
<td>9.0</td>
<td>$\mathbf{0 . 6}$</td>
<td>13.8</td>
<td>9.9</td>
<td>0.2</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction</td>
<td>21.4</td>
<td>15.5</td>
<td>0.8</td>
<td>19.5</td>
<td>13.5</td>
<td>$\mathbf{0 . 6}$</td>
<td>20.0</td>
<td>15.6</td>
<td>$\mathbf{1 . 2}$</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction + TaE</td>
<td>27.0</td>
<td>24.5</td>
<td>1.2</td>
<td>21.4</td>
<td>17.9</td>
<td>0.0</td>
<td>22.1</td>
<td>$\mathbf{1 9 . 9}$</td>
<td>0.7</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction + TaE + memory</td>
<td>$\mathbf{2 9 . 4}$</td>
<td>$\mathbf{2 6 . 4}$</td>
<td>$\mathbf{3 . 2}$</td>
<td>$\mathbf{2 2 . 9}$</td>
<td>$\mathbf{1 8 . 9}$</td>
<td>$\mathbf{0 . 6}$</td>
<td>$\mathbf{2 2 . 6}$</td>
<td>19.7</td>
<td>0.3</td>
</tr>
<tr>
<td>MindAct (GPT-3.5)</td>
<td>20.3</td>
<td>17.4</td>
<td>0.8</td>
<td>19.3</td>
<td>16.2</td>
<td>$\mathbf{0 . 6}$</td>
<td>21.6</td>
<td>18.6</td>
<td>1.0</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction</td>
<td>29.8</td>
<td>25.2</td>
<td>2.0</td>
<td>26.1</td>
<td>19.6</td>
<td>$\mathbf{0 . 6}$</td>
<td>28.0</td>
<td>24.3</td>
<td>$\mathbf{1 . 8}$</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction + TaE</td>
<td>32.8</td>
<td>29.2</td>
<td>2.0</td>
<td>28.0</td>
<td>22.7</td>
<td>$\mathbf{0 . 6}$</td>
<td>29.0</td>
<td>26.2</td>
<td>$\mathbf{1 . 8}$</td>
</tr>
<tr>
<td>SYNAPSE w/ state abstraction + TaE + memory</td>
<td>$\mathbf{3 4 . 0}$</td>
<td>$\mathbf{3 0 . 6}$</td>
<td>$\mathbf{2 . 4}$</td>
<td>$\mathbf{2 9 . 1}$</td>
<td>$\mathbf{2 4 . 2}$</td>
<td>$\mathbf{0 . 6}$</td>
<td>$\mathbf{2 9 . 6}$</td>
<td>$\mathbf{2 6 . 4}$</td>
<td>1.5</td>
</tr>
</tbody>
</table>
<h1>4.4 Evaluation on Realistic Websites</h1>
<p>We also validate the effectiveness of the state abstraction principle, TaE prompting, and exemplar memory in the Mind2Web experiments. The current SOTA agent in this benchmark, MindAct, leverages an element-ranking model to filter the top-50 relevant elements as the clean observation. It uses MCQ to recursively query the LLM to select an action from five candidates until one action is chosen or all options are incorrect. Although MCQ-formatted exemplars outperform direct generation, MindAct often struggles to choose the correct element (Deng et al., 2023). In contrast, in our experiments, both SYNAPSE and its variants use direct generation, a more straightforward prompting scheme. As shown in Tab. 1, we incrementally equip direct generation with state abstraction, trajectory prompting, and exemplar memory, which achieves improvements of $32 \%, 50 \%$, and $56 \%$ in average Step SR across three levels of generalization based on GPT-3.5, respectively. SYNAPSE also achieves $2.5 \times$ Step SR compared to MindAct on average based on CodeLlama-7B.</p>
<p>Table 1: Mind2Web results and ablations with CodeLlama-7B (top) and GPT-3.5 (bottom). We gradually add state abstraction, TaE prompting, and memory to demonstrate the effectiveness of each component. In SYNAPSE w/ state abstraction, we simply use direct generation with fewer top-ranked elements in clean observations, outperforming the MCQ-formatted prompting used in MindAct. SYNAPSE w/ state abstraction + TaE further shows the benefits of using trajectories as exemplars. In both these variants, we use static few-shot exemplars. Finally, we encode the training set as memory and retrieve exemplars via similarity search, which further improves performance.</p>
<h3>4.5 Ablation Studies</h3>
<p>In this section, we perform ablation studies to evaluate the effectiveness of three design choices of SYNAPSE and provide insights into the contributions of each. These findings validate the effectiveness of i) state abstraction in handling complex states and providing more exemplars within the limited context, ii) TaE prompting in enhancing the capability of multi-step decision-making, and iii) exemplar memory in facilitating generalization across tasks.</p>
<p>Ablating State Abstraction. In Fig. 5, we illustrate the consistent performance improvement achieved by state abstraction in MiniWoB++. Due to the limited context, LLMs without state abstraction struggle to solve tasks with complex states, e.g., book-flight, while SYNAPSE effectively overcomes this. This technique also improves performance on tasks with ambiguous descriptions, such as email-inbox-nl-turk, increasing the success rate from $52 \%$ to $100 \%$. In Mind2Web, direct generation with the top five elements improves the success rate by $32 \%$ compared to MCQ with the top-50 elements (Tab. 1), although reducing $k$ leads to a drop in recall from $86 \%$ to $53 \%$. These results emphasize the effectiveness of state abstraction in helping LLMs generate actions under complex states and vague task descriptions.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: State abstraction enables solving MiniWoB++ tasks with complex states (e.g., book-flight). It also improves performance by providing more exemplars (e.g., email-inbox).</p>
<p>Ablating Trajectory-as-Exemplar Prompting. TaE prompting significantly benefits LLMs in tasks with long horizons and repeated actions such as guess-number, use-spinner, and useautocomplete, which are particularly challenging for SOTA ICL methods. For example, RCI has success rates of $20 \%, 88 \%$, and $58 \%$ for these tasks. In contrast, SYNAPSE solves them with success rates of $100 \%, 100 \%$, and $98 \%$. This improvement is attributed to the comprehensive history and temporal action abstraction introduced by TaE prompting. In Mind2Web, TaE prompting further improves the average step success rate by $19 \%$ compared to SYNAPSE with state abstraction only. It also outperforms MindAct by $50 \%$ across three levels of generalization, as shown in Tab. 1.</p>
<p>Exemplar Memory Enables Generalization. Exemplar memory is crucial for generalization, especially for similar computer control tasks. Rather than previous methods that rely on task-specific exemplars, SYNAPSE's memory can automatically find relevant exemplars for the task at hand. It enables the agent to identify and utilize exemplars to generalize from email-inbox-nl-turk to related tasks such as email-inbox-forward-nl-turk and email-inbox. It also adapts to different layouts, e.g., from multi-layouts to multi-orderings. Consequently, SYNAPSE solves 64 tasks in MiniWoB++ with demonstrations of only 48 tasks. It achieves better performance not only for the predefined tasks but also for new tasks outside the scope. For the 16 unseen tasks, the average success rate is almost $100 \%$. For tasks within the scope, the memory mechanism also accurately matches relevant exemplars. SYNAPSE only encounters a $2 \%$ failure rate in click-tab-2-hard due to exemplar mismatches. In Mind2Web, the memory further improves SYNAPSE with state abstraction and TaE prompting, leading to a $6 \%$ improvement in Step SR for cross-task and cross-website generalization. However, the improvement is relatively marginal in cross-domain generalization, which might be attributed to the LLM being influenced by exemplars from unrelated domains. The average distance (similarity scores) between retrieved exemplars and the target task in three Mind2Web test sets are shown in Tab. 2. A greater distance implies less similarity. This accounts for why memory does not aid in cross-domain generalization, as these domains are entirely unseen.</p>
<h1>5 Discussion, Limitations \&amp; Future Work</h1>
<p>In this paper, we introduce SYNAPSE, a computer agent with a prompting technique that is broadly applicable to any decision-making task. SYNAPSE addresses three main challenges faced by current computer agents: the limited context length, the unexplored exemplar structure, and task-specific exemplars. It has three key components: i) state abstraction, which converts raw states to clean observations, reducing the tokens of each state to allow for more few-shot exemplars, ii) trajectory-asexemplar prompting, which prompts the LLM with trajectory-level exemplars to improve multi-step decision-making, and iii) exemplar memory, which stores and retrieves exemplars to enable generalization. Our method outperforms existing methods on 64 tasks in the MiniWoB++ benchmark with a $99.2 \%$ average success rate without self-correction. It is particularly noteworthy that our method successfully solves the challenging book-flight task in MiniWoB++. SYNAPSE also achieves a 56\% relative improvement over SOTA ICL methods in Mind2Web, a real-world website benchmark, at three levels of generalization (cross-task, cross-website, and cross-domain).</p>
<p>We acknowledge that there exist limitations in our framework. High inference latency is a major concern due to the use of LLMs. Using our prompting scheme to distill a more responsive, taskspecific agent from existing LLMs could be a remedy. Another concern is our dependence on the quality of exemplars. Therefore, training a zero-shot computer agent with instruction tuning (Wei et al., 2021; Chung et al., 2022) based on our prompting techniques is a promising research direction. Also, the memory module can be seamlessly combined with human intervention for user customization and task adaptation, which opens up an avenue for future research. In addition, the memory structure and retrieval process can be further investigated for better generalization. It is also worthwhile to combine our methods with compositional generalization methods (Zhou et al., 2022; Wang et al., 2023a) to solve more complicated tasks. Finally, while SYNAPSE currently operates on text, it would be interesting to explore multi-modal and video understanding capabilities to tackle more challenging tasks, e.g., pixel-based Android control (Li et al., 2020; Toyama et al., 2021).</p>
<h1>ACKNOWLEDGEMENTS</h1>
<p>We would like to thank the OpenAI Researcher Access Program for granting us API access for this project. We also thank the anonymous reviewers for their valuable feedback.</p>
<h2>REFERENCES</h2>
<p>DeepMind Interactive Agents Team. Creating multimodal interactive agents with imitation and selfsupervised learning. arXiv preprint arXiv:2112.03763, 2021.</p>
<p>Tianlin Shi, Andrej Karpathy, Linxi Fan, Jonathan Hernandez, and Percy Liang. World of bits: An open-domain platform for web-based agents. In International Conference on Machine Learning, pages 3135-3144. PMLR, 2017.</p>
<p>Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang. Reinforcement learning on web interfaces using workflow-guided exploration. In The Eleventh International Conference on Learning Representations, 2018.</p>
<p>Peter C Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, and Timothy Lillicrap. A data-driven approach for learning to control computers. In International Conference on Machine Learning, pages 9466-9482. PMLR, 2022.</p>
<p>Dean A Pomerleau. Alvinn: An autonomous land vehicle in a neural network. In Advances in Neural Information Processing Systems, pages 305-313, 1989.</p>
<p>Richard S Sutton and Andrew G Barto. Reinforcement Learning: An Introduction. MIT press, 2018.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901, 2020.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, volume 35, pages 24824-24837, 2022a.</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models. Transactions on Machine Learning Research, 2022b. ISSN 2835-8856.</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In The Eleventh International Conference on Learning Representations, 2022a.</p>
<p>Geunwoo Kim, Pierre Baldi, and Stephen McAleer. Language models can solve computer tasks. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.</p>
<p>OpenAI. Gpt-4 technical report, 2023.
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950, 2023.</p>
<p>Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, and Dale Schuurmans. Foundation models for decision making: Problems, methods, and opportunities. arXiv preprint arXiv:2303.04129, 2023.</p>
<p>Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: A survey. arXiv preprint arXiv:2302.07842, 2023.</p>
<p>Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.</p>
<p>Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442, 2023.</p>
<p>Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International Conference on Machine Learning, pages 9118-9147. PMLR, 2022.</p>
<p>Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do as I can, not as I say: Grounding language in robotic affordances. In Conference on Robot Learning, pages 287-318. PMLR, 2023.</p>
<p>Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. In Conference on Robot Learning, pages 1769-1782. PMLR, 2023.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Advances in Neural Information Processing Systems, volume 35, pages 22199-22213, 2022.</p>
<p>Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, et al. Least-to-most prompting enables complex reasoning in large language models. In The Eleventh International Conference on Learning Representations, 2022.</p>
<p>Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: An autonomous agent with dynamic memory and self-reflection. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. Teaching large language models to self-debug. arXiv preprint arXiv:2304.05128, 2023.</p>
<p>Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, and Nan Duan. Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv preprint arXiv:2303.04671, 2023a.</p>
<p>Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving AI tasks with chatbot and its friends in huggingface. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large language models. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, and Dongkuan Xu. Rewoo: Decoupling reasoning from observations for efficient augmented language models. arXiv preprint arXiv:2305.18323, 2023.</p>
<p>Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. Code as policies: Language model programs for embodied control. In 2023 IEEE International Conference on Robotics and Automation (ICRA), pages 9493-9500. IEEE, 2023.</p>
<p>Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task plans using large language models. In 2023 IEEE International Conference on Robotics and Automation (ICRA), pages 11523-11530. IEEE, 2023.</p>
<p>Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023a.</p>
<p>Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom Mitchell, and Shrimai Prabhumoye. Plan, eliminate, and track-language models are good teachers for embodied agents. arXiv preprint arXiv:2305.02412, 2023b.</p>
<p>Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, and Dilek Hakkani-Tur. Learning to navigate the web. In International Conference on Learning Representations, 2018.</p>
<p>Sheng Jia, Jamie Ryan Kiros, and Jimmy Ba. Dom-q-net: Grounded RL on structured language. In International Conference on Learning Representations, 2018.</p>
<p>Izzeddin Gur, Natasha Jaques, Yingjie Miao, Jongwook Choi, Manoj Tiwari, Honglak Lee, and Aleksandra Faust. Environment generation for zero-shot compositional reinforcement learning. In Advances in Neural Information Processing Systems, volume 34, 2021.</p>
<p>Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin V Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, and Aleksandra Faust. Understanding html with large language models. In ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models, 2023a.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485-5551, 2020.</p>
<p>Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.</p>
<p>Shunyu Yao, Howard Chen, John Yang, and Karthik R Narasimhan. Webshop: Towards scalable real-world web interaction with grounded language agents. In Advances in Neural Information Processing Systems, 2022b.</p>
<p>Haotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and Chao Zhang. Adaplanner: Adaptive planning from feedback with language models. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Peter Shaw, Mandar Joshi, James Cohan, Jonathan Berant, Panupong Pasupat, Hexiang Hu, Urvashi Khandelwal, Kenton Lee, and Kristina Toutanova. From pixels to UI actions: Learning to follow instructions via graphical user interfaces. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Douglas Eck, and Aleksandra Faust. A real-world webagent with planning, long context understanding, and program synthesis. arXiv preprint arXiv:2307.12856, 2023b.</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. Agentbench: Evaluating llms as agents. arXiv preprint arXiv:2308.03688, 2023a.</p>
<p>Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building autonomous agents. arXiv preprint arXiv:2307.13854, 2023.</p>
<p>Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, and Timothy Lillicrap. Android in the wild: A large-scale dataset for android device control. In Advances in Neural Information Processing Systems, 2023.</p>
<p>Bryan Wang, Gang Li, and Yang Li. Enabling conversational interaction with mobile ui using large language models. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1-17, 2023b.</p>
<p>Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint arXiv:2307.03172, 2023b.</p>
<p>Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3):535-547, 2019.</p>
<p>Hiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, and Izzeddin Gur. Multimodal web navigation with instruction-finetuned foundation models. arXiv preprint arXiv:2305.11854, 2023.</p>
<p>Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2021.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.</p>
<p>Yang Li, Jiacong He, Xin Zhou, Yuan Zhang, and Jason Baldridge. Mapping natural language instructions to mobile UI action sequences. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8198-8210, 2020.</p>
<p>Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, and Doina Precup. Androidenv: A reinforcement learning platform for android. arXiv preprint arXiv:2105.13231, 2021.</p>
<h1>A Additional Results</h1>
<p>Table 3: Per-task mean success rate comparison between Synapse, humans, and baselines. The data for human participants are obtained from CC-Net (Humphreys et al., 2022). The aggregated performance of the baselines prior to CC-Net is represented as others (Gur et al., 2018; Jia et al., 2018; Liu et al., 2018; Shi et al., 2017). We attach the average success rate and the number of solved tasks for each method at the bottom of the table.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Ours</th>
<th style="text-align: center;">Human</th>
<th style="text-align: center;">RCI</th>
<th style="text-align: center;">AdaPlanner</th>
<th style="text-align: center;">Pix2Act</th>
<th style="text-align: center;">Pix2Act <br> (BC)</th>
<th style="text-align: center;">CC-Net</th>
<th style="text-align: center;">CC-Net <br> (BC)</th>
<th style="text-align: center;">WehGUM</th>
<th style="text-align: center;">WehN- <br> T5</th>
<th style="text-align: center;">Others</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">bioect-angle</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.29</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.80</td>
</tr>
<tr>
<td style="text-align: center;">book-flight</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">chase-circle</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">choose-date</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">choose-date-easy</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">choose-date-medium</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">choose-list</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">0.26</td>
</tr>
<tr>
<td style="text-align: center;">circle-center</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
</tr>
<tr>
<td style="text-align: center;">click-button</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-button-sequence</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-checkboxes</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-checkboxes-large</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.84</td>
</tr>
<tr>
<td style="text-align: center;">click-checkboxes-soft</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.94</td>
</tr>
<tr>
<td style="text-align: center;">click-checkboxes-transfer</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">click-collapsible</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-collapsible-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.17</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;">click-color</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.27</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-dialog</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-dialog-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.24</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-link</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-meme</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.13</td>
</tr>
<tr>
<td style="text-align: center;">click-meme-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.16</td>
</tr>
<tr>
<td style="text-align: center;">click-option</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-pie</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-scroll-list</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.07</td>
</tr>
<tr>
<td style="text-align: center;">click-shades</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;">click-shape</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">click-tab</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-tab-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.27</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-tab-2-easy</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">click-tab-2-hard</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.12</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">click-tab-2-medium</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">click-test</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-test-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">click-test-transfer</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">click-widget</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">copy-paste</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">copy-paste-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">count-shape</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.76</td>
</tr>
<tr>
<td style="text-align: center;">count-sides</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.30</td>
</tr>
<tr>
<td style="text-align: center;">drag-box</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.31</td>
</tr>
<tr>
<td style="text-align: center;">drag-cube</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.18</td>
</tr>
<tr>
<td style="text-align: center;">drag-item</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">drag-items</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.41</td>
</tr>
<tr>
<td style="text-align: center;">drag-items-grid</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.01</td>
</tr>
<tr>
<td style="text-align: center;">drag-shapes</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.92</td>
</tr>
<tr>
<td style="text-align: center;">drag-sort-members</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.66</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.09</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.99</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-delete</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-forward</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-forward-nl</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-forward-nl-turk</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-important</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-nl-turk</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.93</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">0.93</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-noscroll</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-reply</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">email-inbox-star-reply</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">enter-date</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">enter-password</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">enter-text</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">enter-text-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">enter-text-dynamic</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">enter-time</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.90</td>
</tr>
<tr>
<td style="text-align: center;">find-midpoint</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.31</td>
</tr>
<tr>
<td style="text-align: center;">find-word</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">focus-text</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">focus-text-2</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">grid-coordinate</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">guess-number</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.20</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.20</td>
</tr>
<tr>
<td style="text-align: center;">highlight-text</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.90</td>
</tr>
<tr>
<td style="text-align: center;">highlight-text-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.13</td>
</tr>
<tr>
<td style="text-align: center;">identify-shape</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">login-user</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">login-user-popup</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">moving-items</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.78</td>
</tr>
<tr>
<td style="text-align: center;">multi-layouts</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">1.00</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">multi-orderings</th>
<th style="text-align: center;">1.00</th>
<th style="text-align: center;">0.96</th>
<th style="text-align: center;">1.00</th>
<th style="text-align: center;">1.00</th>
<th style="text-align: center;">n/a</th>
<th style="text-align: center;">n/a</th>
<th style="text-align: center;">1.00</th>
<th style="text-align: center;">0.00</th>
<th style="text-align: center;">1.00</th>
<th style="text-align: center;">0.88</th>
<th style="text-align: center;">1.00</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">navigate-tree</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">number-checkboxes</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.16</td>
</tr>
<tr>
<td style="text-align: center;">read-table</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">read-table-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">resize-textarea</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.27</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.11</td>
</tr>
<tr>
<td style="text-align: center;">right-angle</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.38</td>
</tr>
<tr>
<td style="text-align: center;">scroll-text</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">scroll-text-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.96</td>
</tr>
<tr>
<td style="text-align: center;">search-engine</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.15</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">einem-says</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">-0.00</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.28</td>
</tr>
<tr>
<td style="text-align: center;">simple-algebra</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.04</td>
</tr>
<tr>
<td style="text-align: center;">simple-arithmetic</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.07</td>
</tr>
<tr>
<td style="text-align: center;">social-media</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.21</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">social-media-all</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">0.31</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">social-media-some</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.42</td>
</tr>
<tr>
<td style="text-align: center;">terminal</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">-0.01</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">text-editor</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.01</td>
</tr>
<tr>
<td style="text-align: center;">text-transform</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.19</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.00</td>
</tr>
<tr>
<td style="text-align: center;">tic-tac-toe</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.47</td>
</tr>
<tr>
<td style="text-align: center;">unicode-test</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
</tr>
<tr>
<td style="text-align: center;">use-autocomplete</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">0.98</td>
</tr>
<tr>
<td style="text-align: center;">use-colorwheel</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">use-colorwheel-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
</tr>
<tr>
<td style="text-align: center;">use-slider</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.51</td>
</tr>
<tr>
<td style="text-align: center;">use-slider-2</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.09</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr>
<td style="text-align: center;">use-spinner</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.98</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">0.17</td>
</tr>
<tr>
<td style="text-align: center;">visual-addition</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.97</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">1.00</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.01</td>
</tr>
<tr>
<td style="text-align: center;">Average</td>
<td style="text-align: center;">0.992</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.906</td>
<td style="text-align: center;">0.929</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">0.665</td>
<td style="text-align: center;">0.935</td>
<td style="text-align: center;">0.305</td>
<td style="text-align: center;">0.802</td>
<td style="text-align: center;">0.484</td>
<td style="text-align: center;">0.646</td>
</tr>
<tr>
<td style="text-align: center;"># of solved tasks</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">54</td>
<td style="text-align: center;">53</td>
<td style="text-align: center;">59</td>
<td style="text-align: center;">59</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">56</td>
<td style="text-align: center;">56</td>
<td style="text-align: center;">88</td>
</tr>
</tbody>
</table>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: Task-wise comparisons between Synapse, human, two concurrent methods (AdaPlanner and Pix2Act), and WebN-T5, a fine-tuned LLM. Similar to the result in Sec. 4, the bars in each figure are sorted in ascending order based on the success rate differences. Tasks not reported by other methods and those with differences less than 0.05 are not included.</p>
<h1>B ENVIRONMENT DETAILS</h1>
<h2>B. 1 MiniWoB++</h2>
<p>To ensure a fair evaluation, we use the legacy branch of MiniWoB++ as in previous work. Of the 64 tasks that we test (see Tab. 3), 48 are provided with exemplars, and 16 are unseen tasks. The unseen tasks are choose-list, click-checkboxes-transfer, click-checkboxes, click-option, click-tab-2-hard, click-test-2, click-test, copy-paste, login-user, email-inbox-forward-nl-turk, email-inbox-forwardnl, email-inbox, enter-text, multi-orderings, simple-arithmetic, and unicode-test. The average number of exemplars per task for RCI and Synapse is 1.32 and 3.45, respectively. However, the number</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: Ablations of the number of elements after state abstraction in Mind2Web. The backbone language model here is CodeLlama-Instruct-7B.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: An illustration of MiniWoB++ and Mind2Web.
of exemplars for each task varies. For simple tasks, we use a similar number of exemplars as in RCI. To solve complex tasks (e.g., book-flight), we use more exemplars, which lowers the average data efficiency. For example, in book-flight, we include 5 exemplars for better robustness. Moreover, RCI relies on self-correction (task, state, and agent grounding) while SYNAPSE does not. The success rate of RCI will decrease by around $50 \%$ when one of them is missing. Also, one of the benefits of our method is that we can leverage more exemplars in context because of state abstraction.</p>
<p>We use the raw HTML code to represent the agent's state space. We provide the action space of the computer agent in the system prompt. The action space consists of five keyboard and mouse operations, following the prior work (Kim et al., 2023). We use code generation to ground the actions generated by the LLM, the same as the concurrent work (Sun et al., 2023). We use exemplars that specify to click on the first element of all matching ones to avoid clicking on multiple items specified by the xpath. The action space is described in the system prompt:</p>
<div class="codehilite"><pre><span></span><code><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">System</span>
<span class="nx">You</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">large</span><span class="w"> </span><span class="nx">language</span><span class="w"> </span><span class="nx">model</span><span class="w"> </span><span class="nx">trained</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">navigate</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">web</span><span class="p">.</span><span class="w"> </span><span class="nx">To</span><span class="w"> </span><span class="nx">accomplish</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">task</span><span class="p">,</span><span class="w"> </span><span class="nx">use</span>
<span class="w">    </span><span class="nx">methods</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">following</span><span class="w"> </span><span class="nx">Agent</span><span class="w"> </span><span class="kd">class</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">generate</span><span class="w"> </span><span class="nx">actions</span><span class="w"> </span><span class="nx">until</span><span class="w"> </span><span class="nx">you</span><span class="w"> </span><span class="nx">need</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">new</span><span class="w"> </span><span class="nx">state</span><span class="w"> </span><span class="nx">to</span>
<span class="w">    </span><span class="nx">proceed</span><span class="p">.</span>
<span class="o">...</span>
<span class="kd">class</span><span class="w"> </span><span class="nx">Agent</span><span class="p">:</span>
<span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="nx">__init__</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">args</span><span class="p">):</span>
<span class="w">        </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Action</span><span class="p">:</span><span class="w"> </span><span class="k">type</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="kt">string</span><span class="w"> </span><span class="nx">via</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">keyboard</span>
<span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="k">type</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">characters</span><span class="p">:</span><span class="w"> </span><span class="nx">str</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nx">None</span><span class="p">:</span>
<span class="w">        </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Action</span><span class="p">:</span><span class="w"> </span><span class="nx">click</span><span class="w"> </span><span class="nx">an</span><span class="w"> </span><span class="nx">HTML</span><span class="w"> </span><span class="nx">element</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">valid</span><span class="w"> </span><span class="nx">spath</span>
<span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="nx">click_xpath</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">xpath</span><span class="p">:</span><span class="w"> </span><span class="nx">str</span><span class="p">):</span>
<span class="w">        </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Actions</span><span class="p">:</span><span class="w"> </span><span class="nx">press</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">key</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">keyboard</span><span class="p">,</span><span class="w"> </span><span class="nx">including</span><span class="p">:</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">enter</span><span class="p">,</span><span class="w"> </span><span class="nx">space</span><span class="p">,</span><span class="w"> </span><span class="nx">arrowleft</span><span class="p">,</span><span class="w"> </span><span class="nx">arrowright</span><span class="p">,</span><span class="w"> </span><span class="nx">backspace</span><span class="p">,</span><span class="w"> </span><span class="nx">arrowup</span><span class="p">,</span><span class="w"> </span><span class="nx">arrowdown</span><span class="p">,</span><span class="w"> </span><span class="nx">command</span><span class="o">+</span><span class="nx">a</span><span class="p">,</span><span class="w"> </span><span class="nx">command</span><span class="o">+</span><span class="nx">c</span>
<span class="w">        </span><span class="p">,</span><span class="w"> </span><span class="nx">command</span><span class="o">+</span><span class="nx">v</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="nx">press</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">key_type</span><span class="p">:</span><span class="w"> </span><span class="nx">str</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nx">None</span><span class="p">:</span>
<span class="w">        </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Action</span><span class="p">:</span><span class="w"> </span><span class="nx">click</span><span class="w"> </span><span class="nx">an</span><span class="w"> </span><span class="nx">option</span><span class="w"> </span><span class="nx">HTML</span><span class="w"> </span><span class="nx">element</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">list</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">valid</span><span class="w"> </span><span class="nx">xpath</span>
<span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="nx">click_option</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">xpath</span><span class="p">:</span><span class="w"> </span><span class="nx">str</span><span class="p">):</span>
<span class="w">        </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Action</span><span class="p">:</span><span class="w"> </span><span class="nx">move</span><span class="w"> </span><span class="nx">mouse</span><span class="w"> </span><span class="nx">cursor</span><span class="w"> </span><span class="nx">on</span><span class="w"> </span><span class="nx">an</span><span class="w"> </span><span class="nx">HTML</span><span class="w"> </span><span class="nx">element</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">valid</span><span class="w"> </span><span class="nx">xpath</span>
<span class="w">    </span><span class="nx">def</span><span class="w"> </span><span class="nx">movemouse</span><span class="p">(</span><span class="kp">self</span><span class="p">,</span><span class="w"> </span><span class="nx">xpath</span><span class="p">:</span><span class="w"> </span><span class="nx">str</span><span class="p">):</span>
<span class="w">    </span><span class="o">...</span>
<span class="o">...</span>
</code></pre></div>

<p>In MiniWoB++, there are two types of state abstraction prompts. For scenarios where the context can handle multiple states, we utilize state-observation pairs. These pairs are collected alongside the trajectories. The states are obtained from the environment, while the cleaned observations are provided by humans. To further reduce human efforts, we can also automatically infer cleaned observations given trajectories using LLMs. In scenarios with complex states where explicit abstraction is not applicable, we implicitly abstract states by pairing task descriptions and state-parsing code. Similarly, the task descriptions are already given by the environment. The code here is collected via zero-shot sampling from LLMs (GPT-4). The code is tested by executing it with states derived from the environment and having its results reviewed by humans. The state abstraction prompts are retrieved from the memory, together with trajectories.</p>
<h1>B. 2 Mind2Web</h1>
<p>Mind2Web offers a comprehensive collection of over 2,000 tasks from 137 websites in 31 different domains. The task descriptions in Mind2Web only provide high-level goals. It intentionally avoids detailed, step-by-step instructions, encouraging the agents to autonomously understand and perform tasks, rather than simply following instructions. With Mind2Web, agents can interact with webpages in a way that goes beyond the basic operations of searching or reading. They can click, select, and type into website elements. Such interactions mimic typical human activities on websites, thus expanding the range of tasks the agent can perform.
Mind2Web provides test sets for three levels of generalization: cross-task, cross-websites, and crossdomain. To evaluate cross-task generalization, Mind2Web provides 252 tasks from 69 websites, where the agent has possibly interacted with these websites to perform similar tasks. The crosswebsite test set consists of 177 tasks from 10 unique websites not seen in the training set but belonging to domains familiar to the agent. This setup tests the agent's ability to navigate new websites within known domains and tasks. The cross-domain test set, containing 912 tasks from 73 websites, requires the agent to adapt to completely unseen domains in the training set. The remaining data, consisting of 1,009 tasks from 73 websites, are used for the training set.</p>
<h2>C Prompts</h2>
<p>In this section, we provide several examples of our prompting and LLM responses for illustration. We also open source all trajectories in our project website.</p>
<h2>C. 1 TERMINAL</h2>
<p>To finish the terminal task in MiniWoB++, the agent needs to first list the files and then delete one with a certain extension. By using TaE prompting, SYNAPSE completed this task in four steps: two for state abstraction and two for TaE prompting.</p>
<h2>C.1.1 STEP 1: State Abstraction (EXPLICIT)</h2>
<p>Input:</p>
<div class="codehilite"><pre><span></span><code>&gt;<span class="w"> </span>Role:<span class="w"> </span>User
State:
<span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;wrap&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;2&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>Use<span class="w"> </span>the<span class="w"> </span>terminal<span class="w"> </span>below<span class="w"> </span>to<span class="w"> </span>delete<span class="w"> </span>a<span class="w"> </span>file<span class="w"> </span>ending<span class="w"> </span>with<span class="w"> </span>the<span class="w"> </span>extension<span class="w"> </span><span class="nt">&lt;span</span>
<span class="w">        </span><span class="na">class=</span><span class="s">&quot;bold&quot;</span><span class="nt">&gt;</span>.png<span class="nt">&lt;/span&gt;&lt;/div&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;area&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;3&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;&lt;div</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;4&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
</code></pre></div>

<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of
available commands.</span>
</div><div class="terminal-output" data-wob_ref="10" data-wob_eps="e0">
<span class="output" data-wob_ref="11" data-wob_eps="e0">Last login: Tue May 02 2023</span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0">
<span class="user" data-wob_ref="13" data-wob_eps="e0">user\%</span>
<span id="active-input" class="command"></span>
<span id="input-flicker" data-wob_ref="14" data-wob_eps="e0"></span>
$</$ div $>$
$</$ div $>$
$</$ div $>$
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file ending with the extension .png
State:
<div id="wrap" data-wob_ref="2" data-wob_eps="e0">
<div id="query">Use the terminal below to delete a file ending with the extension <span class="bold">.py</span></div>
<div id="area" data-wob_ref="3" data-wob_eps="e0"><div data-wob_ref="4" data-wob_eps="e0">
<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of
available commands.</span>
</div><div class="terminal-output" data-wob_ref="10" data-wob_eps="e0">
<span class="output" data-wob_ref="11" data-wob_eps="e0"><Last login: Tue May 02 2023</span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0">
<span class="user" data-wob_ref="13" data-wob_eps="e0">user\%</span>
<span id="active-input" class="command"></span>
<span id="input-flicker" data-wob_ref="14" data-wob_eps="e0"></span>
$</$ div $>$
$</$ div $>$
$</$ div $>$
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file ending with the extension .py
State:
<div id="wrap" data-wob_ref="2" data-wob_eps="e0">
<div id="query">Use the terminal below to delete a file that has <span class="bold">no file extension</span>.</div>
<div id="area" data-wob_ref="3" data-wob_eps="e0"><div data-wob_ref="4" data-wob_eps="e0">
<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of
available commands.</span>
</div><div class="terminal-output" data-wob_ref="10" data-wob_eps="e0">
<span class="output" data-wob_ref="11" data-wob_eps="e0"><Last login: Tue May 02 2023</span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0">
<span class="user" data-wob_ref="13" data-wob_eps="e0">user\%</span>
<span id="active-input" class="command"></span>
<span id="input-flicker" data-wob_ref="14" data-wob_eps="e0"></span>
$</$ div>
$</$ div $>$
$</$ div $>$
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file that has no file extension.
State:
<div id="wrap" data-wob_ref="2" data-wob_eps="e0">
<div id="query">Use the terminal below to delete a file ending with the extension <span class="bold">.gpg</span></div>
<div id="area" data-wob_ref="3" data-wob_eps="e0"><div data-wob_ref="4" data-wob_eps="e0">
<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of
available commands.</span>


<div class="codehilite"><pre><span></span><code><span class="nt">&lt;/div&gt;&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;10&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;11&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>Last<span class="w"> </span>login:<span class="w"> </span>Sun<span class="w"> </span>Sep<span class="w"> </span>24<span class="w"> </span>2023<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/div&gt;&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-line&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;12&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;user&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;13&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>user$<span class="nt">&lt;/span&gt;</span>
<span class="w">        </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;active-input&quot;</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;command&quot;</span><span class="nt">&gt;&lt;/span&gt;</span>
<span class="w">        </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;input-flicker&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;14&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;&lt;/span&gt;</span>
<span class="w">        </span><span class="nt">&lt;/div&gt;</span>
<span class="w">    </span><span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;input</span><span class="w"> </span><span class="na">type=</span><span class="s">&quot;text&quot;</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;terminal-target&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;15&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="nt">&lt;/div&gt;&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
Observation:
</code></pre></div>




# Output: 

## Role: Assistant

Use the terminal below to delete a file ending with the extension .gpg.

## C.1.2 STEP 2: TaE Prompting

Input:
System Prompt (as mentioned in Sec. B.1)

## Exemplary Trajectory 1


<div class="codehilite"><pre><span></span><code><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Task</span><span class="p">:</span><span class="w"> </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">png</span>
<span class="nx">Trajectory</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Observation</span><span class="p">:</span>
<span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">png</span>
<span class="nx">Action</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">ls</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">enter</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="w">    </span><span class="nx">Observation</span><span class="p">:</span>
<span class="w">    </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">png</span>
<span class="w">    </span><span class="nx">user</span><span class="err">\$</span><span class="w"> </span><span class="nx">ls</span>
<span class="w">    </span><span class="nx">alloy</span><span class="p">.</span><span class="nx">png</span><span class="w"> </span><span class="nx">script</span><span class="p">.</span><span class="nx">zip</span><span class="w"> </span><span class="nx">shark</span><span class="p">.</span><span class="nx">html</span><span class="w"> </span><span class="nx">sudo</span><span class="p">.</span><span class="nx">gpg</span>
<span class="w">    </span><span class="nx">Action</span><span class="p">:</span>
<span class="w">    </span><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Note</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">it</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">allowed</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">use</span><span class="w"> </span><span class="o">*</span><span class="p">.</span><span class="nx">xxx</span><span class="w"> </span><span class="nx">here</span><span class="p">.</span><span class="w"> </span><span class="nx">alloy</span><span class="p">.</span><span class="nx">png</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span>
<span class="w">        </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">png</span><span class="p">.</span><span class="w"> </span><span class="nx">Type</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">complete</span><span class="w"> </span><span class="nx">filename</span><span class="p">.</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">rm</span><span class="w"> </span><span class="nx">alloy</span><span class="p">.</span><span class="nx">png</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">enter</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
</code></pre></div>




## Exemplary Trajectory 2


<div class="codehilite"><pre><span></span><code><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Task</span><span class="p">:</span><span class="w"> </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">py</span>
<span class="nx">Trajectory</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Observation</span><span class="p">:</span>
<span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">py</span>
<span class="nx">Action</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">ls</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">enter</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="w">    </span><span class="nx">Observation</span><span class="p">:</span>
<span class="w">    </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">ending</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="p">.</span><span class="nx">py</span>
<span class="w">    </span><span class="nx">user</span><span class="err">\$</span><span class="w"> </span><span class="nx">ls</span>
<span class="w">    </span><span class="nx">bash</span><span class="p">.</span><span class="nx">gpg</span><span class="w"> </span><span class="nx">image</span><span class="p">.</span><span class="nx">gif</span><span class="w"> </span><span class="nx">nintendo</span><span class="p">.</span><span class="nx">py</span>
<span class="nx">Action</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
</code></pre></div>



\# Note that it is not allowed to use *.xxx here.
\# nintendo.py is the file ending with the extension .py. Type the complete filename.
agent.type('rm nintendo.py')
agent.press('enter')
・・

# Exemplary Trajectory 3 


<div class="codehilite"><pre><span></span><code><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Task</span><span class="p">:</span><span class="w"> </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">has</span><span class="w"> </span><span class="nx">no</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">extension</span><span class="p">.</span>
<span class="nx">Trajectory</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="nx">Observation</span><span class="p">:</span>
<span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">has</span><span class="w"> </span><span class="nx">no</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">extension</span><span class="p">.</span>
<span class="nx">Action</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">ls</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">enter</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">User</span>
<span class="w">    </span><span class="nx">Observation</span><span class="p">:</span>
<span class="w">    </span><span class="nx">Use</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">terminal</span><span class="w"> </span><span class="nx">below</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">delete</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">has</span><span class="w"> </span><span class="nx">no</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">extension</span><span class="p">.</span>
<span class="w">    </span><span class="nx">user</span><span class="err">\$</span><span class="w"> </span><span class="k">is</span>
<span class="w">    </span><span class="nx">encrypted</span><span class="p">.</span><span class="nx">sh</span><span class="w"> </span><span class="nx">chrome</span><span class="p">.</span><span class="nx">txt</span><span class="w"> </span><span class="nx">search</span>
<span class="nx">Action</span><span class="p">:</span>
<span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">Note</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">it</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">allowed</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">use</span><span class="w"> </span><span class="o">*</span><span class="p">.</span><span class="nx">xxx</span><span class="w"> </span><span class="nx">here</span><span class="p">.</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="nx">search</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">has</span><span class="w"> </span><span class="nx">no</span><span class="w"> </span><span class="nx">file</span><span class="w"> </span><span class="nx">extension</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="nx">encrypted</span><span class="p">.</span><span class="nx">sh</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">chrome</span><span class="p">.</span><span class="nx">txt</span><span class="w"> </span><span class="nx">are</span><span class="w"> </span><span class="k">not</span><span class="p">.</span>
<span class="w">        </span><span class="nx">Type</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">complete</span><span class="w"> </span><span class="nx">filename</span><span class="p">.</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">rm</span><span class="w"> </span><span class="nx">search</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="s">&quot;enter&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
</code></pre></div>




## Current Trajectory


<div class="codehilite"><pre><span></span><code>&gt; Role: User
Task: Use the terminal below to delete a file ending with the extension .gpg
Trajectory:
&gt; Role: User
Observation:
Use the terminal below to delete a file ending with the extension .gpg
Action:
</code></pre></div>




## Output:


<div class="codehilite"><pre><span></span><code><span class="p">&gt;</span><span class="w"> </span><span class="nx">Role</span><span class="p">:</span><span class="w"> </span><span class="nx">Assistant</span>
<span class="w">    </span><span class="o">...</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="k">type</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">ls</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="nx">agent</span><span class="p">.</span><span class="nx">press</span><span class="p">(</span><span class="err">&#39;</span><span class="nx">enter</span><span class="err">&#39;</span><span class="p">)</span>
<span class="w">    </span><span class="o">...</span>
</code></pre></div>




## C.1.3 STEP 3: State Abstraction (Explicit)

Input:


<div class="codehilite"><pre><span></span><code>&gt;<span class="w"> </span>Role:<span class="w"> </span>User
State:
<span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;wrap&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;2&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>Use<span class="w"> </span>the<span class="w"> </span>terminal<span class="w"> </span>below<span class="w"> </span>to<span class="w"> </span>delete<span class="w"> </span>a<span class="w"> </span>file<span class="w"> </span>ending<span class="w"> </span>with<span class="w"> </span>the<span class="w"> </span>extension<span class="w"> </span><span class="nt">&lt;span</span>
<span class="w">        </span><span class="na">class=</span><span class="s">&quot;bold&quot;</span><span class="nt">&gt;</span>.png<span class="nt">&lt;/span&gt;&lt;/div&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;area&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;3&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;&lt;div</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;4&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;terminal&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;5&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;terminal-header&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;6&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>terminal<span class="nt">&lt;/div&gt;</span>
<span class="w">    </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">id=</span><span class="s">&quot;terminal-contents&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;7&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;8&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;9&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>Welcome!<span class="w"> </span>Type<span class="w"> </span>help<span class="w"> </span>for<span class="w"> </span>a<span class="w"> </span>list<span class="w"> </span>of
<span class="w">            </span>available<span class="w"> </span>commands.<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/div&gt;&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;10&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;11&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>Last<span class="w"> </span>login:<span class="w"> </span>Tue<span class="w"> </span>May<span class="w"> </span>02<span class="w"> </span>2023<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/div&gt;&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-line&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;17&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;user&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;18&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>user3<span class="nt">&lt;/span&gt;</span>
<span class="w">    </span><span class="nt">&lt;span</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;command&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;19&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>is<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/div&gt;&lt;div</span><span class="w"> </span><span class="na">class=</span><span class="s">&quot;terminal-output&quot;</span><span class="w"> </span><span class="na">data-wob_ref=</span><span class="s">&quot;20&quot;</span><span class="w"> </span><span class="na">data-wob_eps=</span><span class="s">&quot;e0&quot;</span><span class="nt">&gt;</span>
</code></pre></div>



<span class="output" data-wob_ref="21" data-wob_eps="e0">alloy.png script.zip shark.html sudo.gpg</span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0"> <span class="user" data-wob_ref="13" data-wob_eps="e0">user\#</span> <span id="active-input" class="command" data-wob_ref="16" data-wob_eps="e0"></span> <span id="input-flicker" data-wob_ref="14" data-wob_eps="e0" class="hide"></span> </div>
$</$ div $>$
$</$ div $>$
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file ending with the extension .png
user $\ 1 \mathrm{~s}$ ls
alloy.png script.zip shark.html sudo.gpg
State:
<div id="wrap" data-wob_ref="2" data-wob_eps="e0">
<div id="query">Use the terminal below to delete a file ending with the extension <span class="bold">.py</span></div>
<div id="area" data-wob_ref="3" data-wob_eps="e0"><div data-wob_ref="4" data-wob_eps="e0">
<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of available commands.</span>
</div><div class="terminal-output" data-wob_ref="10" data-wob_eps="e0">
<span class="output" data-wob_ref="11" data-wob_eps="e0">Last login: Tue May 02 2023</span>
</div><div class="terminal-line" data-wob_ref="17" data-wob_eps="e0">
<span class="user" data-wob_ref="18" data-wob_eps="e0">user\#</span>
<span class="command" data-wob_ref="19" data-wob_eps="e0">ls</span>
</div><div class="terminal-output" data-wob_ref="20" data-wob_eps="e0">
<span class="output" data-wob_ref="21" data-wob_eps="e0">bash.gpg image.gif nintendo.py</ span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0">
<span class="user" data-wob_ref="13" data-wob_eps="e0">user\#</span>
<span id="active-input" class="command" data-wob_ref="16" data-wob_eps="e0"></span>
<span id="input-flicker" data-wob_ref="14" data-wob_eps="e0" class=""></span>
$</$ div>
$</$ div $>$
$</$ div $>$
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file ending with the extension .py
user $\ 1 \mathrm{~s}$ ls
bash.gpg image.gif nintendo.py
State:
<div id="wrap" data-wob_ref="2" data-wob_eps="e0">
<div id="query">Use the terminal below to delete a file that has <span class="bold">no file extension</span>.</div>
<div id="area" data-wob_ref="3" data-wob_eps="e0"><div data-wob_ref="4" data-wob_eps="e0">
<div id="terminal" data-wob_ref="5" data-wob_eps="e0">
<div id="terminal-header" data-wob_ref="6" data-wob_eps="e0">terminal</div>
<div id="terminal-contents" data-wob_ref="7" data-wob_eps="e0">
<div class="terminal-output" data-wob_ref="8" data-wob_eps="e0">
<span class="output" data-wob_ref="9" data-wob_eps="e0">Welcome! Type help for a list of available commands.</span>
</div><div class="terminal-output" data-wob_ref="10" data-wob_eps="e0">
<span class="output" data-wob_ref="11" data-wob_eps="e0">Last login: Tue May 02 2023</span>
</div><div class="terminal-line" data-wob_ref="17" data-wob_eps="e0">
<span class="user" data-wob_ref="18" data-wob_eps="e0">user\#</span>
<span class="command" data-wob_ref="19" data-wob_eps="e0">ls</span>
</div><div class="terminal-output" data-wob_ref="20" data-wob_eps="e0">
<span class="output" data-wob_ref="21" data-wob_eps="e0">encrypted.sh chrome.txt search</ span>
</div><div class="terminal-line" data-wob_ref="12" data-wob_eps="e0">
<span class="user" data-wob_ref="13" data-wob_eps="e0">user\#</span>
<span id="active-input" class="command" data-wob_ref="16" data-wob_eps="e0"></span>
<span id="input-flicker" data-wob_ref="14" data-wob_eps="e0" class=""></span>
$</$ div>
$</$ div>
$</$ div>
<input type="text" id="terminal-target" data-wob_ref="15" data-wob_eps="e0">
$</$ div $></$ div $>$
$</$ div $>$
Observation:
Use the terminal below to delete a file that has no file extension.
user $\ 1 \mathrm{~s}$ ls


<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Code available at https://ltzheng.github.io/Synapse.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>