<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4332 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4332</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4332</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-99.html">extraction-schema-99</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <p><strong>Paper ID:</strong> paper-279999727</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.17580v1.pdf" target="_blank">Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> The exponential growth of scientific literature challenges researchers extracting and synthesizing knowledge. Traditional search engines return many sources without direct, detailed answers, while general-purpose LLMs may offer concise responses that lack depth or omit current information. LLMs with search capabilities are also limited by context window, yielding short, incomplete answers. This paper introduces WISE (Workflow for Intelligent Scientific Knowledge Extraction), a system addressing these limits by using a structured workflow to extract, refine, and rank query-specific knowledge. WISE uses an LLM-powered, tree-based architecture to refine data, focusing on query-aligned, context-aware, and non-redundant information. Dynamic scoring and ranking prioritize unique contributions from each source, and adaptive stopping criteria minimize processing overhead. WISE delivers detailed, organized answers by systematically exploring and synthesizing knowledge from diverse sources. Experiments on HBB gene-associated diseases demonstrate WISE reduces processed text by over 80% while achieving significantly higher recall over baselines like search engines and other LLM-based approaches. ROUGE and BLEU metrics reveal WISE's output is more unique than other systems, and a novel level-based metric shows it provides more in-depth information. We also explore how the WISE workflow can be adapted for diverse domains like drug discovery, material science, and social science, enabling efficient knowledge extraction and synthesis from unstructured scientific papers and web sources.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4332.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4332.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WISE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Workflow for Intelligent Scientific Knowledge Extraction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A tree-based, LLM-powered workflow that iteratively filters, scores, ranks, and fuses information from web/scientific sources to build a query-specific knowledge container for domain queries (demonstrated on HBB gene — disease associations).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>WISE (Workflow for Intelligent Scientific Knowledge Extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>WISE begins from a user query and an initial set of candidate sources and performs iterative layers of: (1) LLM-driven query-specific content filtering Γ(q,C(s)) to extract focused text segments; (2) score calculation Ψ that computes unique contribution K(s) = |F(s)| - |F(s) ∩ K_l| and normalizes via Score(s) = K(s) / log(1 + w_filtered(s) + |K_l|); (3) threshold checking/pruning comparing max Score to threshold T and selecting Top-k for expansion; (4) knowledge consolidation via an LLM-powered fusion function Λ to merge filtered content into the knowledge container K. The process recursively expands by following links in filtered content and stops when scores fall below T. Outputs are a structured, query-aligned knowledge container containing extracted relations, sub-variations, and detailed textual summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>unspecified LLM(s) (paper uses LLM-powered components but does not name the specific model used for WISE's filtering/fusion; GPT-4o was used as a baseline comparator)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biology / Biomedical (demonstrated on gene-disease associations for HBB)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td>initial seed: 24 sources (initially attempted 34 sources, 24 successfully extracted)</td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>associative relationships and structured entity relationships (gene–disease/phenotype associations and frequency/coverage metrics); not mathematical laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>knowledge container: structured lists of entities and associations, textual summaries, citations, and level-based detail scores (not symbolic equations)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>comparison against a combined union-of-systems ground set; evaluation with recall, ROUGE/BLEU (uniqueness), and a manual level-based depth analysis (levels 0–5 assigned by human annotators)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Recall: 0.842 on HBB disease set; reduced processed text volume by >80% on average (filtering reduction mean 80.14%, example UniProt reduced from 8,249 to 355 words); average level-of-detail: 3.81; reported lower ROUGE/BLEU relative to baselines indicating more unique output (exact ROUGE/BLEU values not provided).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to Pure ChatGPT (GPT-4o) recall 0.474, ChatGPT with Search recall 0.368, Gemini recall 0.105, Google Search recall 0.158; WISE outperformed these baselines on recall, uniqueness (ROUGE/BLEU relative ranks), and level-based depth (WISE 3.81 vs others lower).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Access restrictions (paywalls, bot-detection) prevented extraction from some sources (10/34 failed); dependence on word-overlap metrics can underweight contextual relationships; exact LLM choice unspecified; long-tail or under-documented relations may still be missed; output may be too detailed for non-expert users.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4332.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o (ChatGPT baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o (OpenAI GPT-4o used via ChatGPT / OpenAI API)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large, general-purpose transformer-based LLM used in the paper as baseline systems: Pure ChatGPT (GPT-4o) and ChatGPT augmented with web search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>GPT-4o (as baseline retrieval/generation agent)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used as (a) Pure ChatGPT relying on pretrained knowledge, and (b) ChatGPT with Search (GPT-4o augmented with web search capabilities) to answer the HBB gene query; these baselines receive the query directly and return synthesized answers without the paper's tree-based filtering/pruning workflow.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>GPT-4o (model referenced in paper; context window up to 128k tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General / Biomedical (used to answer biomedical query)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>entity–relation extraction and summarization (gene-disease associations) via generative output, not explicit quantitative laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>textual summaries / lists</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Compared outputs to union-of-systems disease set and evaluated recall, ROUGE/BLEU, and level-based depth</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Pure ChatGPT recall: 0.474; ChatGPT with Search recall: 0.368 (as reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>These are the baselines; WISE outperformed both on recall and depth metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limited context window for practical multi-source ranking despite large nominal token windows; answers can be concise but lack depth or up-to-date citations.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4332.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GIX</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GIX (LLM-based gene interaction extraction system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Named in the paper as an example system leveraging large language models to automate gene interaction extraction and shown to outperform earlier methods on benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>GIX (LLM-driven gene interaction extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mentioned as an LLM-based system that automates gene interaction extraction from literature (paper does not provide implementation details in the main text).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / genomics (gene interaction extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>biological relations (gene–gene / gene–interaction relationships), pattern extraction</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured relations/interaction records (as described conceptually)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>reported to outperform earlier methods on benchmark datasets (per paper's related-work statement) but specifics not provided here</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Positioned as outperforming earlier (pre-LLM) methods on benchmarks (no numeric values provided in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4332.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioBERT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-adapted BERT-based language model pre-trained on large-scale biomedical corpora for tasks like named entity recognition and relation extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Biobert: a pre-trained biomedical language representation model for biomedical text mining</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>BioBERT (domain-adapted transformer for biomedical IE)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>BioBERT is referenced as a domain-adapted pretrained model that yields improved precision for named entity recognition and relation extraction tasks in biomedical text mining; the paper cites it as representative of domain-adapted models used in extracting relations from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>BERT-base architecture pre-trained on biomedical corpora (BioBERT standard variants; model size not specified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / biomedical NLP</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>entity recognition and relation extraction (biomedical relations), not explicit mathematical laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured entities and relations (NER/RE outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Reported improvements in precision on standard IE tasks in prior work (paper cites BioBERT's known evaluation results but does not reproduce them)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Described as improving over earlier feature-engineered models on NER/RE tasks (no numbers provided here)</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4332.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation techniques</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of approaches that combine retrieval from external corpora with LLM generation to ground outputs in retrieved documents and improve factuality and coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Mentioned as prior work that attempts pruning sources and enhancing verification by augmenting LLMs with retrieved documents; the paper contrasts RAG approaches with WISE's hierarchical, query-driven filtering+scoring+stopping framework.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General / Information Retrieval + NLP</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>used to surface evidence-backed assertions and relations from corpora (not necessarily symbolic laws)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>retrieved documents plus generated text; structured retrieval results</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Typical RAG validation uses held-out queries and factuality metrics (paper does not detail RAG validation here)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>RAG is cited as a comparison point; WISE claims to differ by employing hierarchical pruning and adaptive stopping</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>RAG approaches rarely employ hierarchical, query-driven frameworks with adaptive stopping (per paper); may suffer from redundant or low-value retrieval without pruning strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4332.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HybridRAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HybridRAG: Integrating knowledge graphs and vector retrieval augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach integrating knowledge graphs with vector-based retrieval-augmented generation to improve information extraction efficiency and structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hybridrag: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>HybridRAG (knowledge-graph + vector retrieval + RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited as an approach that fuses knowledge-graph structure with vector retrieval and RAG to enable more efficient and structured information extraction; paper references it in the context of literature that combines graph reasoning and retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Information extraction / Knowledge representation</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>structured relations and graph-based representations of knowledge (entity–relation extraction and linking)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>knowledge graph nodes/edges combined with retrieved document context</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e4332.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WorkflowLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>WorkflowLLM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach to enhance workflow orchestration capabilities of large language models, improving how models perform multi-step, structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Workflowllm: Enhancing workflow orchestration capability of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>WorkflowLLM (orchestration enhancements for LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced as prior work in workflow orchestration for LLMs; cited in the paper as related work on orchestrating multi-step processes and pruning/verification strategies, analogous to components of WISE's pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP / LLM systems</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>supports multi-step extraction and decision workflows rather than direct quantitative-law discovery</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>orchestrated multi-step outputs (structured pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e4332.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ByteScience</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ByteScience</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system described as bridging unstructured scientific literature and structured data using auto fine-tuned LLMs at token granularity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bytescience: Bridging unstructured scientific literature and structured data with auto fine-tuned large language model in token granularity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ByteScience (auto fine-tuned LLM for literature→structured data)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Appears in related work as an LLM-based approach that auto-fine-tunes models to convert unstructured scientific text into structured data at fine token granularity, positioned alongside WISE as part of recent advances in automated literature-to-structure systems.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td>auto fine-tuned LLM (specific model not stated in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Scientific literature mining (multi-domain)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>structured extraction of entities/relations; aims to produce structured datasets from unstructured literature</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured data tables / token-granular structured outputs</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e4332.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Large-Scale Knowledge Synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work cited that addresses large-scale synthesis of knowledge and complex retrieval from biomedical documents using machine learning techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Large-scale knowledge synthesis methods (ML-based)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited as related research addressing knowledge synthesis and complex retrieval in biomedical domains, informing the paper's context about large-scale automated extraction from biomedical documents (paper does not detail the method here).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical information retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>knowledge synthesis of relations and facts (entity/relation extraction and aggregation)</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>aggregated facts and synthesized documents/knowledge bases</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e4332.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Buehler2024</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced approach that combines generative knowledge extraction with graph representations and multimodal graph reasoning to accelerate discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Generative knowledge extraction + graph-based multimodal reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited as prior work linking generative extraction methods with graph-based representations and multimodal graph reasoning to derive richer, structured knowledge from scientific sources; the current paper positions knowledge-graph integration as future work inspired by such efforts.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Cross-disciplinary (machine learning + scientific discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>graph-structured relationships and inferred patterns (multi-modal associations), not specified as symbolic laws</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>knowledge graphs plus generative summaries</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4332.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e4332.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or approaches that use LLMs (or other AI models) to extract, distill, or discover quantitative laws, patterns, relationships, or principles from scientific papers or scholarly literature.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tree-LSTM / tree architectures</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree-structured neural architectures (e.g., Tree-LSTM for protein-protein interaction identification)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural tree-structured architectures have been applied to relation extraction tasks such as protein–protein interaction identification and are cited as prior work in extraction from structured/semistructured text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Identifying protein-protein interaction using tree lstm and structured attention</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Tree-structured neural architectures (Tree-LSTM + structured attention)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced as previous neural architectures that improved relation extraction (protein–protein interactions) by exploiting tree-structured inputs and structured attention mechanisms; cited in related work to situate WISE among hierarchical or tree-inspired methods.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / NLP (relation extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_papers</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>type_of_quantitative_law</strong></td>
                            <td>relation extraction (interaction identification), pattern detection in text structure</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_output_format</strong></td>
                            <td>structured relation labels/tuples</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>requires_human_in_loop</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fully_automated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large language model based framework for automated extraction of genetic interactions from unstructured data <em>(Rating: 2)</em></li>
                <li>Hybridrag: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction <em>(Rating: 2)</em></li>
                <li>Bytescience: Bridging unstructured scientific literature and structured data with auto fine-tuned large language model in token granularity <em>(Rating: 2)</em></li>
                <li>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning <em>(Rating: 2)</em></li>
                <li>Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents <em>(Rating: 2)</em></li>
                <li>Workflowllm: Enhancing workflow orchestration capability of large language models <em>(Rating: 1)</em></li>
                <li>Identifying protein-protein interaction using tree lstm and structured attention <em>(Rating: 1)</em></li>
                <li>Tree of science -tos: A web-based tool for scientific literature recommendation. search less, research more! <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4332",
    "paper_id": "paper-279999727",
    "extraction_schema_id": "extraction-schema-99",
    "extracted_data": [
        {
            "name_short": "WISE",
            "name_full": "Workflow for Intelligent Scientific Knowledge Extraction",
            "brief_description": "A tree-based, LLM-powered workflow that iteratively filters, scores, ranks, and fuses information from web/scientific sources to build a query-specific knowledge container for domain queries (demonstrated on HBB gene — disease associations).",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "WISE (Workflow for Intelligent Scientific Knowledge Extraction)",
            "method_description": "WISE begins from a user query and an initial set of candidate sources and performs iterative layers of: (1) LLM-driven query-specific content filtering Γ(q,C(s)) to extract focused text segments; (2) score calculation Ψ that computes unique contribution K(s) = |F(s)| - |F(s) ∩ K_l| and normalizes via Score(s) = K(s) / log(1 + w_filtered(s) + |K_l|); (3) threshold checking/pruning comparing max Score to threshold T and selecting Top-k for expansion; (4) knowledge consolidation via an LLM-powered fusion function Λ to merge filtered content into the knowledge container K. The process recursively expands by following links in filtered content and stops when scores fall below T. Outputs are a structured, query-aligned knowledge container containing extracted relations, sub-variations, and detailed textual summaries.",
            "llm_model_used": "unspecified LLM(s) (paper uses LLM-powered components but does not name the specific model used for WISE's filtering/fusion; GPT-4o was used as a baseline comparator)",
            "scientific_domain": "Biology / Biomedical (demonstrated on gene-disease associations for HBB)",
            "number_of_papers": "initial seed: 24 sources (initially attempted 34 sources, 24 successfully extracted)",
            "type_of_quantitative_law": "associative relationships and structured entity relationships (gene–disease/phenotype associations and frequency/coverage metrics); not mathematical laws",
            "extraction_output_format": "knowledge container: structured lists of entities and associations, textual summaries, citations, and level-based detail scores (not symbolic equations)",
            "validation_method": "comparison against a combined union-of-systems ground set; evaluation with recall, ROUGE/BLEU (uniqueness), and a manual level-based depth analysis (levels 0–5 assigned by human annotators)",
            "performance_metrics": "Recall: 0.842 on HBB disease set; reduced processed text volume by &gt;80% on average (filtering reduction mean 80.14%, example UniProt reduced from 8,249 to 355 words); average level-of-detail: 3.81; reported lower ROUGE/BLEU relative to baselines indicating more unique output (exact ROUGE/BLEU values not provided).",
            "baseline_comparison": "Compared to Pure ChatGPT (GPT-4o) recall 0.474, ChatGPT with Search recall 0.368, Gemini recall 0.105, Google Search recall 0.158; WISE outperformed these baselines on recall, uniqueness (ROUGE/BLEU relative ranks), and level-based depth (WISE 3.81 vs others lower).",
            "challenges_limitations": "Access restrictions (paywalls, bot-detection) prevented extraction from some sources (10/34 failed); dependence on word-overlap metrics can underweight contextual relationships; exact LLM choice unspecified; long-tail or under-documented relations may still be missed; output may be too detailed for non-expert users.",
            "requires_human_in_loop": true,
            "fully_automated": false,
            "uuid": "e4332.0",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "GPT-4o (ChatGPT baselines)",
            "name_full": "GPT-4o (OpenAI GPT-4o used via ChatGPT / OpenAI API)",
            "brief_description": "A large, general-purpose transformer-based LLM used in the paper as baseline systems: Pure ChatGPT (GPT-4o) and ChatGPT augmented with web search.",
            "citation_title": "",
            "mention_or_use": "use",
            "method_name": "GPT-4o (as baseline retrieval/generation agent)",
            "method_description": "Used as (a) Pure ChatGPT relying on pretrained knowledge, and (b) ChatGPT with Search (GPT-4o augmented with web search capabilities) to answer the HBB gene query; these baselines receive the query directly and return synthesized answers without the paper's tree-based filtering/pruning workflow.",
            "llm_model_used": "GPT-4o (model referenced in paper; context window up to 128k tokens)",
            "scientific_domain": "General / Biomedical (used to answer biomedical query)",
            "number_of_papers": null,
            "type_of_quantitative_law": "entity–relation extraction and summarization (gene-disease associations) via generative output, not explicit quantitative laws",
            "extraction_output_format": "textual summaries / lists",
            "validation_method": "Compared outputs to union-of-systems disease set and evaluated recall, ROUGE/BLEU, and level-based depth",
            "performance_metrics": "Pure ChatGPT recall: 0.474; ChatGPT with Search recall: 0.368 (as reported in paper).",
            "baseline_comparison": "These are the baselines; WISE outperformed both on recall and depth metrics.",
            "challenges_limitations": "Limited context window for practical multi-source ranking despite large nominal token windows; answers can be concise but lack depth or up-to-date citations.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.1",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "GIX",
            "name_full": "GIX (LLM-based gene interaction extraction system)",
            "brief_description": "Named in the paper as an example system leveraging large language models to automate gene interaction extraction and shown to outperform earlier methods on benchmarks.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "GIX (LLM-driven gene interaction extraction)",
            "method_description": "Mentioned as an LLM-based system that automates gene interaction extraction from literature (paper does not provide implementation details in the main text).",
            "llm_model_used": null,
            "scientific_domain": "Biomedical / genomics (gene interaction extraction)",
            "number_of_papers": null,
            "type_of_quantitative_law": "biological relations (gene–gene / gene–interaction relationships), pattern extraction",
            "extraction_output_format": "structured relations/interaction records (as described conceptually)",
            "validation_method": "reported to outperform earlier methods on benchmark datasets (per paper's related-work statement) but specifics not provided here",
            "performance_metrics": null,
            "baseline_comparison": "Positioned as outperforming earlier (pre-LLM) methods on benchmarks (no numeric values provided in this paper)",
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.2",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "BioBERT",
            "name_full": "BioBERT",
            "brief_description": "A domain-adapted BERT-based language model pre-trained on large-scale biomedical corpora for tasks like named entity recognition and relation extraction.",
            "citation_title": "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
            "mention_or_use": "mention",
            "method_name": "BioBERT (domain-adapted transformer for biomedical IE)",
            "method_description": "BioBERT is referenced as a domain-adapted pretrained model that yields improved precision for named entity recognition and relation extraction tasks in biomedical text mining; the paper cites it as representative of domain-adapted models used in extracting relations from literature.",
            "llm_model_used": "BERT-base architecture pre-trained on biomedical corpora (BioBERT standard variants; model size not specified in this paper)",
            "scientific_domain": "Biomedical / biomedical NLP",
            "number_of_papers": null,
            "type_of_quantitative_law": "entity recognition and relation extraction (biomedical relations), not explicit mathematical laws",
            "extraction_output_format": "structured entities and relations (NER/RE outputs)",
            "validation_method": "Reported improvements in precision on standard IE tasks in prior work (paper cites BioBERT's known evaluation results but does not reproduce them)",
            "performance_metrics": null,
            "baseline_comparison": "Described as improving over earlier feature-engineered models on NER/RE tasks (no numbers provided here)",
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.3",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Retrieval-Augmented Generation (RAG)",
            "name_full": "Retrieval-Augmented Generation techniques",
            "brief_description": "A family of approaches that combine retrieval from external corpora with LLM generation to ground outputs in retrieved documents and improve factuality and coverage.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Retrieval-Augmented Generation (RAG)",
            "method_description": "Mentioned as prior work that attempts pruning sources and enhancing verification by augmenting LLMs with retrieved documents; the paper contrasts RAG approaches with WISE's hierarchical, query-driven filtering+scoring+stopping framework.",
            "llm_model_used": null,
            "scientific_domain": "General / Information Retrieval + NLP",
            "number_of_papers": null,
            "type_of_quantitative_law": "used to surface evidence-backed assertions and relations from corpora (not necessarily symbolic laws)",
            "extraction_output_format": "retrieved documents plus generated text; structured retrieval results",
            "validation_method": "Typical RAG validation uses held-out queries and factuality metrics (paper does not detail RAG validation here)",
            "performance_metrics": null,
            "baseline_comparison": "RAG is cited as a comparison point; WISE claims to differ by employing hierarchical pruning and adaptive stopping",
            "challenges_limitations": "RAG approaches rarely employ hierarchical, query-driven frameworks with adaptive stopping (per paper); may suffer from redundant or low-value retrieval without pruning strategies.",
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.4",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "HybridRAG",
            "name_full": "HybridRAG: Integrating knowledge graphs and vector retrieval augmented generation",
            "brief_description": "A hybrid approach integrating knowledge graphs with vector-based retrieval-augmented generation to improve information extraction efficiency and structure.",
            "citation_title": "Hybridrag: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction",
            "mention_or_use": "mention",
            "method_name": "HybridRAG (knowledge-graph + vector retrieval + RAG)",
            "method_description": "Cited as an approach that fuses knowledge-graph structure with vector retrieval and RAG to enable more efficient and structured information extraction; paper references it in the context of literature that combines graph reasoning and retrieval.",
            "llm_model_used": null,
            "scientific_domain": "Information extraction / Knowledge representation",
            "number_of_papers": null,
            "type_of_quantitative_law": "structured relations and graph-based representations of knowledge (entity–relation extraction and linking)",
            "extraction_output_format": "knowledge graph nodes/edges combined with retrieved document context",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.5",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "WorkflowLLM",
            "name_full": "WorkflowLLM",
            "brief_description": "An approach to enhance workflow orchestration capabilities of large language models, improving how models perform multi-step, structured tasks.",
            "citation_title": "Workflowllm: Enhancing workflow orchestration capability of large language models",
            "mention_or_use": "mention",
            "method_name": "WorkflowLLM (orchestration enhancements for LLMs)",
            "method_description": "Referenced as prior work in workflow orchestration for LLMs; cited in the paper as related work on orchestrating multi-step processes and pruning/verification strategies, analogous to components of WISE's pipeline.",
            "llm_model_used": null,
            "scientific_domain": "NLP / LLM systems",
            "number_of_papers": null,
            "type_of_quantitative_law": "supports multi-step extraction and decision workflows rather than direct quantitative-law discovery",
            "extraction_output_format": "orchestrated multi-step outputs (structured pipelines)",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.6",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "ByteScience",
            "name_full": "ByteScience",
            "brief_description": "A system described as bridging unstructured scientific literature and structured data using auto fine-tuned LLMs at token granularity.",
            "citation_title": "Bytescience: Bridging unstructured scientific literature and structured data with auto fine-tuned large language model in token granularity",
            "mention_or_use": "mention",
            "method_name": "ByteScience (auto fine-tuned LLM for literature→structured data)",
            "method_description": "Appears in related work as an LLM-based approach that auto-fine-tunes models to convert unstructured scientific text into structured data at fine token granularity, positioned alongside WISE as part of recent advances in automated literature-to-structure systems.",
            "llm_model_used": "auto fine-tuned LLM (specific model not stated in this paper)",
            "scientific_domain": "Scientific literature mining (multi-domain)",
            "number_of_papers": null,
            "type_of_quantitative_law": "structured extraction of entities/relations; aims to produce structured datasets from unstructured literature",
            "extraction_output_format": "structured data tables / token-granular structured outputs",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.7",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Large-Scale Knowledge Synthesis",
            "name_full": "Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents",
            "brief_description": "Work cited that addresses large-scale synthesis of knowledge and complex retrieval from biomedical documents using machine learning techniques.",
            "citation_title": "Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents",
            "mention_or_use": "mention",
            "method_name": "Large-scale knowledge synthesis methods (ML-based)",
            "method_description": "Cited as related research addressing knowledge synthesis and complex retrieval in biomedical domains, informing the paper's context about large-scale automated extraction from biomedical documents (paper does not detail the method here).",
            "llm_model_used": null,
            "scientific_domain": "Biomedical information retrieval",
            "number_of_papers": null,
            "type_of_quantitative_law": "knowledge synthesis of relations and facts (entity/relation extraction and aggregation)",
            "extraction_output_format": "aggregated facts and synthesized documents/knowledge bases",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.8",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Buehler2024",
            "name_full": "Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning",
            "brief_description": "A referenced approach that combines generative knowledge extraction with graph representations and multimodal graph reasoning to accelerate discovery.",
            "citation_title": "Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning",
            "mention_or_use": "mention",
            "method_name": "Generative knowledge extraction + graph-based multimodal reasoning",
            "method_description": "Cited as prior work linking generative extraction methods with graph-based representations and multimodal graph reasoning to derive richer, structured knowledge from scientific sources; the current paper positions knowledge-graph integration as future work inspired by such efforts.",
            "llm_model_used": null,
            "scientific_domain": "Cross-disciplinary (machine learning + scientific discovery)",
            "number_of_papers": null,
            "type_of_quantitative_law": "graph-structured relationships and inferred patterns (multi-modal associations), not specified as symbolic laws",
            "extraction_output_format": "knowledge graphs plus generative summaries",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.9",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "Tree-LSTM / tree architectures",
            "name_full": "Tree-structured neural architectures (e.g., Tree-LSTM for protein-protein interaction identification)",
            "brief_description": "Neural tree-structured architectures have been applied to relation extraction tasks such as protein–protein interaction identification and are cited as prior work in extraction from structured/semistructured text.",
            "citation_title": "Identifying protein-protein interaction using tree lstm and structured attention",
            "mention_or_use": "mention",
            "method_name": "Tree-structured neural architectures (Tree-LSTM + structured attention)",
            "method_description": "Referenced as previous neural architectures that improved relation extraction (protein–protein interactions) by exploiting tree-structured inputs and structured attention mechanisms; cited in related work to situate WISE among hierarchical or tree-inspired methods.",
            "llm_model_used": null,
            "scientific_domain": "Biomedical / NLP (relation extraction)",
            "number_of_papers": null,
            "type_of_quantitative_law": "relation extraction (interaction identification), pattern detection in text structure",
            "extraction_output_format": "structured relation labels/tuples",
            "validation_method": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "challenges_limitations": null,
            "requires_human_in_loop": null,
            "fully_automated": null,
            "uuid": "e4332.10",
            "source_info": {
                "paper_title": "Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large language model based framework for automated extraction of genetic interactions from unstructured data",
            "rating": 2,
            "sanitized_title": "large_language_model_based_framework_for_automated_extraction_of_genetic_interactions_from_unstructured_data"
        },
        {
            "paper_title": "Hybridrag: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction",
            "rating": 2,
            "sanitized_title": "hybridrag_integrating_knowledge_graphs_and_vector_retrieval_augmented_generation_for_efficient_information_extraction"
        },
        {
            "paper_title": "Bytescience: Bridging unstructured scientific literature and structured data with auto fine-tuned large language model in token granularity",
            "rating": 2,
            "sanitized_title": "bytescience_bridging_unstructured_scientific_literature_and_structured_data_with_auto_finetuned_large_language_model_in_token_granularity"
        },
        {
            "paper_title": "Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning",
            "rating": 2,
            "sanitized_title": "accelerating_scientific_discovery_with_generative_knowledge_extraction_graphbased_representation_and_multimodal_intelligent_graph_reasoning"
        },
        {
            "paper_title": "Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents",
            "rating": 2,
            "sanitized_title": "largescale_knowledge_synthesis_and_complex_information_retrieval_from_biomedical_documents"
        },
        {
            "paper_title": "Workflowllm: Enhancing workflow orchestration capability of large language models",
            "rating": 1,
            "sanitized_title": "workflowllm_enhancing_workflow_orchestration_capability_of_large_language_models"
        },
        {
            "paper_title": "Identifying protein-protein interaction using tree lstm and structured attention",
            "rating": 1,
            "sanitized_title": "identifying_proteinprotein_interaction_using_tree_lstm_and_structured_attention"
        },
        {
            "paper_title": "Tree of science -tos: A web-based tool for scientific literature recommendation. search less, research more!",
            "rating": 1,
            "sanitized_title": "tree_of_science_tos_a_webbased_tool_for_scientific_literature_recommendation_search_less_research_more"
        }
    ],
    "cost": 0.013989749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models
21 Jun 2025</p>
<p>Yakin Sajratul 
Member, IEEE, HasanM Rubaiat 
Member, IEEEJamil 
Context-Aware Scientific Knowledge Extraction on Linked Open Data using Large Language Models
21 Jun 2025E04A2330E5A940B2BBA57E3FCBF1C7F0arXiv:2506.17580v1[cs.IR]Knowledge DiscoveryLarge Language ModelsInformation FilteringScientific Data ExtractionKnowledge EnrichmentGene-Disease Associations
The exponential growth of scientific literature presents a significant challenge for researchers seeking to extract and synthesize relevant knowledge.Traditional search engines often return a large number of sources without directly providing detailed answers, while general-purpose Large Language Models (LLMs) may offer concise responses that lack depth or fail to incorporate the most up-to-date information.Furthermore, LLMs with search capabilities are often limited by their context window, resulting in short, incomplete answers.This paper introduces WISE (Workflow for Intelligent Scientific Knowledge Extraction), a novel system that addresses these limitations by combining LLMs with a structured, multi-layered workflow to extract, refine, and rank scientific knowledge tailored to specific queries.WISE employs an LLM-powered, tree-based architecture with a customized search function to iteratively refine extracted data, focusing on query-aligned and contextaware information while actively avoiding redundancy.Dynamic scoring and ranking mechanisms prioritize unique contributions from each source, and adaptive stopping criteria minimize processing overhead.WISE delivers detailed, well-organized, and highly informative answers by systematically exploring and synthesizing knowledge from diverse sources.Experiments focused on biological queries related to HBB gene-associated diseases demonstrate that WISE reduces the volume of processed text by over 80% while simultaneously achieving significantly higher recall compared to baseline methods, including leading search engines and other LLM-based approaches.Further analysis using ROUGE and BLEU metrics reveals that WISE's output is more unique compared to other systems, and a novel levelbased evaluation metric shows that WISE provides more in-depth information.This paper also explores how the WISE workflow can be adapted as a general framework for diverse research domains, such as drug discovery, material science, and social science, enabling efficient knowledge extraction and synthesis from unstructured scientific papers and web sources across a wide array of research domains.</p>
<p>I. INTRODUCTION</p>
<p>T HE relentless expansion of scientific knowledge, reflected in the ever-increasing volume of published literature, presents a formidable challenge for researchers seeking to extract, synthesize, and contextualize relevant information [1], [2].While traditional search engines and general-purpose S. Y. Rubaiat is with the Department of Computer Science, University of Idaho, Moscow, ID, USA (e-mail: ruba3062@vandals.uidaho.edu).</p>
<p>H. M. Jamil is with the Department of Computer Science, University of Idaho, Moscow, ID, USA (e-mail: jamil@uidaho.edu).</p>
<p>Manuscript received January 1, 2025; revised January 1, 2025.</p>
<p>Large Language Models (LLMs) offer some assistance, they often fall short in providing domain-specific insights, filtering irrelevant content, and efficiently managing the sheer volume of data [3]- [5].Traditional search engines typically return a large number of sources, requiring users to manually sift through them to extract relevant information, rather than providing direct, synthesized answers.Navigating this complex information ecosystem manually is both labor-intensive and error-prone, with researchers facing the risk of overlooking critical details as the volume of data grows exponentially.Consider, for example, a researcher investigating genedisease associations related to the HBB gene.Starting from a single authoritative source like the HGNC [6], they might encounter 24 relevant sources.Exploring just one of these, such as ClinVar [7], could unveil hundreds more sources, leading to a rapidly expanding tree of interconnected resources, exemplified by platforms like NCBI [8].This exponential growth of linked resources quickly overwhelms traditional search systems, making it difficult to extract pertinent insights efficiently.Even experienced investigators struggle to filter out superfluous data and focus on the most valuable information, a challenge amplified for newcomers.Consequently, critical information may be missed, and the time required to gain a complete, integrated understanding escalates dramatically.</p>
<p>Purely automated approaches also encounter significant difficulties in this context [9]- [11].The sheer volume of interconnected data can lead to computationally expensive and strategically ineffective processes without robust mechanisms for pruning irrelevant or redundant content.A key challenge lies in determining when to stop searching; continued exploration without clear stopping criteria often yields diminishing returns, underscoring the need for a balanced workflow that ensures thorough yet efficient exploration while prioritizing high-value information [12], [13].</p>
<p>While Large Language Models (LLMs) show promise in specific aspects of information retrieval [14], their inherent limitations hinder their ability to fully address the scale of these challenges.General-purpose LLMs, often provide concise answers that lack the depth and detail required for complex scientific queries, and may not incorporate the most recent findings.For instance, state-of-the-art models like GPT-4o [15], despite having a context window of 128000 tokens, are practically limited to processing data from only about eight sources simultaneously, such as UniProt [16], as illustrated in Figure 1.Although capable of ranking and comparing content within this limited scope, LLMs are constrained by their narrow context window, further reduced by factors like search history.In specialized domains such as biology and medicine, where nuanced and detailed insights are crucial, relying solely on LLM-based searches proves insufficient.These challenges highlight the critical need for combining the capabilities of LLMs with strategic workflows to achieve comprehensive and efficient knowledge retrieval.</p>
<p>To address these challenges, we introduce WISE (Workflow for Intelligent Scientific Extraction), a novel, scalable, treebased framework that integrates LLM-driven filtering, dynamic ranking, and adaptive stopping criteria.WISE is designed to deliver detailed, well-organized, and highly informative answers by systematically exploring and synthesizing knowledge from diverse sources.WISE mirrors the approach of a diligent researcher: identifying relevant information, discarding duplicates, exploring promising leads, and recognizing when further pursuit yields diminishing returns.WISE begins by employing LLMs to filter large text corpora based on a user's domain-specific query, ensuring that only contextually relevant and manageable segments proceed to subsequent stages.It then assigns scores to extracted sources, quantifying their unique contributions relative to previously processed material, thereby minimizing redundancy and focusing on content that adds genuine value.This dynamic ranking process prioritizes high-value information while pruning low-impact paths.The iterative refinement continues layer by layer, with WISE's knowledge container-the growing repository of extracted, query-specific insights-expanding until incremental findings diminish (Figure 4).At this point, WISE intelligently halts further searches, conserving computational resources while delivering comprehensive, contextually nuanced results.In essence, WISE achieves a balance between breadth and depth, effectively leveraging the strengths of LLMs while mitigating their limitations through intelligent pruning and carefully considered stopping criteria.</p>
<p>Our key contributions are summarized as follows:</p>
<p>1) Scalable, Tree-Based Architecture: We introduce a novel, tree-structured workflow (Section II) that efficiently navigates large, heterogeneous datasets.This architecture leverages LLM-based filtering at each layer to incrementally refine data subsets according to domainspecific queries, ensuring scalability and focus.</p>
<p>Number of Source Processed</p>
<p>Characters Words Tokens</p>
<p>Fig. 1.Number of sources, such as UniProt [16], that can be processed simultaneously for ranking by advanced LLMs like GPT-4o demonstrate significant improvements when applying LLM-based filtering with and without query-specific relevance.Given that GPT-4o supports a 128,000-token context window, the number of websites that can be processed is calculated as: Number of websites = 128,000 / Tokens per Website By dynamically ranking sources based on their added value and employing intelligent pruning, WISE focuses computational resources on the most promising leads, effectively filtering out redundant or low-value content.3) Adaptive, Expert-Inspired Exploration: Our approach (Sections II and III) mirrors expert-driven inquiry by progressively deepening the search along promising paths while adaptively halting exploration when further gains are minimal.This ensures a balanced blend of breadth and depth, optimizing both the efficiency and effectiveness of the knowledge discovery process.</p>
<p>4) Demonstrated Effectiveness in Gene-Disease Association Discovery: Through empirical evaluation on genedisease association queries (Section IV), we demonstrate that WISE significantly outperforms baseline methods, including traditional search engines and general-purpose LLMs, in terms of recall, uniqueness of extracted information (ROUGE/BLEU), and depth of knowledge (levelbased analysis).5) Versatile Applications: We showcase WISE's adaptability and potential impact through diverse applications (Section V), including drug discovery, material science, and social science, highlighting its ability to generalize across a wide range of research domains.</p>
<p>II. SYSTEM DESIGN</p>
<p>The WISE framework is designed to streamline the extraction and synthesis of knowledge from unstructured data sources through a structured and multi-layered approach.As illustrated in Figure 2, its architecture comprises four key stages that work in tandem to filter, score, rank, and consolidate information.Each stage contributes to transforming raw data into context-aware insights, enabling efficient knowledge discovery and refinement.</p>
<p>1) Content Filtering: This stage employs query-specific extraction via LLM-driven contextual analysis, ensuring that only information relevant to the query is retained while noise, such as advertisements, is removed.This significantly reduces computational overhead in subsequent stages.2) Score Calculation: In this stage, the filtered content is evaluated for its unique contribution to the evolving knowledge container.Novel and relevant insights are prioritized, while redundant material is discarded.3) Threshold Checking: This component determines whether continued exploration of sources is justified.It acts as a termination criterion for the recursive process, halting when additional contributions fall below a defined threshold.4) Knowledge Consolidation: Extracted information is incrementally merged into a growing repository of domainspecific knowledge.This ensures that the final knowledge container is comprehensive, context-aware, and aligned with the user's query.WISE initiates its process with a user-provided query q and an empty knowledge container K 0 .This container evolves iteratively as new insights are integrated.The initial set of sources S 0 = {s 1 , s 2 , . . ., s n } is retrieved using a traditional similarity-based search function Φ(q), which identifies a collection of candidate sources relevant to the query.These sources serve as the root nodes for the tree-based search process.Formally:
K 0 = ∅, S 0 = Φ(q) A. Content Filtering
Each source s i belonging to the set S l at layer l undergoes a query-specific refinement process.This process extracts content directly relevant to the query q.The filtering function Γ, which leverages the contextual understanding capabilities of an LLM, transforms the raw content C(s i ) of a source s i into a focused subset F(s i ):
F(s i ) = Γ(q, C(s i ))
By isolating only the most pertinent information, F(s i ) significantly reduces noise and irrelevant data.This streamlining enhances the efficiency of subsequent computational tasks and downstream processing stages.For simplicity, the result of the filtering operation for all sources at layer l is denoted as:
F l = {F(s 1 ), F(s 2 ), . . . , F(s n )} l
Here, F l represents the set of all query-specific filtered content derived at layer l from the sources in S l .</p>
<p>B. Score Calculation</p>
<p>Following the filtering stage, WISE quantifies the unique contribution of each source to the knowledge container.Let w filtered (s i ) denote the number of words in the filtered content of each source s i :
w filtered (s i ) = |F(s i )|
where |F(s i )| represents the cardinality (number of elements) of the set F(s i ).</p>
<p>Next, we determine the number of words that overlap between the source's filtered content F(s i ) and the current knowledge container K l .Let w overlap (s i , K l ) denote this count:
w overlap (s i , K l ) = |F(s i ) ∩ K l |
Here, |F(s i ) ∩ K l | represents the cardinality of the intersection of the two sets.</p>
<p>The unique knowledge contribution K(s i ) of source s i is then defined as the difference between the number of words in the filtered content and the number of overlapping words:
K(s i ) = w filtered (s i ) − w overlap (s i , K l )
This value, K(s i ), represents the number of new, unique words that source s i contributes to the knowledge container.</p>
<p>To normalize and evaluate the contribution of each source, we define the following metrics:</p>
<ol>
<li>
<p>Knowledge Density (Per-Word Normalization): This metric normalizes the unique knowledge contribution by the size of the source (measured in the number of words in the filtered content).It is calculated as:
Knowledge Density(s i ) = K(s i ) w filtered (s i )
This ratio represents the proportion of unique words in the filtered content of source s i .</p>
</li>
<li>
<p>Knowledge Increase (Relative Growth): This metric measures the relative contribution of the source to the existing knowledge container, expressed as a proportion of the current size of the knowledge container:
Knowledge Increase(s i ) = K(s i ) |K l |
Here, |K l | denotes the cardinality of the knowledge container K l , representing the total number of words in the knowledge container at layer l.</p>
</li>
</ol>
<p>To integrate the concepts of local efficiency (size of the source) and global contribution (size of the knowledge container), we define a unified scoring function Ψ that employs log scaling to balance these factors:</p>
<ol>
<li>Combined Normalized Metric:
Score(s i ) = Ψ(F(s i ), K l ) = K(s i ) log(1 + w filtered (s i ) + |K l |)
This combined metric prioritizes sources that offer unique and meaningful contributions, accounting for both the relative size of the source (in terms of the number of words in its filtered content) and its impact on the evolving knowledge container (in terms of the number of unique words it contributes).</li>
</ol>
<p>C. Threshold Checking and Pruning</p>
<p>WISE evaluates whether continued exploration will yield meaningful insights by comparing the highest score among the current sources, max si∈S l Score(s i ), to a predefined threshold T .If no source surpasses this threshold, the recursive process terminates:
max si∈S l Score(s i ) &lt; T =⇒ Terminate
If at least one source meets or exceeds the threshold, WISE selects the top k sources based on their scores for further exploration:
S l+1 = Top k (S l , Score)
This pruning step ensures that computational efforts are focused on sources most likely to enrich the knowledge container.</p>
<p>D. Knowledge Container Construction</p>
<p>The knowledge container K l is updated by incorporating the filtered content of the chosen sources.This process further enhances the repository of query-relevant information.The update rule is defined as:
K l+1 = Λ(K l , S l+1 ) = K l ∪ si∈S l+1 F(s i )
Here, Λ represents an LLM-powered fusion function designed to merge new information from the selected sources S l+1 with the existing knowledge base K l .Upon termination of the recursive process, the final knowledge base K f represents the aggregated and refined knowledge for the query q:
K f = K l at termination E. Recursive Algorithm: WISE Framework
Algorithm 1 outlines the recursive process for constructing a query-specific knowledge base.The subsequent layer's sources, S l+1 , are obtained by analyzing the links embedded in the filtered content of the top k sources from the current layer, Top k (S l , Score).This ensures that the exploration focuses on paths that are both contextually relevant and computationally efficient.</p>
<p>III. EXPERIMENT</p>
<p>The experimental setup and methodology used to evaluate WISE's ability to extract and synthesize knowledge from unstructured scientific data are detailed here.Our experiments focused on the query:</p>
<p>Q: What is the comprehensive set of diseases and phenotypes that are linked to genetic variants within the HBB gene?This query, centered on the HBB gene, provided a rigorous test case for WISE's capabilities due to the domain's complexity and the interconnected nature of the information.</p>
<p>A. Experimental Setup</p>
<p>The experiment started with an initial set of 24 sources related to the HBB gene, obtained from the HGNC database [6].Each source was meticulously classified into sections using structural elements, tags, and hyperlinks, extracted through a regular expression-based process.This resulted in a dataset enriched with metadata, including section identifiers and reference sources.We performed asynchronous content extraction from these sources, which served as the foundational nodes for WISE's progressive deepening process [17].</p>
<p>B. Query-Specific Content Filtering</p>
<p>WISE begins by employing the LLM-driven content filtering process detailed in Section II-A to refine the raw content of each source based on its relevance to the user-specified query.For this experiment, focused on the query Q, the filtering function Γ takes advantage of contextual understanding of the LLM to isolate pertinent information, eliminating extraneous Algorithm 1: Recursive WISE Framework Input : Query q, Initial sources S 0 , Knowledge Container K 0 , Threshold T Output: Final knowledge base K f 1 Function WISE(S l , K l , l):
2 if S l = ∅ or max si∈S l Score(s i ) &lt; T then 3 return K l ;
// Terminate recursion if no significant sources remain or the set of sources is empty 4 foreach s i ∈ S l do 5 F(s i ) ← Γ(q, C(s i )) ; // Filter content for query q using filtering function return WISE(S l+1 , K l+1 , l + 1) ; // Recursive call to the next layer 10 return K f ← WISE(S 0 , K 0 , 0) ; // Initialize recursion with initial sources, empty knowledge container, and layer 0 content such as advertisements, unrelated sections, and general background information that does not directly address the specifics of the query.Figure 3 illustrates the significant impact of content filtering on data volume for selected sources, demonstrating the substantial reduction in content size achieved through this process.Notably, the UniProt [16] entry for the HBB gene, initially containing 8,249 words, was reduced to just 355 words after applying query-specific filtering.This exemplifies the prevalence of extraneous information even within highly regarded scientific resources.Across all sources, filtering reduced content size by an average of 80.14%, with reductions as high as 96.12% observed in some cases.This dramatic reduction highlights the effectiveness of LLM-driven filtering in isolating relevant content, thereby significantly reducing computational overhead and improving the efficiency and precision of downstream processing stages.By focusing on query-relevant information, WISE ensures that subsequent steps, such as score calculation and knowledge integration, operate on a refined and highly pertinent dataset.
Γ 6 Score(s i ) ← Ψ(F(s i ), K l ) ; //</p>
<p>C. Score Calculation and Ranking</p>
<p>To validate the effectiveness of our scoring mechanism in prioritizing query-specific relevance, we conducted experi-ments focusing on the query Q.As detailed in Section II-B, WISE employs a dynamic, content-driven scoring approach that contrasts sharply with traditional ranking methods used by systems like Google and ChatGPT, which often rely on factors like source popularity or SEO (Search engine optimization) [18] optimization.</p>
<p>Our scoring mechanism calculates a combined normalized score for each source, integrating both local efficiency (source size) and global contribution (impact on the knowledge container).This ensures that sources offering substantive, queryspecific insights are prioritized, regardless of their general popularity.Initial experiments, illustrated in Figure 3, demonstrate that widely recognized sources, such as UniProt [16] or AlphaFold [19], did not always rank highest due to the presence of content unrelated to the specific query.This finding validates our design choice to prioritize content relevance over superficial attributes.</p>
<p>Content Density and Scores</p>
<p>Original Content Filtered Content Score Fig. 3. WISE filtering and scoring in selected 4 sources, showing content density before and after filtering along with their scores.It demonstrates that content size alone does not determine a high score; the unique contribution must be significant relative to the existing knowledge base.</p>
<p>D. Thresholding and Knowledge Container Construction</p>
<p>WISE employs a threshold-based pruning mechanism, as detailed in Section II-C, to ensure efficient exploration of the knowledge space.This mechanism dynamically determines when to terminate the search process based on the diminishing returns observed in source scores.As the system progresses through successive layers, the knowledge container (described in Section II-D) grows, leading to increased overlap between newly encountered sources and the existing knowledge.Consequently, the unique contribution of each new source tends to decrease.</p>
<p>In this experiment, a threshold value of 20 was empirically determined to effectively balance exploration and exploitation.When the highest score among the current sources falls below this threshold, or when no additional sources are available, WISE terminates the exploration process.This adaptive stopping criterion, mirroring the behavior of expert researchers, prevents the system from pursuing low-yield paths and conserves computational resources.</p>
<p>Figure 4 illustrates this phenomenon, showing a consistent decrease in the scores of top-ranked sources across three successive layers.This trend validates the effectiveness of the threshold-based pruning strategy in identifying the point of diminishing returns.The knowledge container, constructed by integrating the filtered content from the top two sources at each layer, evolves into a rich and contextually relevant repository of information, progressively refined with each iteration.This iterative process ensures that the final knowledge container is both comprehensive and focused, containing the most valuable insights related to the query.Fig. 4. Scores for Ranks 1, 2, and 3 across layers, highlighting their gradual decrease over time.This also demonstrates the growth of the knowledge container size with each layer, eventually plateauing as layers increase.</p>
<p>IV. RESULTS</p>
<p>A comprehensive analysis of WISE's performance, contrasting it with established methods across several critical dimensions, is presented here.Our evaluation, based on the experiments detailed in Section III, focused on the query Q, designed to probe both the breadth and depth of knowledge extraction.To provide a robust and nuanced evaluation, we compared WISE against four baseline systems, each representing a different approach to information retrieval and synthesis: Pure ChatGPT [15], [20] (a standard model, version GPT-4o accessed via the OpenAI API, relying solely on its pretrained knowledge), ChatGPT with Search [21], [22] (a version of ChatGPT, version GPT-4o augmented with web search capabilities), Gemini [23] (Google's large language model, designed to integrate information from various sources), and traditional Google Search [24], [25] (the standard Google Search engine, considering the top 5 search results for analysis).For all baseline systems, default parameters were used, and the query Q was directly input without any modifications.</p>
<p>A. Evaluation Metrics</p>
<p>Our analysis employs a combination of quantitative metrics, focusing on the relevance, uniqueness, and depth of the extracted information.</p>
<p>1) ROUGE and BLEU</p>
<p>To assess the overlap and uniqueness of the information extracted by each system, we employed ROUGE [26] (Recall-Oriented Understudy for Gisting Evaluation) and BLEU [27] (Bilingual Evaluation Understudy) metrics, commonly used for evaluating machine-generated text.We adapted these metrics, calculating ROUGE-1, ROUGE-2, and ROUGE-L, along with BLEU, to compare each system's output against the others.Figure 5 presents the average ROUGE and BLEU scores for each system when used as a reference, revealing that WISE consistently exhibits the lowest scores, indicating that its generated content is more distinct and less repetitive compared to other approaches.</p>
<p>2) Recall</p>
<p>To evaluate the comprehensiveness of each system, we calculated their recall based on a combined output created by taking the union of all unique diseases identified by any of the five systems.This combined output, representing a comprehensive collection of potentially relevant diseases, is detailed in Table II.WISE achieved a recall of 0.842, significantly outperforming the baseline systems, as shown in Figure 6.In contrast, ChatGPT achieved a recall of 0.474, ChatGPT with Search achieved a recall of 0.368, while Google Search Gemini and traditional Google Search scored considerably lower at 0.105 and 0.158 respectively.This emphasizes WISE's superior ability to identify a greater proportion of potentially relevant diseases.</p>
<p>Google Search</p>
<p>Gemini ChatGPT with Search WISE ChatGPT Fig. 6.Recall scores of each system, demonstrating that WISE identifies a greater proportion of diseases from the combined output.</p>
<p>3) Level-Based Analysis</p>
<p>To further analyze the depth of information provided by each system, and to establish a metric that can generally be used to assess the richness of content, we employed a levelbased analysis.In this approach, each identified disease was manually assigned a level from 0 to 5 based on the following criteria:</p>
<p>• Level 0: Disease name only.</p>
<p>• Level 1: Basic description of the disease.</p>
<p>• Level 2: Information about the cause of the disease.</p>
<p>• Level 3: Details about the disease's mechanism.</p>
<p>TABLE II DISEASE IDENTIFICATION ACROSS SYSTEMS</p>
<p>Disease</p>
<p>Normal Google Search Google Search Gemini ChatGPT with Search ChatGPT WISE
Hemoglobin SC ✗ ✗ ✓ ✓ ✓ Hemoglobin O ✗ ✗ ✗ ✓ ✗ Hemoglobin S/β-Thalassemia ✗ ✗ ✓ ✓ ✓ Hemoglobin S Oman ✗ ✗ ✗ ✗ ✓ Malaria ✗ ✗ ✗ ✗ ✓ Sickle Cell Disease ✓ ✓ ✓ ✓ ✓ Hispanic Gamma-Delta-β Thalassemia ✗ ✗ ✗ ✗ ✓ β-Type Methemoglobinemia ✗ ✗ ✗ ✗ ✓ Dominant β-Thalassemia ✗ ✗ ✗ ✗ ✓ Hemoglobinopathies ✓ ✗ ✗ ✗ ✗ Heinz Body Anemia ✗ ✗ ✗ ✗ ✓ Hemoglobin C ✗ ✗ ✓ ✓ ✓ Hemoglobin M ✗ ✗ ✗ ✗ ✓ Hemoglobin D ✗ ✗ ✗ ✓ ✗ Familial Erythrocytosis 6 ✗ ✗ ✗ ✗ ✓ Hemoglobin S Antilles ✗ ✗ ✗ ✗ ✓ Hemoglobin E ✗ ✗ ✓ ✓ ✓ Hereditary Persistence of Fetal Hemoglobin ✗ ✗ ✓ ✓ ✓ β-Thalassemia ✓ ✓ ✓ ✓ ✓
method for assessing the richness of information provided by any system.Figure 7 presents the average level of detail for each system, showing that WISE achieved the highest score (3.81), significantly surpassing the other systems.This result demonstrates that WISE provides more in-depth and comprehensive information about the identified diseases compared to the baselines.The convergence of these metrics paints a compelling picture of WISE's strengths.It is not only capable of identifying a wider range of diseases and phenotypes linked to the HBB gene (demonstrated by its high recall) but also of providing richer, more unique, and contextually relevant information (shown through the ROUGE, BLEU, and level-based analyses).The superior performance of WISE across all these metrics highlights its potential as a transformative system for information retrieval in complex domains.</p>
<p>These findings can be attributed to WISE's unique design, particularly its dynamic scoring mechanism, tree-based ar-chitecture, and LLM-powered content filtering.The dynamic scoring prioritizes content relevance over superficial attributes, ensuring that the most valuable sources are identified.The tree-based architecture allows for efficient exploration of the knowledge space, while the LLM-driven filtering ensures that only pertinent information is processed.</p>
<p>V. APPLICATIONS</p>
<p>The adaptability of WISE extends far beyond the specific use case we have explored thus far, underscoring its potential to transform knowledge synthesis across diverse domains.In this section, we illustrate WISE's versatility by exploring its prospective applications, demonstrating how its unique capabilities can address existing challenges and accelerate progress in various fields.</p>
<p>ChatGPT with search Gemini Google Search</p>
<p>ChatGPT WISE Fig. 7. Average level of detail for each system, demonstrating WISE's superior ability to provide in-depth and comprehensive information about identified diseases.</p>
<p>A. Drug Discovery: Unveiling Novel Therapeutic Pathways</p>
<p>The process of drug discovery often hinges on unraveling the intricate relationships between genes, diseases, and potential therapeutic targets.WISE offers a transformative approach to this challenge by providing an efficient and comprehensive means of identifying these complex associations, surpassing the limitations of manual methods and existing systems.Consider the following query: Q: What diseases are associated with C16orf82, and are there any existing drugs targeting these conditions?</p>
<p>This query, while seemingly simple, requires navigating a complex web of genetic and pharmacological information.WISE can reveal novel connections within the existing literature, identifying not only diseases sharing genetic origins or structural similarities in proteins (including overlapping reading frames, ORFs) but also highlighting previously unlinked diseases that may share common pathways or molecular interactions.These insights provide valuable leads for drug repurposing and the development of novel therapeutic strategies, effectively accelerating the drug discovery process by integrating these discoveries with relevant drug information, thus delivering precise and actionable intelligence for pharmaceutical development.</p>
<p>B. Material Structure Analysis: Accelerating Inverse Design</p>
<p>The field of materials science, particularly the domain of inverse material design, is often constrained by time-intensive and inefficient processes for identifying suitable material structures that meet specific requirements.WISE offers a streamlined approach to this challenge.For instance, consider this query: Q: What are the most suitable material structures for achieving high thermal conductivity and mechanical strength in lightweight applications?By directly linking structural properties to specific application requirements, WISE enables researchers to explore material structure databases with unprecedented speed and efficiency.This reduces the manual effort and time required for material selection, allowing researchers to focus on designing solutions that precisely meet their objectives, rather than spending excessive time on information gathering.By reducing reliance on inefficient, time-intensive methods, WISE serves as a powerful tool to accelerate the field of materials science.</p>
<p>C. Social Issue Analysis: Illuminating Complex Societal Challenges</p>
<p>WISE is equally applicable to addressing complex social issues, where the analysis of vast amounts of unstructured data is critical.Social scientists and policymakers grapple with a range of complex challenges, requiring the integration of data from diverse sources to identify patterns and develop effective interventions.For example:</p>
<p>Q: What factors are contributing to the rising cancer rates in [specific location]?This query, designed to highlight the social, environmental, and economic challenges that drive increases in rates of cancer, demands the integration of multiple viewpoints, datasets, and research findings.WISE can synthesize information from diverse sources to identify complex patterns, including increased exposure to environmental toxins, socio-economic inequalities, or shortcomings in public health policy.By highlighting key contributing factors, WISE offers researchers and policymakers critical data points and insight that empowers them to develop data-driven hypotheses and implement more targeted interventions.The ability of WISE to generate comparative examples from similar regions further allows for a deeper, more nuanced understanding of the issue at hand.</p>
<p>The examples above underscore WISE's flexibility and adaptability, demonstrating its applicability beyond specific domains.Its ability to process complex queries and synthesize domain-specific knowledge makes it a valuable asset across a broad range of fields, from medical research to materials science and social issue analysis.Over time, WISE's workflow has the potential to further accelerate progress in areas like cancer research, environmental studies, and many others, by providing a more efficient and reliable approach to obtaining detailed and context-aware information.These diverse applications highlight WISE's potential to enable deeper insights and foster innovation across a wide spectrum of scientific and societal disciplines.</p>
<p>VI. FUTURE WORK</p>
<p>While WISE has demonstrated significant capabilities in our experiments, its journey is far from complete.We are actively exploring several promising avenues for further development, poised to enhance the system's robustness, efficiency, and applicability.The following represent key directions for future research, although these improvements are not yet incorporated into the current implementation and remain outside the scope of this paper.</p>
<p>A. Knowledge Graph Integration: Unlocking Deeper Relational Insights</p>
<p>The integration of knowledge graphs represents a transformative opportunity to amplify WISE's ability to reason about complex relationships within scientific data.Knowledge graphs, which represent information as interconnected nodes and edges, offer a structured approach for preserving and reasoning about intricate interdependencies.Such an approach transcends the limitations of purely text-based analysis, enabling WISE to identify connections between seemingly disparate entities and uncover subtle yet significant articulation points that are often missed by traditional methods.</p>
<p>By incorporating knowledge graphs, WISE can maintain a dynamic understanding of the relationships between entities, thereby eliminating the need for repeated, LLM-driven knowledge unions.Instead, newly extracted information can be directly appended to the appropriate nodes and edges in the graph, ensuring continuity, efficiency, and preventing information loss.Preliminary experiments, for example, have demonstrated that representing the UniProt entry for the HBB gene as a knowledge graph with 56 nodes and 55 edges effectively captures its content with reduced complexity compared to raw text.Further filtering this knowledge graph with a query related to HBB-specific diseases resulted in a focused subgraph with 11 nodes and 16 edges, while maintaining key interconnected causes, like shared hormonal pathways across multiple diseases.</p>
<p>Furthermore, knowledge graphs facilitate intuitive visualizations, enhancing user understanding and interpretation.Their structured nature supports advanced reasoning capabilities, enabling WISE to achieve deeper insights through graphbased matching techniques, outperforming traditional content comparison approaches.This integration promises a more powerful and efficient means of knowledge discovery.</p>
<p>B. Enhanced Query Engagement: Steering Towards Precise Intent</p>
<p>WISE currently relies on user-provided queries, future iterations will focus on enhancing query engagement to steer the system towards a more precise understanding of user intent.Although our similarity-based searches have proven effective so far, there is a clear potential to amplify WISE's performance through a more iterative and user-involved query process.Future iterations of WISE will incorporate mechanisms for better understanding user intent through supplementary information gathering.For example, users could be prompted to provide additional context or goals for their search, enabling more precise and targeted results.Moreover, the system could implement automatic query enhancement, leveraging prior searches and literature data to refine user input iteratively.This process may also include layers of semantic understanding, improved similarity measures, and propose augmented queries for user approval.These advancements would significantly reduce the burden on lessexperienced users, simplifying complex search tasks while maintaining the high standards of precision that WISE offers.These improvements could also help the system identify if the query is underdefined or if there is some implicit constraints in the query.</p>
<p>VII. RELATED WORK</p>
<p>Prior research in information extraction has significantly advanced from manual curation and feature-engineered machine learning models to more sophisticated LLM-based approaches.Systems such as GIX [28] effectively leverage large language models to automate gene interaction extraction, outperforming earlier methods on benchmark datasets.Similarly, treestructured neural architectures have improved the identification of protein-protein interactions [29], and comprehensive reviews highlight the rise of neural network-based classifiers in biomedical relation extraction [30].Domain-adapted models, such as BioBERT [31], have demonstrated notable gains in precision for tasks including named entity recognition and relation extraction, while further explorations have extended the scope from binary to complex biomedical relations [32].Beyond the biomedical domain, research has shown that integrating pre-trained models with domain-specific corpora and graph-based reasoning can uncover intricate patterns, enabling richer insights and improved retrieval accuracy [33]- [36].</p>
<p>Despite these advancements, existing approaches often struggle to dynamically refine their focus or determine when further exploration yields diminishing returns.Retrieval-Augmented Generation techniques [37] and workflow orchestration strategies [38] have attempted to address these challenges by pruning sources and enhancing verification, yet they rarely employ hierarchical, query-driven frameworks that integrate filtering, scoring, and adaptive stopping criteria.Other efforts have focused on bridging the gap between unstructured and structured data [39], [40] but have not fully embraced iterative, tree-based methodologies for source selection and knowledge consolidation.In this context, WISE advances the state of the art by combining robust filtering, dynamic ranking, and a scalable tree-inspired workflow, thereby ensuring that only the most valuable, context-relevant information is retained for efficient, high-quality knowledge extraction.</p>
<p>VIII. DISCUSSION</p>
<p>The development and application of WISE highlight its transformative potential in synthesizing knowledge for complex queries, yet certain challenges and limitations merit discussion.One of the primary obstacles encountered during the experiments was restricted access to some data sources.Out of 34 initial sources, WISE successfully extracted content from 24, while the remaining 10 sources were inaccessible.Figure 8 illustrates this disparity, emphasizing the growing trend among web platforms to limit data extraction.This failure to extract content stemmed primarily from two key factors: the increasing prevalence of paywalls, which create direct economic barriers to access, and security measures like bot detection, which are often deployed to protect intellectual property, user privacy, and prevent the unauthorized use of data for LLM training and content analysis.While these restrictions serve important purposes, such as protecting content creators and user data, they also hinder innovations like WISE, which focus on advancing non-commercial, academic, and research applications.Overcoming these challenges may require collaboration with data providers, the development of ethical and compliant retrieval techniques.Another important consideration is the comprehensiveness of WISE's outputs.By design, WISE delivers detailed, authoritative responses that include exhaustive references, disease sub-variations, and contextual information.While this level of detail is highly valuable for academic and clinical professionals, it may overwhelm non-specialist users who require more concise and simplified information.The extensive details and length of the responses may be daunting, highlighting the need for customizable output formats tailored to different audiences.</p>
<p>Features such as adjustable levels of detail or user-specific summaries could enhance WISE's accessibility and usability across a broader range of users.</p>
<p>A related challenge lies in word weighting during the synthesis of information.In WISE's current implementation, more frequent words like "and" or "the" are deprioritized based on term frequency (TF), ensuring that the system focuses on content-specific terms.However, the exact contextual relationships between terms-critical for disambiguating similar entities-could benefit from improvements.Techniques like TF-IDF (Term Frequency-Inverse Document Frequency) are currently in consideration, as they would assign higher weight to less frequent but more meaningful terms.Additionally, as discussed in Section VI, the integration of a knowledge graph offers a promising solution to this challenge.By representing relationships explicitly through nodes and edges, a knowledge graph would inherently prioritize meaningful connections, eliminating reliance on textual frequency metrics.</p>
<p>Despite these challenges, WISE represents a significant advancement in information retrieval and synthesis, setting a new standard for addressing complex queries.Its ability to dynamically filter, rank, and construct comprehensive knowledge containers demonstrates its transformative potential across diverse domains.The innovative architecture of WISE effectively bridges critical gaps in existing systems, offering a robust tool for academic, clinical, and interdisciplinary applications.</p>
<p>IX. CONCLUSION</p>
<p>WISE presents a novel and effective approach to navigating the complexities of scientific information retrieval.By integrating LLM-driven filtering, dynamic ranking, and adaptive stopping criteria within a tree-based framework, WISE empowers researchers to efficiently and accurately extract and synthesize knowledge from vast and heterogeneous data sources.Our experiments on gene-disease association queries demonstrated WISE's superior performance compared to baseline methods, showcasing its ability to uncover a broader range of relevant information, including rare conditions and nuanced connections often overlooked by traditional search engines and basic LLM implementations.This enhanced precision and comprehensiveness, achieved through a content-driven, progressive deepening approach, offers significant potential for accelerating scientific discovery across diverse domains.</p>
<p>The development of WISE represents a substantial step forward in the pursuit of intelligent knowledge discovery.Its human-inspired methodology, mimicking the systematic approach of expert researchers, allows for a balanced exploration of information, prioritizing high-value insights while effectively managing computational resources.The framework's adaptability and scalability, demonstrated through its application to diverse research domains, further suggest its potential as a generalizable solution for complex information landscapes.We believe that WISE offers a valuable tool for researchers seeking to unlock the full potential of the everexpanding universe of scientific knowledge, paving the way for more efficient and impactful research endeavors.By address-ing the limitations of traditional search engines and generalpurpose LLMs, WISE provides a robust and scalable solution for extracting and synthesizing knowledge, ultimately contributing to more informed and accelerated scientific progress.</p>
<p>Fig. 8 .
8
Fig. 8.The number of sources that restrict data extraction by implementing blocks on automated processes.</p>
<p>Average Level of Detail: Represents the average depth of information provided across all diseases identified by the system, based on a 0-5 scale where higher values indicate more detailed information (see Section III for level criteria).
TABLE ISYSTEM COMPARISONFeatureWISE ChatGPT ChatGPT with Search Gemini Google SearchNumber of Diseases Identified169723Recall0.840.470.360.100.15Average Level of Detail a3.83.333.422.53.0Structured Output✓✓✓✓✗Inclusion of Sub-variations✓✗✓✗✗Source Citation✓✗✓✗✓Identification of Rare Conditions✓✗✗✗✗aUp-to-Date Information✓✗✓✗✓
ACKNOWLEDGMENT This Research was supported in part by a National Institutes of Health IDeA grant P20GM103408, a National Science Foundation CSSI grant OAC 2410668, and a US Department of Energy grant DE-0011014.
Challenges and best practices for digital unstructured data enrichment in health research: A systematic narrative review. J Sedlakova, P Daniore, A Horn, M Wintsch, M Wolf, C Stanikic, C Haag, G Sieber, K Schneider, D Staub, O Alois Ettlin, F Grübner, V Rinaldi, Wyl, 10.1371/journal.pdig.0000347PLOS Digital Health. 21010 2023University of Zurich Digital Society Initiative (UZH-DSI) Health Community</p>
<p>Big data application in biomedical research and health care: A literature review. J Luo, M Wu, D Gopukumar, Y Zhao, 10.4137/BII.S31559pMID: 26843812Biomedical Informatics Insights. BII.S3155982016</p>
<p>Large language models and future of information retrieval: Opportunities and challenges. C Zhai, Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval2024</p>
<p>Towards a search engine for machines: Unified ranking for multiple retrieval-augmented large language models. A Salemi, H Zamani, 10.1145/3626772.3657733Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR '24. the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval, ser. SIGIR '24New York, NY, USAAssociation for Computing Machinery2024</p>
<p>Large language models are built-in autoregressive search engines. N Ziems, W Yu, Z Zhang, M Jiang, arXiv:2305.096122023arXiv preprint</p>
<p>. HBB Gene -Gene Symbol Report. 48272024HUGO Gene Nomenclature Committee (HGNC)</p>
<p>HBB Gene -Clinical Genome Knowledge Base. Clinical Genome Resource (ClinGen). 2024</p>
<p>Sickle Cell Anemia -NCBI Bookshelf. 2024National Center for Biotechnology Information (NCBI)</p>
<p>A review on scientific knowledge extraction using large language models in biomedical sciences. G L Garcia, J R R Manesco, P H Paiola, L Miranda, M P De Salvo, J P Papa, 2024</p>
<p>Harnessing the power of chatgpt for automating systematic review process: Methodology, case study, limitations, and future directions. A Alshami, M Elsayed, E Ali, A E E Eltoukhy, T Zayed, Systems. 1172023</p>
<p>Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents. S Saxena, R Sangani, S Prasad, S Kumar, M Athale, R Awhad, V Vaddina, 10.1109/BigData55660.2022.100207252022 IEEE International Conference on Big Data (Big Data). Los Alamitos, CA, USAIEEE Computer SocietyDec. 2022</p>
<p>Modelling stopping criteria for search results using Poisson processes. A Sneyd, M Stevenson, Emnlp-Ijcnlp) , K Inui, J Jiang, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. Hong Kong, the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingChinaAssociation for Computational LinguisticsNov. 2019</p>
<p>Adaptive stopping algorithms based on concentration inequalities. M Parmentier, A Legay, 10.1007/978-3-031-75434-0_23Bridging the Gap Between AI and Reality: Second International Conference. AISoLA 2024, Crete, Greece; Berlin, HeidelbergSpringer-VerlagOctober 30 -November 3, 2024. 2025</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, 2023</p>
<p>2024, the GPT-4o model supports a context window of up to 128,000 tokens. Openai, Gpt-4o</p>
<p>Hemoglobin subunit beta. U Consortium, 2024</p>
<p>Mining knowledge at multiple concept levels. J Han, Proceedings of the fourth international conference on Information and knowledge management. the fourth international conference on Information and knowledge management1995</p>
<p>A brief review on search engine optimization. D Sharma, R Shukla, A K Giri, S Kumar, 2019 9th international conference on cloud computing, data science &amp; engineering (confluence). IEEE2019</p>
<p>Highly accurate protein structure prediction with alphafold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, nature. 59678732021</p>
<p>Putting gpt-4o to the sword: A comprehensive evaluation of language, vision, speech, and multimodal proficiency. S Shahriar, B D Lund, N R Mannuru, M A Arshad, K Hayawi, R V K Bevara, A Mannuru, L Batool, Applied Sciences. 14172024</p>
<p>Introducing chatgpt search. Openai, 2024</p>
<p>W Sun, L Yan, X Ma, S Wang, P Ren, Z Chen, D Yin, Z Ren, arXiv:2304.09542Is chatgpt good at search? investigating large language models as reranking agents. 2023arXiv preprint</p>
<p>Gemini: a family of highly capable multimodal models. G Team, R Anil, S Borgeaud, J.-B Alayrac, J Yu, R Soricut, J Schalkwyk, A M Dai, A Hauth, K Millican, arXiv:2312.118052023arXiv preprint</p>
<p>Google search as an additional source in systematic reviews. J Piasecki, M Waligora, V Dranseika, Science and engineering ethics. 242018</p>
<p>The google similarity distance. R L Cilibrasi, P M Vitanyi, IEEE Transactions on knowledge and data engineering. 1932007</p>
<p>Recall-oriented understudy for gisting evaluation (rouge). C Lin, August. 2005202005</p>
<p>Bleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational Linguistics2002</p>
<p>Large language model based framework for automated extraction of genetic interactions from unstructured data. J K Gill, M Chetty, S Lim, J Hallinan, 10.1371/journal.pone.0303231PLOS ONE. 195</p>
<p>Identifying protein-protein interaction using tree lstm and structured attention. M Ahmed, J Islam, M R Samee, R E Mercer, 2019 IEEE 13th International Conference on Semantic Computing (ICSC). 2019</p>
<p>Neural network-based approaches for biomedical relation classification: A review. Y Zhang, H Lin, Z Yang, J Wang, Y Sun, B Xu, Z Zhao, 10.1016/j.jbi.2019.103294J. of Biomedical Informatics. 99CNov. 2019</p>
<p>Biobert: a pre-trained biomedical language representation model for biomedical text mining. J Lee, W Yoon, S Kim, D Kim, S Kim, C H So, J Kang, Bioinformatics. 3642020</p>
<p>Biomedical relation extraction: From binary to complex. D Zhou, D Zhong, Y He, 10.1155/2014/298473Computational and Mathematical Methods in Medicine. 201412984732014</p>
<p>Hybridrag: Integrating knowledge graphs and vector retrieval augmented generation for efficient information extraction. B Sarmah, D Mehta, B Hall, R Rao, S Patel, S Pasquali, Proceedings of the 5th ACM International Conference on AI in Finance. the 5th ACM International Conference on AI in Finance2024</p>
<p>Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning. M J Buehler, 10.1088/2632-2153/ad7228Machine Learning: Science and Technology. 5335083sep 2024</p>
<p>Tree of science -tos: A web-based tool for scientific literature recommendation. search less, research more!. M Zuluaga, S Robledo, O Arbelaez-Echeverri, G A Osorio-Zuluaga, N Duque-Méndez, Issues in Science and Technology Librarianship. 100Aug. 2022</p>
<p>Embedding and extraction of knowledge in tree ensemble classifiers. W Huang, X Zhao, X Huang, 10.1007/s10994-021-06068-6Mach. Learn. 1115May 2022</p>
<p>Multi-source knowledge pruning for retrieval-augmented generation: A benchmark and empirical study. S Yu, M Cheng, J Yang, J Ouyang, Y Luo, C Lei, Q Liu, E Chen, 2024</p>
<p>Workflowllm: Enhancing workflow orchestration capability of large language models. S Fan, X Cong, Y Fu, Z Zhang, S Zhang, Y Liu, Y Wu, Y Lin, Z Liu, M Sun, 2024</p>
<p>Challenges and advances in information extraction from scientific literature: a review. Z Hong, L Ward, K Chard, B Blaiszik, I Foster, 10.1007/s11837-021-04902-9JOM. 73112021</p>
<p>Bytescience: Bridging unstructured scientific literature and structured data with auto fine-tuned large language model in token granularity. T Xie, H Zhang, S Wang, Y Wan, I Razzak, C Kit, W Zhang, B Hoex, 2024</p>            </div>
        </div>

    </div>
</body>
</html>