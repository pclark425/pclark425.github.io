<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2536 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2536</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2536</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-fbf18a32422798077ccc4a5fba8cf88a7203d7b2</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/fbf18a32422798077ccc4a5fba8cf88a7203d7b2" target="_blank">AgentScope: A Flexible yet Robust Multi-Agent Platform</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes AgentScope, a developer-centric multi-agent platform with message exchange as its core communication mechanism, and designs an actor-based distribution framework, enabling easy conversion between local and distributed deployments and automatic parallel optimization without extra effort.</p>
                <p><strong>Paper Abstract:</strong> With the rapid advancement of Large Language Models (LLMs), significant progress has been made in multi-agent applications. However, the complexities in coordinating agents' cooperation and LLMs' erratic performance pose notable challenges in developing robust and efficient multi-agent applications. To tackle these challenges, we propose AgentScope, a developer-centric multi-agent platform with message exchange as its core communication mechanism. The abundant syntactic tools, built-in agents and service functions, user-friendly interfaces for application demonstration and utility monitor, zero-code programming workstation, and automatic prompt tuning mechanism significantly lower the barriers to both development and deployment. Towards robust and flexible multi-agent application, AgentScope provides both built-in and customizable fault tolerance mechanisms. At the same time, it is also armed with system-level support for managing and utilizing multi-modal data, tools, and external knowledge. Additionally, we design an actor-based distribution framework, enabling easy conversion between local and distributed deployments and automatic parallel optimization without extra effort. With these features, AgentScope empowers developers to build applications that fully realize the potential of intelligent agents. We have released AgentScope at https://github.com/modelscope/agentscope, and hope AgentScope invites wider participation and innovation in this fast-moving field.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2536.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2536.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentScope</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentScope: A Flexible yet Robust Multi-Agent Platform</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A developer-centric multi-agent platform for building, coordinating, and deploying LLM-powered agents with a message-exchange core, built-in fault tolerance, multi-modal and tool support, RAG integration, and an actor-based distributed execution framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AgentScope: A Flexible yet Robust Multi-Agent Platform</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentScope</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AgentScope is an end-to-end platform for building multi-agent applications around large language models. It uses messages (Python dicts with mandatory 'name' and 'content' fields and optional 'url', UUID and timestamp) as the atomic communication unit, provides syntactic utilities (pipelines, message hubs), built-in agent templates and services, a service toolkit for tool/function invocation, retrieval-augmented generation (RAG) integration via KnowledgeBanks, automatic prompt tuning and in-context learning, fault-tolerance hooks (auto-retry, rule-based correction, customizable fault handlers, agent-level critique), multi-modal lazy-loading via URL-attached messages, and an actor-based distributed runtime with placeholders for automatic parallelization and hybrid local/distributed execution. The platform is aimed at increasing developer productivity, robustness against LLM/API failures, and efficiency for distributed multi-agent LLM applications.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (supports any number; message hub/broadcast and pipelines support groups)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Built-in and customizable agent types: UserAgent (user proxy), DialogAgent (general conversational agent with configurable system prompt), DictDialogAgent (returns structured Python-dict responses), ReActAgent (reasoning + tool-using agent following ReAct pattern), ProgrammerAgent (writes and executes Python code), TextToImageAgent (generates images), RpcUserAgent / RpcDialogAgent (distributed RPC-enabled user/dialog proxies), RAGAgent / LlamaIndexAgent (agents augmented with retrieval from KnowledgeBank). Developers can create further specialized agents by configuring model, system prompt, toolset and RAG objects.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Support across multiple phases: literature review / knowledge retrieval (RAG and KnowledgeBanks), idea/specification generation (DialogAgent, prompt tuning, automatic sys-prompt generation), implementation/execution (ProgrammerAgent, tool usage via service toolkit), iterative experimentation and debugging (agent-level critique, logging, fault handlers), multi-modal data collection and processing, and evaluation/monitoring (logging, cost/usage monitoring, in-context evaluator possibilities).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Procedure-oriented message exchange with explicit workflows: sequential/conditional/iterative pipelines, message hubs (broadcast groups), and an actor-based distributed execution model where agents (actors) compute when required input messages are ready. Workflows can be expressed as DAGs (ASDiGraph) or procedural pipelines; placeholders enable non-blocking scheduling until values are resolved. Supports both centralized forwarding (message hub / AgentScope Studio) and hybrid local/distributed execution (actor model with agent servers).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Message passing using structured Python dictionary messages with mandatory fields: 'name' (sender), 'content' (text), optional 'url' (points to multi-modal data); each message has UUID and timestamp. Tool/function calls use JSON-schema descriptions and standardized calling formats (e.g., JSON objects or Markdown fenced code blocks with fields like 'thought', 'speak', 'function'); service toolkit exposes functions as JSON-schema formatted tools compatible with model APIs that accept function schemas (e.g., OpenAI-style function calling). Multi-modal data is transmitted by URL references (lazy loading).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Multiple feedback channels: iterative reasoning-acting loop (ReAct) where LLMs receive function execution results and error descriptions and then refine actions; automatic prompt tuning and in-context learning for system prompt updates; agent-level critique patterns (self-critique, pairwise critique, human-augmented critique) to detect and correct semantic/model-resolvable errors; customizable fault handlers (parse_func, fault_handler, max_retries) and rule-based correction for format errors; logging and monitoring provide human-in-the-loop feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand and stepwise: agents exchange messages after each relevant step or pipeline stage; message hubs broadcast updates to participants as messages are produced; actor model enables asynchronous, event-driven execution (an agent runs when all required input messages are available); iterative tool-usage loops produce repeated reasoning/acting exchanges until tasks resolve.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General-purpose multi-agent LLM applications (software engineering/coding assistants, multi-modal content tasks, intelligent assistants, society simulation); provides explicit support for knowledge-intensive tasks via RAG (useful for literature review and domain-specific scientific knowledge retrieval).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No quantitative experimental performance metrics (accuracy, runtime, or comparative numbers) reported in the paper; qualitative system-level performance claims include: improved developer productivity, robustness through fault-tolerance mechanisms, and efficiency gains from automatic parallel optimization in the actor-based distributed mode, but no numeric results are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>No empirical baseline comparisons reported; the paper describes architectural and feature-level benefits relative to generic single-agent setups and ad-hoc multi-agent developments but does not present controlled experimental comparisons to single-agent systems or other multi-agent frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Qualitative benefits reported: easier programming (pipelines, message hubs, zero-code workstation), robust handling of LLM/API errors (auto-retry, rule-based fixes, customizable fault handlers), modular tool usage (service toolkit + ReAct loop) enabling reliable function invocation, scalable distributed execution with automatic parallel optimization (actor model + placeholders), efficient multi-modal data handling via URL-based lazy loading, shared knowledge via KnowledgeBanks reducing redundant indexing. These benefits are presented descriptively without numeric quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Identified challenges: LLM hallucinations and unpredictable outputs that can cascade across agents; tool/service accessibility failures and network/API outages; parsing/format errors in LLM outputs; complexity of distributed debugging and potential communication overhead in poor system designs; control-flow decisions that depend on placeholder values may require temporary blocking; not all errors are resolvable automatically (e.g., expired API keys) and require human intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>None reported. The paper does not include ablation experiments quantifying the effect of components (e.g., message hub, fault handlers, actor model) on system performance.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>No numerically optimal configurations provided. The paper recommends configurable knobs: fault tolerance parameters (parse_func, fault_handler, max_retries), choice of pipeline types (sequential, conditional, loop), hybrid local/distributed deployment to place resource-heavy agents remotely, use of KnowledgeBanks to share RAG indexes across agents, and enabling in-context learning or auto sys-prompt generation for improved agent behavior; these are presented as flexible options rather than empirically optimized settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AgentScope: A Flexible yet Robust Multi-Agent Platform', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks <em>(Rating: 2)</em></li>
                <li>ReAct: Synergizing Reasoning and Acting in Language Models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2536",
    "paper_id": "paper-fbf18a32422798077ccc4a5fba8cf88a7203d7b2",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "AgentScope",
            "name_full": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
            "brief_description": "A developer-centric multi-agent platform for building, coordinating, and deploying LLM-powered agents with a message-exchange core, built-in fault tolerance, multi-modal and tool support, RAG integration, and an actor-based distributed execution framework.",
            "citation_title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
            "mention_or_use": "use",
            "system_name": "AgentScope",
            "system_description": "AgentScope is an end-to-end platform for building multi-agent applications around large language models. It uses messages (Python dicts with mandatory 'name' and 'content' fields and optional 'url', UUID and timestamp) as the atomic communication unit, provides syntactic utilities (pipelines, message hubs), built-in agent templates and services, a service toolkit for tool/function invocation, retrieval-augmented generation (RAG) integration via KnowledgeBanks, automatic prompt tuning and in-context learning, fault-tolerance hooks (auto-retry, rule-based correction, customizable fault handlers, agent-level critique), multi-modal lazy-loading via URL-attached messages, and an actor-based distributed runtime with placeholders for automatic parallelization and hybrid local/distributed execution. The platform is aimed at increasing developer productivity, robustness against LLM/API failures, and efficiency for distributed multi-agent LLM applications.",
            "number_of_agents": "variable (supports any number; message hub/broadcast and pipelines support groups)",
            "agent_specializations": "Built-in and customizable agent types: UserAgent (user proxy), DialogAgent (general conversational agent with configurable system prompt), DictDialogAgent (returns structured Python-dict responses), ReActAgent (reasoning + tool-using agent following ReAct pattern), ProgrammerAgent (writes and executes Python code), TextToImageAgent (generates images), RpcUserAgent / RpcDialogAgent (distributed RPC-enabled user/dialog proxies), RAGAgent / LlamaIndexAgent (agents augmented with retrieval from KnowledgeBank). Developers can create further specialized agents by configuring model, system prompt, toolset and RAG objects.",
            "research_phases_covered": "Support across multiple phases: literature review / knowledge retrieval (RAG and KnowledgeBanks), idea/specification generation (DialogAgent, prompt tuning, automatic sys-prompt generation), implementation/execution (ProgrammerAgent, tool usage via service toolkit), iterative experimentation and debugging (agent-level critique, logging, fault handlers), multi-modal data collection and processing, and evaluation/monitoring (logging, cost/usage monitoring, in-context evaluator possibilities).",
            "coordination_mechanism": "Procedure-oriented message exchange with explicit workflows: sequential/conditional/iterative pipelines, message hubs (broadcast groups), and an actor-based distributed execution model where agents (actors) compute when required input messages are ready. Workflows can be expressed as DAGs (ASDiGraph) or procedural pipelines; placeholders enable non-blocking scheduling until values are resolved. Supports both centralized forwarding (message hub / AgentScope Studio) and hybrid local/distributed execution (actor model with agent servers).",
            "communication_protocol": "Message passing using structured Python dictionary messages with mandatory fields: 'name' (sender), 'content' (text), optional 'url' (points to multi-modal data); each message has UUID and timestamp. Tool/function calls use JSON-schema descriptions and standardized calling formats (e.g., JSON objects or Markdown fenced code blocks with fields like 'thought', 'speak', 'function'); service toolkit exposes functions as JSON-schema formatted tools compatible with model APIs that accept function schemas (e.g., OpenAI-style function calling). Multi-modal data is transmitted by URL references (lazy loading).",
            "feedback_mechanism": "Multiple feedback channels: iterative reasoning-acting loop (ReAct) where LLMs receive function execution results and error descriptions and then refine actions; automatic prompt tuning and in-context learning for system prompt updates; agent-level critique patterns (self-critique, pairwise critique, human-augmented critique) to detect and correct semantic/model-resolvable errors; customizable fault handlers (parse_func, fault_handler, max_retries) and rule-based correction for format errors; logging and monitoring provide human-in-the-loop feedback.",
            "communication_frequency": "On-demand and stepwise: agents exchange messages after each relevant step or pipeline stage; message hubs broadcast updates to participants as messages are produced; actor model enables asynchronous, event-driven execution (an agent runs when all required input messages are available); iterative tool-usage loops produce repeated reasoning/acting exchanges until tasks resolve.",
            "task_domain": "General-purpose multi-agent LLM applications (software engineering/coding assistants, multi-modal content tasks, intelligent assistants, society simulation); provides explicit support for knowledge-intensive tasks via RAG (useful for literature review and domain-specific scientific knowledge retrieval).",
            "performance_metrics": "No quantitative experimental performance metrics (accuracy, runtime, or comparative numbers) reported in the paper; qualitative system-level performance claims include: improved developer productivity, robustness through fault-tolerance mechanisms, and efficiency gains from automatic parallel optimization in the actor-based distributed mode, but no numeric results are provided.",
            "baseline_comparison": "No empirical baseline comparisons reported; the paper describes architectural and feature-level benefits relative to generic single-agent setups and ad-hoc multi-agent developments but does not present controlled experimental comparisons to single-agent systems or other multi-agent frameworks.",
            "coordination_benefits": "Qualitative benefits reported: easier programming (pipelines, message hubs, zero-code workstation), robust handling of LLM/API errors (auto-retry, rule-based fixes, customizable fault handlers), modular tool usage (service toolkit + ReAct loop) enabling reliable function invocation, scalable distributed execution with automatic parallel optimization (actor model + placeholders), efficient multi-modal data handling via URL-based lazy loading, shared knowledge via KnowledgeBanks reducing redundant indexing. These benefits are presented descriptively without numeric quantification.",
            "coordination_challenges": "Identified challenges: LLM hallucinations and unpredictable outputs that can cascade across agents; tool/service accessibility failures and network/API outages; parsing/format errors in LLM outputs; complexity of distributed debugging and potential communication overhead in poor system designs; control-flow decisions that depend on placeholder values may require temporary blocking; not all errors are resolvable automatically (e.g., expired API keys) and require human intervention.",
            "ablation_studies": "None reported. The paper does not include ablation experiments quantifying the effect of components (e.g., message hub, fault handlers, actor model) on system performance.",
            "optimal_configurations": "No numerically optimal configurations provided. The paper recommends configurable knobs: fault tolerance parameters (parse_func, fault_handler, max_retries), choice of pipeline types (sequential, conditional, loop), hybrid local/distributed deployment to place resource-heavy agents remotely, use of KnowledgeBanks to share RAG indexes across agents, and enabling in-context learning or auto sys-prompt generation for improved agent behavior; these are presented as flexible options rather than empirically optimized settings.",
            "uuid": "e2536.0",
            "source_info": {
                "paper_title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
            "rating": 2
        },
        {
            "paper_title": "ReAct: Synergizing Reasoning and Acting in Language Models",
            "rating": 2
        }
    ],
    "cost": 0.01024725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>AgentScope: A Flexible yet Robust Multi-Agent Platform</h1>
<p>Dawei Gao ${ }^{\dagger}$, Zitao $\mathrm{Li}^{\dagger}$, Xuchen Pan<em>, Weirui Kuang</em>, Zhijian Ma<em>, Bingchen Qian</em>, Fei Wei<em>, Wenhao Zhang</em>, Yuexiang Xie<em>, Daoyuan Chen</em>, Liuyi Yao, Hongyi Peng, Zeyu Zhang, Lin Zhu, Chen Cheng, Hongzhu Shi, Yaliang $\mathrm{Li}^{\ddagger}$, Bolin Ding ${ }^{\ddagger}$, Jingren Zhou</p>
<p>Alibaba Group</p>
<h4>Abstract</h4>
<p>With the rapid advancement of Large Language Models (LLMs), significant progress has been made in multi-agent applications. However, the complexities in coordinating agents' cooperation and LLMs' erratic performance pose notable challenges in developing robust and efficient multi-agent applications. To tackle these challenges, we propose AgentScope, a developer-centric multi-agent platform with message exchange as its core communication mechanism. The abundant syntactic tools, built-in agents and service functions, user-friendly interfaces for application demonstration and utility monitor, zero-code programming workstation, and automatic prompt tuning mechanism significantly lower the barriers to both development and deployment. Towards robust and flexible multi-agent application, AgentScope provides both built-in and customizable fault tolerance mechanisms. At the same time, it is also armed with system-level support for managing and utilizing multi-modal data, tools, and external knowledge. Additionally, we design an actor-based distribution framework, enabling easy conversion between local and distributed deployments and automatic parallel optimization without extra effort. With these features, AgentScope empowers developers to build applications that fully realize the potential of intelligent agents. We have released AgentScope at https://github.com/modelscope/agentscope, and hope AgentScope invites wider participation and innovation in this fast-moving field.</p>
<h2>1 Introduction</h2>
<p>Multi-agent systems, as upgraded extensions of single-agent systems, require collaborative efforts from multiple agents working in concert (Wang et al., 2023; Xi et al., 2023). With the advancement of Large Language Models (LLMs) (Ouyang et al., 2022; OpenAI, 2023; Touvron et al., 2023a,b), multi-agent applications have made great progress in both research and industrial communities, including software engineering (Hong et al., 2023), society simulation (Park et al., 2023), and intelligent assistant (Wu et al., 2023; AutoGPT-Team, 2023). Although significant progress has been made in multi-agent scenarios, there are still major challenges remaining in multi-agent application development.</p>
<p>Developing a multi-agent application is more complex than creating a single-agent one. Unlike single-agent setups where an agent solely interacts with users, the development in the multi-agent scenario requires careful creation and management of multiple models and agents (Wang et al., 2023; Xi et al., 2023), which poses high requirements for both versatility and handiness for a platform. In particular, the following aspects feature the challenges: 1) Agents involved in a multi-agent application can specialize at different functions via different initial configurations; 2) A multi-agent application may require agents to be executed in a standardized operating procedure (SOP) or a more dynamic workflow; 3)The communication pattern between agents can be varying from one-to-one or broadcasting (e.g., a discussion group of agents). As a result, developers expect a handy platform that can provide concise and clear programming patterns when taking care of all the aspects above, accelerating and facilitating the development cycle. Achieving versatility and handiness simultaneously</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>requires careful design and taking trade-offs, and it remains a persistent goal for all multi-agent platform designs.</p>
<p>Aberrations are tinderboxs in a multi-agent system. Although LLMs have advanced rapidly, they still struggle with issues like hallucination (Rawte et al., 2023; Zhang et al., 2023b) and inadequate instructionfollowing (Fu et al., 2019; Zhang et al., 2023a). Besides, an agent can be equipped with various tools, but those tools introduce additional uncertainties (e.g., accessibility to a database or the search engine). From the perspective of multi-agent system robustness, any unexpected error or response can propagate to the whole system, causing a series of cascading effects if not handled properly. Thus, it is crucial for multi-agent applications to autonomously detect and handle unexpected responses from LLMs. While LLMs may assist in identifying and managing these errors, it remains a challenge to determine whether they can resolve errors on their own and to automatically provide the necessary information for error correction. Consequently, designing fault-tolerant that incorporate LLMs is a key challenge in the development of multi-agent applications.</p>
<p>Supporting agents with multi-modal data, tools, and external knowledge is highly systematic. Besides generating answers with LLMs, agents are expected to be more versatile, including generating and handling multi-modal data (Su et al., 2023; Betker et al., 2023), preparing and invoking functions as tools (Yao et al., 2023; Shen et al., 2024), managing external knowledge banks, and using the retrieved knowledge for augmentation generation (Lewis et al., 2020a). However, integrating these functionalities in multi-agent applications requires a comprehensive and systematic approach. Supporting multi-modal content is a complex endeavor, necessitating considerations for data storage, presentation, user interaction, message transmission, and communication. Tool utilization of agents requires unifying the function calling pattern and output parsing, prompting to instruct LLMs, and designing reasoning mechanisms to ensure the tasks can be accomplished step by step. As for external knowledge, beyond the retrieval-augmented generation (RAG) techniques, we need to consider how to efficiently share and manage the knowledge in multi-agent scenarios while leaving enough flexibility for retrieval strategies. While some existing works investigate how those techniques individually work within specialized agent systems, general platform-level programming interfaces remain absent.</p>
<p>Distributed applications bring extra programming difficulties and system design challenges. An industrialoriented scenario for multi-agent applications is that the agents are owned by different organizations and run on different machines because the agents are equipped with unique private knowledge or patented tools. Developing such applications usually requires the developers to have professional knowledge of distributed system programming and optimization in the design phase. Besides, distributed applications usually require a great extra effort in the development and testing, especially when debugging and diagnosing issues spread across distributed processes or agents. Moreover, integrating advanced features like multi-modal data processing poses additional challenges in a distributed setting, when the agents require different time to accomplish the sub-tasks or the generated contents are very heterogeneous. Poor distributed system design can result in excessive communication overhead between agents. Therefore, building distributed multi-agent applications requires the large efforts of experienced developers and a high barrier for beginners to migrate their prototypes to a distributed style for optimal efficiency.</p>
<p>To tackle the aforementioned challenges, we introduce AgentScope, a novel multi-agent platform designed for developers with varying levels of expertise. AgentScope is well-designed with a message exchange communication mechanism that embodies great usability, robustness, and efficiency. We underscore the salient features of AgentScope as follows:</p>
<p>Exceptional Usability for Developers. AgentScope is designed with a fundamental emphasis on ease of use, particularly for developers with varying levels of expertise. By implementing a procedure-oriented message exchange mechanism, AgentScope ensures a smooth learning curve on multi-agent application development. To alleviate the programming burdens, AgentScope offers an extensive suite of syntactic utilities, including various pipelines and an information-sharing mechanism. Besides programming with our framework, we also improve usability by providing a zero-code drag-and-drop programming workstation, which can enable those with limited Python programming experience to build their own applications with little effort. Compared with building the skeleton of the application, prompt tuning can be a more time-consuming stage in multi-agent application development. In AgentScope, we equip our agents with a set of automatic prompt tuning mechanisms to relieve such burden. Coupled with rich built-in resources and integrated user interaction modules, AgentScope makes building a multi-agent application much more enjoyable than ever.</p>
<p>Robust Fault Tolerance for Diverse LLMs and APIs. As the scale and scope of models and APIs</p>
<p>expand, a robust fault-tolerance mechanism in multi-agent applications becomes paramount. AgentScope integrates a comprehensive service-level retry mechanism to maintain API reliability. AgentScope is equipped with a set of rule-based correction tools to handle some obvious formatting problems in the responses of LLMs. Moreover, AgentScope offers customizable fault tolerance configurations, enabling developers to tailor their own fault tolerance mechanism through parameters like parse_func, fault_handler, and max_retries. While admittedly, not all the errors can be handled by the aforementioned mechanism, we propose a logging system with customized features for multi-agent applications as the last safeguard for AgentScope.</p>
<p>Extensive Compatibility for Multi-Modal, Tools, and External Knowledge. With the remarkable progress of large-scale multi-modal models, AgentScope supports multi-modal data (e.g., texts, images, audio, and videos) in dialog conversation, message transmission, and data storage. Specifically, AgentScope decouples multi-modal data transmission from storage and employs a lazy loading strategy by providing a unified URLbased attribute in messages. During message transmission, AgentScope only attaches a URL to the message, and the multi-modal data is loaded only when necessary, such as when being rendered in web UI or invoked by model wrappers. For tool usage, AgentScope provides a component, called service toolkit, as a one-step solution for tool usage, including function preprocessing, prompt engineering, reasoning, and response parsing with fault-tolerance features. To support efficient external knowledge usage, AgentScope provides end-to-end, highly configurable, and sharable knowledge processing modules for retrieval-augmented generation (RAG), from data preprocessing to customizable retrieval.</p>
<p>Optimized Efficiency for Distributed Multi-Agent Operations. Recognizing the vital importance of distributed deployment, AgentScope introduces an actor-based distributed mechanism that enables centralized programming of complex distributed workflows, and automatic parallel optimization. Particularly, the workflows for local and distributed deployments is a exactly the same one, indicating negligible overhead when migrating applications between centralized and distributed environments. With such a distribution framework, AgentScope empowers developers to concentrate on the application design rather than implementation details.</p>
<p>Summary To summarize, AgentScope, a novel multi-agent platform proposed for flexibility and robustness, includes the following advanced features:</p>
<ol>
<li>AgentScope provides a procedure-oriented message exchange mechanism with a set of syntactic features to facilitate multi-agent programming, a zero-code drag-and-drop programming workstation, and a set of automatic prompt tuning mechanisms.</li>
<li>The fault tolerance designs of AgentScope enable developers to handle errors elegantly for their applications.</li>
<li>The support for the multi-modal applications reduces the overheads of heterogeneous data generation and transmission. The service toolkit component facilitates the tool usage of agents in AgentScope, and the knowledge processing modules provide a flexible solution for agents to handle different information.</li>
<li>The actor-based distributed mode of AgentScope can help develop efficient and reliable distributed multi-agent applications seamlessly.</li>
</ol>
<p>Roadmap In the following sections, we navigate through the core components and capabilities of AgentScope, showcasing its role in advancing the development and deployment of multi-agent applications. Section 2 provides an overview, while Section 3 focuses on the user experience. Section 4 introduces the fault tolerance mechanism in AgentScope. Sections 5, 6, and 7 cover the multi-modal support, tool usage, and retrievalaugmented generation modules in AgentScope. Section 8 presents our platform's support for distributed multi-agent applications. Use cases are presented in Section 9, related work is summarized in Section 10, and concluding thoughts are recorded in Section 11.</p>
<h1>2 Overview</h1>
<h3>2.1 Basic Concepts in AgentScope</h3>
<p>This section introduces the primary concepts in AgentScope: message, agent, service, and workflow. These four concepts are throughout the platform and all multi-agent applications based on it.</p>
<ul>
<li>Message: Messages serve as the carriers for information exchange in multi-agent conversations, encapsulating the source and content of the information. In AgentScope, messages are implemented as Python dictionaries with two mandatory fields (name and content) and an optional field (url). The name field records the name of the agent that generates the message, and the content field contains the text-based information generated by the agent. The url field is designed to hold the Uniform Resource Locator (URL), which typically links to multi-modal data, such as images or videos. Messages with this field are particularly relevant for interactions with agents that can process and generate multi-modal content. Each message is uniquely identified by an auto-generated UUID and timestamp, ensuring traceability. Example 1 shows how the messages can be created, serving as atoms in the inter-agent communication of AgentScope.</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.message</span><span class="w"> </span><span class="kn">import</span> <span class="n">Msg</span>
<span class="n">msg1</span> <span class="o">=</span> <span class="n">Msg</span><span class="p">(</span><span class="s2">&quot;Alice&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello!&quot;</span><span class="p">)</span>
<span class="n">msg2</span> <span class="o">=</span> <span class="n">Msg</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Bob&quot;</span><span class="p">,</span>
    <span class="n">content</span><span class="o">=</span><span class="s2">&quot;How do you find this picture I captured yesterday?&quot;</span><span class="p">,</span> 
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;https://xxx.png&quot;</span>
<span class="p">)</span>
</code></pre></div>

<p>Example 1: Illustrative examples of message creation in AgentScope.</p>
<ul>
<li>Agent: Agents are the primary actors within multi-agent applications, acting as conversational participants and executors of tasks. In AgentScope, agent behaviors are abstracted through two interfaces: the reply and observe functions. The reply function takes a message as input and produces a response, while the observe function processes incoming messages without generating a direct reply. The interplay between agents and messages, as shown in Example 2, forms the operational basis of AgentScope and is essential for developers to model complex interactions in multi-agent LLMs.</li>
</ul>
<div class="codehilite"><pre><span></span><code>#<span class="w"> </span><span class="nv">agent1</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">agent2</span><span class="w"> </span><span class="nv">are</span><span class="w"> </span><span class="nv">two</span><span class="w"> </span><span class="nv">initialized</span><span class="w"> </span><span class="nv">agents</span>,<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">example</span>
#<span class="w"> </span><span class="nv">agent1</span>,<span class="w"> </span><span class="nv">agent2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">DialogAgent</span><span class="ss">(</span>...<span class="ss">)</span>,<span class="w"> </span><span class="nv">DialogAgent</span><span class="ss">(</span>...<span class="ss">)</span>
<span class="nv">msg1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">agent1</span><span class="ss">()</span>
<span class="nv">msg2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">agent2</span><span class="ss">(</span><span class="nv">msg1</span><span class="ss">)</span>
</code></pre></div>

<p>Example 2: Demonstration of message exchange between agents in AgentScope.</p>
<ul>
<li>Workflow: Workflows represent ordered sequences of agent executions and message exchanges between agents, analogous to computational graphs in TensorFlow, but with the flexibility to accommodate non-DAG structures. Workflows define the flow of information and task processing among agents, facilitating parallel execution and efficiency improvements. This concept is essential for designing multiagent systems that interact with LLMs, as it allows for the coordination of complex, interdependent tasks.</li>
<li>Service Functions and Tools: Note that service functions are closely related to but different from the concept, tools, in the context of agent design in AgentScope. Service functions refer to the functional APIs that return a formatted output ServiceResponse, while tools refer to processed services functions with functionality descriptions and necessary input parameters prepared. We introduce these two concepts in AgentScope because LLMs require help to invoke service functions as tools. One observation is that LLMs may need help understanding the functionalities of the service functions precisely and</li>
</ul>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Architecture of AgentScope.
demand more descriptive information to make accurate decisions. Meanwhile, LLMs can not (reliably) fill in some input parameters of the APIs, such as the API keys of Bing and Google Search. As a result, AgentScope defines tools as processed service functions.</p>
<h1>2.2 Architecture of AgentScope</h1>
<p>We present AgentScope as an infrastructural platform to facilitate the creation, management, and deployment of multi-agent applications integrated with LLMs. The architecture of AgentScope comprises three hierarchical layers and a set of user interaction interfaces, as shown in Fig. 1. These layers provide support for multi-agent applications from different levels, including elementary and advanced functionalities of a single agent (utility layer), resources and runtime management (manager and wrapper layer), and agent-level to workflow-level programming interfaces (agent layer). AgentScope introduces intuitive abstractions designed to fulfill the diverse functionalities inherent to each layer and simplify the complicated inter-layer dependencies when building multi-agent systems. Furthermore, we offer programming interfaces and default mechanisms to strengthen the resilience of multi-agent systems against faults within different layers.</p>
<ul>
<li>Utility Layer: As the platform's foundation, the utility layer in AgentScope provides essential services to support the core functionalities of agents. This layer abstracts the complexity of underlying operations, such as model API invocation and service functions including code execution and database operations, allowing agents to focus on their primary tasks. AgentScope's utility layer is designed with ease of use and robustness as its utmost priority, supporting versatile operations in multi-agent systems and providing built-in autonomous retry mechanisms for exception and error handling against unexpected interruptions.</li>
<li>Manager and Wrapper Layer: As an intermediary, the manager and wrapper abstraction layer manages the resources and API services, ensuring high availability of resources and providing resistance to undesired responses from LLMs. Unlike the utility layer, which provides default handlers, the manager and wrapper layer also offers customizable interfaces for fault tolerance controls depending on developers' needs and the specific requirements of the application. This layer is responsible for maintaining the operational integrity of the agents, a crucial aspect for LLMs to perform consistently</li>
</ul>
<p>under diverse conditions. Detailed elaboration on the fault tolerance mechanisms is provided in Section 4 .</p>
<ul>
<li>Agent Layer: At the core of AgentScope lies the agent abstraction, which forms the backbone of the multi-agent workflow and is the primary entity responsible for interaction and communication. This layer is designed to facilitate the construction of intricate workflows and enhance usability, reducing the programming burden on developers. By integrating streamlined syntax and tools, AgentScope empowers developers to concentrate on the implementation and optimization of agent-based applications that leverage the capabilities of LLMs. The programming features and syntactic sugars are introduced in Section 3 with more details.</li>
<li>User interaction: In addition to the layered architecture, AgentScope provides multi-agent oriented interfaces such as an annotated terminal presenting basic information, Web UI monitoring the system, a Gradio-base (Abid et al., 2019) interface that can change a command line application to a graphical one with only one step and a drag-and-drop zero-code programming workstation (Figure 4). These interfaces allow developers to effortlessly monitor the status and metrics of the application, including agent communication, execution timing, and financial costs.</li>
</ul>
<p>Collectively, the layered constructs of AgentScope provide the essential building blocks for developers to craft bespoke multi-agent applications that leverage the advanced capabilities of large language models. The subsequent section will delve into the features of AgentScope that enhance the programming experience for multi-agent application development.</p>
<h1>3 High Usability</h1>
<p>The design of AgentScope prioritizes usability, aiming to streamline the development process for multi-agent with LLMs and to ensure a smooth interaction experience for both users and developers. This section delves into how AgentScope flattens the learning curve and enhances the programmer's experience by introducing intuitive concepts and features that facilitate the creation of complex multi-agent applications.</p>
<h3>3.1 Syntactic Sugar for Multi-Agent Workflows</h3>
<p>Leveraging basic concepts introduced in Section 2.1, developers are empowered to construct sophisticated multi-agent applications. Nonetheless, directly coding each agent's message exchange can become cumbersome, as shown in Example 3. Recognizing this, AgentScope introduces two syntactic utilities: pipelines and message hubs, to abstract away the complexity and minimize repetition.</p>
<div class="codehilite"><pre><span></span><code># set up agents: agent1 to agent5
# ...
msg = agent1(msg ( &quot; Alice &quot; , &quot; Hello ! &quot; ))
msg = agent2(msg)
msg = agent3(msg)
msg = agent4(msg)
msg = agent5(msg)
</code></pre></div>

<p>Example 3: Example of programming a sequential workflow with basic concepts in AgentScope.</p>
<p>Pipeline Abstraction The pipeline abstraction reduces repetitive coding by encapsulating patterns of message transmission, including sequential, conditional, and iterative exchanges, into simple and reusable components. With these pipelines, developers can focus on the logic of agent interactions rather than the boilerplate code. Example 4 illustrates how pipelines can be employed in both functional and object-oriented styles to create a clear and concise agent workflow. Besides the sequential pipeline in the example, AgentScope also provides if-else, switch, while-loop, and for-loop pipelines, facilitating the programming of the multi-agent interactions.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># set up agents: agent1 to agent5</span>
<span class="c1"># ...</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.pipelines</span><span class="w"> </span><span class="kn">import</span> <span class="n">SequentialPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.pipelines.functional</span><span class="w"> </span><span class="kn">import</span> <span class="n">sequentialpipeline</span>
<span class="c1"># using functional pipeline</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sequentialpipeline</span><span class="p">([</span><span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span><span class="p">,</span> <span class="n">agent3</span><span class="p">,</span> <span class="n">agent4</span><span class="p">,</span> <span class="n">agent5</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
<span class="c1"># using object pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">SequentialPipeline</span><span class="p">([</span><span class="n">agent1</span><span class="p">,</span> <span class="n">agent2</span><span class="p">,</span> <span class="n">agent3</span><span class="p">,</span> <span class="n">agent4</span><span class="p">,</span> <span class="n">agent5</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>

<p>Example 4: Using functional and object sequential pipeline to construct workflow in AgentScope.</p>
<p>Message Hub for Agent Communication In multi-agent systems, especially when integrated with LLMs, efficiently managing communication among a group of agents is essential. The message hub in AgentScope serves as a broadcast mechanism that simplifies group interactions. Developers can initiate a message hub by defining participating agents and can include initial broadcast messages. When new messages are generated by the agents within the message hub, they are automatically disseminated to other participants, as demonstrated in Example 5. This abstraction is particularly useful for multi-agent scenarios involving LLMs, where dynamic and contextually rich conversations are commonly observed (Du et al., 2023).</p>
<div class="codehilite"><pre><span></span><code># set up agents: agent1 to agent4
# ...
greeting = Msg(&quot;host&quot;, &quot;Welcome to the message hub!&quot;)
with msghub(participant=[agent1, agent2, agent3],
    announcement=greeting) as hub:
    # Message will be broadcast to agent2 and agent3 automatically
    agent1()
    # Delete agent2 from the message hub
    hub.delete(agent2)
    # Add agent4 into the message hub
    hub.add(agent4)
    # Broadcast message
    hub.broadcast(Msg(&quot;host&quot;, &quot;Welcome agent4 to join the hub!&quot;))
</code></pre></div>

<p>Example 5: Using message hub with AgentScope.</p>
<h1>3.2 Resource-Rich Environment for Agent Development</h1>
<p>To further enhance usability, AgentScope is equipped with a rich set of built-in resources, including services, dedicated agents, and pre-configured examples. These resources are designed to reduce the initial setup effort and enable rapid prototyping and deployment of multi-agent LLM systems.</p>
<p>Comprehensive Service Integration AgentScope integrates various service functions, such as web search, database querying, and code execution, to support the tool usage capabilities of agents. These service functions are essential for building helpful agents with LLMs, as agents often need to draw information from external sources or execute tasks that go beyond the equipped LLMs' internal knowledge. Example 6 showcases the seamless conversion of a service into an OpenAI-Compatible JSON format, simplifying the integration process for developers.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.service</span><span class="w"> </span><span class="kn">import</span> <span class="n">ServiceFactory</span><span class="p">,</span> <span class="n">web_search</span>
<span class="n">bing_search</span><span class="p">,</span> <span class="n">func_json</span> <span class="o">=</span> <span class="n">ServiceFactory</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">web_search</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;bing&quot;</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;</span>
<span class="mi">4</span><span class="p">,</span> <span class="n">xxx</span><span class="s2">&quot;, num_results=10)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">func_json</span><span class="p">)</span>
<span class="c1"># {</span>
<span class="mi">7</span> <span class="c1"># &quot;name&quot;: &quot;web_search&quot;,</span>
<span class="c1"># &quot;description&quot;: &quot;Searching the given question with bing.&quot;,</span>
<span class="c1"># &quot;parameters&quot;: {</span>
<span class="c1"># &quot;type&quot;: &quot;object&quot;,</span>
<span class="c1"># &quot;properties&quot;: {</span>
<span class="c1"># &quot;type&quot;: &quot;object&quot;,</span>
<span class="c1"># &quot;properties&quot;: {</span>
<span class="c1"># &quot;question&quot;: {</span>
<span class="c1"># &quot;type&quot;: &quot;string&quot;,</span>
<span class="c1"># &quot;description&quot;: &quot;The string question to search in Bing.&quot;</span>
<span class="c1"># }</span>
<span class="c1"># }</span>
<span class="c1"># }</span>
<span class="c1"># }</span>
<span class="c1"># }</span>
<span class="n">searching_result</span> <span class="o">=</span> <span class="n">bing_search</span><span class="p">(</span><span class="s2">&quot;What&#39;s the date today?&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Example 6: Converting web search service into the function and JSON format dictionary that agent can use.</p>
<p>Pre-built Agent Templates As cataloged in Table 1, AgentScope offers pre-built agents and ready-to-use components for tasks like dialogue management, user proxying, multi-modal data handling, and distributed deployment. These templates serve as starting points for developers to customize and extend, significantly accelerating the development of multi-agent LLM applications.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Agent Name</th>
<th style="text-align: left;">Function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">UserAgent</td>
<td style="text-align: left;">The proxy of the user.</td>
</tr>
<tr>
<td style="text-align: left;">DialogAgent</td>
<td style="text-align: left;">A general dialog agent, whose role can be set by system prompt.</td>
</tr>
<tr>
<td style="text-align: left;">DictDialogAgent</td>
<td style="text-align: left;">A dictionary version dialog agent, who responds in Python dictionary format.</td>
</tr>
<tr>
<td style="text-align: left;">ReActAgent</td>
<td style="text-align: left;">An agent that can reason and use tools</td>
</tr>
<tr>
<td style="text-align: left;">ProgrammerAgent</td>
<td style="text-align: left;">An agent that can write and execute Python code.</td>
</tr>
<tr>
<td style="text-align: left;">TextToImageAgent</td>
<td style="text-align: left;">An agent that generates images according to the requirements.</td>
</tr>
<tr>
<td style="text-align: left;">RpcUserAgent</td>
<td style="text-align: left;">A distributed version user proxy.</td>
</tr>
<tr>
<td style="text-align: left;">RpcDialogAgent</td>
<td style="text-align: left;">A distributed version DialogAgent.</td>
</tr>
</tbody>
</table>
<p>Table 1: Some examples of built-in agents and their functions in AgentScope.</p>
<h1>3.3 Multi-Agent Oriented Demonstration Interfaces</h1>
<p>Furthermore, AgentScope introduces interaction interfaces tailored for multi-agent systems, as illustrated in Figures 2 and 3. These interfaces provide a rich multi-modal experience, crucial for systems incorporating LLMs that handle diverse data types.</p>
<p>Agent Differentiation in User Interfaces To facilitate user interaction with multiple agents, AgentScope assigns unique colors and icons to each agent, enhancing clarity and visual distinction in both terminal and web UI (Fig. 3). The "first-person perspective" feature allows users to experience interactions from the viewpoint of a specified agent, aligning with their role in the application, such as in a game scenario. This feature not only enriches the multi-agent experience but also mirrors the nuanced interactions that occur in human-agent and agent-agent dialogues within LLM systems.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The dialogue history of a werewolf game in AgentScope.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Multi-modal interactions between agents in web UI.</p>
<p>Monitoring and Cost Management A vital aspect of deploying LLMs at scale is resource management. AgentScope includes a monitoring module that tracks model and API usage, as well as calculating financial costs. Developers can customize metrics and set budget limits, receiving automatic alerts when thresholds are approached or exceeded. This proactive cost management is particularly important for LLMs that may incur high computational expenses.</p>
<p>AgentScope Gradio Interface Once you have a multi-agent application, executing it in the terminal may be a concise choice but lacks attraction. In AgentScope, we provide a powerful Gradio-based interface that is compatible with all AgentScope applications as long as there is a main function as the application's entry point. For example, if the main function of the application is in application.py file, then running "as_studio application.py" can build a Gradio application with a graphical user interface and support multi-modal content upload and presentation.</p>
<h1>3.4 Towards Graphical Application Development</h1>
<p>The design mentioned above provides massive convenience for those familiar with Python programming to quickly develop their multi-agent applications. However, AgentScope takes a step further. AgentScope provides a drag-and-drop online workstation on which developers only need to drag the module blocks to compose an application; then, the workstation can generate a configuration file of the application in JSON or even a piece of Python code. With this feature, those with limited experience with Python programming can build their multi-agent application without writing any Python code, while those familiar with Python can instantly obtain a piece of draft code ready for further customization. A screenshot of the online workstation is shown in Fig. 4, and the idea supporting this implementation is illustrated as follows.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Drag-and-drop programming workstation.</p>
<p>Expressing Multi-agent application with nodes in directed acyclic graph (DAG). Based on the highly modular design of our basic infrastructure, all the key components can be represented as a node, and an application can be built by constructing a directed cycle graph (DAG). The execution of the application is equivalent to triggering and running the nodes in the graph following the traversing order of DAG. Following the traditional terms, we name such DAG execution as a workflow and name the nodes in the workflow as workflow nodes. According to their functionality, the workflow nodes are categorized into six different types: model nodes, agent nodes, pipeline nodes, service nodes and copy nodes.</p>
<ul>
<li>Model nodes: Model nodes are designed to be relatively independent of the DAG. They correspond to the model configurations in AgentScope and work as entries to let users configure their models (LLMs, embedding models, or multi-modal models) and maintain such information for all the nodes in the following workflow that need to use the model.</li>
<li>Service (tool) nodes: These nodes correspond to the services available in AgentScope. Some of them require additional information to set up, such as Google search and Bing search, which require API keys; others can be used directly.</li>
<li>Agent nodes: As the name suggests, agent nodes represent the agents in AgentScope, which means users need to decide the models, agent name and system prompts for the agent.</li>
<li>
<p>Pipeline nodes: The pipeline node includes the operators of AgentScope, including the message hub and the pipelines (sequential, for-loop, while-loop, etc.). With such nodes, DAG representations can be as concise as Python programming.</p>
</li>
<li>
<p>Message node: The message node is designed for cases where some initial messages are needed, such as the announcement (initial message) for the message hub.</p>
</li>
<li>Copy node: The copy node is a special kinds of node that replicate the results of a parent node when its output is needed for multiple subsequent operations.</li>
</ul>
<p>Execute DAG with JSON or compile to Python. With the nodes above, developers can build applications by composing DAGs. However, the DAG is highly UI-dependent. Although a DAG can be represented in some formats (e.g., JSON format recording each node's information and execution dependency), we still need to ensure it is as reusable as other applications. To overcome this, AgentScope is equipped with a data structure called ASDiGraph, which provides two solutions based on it.</p>
<ul>
<li>Direct-run: Given a JSON file recording the DAG information, ASDiGraph can parse DAG information and sort the nodes in topological order. With these sorted nodes, the run function of ASDiGraph can execute them in order and feed the predecessor's output to their successors as an application is executed step by step.</li>
<li>To-Python compiler: The second solution is to translate the JSON file to a Python script. With the highly modularized components of AgentScope, the key idea is to rely on internal mappings of the functionality, required inputs, and expected outputs to small pieces of Python code. Specifically, each node contains Python code for importing dependent modules, initiating models or agents, and executing the application logic. ASDiGraph first groups the pieces of importing code and initiating code, and then it composes the pieces of execution code following the topological order. Therefore, users will obtain a complete Python script after the ASDiGraph finishes compilation.</li>
</ul>
<h1>3.5 Automatic Prompt Tuning</h1>
<p>For a multi-agent system that utilizes LLMs for generation, writing an appropriate prompt requires significant human effort and expertise (Pryzant et al., 2023), which motivates us to provide automatic prompt generation and tuning in AgentScope for its high usability. Specifically, AgentScope allows users to generate prompts based on a simple description of the agent in natural language, update prompts according to contexts, and enable in-context learning.</p>
<p>System Prompt Tuning When an agent is created, a system prompt should be associated with the agent to define its roles and responsibilities for following human instructions. For example, a Programmer Agent might be prompted as "You are proficient in writing and executing Python code". Meanwhile, a detailed and informative system prompt can improve agent performance and ensure that the agent performs as expected, such as "You are proficient in writing and executing Python code. You prefer to write the code in a modular fashion and provide unit tests for each module". With AgentScope, users only need to provide a simple description of the agent when creating the agents, and AgentScope can automatically generate such helpful system prompts using built-in tools based on LLMs, as shown in Example 7.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># set up agents with automatic prompt generation</span>
<span class="c1"># ...</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ProgrammerAgent</span>
<span class="c1"># Load model configs</span>
<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">model_configs</span><span class="o">=</span><span class="s2">&quot;model_configs.json&quot;</span><span class="p">)</span>
<span class="c1"># Create a programmer agent</span>
<span class="n">programmer_agent</span> <span class="o">=</span> <span class="n">ProgrammerAgent</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="n">auto_sys_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">model_config_name</span><span class="o">=</span><span class="s2">&quot;my_config&quot;</span><span class="p">,</span>
    <span class="n">sys_prompt</span><span class="o">=</span><span class="s2">&quot;an assistant that can write Python code&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Example 7: Initialize a programmer agent with automatic system prompt generation.</p>
<p>Besides, AgentScope provides interfaces for system prompt updates, which include manually setting by users or automatically adjusting based on the context. As a promising future direction, meta-prompting techniques (Pryzant et al., 2023; Suzgun and Kalai, 2024) can also be integrated into AgentScope, which might involve integrating an evaluator to provide guidance for automatic prompt optimization.</p>
<p>In-Context Learning Providing multiple demonstrations to the LLMs can greatly enhance their ability to follow instructions, particularly when we want them to complete specific downstream tasks (Dai et al., 2023; Wei et al., 2022). AgentScope provides a simple switch to turn on/off the in-context learning behavior for agents that utilize LLMs. When users choose to apply in-context learning, they only need to provide demonstration candidates and configure how to match the most suitable ones, as illustrated in Example 8. AgentScope offers several widely-used and useful matching approaches, such as random selection, similar questions, and similar answers, and allows for user customization.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># set up agents with in-context learning</span>
<span class="c1"># ...</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReActAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentscope.utils.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_demo_data</span>
<span class="c1"># Load model configs</span>
<span class="n">agentscope</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">model_configs</span><span class="o">=</span><span class="s2">&quot;model_configs.json&quot;</span><span class="p">)</span>
<span class="c1"># Load demonstrations</span>
<span class="n">react_pairs</span> <span class="o">=</span> <span class="n">load_demo_data</span><span class="p">(</span><span class="s2">&quot;my_demos.txt&quot;</span><span class="p">)</span>
<span class="c1"># Create a reAct agent</span>
<span class="n">react_agent</span> <span class="o">=</span> <span class="n">ReActAgent</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;react_agent&quot;</span><span class="p">,</span> <span class="n">enable_icl</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                    <span class="n">demos</span><span class="o">=</span><span class="n">react_pairs</span><span class="p">,</span> <span class="n">matching_approach</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Example 8: Enable in-context learning when creating an agent.</p>
<h1>4 Fault-Tolerant Mechanisms</h1>
<p>In the realm of multi-agent systems, particularly those interfacing with diverse open-source LLMs with various instruction-following capabilities, fault tolerance is a key property to ensure seamless operation. AgentScope is engineered to autonomously handle a wide range of errors with minimal human intervention required, drawing upon a comprehensive fault-tolerant infrastructure that is acutely aware of the complexities involved in multi-agent coordination and LLM dependencies.</p>
<p>Error Classification and Handling Strategies Our approach begins with a methodical classification of errors into distinct levels, each with tailored handling strategies:</p>
<ul>
<li>Accessibility errors: In AgentScope, an agent's functionalities rely on different kinds of services, but those services may be subject to temporary inaccessible errors. These errors may be caused by model instability or network conditions. For example, the model APIs may return a timeout error when there is traffic congestion during busy hours, or a database on a remote machine may be inaccessible because of transient network outages.</li>
<li>
<p>Rule-resolvable errors: As many multi-agent applications require information exchange between services or agents, it is essential to follow the protocols for those communications, e.g., in JSON format. However, as the responses of LLMs are not fully controllable yet, their return may not follow the format required in the prompts. For example, we may expect a response from an LLM in JSON, but a right brace is missed at the end of the return, leading to parsing failure. As the JSON format has clear specifications, it is reasonable to assume that a subset of these errors can be resolved by correcting the format according to the rules to meet the specifications.</p>
</li>
<li>
<p>Model-resolvable errors: When a multi-agent system handles some complicated tasks, the ability of the agent to understand the input, make decisions, and deliver outputs mostly depends on the capability of LLMs. In some cases, the responses of LLMs are in the expected format, but the content has problems, such as argument errors, semantic errors, or programming mistakes. It is hard to have pre-defined rules to regularize those responses for diverse tasks, but it has also been shown that such errors may be detected and recovered by further interaction with the LLMs.</p>
</li>
<li>Unresolvable errors: Eventually, there must be some errors that cannot be detected or solved. A typical example is that the API key of an LLM is expired or unauthorized. The agents relying on it or the system can do nothing to resolve such errors without human intervention.</li>
</ul>
<p>Fault Tolerance mechanisms in AgentScope In AgentScope, we provide different mechanisms to encounter the errors summarized above.</p>
<ul>
<li>Basic auto-retry mechanisms: To combat accessibility errors, AgentScope's API services and model wrappers are fortified with retry logic that developers can customize, such as setting the maximum retry count. This ensures that agents can recover from sporadic disruptions and maintain their operational continuity.</li>
<li>Rule-based correction tools: The rule-based correction tools are introduced into AgentScope to efficiently and economically handle some easy-to-fix format errors in the responses of LLMs. For example, we establish a set of default rules in AgentScope that can complete unmatchable braces and extract JSON data from strings. Such rule-based correction tools can correct some of the common rule-resolvable errors without calling LLM APIs again, which means shorter processing time and no LLM API call cost.</li>
<li>Customizable fault handlers: AgentScope also integrates flexible interfaces of fault handlers in model wrappers for developers to define how to parse the responses from LLMs and handle the unexpected outputs. Application developers can configure their fault handling mechanism by providing a parsing function, fault handling function, and the number of chances given to LLMs through configurable parameters (i.e., parse_func and fault_handler and max_retries) when invoking LLMs. With such developer-friendly design, AgentScope can be configurably robust to rule-resolvable errors (when the build-in rules fail to handle) and some model-resolvable errors that can be detected and handled by a single agent (e.g., distilling a verbose summary to a more concise one).</li>
<li>Agent-level fault handling: There are model-resolvable errors that require more advanced LLM usages or agent-level interaction to recover. For example, detecting semantic errors, which usually include factual inaccuracy, logical inconsistency, contextual incoherence, unreasonable inference, and inappropriate vocabulary usage, is challenging since they may not necessarily trigger immediate red flags within the system's existing validation processes. Developers can utilize the agent's ability in AgentScope (e.g., memory module and message hub) to critique for semantic error checking such as self-critique, pairwise critique, and human-augmented critique.</li>
<li>Logging system: Although the unsolvable errors are too tricky for the system to handle, AgentScope provides an improved logging system for developers to quickly monitor and identify the problems in multi-agent applications. The logging system in AgentScope has customized features for the multi-agent application scenarios, including adding a logging level called CHAT for logging conversations between agents, providing formatted logs with various execution information, and a WebUI user interface to facilitate monitoring.</li>
</ul>
<h1>5 Multi-Modal Applications</h1>
<p>The integration of multi-modal data is indispensable for advancing the capabilities and applications of multi-agent with LLMs. AgentScope is designed to seamlessly support various data modalities, leveraging the diverse inputs and outputs that contemporary LLMs can process and produce.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The generation, storage, and transmission of Multi-modal data in AgentScope.</p>
<p>Management of Multi-Modal Data In a running AgentScope application, the lifecycle of multi-modal data is carefully managed. This management includes the generation, transmission, and storage of multi-modal data - all facilitated through a decoupled architecture using URLs and a local file manager system. Fig. 5 exemplifies this process, including data originating from user inputs or model generations, data storage and retrieval, and data sharing.</p>
<ul>
<li>Multi-modal data generation: There are two primary sources of multi-modal data in AgentScope. One source is simply the locally stored multi-modal files, which can be used by either user proxy agents or general agents with access to the local file system. Another source is the model-modal content generation models. Our model APIs and the model wrappers integrate the most popular multi-modal models, such as the text-to-image content generation models like OpenAI's DALL-E, and conversely, the image-to-text image analysis models, e.g., GPT-4V. Besides the built-in APIs, developers can introduce their favorite multi-modal models and customize their own model wrappers, with our ready-to-use examples as the starting points. This customization process is streamlined in AgentScope and benefits from our modular design, allowing developers to connect their multi-modal services with minimal effort.</li>
<li>Multi-modal data storage: As mentioned above, multi-modal data in the multi-agent application can be either from ready-to-use local files or generated by multi-modal models. When a multi-modal model wrapper is invoked to generate multi-modal data, it first saves the data locally with the help of the file manager and returns a local URL when it receives multi-modal data from the model API service.</li>
<li>Multi-modal data transmission: AgentScope simplifies the process of multi-modal data sharing between agents by allowing agents to encapsulate local or remote URLs in multi-modal messages to indicate the actual storage locations of the data. The receiver agents can load the multi-modal data through the URLs when ready to process those.</li>
</ul>
<p>The benefits of introducing URLs in the messages when agents share multi-modal data are three-fold. Firstly, it can minimize the message size to avoid potential errors or delays because of the network bandwidth and enable the receiver agent to load the data on demand. Secondly, if there is other text information in the message, the downstream agents can potentially prioritize or parallel the processing of the text information to/and the processing of multi-modal information. Last but not least, such URL-attached messages can also facilitate the multi-modal data demonstration, which will be introduced in the following section.</p>
<p>Multi-Modal Interaction Modes With the implementation of URL-attached messages, AgentScope empowers users to interact with multi-modal systems via accessible interfaces such as terminal and web UI. Fig. 3 showcases the user's ability to interact with multi-modal data within interaction modes. In the terminal, users can conveniently access locally stored data by activating the provided URLs. The web UI further enhances user experience by providing an intuitive platform to view and analyze multi-modal content, aligning with the expectations of modern web applications.</p>
<p>Through AgentScope, developers are equipped to tailor model API services and wrappers to their individual needs, forge applications that handle diverse data modalities, and provide users with the necessary tools to engage with multi-modal agents effectively. This comprehensive support for multi-modal applications positions AgentScope as a versatile and powerful framework for harnessing the full potential of multi-agent LLMs, broadening the horizons for developers and researchers alike in creating sophisticated and interactive AI systems.</p>
<h1>6 Tool Usage</h1>
<p>Tool usage is an important feature for LLM-empowered agents, allowing agents to perceive, change their environment, and handle more complex tasks (Wu et al., 2023; Paranjape et al., 2023; Parisi et al., 2022). For simplicity, we treat using tools as equivalent to calling service functions by LLMs. In AgentScope, the tool usage module is designed based on ReAct algorithm (Yao et al., 2023), which allows for the generation of interleaved reasoning and task-specific actions, along with a core component-service toolkit. Such design features high compatibility, extensibility, robustness, and re-usability, spanning from function pre-processing, prompt engineering, reasoning, and response parsing to agent-level fault tolerance. Specifically, in AgentScope the tool usage involves four steps:</p>
<ul>
<li>Function Preparation: Parse the provided service functions, and pre-process the functions so that LLMs can utilize them directly.</li>
<li>Instruction Preparation: Prepare instruction prompt for tool usage to elaborate the available tool functions to LLMs, including the purpose, arguments, constraints of the function, and its calling format.</li>
<li>Iterative Reasoning: LLMs generate strategic reasoning, make decisions for tool usage, and respond in the required format.</li>
<li>Iterative Acting: Parse and check the LLM response according to the calling format, invoke functions if the response adheres to the expected format, or generate a detailed error message to LLMs for correction.</li>
</ul>
<p>In the above process, the service toolkit module is responsible for tool functions management, preprocessing, prompt engineering, response parsing, and function execution, and it is highly modular and extensible. Fig. 6 demonstrates how the service toolkit works in AgentScope when users post a query.</p>
<p>Function Preparation. In function preparation, the target is to preset the developer-specific arguments, and to generate ready-to-use functions and their corresponding formatted description for LLMs. In AgentScope, developers only need to register their functions with preset arguments in the service toolkit. As shown in Fig. 6, developers choose the Bing search function and provide the API key during registration. Then the service toolkit will automatically generate the processed ready-to-use function and its description in JSON schema format. The descriptions will be used to generate tool instructions in natural language. Optionally, some model APIs (e.g., OpenAI and DashScope Chat API, etc.) can receive the JSON schema descriptions directly, which we will discuss in Sec. 6.1.</p>
<p>Instruction Preparation For novice developers, the service toolkit builds in templates for tool instruction and calling format for tool usage, as demonstrated in Fig. 6. The tools instruction template lists each function with a clear description and the parameters it requires, leading to an easy understanding of their functionalities. On the other hand, the calling format, as demonstrated in Fig. 6, requires a JSON dictionary in a Markdown fenced code block with thought, speak, and function fields. During LLM generation, we expect the thought field will provide a reasoning process for the next acting, including analyzing the current situation, selecting candidate functions, and correcting errors.</p>
<p>Iterative Reasoning In AgentScope the reasoning and acting steps are iterative. As stated above, in the reasoning step LLMs should analyze the current situation and decide the next actions. Developers only need to construct prompts with the tool instructions and the calling format instructions and feed them into the LLMs. Such design provides high reusability and flexibility, that is, the service toolkit is task-independent and can be adapted to different tasks and scenarios very easily.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: The ReAct-based tool usage module in AgentScope.</p>
<p>Iterative Acting In the acting step, the service toolkit will parse the LLM response according to the calling format, extract the selected function, and execute it with the corresponding arguments. If the response conforms to the format requirements, and the function executes successfully, the service toolkit will return the execution results directly, which LLM can generate a response based on in the next reasoning step. Otherwise, we break down errors into response parsing errors, function execution errors, and other runtime errors. For response parsing and function execution errors, we expose them to LLM with detailed error information for correction in the next reasoning-acting iteration, leaving the other runtime errors to developers.</p>
<h1>6.1 Customization for Experienced Developers</h1>
<p>AgentScope supports developers in highly customizing their tool instructions and function calling formats. To customize tool instruction, the service toolkit in AgentScope provides JSON schema descriptions automatically, which provides a structured way to elaborate how a function should be called, including its name, purpose, arguments, and other relevant details. These formatted descriptions can be directly fed into some advanced model APIs, e.g. OpenAI and DashScope Chat APIs. For users who want to deeply customize their tool instructions, they can construct instructions based on the JSON schema descriptions.</p>
<p>Besides the tools instruction, AgentScope also provides great flexibility, that is, AgentScope provides various model response parsers, including Markdown fenced code blocks, JSON object code blocks, and customizable tagged contents, as demonstrated in Fig. 7. For the users who want to customize the function calling format, the Markdown fenced code blocks and JSON object code block allow them to quickly construct the format instruction and parse the LLM response according to the content types. For users who want to obtain multi-fields from LLMs, the multi-tagged contents allow the developers to combine different tagged contents at will and extract them easily from the response into a Python dictionary. With these parsers, developers are able to customize their own calling format easily.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Parsers in AgentScope.</p>
<h1>7 Agents with Retrieval-Augmented Generation</h1>
<p>With the growing applications of LLMs, some circumstances require knowledge that is not contained in the training data set, for example, knowledge in highly professional domains or not publicly available. Even given the required datasets, the fine-tuning or re-training of the LLMs is still expensive. Accordingly, retrieval-augmented generation (RAG), an innovative approach that aims to boost the power of LLMs in customized knowledge domain (Gao et al., 2023; Lewis et al., 2020b), is gaining increasing attention in the literature.</p>
<p>The methodology of RAG can be considered as inserting a pre-processing step into the common utilization pipeline of LLMs. That is, given a collection of documents that contains needed knowledge, a similarity-based index is built, and the original user input is zipped with the most relevant pieces of information and converted into prompts, then fed to the LLMs. Therefore, the methodology of RAG involves multiple phases, that is, the collection of documents that contain the necessary information, the segmentation of the documents, the indexing of the segments (a.k.a. chunks or nodes), the similarity-based index retrieval, the fusion of the original query (i.e. user input) and retrieved results, the composing of prompts, and lastly, generation of reasonable responses from the LLM based on the informative prompts.</p>
<p>In short, RAG embraces both the power of information retrieval and the generative capabilities of LLMs, and provides enhanced LLM service with customized domain knowledge at low cost. Meanwhile, assisted by RAG, the hallucination could be avoided and the factual accuracy could be significantly improved.</p>
<p>As a developer-oriented multi-agent platform, AgentScope provides comprehensive RAG support for multiagent applications. Given popular RAG frameworks such as e.g., LlamaIndex (Liu, 2022), LangChain (LangchainAI, 2023), etc., AgentScope is designed with highly flexible abstracted processes to be compatible with those frameworks. In what follows, we introduce several key features of AgentScope RAG.</p>
<p>Configurations in One-Stop Due to the complexity of the working pipeline, the configuration of RAG services is highly convoluted and often headache-some for users. While the RAG service provided by AgentScope is comprehensive and also involves multi-agent workflow, AgentScope provides a simple one-stop configuration solution by using a single .json file to group all RAG-related configurations.</p>
<p>With this highly systematized configuration interface, users only need to focus on constructing the workflow, without being distracted by the repetitious configurations. For example, the RAG-empowered agents may involve a wide collection of knowledge bases that need to be configured in detail. With this "One-Stop" feature, the corresponding adjustments of the modules (which may lead to different performances) are integrated as the editing over simply one single file. Moreover, this solution also naturally adapts to the AgentScope Workstation, in which the dialog-box-based configuration can be easily exported to executable files and later loaded in Python programs.</p>
<p>Knowledge-oriented Data Managements The application of RAG in multi-agent circumstances is more complicated compared with the application on a single agent. For example, for a single agent, one can directly</p>
<p>encapsulate the needed knowledge to the agent. Therefore, the initialization of each RAG agent involves the whole pipeline of conversion from the original documents to vector-stored indexes with retrievers. However, in multi-agent applications, it is natural for agents to share knowledge, such that repeatedly executing index computation for each agent is needless. Therefore, AgentScope introduces the notion of knowledge banks.</p>
<p>Knowledge banks can be considered as a collection of knowledge containers, where the smallest manageable unit is a customized object (which will be referred to as a "RAG object" in the following context). The workflow starts with initializing the knowledge bank, which mainly relies on the information contained in the .json configuration file. The information includes the directory and extensions (such as .py or .md) of documents, the granularity and choice of segmentation tools (e.g. the splitters in Llama-Index) for the documents, and choice of model for indexing. After the initialization, the computed results are persisted to the designated directory for later use and we also obtain a knowledge bank consisting of RAG objects, each marked with a unique knowledge_id, associated with the index of the corresponding documents, an information retriever, and other attributes. Note that AgentScope permits each RAG agent to load with more than one RAG object.</p>
<p>Agents with RAG The application of agents with RAG in AgentScope is very simple. For example, we first need to initialize a KnowledgeBank with some RAG framework, e.g. LlamaIndex, and all the documents. Then, we configure an RAG agent and load it with the knowledge bank. After that, the initialization is completed and we can use the RAG agent like any other agent in AgentScope. It is worth noting that if KnowldgeBank is obtained with LlamaIndex framework, then we need to use LlamaIndexAgent (inherited from RAGAgentBase). The readers may refer to Section 9.5 for a concrete application sample, which implements a copilot for AgentScope using our RAG agents. Overall, the key features of RAG agents are summarized as follows:</p>
<ul>
<li>The RAG agent is permitted to load several RAG objects (i.e. any subset of the knowledge bank). One can choose to load the original RAG objects from the knowledge bank (in such case, the modification to an object may affect all the agents who use it) or a copy of it.</li>
<li>While agents are initialized with a KnowledgeBank object, it is permitted for the agents to update knowledge in time. The operations include inserting, deleting, or replacing knowledge pieces. Moreover, we provide a solution by monitoring certain directories and keeping the RAG object updated with the contents in the directories.</li>
<li>The fusion mechanism of the retrieved results from multiple RAG objects is fully customizable. For example, since knowledge may be of different importance or trustworthiness, the agent can set weights for information retrieved from different RAG objects for subsequent processes.</li>
<li>RAGs agents are permitted to recompose the query in configurable repeats and conduct multiple queries for more comprehensive answers.</li>
</ul>
<h1>8 Actor-based Distributed Framework</h1>
<p>Efficiency and extensibility are essential when building industry-level applications on multi-agent systems. The inference speed of the agents in multi-agent applications may vary dramatically. For example, suppose an agent in a multi-modal application employs a text-to-video model. In that case, its response time may be significantly longer than that of an agent designed to fill in details of stories. Parallelization, as a classic idea, should be introduced to boost efficiency. Besides, multi-agent applications can comprise agents physically distributed on different machines. A typical use case is that a company can wrap its patented techniques or private knowledge bases into an agent on their local machines connected to the internet and provide autonomous services to other entities via agent interactions.</p>
<p>However, when it comes to multi-agent systems, a challenge is that developers need to make decisions between the following two pairs of technology roadmaps. As there is no free lunch, any combinations have their benefits and drawbacks.</p>
<ul>
<li>Centralized v.s. decentralized coordination. In the context of the distributed system, centralized coordination means multiple computation nodes being managed by a central node, such as the serverclient model. A multi-agent mechanism with centralized coordination means the execution of the agents is scheduled by, and the messages between agents are forwarded by a central coordination component. On the contrary, decentralized coordination does not rely on any central component to schedule or forward messages, but the agents in such a system can be invoked automatically and send messages directly to the downstream agents for further processing.
While centralized coordination is a straightforward style that can be understood and is easy to debug, its disadvantages include vulnerability to central node failures, imposing heavy traffic on the central node, and difficulty in scaling or extending to complicated applications. In contrast, decentralized coordination may require extra effort to develop and maintain but has a higher robustness against failure of any single node.</li>
<li>Static vs. dynamic workflow design. A similar comparison can be found between the static computational graph employed in early versions of TensorFlow (Abadi et al., 2016) and the dynamic computation graph used in PyTorch Paszke et al. (2019). In the context of multi-agent applications, the choice between a static and dynamic workflow is akin to choosing between pre-compiled and interpreted execution. The static workflow design can enable the optimization of the workflow graph level for running time and resource allocation. However, static workflow design requires the workflow graph to be known before execution, which limits the adaptation into applications, especially the ones with loop structures in the design. In contrast, dynamic workflows offer greater flexibility at the expense of optimization potential. This is particularly relevant when dealing with large language models where execution paths can change based on the input data or model inference results.
<img alt="img-7.jpeg" src="img-7.jpeg" /></li>
</ul>
<p>Figure 8: An example of a distributed application in AgentScope, illustrating various processes as denoted by different colors.</p>
<p>Distributed mode in AgentScope. AgentScope balances these technology roadmaps by implementing an actor-based distributed mode that is mindful of the unique needs of multi-agent LLM systems, with the following important features:</p>
<ul>
<li>
<p>Automatic parallel optimization without static graphs. AgentScope leverages the actor model to enable automatic parallel optimization, allowing developers to circumvent the intricacies of static graph programming. This approach seamlessly aligns with the dynamic and often unpredictable nature of LLMs, where the computational graph can alter based on evolving contexts and dialogue states.</p>
</li>
<li>
<p>Programming workflows with minimal complexity. In contrast to traditional actor models and peer-topeer (P2P) implementations that require intricate execution ordering for distributed agents, AgentScope simplifies workflow programming to a single procedural style within a Python function. This design significantly flattens the learning curve for developers, making the construction of sophisticated multiagent LLMs more accessible.</p>
</li>
<li>Hybrid local and distributed agent support. AgentScope's flexibility extends to supporting a hybrid mode where some agents operate locally while others are distributed. This feature is particularly beneficial when integrating LLMs with varying computational requirements, allowing for resource-intensive models to be distributed while less demanding agents remain local, all without the developer needing to differentiate between the two during implementation.</li>
</ul>
<p>Specifically, we can concisely describe how AgentScope incorporates the actor model as the following. In this conceptual framework, an "actor" acts as a stand-alone entity that processes computation upon receipt of all necessary messages. This paradigm ensures that each agent, corresponding to an actor, only engages in computation once the required input messages are ready, thus achieving automatic parallel optimization.</p>
<p>However, the actor-model-based workflow presents a programming challenge: the variable (i.e., messages) passing between actors (i.e., agents) may be placeholders without any practical meaning at the beginning. To alleviate this, AgentScope introduces the "placeholder" message, a novel data structure that allows the main process to continue without blocking, while preserving the necessary information to retrieve real values later (Fig. 8). This mechanism is particularly advantageous for multi-agent LLM systems, where execution flow must adapt to the variable output of language models.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># set up distributed agent: agent1</span>
<span class="o">...</span>
<span class="n">input_msg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Msg</span><span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;Which agent should respond next, agent2 or agent3?&quot;</span><span class="p">)</span>
<span class="c1"># the variable choice is a placeholder</span>
<span class="n">choice</span><span class="p">:</span><span class="w"> </span><span class="n">placeholder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">host_agent</span><span class="p">(</span><span class="n">input_msg</span><span class="p">)</span>
<span class="k">if</span><span class="w"> </span><span class="n">choice</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;agent2&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">agent2</span><span class="p">()</span>
<span class="k">elif</span><span class="w"> </span><span class="n">choice</span><span class="p">[</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;agent3&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">agent3</span><span class="p">()</span>
</code></pre></div>

<p>Example 9: Demonstrating the use of placeholders in control flow within AgentScope.</p>
<p>Another series of challenges arise when placeholders are used within control flow statements (e.g., if-else, loops) without their real values. An example is shown in Example 9, where a placeholder is required to make decisions. In these circumstances, AgentScope temporarily blocks the process to retrieve its actual value, thus ensuring the continuity of the control flow.</p>
<p>The actor-based distributed mode in AgentScope not only provides automatic parallel optimization and simplifies the developer experience but also demonstrates high efficiency for distributed multi-agent LLM applications. It enables developers to focus on implementing agent logic, particularly the "reply" function, without concern for underlying distributed complexities. This streamlined approach to distributed multi-agent systems can advance the field of LLMs by making it easier to develop, run, and debug sophisticated and scalable multi-agent architectures.</p>
<p>One-click deployment in AgentScope. To further ease the distributed deployment, AgentScope provides agent server and a unified message center, named AgentScope Studio.</p>
<p>Specifically, the agent server is hold in remote machines, which receives requests from AgentScope applications, and initialize their required agents in the deployed machine automatically. That means, developers can set up agent instances remotely, without programming in different machines. Such feature provides high flexibility, especially for large-scale simulations, where a large number of agent instances will be set up in remote machines.</p>
<p>For AgentScope Studio, it provides a unified display interface for distributed multi-agent applications, where messages from all distributed agents will be gathered and displayed in this studio, and allows developers</p>
<p>to forward these messages to their own display interface. Besides, AgentScope studio supports agent servers management, that is, in this studio developers can check the deployment of distributed agents, open or close agent servers remotely. With this studio, developers can manage their applications much more easily.</p>
<h1>9 Signature Applications of AgentScope</h1>
<p>As introduced in the previous sections, AgentScope is a multi-agent platform delicately designed for integrating and coordinating large-scale models in a user-friendly and fault-tolerant manner, and it is an ideal platform for a vast spectrum of applications. AgentScope can implement applications spanning from a simple single-agent vs. user dialog to complicated interactive multiplayer role-play games like werewolf. Moreover, beyond centralized deployments, AgentScope can extend to distributed conversations that involve parallel operations across multiple machines. In this section, we look into several signature applications of AgentScope that persuasively illustrate the framework's outstanding and diverse capabilities. All examples referenced herein are accessible in our GitHub repository for community use and contribution.</p>
<h3>9.1 Dialog Agents: Basic Conversation</h3>
<p>The simplest yet most fundamental application of AgentScope is the basic conversation, where the user directly interacts with the dialog agent. This application is an excellent starting point for fresh users of AgentScope to quickly capture the core message-passing mechanism in our framework.</p>
<p>The basic conversation example demonstrates the usage of two fundamental built-in agents in AgentScope, the UserAgent and DialogAgent, which facilitate inputs from the user and the responses from LLMs, respectively. Normally, as illustrated in Example 10, the first step of all applications is the initialization, which is to load the model configurations (specified in the model_configs.json file) through the init interface of AgentScope, which assigns the LLM-empowered agents with selected models. Currently, AgentScope is compatible with various platforms and APIs, including but not limited to standard OpenAI chat/embedding/DALL-E, HuggingFace, ModelScope, and a collection of locally hosted models with FastChat, vllm, and Flask. Moreover, the init interface also specifies detailed options such as file storage, logging, agent configures, etc.. With all the configurations settled, it is ready to construct the conversation flow, i.e. the message-exchanging mechanism between the user/agents, which is an essential building block for all agent-based applications. In this workflow, the AI agent will always respond to the user's input, the conversation could form an endless loop until the user decides to opt-out.</p>
<p>To implement more sophisticated applications, AgentScope facilitates pipelines, which provide a wellstructured and scalable framework for complex agent interactions (in terms of messages). As illustrated in Example 11, we can implement the basic conversation example with a sequential pipeline or loop pipeline. Readers may also refer to Appendix A for conversation history while running the demo codes.</p>
<h3>9.2 Dialog Agents: Group Conversation with Mentions</h3>
<p>Beyond the basic conversation between a user and a single dialog agent, AgentScope supports group conversations. To improve the interactivity, we introduce the "mentions" feature, which allows the user or agent to call a specific agent by simply "@agent_name". The "mention" feature is supported by applying the filter_agents function, which screens the message and identifies if any agent is mentioned in the message content.</p>
<p>In this example, we first initialize the agents involved in the conversation as shown in Example 12. Here, the characteristics of the agents can be customized in the agent_config.json file, e.g. using sys_prompt to customize the reaction style or functionality of the agents. Also, we utilize the message hub (msghub) to facilitate message deliveries among a group of agents. The msghub allows the sharing of public information (e.g. an announcement) and permits agents to broadcast messages to all agents. The conversation would end if a timeout limit is reached, or the user types in "exit".</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{\dagger}$ Co-first authors.
*Equal contribution.
${ }^{\ddagger}$ Corresponding authors, email address: {yaliang.li, bolin.ding}@alibaba-inc.com&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>