<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5635 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5635</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5635</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-117.html">extraction-schema-117</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to estimate or predict the probability or likelihood of specific future real-world scientific discoveries, including details on methods, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-258967487</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.19187v3.pdf" target="_blank">Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification (UQ) for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or computational constraints. In this work, we investigate UQ in NLG for *black-box* LLMs. We first differentiate *uncertainty* vs *confidence*: the former refers to the ``dispersion'' of the potential predictions for a fixed input, and the latter refers to the confidence on a particular prediction/generation. We then propose and compare several confidence/uncertainty measures, applying them to *selective NLG* where unreliable results could either be ignored or yielded for further assessment. Experiments were carried out with several popular LLMs on question-answering datasets (for evaluation purposes). Results reveal that a simple measure for the semantic dispersion can be a reliable predictor of the quality of LLM responses, providing valuable insights for practitioners on uncertainty management when adopting LLMs. The code to replicate our experiments is available at https://github.com/zlin7/UQ-NLG.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5635",
    "paper_id": "paper-258967487",
    "extraction_schema_id": "extraction-schema-117",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00809475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models
20 May 2024</p>
<p>Zhen Lin zhenlin4@illinois.edu 
University of Illinois at Urbana-Champaign</p>
<p>Shubhendu Trivedi shubhendu@csail.mit.edu 
Jimeng Sun jimeng@illinois.edu 
University of Illinois at Urbana-Champaign</p>
<p>Carle's Illinois College of Medicine
University of Illinois at Urbana-Champaign</p>
<p>Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models
20 May 2024C9456743AA372E5A3BC5E32BED7F8070arXiv:2305.19187v3[cs.CL]Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100. Question: When was the Vat formally opened? Reference: It was formally established in 1475 Answer: In 1475 Rating: 100. Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100. Question: In Scotland a bothy/bothie is a? Reference: House Answer: House Rating: 100. Question: Where in England was Dame Judi Dench born? Reference: York Answer: London Rating: 0. Question: [question] Reference: [reference answer] Answer: [generated response] Rating: Rate the level of consistency between the answer to the question and the reference answer, from 0 to 100. Question: who makes up the state council in russia Reference: governors and presidents Answer: governors and presidents Rating: 100. Question: when does real time with bill maher come back Reference: November 9, 2018 Answer: September 8, 2000 Rating: 0. Question: [question] Reference: [reference answer] Answer: [generated response] Rating:https: // openreviewnet/ forum? id= DWkJCSxKU5 what is the library for? Reference: research Answer: tourism Rating: 0Question: [question] Reference: [reference answer] Answer: [generated response] Rating:
Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains.However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification (UQ) for NLG.Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or computational constraints.In this work, we investigate UQ in NLG for black-box LLMs.We first differentiate uncertainty vs confidence: the former refers to the "dispersion" of the potential predictions for a fixed input, and the latter refers to the confidence on a particular prediction/generation.We then propose and compare several confidence/uncertainty measures, applying them to selective NLG where unreliable results could either be ignored or yielded for further assessment.Experiments were carried out with several popular LLMs on question-answering datasets (for evaluation purposes).Results reveal that a simple measure for the semantic dispersion can be a reliable predictor of the quality of LLM responses, providing valuable insights for practitioners on uncertainty management when adopting LLMs.The code to replicateour experiments is available at https://github.com/zlin7/UQ-NLG.1 See Section 3.2 for a discussion of uncertainty vs. confidence.</p>
<p>Introduction</p>
<p>Large language models (LLMs) have recently gained significant attention in natural language generation (NLG) (Touvron et al., 2023a;Katz et al., 2023;OpenAI, 2023;Chowdhery et al., 2022).Trained on vast amounts of data, they exhibit impressive abilities in generating human-like responses.As such advances invariably lead to wider adoption of LLM for language generation tasks, such as question-answering (QA), it is crucial to quantify their uncertainty.</p>
<p>Uncertainty quantification (UQ) is well-studied within machine learning.A reliable measure of uncertainty is important to decide when to trust a model.When a model shows high uncertainty or returns low-confidence predictions 1 , the input should either be rejected or yielded to further evaluation (Gal &amp; Ghahramani, 2016).</p>
<p>Related Works</p>
<p>The quantification of uncertainty has emerged as a significant area of research across various machine learning domains, including natural language processing (NLP).However, previous NLP studies have predominantly addressed the associated UQ challenges similarly to classification or regression methodologies (Desai &amp; Durrett, 2020;Jiang et al., 2021;Kamath et al., 2020;Wang et al., 2022;Xiong et al., 2023).For instance, Kamath et al. (2020) examines the selective question-answering task as a multiple-choice problem, reducing it to a de facto classification task rather than directly engaging with free-form generation.As recently argued in Kuhn et al. (2023), such approaches enable the application of UQ measures akin to those employed in more extensively researched classification or regression contexts, but overlook the generative aspects and distinct challenges of NLG.</p>
<p>Recently, some research started to study uncertainty quantification for NLG.One line of research involves asking the LLM itself for its confidence, with or without additional fine-tuning (Kadavath et al., 2022;Lin et al., 2022a;Mielke et al., 2020;Chen &amp; Mueller, 2023).Apart from being expensive, such approaches can be hard to generalize due to opaque training details or differences between LLMs (Kuhn et al., 2023).The work most relevant to ours is Kuhn et al. (2023), which proposes to compute the "semantic entropy" by considering the equivalence relationships amongst generated answers, and requires no training.Nonetheless, it still requires access to the token-level numerical output of the LLM, which is not always available.</p>
<p>As discussed, one of the most pertinent applications of uncertainty quantification in NLG involves the development of methods for selective NLG (or, NLG with rejection).This emerging field has limited research to date, but shares close ties with classification with rejection.Both tasks can be viewed as determining when to trust a model, whether it is a classifier or an LLM.Numerous classification with rejection methods emphasize the identification of a reliable confidence score (some of which are jointly trained with the classifier) (Corbière et al., 2019;Fumera et al., 2000;Geifman &amp; El-Yaniv, 2017;Jiang et al., 2018), which is often not only dependent on the input but also on the prediction.As existing uncertainty quantification research for NLG primarily focuses on input uncertainty (Kuhn et al., 2023;Malinin &amp; Gales, 2021), it overlooks the crucial aspect of confidence, which is essential in deciding when to trust an LLM's response (see Section 3.2 for more discussion).Recent works have explored selective classification in NLP tasks (Varshney et al., 2022a;b).However, the distinct generative nature of NLG precludes the direct adaptation of confidence measures from the classification with rejection literature.This paper serves as a step to bridge this gap and enhance the effectiveness of uncertainty quantification in NLG.</p>
<p>It is worth noting that the issue of LLMs being overconfident (Mielke et al., 2022;Si et al., 2022;Xiong et al., 2023) is orthogonal to our work, as we evaluate measures basing how they rank different samplessuch measures may then be calibrated by distribution-free uncertainty quantification methods like in Schuster et al. (2022) 2 .Giulianelli et al. (2023) also provides an interesting exploration of the inherent uncertainty in human responses for many NLG tasks, in a black-box manner.Finally, carefully designed prompts have been proposed to improve the quality of the generated responses in general (Zhou et al., 2023;Si et al., 2023;Wei et al., 2022).Orthogonal to UQ but related to selective NLG, Varshney &amp; Baral (2023) focuses on reattempting rejected samples, with the help of an auxiliary model trained on an additional dataset that predicts the correctness of the generation.This paper focuses on providing quantitative uncertainty/confidence measures, which can be used to identify high-quality generations.</p>
<p>Background</p>
<p>In this section, we describe the specific type of uncertainty under examination in the context of Natural Language Generation (NLG), while introducing terminologies used in the rest of the paper.</p>
<p>Predictive Uncertainty in NLG</p>
<p>Predictive uncertainty is a prevalent subject in probabilistic modeling, especially Bayesian literature (Malinin &amp; Gales, 2018;Gal &amp; Ghahramani, 2016).It quantifies the degree of dispersion in the predicted distribution of Y , conditioned on the input X = x.As it is generally a characteristic of the predicted distribution, we denote it as U (x), dependent only on x.For example, when Y |X = x adheres to a Gaussian distribution, the variance serves as an indicator of the uncertainty.</p>
<p>NLG can be viewed as a classification problem characterized by an exceedingly high dimension.In classification, the uncertainty is frequently measured by the entropy of the prediction (e.g.Abdar et al. (2021b); Kuhn et al. (2023); Sun et al. (2019); Wellmann &amp; Regenauer-Lieb ( 2012)).The predictive entropy is formally defined as H(Y |x) = − p(y|x) log (p(y|x))dy, which becomes the following uncertainty score in NLG:
U (x) = H(S|x) = − s p(s|x) log (p(s|x)).
(1)</p>
<p>Here, x represents the input, and the summation is taken over all potential sequences (responses).</p>
<p>Predictive uncertainty is occasionally characterized as total uncertainty, encompassing both epistemic and aleatoric uncertainty.Epistemic uncertainty (model uncertainty) can potentially be reduced with additional information, such as the use of a better model and/or additional training data (Hüllermeier &amp; Waegeman, 2021;Lahlou et al., 2023).For example, an enhanced LLM trained on more math problems could potentially generate better proofs with lower epistemic uncertainty.In contrast, aleatoric uncertainty (data uncertainty) pertains to the irreducible component of uncertainty inherently associated with the data generation process (Senge et al., 2014).In a sense, this is related to the "open-endedness" in NLG.For instance, for the question "when did the Philadelphia Eagles win their latest Super Bowl" (as of 2023), the answer could be either 2017 or 2018, as the game took place in February 2018 but belongs to the 2017 season.Some questions (x) intrinsically allow for markedly different answers (s).Decomposing aleatoric vs epistemic uncertainty is, however, often complex and typically not required for learning algorithms in real-world predictive applications (Hüllermeier &amp; Waegeman, 2021).</p>
<p>Like most existing literature, we focus on quantifying the total uncertainty3 .We would like to emphasize again that like Kuhn et al. (2023), we adopt QA datasets due to the simplicity of evaluation.Methods proposed in this paper could still potentially be applied to more open-ended tasks with no reference answers, but the question then becomes: First, can we evaluate the quality of the UQ in a scalable fashion, given that extensive human evaluation might be necessitated?Second, how do we formulate the task and what does uncertainty entail in practice, when the questions are intrinsically open-ended?These are interesting but arguably much harder and less well-defined questions that could be explored in future work.</p>
<p>Uncertainty vs. Confidence</p>
<p>Uncertainty and confidence are sometimes deemed antonyms.However, confidence scores typically bear a slightly different meaning, especially outside the Bayesian literature.Specifically, while U , as discussed in Section 3.1, only depends on x and is a property of the predicted distribution, the confidence scores are generally associated with both the input and the prediction and can be expressed as C(x, y) (Chow, 1970;Corbière et al., 2019;Jiang et al., 2018;Lin et al., 2022b).As a concrete example, for P (Y |x) = N (µ, σ2 ), the variance σ 2 is an uncertainty measure.For a particular prediction Y = y, the negative z-score − |y−µ| σ could be a confidence measure.Notice the use of a lower-case y in the notation, instead of a upper-case Y that represents a random variable.In the context of classification, one of the simplest and most used confidence measures is just the predicted probability p(Y = y|x) (Geifman &amp; El-Yaniv, 2017;Hendrycks &amp; Gimpel, 2017).The corresponding confidence score in NLG is the joint probability:
C(x, s) = p(s|x) = i p(s i |s &lt;i , x).
(2)</p>
<p>Obviously, Eq. ( 2) requires access to the original LLM4 .In Section 4, we will elaborate some alternatives that do not require such white-box access.</p>
<p>Existing literature sometimes uses uncertainty estimate U (x) to predict the correctness of a particular response s (Kuhn et al., 2023;Malinin &amp; Gales, 2021), ignoring the distinction between uncertainty and confidence.Section 5 shows that this is problematic, and confidence is a more reliable indicator of the correctness of a given response.</p>
<p>Quantifying the Uncertainty for NLG</p>
<p>In this section, we discuss several uncertainty quantification methods that can be applied to black-box LLMs.Some of these methods are sourced from the existing literature, while the majority are simple proposals of our own.The discussed methods can be structured as taking the following steps:</p>
<p>Measuring Response Similarities</p>
<p>We mainly focus on two ways to compare the similarity between a pair of responses.</p>
<p>Jaccard Similarity:</p>
<p>The Jaccard similarity is a widely employed metric for determining the similarity between two sets.It is calculated by dividing the cardinality of the intersection of the two sets by the cardinality of their union.A rule-based metric that is easy to implement, the Jaccard index has been extensively utilized in Natural Language Processing (NLP) tasks (Cronin et al., 2017;Pilehvar et al., 2013;Qurashi et al., 2020), where sentences or documents are treated as sets of words.Specifically, the Jaccard similarity between two responses s j1 and s j2 (considered as sets of words) where j 1 , j 2 ∈ [m] is computed as:
a Jaccard (s j1 , s j2 ) = |s j1 ∩ s j2 |/|s j1 ∪ s j2 |∈ [0, 1]. (3)
Despite the computation efficiency, Jaccard similarity has certain limitations, including the lack of consideration for word order and the inability to capture crucial expressions such as negation.</p>
<p>Natural Language Inference (NLI): As noted above, rule-based similarity may not effectively capture the nuances present in generated responses.A potential alternative approach involves utilizing a Natural Language Inference (NLI) classifier for this task.Numerous NLI datasets are available for training such classifiers (Williams et al., 2018;Bowman et al., 2015;Poliak, 2020).In Section 5, we will adopt the methodology outlined by Kuhn et al. (2023) and employ an off-the-shelf DeBERTa-large model (He et al., 2021) as the classifier.A NLI classifier typically predicts scores (logits) for three distinct classes: entailment, neutral, and contradiction.We can use the predicted probabilities as the similarity, denoted as a N LI (s j1 , s j2 ).</p>
<p>To obtain a continuous value ranging from 0 to 1, we apply the softmax function to the predicted logits, resulting in pcontra (s j1 , s j2 ) and pentail (s j1 , s j2 ) (both depend on x).We then define the following:
a N LI,entail (s j1 , s j2 ) = pentail (s j1 , s j2 ) a N LI,contra (s j1 , s j2 ) = 1 − pcontra (s j1 , s j2 ).(4)
It should be emphasized that obtaining pentail and pcontra is not in conflict with our primary objective of quantifying the uncertainty of a black-box LLM, for two key reasons.Firstly, the NLI model can be (and is) substantially smaller than the LLM, because NLI is a considerably simpler task, and the NLI model is not required to have the same "knowledge" as the LLM.Secondly, the LLM's function in NLG is to generate responses (sequences of tokens); thus, any additional information, such as token-level logits or embeddings, is not part of the standard output and may not be accessible to users.In contrast, the NLI model's outputs are the probabilities we utilize.</p>
<p>Estimating Uncertainty and Confidence from Similarities</p>
<p>In this section, we aim to convert similarities from Section 4.1 into uncertainty/confidence measures.Kuhn et al. (2023).The original paper proposed to use a NLI classifier to group responses into several "semantic equivalence" subsets (which form a partition of all responses).They use such "semantic equivalence" classes as well as the numerical output of the base LLM to compute the "semantic entropy"5 .While such a method cannot be applied to a black-box LLM, in their experiments they also used the number of "semantic sets" (equivalence classes), which is an uncertainty measure applicable to black-box LLMs6 .We denote this uncertainty measure as U NumSet7 .For example, for the question "What city was Zeus the patron god of?", the three responses "Olympia", "Zeus was the patron god of Olympia, Greece", and "Corinth" form two semantic sets (with the first two responses in one set).Intuitively, if in the m responses, the LLM generates more semantically different answers, then the total uncertainty is high.</p>
<p>Number of Semantic Sets was first proposed in</p>
<p>Sum of Eigenvalues of the Graph Laplacian</p>
<p>In reality, whether two responses share the same meaning is not black-and-white.In the example of Zeus above, potential responses "Olympia" and "Greece" are neither exactly the same nor completely different.Moreover, there is no guarantee that the semantic equivalence judged by the NLI model (or any other measure) is transitive.As a result, a more nuanced and "continuous" way to measure the number of meanings is preferable.</p>
<p>Since we only know the pairwise similarities a j1,j2 between response s j1 and s j2 , but not the embeddings of the generated responses, a natural choice for the clustering responses is spectral clustering.Fixing an input x, we first treat each generated response as one node and define the symmetric weighted adjacency matrix as W = (w j1,j2 ) j1,j2=1,...,m where w j1,j2 = (a j1,j2 + a j2,j1 )/2.The symmetric normalized graph Laplacian is then given by
L := I − D − 1 2 W D − 1 2 (5) D j1,j2 = j ′ ∈[m] w j1,j ′ (j 1 = j 2 ) 0 (j 1 ̸ = j 2 )(6)
A continuous version of U NumSet could be defined with λ 1 &lt; • • • &lt; λ m , the eigenvalues of L:
U EigV = m k=1 max(0, 1 − λ k ). (7)
To see the connection, between U EigV and U NumSet , we recall the classical theorem:</p>
<p>Theorem 1. (Von Luxburg, 2007) The multiplicity of the eigenvalue 0 of L is equal to the number of connected components in the graph represented by W .</p>
<p>In other words, with a binary W (two responses are either connected or not at all), the multiplicity of the zero eigenvalue coincides with the number of semantic sets (U NumSet ).With a weighted W whose entries are continuous, there is typically only one connected component.However, in spectral clustering, the distribution of the eigenvalues is typically used to determine the number of clusters (Von Luxburg, 2007) 8 .An illustration is provided in Fig. 1, with U EigV roughly corresponding to the "number of semantic meanings".In Eq. ( 7) we ignore eigenvalues larger than 1 as only the smallest few eigenvalues carry important information about the clusters (Von Luxburg, 2007).Figure 1: The distribution of the eigenvalues of the graph Laplacian generated by a N LI,entail , for two questions from trivia, as well as the 10 generated responses.On the left, the question and reference answer are "Q: Dave Gilmore and Roger Waters were in which rock group?A: Pink Floyd".We have somewhere between two and three meanings, and U EigV is slightly above 2.The question on the right is "Q: What claimed the life of singer Kathleen Ferrier?A: Cancer", and we observe more diverse responses.As a result, we see a higher U EigV (almost 6).
2 4 6 8 10 k-th eigenvalue 0.0 0.5 1.0 U eigV = 2.</p>
<p>The Degree Matrix</p>
<p>The previous two methods helped us define the uncertainty U (x) but cannot assign a confidence score to each generated response.We utilize the degree matrix D in Eq. ( 6) to define both metrics, as D already contains relevant information: A node with high degree is well-connected to other nodes, suggesting that it lies in a confident region of the LLM.We thus define uncertainty estimate U Deg (x) and confidence score C Deg (x, s j ) as
U Deg (x) = trace(mI − D)/m 2 C Deg (x, s j ) = D j,j /m. (8)
Here, we assume W j1,j2 ∈ [0, 1].U Deg can also be interpreted as the average pairwise distance.</p>
<p>Eccentricity Recall that one challenge from earlier is that we only have the similarity (or distance) between different responses, but do not know their actual embedding space.The graph Laplacian, however, can provide us with coordinates for the responses.Denote u 1 , . . ., u k ∈ R m as the smallest k eigenvectors of L, then an informative embedding of s j is simply et al., 2001;Von Luxburg, 2007).
v j = [u 1,j , . . . , u k,j ] (Ng
As a result, we could use the average distance from center as the uncertainty measure, and each response's distance from the center as the (negative) confidence.Formally, the "eccentricity" estimates are:
U Ecc (x) = ∥[v ′ ⊤ 1 , . . . , v ′ ⊤ m ]∥ 2 C Ecc (x, s j ) = −∥v ′ j ∥ 2 (9)
where
v ′ j = v j − 1 m m j ′ =1 v j ′
represents the offset from the average embedding.Ren et al. ( 2023) uses a similar idea for OOD detection for LLMs, which however requires white-box access to the original language model.Fig. 2 illustrates a sample embedding (from coqa).</p>
<p>Remark:</p>
<p>The confidence scores C Ecc and C Deg in the current form are hardly interpretable.For example, C Ecc could have a value of 10 or 0.4.In practice, they could easily be calibrated to match the probability of whether the answer is correct.In Appendix C.5 we show that with simple calibration these confidence scores could faithfully reflect the probability of correct answer.In this section, we evaluate the quality of uncertainty and confidence measures proposed in Section 4.</p>
<p>Experiments</p>
<p>Setup for experiments</p>
<p>Datasets Following Kuhn et al. (2023), we use the open-book conversational question answering dataset, CoQA (coqa) (Reddy et al., 2019), and the closed-book QA dataset, TriviaQA (trivia) (Joshi et al., 2017).In addition, we also use the more challenging closed-book QA dataset, Natural Questions (nq) (Kwiatkowski et al., 2019).We use the development split of coqa with 7,983 questions, the validation split of nq with 3,610 questions, and the validation split of the rc.nocontext subset of trivia with 9,960 (de-duplicated) questions.We repeat all experiments 10 times, each time with a random subset of 1,000 questions as the calibration set for hyper-parameters of U and C measures, and test the performance on the remaining data.We report the mean and standard deviation of all evaluation metrics (see Section 5.2).</p>
<p>LLMs</p>
<p>We followed Kuhn et al. (2023) and include OPT (Zhang et al., 2022) in our experiments.We also test three more recent models that have demonstrated superior performance: LLaMA (Touvron et al., 2023a), LLaMA2 (Touvron et al., 2023b) and the black-box gpt-3.5-turboserved by OpenAI via an API9 .For both LLaMA and OPT, we use the 13B versions.We use the default generation configs for all models.</p>
<p>Baselines We compare all uncertainty and confidence measures listed in Section 4, including NumSet, Deg, Ecc and EigV.Deg, Ecc and EigV are constructed with three versions using a Jaccard , a N LI,entail , a N LI,contra (with suffix J/E/C, respectively).We also include "lexical similarity" (U LexiSim ) from Kuhn et al. (2023) which measures the average rougeL between responses.Note that only U NumSet and U LexiSim have appeared in literature before (Kuhn et al., 2023).To benchmark these methods with the existing literature, we include two white-box baselines for non-GPT LLMs:</p>
<p>• Semantic Entropy (SE) (Kuhn et al., 2023): This uncertainty estimate (U SE ) groups answers like NumSet, and then computes the entropy over the aggregated semantic sets.This requires access to the token-level logits from the base LLM.• P(true) (Kadavath et al., 2022): This confidence measure C P(true) estimates the probability that a model's generation is correct by asking the model itself10 .We follow the prompts provided in Kuhn et al. (2023); Kadavath et al. (2022), and convert C P(true) to an uncertainty estimate U P(true) by taking the average over all responses.</p>
<p>Evaluation</p>
<p>Evaluation Metrics: Effective uncertainty measures must reflect the reliability of LLM responses, with higher uncertainty and lower confidence more likely leading to incorrect generations.Following prior works (Kuhn et al., 2023;Band et al., 2022), we evaluate the quality of the proposed UQ measures by using them to predict whether a generation is correct or not, and compute the Area Under Receiver Operating Characteristic (AUROC) for such prediction.Specifically, if we denote acc i,j = 1{s i,j correctly answers x i },
we compute average AUROC using C(x • , s •,j ) to predict acc •,j for j ∈ [m]. Unless otherwise noted, m = 20.
AUROC however bears two limitations: it can only be applied on binary labels, and its value is hard to interpret.Thus, we use Area Under Accuracy-Rejection Curve (AUARC) (Nadeem et al., 2009), as an alternative evaluation metric11 .Illustrated in Fig. 3, Accuracy-Rejection Curve (ARC) is computed as the average target (i.e.accuracy) when we reject a subset of the samples basing on predictor (i.e.U or C).As we reject more high-uncertainty samples, the remaining samples should have higher accuracy.The "Oracle" (max) AUARC is achieved by directly using the target as the predictor, while the AUARC of a random predictor equals to the base accuracy without rejection.</p>
<p>Correctness of Generations:</p>
<p>We assess the correctness of the generated responses automatically using gpt-3.5-turbofrom the OpenAI API.This model is provided with the question, reference answer, and LLM-generated response, and it assigns a correctness score between 0 and 1. Responses with scores above 0.7 are deemed correct.Like Kuhn et al. (2023) (which used rougeL score as a heuristic to evaluate the correctness of generated responses), we also perform human verification on the correctness of the autogenerated judgment by gpt-3.5-turboand found that the accuracy is about 0.95 (see the Appendix for more details).</p>
<p>Results</p>
<p>Uncertainty Measures:</p>
<p>We first evaluate the uncertainty measures by using them as the predictor to predict expected accuracy (shorthanded as U+EA), estimated with Ê[acc i ] = 1 m m j=1 acc i,j (m=20).The AUARCs are shown in Table 1 (AUROC is skipped as expected accuracy is not binary).For readability, we include only a N LI,entail which empirically performs the best, with full experiment results in the Appendix.We hypothesize that a N LI,entail outperforms a N LI,contra because even if generations do not contradict each other, they could be still mostly meaningless, whereas generations that actually align could indicate low uncertainty.A such example could be found in Fig. 5 (see more discussion in Appendix B.6). Deg, Ecc, and EigV perform similarly as an uncertainty measure.In some cases, such as trivia(llama), the AUARC (for Deg) is close to the upper-bound (Oracle).In general, we found that the choice of similarity (E-entailment, C-contra, J-Jaccard) matters more than the choice of Deg, Ecc, EigV. Figure 3: The ROC (left) computed using the accuracy of the 1st generated response and the corresponding confidence C (when available, otherwise U ), for LLaMA on trivia.ARC (right) is computed using U and expected accuracy.(For ARC, average accuracy is noisy at high rejection rate due to small sample size.)The suffix (E) denotes for a N LI,entail .Different ways to construct U or C from a N LI,entail make a relatively small difference, but are all noticeably better than the baselines (including the white-box baselines).The ARC suggests that if we select only the top 50% samples using, for example, Deg (E), we could improve the accuracy from 62% to around 90%.A small m like 3 already greatly improves the accuracy in selective generation, compared with no rejection or rejection based on random noise (Base Accuracy).In general, confidence-based measures (Deg and Ecc) achieve better performance in the C+IA setting, confirming the intuition that response-dependent confidence measures predict the quality of individual responses better.</p>
<p>Confidence Measures: To evaluate confidence measures, we compute AUROC and AUARC, and take the average across all m generations.We refer to this as the "C+IA" (Confidence + Individual Accuracy) setting.The results are reported in Table 2 (with AUROCs deferred to the Appendix).Note that Ecc and Deg are actual confidence measures and EigV is an uncertainty measure (not response-specific).As a result, able to further distinguish the quality of each response, Deg and Ecc typically observe higher performance in Table 2 compared with Table 1, while the uncertainty-only measures like EigV stay the same, echoing the discussion in Section 3.2.</p>
<p>Varying the Number of Generations:</p>
<p>In Fig. 4, we report results when we vary the number of generations m, for trivia and LLaMA.It is observed that even with m = 3, the confidence or uncertainty measures already achieve good performance.As m increases, the quality of C and U typically increases.Note that for AUARC(C+IA), only the confidence measure (C Deg and C Ecc ) improves, and the other measures, being response-agnostic uncertainty measures, stay the same.NumSet seemingly deteriorates as m increases in this plot, because it seems to predict the quality of the first few responses (for LLaMA+trivia only) better.As a result, as we take the average of more samples, the higher performance flattens out.The trend is different for other settings, and is flat in general when considering all data and LLMs.A full presentation of the results varying the number of generations could be found in Appendix C.1.In practice, one could choose the quality-computation trade-off by picking a number of generations that is appropriate.</p>
<p>Q: why was the plague that struck athens so devastating A: close quarters and poor hygiene 10 Generations: There's no cure a large flock of birds because the plague was unknown at the time The plague was devastating then because the diseases were unknown and a mystery to the \ ancient world and the there where numerous diseases spread it was so short and caused so much quaratic Athens was located within a part of Greece that was full of fleas The plague of Athens was a pandemic that hit the Greek city of Athens and surrounding \ areas in 429-428 BC Soldiers returning from battle because they were because it happened just as farming season began</p>
<p>Conclusion and Discussion</p>
<p>In this paper, we studied the problem of uncertainty quantification in black-box LLMs, with an emphasis on assessing the quality of generated responses to a diverse set of questions.We developed and tested a range of easily implementable uncertainty and confidence measures.Our results demonstrated that using similarity as determined by an NLI model, along with simple measures that measure dispersion based on these similarities, can effectively identify difficult questions and confident answers, often outperforming existing white-box benchmarks.The objective of this paper is to provide practitioners with simple and effective methods to manage uncertainty, reduce incorrect answers (possibly by excluding them), and apply LLMs with confidence.</p>
<p>To conclude, we also note some limitations of our work and challenges remaining to be addressed.Currently, the evaluation of uncertainty/confidence measures is restricted to question-answering tasks, because it is generally difficult to acquire labels on whether a response is "reliable" or not for open-ended conversations.</p>
<p>Even for the datasets used in our paper, while our use of GPT as the judge improves upon previous heuristics (of using rougeL), the evaluation can be improved if human labels are used.Moreover, we currently evaluate uncertainty and confidence separately.Methods that consider both have the potential to predict the quality of generations better.Finally, the uncertainty and confidence measures in this work (and those mentioned in Section 2) reflect those in the "posterior" represented by the LLM.This has two implications: When the sampling temperature is 0 (i.e.greedy decoding), all methods will give degenerate results, and one might resort to white-box methods or external information to quantify the uncertainty.Also, our methods may not identify factual errors propagated from the training corpus or identify when the LLM is being overconfident (which is related to calibration, an orthogonal research topic).We hope this work could serve as a foundation for future research in these directions.</p>
<p>Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al.Opt: Open pre-trained transformer language models.arXiv preprint arXiv:2205.01068,2022.</p>
<p>Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto.Navigating the grey area: Expressions of overconfidence and uncertainty in language models.ArXiv, abs/2302.13439,2023.</p>
<p>A Proof for Theorem 1</p>
<p>Theorem 1 is the same as Proposition 4 in Von Luxburg (2007) (Note the L defined in Theorem 1 is equivalent to L sym in Von Luxburg ( 2007)).We briefly recover the proof below, beginning with a proposition:
Proposition 1. Von Luxburg (2007) For every f ∈ R m f ⊤ Lf = 1 2 m i,j=1 w i,j f i √ d i − f j d j 2(10)
Proposition 1 can be verified by simple algebra.Now, suppose the graph has k connected components.We first find k orthonormal eigenvectors.This can be done by letting v 1 , . . ., v k be k vectors such that
v l (j) =      √ dj j ′ ∈S l d j ′ j ∈ S l 0 j ̸ ∈ S l (11)
It is easy to verify that ∀l = 1, . . ., k, ∥v l ∥= 1.For l 1 ̸ = l 2 , ⟨v l1 , v l2 ⟩ = 0 because S l2 and S l1 are disjoint.Finally, the i-th entry of
j ′ ∈S l d j ′ Lv l is 0 if i ̸ ∈ S l ,andd i − 1 √ d i j w ij 1 √ d i d i = 0 (12) if i ∈ S l (because L = I − D − 1 2 W D − 1 2 ).
Now, we argue that we cannot find another vector v that is a zero eigenvector.By Proposition 1 v must be be a scaled version of v l on component S l .w.l.o.g., assume v(j) ̸ = 0, with j ∈ S l .Then, by Proposition 1, ∃c such that ∀j ′ ∈ S l , v(j ′ ) = cv l (j ′ ).This means ⟨v, v l ⟩ ̸ = 0. Thus, we cannot find another zero eigenvector.</p>
<p>B Additional Experiment Details and Ablations</p>
<p>B.1 Prompts for Response Generation</p>
<p>TriviaQA: We use the exact prompt in Touvron et al. (2023a) for TriviaQA, which is reproduced below:</p>
<p>Answer these questions: Q: In Scotland a bothy/bothie is a? A: House Q: [Provided question] A:</p>
<p>Natural Questions is a much harder dataset than TriviaQA, so we use the same 5-shot prompt version of the prompt in Touvron et al. (2023a) (with 5 questions randomly picked from the training set).</p>
<p>CoQA: For CoQA, we use the code provided by Kuhn et al. (2023) to prepare the data12 .We provide the prompts below for convenience: where additional question-answer pairs are preceding turns of the conversation about the paragraph consisting of questions and reference answers.</p>
<p>Verifying the correctness of GPT evaluations</p>
<p>We sample 33 samples per dataset and model (OPT, LLaMA, GPT) and perform a human evaluation of the quality of the GPT judgement.That is, we compare the human judgement on whether a generated response is correct or not with the GPT's judgement, like in Kuhn et al. (2023).In Table 3, we show the breakdown of the accuracy by datasets.</p>
<p>Table 3: The accuracy of the GPT evaluation on the correctness of the responses, measured by the authors.For example, for trivia, the human evaluations and the GPT evaluations are aligned on 97 out of the 99 question/answer pairs, leading to an accuracy of 98.0.</p>
<p>coqa trivia nq</p>
<p>Accuracy of GPT evaluation 90.9 98.0 95.9</p>
<p>We also include a few typical examples where the GPT evaluation is more reliable than the rougeL evaluation used in Kuhn et al. (2023) • "Q: Were they nice to the other critters?A: no".GPT correctly identifies that "They were mean to the other animals" is a correct answer, but the rougeL metric does not capture this logic.• "Q: Who created the immunity plan?A: the Gulf Cooperation Council".GPT correctly identities that "GCC" is a correct answer (an abbreviation of the Gulf Coorperation Councol", but rougeL cannot identify this mechanically).• "Q: when was the last bear killed in the uk A: c. 1000 AD".GPT classifies the response "The last bear in the UK was killed over a thousand years ago, in the 9th century, so there is no specific date available" as correct, but rougeL fails to do so.</p>
<p>The GPT evaluation also introduces its own problems, though.For example, when it is used to evaluate its own response to the question "when did it become law to stand for the national anthem" with reference answer "6/22/1942", it rates "There is no federal law that mandates standing for the national anthem in the United States" as 100.However, we believe it is using its own knowledge here and largely ignores the reference answer.Such problems could potentially be improved with better prompts.</p>
<p>B.4 Hyper-parameters for Uncertainty/Confidence Measures</p>
<p>For all U and C measures involving a N LI,entail and a N LI,contra , we need to choose a temperature for the NLI model.The temperature is chosen from 0.1, 0.25, 0.5, 1, 3, 5, and 7.For U Ecc and C Ecc , we also need to choose a cutoff for eigenvalues.For simplicity we use the same threshold for each experiment/dataset, and the threshold is chosen from 0.4, 0.5, 0.6, 0.7, 0.8, and 0.9.</p>
<p>B.5 Computational Requirements</p>
<p>We perform all experiments on a machine with 2x AMD EPYC Milan 7513 CPU, 512 GB RAM, 8x A6000 GPUs.Generating 20 responses with OPT/LLaMA for coqa, nq, trivia takes from 2.5 to 15 hours, or from 2 to 11 seconds per question.CoQA takes the longest due to the story input.Running the NLI model for 20 responses (assuming the worst case that no two responses are exactly the same, which means 380 comparisons) takes about 0.8 seconds.</p>
<p>B.6 Full Experiment Results</p>
<p>In the main text, we present only results for a N LI,entail .We show results for a Jaccard and a N LI,contra in Tables 4 to 6.We observe that with the default generation configs, the choice of similarity measure (a N LI,contra , a N LI,entail , a Jaccard ) seems to play a bigger role than the construction of U and C measures.a N LI,entail consistently performs the best, especially on nq.This is likely due to the nature of the questions.For example, for questions starting with "why", for a collection of low-quality random answers, a N LI,contra does not consider them as high-uncertainty because they don't actually contradict each other, but a N LI,entail captures such high-uncertainty case, as illustrated by Fig. 5. On the other hand, for the more factual questions like in Fig. 6, both all similarity measures agree on high-uncertainty cases, as there are few other ways to state the correct answer.It will be interesting to see more future research on the choice of the appropriate similarity for different tasks (which could involve different types of questions).</p>
<p>C Additional Results</p>
<p>C.1 Number of Generations</p>
<p>In the main text, we include results with only m = 20.Here, we show the full results with m = 3, 5, 10, in Tables 7 to 9. The results are very similar to when m = 20: In general, a N LI,entail seems to provide the best results, and the choice of similarity seems more important than the choice of construction (Ecc,Deg,EigV).As m increases, the performance typically increases as well.With three generations (m = 3) we already see noticeable performance boost if we perform selective generation (AUARC).</p>
<p>C.2 Uncertainty + Individual Accuracy</p>
<p>We present the result of using uncertainty to predict individual accuracy in Table 10.This is similar to the practice of Kuhn et al. (2023); Malinin &amp; Gales (2021).Formally, this setting is U (x) + Individual Accuracy:</p>
<p>We use the uncertainty estimated on m samples for each of the m samples to predict each answer's accuracy.For AUROC, this means
AU ROC U+IA = m j=1 AU ROC([−U (x 1 ), . . . , −U (x N )], [acc 1,j , . . . , acc N,j ]).(13)</p>
<p>C.3 Effects of Sampling Temperature of LLM</p>
<p>In the main text, we use the default generation config from hugginface or OpenAI's API for the LLMs.In Tables 7 to 9, the temperature is 1 for all models except for LLaMA2 (which uses 0.6) and top_p is 1 for all models except for LLaMA2 (which uses 0.9).Being sampling-based uncertainty quantification methods, our proposed measures obviously are affected by the temperature of the base LLM, and as we noted in the main paper, when very low temperature we do not expect such sampling-based black-box methods to work at all.Thus, in Tables 11 to 13, we lower the temperature to 0.5 and observe the effects.</p>
<p>Lower temperature leads to a less divergent posterior, which makes it more difficult for sampling based methods to get an estimate of uncertainty or confidence.As a result, compared with results at higher</p>
<p>Figure 2 :
2
Figure 2: An example of the 2D UMAP (McInnes et al., 2018) projection of the embeddings used in Ecc for 20 responses.The question and answer are "Q: What is the bakery's name?A:the Dominique Ansel Bakery".Similar answers tend to live closely together, justifying the use of distance-based uncertainty and confidence measures (U Ecc and C Ecc ).</p>
<p>Figure 4 :
4
Figure 4: AUARC for confidence (left) and uncertainty (right), with different number of sampled responses.A small m like 3 already greatly improves the accuracy in selective generation, compared with no rejection or rejection based on random noise (Base Accuracy).In general, confidence-based measures (Deg and Ecc) achieve better performance in the C+IA setting, confirming the intuition that response-dependent confidence measures predict the quality of individual responses better.</p>
<p>Figure 5 :
5
Figure 5: An example where contradiction-based U EigV indicates low uncertainty, yet the generated responses are mostly low-quality.Entailment-based similarity suggests high uncertainty.</p>
<p>[</p>
<p>The provided context paragraph] [additional question-answer pairs] Q: [Provided question] A:</p>
<p>Fig. 7 also provides an example showing why semantic-based similarities are preferred over lexical-based ones.</p>
<p>Figure 7 :
7
Figure 7: An example where purely lexical similarity performs worse than semantic-based ones.Although the generations are phrased differently, they all convey the exact same meaning.</p>
<p>139
Pink Floyd Pink Floyd in Edinburgh Pink Floyd1.0U eigV = 5.984Leukemia Low Blood Pressure Cervical cancerShamblesCancer in 1953 at 41Pink Floyd Pink Floyd0.5Breast cancer TuberculosisPink FloydCancerPink Floyd Pink Floyd Pink Floyd0.024 k-th eigenvalue 68 10Leukaemia Cancer (in 1953 at age 41) Throat cancer</p>
<p>Table 1 :
1
AUARC when using U (x) to predict expected accuracy.The best black-box methods are in bold and the best overall is underscored.In general, our proposed uncertainty measures perform significantly better than the baselines, sometimes outperforming the white-box methods.
trivia(llama) trivia(llama2) trivia(opt)trivia(gpt) coqa(llama) coqa(llama2) coqa(opt)coqa(gpt)nq(llama)nq(llama2)nq(opt)nq(gpt)Random 61.18±0.0776.24±0.1125.75±0.12 87.42±0.08 62.46±0.11 78.71±0.13 53.81±0.18 79.76±0.14 23.63±0.36 44.13±0.688.60±0.1862.72±0.39Oracle87.03±0.0596.50±0.0354.72±0.19 99.09±0.01 86.29±0.06 96.92±0.03 79.41±0.14 97.45±0.03 47.67±0.55 77.62±0.63 23.28±0.43 90.65±0.21BaselinesNumSet 78.78±0.17 LexiSim 80.32±0.0691.37±0.12 91.73±0.1339.46±0.29 93.18±0.11 67.58±0.17 83.66±0.17 60.41±0.27 80.69±0.22 28.18±0.55 57.55±0.98 10.36±0.27 68.92±0.74 45.68±0.24 94.69±0.15 78.17±0.15 89.29±0.16 71.46±0.21 86.60±0.13 40.15±0.70 61.88±1.14 15.92±0.55 73.40±0.74
OursEigV (E) 85.01±0.08 93.07±0.1751.54±0.2195.16±0.2181.27±0.1290.21±0.2473.46±0.20 88.80±0.1040.42±0.6763.58±0.9618.20±0.4475.17±0.80Ecc (E) 84.66±0.0693.12±0.1251.42±0.2295.21±0.2280.55±0.1490.02±0.2272.73±0.20 88.67±0.1340.38±0.6863.41±0.9218.82±0.4675.40±0.49Deg (E) 85.27±0.</p>
<p>06 93.05±0.14 52.06±0.21 95.00±0.23 81.50±0.15 90.18±0.22 73.91±0.19
88.63±0.23 41.07±0.69 63.41±1.03 18.43±0.48 74.35±0.78White-boxSE P(true) 64.98±0.10 79.15±0.0893.99±0.06 82.53±0.0951.11±0.20 20.25±0.11--78.83±0.16 89.29±0.17 70.75±0.21 64.04±0.18 79.92±0.17 50.23±0.23--36.03±0.54 62.40±0.98 18.40±0.44 24.72±0.42 44.25±0.65 7.63±0.22--</p>
<p>Table 2 :
2
AUARC when using C(x, s) to predict individual accuracy.The best black-box methods are in bold and the best overall is underscored.Compared with Table1, the AUARC for confidence measures (Deg and Ecc) generally improve, as they could discriminate the quality of each response.
trivia(llama) trivia(llama2) trivia(opt)trivia(gpt) coqa(llama) coqa(llama2) coqa(opt)coqa(gpt)nq(llama)nq(llama2)nq(opt)nq(gpt)Random 61.18±0.0776.24±0.1125.75±0.12 87.42±0.08 62.46±0.11 78.71±0.13 53.81±0.18 79.76±0.14 23.63±0.36 44.13±0.688.60±0.1862.72±0.39Oracle91.24±0.0396.92±0.0360.68±0.16 99.17±0.01 91.85±0.05 97.55±0.03 87.15±0.11 97.80±0.03 57.69±0.53 80.22±0.56 29.65±0.45 91.97±0.18BaselinesNumSet 78.78±0.17 LexiSim 80.32±0.0691.37±0.12 91.73±0.1339.46±0.29 93.18±0.11 67.58±0.17 83.66±0.17 60.41±0.27 80.69±0.22 28.18±0.55 57.55±0.98 10.36±0.27 68.92±0.74 45.68±0.24 94.69±0.15 78.17±0.15 89.29±0.16 71.46±0.21 86.60±0.13 40.15±0.70 61.88±1.14 15.92±0.55 73.40±0.74EigV (E) 85.01±0.0893.07±0.1751.54±0.21 95.16±0.21 81.27±0.12 90.21±0.24 73.46±0.20 88.80±0.10 40.42±0.67 63.58±0.96 18.20±0.44 75.17±0.80OursEcc (E) 88.17±0.11 93.21±0.07 55.82±0.21 95.11±0.18 84.62±0.13 90.21±0.25 78.14±0.20 88.42±0.19 45.78±0.69 63.89±1.08 21.00±0.49 75.43±0.67Deg (E) 88.86±0.05 93.19±0.11 56.11±0.19 94.94±0.16 84.60±0.15 89.75±0.19 77.83±0.20 88.02±0.31 46.54±0.69 63.55±1.01 21.30±0.50 74.67±0.64White-boxSE P(true) 67.27±0.11 79.15±0.0893.99±0.06 82.18±0.0851.11±0.20 20.89±0.12--78.83±0.16 89.29±0.17 70.75±0.21 66.23±0.19 79.55±0.16 49.84±0.23--36.03±0.54 62.40±0.98 18.40±0.44 27.62±0.46 44.34±0.64 8.07±0.21--</p>
<p>Table 4 :
4
AUARC, U (x) + Expected Accuracy, with m = 20 (similar to Table1).The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 20trivia(llama)61.18±0.07 87.03±0.05 78.78±0.17 80.32±0.0684.97±0.0684.48±0.0785.04±0.0685.01±0.0884.66±0.0685.27±0.06 83.94±0.0783.74±0.0784.29±0.0679.15±0.08 64.98±0.10trivia(llama2) 76.24±0.11 96.50±0.03 91.37±0.12 91.73±0.1393.07±0.1693.12±0.0693.23±0.0893.07±0.1793.12±0.1293.05±0.1492.74±0.0692.62±0.0992.60±0.1093.99±0.06 82.53±0.09trivia(opt)25.75±0.12 54.72±0.19 39.46±0.29 45.68±0.2450.16±0.2350.37±0.2450.52±0.2251.54±0.2151.42±0.2252.06±0.21 50.60±0.2150.85±0.2051.49±0.2051.11±0.20 20.25±0.11trivia(gpt)87.42±0.08 99.09±0.01 93.18±0.11 94.69±0.1594.82±0.2394.82±0.1994.92±0.1395.16±0.21 95.21±0.22 95.00±0.23 94.83±0.1594.70±0.1794.62±0.21--coqa(llama)62.46±0.11 86.29±0.06 67.58±0.17 78.17±0.1580.85±0.1178.81±0.1280.86±0.1281.27±0.1280.55±0.1481.50±0.15 79.38±0.1379.60±0.1380.39±0.1578.83±0.16 64.04±0.18coqa(llama2)78.71±0.13 96.92±0.03 83.66±0.17 89.29±0.1689.73±0.3189.67±0.5589.71±0.3890.21±0.24 90.02±0.22 90.18±0.22 89.28±0.2489.12±0.1689.25±0.2289.29±0.17 79.92±0.17coqa(opt)53.81±0.18 79.41±0.14 60.41±0.27 71.46±0.2172.87±0.2070.77±0.2272.92±0.2073.46±0.2072.73±0.2073.91±0.19 71.60±0.2271.43±0.2272.25±0.2270.75±0.21 50.23±0.23coqa(gpt)79.76±0.14 97.45±0.03 80.69±0.22 86.60±0.13 88.72±0.1388.11±0.2588.70±0.17 88.80±0.1088.67±0.1388.63±0.2387.66±0.2988.13±0.1988.08±0.19--nq(llama)23.63±0.36 47.67±0.55 28.18±0.55 40.15±0.7036.99±0.6434.29±0.6037.27±0.6440.42±0.6740.38±0.6841.07±0.69 40.07±0.7039.78±0.6740.17±0.6436.03±0.54 24.72±0.42nq(llama2)44.13±0.68 77.62±0.63 57.55±0.98 61.88±1.14 62.89±1.13 62.99±0.96 63.07±1.13 63.58±0.96 63.41±0.92 63.41±1.03 62.21±0.9461.65±0.9661.97±0.9062.40±0.98 44.25±0.65nq(opt)8.60±0.1823.28±0.43 10.36±0.27 15.92±0.5515.05±0.4614.21±0.4315.08±0.4718.20±0.4418.82±0.46 18.43±0.48 17.98±0.50 18.38±0.49 18.56±0.48 18.40±0.447.63±0.22nq(gpt)62.72±0.39 90.65±0.21 68.92±0.74 73.40±0.74 75.49±0.66 75.04±0.70 75.21±0.76 75.17±0.80 75.40±0.4974.35±0.7873.75±0.8973.11±0.7772.95±0.88--</p>
<p>Table 5 :
5
AUARC, C(x, s) + Individual Accuracy, with m = 20 (similar to Table2).The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 20</p>
<p>Table 6 :
6
AUROC, C(x, s) + Individual Accuracy, with m = 20.The best black-box methods are in bold and the best overall is underscored.The conclusions are similar to Table8, with confidence measures based on a N LI,entail (E) performing the best.Figure 6: An example where contradiction-based U EigV indicates high uncertainty.In this case, the entailment-based and Jaccard-based similarity also indicates high uncertainty.
BaselinesOursWhite-boxNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 20trivia(llama)78.79±0.13 75.92±0.0486.29±0.0792.61±0.0693.69±0.0686.47±0.1493.51±0.3594.60±0.05 84.58±0.08 90.14±0.22 91.45±0.07 76.61±0.10 59.21±0.09trivia(llama2) 86.02±0.11 82.77±0.1089.28±0.1689.79±0.1489.97±0.0989.18±0.1989.78±0.0889.38±0.1687.60±0.05 87.07±0.32 86.93±0.09 89.75±0.07 65.05±0.14trivia(opt)75.02±0.16 74.49±0.1883.14±0.1291.55±0.0789.64±0.0986.09±0.1092.71±0.3092.83±0.08 85.16±0.10 89.38±0.07 90.60±0.06 86.19±0.09 41.76±0.11trivia(gpt)74.69±0.24 78.18±0.1780.90±0.5080.92±0.5480.88±0.4981.78±0.25 81.80±0.2280.50±0.2279.37±0.18 77.58±0.24 77.42±0.19--coqa(llama)59.34±0.14 71.09±0.1776.78±0.1176.24±0.1784.47±0.1177.65±0.0985.07±0.1284.91±0.1574.43±0.12 81.34±0.12 83.13±0.11 73.32±0.16 55.39±0.17coqa(llama2)63.56±0.25 73.69±0.2876.88±0.4377.19±0.2577.41±0.3277.94±0.31 78.37±0.6076.76±0.3374.49±0.29 73.86±0.26 74.97±0.29 73.02±0.31 50.88±0.27coqa(opt)59.72±0.08 71.81±0.1574.67±0.1476.24±0.1382.37±0.2875.61±0.1384.25±0.1284.06±0.0973.16±0.13 80.70±0.12 82.02±0.10 71.68±0.13 45.82±0.15coqa(gpt)52.44±0.08 63.39±0.19 72.26±0.2769.29±0.1770.64±0.2572.17±0.1770.40±0.3869.36±0.8768.18±0.21 67.46±0.19 68.57±0.19--nq(llama)60.61±0.31 75.19±0.3269.41±0.3872.30±0.3573.35±0.3975.05±0.3283.37±0.3183.99±0.29 75.40±0.36 81.27±0.28 82.34±0.34 69.79±0.26 56.35±0.40nq(llama2)71.02±0.41 72.41±0.4475.26±0.8776.07±0.4676.27±0.5276.50±0.4177.13±0.4876.57±0.4674.14±0.38 73.46±0.46 74.07±0.42 73.46±0.40 52.12±0.30nq(opt)60.45±0.47 70.66±0.6968.01±0.5874.78±0.4371.77±0.4777.03±0.3283.61±0.29 83.51±0.30 77.55±0.45 79.23±0.75 82.25±0.41 79.16±0.26 46.74±0.51nq(gpt)62.88±0.51 65.32±0.62 69.99±0.66 69.71±0.56 69.34±0.4669.05±0.6369.44±0.6967.81±0.6066.40±0.69 63.38±0.97 63.68±0.71--</p>
<p>Table 7 :
7
AUARC, U (x) + Expected Accuracy, with m = 3, 5, 10 (similar to Table1).The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 3trivia(llama)61.13±0.07 87.00±0.05 76.51±0.1577.79±0.1379.65±0.1579.63±0.2979.62±0.1679.84±0.1579.54±0.1679.86±0.1978.98±0.1478.15±0.2378.99±0.1177.53±0.11 64.32±0.08trivia(llama2) 76.24±0.11 96.50±0.03 87.49±0.2288.38±0.2088.89±0.23 88.87±0.15 88.89±0.30 88.85±0.27 88.69±0.20 88.81±0.2588.57±0.2988.29±0.3388.59±0.2793.34±0.07 82.25±0.09trivia(opt)25.45±0.11 54.20±0.18 39.64±0.2941.08±0.1744.06±0.1944.95±0.2144.23±0.2045.45±0.2144.97±0.1745.49±0.2144.02±0.1943.55±0.2044.11±0.1848.87±0.18 19.92±0.10trivia(gpt)87.42±0.08 99.09±0.01 91.17±0.11 92.38±0.1292.26±0.2792.36±0.3192.22±0.3492.57±0.23 92.58±0.25 92.53±0.1692.28±0.0992.18±0.2592.28±0.12--coqa(llama)62.46±0.11 86.29±0.06 67.19±0.1675.28±0.1776.29±0.1375.90±0.2076.30±0.1776.96±0.1876.21±0.2577.00±0.1976.05±0.1775.42±0.2676.11±0.2177.68±0.16 63.75±0.20coqa(llama2)78.71±0.13 96.92±0.03 82.29±0.1686.51±0.2186.82±0.3086.57±0.2786.99±0.23 86.97±0.2986.71±0.2686.98±0.3186.48±0.2386.40±0.3586.44±0.3088.82±0.17 79.82±0.16coqa(opt)53.78±0.17 79.39±0.13 59.44±0.1966.15±0.1766.94±0.2866.94±0.1866.95±0.2267.82±0.1767.07±0.2567.78±0.2766.56±0.2265.72±0.3666.52±0.2468.96±0.20 50.06±0.23coqa(gpt)79.76±0.14 97.45±0.03 80.22±0.2285.72±0.2686.46±0.2585.44±0.3986.41±0.29 86.32±0.3586.08±0.3186.43±0.2885.87±0.2386.32±0.2385.98±0.20--nq(llama)23.54±0.34 47.57±0.52 27.77±0.3533.97±0.5632.79±0.5632.98±0.4232.84±0.5435.30±0.4933.98±0.6235.32±0.5634.68±0.6133.35±0.6634.74±0.5833.49±0.48 24.66±0.38nq(llama2)44.13±0.68 77.62±0.63 53.46±0.7457.74±1.1558.05±1.0057.64±0.8658.25±1.10 58.61±0.77 57.94±0.87 58.40±0.7957.74±1.0957.20±1.1157.71±1.0560.65±0.95 44.02±0.66nq(opt)8.64±0.1823.32±0.42 10.34±0.2412.32±0.3712.94±0.3813.80±0.4513.03±0.4014.90±0.4314.40±0.4314.96±0.4613.99±0.3913.61±0.4714.05±0.3817.34±0.387.68±0.19nq(gpt)62.72±0.39 90.65±0.21 66.85±0.9770.02±0.8570.97±0.85 70.83±0.82 71.06±0.87 70.93±0.9170.14±1.1470.86±0.93 70.36±0.7569.37±0.9070.13±0.80--m = 5trivia(llama)61.15±0.07 87.01±0.05 78.76±0.1478.86±0.0982.20±0.1482.25±0.1082.32±0.1082.45±0.0982.21±0.1282.47±0.1281.59±0.0881.07±0.0981.62±0.0778.44±0.08 64.58±0.09trivia(llama2) 76.24±0.11 96.50±0.03 89.53±0.2990.15±0.1491.11±0.17 90.96±0.13 91.04±0.2390.93±0.0990.98±0.1990.91±0.1690.71±0.1590.46±0.1390.57±0.1993.60±0.07 82.35±0.09trivia(opt)25.45±0.11 54.20±0.18 41.52±0.3141.96±0.2746.59±0.2047.64±0.2646.87±0.2048.07±0.2448.11±0.1648.33±0.1947.37±0.1846.95±0.2047.59±0.1949.92±0.18 19.95±0.11trivia(gpt)87.42±0.08 99.09±0.01 92.04±0.1193.47±0.1793.62±0.2593.49±0.3493.51±0.3493.72±0.1393.48±0.1893.75±0.1293.57±0.1993.49±0.1193.53±0.12--coqa(llama)62.46±0.11 86.29±0.06 68.31±0.1676.25±0.1777.98±0.1577.59±0.1178.06±0.0778.79±0.1278.18±0.1978.85±0.1777.74±0.1277.36±0.2477.93±0.1478.25±0.16 63.94±0.19coqa(llama2)78.71±0.13 96.92±0.03 83.10±0.1488.13±0.2388.47±0.11 88.44±0.36 88.51±0.27 88.52±0.30 88.41±0.27 88.57±0.1888.04±0.2087.63±0.1887.99±0.2189.08±0.16 79.88±0.16coqa(opt)53.79±0.17 79.39±0.13 61.15±0.3167.85±0.2269.18±0.1968.98±0.2569.34±0.2470.29±0.2269.74±0.2670.35±0.2368.97±0.2168.32±0.2569.16±0.1870.06±0.21 50.08±0.22coqa(gpt)79.76±0.14 97.45±0.03 80.39±0.2386.58±0.2187.77±0.1686.88±0.2387.63±0.2887.43±0.1687.34±0.2287.49±0.3186.98±0.2087.40±0.2487.16±0.15--nq(llama)23.53±0.35 47.56±0.53 28.23±0.4336.52±0.5534.39±0.5534.52±0.5334.69±0.5537.87±0.6037.47±0.5938.14±0.6037.29±0.5736.13±0.6137.21±0.6134.56±0.46 24.74±0.42nq(llama2)44.13±0.68 77.62±0.63 55.51±0.7759.85±1.2760.05±1.2360.15±1.1760.08±0.9560.93±0.85 60.68±1.01 61.01±0.93 60.39±1.0459.45±1.0060.11±1.04 61.34±0.97 44.19±0.66nq(opt)8.64±0.1823.33±0.42 10.67±0.3113.67±0.5113.66±0.3814.06±0.3913.87±0.3916.39±0.44 16.28±0.49 16.48±0.45 16.11±0.4516.00±0.4016.29±0.42 18.08±0.427.64±0.20nq(gpt)62.72±0.39 90.65±0.21 67.94±1.1271.18±0.8372.59±0.78 72.30±1.07 72.48±0.81 72.74±0.94 72.20±0.82 72.38±0.7071.37±0.8770.75±0.8471.29±0.67--m = 10trivia(llama)61.16±0.07 87.02±0.05 79.26±0.2079.46±0.0583.98±0.0883.84±0.0684.04±0.0884.10±0.0583.80±0.0984.27±0.0683.32±0.0582.90±0.0783.44±0.0678.99±0.08 64.79±0.10trivia(llama2) 76.24±0.11 96.50±0.03 90.79±0.2391.24±0.1592.53±0.10 92.43±0.11 92.53±0.13 92.47±0.1492.36±0.1792.40±0.1792.13±0.1091.92±0.2091.98±0.0993.86±0.06 82.35±0.09trivia(opt)25.56±0.11 54.39±0.18 41.50±0.3243.28±0.2748.79±0.2149.63±0.2249.17±0.2150.23±0.2250.39±0.2050.70±0.1949.58±0.2049.48±0.1850.08±0.1850.80±0.20 20.08±0.11trivia(gpt)87.42±0.08 99.09±0.01 92.81±0.1094.44±0.1794.38±0.2594.24±0.2294.28±0.2994.65±0.16 94.66±0.15 94.52±0.1794.40±0.1594.29±0.1794.26±0.16--coqa(llama)62.46±0.11 86.29±0.06 68.33±0.3377.47±0.1279.72±0.1278.59±0.1379.81±0.1280.42±0.1579.79±0.1780.49±0.1478.99±0.1178.89±0.1779.50±0.1378.72±0.16 63.99±0.18coqa(llama2)78.71±0.13 96.92±0.03 83.58±0.1288.85±0.1289.29±0.2689.25±0.2189.20±0.5289.56±0.19 89.53±0.25 89.54±0.2588.86±0.2088.68±0.2388.86±0.1689.17±0.17 79.89±0.17coqa(opt)53.80±0.18 79.40±0.13 61.40±0.2270.13±0.1971.73±0.2170.61±0.1871.86±0.1872.58±0.2271.98±0.1772.85±0.1971.06±0.2170.67±0.1871.33±0.1970.83±0.21 50.16±0.22coqa(gpt)79.76±0.14 97.45±0.03 80.65±0.2286.59±0.1888.41±0.2487.23±0.5088.42±0.1388.28±0.1987.91±0.3288.14±0.2787.45±0.3287.84±0.3087.74±0.20--nq(llama)23.58±0.35 47.61±0.53 28.29±0.5138.74±0.6535.63±0.6234.96±0.5836.03±0.6239.35±0.64 39.30±0.65 39.82±0.6539.08±0.6438.33±0.6239.10±0.6335.56±0.56 24.66±0.40nq(llama2)44.13±0.68 77.62±0.63 56.71±0.9561.12±0.9362.12±1.12 61.82±0.93 62.09±1.09 62.62±1.03 62.53±0.99 62.60±1.0761.47±1.1160.82±0.9661.26±1.0061.98±0.97 44.19±0.63nq(opt)8.62±0.1823.29±0.42 10.85±0.2015.16±0.4914.47±0.3814.81±0.4214.77±0.4117.67±0.4418.12±0.44 17.81±0.4817.45±0.4717.60±0.4617.79±0.46 18.49±0.447.59±0.22nq(gpt)62.72±0.39 90.65±0.21 68.85±1.2872.53±0.8274.26±0.64 74.24±0.59 74.07±0.91 74.12±0.78 73.98±0.70 73.75±0.8172.90±0.7972.48±0.8172.43±0.82--</p>
<p>Table 8 :
8
AUARC, C(x, s) + Individual Accuracy, with m = 3, 5, 10 (similar to Table2).The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 3trivia(llama)61.21±0.07 91.25±0.03 81.00±0.1782.84±0.1184.98±0.1485.59±0.0985.93±0.0885.19±0.1785.83±0.1285.76±0.3483.98±0.1084.02±0.1084.78±0.1480.15±0.10 67.51±0.09trivia(llama2) 76.26±0.13 96.93±0.04 88.30±0.2389.28±0.2189.77±0.30 89.79±0.17 89.78±0.30 89.76±0.20 89.65±0.21 89.68±0.2589.40±0.2789.22±0.1889.33±0.1793.58±0.08 82.19±0.12trivia(opt)25.73±0.13 60.65±0.17 43.64±0.3645.80±0.2149.01±0.1849.94±0.3550.40±0.1950.55±0.2550.79±0.2251.10±0.2048.94±0.2048.54±0.3249.45±0.1652.77±0.17 20.46±0.11trivia(gpt)87.45±0.08 99.18±0.01 91.46±0.12 92.61±0.1392.51±0.2292.69±0.17 92.61±0.23 92.81±0.23 92.78±0.25 92.62±0.1592.50±0.1092.29±0.1292.49±0.07--coqa(llama)62.62±0.14 91.93±0.07 69.05±0.2279.80±0.2280.70±0.1680.51±0.1681.57±0.15 81.54±0.22 81.77±0.26 81.57±0.2080.32±0.1680.37±0.2681.34±0.1780.24±0.21 66.24±0.20coqa(llama2)78.92±0.16 97.60±0.04 82.74±0.1987.24±0.1987.60±0.2187.34±0.3987.70±0.16 87.67±0.18 87.63±0.2387.48±0.2587.18±0.2387.08±0.2287.25±0.1889.17±0.17 79.76±0.17coqa(opt)53.70±0.22 87.09±0.14 61.60±0.2371.18±0.2271.96±0.3572.21±0.2873.17±0.2573.20±0.2873.66±0.36 73.31±0.2171.69±0.2671.63±0.2772.68±0.2472.15±0.23 49.55±0.26coqa(gpt)79.76±0.17 97.80±0.04 80.21±0.2485.92±0.3186.69±0.3385.85±0.2186.52±0.25 86.58±0.3686.07±0.3986.60±0.3086.09±0.2686.02±0.3786.35±0.22--nq(llama)23.40±0.31 57.37±0.46 29.00±0.4638.30±0.6836.28±0.7336.30±0.6437.06±0.6739.84±0.67 39.93±0.76 40.45±0.6339.03±0.6638.67±0.76 40.46±0.73 36.45±0.52 27.15±0.44nq(llama2)44.11±0.75 80.20±0.61 54.43±0.86 59.01±1.31 59.22±1.09 59.12±1.07 59.48±1.05 59.78±0.84 59.24±1.12 59.32±0.9558.91±1.1458.02±1.0858.53±1.0861.22±0.96 44.59±0.71nq(opt)8.94±0.2430.49±0.59 11.35±0.2814.44±0.4315.00±0.4314.60±0.3815.85±0.4017.76±0.3417.13±0.5518.11±0.4416.81±0.3716.81±0.4717.35±0.4320.39±0.408.46±0.33nq(gpt)62.42±0.46 91.83±0.22 67.54±0.9369.96±0.9370.84±0.88 70.89±0.87 70.83±0.75 70.93±0.99 71.11±0.91 70.89±0.8470.20±0.8269.59±0.9069.90±0.88--m = 5trivia(llama)61.22±0.08 91.26±0.04 81.60±0.1782.01±0.1185.60±0.1186.57±0.1887.42±0.0985.83±0.0887.33±0.1087.57±0.1784.79±0.0985.79±0.1686.48±0.1080.01±0.09 67.31±0.10trivia(llama2) 76.28±0.12 96.93±0.03 90.07±0.2890.61±0.1691.62±0.15 91.55±0.13 91.55±0.2491.44±0.0991.59±0.18 91.56±0.1491.17±0.1590.94±0.0991.00±0.1693.75±0.07 82.07±0.11trivia(opt)25.54±0.11 60.40±0.14 44.00±0.3644.67±0.2749.71±0.1850.43±0.2352.13±0.1751.29±0.1652.99±0.1853.48±0.1750.44±0.1651.34±0.2652.09±0.1652.16±0.17 20.46±0.10trivia(gpt)87.44±0.08 99.18±0.01 92.19±0.1193.61±0.1993.74±0.3093.55±0.2993.74±0.23 93.87±0.14 93.76±0.2293.65±0.1893.71±0.1893.62±0.1193.53±0.10--coqa(llama)62.46±0.12 91.86±0.06 69.40±0.1779.16±0.1780.70±0.1480.77±0.1183.00±0.1481.73±0.1783.02±0.15 83.06±0.1880.49±0.1681.62±0.2382.68±0.1479.69±0.18 66.11±0.17coqa(llama2)78.85±0.15 97.58±0.04 83.45±0.1588.59±0.2588.98±0.1288.84±0.1989.05±0.16 89.03±0.28 89.08±0.1688.80±0.2188.51±0.2088.26±0.1988.40±0.1789.30±0.18 79.78±0.16coqa(opt)53.63±0.22 87.04±0.14 62.58±0.4370.92±0.2372.27±0.2272.60±0.2675.02±0.2073.60±0.2175.63±0.21 75.43±0.2172.21±0.2173.74±0.2174.81±0.2271.82±0.22 49.76±0.26coqa(gpt)79.78±0.14 97.80±0.03 80.36±0.2386.68±0.2187.92±0.1586.75±0.3187.57±0.2287.59±0.1687.22±0.2587.37±0.2087.11±0.1987.14±0.2487.33±0.17--nq(llama)23.73±0.31 57.84±0.45 29.05±0.5839.82±0.5637.13±0.6035.42±0.5838.63±0.6241.37±0.5843.17±0.5544.00±0.5740.69±0.5841.36±0.5843.13±0.5936.43±0.41 27.99±0.53nq(llama2)44.16±0.66 80.24±0.54 55.92±0.8260.59±1.3160.61±1.2360.92±1.13 60.91±1.10 61.54±0.92 61.52±0.92 61.22±0.93 61.01±1.05 60.51±1.02 60.70±0.98 61.59±0.97 44.48±0.63nq(opt)8.79±0.2030.13±0.49 11.26±0.2915.15±0.5615.00±0.3814.63±0.3416.46±0.4418.49±0.4518.60±0.5119.78±0.4618.23±0.4718.97±0.45 19.50±0.46 19.90±0.418.46±0.27nq(gpt)62.42±0.40 91.83±0.19 68.05±1.0871.19±0.8672.65±0.79 72.46±0.77 72.44±0.92 72.76±0.99 72.56±0.81 72.34±0.8071.31±0.8970.78±0.8770.86±0.87--m = 10trivia(llama)61.03±0.07 91.16±0.04 80.34±0.2480.55±0.0785.26±0.0887.18±0.0688.13±0.0785.39±0.0787.87±0.0688.44±0.0684.48±0.0786.52±0.0787.26±0.0779.60±0.08 67.04±0.10trivia(llama2) 76.25±0.12 96.92±0.03 90.98±0.2391.37±0.1792.66±0.1192.63±0.1192.76±0.0992.58±0.1592.60±0.1492.69±0.1192.27±0.1192.03±0.1491.97±0.0993.90±0.06 82.03±0.10trivia(opt)25.65±0.11 60.54±0.15 42.34±0.3344.23±0.2749.90±0.2152.66±0.1953.51±0.1951.38±0.2154.79±0.1955.20±0.1750.72±0.1853.22±0.1754.00±0.1751.64±0.19 20.69±0.11trivia(gpt)87.45±0.08 99.18±0.01 92.90±0.1194.51±0.1794.46±0.2594.34±0.2094.37±0.3094.73±0.16 94.75±0.17 94.60±0.1994.46±0.1594.23±0.1594.27±0.14--coqa(llama)62.44±0.10 91.85±0.05 68.64±0.3478.50±0.1480.77±0.1380.35±0.1783.96±0.1481.55±0.1684.09±0.11 84.06±0.1280.00±0.1382.59±0.2283.52±0.1379.25±0.16 65.98±0.17coqa(llama2)78.70±0.13 97.55±0.03 83.62±0.1288.98±0.1289.45±0.2789.28±0.3889.59±0.18 89.72±0.19 89.77±0.2489.33±0.2389.01±0.2188.81±0.2188.97±0.1689.22±0.17 79.55±0.17coqa(opt)53.78±0.18 87.14±0.11 61.93±0.2471.45±0.2072.97±0.2072.89±0.1776.73±0.2073.93±0.2477.39±0.27 77.30±0.1972.41±0.2175.59±0.2476.57±0.2071.57±0.22 49.96±0.24coqa(gpt)79.81±0.13 97.81±0.03 80.73±0.2186.64±0.1888.51±0.2387.30±0.1588.06±0.1588.36±0.2087.72±0.2387.88±0.1387.52±0.3187.48±0.1787.74±0.11--nq(llama)23.67±0.36 57.75±0.52 28.51±0.5439.91±0.6436.62±0.6934.97±0.6839.13±0.7240.57±0.6944.78±0.7445.63±0.7140.35±0.6643.21±0.7044.74±0.6736.16±0.55 27.52±0.45nq(llama2)44.07±0.70 80.16±0.58 56.70±0.9461.28±0.9462.24±1.13 62.48±1.08 62.32±1.15 62.67±1.10 63.25±1.13 62.58±1.0061.59±1.1361.23±1.0861.57±1.0762.00±0.98 44.22±0.67nq(opt)8.66±0.2129.80±0.51 11.01±0.2415.71±0.5014.99±0.4314.75±0.4516.71±0.5118.51±0.4820.08±0.4920.87±0.5318.34±0.4719.90±0.47 20.53±0.48 19.18±0.458.21±0.25nq(gpt)62.71±0.39 91.97±0.18 69.06±1.2072.59±0.8174.37±0.64 74.18±0.65 74.25±0.71 74.29±0.62 74.40±0.78 73.80±0.7672.93±0.7971.98±0.8171.99±0.84--</p>
<p>Table 9 :
9
AUROC, C(x, s) + Individual Accuracy, with m = 3, 5, 10 (similar to Table9).The best black-box methods are in bold and the best overall is underscored.</p>
<p>Table 11 :
11
AUARC, U (x) + Expected Accuracy, with m = 3, 5, 10, 20 (similar to Table1) and the temperature of the LLM set to 0.5.The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 3</p>
<p>Table 12 :
12
AUARC, C(x, s) + Individual Accuracy, with m = 3, 5, 10, 20 (similar to Table2) and the temperature of the LLM set to 0.5.The best black-box methods are in bold and the best overall is underscored.
BaselinesOursWhite-boxRandomOracleNumSetLexiSimEigV (C)Ecc (C)Deg (C)EigV (E)Ecc (E)Deg (E)EigV (J)Ecc (J)Deg (J)SEP(true)m = 3
See Appendix for results on calibrated confidence measures.
. Calculate the pairwise similarity scores a(s j1 , s j2 ) for these m responses.
. Compute an uncertainty estimate U (x) or a confidence score C(x, s j ) using the similarity values.3 In fact, when the level of "open-endedness" of an input distribution is similar, the ranking of total uncertainty should still be indicative of that of the epistemic uncertainty.
Here, we assume a auto-regressive LLM. For other models, computing such a quantify might require a different approach, if possible.
This is an improved version of Eq. (1), where s is replaced with c where c denotes a semantic concept instead of a response. p(s|x) is replaced with p(c|x) = s∈c p(c|x) correspondingly.
https://github.com/lorenzkuhn/semantic_uncertainty
We follow the bi-directional entailment algorithm inKuhn et al. (2023) to construct such semantic sets using a N LI,entail and a N LI,contra and assuming transitivity of semantic equivalence. Specifically, we iterate over j 1 &lt; j 2 , and merge s j 2 into the same semantic set of s j 1 if pentail (s j 1 , s j 2 ) &gt; pcontra(sj 1 , s j 2 ) and pentail (s j 2 , s j 1 ) &gt; pcontra(sj 2 , s j 1 ).
In particular, a "gap" between a small eigenvalue λ k to a large one λ k+1 indicates that there are k clusters.
All gpt-3.5-turbo used in this paper are the 0301 version.
Published in Transactions on Machine LearningResearch (05/2024) <br />
Note that P(true) may not require white-box access if one is willing to sample a lot of responses from the LLM, which is however computationally expensive.
While originally AUARC was defined with a binary accuracy label, one could generalize it to any continuous label, such as the expected accuracy (using a Monte Carlo estimate).
https://github.com/lorenzkuhn/semantic_uncertainty/blob/main/code/parse_coqa.py
https://huggingface.co/microsoft/deberta-large-mnli
AcknowledgementsThis work was supported by NSF award SCH-2205289, SCH-2014438, IIS-1838042, NIH award R01 1R01NS107291-01.temperature, we observe that in general, the white-box method (SE) performs better than our black-box methods when m is small.However, as m increases (≥ 10), our methods' performance picks up.C.4 Generation without RejectionPrevious results indicate the practical performance of using the proposed U and C for selective generation, where some hard questions are ignored.In Table14we simply pick the most confident response.Even without rejection, most confidence measures can pick better responses and significantly improve the accuracy.C.5 Confidence vs CalibrationAs suggested in Section 2, model calibration is an orthogonal research direction.Once the confidence measures are given, a calibration method could then be applied to calibrate the confidence scores into something close to the probability of correct answer.We applied the classical histogram binning methodZadrozny &amp; Elkan (2001)on all methods, and compute the adaptive calibration error (ACE)Nixon et al. (2019).The number of bins is set to 15 following the standard practiceNixon et al. (2019), and the confidence measures are calibrated on the 1st generation of 1000 calibration samples and evaluated on the rest.Confidence measures are estimated using 20 generations.The results are in Table16.After calibration, the confidence scores can faithfully reflect the accuracy.For example, for Ecc (E) on trivia(llama), the gap between calibrated probability and the actual accuracy is only 0.026.Published in Transactions on Machine Learning Research (05/2024)
References Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi, 10.1016/j.inffus.2021.05.008.URLhttps://www.sciencedirect.com/science/article/pii/S1566253521001081A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion. 2021a76</p>
<p>A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion. Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, Rajendra Acharya, ArXiv, abs/2211.127172021b. 202276244906451Benchmarking bayesian deep learning on diabetic retinopathy detection tasks</p>
<p>A large annotated corpus for learning natural language inference. R Samuel, Gabor Bowman, Christopher Angeli, Christopher D Potts, Manning, 10.18653/v1/D15-1075Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalSeptember 2015Association for Computational Linguistics</p>
<p>Quantifying uncertainty in answers from any language model via intrinsic and extrinsic confidence assessment. Jiuhai Chen, Jonas Mueller, arXiv:2308.161752023arXiv preprint</p>
<p>On Optimum Recognition Error and Reject Tradeoff. C K Chow, 10.1109/TIT.1970.1054406IEEE Transactions on Information Theory. 1970</p>
<p>. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Emily Vinodkumar Prabhakaran, Nan Reif, Ben Du, Reiner Hutchinson, James Pope, Jacob Bradbury, Michael Austin, Guy Isard, Pengcheng Gur-Ari, Toju Yin, Anselm Duke, Sanjay Levskaya, Sunipa Ghemawat, Henryk Dev, Xavier Michalewski, Vedant Garcia, Kevin Misra, Liam Robinson, Denny Fedus, Daphne Zhou, David Ippolito, Hyeontaek Luan, Barret Lim, Alexander Zoph, Ryan Spiridonov, Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck2022Jeff Dean, Slav Petrovand Noah Fiedel. Palm: Scaling language modeling with pathways</p>
<p>Addressing failure prediction by learning model confidence. Charles Corbière, Thome Nicolas, Avner Bar-Hen, Matthieu Cord, Patrick Pérez, Advances in Neural Information Processing Systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, Curran Associates, Inc201932</p>
<p>A comparison of rule-based and machine learning approaches for classifying patient portal messages. Daniel Robert M Cronin, Joshua C Fabbri, S Denny, Gretchen Trent Rosenbloom, Jackson Purcell, International journal of medical informatics. 1052017</p>
<p>Calibration of pre-trained transformers. Shrey Desai, Greg Durrett, 10.18653/v1/2020.emnlp-main.21Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsOnline, November 2020</p>
<p>Reject option with multiple thresholds. Pattern Recognition. Giorgio Fumera, Fabio Roli, Giorgio Giacinto, 10.1016/S0031-3203(00)00059-52000</p>
<p>Dropout as a bayesian approximation: Representing model uncertainty in deep learning. Yarin Gal, Zoubin Ghahramani, Proceedings of The 33rd International Conference on Machine Learning. Maria , Florina Balcan, Kilian Q Weinberger, The 33rd International Conference on Machine LearningNew York, New York, USA20-22 Jun 201648Proceedings of Machine Learning Research</p>
<p>Selective classification for deep neural networks. Yonatan Geifman, Ran El-Yaniv, Advances in Neural Information Processing Systems. 2017</p>
<p>What comes next? evaluating uncertainty in neural text generators against human production variability. Mario Giulianelli, Joris Baan, Wilker Aziz, Raquel Fernández, Barbara Plank, 2023</p>
<p>Deberta: Decoding-enhanced bert with disentangled attention. Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, International Conference on Learning Representations. 2021</p>
<p>A baseline for detecting misclassified and out-of-distribution examples in neural networks. Dan Hendrycks, Kevin Gimpel, International Conference on Learning Representations. 2017</p>
<p>Probabilistic backpropagation for scalable learning of bayesian neural networks. José Miguel, Hernández-Lobato , Ryan P Adams, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015. Francis R Bach, David M Blei, the 32nd International Conference on Machine Learning, ICML 2015Lille, France6-11 July 2015. 2015JMLR Workshop and Conference Proceedings</p>
<p>Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Eyke Hüllermeier, Willem Waegeman, Machine Learning. 2021110</p>
<p>To trust or not to trust a classifier. Heinrich Jiang, Been Kim, Maya Gupta, Melody Y Guan, Advances in Neural Information Processing Systems. 2018</p>
<p>How can we know when language models know? on the calibration of language models for question answering. Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig, 10.1162/tacl_a_00407Transactions of the Association for Computational Linguistics. 92021</p>
<p>TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer, 10.18653/v1/P17-1147Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171</p>
<p>Language models (mostly) know what they know. Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield Dodds, Nova Dassarma, Eli Tran-Johnson, arXiv:2207.052212022arXiv preprint</p>
<p>Selective question answering under domain shift. Amita Kamath, Robin Jia, Percy Liang, 10.18653/v1/2020.acl-main.503Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 2020</p>
<p>. Martin Daniel, Michael James Katz, Shang Bommarito, Pablo Gao, Arredondo, 20234389233Gpt-4 passes the bar exam. Available at SSRN</p>
<p>Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. Lorenz Kuhn, Yarin Gal, Sebastian Farquhar, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Natural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov, 10.1162/tacl_a_00276Transactions of the Association for Computational Linguistics. 72019</p>
<p>DEUP: Direct epistemic uncertainty prediction. Salem Lahlou, Moksh Jain, Hadi Nekoei, I Victor, Paul Butoi, Jarrid Bertin, Maksym Rector-Brooks, Yoshua Korablyov, Bengio, Transactions on Machine Learning Research. 2835-88562023</p>
<p>Simple and scalable predictive uncertainty estimation using deep ensembles. Alexander Balaji Lakshminarayanan, Charles Pritzel, Blundell, Advances in Neural Information Processing Systems. 2017</p>
<p>Teaching models to express their uncertainty in words. Stephanie C Lin, Jacob Hilton, Owain Evans, ArXiv, abs/2205.143342022a</p>
<p>Scrib: set-classifier with classspecific risk bounds for blackbox models. Zhen Lin, Lucas Glass, Brandon Westover, Cao Xiao, Jimeng Sun, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2022b36</p>
<p>Predictive uncertainty estimation via prior networks. Andrey Malinin, Mark Gales, Advances in Neural Information Processing Systems. S Bengio, H Wallach, H Larochelle, K Grauman, N Cesa-Bianchi, R Garnett, Curran Associates, Inc201831</p>
<p>Uncertainty estimation in autoregressive structured prediction. Andrey Malinin, Mark Gales, International Conference on Learning Representations. 2021</p>
<p>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. L Mcinnes, J Healy, J Melville, February 2018ArXiv e-prints</p>
<p>Linguistic calibration through metacognition: aligning dialogue agent responses with expected correctness. Sabrina J Mielke, Arthur Szlam, Y-Lan Boureau, Emily Dinan, CoRR, abs/2012.149832020</p>
<p>Reducing conversational agents' overconfidence through linguistic calibration. Sabrina J Mielke, Arthur Szlam, Emily Dinan, Y-Lan Boureau, 10.1162/tacl_a_00494Transactions of the Association for Computational Linguistics. 102022</p>
<p>Accuracy-rejection curves (arcs) for comparing classification methods with a reject option. Malik Sajjad, Ahmed Nadeem, Jean-Daniel Zucker, Blaise Hanczar, Proceedings of the third International Workshop on Machine Learning in Systems Biology. Sašo Džeroski, Pierre Guerts, Juho Rousu, the third International Workshop on Machine Learning in Systems BiologyLjubljana, SloveniaSep 20098of Proceedings of Machine Learning Research</p>
<p>On spectral clustering: Analysis and an algorithm. Andrew Ng, Michael Jordan, Yair Weiss, Advances in Neural Information Processing Systems. T Dietterich, S Becker, Z Ghahramani, MIT Press200114</p>
<p>Measuring calibration in deep learning. Jeremy Nixon, Michael W Dusenberry, Linchuan Zhang, Ghassen Jerfel, Dustin Tran, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops. the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) WorkshopsJune 2019</p>
<p>. OpenAI. Gpt-4 technical report. 2023</p>
<p>Align, disambiguate and walk: A unified approach for measuring semantic similarity. Mohammad Taher Pilehvar, David Jurgens, Roberto Navigli, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 51st Annual Meeting of the Association for Computational LinguisticsSofia, BulgariaAssociation for Computational LinguisticsAugust 20131</p>
<p>A survey on recognizing textual entailment as an NLP evaluation. Adam Poliak, 10.18653/v1/2020.eval4nlp-1.10Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems. the First Workshop on Evaluation and Comparison of NLP SystemsAssociation for Computational LinguisticsNovember 2020</p>
<p>Document processing: Methods for semantic text similarity analysis. Abdul Wahab Qurashi, Violeta Holmes, Anju P Johnson, 10.1109/INISTA49547.2020.91946652020 International Conference on INnovations in Intelligent SysTems and Applications (INISTA). 2020</p>
<p>CoQA: A conversational question answering challenge. Siva Reddy, Danqi Chen, Christopher D Manning, 10.1162/tacl_a_00266Transactions of the Association for Computational Linguistics. 72019</p>
<p>Out-of-distribution detection and selective generation for conditional language models. Jie Ren, Jiaming Luo, Yao Zhao, Kundan Krishna, Mohammad Saleh, Balaji Lakshminarayanan, Peter J Liu, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Confident adaptive language modeling. Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Q Vinh, Yi Tran, Donald Tay, Metzler, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Reliable classification: Learning classifiers that distinguish aleatoric and epistemic uncertainty. Robin Senge, Stefan Bösner, Krzysztof Dembczyński, Jörg Haasenritter, Oliver Hirsch, Norbert Donner-Banzhoff, Eyke Hüllermeier, 10.1016/j.ins.2013.07.030Inf. Sci. 0020-0255255jan 2014</p>
<p>Re-examining calibration: The case of question answering. Chenglei Si, Chen Zhao, Sewon Min, Jordan Boyd-Graber, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>Prompting GPT-3 to be reliable. Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Lee Boyd-Graber, Lijuan Wang, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Feature selection using neighborhood entropy-based uncertainty measures for gene expression data classification. Lin Sun, Xiaoyu Zhang, Yuhua Qian, Jiucheng Xu, Shiguang Zhang, Information Sciences. 5022019</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023aarXiv preprint</p>
<p>. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing , Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, 2023bAurelien RodriguezAngela Fan, Melanie Kambadur; Robert Stojnic, Sergey Edunovand Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models</p>
<p>Post-abstention: Towards reliably re-attempting the abstained instances in QA. Neeraj Varshney, Chitta Baral, 10.18653/v1/2023.acl-long.55Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 20231</p>
<p>Investigating selective prediction approaches across several tasks in IID, OOD, and adversarial settings. Neeraj Varshney, Swaroop Mishra, Chitta Baral, 10.18653/v1/2022.findings-acl.158Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational LinguisticsMay 2022a</p>
<p>Towards improving selective prediction ability of NLP systems. Neeraj Varshney, Swaroop Mishra, Chitta Baral, 10.18653/v1/2022.repl4nlp-1.23Proceedings of the 7th Workshop on Representation Learning for NLP. the 7th Workshop on Representation Learning for NLPDublin, IrelandAssociation for Computational LinguisticsMay 2022b</p>
<p>A tutorial on spectral clustering. Ulrike Von, Luxburg , Statistics and computing. 172007</p>
<p>Uncertainty estimation and reduction of pre-trained models for text regression. Yuxia Wang, Daniel Beck, Timothy Baldwin, Karin Verspoor, 10.1162/tacl_a_00483Transactions of the Association for Computational Linguistics. 102022</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Uncertainties have a meaning: Information entropy as a quality measure for 3-d geological models. Florian Wellmann , Klaus Regenauer-Lieb, Tectonophysics. 5262012</p>
<p>A broad-coverage challenge corpus for sentence understanding through inference. Adina Williams, Nikita Nangia, Samuel Bowman, 10.18653/v1/N18-1101Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational LinguisticsJune 20181</p>
<p>Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, Bryan Hooi, 2023</p>
<p>Learning and making decisions when costs and probabilities are both unknown. Bianca Zadrozny, Charles Elkan, 10.1145/502512.50254061.18±0.07 91.24±0.03 78.78±0.17 80.32±0.06Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '01. the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '01New York, NY, USA2001Association for Computing Machinery. ISBN 158113391X</p>            </div>
        </div>

    </div>
</body>
</html>