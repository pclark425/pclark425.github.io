<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7582 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7582</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7582</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-141.html">extraction-schema-141</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models estimate probabilities for future real-world scientific discoveries, including model details, prediction targets, datasets, forecasting horizon, probability estimation methods, evaluation metrics, reported performance, calibration quality, baselines, limitations, and concrete probability examples.</div>
                <p><strong>Paper ID:</strong> paper-264406226</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.13014v1.pdf" target="_blank">Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament</a></p>
                <p><strong>Paper Abstract:</strong> Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence. However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent. To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform. The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict. Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts. We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question. We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis. Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts. A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data. This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7582.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7582.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models estimate probabilities for future real-world scientific discoveries, including model details, prediction targets, datasets, forecasting horizon, probability estimation methods, evaluation metrics, reported performance, calibration quality, baselines, limitations, and concrete probability examples.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art large language model from OpenAI based on the Transformer architecture and trained with next-token prediction plus reinforcement learning from human feedback; used here to produce explicit probabilistic forecasts for real-world binary events via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language model trained on large internet text corpora using next-token prediction; further fine-tuned with reinforcement learning from human feedback (RLHF); in this study used via the web chat interface with a prompting strategy to elicit explicit percentage probability forecasts and short rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>probability_estimation_method</strong></td>
                            <td>Direct elicitation from model output via expert‑style prompt (superforecaster prompt); default temperature; when model returned a probability range the mean of the range endpoints was used; no post-hoc calibration (e.g., temperature scaling) or automated Bayesian calibration applied to model outputs in the main experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>prediction_target</strong></td>
                            <td>Binary real-world event outcomes drawn from a Metaculus forecasting tournament (23 binary questions covering topics such as Big Tech labor actions, U.S. politics including motions to vacate the Speaker, viral outbreak events, international conflict outcomes, and agreements such as the Black Sea grain deal).</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>Mixed real-world events (politics, technology/industry, public health/viral outbreaks, international relations); not specialized to laboratory scientific-discovery forecasts in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Evaluation: the set of 23 binary Metaculus forecasting questions and associated background info provided at forecast time; Model training datasets are not enumerated in the paper (general large internet text corpus and RLHF fine-tuning are referenced, but no specific corpus names or dates beyond a training cutoff are given).</td>
                        </tr>
                        <tr>
                            <td><strong>forecasting_horizon</strong></td>
                            <td>Short-term tournament horizons within the three-month Quarterly Cup (questions launched July 3, 2023; tournament concluded October 4, 2023); individual question resolution windows varied (examples include deadlines like 'before October 1, 2023' and other question-specific cutoffs), so typical horizons in this experiment were up to ≈3 months or shorter depending on question.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Primary: Brier score (B = (f - o)^2) aggregated across questions; secondary/auxiliary analyses: directional correctness (relative to 50% midpoint), coefficient of variation (CV) of probability distributions, Levene's test for equality of variances around midpoint, Bayesian Model Averaging (BMA) combining GPT-4 and human forecasts; statistical tests reported (t-tests, ANCOVA, chi-square, Cohen's d).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_performance</strong></td>
                            <td>GPT-4 mean Brier score = 0.20 (SD = 0.18) across 23 binary questions; median human-crowd mean Brier score = 0.07 (SD = 0.08). No-information (50%) baseline Brier = 0.25. Difference human minus GPT-4 Δ = 0.13, t(44) = 3.11, p = .003, Cohen's d = 0.94. Directionally correct frequency: GPT-4 69.57% vs. human crowd 95.65% (GPT-4 vs random 50%: Z = 1.88, p = .061). BMA weighted Brier = 0.13 (SD = 0.09) using likelihood weights derived in exploratory analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Authors conclude GPT-4 did not significantly improve over the no-information (50%) baseline (statistically indistinguishable from 0.25 Brier baseline), indicating poor effective forecasting calibration/performance in this setting; exploratory statistics show GPT-4 had lower dispersion (CV centered on mean = 48.22%, CV around midpoint = 42.14%) than humans (73.67% and 57.59% respectively), consistent with a more conservative/centrist tendency, but tests did not show statistically significant variance differences around 50%; no numeric calibration error (e.g., ECE) reported.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Median human‑crowd forecast (per-question median from Metaculus participants), no-information 50% baseline (Brier=0.25), and an exploratory Bayesian Model Averaging (BMA) combining GPT-4 and human forecasts; statistical null-hypothesis tests (t-tests, chi-square) were used for comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Knowledge cutoff / lack of real‑time updating in GPT-4 (authors mitigated by feeding Metaculus background info but model still lacked ongoing internet access); GPT-4 produced single initial forecasts only (no autonomous repeated updating), whereas humans iteratively update; small sample of binary questions (N=23) limits power and generalizability; evaluation limited to binary questions (excluded continuous quantiles); model used at default temperature and not calibrated or ensembled in diverse ways (single prompt, single temperature), so results reflect that specific setup; potential effects of RLHF pushing toward conservative midpoints discussed but not conclusively demonstrated; results concern real-world event forecasting rather than laboratory scientific-discovery forecasting specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>probability_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_world_future</strong></td>
                            <td>True</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large Language Models Are Zero-Shot Time Series Forecasters <em>(Rating: 2)</em></li>
                <li>Chimeric Forecasting: Combining Probabilistic Predictions from Computational Models and Human Judgment <em>(Rating: 2)</em></li>
                <li>Hybrid Forecasting of Geopolitical Events <em>(Rating: 2)</em></li>
                <li>Fine-tuning Language Models from Human Preferences <em>(Rating: 1)</em></li>
                <li>Superforecasting: The Art and Science of Prediction <em>(Rating: 1)</em></li>
                <li>Sparks of Artificial General Intelligence: Early Experiments with GPT-4 <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7582",
    "paper_id": "paper-264406226",
    "extraction_schema_id": "extraction-schema-141",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A state-of-the-art large language model from OpenAI based on the Transformer architecture and trained with next-token prediction plus reinforcement learning from human feedback; used here to produce explicit probabilistic forecasts for real-world binary events via prompting.",
            "citation_title": "Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Transformer-based large language model trained on large internet text corpora using next-token prediction; further fine-tuned with reinforcement learning from human feedback (RLHF); in this study used via the web chat interface with a prompting strategy to elicit explicit percentage probability forecasts and short rationales.",
            "model_size": null,
            "probability_estimation_method": "Direct elicitation from model output via expert‑style prompt (superforecaster prompt); default temperature; when model returned a probability range the mean of the range endpoints was used; no post-hoc calibration (e.g., temperature scaling) or automated Bayesian calibration applied to model outputs in the main experiment.",
            "prediction_target": "Binary real-world event outcomes drawn from a Metaculus forecasting tournament (23 binary questions covering topics such as Big Tech labor actions, U.S. politics including motions to vacate the Speaker, viral outbreak events, international conflict outcomes, and agreements such as the Black Sea grain deal).",
            "domain": "Mixed real-world events (politics, technology/industry, public health/viral outbreaks, international relations); not specialized to laboratory scientific-discovery forecasts in this study.",
            "dataset_used": "Evaluation: the set of 23 binary Metaculus forecasting questions and associated background info provided at forecast time; Model training datasets are not enumerated in the paper (general large internet text corpus and RLHF fine-tuning are referenced, but no specific corpus names or dates beyond a training cutoff are given).",
            "forecasting_horizon": "Short-term tournament horizons within the three-month Quarterly Cup (questions launched July 3, 2023; tournament concluded October 4, 2023); individual question resolution windows varied (examples include deadlines like 'before October 1, 2023' and other question-specific cutoffs), so typical horizons in this experiment were up to ≈3 months or shorter depending on question.",
            "evaluation_metric": "Primary: Brier score (B = (f - o)^2) aggregated across questions; secondary/auxiliary analyses: directional correctness (relative to 50% midpoint), coefficient of variation (CV) of probability distributions, Levene's test for equality of variances around midpoint, Bayesian Model Averaging (BMA) combining GPT-4 and human forecasts; statistical tests reported (t-tests, ANCOVA, chi-square, Cohen's d).",
            "reported_performance": "GPT-4 mean Brier score = 0.20 (SD = 0.18) across 23 binary questions; median human-crowd mean Brier score = 0.07 (SD = 0.08). No-information (50%) baseline Brier = 0.25. Difference human minus GPT-4 Δ = 0.13, t(44) = 3.11, p = .003, Cohen's d = 0.94. Directionally correct frequency: GPT-4 69.57% vs. human crowd 95.65% (GPT-4 vs random 50%: Z = 1.88, p = .061). BMA weighted Brier = 0.13 (SD = 0.09) using likelihood weights derived in exploratory analysis.",
            "calibration_quality": "Authors conclude GPT-4 did not significantly improve over the no-information (50%) baseline (statistically indistinguishable from 0.25 Brier baseline), indicating poor effective forecasting calibration/performance in this setting; exploratory statistics show GPT-4 had lower dispersion (CV centered on mean = 48.22%, CV around midpoint = 42.14%) than humans (73.67% and 57.59% respectively), consistent with a more conservative/centrist tendency, but tests did not show statistically significant variance differences around 50%; no numeric calibration error (e.g., ECE) reported.",
            "baseline_methods": "Median human‑crowd forecast (per-question median from Metaculus participants), no-information 50% baseline (Brier=0.25), and an exploratory Bayesian Model Averaging (BMA) combining GPT-4 and human forecasts; statistical null-hypothesis tests (t-tests, chi-square) were used for comparisons.",
            "limitations": "Knowledge cutoff / lack of real‑time updating in GPT-4 (authors mitigated by feeding Metaculus background info but model still lacked ongoing internet access); GPT-4 produced single initial forecasts only (no autonomous repeated updating), whereas humans iteratively update; small sample of binary questions (N=23) limits power and generalizability; evaluation limited to binary questions (excluded continuous quantiles); model used at default temperature and not calibrated or ensembled in diverse ways (single prompt, single temperature), so results reflect that specific setup; potential effects of RLHF pushing toward conservative midpoints discussed but not conclusively demonstrated; results concern real-world event forecasting rather than laboratory scientific-discovery forecasting specifically.",
            "probability_examples": null,
            "real_world_future": true,
            "uuid": "e7582.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large Language Models Are Zero-Shot Time Series Forecasters",
            "rating": 2,
            "sanitized_title": "large_language_models_are_zeroshot_time_series_forecasters"
        },
        {
            "paper_title": "Chimeric Forecasting: Combining Probabilistic Predictions from Computational Models and Human Judgment",
            "rating": 2,
            "sanitized_title": "chimeric_forecasting_combining_probabilistic_predictions_from_computational_models_and_human_judgment"
        },
        {
            "paper_title": "Hybrid Forecasting of Geopolitical Events",
            "rating": 2,
            "sanitized_title": "hybrid_forecasting_of_geopolitical_events"
        },
        {
            "paper_title": "Fine-tuning Language Models from Human Preferences",
            "rating": 1,
            "sanitized_title": "finetuning_language_models_from_human_preferences"
        },
        {
            "paper_title": "Superforecasting: The Art and Science of Prediction",
            "rating": 1,
            "sanitized_title": "superforecasting_the_art_and_science_of_prediction"
        },
        {
            "paper_title": "Sparks of Artificial General Intelligence: Early Experiments with GPT-4",
            "rating": 1,
            "sanitized_title": "sparks_of_artificial_general_intelligence_early_experiments_with_gpt4"
        }
    ],
    "cost": 0.00843375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament
17 Oct 2023</p>
<p>Philipp Schoenegger 
London School of Economics and Political Science</p>
<p>Peter S Park 
London School of Economics and Political Science</p>
<p>Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament
17 Oct 20230EFCC37F74FFBB438A191D0BF13347E2arXiv:2310.13014v1[cs.CY]
Accurately predicting the future would be an important milestone in the capabilities of artificial intelligence.However, research on the ability of large language models to provide probabilistic predictions about future events remains nascent.To empirically test this ability, we enrolled OpenAI's state-of-the-art large language model, GPT-4, in a three-month forecasting tournament hosted on the Metaculus platform.The tournament, running from July to October 2023, attracted 843 participants and covered diverse topics including Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.Focusing on binary forecasts, we show that GPT-4's probabilistic forecasts are significantly less accurate than the median human-crowd forecasts.We find that GPT-4's forecasts did not significantly differ from the no-information forecasting strategy of assigning a 50% probability to every question.We explore a potential explanation, that GPT-4 might be predisposed to predict probabilities close to the midpoint of the scale, but our data do not support this hypothesis.Overall, we find that GPT-4 significantly underperforms in real-world predictive tasks compared to median human-crowd forecasts.A potential explanation for this underperformance is that in real-world forecasting tournaments, the true answers are genuinely unknown at the time of prediction; unlike in other benchmark tasks like professional exams or time series forecasting, where strong performance may at least partly be due to the answers being memorized from the training data.This makes real-world forecasting tournaments an ideal environment for testing the generalized reasoning and prediction capabilities of artificial intelligence going forward.</p>
<p>Introduction</p>
<p>In the field of artificial intelligence (AI), large language models (LLMs) have recently shown surprising capabilities in a multitude of economically relevant tasks 25 that were previously thought to require human cognition. 6State-of-the-art LLMs are comprised of an extremely large amount of parameters-typically organized in terms of the Transformer architecture 37 -and trained on a large corpus of Internet-based text data.This corpus of training data is used to train LLMs to predict the next sequence of tokens given an input.Despite the simplicity of the general task for which LLMs are trained-next token prediction-the resulting transfer learning causes LLMs to also become ostensibly proficient at a wide variety of specific tasks, including reading comprehension, 30,38 summarization, 11 translation, 15 coding, 6 deception, 32 medical-license exams 6,27 , and bar exams. 6,17e ostensibly impressive capabilities of LLMs come with several important caveats.One of the most important caveats to keep in mind is that when an LLM consistently outputs the true answers to questions in a task benchmark or exam, it is unclear whether the LLM's true answers reflect a genuine understanding of the task: and as such, are likely to generalize to out-of-distribution settings. 1n alternative hypothesis is that the training dataset contains at least part of the task benchmark's questions and corresponding answers, and that the given LLM capability may thus not reflect a genuine understanding that can generalize to analogous questions not in the training dataset. 2,4,8,19or example, consider a scenario where an organic-chemistry exam question is inputted into the LLM, and it outputs the true answer.It remains unclear whether this is due to the LLM possessing a deep understanding of the relevant organic-chemistry concepts, as opposed to simply reproducing the answer to the specific question contained in its training dataset.It is not trivial to rigorously formalize the dichotomy between genuine understanding and training-data memorization, as genuine understanding also ultimately arises from the relevant content in the training dataset.But the very real phenomenon of generalizability-or lack thereof-seems to be at the heart of the dichotomy. 12ven the problem of distinguishing whether an LLM's proficiency at a task benchmark is due to genuine understanding or to memorizing the training data, we propose evaluating LLM capabilities in contexts where the true answers are unknown beforehand and as such cannot be part of the training data.An especially important such context is forecasting, a domain where the answers are initially unknown to everyone (even the human evaluators) until they are validated or falsified by future events. 33We distinguish this context from the related but different forecasting context of zero-shot extrapolations of time series. 13In contrast, our definition of 'forecasting'-producing accurate probabilistic predictions of future events-does not encounter the problem of distinguishing the benchmark data from the training data.As such, it allows for a more robust and generalizable evaluation of LLM capabilities: beyond the rote memorization of training data.</p>
<p>Our study evaluates the forecasting capabilities of GPT-4, a state-of-the-art LLM created by OpenAI, 28 by entering it in a forecasting tournament.Forecasting tournaments are competitions wherein individual forecasters provide probabilistic forecasts on questions concerning future events. 36These predictions are then scored based on the accuracy of their forecasts: the closer one's prediction is to the truth, the more likely one is to be rewarded.The collective accuracy of the predictions resulting from such forecasting tournaments hinges on the 'wisdom of the crowd,' i.e., the observation that aggregated forecasts of a group are often more accurate than the forecasts of individuals, 7,20 even if judgments are correlated and biased. 10This setting allows us to test LLM capabilities in a context where the answer is genuinely unknown beforehand and thus cannot be contained within the training dataset.This setting may also be critical for whether LLMs are or will be able to rival-or even outperform-humans at jobs that require prescient decision-making. 31Accurately predicting the future is foundational to decision-making in most public and private sectors. 33Consequently, comparing the forecasting capabilities of GPT-4 with those of humans promises to be a good test case for many potential economic applications of advanced AI.</p>
<p>As such, we have pre-registered-along with our analysis plans-the following null hypothesis:</p>
<p>The mean accuracy of GPT-4 forecasts is not different from the mean accuracy of median human-crowd forecasts.H 0 : µ GPT-4 = µ Human Human crowds in forecasting tournaments are among the best options for producing accurate probabilistic predictions. 9,35If a state-of-the-art LLM like GPT-4 is able to outperform a human crowd of forecasters, this would be consistent with the model having learned a deep understanding of the relevant capabilities, like probabilistic reasoning, generalization, and accurate prediction.</p>
<p>Methods</p>
<p>We conducted our study on Metaculus, a platform that hosts forecasting tournaments where members of the public can submit predictions, compete for prizes, and establish a forecasting track record.Metaculus' forecasting platform has been employed in various academic and policy prediction contexts, such as the monkeypox outbreak in 2022 22 and the COVID pandemic. 21We leveraged the opportunity provided by the launch of the Quarterly Cup 24 on July 3, 2023, as this three-month tournament offered an ideal context to evaluate LLM prediction capabilities.This setting provided us with a context where an LLM could compete with human forecasters to make probabilistic predictions about various topical questions.</p>
<p>Our questions were vetted by the Metaculus moderation team, who aimed to resolve the questions in a consistent and accurate manner in order to ensure high-quality data.The forecasting questions studied here were on a wide array of topics, such as U.S. industrial action disputes, military interventions in Niger, outbreaks of Marburg virus disease, and the Black Sea grain deal.For examples of the forecasting questions used in our study, see Table 1.For a full set of questions, see Appendix A.</p>
<p>Will the United Auto Workers call a strike against any of the Big Three Detroit automakers before September 19, 2023?Will Mohamed Bazoum, Nigerien President, return to power before August 31, 2023?Will India's Chandrayaan-3 mission successfully land a rover on the moon?Will the Black Sea grain deal be revived before October 1, 2023?Will a non-proprietary LLM be in the top 5 of the chat.lmsys.orgleaderboard on September 30, 2023?Table 1: Examples of forecasting questions used in our study.</p>
<p>Our study's questions were answered by both GPT-4 and a large set of human forecasters.The tournament concluded on October 4, with a total of 51 questions posed, and with 843 unique forecasters entering at least one prediction.For our analysis, we focused solely on the subset of binary questions, of which there were 23.This is because binary questions were the only types of questions that our LLM forecaster could straightforwardly answer without requiring additional human input.This could have biased the predictions, such as by drawing distributions based on quartile point estimates.</p>
<p>We used the web interface of GPT-4 at the default temperature value.Temperature is a hyperparameter that controls the randomness of a model's output, with higher temperature settings resulting in more random outputs, and lower temperature settings resulting in more deterministic outputs.Our prompt was crafted by drawing on established research in forecasting, with the aim of steering GPT-4 towards comfortably providing numerical predictions and of enhancing the accuracy of these predictions.First, we prompted the model to emulate a superforecaster, 36 aligning with the bestpractice recommendations of how to prompt models to act as if they were domain experts. 39This part of the prompt enabled us to consistently avoid getting responses of a different format than explicit probabilistic forecasts.</p>
<p>Second, we grounded our prompt on research from the forecasting literature that highly complex qualitative rationales and the use of base rates are associated with forecasting accuracy. 16This part of the prompt was an attempt to not only elicit probabilistic forecasts, but to ensure that these are as highly accurate as possible.</p>
<p>The overall prompt is given by the following.</p>
<p>Prompt: In this chat, you are a superforecaster that has a strong track record of accurate forecasts of the future.As an experienced forecaster, you evaluate past data and trends carefully and aim to predict future events as accurately as you can, even though you cannot know the answer.This means you put probabilities on outcomes that you are uncertain about (ranging from 0 to 100%).When the outcome is continuous, you give me 25th interquartile ranges.You also quickly outline your rationale.In your rationales, you carefully consider the reasons for and against your probability estimate, you will make use of comparison classes of similar events and probabilities and take into account base rates and past events as well as other forecasts and predictions.You will also consider different perspectives.</p>
<p>Each question of the tournament was predicted via a single chat log, with the prompt positioned at the outset.Following this, GPT-4 was supplied with the background information, the specific resolution criteria of the question, and the final question text exactly as presented on Metaculus.This information, provided by Metaculus users or staff, helped mitigate the temporal distance between the training data set cutoff data and the question launch, which is less fundamental of an information gap for the human comparison group.For a full set of this information for one question, see Appendix B. For some questions, the median human-crowd prediction was available at the time of forecast; while for others, it was not.In the case of the latter, we included the median human-crowd prediction in the description provided to GPT-4.</p>
<p>Subsequently, we collected the probabilistic prediction and inputted it into the question, in percent form.In cases where the model output was a probability range, the mean probability of the two values was used instead.We abstained from making any revisions to the initial forecasts.We did so because determining when to update and what information to employ for this update would have necessitated a significant degree of human involvement in the process, which we sought to minimize given that updating is a crucial skill for human forecasters. 23Since repeated updating is fundamental to the method of crowd-aggregated forecasting, it was important to account for GPT-4's inability to autonomously carry out this task in order to enable unbiased inferences from our results.</p>
<p>In order to control for these confounding factors, our design entailed recording both the initial model forecast and the crowd-aggregated median forecast at the close of the same day at which the model forecast was submitted.This allowed us to control for updating over extended question periods, which is done by humans, but is difficult to operationalize for GPT-4 without introducing bias in deciding when and how to prompt the update.Our comparison thus directly put GPT-4 on par with the human forecasters by only looking at initial forecasts.The full data encompassed for each question GPT-4's forecast, the median human-crowd forecast at the conclusion of the same day, the ground truth, whether a community prediction was visible at the time of prediction, the number of human forecasters at this point in time (for a median number of 37 forecasters), and the total duration, spanning the timeframe from when predictions were made to the eventual resolution of the question.This set of data was collected for all 23 binary forecasts.</p>
<p>Results</p>
<p>First, we examine the probabilistic forecasts of both GPT-4 and the human crowd for each question in a directional analysis.See Figure 1 for a paired comparison plot illustrating the respective probability forecasts, with the upper panel displaying questions that resolved positively and the lower panel displaying questions that resolved negatively.These data indicate that in 18 out of 23 questions, the median human-crowd forecasts were directionally closer to the truth than GPT-4's predictions, χ 2 (1) = 12.52, p = .001.</p>
<p>We also compared the frequency with which each of GPT-4's forecast and the aggregate human forecast was directionally correct, i.e., on the correct side of the probability midpoint.When doing so, we observed that the GPT-4 forecast was directionally correct 69.57% of the time, in contrast to 95.65% of the time for the aggregate human forecast, although the difference in distributions between the two was not statistically significant, χ 2 (1) = 3.78, p = .052.Similarly, the 69.57% proportion of directionally correct answers for GPT-4 also did not statistically deviate from the random 50% baseline, Z = 1.88, p = .061.These data suggest that while the aggregate human forecasts were comparatively more often closer to the truth than those of GPT-4, we do not find statistically significant results when testing this independently in relation to the probability scale midpoint.</p>
<p>The primary pre-registered outcome of interest for our analysis is forecasting accuracy.To compute this accuracy as our dependent variable, we employ Brier scores, 5 with the score for each individual provided below.Here, f is the forecasted probability and o is the observed outcome (which is 1 if the event occurs and 0 if it does not), given by B = (f − o) 2 .We then aggregate the question-level Brier scores per condition as
1 N N i=1 (f i,condition − o i ) 2 .
(</p>
<p>A perfect accuracy would yield a Brier score of 0, while perfect inaccuracy would result in a Brier score of 1.</p>
<p>In our data, we calculate the mean accuracy by aggregating the the question-level Brier scores for GPT-4's predictions and the median human-crowd forecasts.We observe an average Brier score for GPT-4's predictions of B = .20(SD = .18),while the human forecaster average Brier score was B = .07(SD = .08).Initially, we test both GPT-4's and the human crowd's accuracy against a simple no-information baseline.This baseline is the Brier score of 0.25, equivalent to predicting 50% on each question.This serves as a first test of prediction accuracy.Our analysis reveals that GPT-4 does not exhibit predictive performance that is statistically distinct from the no-information baseline, t(22) = −1.23,p = 0.23.On the other hand, we find that the human crowd's accuracy is significantly superior to that of the no-information baseline, t(  findings suggest that while the aggregate human-crowd forecasts have high accuracy, the mean LLM forecasts do not significantly improve on the no-information baseline.</p>
<p>In order to test our pre-registered null hypothesis, we compare the mean accuracy of GPT-4 and that of the human crowd.This yields a total mean difference of ∆ = .13,which is statistically significant at the two-tailed test, t(44) = 3.11, p = .003,with an effect size of Cohen's d = .94.</p>
<p>Based on this, we reject our null hypothesis, and conclude that GPT-4 significantly underperforms in this real-world forecasting tournament compared to the median human-crowd forecasts that are currently employed in forecasting tournaments.We also find that GPT-4's accuracy was not significantly different on questions that included the community prediction compared to those that did not, t(21) = −1.81,p = 0.085, suggesting that this result is explained by an internal factor of GPT-4's forecasting performance.For a graphical depiction of the distribution of Brier scores per condition, see Figure 2.</p>
<p>One potential reason that might explain this outcome could be that GPT-4's predictions, due to its reinforcement learning from human feedback, 40  midpoint (50%) in a form of model conservatism.This could explain the low prediction accuracy in our forecasting tournament with a small-to-medium sample size of questions.To analyse this, we conducted the following exploratory analyses.First, we computed the coefficient of variation (CV) as a normalized measure of dispersion for the predictions made by both GPT-4 and the human crowd.Our analysis found a CV of 48.22% for GPT-4 and 73.67% for the human crowd when centered on the mean, suggesting that GPT-4 has less dispersion.Similarly, when anchoring the CV around the midpoint of the probability scale, the values were 42.14% for GPT-4 and 57.59% for the human crowd respectively, again showing the pattern of GPT-4 having less dispersion.</p>
<p>These analyses might suggest that GPT-4's predictions could be more densely clustered around both the mean and the midpoint compared to the human crowd, aligning with a more cautious prediction pattern: one that is less inclined towards extreme forecasts.However, our inferential analysis employing Levene's test for equality of variances at the 50% midpoint did not yield statistically significant evidence to substantiate differences in variance around the midpoint, F (1, 44) = .54,p = .47.Thus, our results do not provide grounds for asserting a difference in variance around the probability scale midpoint.See Figure 3 for a graphical representation of these findings.Furthermore, in an additional exploratory analysis, we probe whether the relationship between the duration of a forecasting question remaining unresolved and the forecasting accuracy at the inception of this period significantly diverges between GPT-4's forecasts and human-crowd forecasts.This is interesting because it may be that GPT-4's forecasts are especially good, or especially bad, at predicting questions that resolve very quickly compared to those that do not.See Figure 4 for a scatterplot illustrating accuracy and question duration with linear fits.Our results show that we do not detect statistically significant effects of duration, ps &gt; .36.To test this question directly, we conducted an Analysis of Covariance (ANCOVA) to assess whether the relationship between accuracy and question duration differs between GPT-4's forecasts and those made by human forecasters.The main effect of the method (human crowd vs. GPT-4) was statistically significant, F (1, 42) = 9.38, p = .004,indicating a notable difference in accuracy between the two forecasting methods.However, the main effect of duration was not significant, F (1, 42) = 0.017, p = .898,suggesting that question duration did not significantly affect the accuracy of forecasts.Moreover, the interaction between method and duration was also not significant, F (1, 42) = 0.75, p = .392,suggesting that the relationship between question duration and accuracy did not significantly vary between GPT-4 and the human crowd.</p>
<p>Additionally, there are also a variety of aggregation techniques that may prove useful in combining the aggregate human forecast and GPT-4's forecast.We report the exploratory results of a Bayesian Model Averaging (BMA) approach, which takes into account the uncertainty across models prior to combining the predictions from multiple models.We first calculate the likelihoods of each model (.82 for GPT-4 and .93 for the human crowd) before normalizing them and computing the posterior model probabilities.With these, we have the following weighted average:
Brier BMA = (0.467 • Brier GPT-4 ) + (0.533 • Brier Human Crowd ).(2)
We compute Brier BMA = .13(SD = .09),which is significantly more accurate than the random baseline, t(22) = −5.91,p &lt; .001.</p>
<p>We have presented this simple aggregation as an instance of how LLM predictions may feed into future aggregation approaches.We point out that given our finding of poor prediction accuracy, current models like GPT-4 may be unlikely to make worthwhile additions to aggregation algorithms.However, this may change with advances in LLM capabilities and LLM-forecasting technology.</p>
<p>Discussion</p>
<p>Our findings from entering GPT-4 into a real-world forecasting tournament on the Metaculus platform suggest that even this state-of-the-art LLM has unimpressive forecasting capabilities.Despite being prompted with established superforecasting techniques and best-practice prompting approaches, GPT-4 was heavily outperformed by the forecasts of the human crowd, and did not even outperform a no-information baseline of predicting 50% on every question.The robustness of this finding is suggested by the fact that the question set was diverse, drawing on a wide variety of topics like Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.We argue that our data also provide additional evidence for the predictive power of human crowd forecasting competitions, as their accuracy was impressive throughout the questions studied here.Our results thus suggest that current LLMs may not yet perform well in a variety of real-world prediction tasks that would necessitate probabilistic foresight.</p>
<p>One potential contributing factor to GPT-4's inadequate forecasting capability is the fact that its training data is subject to a knowledge cutoff after a certain point in time. 28In contrast to human forecasters who keep up-to-date with recent events, GPT-4 is not updated with events that occur post-training.Given the dynamic nature of many world events, GPT-4's lack of real-time knowledge updating can be a significant barrier to accurate forecasting.Our design tried to address this concern by inputting the question's background information presented on Metaculus to the LLM, so that it would not be wholly unaware of a potentially novel context.While this does not fully bring the model up to speed with human forecasters that seek out prediction competition on Metaculus, it does help mitigate the information gap posed by the knowledge cutoff.Additional ways to mitigate the limitations to forecasting posed by LLMs' knowledge cutoff would be fruitful in future studies. 18enAI's mission is to create "highly autonomous systems that outperform humans at most economically valuable work." 29Whether this AI-led future is on track to occur will likely be in large part determined by how capable LLMs-and AI systems in general-turn out to be at economically relevant tasks, 31 especially without human hand-holding.Forecasting is a task of especially high economic relevance, especially for a large proportion of white-collar fields-such as business, policy, and law-that rely heavily on accurate predictions across a myriad of contexts.As of now, our results suggest that even state-of-the-art AI systems are not yet posed to replace human expertise in these areas, due to the inadequate forecasting capabilities of these systems.However, it will be especially important to closely monitor AI capability advances in the domain of accurate forecasting, as foresight will remain an essential skill for autonomous systems.</p>
<p>Another relevant implication of AI forecasting capabilities-or lack thereof-is the risk arising from AI systems that are proficient at long-term planning.An AI system with robust long-term planning capabilities would be able to presciently pursue their goal, which can be a sizable and potentially catastrophic danger if the goal happens to be incompatible with the well-being of humans 26 (e.g., the goal of engineering a pandemic that kills as many people as possible over the long run).Proficiency in long-term planning requires the ability to accurately forecast future scenarios.For many realworld tasks, such accurate forecasting is a highly complex endeavor, at which even many (but not all) humans arguably perform poorly. 34Our finding that GPT-4 has particularly poor forecasting capabilities bolsters the case that the threat of an AI system planning in the long term against human interests remains presently low.However, this should not be taken as a reason to be complacent.The pace at which AI capabilities advance suggests that it remains crucial to continually monitor the progression of AI systems in terms of their forecasting abilities to ensure that their development remains robustly safe.</p>
<p>Our results raise several avenues for further research.First, it may be argued that our findings might, at least in part, be explained by the human comparison group's ability to harness the wisdom of the crowd, 14 whereas the LLM prediction might be best understood as a single forecast only.One counterargument to this claim is that LLM predictions themselves may draw on a wisdomof-the-crowd effect from their large and multifaceted training dataset.Future research on how to employ a larger ensemble of LLM forecasters that draw on diverse inputs, training datasets, prompts, temperature values, and other variations would be fruitful.</p>
<p>Second, there may be merit in implementing LLM forecasters that can access the internet for information and autonomously update their forecasts.While the design and implementation of such a setup pose challenges, particularly as most such design choices require human input which may introduce bias, it remains a noteworthy endeavor.Internet access may also help mitigate the design weakness outlined earlier, where the temporal distance between the training data cutoff and the forecasting question's start may impair contextual understanding of the question details.</p>
<p>Third, we outlined a simple Bayesian model-averaging approach for aggregating human and machine forecasts.Future work may delve deeper into alternative ways to combine such forecasts, such as exploring ways of using LLM forecasts in extremizing algorithms or other ways of selectively choosing to favor or disfavor LLM forecasts depending on their eventual performance and comparative strengths and weaknesses.However, it is worth pointing out that given the current poor prediction performance, such approaches probably only become worthwhile once LLM foresight abilities are significantly improved.</p>
<p>Finally, it would be productive to investigate the integration of human and LLM forecasts, such as by examining whether hybrid forecasting models outperform the standalone baselines.Such hybrid forecasters (i.e., human forecasters that rely upon LLM outputs to make predictions) may be able to combine the respective strengths of both human cognition and LLM cognition, which open up the potential for new forecasting techniques based on the augmentation-rather than replacement-of humans by AI. 3 Our data suggest a clear weakness in an otherwise impressive catalogue of LLM capabilities: predicting the future.This highlights a number of technical challenges and future research directions for how LLMs may be harnessed for forecasting, as well as for various real-world tasks that require or are helped by robust forecasting capabilities.Our results suggest that the wisdom of human crowds remains a powerful tool in providing probabilistic forecasts about the future.This context of a forecasting tournament may also prove to be an especially fruitful environment for probing the degree to which LLMs are capable of generalized reasoning and prediction.</p>
<p>Resolution Criteria</p>
<p>This question resolves as Yes if, before October 1, 2023, a member of the Republican Party introduces a resolution to remove Kevin McCarthy as Speaker of the House and a vote on the resolution is held.Both the introduction of the resolution and the vote must occur before October 1, 2023.Otherwise this question resolves as No.The outcome of the vote and any such resolutions introduced by representatives who are not Republicans are irrelevant for the purposes of this question.</p>
<p>Background Information</p>
<p>Kevin McCarthy was elected Speaker of the US House of Representatives on January 7, 2023, after 15 ballots, the first time since 1923 an election for Speaker required more than one ballot.The contentious election and concessions to the House Freedom Caucus -including rules that allow any member of the House to call for a vote that would oust the Speaker by simple majority -have weakened his position as Speaker.</p>
<p>The rules for the House of Representatives of the 118th Congress adopt those of the 117th Congress with some amendments.The relevant portion of the rules is Rule IX, the text of which is quoted below.The amended rules remove subparagraph (3) of clause 2(a) (shown in bold).</p>
<ol>
<li>
<p>Questions of privilege shall be, first, those affecting the rights of the House collectively, its safety, dignity, and the integrity of its proceedings; and second, those affecting the rights, reputation, and conduct of Members, Delegates, or the Resident Commissioner, individually, in their representative capacity only.</p>
</li>
<li>
<p>(a)(1) A resolution reported as a question of the privileges of the House, or offered from the floor by the Majority Leader or the Minority Leader as a question of the privileges of the House, or offered as privileged under clause 1, section 7, article I of the Constitution, shall have precedence of all other questions except motions to adjourn.A resolution offered from the floor by a Member, Delegate, or Resident Commissioner other than the Majority Leader or the Minority Leader as a question of the privileges of the House shall have precedence of all other questions except motions to adjourn only at a time or place, designated by the Speaker, in the legislative schedule within two legislative days after the day on which the proponent announces to the House an intention to offer the resolution and the form of the resolution.Oral announcement of the form of the resolution may be dispensed with by unanimous consent.</p>
</li>
</ol>
<p>(2) The time allotted for debate on a resolution offered from the floor as a question of the privileges of the House shall be equally divided between (A) the proponent of the resolution, and (B) the Majority Leader, the Minority Leader, or a designee, as determined by the Speaker.</p>
<p>(3) A resolution causing a vacancy in the Office of Speaker shall not be privileged except if offered by direction of a party caucus or conference.(b) A question of personal privilege shall have precedence of all other questions except motions to adjourn.</p>
<p>On September 19, 2023, journalist Matt Laslo claimed to have discovered a draft motion to vacate the office of Speaker of the House in a bathroom in the US Capitol, with Matt Gaetz as the member to submit the resolution.</p>
<p>Figure 1 :
1
Figure 1: Paired comparison plot showing probability forecasts (in %) per question for the median human-crowd forecast and the GPT-4 forecast.The top panel lists questions that resolved negatively.The bottom panel lists questions that resolved positively.</p>
<p>Figure 3 :
3
Figure 3: Raincloud plot of the distribution of probability forecasts (in %) made by GPT-4 and by the median human-crowd forecast for all questions.Box plots represent interquartile ranges.</p>
<p>Figure 4 :
4
Figure 4: Scatterplot and linear fit for the relationship between forecasting accuracy (Brier score) and duration (in days) by condition.</p>
<p>AcknowledgementsWe thank Molly Hickman, Barbara Fasolo, Siti Liyana Azman, Indre Tuminauskaite, Jeffrey Haines, Isabel Juniewicz, Philip Tetlock, and the Metaculus team for helpful comments.P.S. is funded by the LSE Department of Management.P.S.P. is funded by the MIT Department of Physics.Data availabilityOur pre-registration and analysis plan can be found in our Open Science Foundation database: https://osf.io/tfbvd/?view_only=bfc6d61152654e3b84c36446f1858fb2Appendix A Forecasting questions Will India's Chandrayaan-3 mission successfully land a rover on the moon?Will Mohamed Bazoum, Nigerien President, return to power before August 31, 2023?Will the House Oversight Committee receive access to requested Joe Biden records related to Hunter Biden's Ukraine dealings before September 1st?Will General Sergei Surovikin be stripped of his command by July 11th?Will Putin attend the G20 summit in India?Will the United Auto Workers call a strike against any of the Big Three Detroit automakers before September 19, 2023?Will Chevron reach an agreement with the Offshore Alliance to end or prevent industrial actions before September 25, 2023?Before October 1, 2023, will US Senator Bob Menendez announce that he is resigning?Who will be the de facto leader of Gabon on September 30, 2023 (General Brice Oligui Nguema)?Who will be the de facto leader of Gabon on September 30, 2023?(Albert Ondo Ossa) Table2: Full list of forecasting questions used in our study.Appendix B Example forecasting question and its corresponding informationQuestionWill a vote on a Republican-introduced resolution to vacate the Speaker of the House be held before October 1, 2023?
A Theory for Emergence of Complex Skills in Language Models. Sanjeev Arora, Anirudh Goyal, arXiv:2307.159362023arXiv preprint</p>
<p>On the Dangers of Stochastic Parrots: Can Language Models be too Big?. Emily M Bender, 10.1145/3442188.3445922Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT '21. Virtual Event. the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT '21. Virtual EventCanadaAssociation for Computing Machinery2021</p>
<p>Hybrid Forecasting of Geopolitical Events. M Daniel, Benjamin, AI Magazine2023</p>
<p>Emergent and Predictable Memorization in Large Language Models. Stella Biderman, arXiv:2304.11158[cs.CL]2023</p>
<p>Verification of Forecasts Expressed in Terms of Probability. Glenn W Brier, Monthly Weather Review. 781950</p>
<p>Sébastien Bubeck, arXiv:2303.12712[cs.CL]Sparks of Artificial General Intelligence: Early Experiments with GPT-4. 2023. </p>
<p>Identifying Expertise to Extract the Wisdom of Crowds. V David, Eva Budescu, Chen, Management Science. 612015</p>
<p>Quantifying Memorization Across Neural Language Models. Nicholas Carlini, The Eleventh International Conference on Learning Representations, ICLR 2023. Kigali, RwandaMay 1-5, 2023. OpenReview.net, 2023</p>
<p>Asking Better Questions: The Art and Science of Forecasting. Emily Dardaman, Abhishek Gupta, CHI 2023 Designing Technology and Policy Simultaneously: Towards A Research Agenda and New Practice Workshop. Hamburg, GermanyACM2023</p>
<p>When is a Crowd Wise?. P Clintin, Davis-Stober, In: Decision. 12792014</p>
<p>News Summarization and Evaluation in the Era of GPT-3. Tanya Goyal, Junyi , Jessy Li, Greg Durrett, arXiv:2209.12356[cs.CL]2023</p>
<p>A Continuum of Learning: From Rote Memorization to Meaningful Learning in Organic Chemistry. P Nathaniel, Stacey Grove, Bretz Lowery, Chemistry Education Research and Practice. 1332012</p>
<p>Large Language Models Are Zero-Shot Time Series Forecasters. Nate Gruver, arXiv:2310.07820[cs.LG]2023</p>
<p>The Wisdom of Timely Crowds. Mark Himmelstein, David V Budescu, Ying Han, Judgment in Predictive Analytics. Springer2023</p>
<p>Is ChatGPT a Good Translator? Yes with GPT-4 as the Engine. Wenxiang Jiao, arXiv:2301.08745[cs.CL]2023</p>
<p>What do Forecasting Rationales Reveal about Thinking Patterns of Top Geopolitical Forecasters?. Christopher W Karvetski, In: International Journal of Forecasting. 382022</p>
<p>GPT-4 Passes the Bar Exam. Martin Daniel, Katz, SSRN. 2023</p>
<p>Large Language Models with Controllable Working Memory. Daliang Li, 10.18653/v1/2023.findings-acl.112Findings of the Association for Computational Linguistics: ACL 2023. Toronto, CanadaAssociation for Computational Linguistics2023</p>
<p>Data Contamination: From Memorization to Exploitation. Inbal Magar, Roy Schwartz, 10.18653/v1/2022.acl-short.18Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational LinguisticsMay 20222Short Papers)</p>
<p>The Wisdom of Select Crowds. Jack B Albert E Mannes, Richard P Soll, Larrick, Journal of Personality and Social Psychology. 1072762014</p>
<p>Chimeric Forecasting: Combining Probabilistic Predictions from Computational Models and Human Judgment. Thomas Mcandrew, BMC Infectious Diseases. 228332022</p>
<p>Early Human Judgment Forecasts of Human Monkeypox. Thomas Mcandrew, The Lancet Digital Health. 4May 2022. 2022</p>
<p>Identifying and Cultivating Superforecasters as a Method of Improving Probabilistic Predictions. Barbara Mellers, Perspectives on Psychological Science. 1032015</p>
<p>Quarterly Cup. Metaculus, 2023</p>
<p>A Comprehensive Overview of Large Language Models. Humza Naveed, </p>
<p>The Alignment Problem from a Deep Learning Perspective. Richard Ngo, Lawrence Chan, Sören Mindermann, arXiv:2209.00626[cs.AI]2023</p>
<p>Capabilities of GPT-4 on Medical Challenge Problems. Harsha Nori, arXiv:2303.13375[cs.CL]2023</p>
<p>GPT-4. arXiv:2303.08774[cs.CL]2023OpenAITechnical Report</p>
<p>. Openai Openai, Charter, Openai, 2018</p>
<p>Diminished Diversity-of-Thought in a Standard Large Language Model. Peter S Park, Philipp Schoenegger, Chongyang Zhu, arXiv:2302.07267[cs.HC]2023</p>
<p>Divide-and-Conquer Dynamics in AI-Driven Disempowerment. Peter S Park, Max Tegmark, arXiv:2310.06009[cs.CY]2023</p>
<p>AI Deception: A Survey of Examples, Risks, and Potential Solutions. Peter S Park, arXiv:2308.14752[cs.CY]2023</p>
<p>Forecasting: Theory and Practice. Fotios Petropoulos, International Journal of Forecasting. 382022</p>
<p>Superforecasting: The Art and Science of Prediction. Philip E Tetlock, Dan Gardner, 2016Random House</p>
<p>Bringing Probability Judgments into Policy Debates via Forecasting Tournaments. Philip E Tetlock, Barbara A Mellers, Scoblic Peter, Science. 3552017</p>
<p>Forecasting Tournaments: Tools for Increasing Transparency and Improving the Quality of Debate. Philip E Tetlock, Current Directions in Psychological Science. 232014</p>
<p>Attention is All You Need. Ashish Vaswani, Advances in Neural Information Processing Systems. 302017</p>
<p>Can ChatGPT Pass High School Exams on English Language Comprehension?. C F Joost, Winter, In: International Journal of Artificial Intelligence in Education. 1560-42922023</p>
<p>ExpertPrompting: Instructing Large Language Models to be Distinguished Experts. Benfeng Xu, arXiv:2305.14688[cs.CL]2023</p>
<p>Fine-tuning Language Models from Human Preferences. M Daniel, Ziegler, arXiv:1909.085932019arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>