<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6925 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6925</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6925</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-255523691</p>
                <p><strong>Paper Title:</strong> <a href="https://api.elsevier.com/content/article/pii/S1364661322003230" target="_blank">Decoding semantic representations in mind and brain</a></p>
                <p><strong>Paper Abstract:</strong> A key goal for cognitive neuroscience is to understand the neurocognitive systems that support semantic memory. Recent multivariate analyses of neuroimaging data have contributed greatly to this effort, but the rapid development of these novel approaches has made it difficult to track the diversity of findings and to understand how and why they sometimes lead to contradictory conclusions. We address this challenge by reviewing cognitive theories of semantic representation and their neural instantiation. We then consider contemporary approaches to neural decoding and assess which types of representation each can possibly detect. The analysis suggests why the results are heterogeneous and identifies crucial links between cognitive theory, data collection, and analysis that can help to better connect neuroimaging to mechanistic theories of semantic cognition.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6925.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6925.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Category-based theories</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Category-based semantic representation theories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theoretical class proposing that semantic memory stores discrete, independent category representations (e.g., 'bird', 'car') that are activated for stimuli and drive access to category-typical properties and inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Category-based theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic / probabilistic distribution over categories</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as discrete units or axes corresponding to categories; a stimulus is mapped to a category representation (or a multinomial distribution over categories) which then provides access to associated semantic information.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains fast categorization, typicality effects, and provides direct access to category-typical properties; supports classification-based comprehension and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral experiments; neuroimaging (MVPC, univariate); neuropsychology</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>category verification, rapid categorization, fMRI decoding of category labels</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Neuroimaging and lesion studies often find brain regions whose activation discriminates categories reliably across subjects, consistent with localized category signals (e.g., category-selective regions in ventro-temporal cortex).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Multivariate and generative analyses can also be explained by feature-based or vector-space representations; distributed/conjoint codes and modality-grounded representations can produce category-discriminative patterns without dedicated discrete category units.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6925.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feature-based theories</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feature-based (featural) semantic representation theories</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representations are vectors of interpretable semantic features (e.g., can fly, has feathers) where each dimension independently encodes presence/absence or probability of a property.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Feature-based theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature‑based vector</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Each concept is a vector over explicitly interpretable features; conceptual similarity derives from feature overlap and retrieval entails reading feature elements (possibly thresholded) to infer properties.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for property-based similarity, typicality, graded inference, and cross-modal generalization when features are grounded in modality-specific systems.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>behavioral feature-norming; fMRI/encoding studies; neuropsychological dissociations</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>semantic feature verification, semantic feature production norms, encoding models predicting voxel activity from feature vectors</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Encoding models fit with interpretable feature vectors can predict voxel responses and yield maps where voxels appear to weight interpretable features, suggesting local feature encoding in cortex (though results depend on regularizer/assumptions).</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Interpretation of voxel-feature weight maps is sensitive to regularization choices and often yields mosaic-like or unexpected localizations; conjoint codes can hide interpretable feature mappings at single-unit level.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6925.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vector-space models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>High-dimensional vector-space (distributional) semantic models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are points in a high-dimensional space with uninterpretable dimensions (e.g., LSA, word2vec, BERT embeddings); similarity and directions in that space support retrieval/inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Vector-space / Distributional semantic models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high‑dimensional space</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Each concept corresponds to a dense activation vector across representational units whose relative position to other vectors encodes semantic similarity; dimensions need not be interpretable individually.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains graded similarity relations, analogy via vector arithmetic/directions, and supports distributional accounts of meaning derived from co-occurrence statistics or neural network internal states.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational models; fMRI encoding/decoding (encoding/decoder inversion studies); comparisons with deep network layers</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>encoding/decoding using distributional embeddings; RSA comparing neural similarity to model similarity matrices; sentence-level decoding from whole-brain patterns</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Whole-brain inverted encoding using distributional vectors can recover sentence/word meaning with measurable accuracy and widespread voxel involvement, consistent with distributed vector-like coding but not informative about single-unit interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Symbol-grounding problem: distributional vectors need mapping to modality-specific surface representations to support grounded inference; fMRI spatial distribution is variable across subjects making one-to-one mapping unclear.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6925.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-contained vs Grounded</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-contained versus grounded semantic representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Dichotomy about retrieval: self-contained views hold that semantic representations encapsulate retrievable content; grounded views hold meaning is realized by mapping to modality-specific surface representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Self-contained vs Grounded representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation vs internal vector/symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Self-contained: representations contain retrievable content (features or vector-space proximities suffice for inference). Grounded: semantic representations derive meaning by activating modality-specific perceptual/action/linguistic systems (surface representations) that realize properties.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Grounded theories explain embodiment effects, modality-specific activations during semantic tasks; self-contained theories explain cross-modal decoding from a single amodal representational system.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI (modality-specific activations), TMS, lesion studies, behavioral (embodiment effects)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>cross-modal decoding, tasks probing multiple stimulus modalities, TMS disruption of modality-specific areas</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Decoding semantic information from modality-specific cortices (e.g., visual areas for pictures) is common, but cross-modal decoding studies are relatively few and mixed; lesion/TMS evidence implicates bilateral anterior temporal lobes (ATL) in amodal conceptual representation, supporting some grounded-hub hybrid accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Decodability from visual/perceptual areas could reflect perceptual confounds rather than semantic encoding; self-contained accounts face symbol-grounding problem without mappings to surface representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6925.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hub-and-spokes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hub-and-spokes model of semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neurocomputational proposal that a transmodal hub (bilateral anterior temporal lobes) integrates modality-specific 'spokes' to form amodal conceptual representations used for inference and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Hub-and-spokes model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational network / integrative hub</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Spokes are modality-specific regions encoding perceptual and motor properties; a central hub (ATL) binds and abstracts across modalities producing amodal conceptual representations that mediate cross-modal generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains cross-modal semantic impairment following ATL damage (semantic dementia), generalization across modalities, and graded conceptual structure.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>lesion studies (semantic dementia), rTMS, fMRI (ATL involvement), computational simulation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>cross-modal semantic tasks, TMS disruption of ATL, fMRI with orthogonalized visual/semantic similarity</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Convergent evidence from semantic dementia, rTMS to ATL slowing semantic judgments, and distortion-corrected fMRI implicate bilateral ATL as critical hub-like locus for transmodal conceptual representation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Some studies find semantic structure in multiple distributed regions; precise localization and extent of hub function vary and depend on imaging methods/coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6925.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Convergence zone</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convergence zone hypothesis (Damasio)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposal that convergence zones (association regions) bind multiregional modality-specific activations to form coherent conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Convergence zone hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>binding / distributed convergence</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Higher-order association regions act as convergence hubs that coordinate activity across modality-specific areas to bind perceptual, motor, and linguistic representations into integrated concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains binding of distributed representations into unitary concepts and the role of association cortices in semantic retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical proposal supported by lesion and connectivity studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>connectivity analyses, lesion correlation, multimodal semantic tasks</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Connectivity and lesion evidence indicate association areas coordinate modality-specific regions, consistent with convergence zone function, but spatially distributed contributions complicate simple localization.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Degree to which convergence zones constitute discrete, localized hubs versus widely distributed graded systems is debated; imaging limitations (e.g., signal dropout) may obscure full picture.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6925.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GRAPES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GRAPES (Grounding Representations in Action, Perception, and Emotion Systems)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Framework proposing that semantic features are 'labeled' by connectivity to modality-specific surface representations, grounding features in perception, action, and emotion networks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>GRAPES framework</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>grounded / feature‑based</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Featural dimensions in semantic representation gain their meaning via preferential connectivity to corresponding modality-specific cortical areas (e.g., color features linked to color perception areas).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for anatomically predictable distributions of feature encoding (e.g., action-related features in motor regions), explains cross-domain interactions and modality-specific deficits.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI activation patterns; connectivity studies; behavioral feature norms</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>feature rating tasks, fMRI contrasts for property types, connectivity mapping</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Studies that map features to cortical regions find modality-predictable activations (e.g., action features in motor-related cortex), consistent with grounded feature labeling by connectivity.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Some encoding/decoding results implicate regions without clear modality-specific function, and interpretations depend on task and regularization; distributed conjoint codes complicate simple mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6925.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic feature neural networks (PDP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallel distributed processing (PDP) / semantic feature neural network models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Computational models in which semantic knowledge emerges in distributed, graded patterns across many units via learned connectivity, with representations often conjoint and not locally interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Semantic PDP / attractor models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed neural network representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as distributed activation patterns across many units in neural networks trained on associative constraints; inference and generalization arise from network dynamics rather than labeled units.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains graded degradation patterns in semantic dementia, emergent category-specificity, and dynamic (time-varying) representational trajectories during processing.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational simulation; mapping of model representational geometry to neural data; lesion-model comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>model-to-brain RSA comparisons, ECoG temporal decoding, simulation of lesion effects</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Neurocomputational models produce conjoint, dispersed, heterogeneous codes similar to those that some whole-brain regularized decoding methods reveal; models predict dynamic representational change over time observed in ECoG.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Standard fMRI analysis choices favor discovery of localized, homogeneous signals, potentially masking the distributed conjoint codes predicted by PDP models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6925.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributional semantic models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corpus-derived distributional models (LSA, word2vec, BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Models that learn vector embeddings for words/phrases by leveraging distributional statistics in large text corpora or language models, producing high-dimensional representations used in encoding/decoding of brain data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributional semantic models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high‑dimensional vector space (learned embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Word/sentence meanings are encoded as dense vectors derived from language usage patterns; these embeddings can be used as predictors in encoding models to map language meaning to brain activation patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Can capture many aspects of semantic similarity and support decoding of linguistic meaning from neural signals; deeper models capture more abstract semantic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI encoding/decoding studies; computational comparisons; RSA</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>voxelwise encoding with distributional embeddings, inversion to decode sentences, RSA to compare model and neural RSMs</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Encoding/inversion studies using distributional embeddings can decode sentence-level meaning and reveal broad, distributed cortical involvement, but selection of voxels is highly variable across individuals.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Distributional models lack inherent grounding to modality-specific systems, raising symbol-grounding concerns; spatial distribution of predictive voxels is inconsistent across subjects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6925.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NNSE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Non-Negative Sparse Embeddings (NNSE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of distributional embeddings constrained to be sparse and non-negative to yield more interpretable, feature-like dimensions from corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>NNSE (sparse interpretable embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature‑like sparse vector embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Transforms standard corpus-based embeddings by enforcing sparsity and positivity such that dimensions resemble interpretable semantic features, enabling use as feature vectors for encoding models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Aims to combine advantages of feature-based interpretability with corpus-derived coverage, enabling more interpretable encoding maps.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>computational modeling; fMRI encoding comparisons (discussed as a method)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>use of NNSE vectors as regressors in encoding models predicting voxel responses</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>NNSE yields more interpretable dimensions than unconstrained embeddings and can be used to build feature-like predictors for voxelwise models, though empirical fMRI results depend on regularization and model inversion choices.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Interpretability gains are partial and do not resolve grounding; encoder weight maps still sensitive to analytic choices.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6925.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deep neural networks (vision/language)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep neural network models (DCNNs, transformer language models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Layered models trained on large visual or linguistic datasets that produce hierarchical internal representations; deeper layers often capture more abstract semantic structure analogous to higher-level cortex.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Deep neural networks as models of semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>learned high‑dimensional hierarchical representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Trained deep networks form layerwise activation patterns that represent increasingly abstract features; mapping neural responses onto particular model layers can illuminate which cortical regions encode visual versus semantic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Provide mechanistic accounts of hierarchical transformation from visual input to semantic structure, and can explain graded/variable representations across individuals in deeper layers.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>comparative modeling; fMRI substitution/interfacing studies; representational similarity analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>replace model layer activations with neural patterns to evaluate classification, RSA between model and brain representational geometries, encoding with model-derived features</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Studies show that deep network layers correspond to stages in ventral visual stream and that richer semantic structure represented in deeper layers is reflected across ventral cortex; individual differences increase at deeper layers.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Direct one-to-one mapping between model units and cortical units is imperfect; individual differences between trained networks and brains complicate strong claims.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6925.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Independent vs Conjoint codes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Independent (local) versus conjoint (distributed ensemble) neural codes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Coding distinction: independent codes have single units that each encode an interpretable semantic element; conjoint codes require joint patterns across units for interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Independent vs Conjoint neural coding</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>representational code organization</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Independent code: each unit signals a particular semantic feature/category irrespective of others. Conjoint code: meaning emerges from the multivariate pattern across units, and single-unit activations are not interpretable alone.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Independent coding facilitates localized feature maps and simple decoding; conjoint coding supports high-capacity, compact distributed representations and complex combinatorial structure.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>theoretical analysis; comparisons of MVPC, RSA, encoding approaches; computational models</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>MVPC, RSA, voxelwise encoding; analyses testing single-voxel interpretability vs multivariate dependencies</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Many analytic choices (ROI/searchlight/univariate) preferentially detect independent codes; regularized whole-brain methods and model comparisons reveal evidence consistent with conjoint distributed codes in some datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Apparent independent codes in many studies could reflect methodological biases (smoothing, ROIs) rather than true independence; conjoint codes are harder to detect and thus underreported.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e6925.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Homogeneous vs Heterogeneous codes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Homogeneous versus heterogeneous neural coding schemes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Within-subject code property: homogeneous codes have involved units all change in the same direction for a concept; heterogeneous codes exhibit mixed directions and magnitudes across units.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Homogeneous vs Heterogeneous code</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>representational code property</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Homogeneous: signal-carrying units uniformly increase (or decrease). Heterogeneous: different units show different sign/magnitude changes; averaging and smoothing favor detecting homogeneous codes.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Heterogeneous codes permit richer, distributed encoding but are vulnerable to temporal/spatial averaging; homogeneous codes are easier to detect with univariate approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>analytic considerations; ECoG temporal decoding; fMRI methodological comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>slow event-related fMRI, ECoG with time-windowed classifiers, analyses of effects of smoothing and averaging</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Temporal blending in BOLD or spatial smoothing can obscure heterogeneous codes; ECoG shows rapidly changing codes over time supporting heterogeneous/dynamic encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Many fMRI results showing homogeneous effects may be analytic artifacts of smoothing/averaging rather than true homogeneous neural codes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e6925.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Contiguous vs Dispersed organization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anatomical organization: contiguous versus dispersed representational layouts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Describes whether units encoding a semantic element are localized to a contiguous brain region or spread (dispersed) across multiple distant areas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Contiguous vs Dispersed anatomical organization</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>anatomical representational format</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Contiguous: representation units reside in same brain region; Dispersed: units occur in multiple anatomically distant regions and may vary across individuals.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Contiguous organization supports ROI/searchlight detection and modality-grounded maps; dispersed organization supports distributed computation and integration across networks.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI studies with different analytic strategies; model-based simulations; TMS/lesion localization contrasts</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>searchlight MVPC, whole-brain regularized decoding, lesion/TMS causal studies</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Many classic results (e.g., fusiform face area) reflect contiguous signals, but whole-brain regularized decoding and structured sparsity methods reveal broader dispersed involvement across ATL, parietal, and prefrontal regions for semantic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Searchlight and ROI methods can miss dispersed conjoint codes; demonstrating dispersion requires whole-brain sensitive acquisition and analytic choices that relax localization assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e6925.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MVPC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multivariate Pattern Classification (MVPC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Decoding approach that fits classifiers (SVM, logistic, naive Bayes) to neural patterns to predict stimulus categories; sensitive to any representation that makes categories separable in activation space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>MVPC (decoding)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>analytic method for detecting representational separability</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Trains classifiers on labeled neural response patterns to predict category labels; can detect independent or conjoint codes and both homogeneous and heterogeneous signal depending on regularization and feature selection.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Demonstrates that target categories are encoded in the measured neural patterns when classifiers generalize to held-out data.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>numerous fMRI decoding studies; comparative method analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>training/testing with cross-validation on category-labeled neural responses (images, words), ROI/searchlight/whole-brain variants</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>MVPC often finds category information in ventro-temporal and distributed regions, but results depend strongly on feature preselection (ROI/searchlight) and regularization choices (L1, L2, SOS), which bias toward sparse vs distributed solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Positive classification does not distinguish between categorical, feature-based, or vector-space representations because all can yield separable categories; overfitting and analytic assumptions can produce misleading localization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e6925.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RSA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Representational Similarity Analysis (RSA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Method that compares a target representational similarity matrix (RSM) (e.g., semantic distances) with a neural similarity matrix (NSM) to assess whether neural activation patterns reflect a hypothesized structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Representational Similarity Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>analytic method for representational geometry</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Computes pairwise similarity/dissimilarity between stimuli in model and neural data and evaluates correlation between matrices; can detect categorical, featural, or vector-space structure reflected in neural geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>A positive correlation indicates the neural population encodes the target similarity structure (not necessarily the underlying format of single units).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI RSA studies comparing visual vs semantic models; cross-modal RSA</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>searchlight or ROI RSA correlating neural NSMs with semantic or visual RSMs derived from behavior, features, or models</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>RSA findings vary with choice of target RSM and stimuli: posterior temporo-occipital areas often reflect visual structure, while more anterior ventrotemporal/ATL regions better reflect semantic structure when visual confounds are controlled.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>RSA correlations can be small yet significant; confounding factors (visual similarity) can lead to misattribution of encoding to semantics rather than perceptual structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6925.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e6925.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Encoding / Generative models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Voxelwise encoding and generative decoding approaches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Fit an encoding model per unit that predicts its response from semantic feature vectors; inversion of encoders allows decoding of semantic vectors from observed brain patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decoding semantic representations in mind and brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Encoding/generative modeling</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>analytic method linking interpretable predictors to single-unit responses</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Separate regression models predict each voxel's response from semantic predictors (features or embeddings); model weights are interpreted as indicating which features a voxel encodes, or inverted to recover stimulus-level semantic vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>When encoding succeeds with interpretable predictors, voxels can be mapped onto semantic features; inversion can recover whole-brain semantic state (sentence meaning) for decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI encoding/decoding studies (Mitchell et al. style; Huth et al.; Pereira et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>voxelwise regression using feature vectors or embeddings, inversion to rank/identify decoded words/sentences</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Encoding models with interpretable features yield local semantic feature weight maps but these depend strongly on regularization; whole-brain inversion recovers sentence meaning but selects many voxels scattered across networks and shows high intersubject variability.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Single-voxel encoders can fail when units participate in conjoint codes (their independent response is not predictable from features); regularizer choice dramatically changes apparent voxel-function mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Frisby et al., 2023</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Predicting human brain activity associated with the meanings of nouns <em>(Rating: 2)</em></li>
                <li>Natural speech reveals the semantic maps that tile human cerebral cortex <em>(Rating: 2)</em></li>
                <li>The neural and computational bases of semantic cognition <em>(Rating: 2)</em></li>
                <li>Where do you know what you know? The representation of semantic knowledge in the human brain <em>(Rating: 2)</em></li>
                <li>Semantic Cognition: A Parallel Distributed Processing Approach <em>(Rating: 2)</em></li>
                <li>Grounded cognition <em>(Rating: 2)</em></li>
                <li>Deep neural networks: a new framework for modeling biological vision and brain information processing <em>(Rating: 1)</em></li>
                <li>Representational similarity analysis reveals commonalities and differences in the semantic processing of words and objects <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6925",
    "paper_id": "paper-255523691",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Category-based theories",
            "name_full": "Category-based semantic representation theories",
            "brief_description": "Theoretical class proposing that semantic memory stores discrete, independent category representations (e.g., 'bird', 'car') that are activated for stimuli and drive access to category-typical properties and inferences.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Category-based theory",
            "theory_type": "symbolic / probabilistic distribution over categories",
            "theory_description": "Concepts are represented as discrete units or axes corresponding to categories; a stimulus is mapped to a category representation (or a multinomial distribution over categories) which then provides access to associated semantic information.",
            "functional_claims": "Explains fast categorization, typicality effects, and provides direct access to category-typical properties; supports classification-based comprehension and inference.",
            "evidence_source": "behavioral experiments; neuroimaging (MVPC, univariate); neuropsychology",
            "experimental_paradigm": "category verification, rapid categorization, fMRI decoding of category labels",
            "key_result": "Neuroimaging and lesion studies often find brain regions whose activation discriminates categories reliably across subjects, consistent with localized category signals (e.g., category-selective regions in ventro-temporal cortex).",
            "supports_theory": null,
            "counter_evidence": "Multivariate and generative analyses can also be explained by feature-based or vector-space representations; distributed/conjoint codes and modality-grounded representations can produce category-discriminative patterns without dedicated discrete category units.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.0"
        },
        {
            "name_short": "Feature-based theories",
            "name_full": "Feature-based (featural) semantic representation theories",
            "brief_description": "Representations are vectors of interpretable semantic features (e.g., can fly, has feathers) where each dimension independently encodes presence/absence or probability of a property.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Feature-based theory",
            "theory_type": "feature‑based vector",
            "theory_description": "Each concept is a vector over explicitly interpretable features; conceptual similarity derives from feature overlap and retrieval entails reading feature elements (possibly thresholded) to infer properties.",
            "functional_claims": "Accounts for property-based similarity, typicality, graded inference, and cross-modal generalization when features are grounded in modality-specific systems.",
            "evidence_source": "behavioral feature-norming; fMRI/encoding studies; neuropsychological dissociations",
            "experimental_paradigm": "semantic feature verification, semantic feature production norms, encoding models predicting voxel activity from feature vectors",
            "key_result": "Encoding models fit with interpretable feature vectors can predict voxel responses and yield maps where voxels appear to weight interpretable features, suggesting local feature encoding in cortex (though results depend on regularizer/assumptions).",
            "supports_theory": null,
            "counter_evidence": "Interpretation of voxel-feature weight maps is sensitive to regularization choices and often yields mosaic-like or unexpected localizations; conjoint codes can hide interpretable feature mappings at single-unit level.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.1"
        },
        {
            "name_short": "Vector-space models",
            "name_full": "High-dimensional vector-space (distributional) semantic models",
            "brief_description": "Concepts are points in a high-dimensional space with uninterpretable dimensions (e.g., LSA, word2vec, BERT embeddings); similarity and directions in that space support retrieval/inference.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Vector-space / Distributional semantic models",
            "theory_type": "high‑dimensional space",
            "theory_description": "Each concept corresponds to a dense activation vector across representational units whose relative position to other vectors encodes semantic similarity; dimensions need not be interpretable individually.",
            "functional_claims": "Explains graded similarity relations, analogy via vector arithmetic/directions, and supports distributional accounts of meaning derived from co-occurrence statistics or neural network internal states.",
            "evidence_source": "computational models; fMRI encoding/decoding (encoding/decoder inversion studies); comparisons with deep network layers",
            "experimental_paradigm": "encoding/decoding using distributional embeddings; RSA comparing neural similarity to model similarity matrices; sentence-level decoding from whole-brain patterns",
            "key_result": "Whole-brain inverted encoding using distributional vectors can recover sentence/word meaning with measurable accuracy and widespread voxel involvement, consistent with distributed vector-like coding but not informative about single-unit interpretability.",
            "supports_theory": null,
            "counter_evidence": "Symbol-grounding problem: distributional vectors need mapping to modality-specific surface representations to support grounded inference; fMRI spatial distribution is variable across subjects making one-to-one mapping unclear.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.2"
        },
        {
            "name_short": "Self-contained vs Grounded",
            "name_full": "Self-contained versus grounded semantic representations",
            "brief_description": "Dichotomy about retrieval: self-contained views hold that semantic representations encapsulate retrievable content; grounded views hold meaning is realized by mapping to modality-specific surface representations.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Self-contained vs Grounded representations",
            "theory_type": "embodied simulation vs internal vector/symbolic",
            "theory_description": "Self-contained: representations contain retrievable content (features or vector-space proximities suffice for inference). Grounded: semantic representations derive meaning by activating modality-specific perceptual/action/linguistic systems (surface representations) that realize properties.",
            "functional_claims": "Grounded theories explain embodiment effects, modality-specific activations during semantic tasks; self-contained theories explain cross-modal decoding from a single amodal representational system.",
            "evidence_source": "fMRI (modality-specific activations), TMS, lesion studies, behavioral (embodiment effects)",
            "experimental_paradigm": "cross-modal decoding, tasks probing multiple stimulus modalities, TMS disruption of modality-specific areas",
            "key_result": "Decoding semantic information from modality-specific cortices (e.g., visual areas for pictures) is common, but cross-modal decoding studies are relatively few and mixed; lesion/TMS evidence implicates bilateral anterior temporal lobes (ATL) in amodal conceptual representation, supporting some grounded-hub hybrid accounts.",
            "supports_theory": null,
            "counter_evidence": "Decodability from visual/perceptual areas could reflect perceptual confounds rather than semantic encoding; self-contained accounts face symbol-grounding problem without mappings to surface representations.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.3"
        },
        {
            "name_short": "Hub-and-spokes",
            "name_full": "Hub-and-spokes model of semantic representation",
            "brief_description": "Neurocomputational proposal that a transmodal hub (bilateral anterior temporal lobes) integrates modality-specific 'spokes' to form amodal conceptual representations used for inference and generalization.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Hub-and-spokes model",
            "theory_type": "relational network / integrative hub",
            "theory_description": "Spokes are modality-specific regions encoding perceptual and motor properties; a central hub (ATL) binds and abstracts across modalities producing amodal conceptual representations that mediate cross-modal generalization.",
            "functional_claims": "Explains cross-modal semantic impairment following ATL damage (semantic dementia), generalization across modalities, and graded conceptual structure.",
            "evidence_source": "lesion studies (semantic dementia), rTMS, fMRI (ATL involvement), computational simulation",
            "experimental_paradigm": "cross-modal semantic tasks, TMS disruption of ATL, fMRI with orthogonalized visual/semantic similarity",
            "key_result": "Convergent evidence from semantic dementia, rTMS to ATL slowing semantic judgments, and distortion-corrected fMRI implicate bilateral ATL as critical hub-like locus for transmodal conceptual representation.",
            "supports_theory": true,
            "counter_evidence": "Some studies find semantic structure in multiple distributed regions; precise localization and extent of hub function vary and depend on imaging methods/coverage.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.4"
        },
        {
            "name_short": "Convergence zone",
            "name_full": "Convergence zone hypothesis (Damasio)",
            "brief_description": "Proposal that convergence zones (association regions) bind multiregional modality-specific activations to form coherent conceptual representations.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Convergence zone hypothesis",
            "theory_type": "binding / distributed convergence",
            "theory_description": "Higher-order association regions act as convergence hubs that coordinate activity across modality-specific areas to bind perceptual, motor, and linguistic representations into integrated concepts.",
            "functional_claims": "Explains binding of distributed representations into unitary concepts and the role of association cortices in semantic retrieval.",
            "evidence_source": "theoretical proposal supported by lesion and connectivity studies",
            "experimental_paradigm": "connectivity analyses, lesion correlation, multimodal semantic tasks",
            "key_result": "Connectivity and lesion evidence indicate association areas coordinate modality-specific regions, consistent with convergence zone function, but spatially distributed contributions complicate simple localization.",
            "supports_theory": null,
            "counter_evidence": "Degree to which convergence zones constitute discrete, localized hubs versus widely distributed graded systems is debated; imaging limitations (e.g., signal dropout) may obscure full picture.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.5"
        },
        {
            "name_short": "GRAPES",
            "name_full": "GRAPES (Grounding Representations in Action, Perception, and Emotion Systems)",
            "brief_description": "Framework proposing that semantic features are 'labeled' by connectivity to modality-specific surface representations, grounding features in perception, action, and emotion networks.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "GRAPES framework",
            "theory_type": "grounded / feature‑based",
            "theory_description": "Featural dimensions in semantic representation gain their meaning via preferential connectivity to corresponding modality-specific cortical areas (e.g., color features linked to color perception areas).",
            "functional_claims": "Accounts for anatomically predictable distributions of feature encoding (e.g., action-related features in motor regions), explains cross-domain interactions and modality-specific deficits.",
            "evidence_source": "fMRI activation patterns; connectivity studies; behavioral feature norms",
            "experimental_paradigm": "feature rating tasks, fMRI contrasts for property types, connectivity mapping",
            "key_result": "Studies that map features to cortical regions find modality-predictable activations (e.g., action features in motor-related cortex), consistent with grounded feature labeling by connectivity.",
            "supports_theory": null,
            "counter_evidence": "Some encoding/decoding results implicate regions without clear modality-specific function, and interpretations depend on task and regularization; distributed conjoint codes complicate simple mapping.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.6"
        },
        {
            "name_short": "Semantic feature neural networks (PDP)",
            "name_full": "Parallel distributed processing (PDP) / semantic feature neural network models",
            "brief_description": "Computational models in which semantic knowledge emerges in distributed, graded patterns across many units via learned connectivity, with representations often conjoint and not locally interpretable.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Semantic PDP / attractor models",
            "theory_type": "distributed neural network representations",
            "theory_description": "Concepts are represented as distributed activation patterns across many units in neural networks trained on associative constraints; inference and generalization arise from network dynamics rather than labeled units.",
            "functional_claims": "Explains graded degradation patterns in semantic dementia, emergent category-specificity, and dynamic (time-varying) representational trajectories during processing.",
            "evidence_source": "computational simulation; mapping of model representational geometry to neural data; lesion-model comparisons",
            "experimental_paradigm": "model-to-brain RSA comparisons, ECoG temporal decoding, simulation of lesion effects",
            "key_result": "Neurocomputational models produce conjoint, dispersed, heterogeneous codes similar to those that some whole-brain regularized decoding methods reveal; models predict dynamic representational change over time observed in ECoG.",
            "supports_theory": true,
            "counter_evidence": "Standard fMRI analysis choices favor discovery of localized, homogeneous signals, potentially masking the distributed conjoint codes predicted by PDP models.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.7"
        },
        {
            "name_short": "Distributional semantic models",
            "name_full": "Corpus-derived distributional models (LSA, word2vec, BERT)",
            "brief_description": "Models that learn vector embeddings for words/phrases by leveraging distributional statistics in large text corpora or language models, producing high-dimensional representations used in encoding/decoding of brain data.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Distributional semantic models",
            "theory_type": "high‑dimensional vector space (learned embeddings)",
            "theory_description": "Word/sentence meanings are encoded as dense vectors derived from language usage patterns; these embeddings can be used as predictors in encoding models to map language meaning to brain activation patterns.",
            "functional_claims": "Can capture many aspects of semantic similarity and support decoding of linguistic meaning from neural signals; deeper models capture more abstract semantic structure.",
            "evidence_source": "fMRI encoding/decoding studies; computational comparisons; RSA",
            "experimental_paradigm": "voxelwise encoding with distributional embeddings, inversion to decode sentences, RSA to compare model and neural RSMs",
            "key_result": "Encoding/inversion studies using distributional embeddings can decode sentence-level meaning and reveal broad, distributed cortical involvement, but selection of voxels is highly variable across individuals.",
            "supports_theory": null,
            "counter_evidence": "Distributional models lack inherent grounding to modality-specific systems, raising symbol-grounding concerns; spatial distribution of predictive voxels is inconsistent across subjects.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.8"
        },
        {
            "name_short": "NNSE",
            "name_full": "Non-Negative Sparse Embeddings (NNSE)",
            "brief_description": "A variant of distributional embeddings constrained to be sparse and non-negative to yield more interpretable, feature-like dimensions from corpora.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "NNSE (sparse interpretable embeddings)",
            "theory_type": "feature‑like sparse vector embeddings",
            "theory_description": "Transforms standard corpus-based embeddings by enforcing sparsity and positivity such that dimensions resemble interpretable semantic features, enabling use as feature vectors for encoding models.",
            "functional_claims": "Aims to combine advantages of feature-based interpretability with corpus-derived coverage, enabling more interpretable encoding maps.",
            "evidence_source": "computational modeling; fMRI encoding comparisons (discussed as a method)",
            "experimental_paradigm": "use of NNSE vectors as regressors in encoding models predicting voxel responses",
            "key_result": "NNSE yields more interpretable dimensions than unconstrained embeddings and can be used to build feature-like predictors for voxelwise models, though empirical fMRI results depend on regularization and model inversion choices.",
            "supports_theory": null,
            "counter_evidence": "Interpretability gains are partial and do not resolve grounding; encoder weight maps still sensitive to analytic choices.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.9"
        },
        {
            "name_short": "Deep neural networks (vision/language)",
            "name_full": "Deep neural network models (DCNNs, transformer language models)",
            "brief_description": "Layered models trained on large visual or linguistic datasets that produce hierarchical internal representations; deeper layers often capture more abstract semantic structure analogous to higher-level cortex.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Deep neural networks as models of semantic representation",
            "theory_type": "learned high‑dimensional hierarchical representations",
            "theory_description": "Trained deep networks form layerwise activation patterns that represent increasingly abstract features; mapping neural responses onto particular model layers can illuminate which cortical regions encode visual versus semantic structure.",
            "functional_claims": "Provide mechanistic accounts of hierarchical transformation from visual input to semantic structure, and can explain graded/variable representations across individuals in deeper layers.",
            "evidence_source": "comparative modeling; fMRI substitution/interfacing studies; representational similarity analyses",
            "experimental_paradigm": "replace model layer activations with neural patterns to evaluate classification, RSA between model and brain representational geometries, encoding with model-derived features",
            "key_result": "Studies show that deep network layers correspond to stages in ventral visual stream and that richer semantic structure represented in deeper layers is reflected across ventral cortex; individual differences increase at deeper layers.",
            "supports_theory": true,
            "counter_evidence": "Direct one-to-one mapping between model units and cortical units is imperfect; individual differences between trained networks and brains complicate strong claims.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.10"
        },
        {
            "name_short": "Independent vs Conjoint codes",
            "name_full": "Independent (local) versus conjoint (distributed ensemble) neural codes",
            "brief_description": "Coding distinction: independent codes have single units that each encode an interpretable semantic element; conjoint codes require joint patterns across units for interpretation.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Independent vs Conjoint neural coding",
            "theory_type": "representational code organization",
            "theory_description": "Independent code: each unit signals a particular semantic feature/category irrespective of others. Conjoint code: meaning emerges from the multivariate pattern across units, and single-unit activations are not interpretable alone.",
            "functional_claims": "Independent coding facilitates localized feature maps and simple decoding; conjoint coding supports high-capacity, compact distributed representations and complex combinatorial structure.",
            "evidence_source": "theoretical analysis; comparisons of MVPC, RSA, encoding approaches; computational models",
            "experimental_paradigm": "MVPC, RSA, voxelwise encoding; analyses testing single-voxel interpretability vs multivariate dependencies",
            "key_result": "Many analytic choices (ROI/searchlight/univariate) preferentially detect independent codes; regularized whole-brain methods and model comparisons reveal evidence consistent with conjoint distributed codes in some datasets.",
            "supports_theory": null,
            "counter_evidence": "Apparent independent codes in many studies could reflect methodological biases (smoothing, ROIs) rather than true independence; conjoint codes are harder to detect and thus underreported.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.11"
        },
        {
            "name_short": "Homogeneous vs Heterogeneous codes",
            "name_full": "Homogeneous versus heterogeneous neural coding schemes",
            "brief_description": "Within-subject code property: homogeneous codes have involved units all change in the same direction for a concept; heterogeneous codes exhibit mixed directions and magnitudes across units.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Homogeneous vs Heterogeneous code",
            "theory_type": "representational code property",
            "theory_description": "Homogeneous: signal-carrying units uniformly increase (or decrease). Heterogeneous: different units show different sign/magnitude changes; averaging and smoothing favor detecting homogeneous codes.",
            "functional_claims": "Heterogeneous codes permit richer, distributed encoding but are vulnerable to temporal/spatial averaging; homogeneous codes are easier to detect with univariate approaches.",
            "evidence_source": "analytic considerations; ECoG temporal decoding; fMRI methodological comparisons",
            "experimental_paradigm": "slow event-related fMRI, ECoG with time-windowed classifiers, analyses of effects of smoothing and averaging",
            "key_result": "Temporal blending in BOLD or spatial smoothing can obscure heterogeneous codes; ECoG shows rapidly changing codes over time supporting heterogeneous/dynamic encoding.",
            "supports_theory": null,
            "counter_evidence": "Many fMRI results showing homogeneous effects may be analytic artifacts of smoothing/averaging rather than true homogeneous neural codes.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.12"
        },
        {
            "name_short": "Contiguous vs Dispersed organization",
            "name_full": "Anatomical organization: contiguous versus dispersed representational layouts",
            "brief_description": "Describes whether units encoding a semantic element are localized to a contiguous brain region or spread (dispersed) across multiple distant areas.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Contiguous vs Dispersed anatomical organization",
            "theory_type": "anatomical representational format",
            "theory_description": "Contiguous: representation units reside in same brain region; Dispersed: units occur in multiple anatomically distant regions and may vary across individuals.",
            "functional_claims": "Contiguous organization supports ROI/searchlight detection and modality-grounded maps; dispersed organization supports distributed computation and integration across networks.",
            "evidence_source": "fMRI studies with different analytic strategies; model-based simulations; TMS/lesion localization contrasts",
            "experimental_paradigm": "searchlight MVPC, whole-brain regularized decoding, lesion/TMS causal studies",
            "key_result": "Many classic results (e.g., fusiform face area) reflect contiguous signals, but whole-brain regularized decoding and structured sparsity methods reveal broader dispersed involvement across ATL, parietal, and prefrontal regions for semantic tasks.",
            "supports_theory": null,
            "counter_evidence": "Searchlight and ROI methods can miss dispersed conjoint codes; demonstrating dispersion requires whole-brain sensitive acquisition and analytic choices that relax localization assumptions.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.13"
        },
        {
            "name_short": "MVPC",
            "name_full": "Multivariate Pattern Classification (MVPC)",
            "brief_description": "Decoding approach that fits classifiers (SVM, logistic, naive Bayes) to neural patterns to predict stimulus categories; sensitive to any representation that makes categories separable in activation space.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "MVPC (decoding)",
            "theory_type": "analytic method for detecting representational separability",
            "theory_description": "Trains classifiers on labeled neural response patterns to predict category labels; can detect independent or conjoint codes and both homogeneous and heterogeneous signal depending on regularization and feature selection.",
            "functional_claims": "Demonstrates that target categories are encoded in the measured neural patterns when classifiers generalize to held-out data.",
            "evidence_source": "numerous fMRI decoding studies; comparative method analyses",
            "experimental_paradigm": "training/testing with cross-validation on category-labeled neural responses (images, words), ROI/searchlight/whole-brain variants",
            "key_result": "MVPC often finds category information in ventro-temporal and distributed regions, but results depend strongly on feature preselection (ROI/searchlight) and regularization choices (L1, L2, SOS), which bias toward sparse vs distributed solutions.",
            "supports_theory": null,
            "counter_evidence": "Positive classification does not distinguish between categorical, feature-based, or vector-space representations because all can yield separable categories; overfitting and analytic assumptions can produce misleading localization.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.14"
        },
        {
            "name_short": "RSA",
            "name_full": "Representational Similarity Analysis (RSA)",
            "brief_description": "Method that compares a target representational similarity matrix (RSM) (e.g., semantic distances) with a neural similarity matrix (NSM) to assess whether neural activation patterns reflect a hypothesized structure.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Representational Similarity Analysis",
            "theory_type": "analytic method for representational geometry",
            "theory_description": "Computes pairwise similarity/dissimilarity between stimuli in model and neural data and evaluates correlation between matrices; can detect categorical, featural, or vector-space structure reflected in neural geometry.",
            "functional_claims": "A positive correlation indicates the neural population encodes the target similarity structure (not necessarily the underlying format of single units).",
            "evidence_source": "fMRI RSA studies comparing visual vs semantic models; cross-modal RSA",
            "experimental_paradigm": "searchlight or ROI RSA correlating neural NSMs with semantic or visual RSMs derived from behavior, features, or models",
            "key_result": "RSA findings vary with choice of target RSM and stimuli: posterior temporo-occipital areas often reflect visual structure, while more anterior ventrotemporal/ATL regions better reflect semantic structure when visual confounds are controlled.",
            "supports_theory": null,
            "counter_evidence": "RSA correlations can be small yet significant; confounding factors (visual similarity) can lead to misattribution of encoding to semantics rather than perceptual structure.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.15"
        },
        {
            "name_short": "Encoding / Generative models",
            "name_full": "Voxelwise encoding and generative decoding approaches",
            "brief_description": "Fit an encoding model per unit that predicts its response from semantic feature vectors; inversion of encoders allows decoding of semantic vectors from observed brain patterns.",
            "citation_title": "Decoding semantic representations in mind and brain",
            "mention_or_use": "mention",
            "theory_name": "Encoding/generative modeling",
            "theory_type": "analytic method linking interpretable predictors to single-unit responses",
            "theory_description": "Separate regression models predict each voxel's response from semantic predictors (features or embeddings); model weights are interpreted as indicating which features a voxel encodes, or inverted to recover stimulus-level semantic vectors.",
            "functional_claims": "When encoding succeeds with interpretable predictors, voxels can be mapped onto semantic features; inversion can recover whole-brain semantic state (sentence meaning) for decoding.",
            "evidence_source": "fMRI encoding/decoding studies (Mitchell et al. style; Huth et al.; Pereira et al.)",
            "experimental_paradigm": "voxelwise regression using feature vectors or embeddings, inversion to rank/identify decoded words/sentences",
            "key_result": "Encoding models with interpretable features yield local semantic feature weight maps but these depend strongly on regularization; whole-brain inversion recovers sentence meaning but selects many voxels scattered across networks and shows high intersubject variability.",
            "supports_theory": null,
            "counter_evidence": "Single-voxel encoders can fail when units participate in conjoint codes (their independent response is not predictable from features); regularizer choice dramatically changes apparent voxel-function mappings.",
            "citation": "Frisby et al., 2023",
            "uuid": "e6925.16"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Predicting human brain activity associated with the meanings of nouns",
            "rating": 2,
            "sanitized_title": "predicting_human_brain_activity_associated_with_the_meanings_of_nouns"
        },
        {
            "paper_title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
            "rating": 2,
            "sanitized_title": "natural_speech_reveals_the_semantic_maps_that_tile_human_cerebral_cortex"
        },
        {
            "paper_title": "The neural and computational bases of semantic cognition",
            "rating": 2,
            "sanitized_title": "the_neural_and_computational_bases_of_semantic_cognition"
        },
        {
            "paper_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "rating": 2,
            "sanitized_title": "where_do_you_know_what_you_know_the_representation_of_semantic_knowledge_in_the_human_brain"
        },
        {
            "paper_title": "Semantic Cognition: A Parallel Distributed Processing Approach",
            "rating": 2,
            "sanitized_title": "semantic_cognition_a_parallel_distributed_processing_approach"
        },
        {
            "paper_title": "Grounded cognition",
            "rating": 2,
            "sanitized_title": "grounded_cognition"
        },
        {
            "paper_title": "Deep neural networks: a new framework for modeling biological vision and brain information processing",
            "rating": 1,
            "sanitized_title": "deep_neural_networks_a_new_framework_for_modeling_biological_vision_and_brain_information_processing"
        },
        {
            "paper_title": "Representational similarity analysis reveals commonalities and differences in the semantic processing of words and objects",
            "rating": 1,
            "sanitized_title": "representational_similarity_analysis_reveals_commonalities_and_differences_in_the_semantic_processing_of_words_and_objects"
        }
    ],
    "cost": 0.023238,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Feature Review Decoding semantic representations in mind and brain
March 2023</p>
<p>Saskia L Frisby saskia.frisby@mrc-cbu.cam.ac.uk 
Medical Research Council (MRC) Cognition and Brain Sciences Unit
Chaucer RoadCB2 7EFCambridgeUK</p>
<p>Ajay D Halai 
Medical Research Council (MRC) Cognition and Brain Sciences Unit
Chaucer RoadCB2 7EFCambridgeUK</p>
<p>Christopher R Cox 
Department of Psychology
Louisiana State University
70803Baton RougeLAUSA</p>
<p>Matthew A Lambon Ralph 
Medical Research Council (MRC) Cognition and Brain Sciences Unit
Chaucer RoadCB2 7EFCambridgeUK</p>
<p>Timothy T Rogers 
Department of Psychology
University of Wisconsin-Madison
1202 West Johnson Street53706MadisonWIUSA</p>
<p>Feature Review Decoding semantic representations in mind and brain</p>
<p>258 Trends in Cognitive Sciences
273March 202310.1016/j.tics.2022.12.006*Correspondence: (S.L. Frisby) and ttrogers@wisc.edu (T.T. Rogers). Trends in Cognitive Sciences OPEN ACCESS
A key goal for cognitive neuroscience is to understand the neurocognitive systems that support semantic memory. Recent multivariate analyses of neuroimaging data have contributed greatly to this effort, but the rapid development of these novel approaches has made it difficult to track the diversity of findings and to understand how and why they sometimes lead to contradictory conclusions. We address this challenge by reviewing cognitive theories of semantic representation and their neural instantiation. We then consider contemporary approaches to neural decoding and assess which types of representation each can possibly detect. The analysis suggests why the results are heterogeneous and identifies crucial links between cognitive theory, data collection, and analysis that can help to better connect neuroimaging to mechanistic theories of semantic cognition.The neurocognitive quest for semantic representationsCognitive science has long sought to understand the mechanisms underlying human semantic memorythe storehouse of knowledge that supports our ability to comprehend and produce language, recognize and classify objects, and understand everyday events. Recently, crossfertilization of cognition, neuroscience, and machine learning has generated a plethora of new analysis methods to aid the discovery of neural systems that encode semantic information[1][2][3][4][5]. Although this renaissance has produced a remarkable array of new findings, the evolution of different approaches across research groups makes it difficult to track them all, understand their respective strengths and limitations, and compare results across studies. Consequently, the literature contains sometimes startlingly different conclusions about the nature, structure, and organization of semantic representations in the mind and brain, and the field has little recourse for understanding why the differences arise or how they might be reconciled.We address this challenge by reviewing hypotheses about how semantic information may be encoded computationally and neurally, then critically evaluating the types of representational structure that contemporary multivariate methods can possibly discover in functional neuroimaging data. Crucially, each method encapsulates assumptions about how neural systems encode mental structure that then constrain the types of neural coding it can, and cannot, detect. Hypothesis, data collection, and analysis are therefore linked in ways that sometimes go unremarked and may explain the heterogeneity of findings in the literature. Through exposition of these points, we present an overview of the current empirical landscape with the aim of both organizing current thinking about semantic representations in mind and brain, and of providing a more general field guide to contemporary multivariate methods for brain imaging.What might semantic representations be like computationally?Semantic representations serve at least two crucial cognitive functions. First, they express conceptual similarity structureknowledge that items can be similar in kind even if they are distinct Highlights State-of-the-art brain imaging studies have recently produced a variety of sometimes contradictory conclusions about the neural systems that support human semantic memory.Multivariate techniques deployed in this work adopt implicit or explicit assumptions that limit the types of signal they can detect, and thus the types of hypotheses they can test.We lay out the space of possible cognitive and neural representations and then critically review contemporary methods to determine which analyses can test which hypotheses.The results account for the heterogeneity of recent findings and identify an important empirical and methodological gap that makes it difficult to connect the imaging literature to neurocomputational models of semantic processing.</p>
<p>A key goal for cognitive neuroscience is to understand the neurocognitive systems that support semantic memory. Recent multivariate analyses of neuroimaging data have contributed greatly to this effort, but the rapid development of these novel approaches has made it difficult to track the diversity of findings and to understand how and why they sometimes lead to contradictory conclusions. We address this challenge by reviewing cognitive theories of semantic representation and their neural instantiation. We then consider contemporary approaches to neural decoding and assess which types of representation each can possibly detect. The analysis suggests why the results are heterogeneous and identifies crucial links between cognitive theory, data collection, and analysis that can help to better connect neuroimaging to mechanistic theories of semantic cognition.</p>
<p>The neurocognitive quest for semantic representations</p>
<p>Cognitive science has long sought to understand the mechanisms underlying human semantic memorythe storehouse of knowledge that supports our ability to comprehend and produce language, recognize and classify objects, and understand everyday events. Recently, crossfertilization of cognition, neuroscience, and machine learning has generated a plethora of new analysis methods to aid the discovery of neural systems that encode semantic information [1][2][3][4][5]. Although this renaissance has produced a remarkable array of new findings, the evolution of different approaches across research groups makes it difficult to track them all, understand their respective strengths and limitations, and compare results across studies. Consequently, the literature contains sometimes startlingly different conclusions about the nature, structure, and organization of semantic representations in the mind and brain, and the field has little recourse for understanding why the differences arise or how they might be reconciled.</p>
<p>We address this challenge by reviewing hypotheses about how semantic information may be encoded computationally and neurally, then critically evaluating the types of representational structure that contemporary multivariate methods can possibly discover in functional neuroimaging data. Crucially, each method encapsulates assumptions about how neural systems encode mental structure that then constrain the types of neural coding it can, and cannot, detect. Hypothesis, data collection, and analysis are therefore linked in ways that sometimes go unremarked and may explain the heterogeneity of findings in the literature. Through exposition of these points, we present an overview of the current empirical landscape with the aim of both organizing current thinking about semantic representations in mind and brain, and of providing a more general field guide to contemporary multivariate methods for brain imaging.</p>
<p>What might semantic representations be like computationally?</p>
<p>Semantic representations serve at least two crucial cognitive functions. First, they express conceptual similarity structureknowledge that items can be similar in kind even if they are distinct Highlights State-of-the-art brain imaging studies have recently produced a variety of sometimes contradictory conclusions about the neural systems that support human semantic memory.</p>
<p>Multivariate techniques deployed in this work adopt implicit or explicit assumptions that limit the types of signal they can detect, and thus the types of hypotheses they can test.</p>
<p>We lay out the space of possible cognitive and neural representations and then critically review contemporary methods to determine which analyses can test which hypotheses.</p>
<p>The results account for the heterogeneity of recent findings and identify an important empirical and methodological gap that makes it difficult to connect the imaging literature to neurocomputational models of semantic processing. in appearance (e.g., hummingbird and ostrich), verbal labels (e.g., dog and wolf), or the action plans that engage them (e.g., glue and tape). Children as young as 9 months of age detect such relationships and use them to guide reaches even when they contravene perceptual similarity [6][7][8]. Adults can reliably judge relatedness in kind and sort items into conceptual groups on this basis [9][10][11], and both children and adults use conceptual similarity as a primary basis for generalizing names and other properties [12][13][14]. Second, semantic representations support knowledge retrieval or inferenceattributing to an item or event properties that are not directly observed or stated. For instance, when observing a picture of a parrot in a textbook, the student may infer that the item can fly even though the image is static; reading about a trip to the restaurant, she may infer that the diner had to pay even if this is not mentioned; observing the new neighbor's pet, a toddler may call it 'doggie' even if it is an unfamiliar breed, and so on. Semantic representations thus can be defined as the cognitive and neural states that express conceptual structure and support semantic retrieval/inference. Hypotheses about the cognitive mechanisms that support these functions reside within a fairly constrained space of possibilities ( Figure 1).</p>
<p>Considering conceptual structure, most approaches adopt one of three positions. The first proposes that semantic memory contains many discrete and independent category (see Glossary) representations, each corresponding roughly to a basic-level natural language concept such as tree or boat [15,16] (Figure 1, top) and possibly to more general (plant, vehicle) or specific (elm, yacht) classes [17,18]. On this view, verbal comprehension involves discerning the category to which a word refers [19] whereas comprehension of visual and other sensory inputs involves correctly classifying a perceived item [4,18,20,21]. Category-based theories explain conceptual structure by proposing that conceptually similar items activate the same category representationfor instance, parrots, hummingbirds, and robins are viewed as being conceptually related because they all activate the mental category bird.</p>
<p>The second view proposes that semantic representations are composed of local features, each independently indicating the presence/absence of a property such as is red, can fly, or has eyes ( Figure 1, middle row). Each perceived item or word activates associated features, indicating properties that are likely to be true of the item [22][23][24][25][26]. Conceptual similarity structure arises from property overlap: hummingbirds and ostriches are understood to be similar in kind because they possess many common properties (wings, feathers, etc.), but are also known to be nonidentical because they possess individuating properties as well [27,28].</p>
<p>Category-based approaches are often distinguished from feature-based views because of the special role that category representations play in determining conceptual similarity and supporting inference. For instance, prototype theories [29], 'entry-level' [18,30] and spreadingactivation views [31], rational approaches [15], and some neurally inspired models of object categorization [32] all propose that access to semantic information depends upon first matching a stimulus (image, word, sound, etc.) to a semantic category. Successful categorization then provides direct access to semantic information or initiates a 'search' of the semantic system, allowing retrieval of other properties. On such views, semantic categories constitute more than merely an additional feature that is attributed to a perceived item.</p>
<p>Nevertheless, under both approaches semantic representations can also be viewed as vectors in a high-dimensional representation space. For categorical theories, dimensions encode membership of distinct and mutually exclusive categories, and the representation of an item is a multinomial probability distribution indicating the probability that a stimulus belongs to each class. For instance, observing an item with wings, feathers, and a beak would generate a high probability density on the bird axis and a low density on axes corresponding to fish, car, boat, etc. because </p>
<p>Trends in Cognitive Sciences</p>
<p>Glossary</p>
<p>Category: (of a representation) composed of discrete, independent units that each correspond to a concept (such as boat, vehicle, or yacht). Conjoint: (of a representation) consisting of units that express different semantic information depending on the states of other units. Consistent: (of a representation) associated with the same direction of change in activation across individualsfor example, homologous voxels in different individuals become more active when representing cat. Contiguous: (of a representation) composed of units residing in the same brain region. Decoding: predicting the stimulus (or sometimes the properties of the stimulus, or of the task) experienced by a participant using patterns of activity across multiple neural units. Dispersed: (of a representation) composed of units residing in different brain regions. Electrocorticography (ECoG): a method of measuring brain activity via intracranial electrodes placed on the cortical surface. Electroencephalography (EEG): a method of measuring brain activity via electrodes placed on the scalp. Encoding model: a model that predicts the activity of a single neural unit using multiple independently interpretable features of the stimulus. Multiple encoding models are used to predict activity across multiple neural units. Feature-based: (of a representation) composed of multiple independently interpretable features (such as is red or can fly). Functional magnetic resonance imaging (fMRI): a method of measuring brain activity by detecting changes in blood flow. Grounded: (of a representation) requiring the generation of modalityspecific surface representations to produce retrieval/inference. Heterogeneous: (of a representation) consisting of units that adopt different activation states when representing a concept. Homogeneous: (of a representation) consisting of units that all adopt the same activation state when representing a concept. Inconsistent: (of a representation) associated with different directions of the probability that the item is a bird is high and the probability of it belonging to other categories is low. For feature-based theories, dimensions encode various directly interpretable properties, and the representation of an item indicates, independently on each dimension, the binomial probability that the item possesses the corresponding property. On this view, cardinal is a vector with high values on dimensions such as is red and can fly, but low values on dimensions such as has scales and can swim. Moreover, some such features may directly indicate the semantic category label of an item (e.g., 'bird', 'fish'), although, in contrast to category-based theories, such labels have no special function beyond that of other features. In both cases, conceptual structure reflects the similarity of different points in the vector space.</p>
<p>The third proposal likewise views semantic representations as points in a high-dimensional vector space, but without assigning any directly interpretable meaning to the corresponding dimensions ( Figure 1, bottom). Perception of a stimulus or word evokes an activation pattern across an ensemble of representation units, corresponding to a point in the space where the proximity between points expresses conceptual similarity [33][34][35]. Unlike feature-and category-based approaches, however, one cannot discern what information is encoded in the representation by looking at the activation of each element taken independently. Instead, what matters is the similarity of a given vector to those elicited by other items, taken across all units in the ensemble. On this view, cardinal is a vector with high values on some dimensions and low values on others.</p>
<p>Examining each dimension reveals no information about the properties of the cardinal, but information can be gleaned from the fact that cardinal is located very close to goldfinch, reasonably close to ostrich, and far from canoe (Box 1).</p>
<p>Considering retrieval/inference, most approaches adopt one of two proposals, both compatible with the perspectives on conceptual structure outlined above. First, semantic information may be self-contained within the representation such that activation brings retrieval/inference along with it ( Figure 1; left column). For categorical models, the category representation might encapsulate knowledge of properties essential to or characteristic of category members, as in classical, prototype, and rational models [36][37][38]. In feature-based models, because each element of the representation vector corresponds to an explicit property, the system need only 'read off' the vector elements active above some threshold to attribute the corresponding properties to the perceived/named item. Such a view is captured by semantic feature-based neural network models [22][23][24], spreading-activation models [31,39,40], and distributional semantic models that constrain representations to have interpretable dimensions (such as topic models and non-negative sparse embeddings; Box 1) [41,42]. For vector space models, although the dimensions of the representation space are not independently interpretable, retrieval/inference can still be self-contained by proposing that these functions rely on similarity and/or direction within the representation space [34]. For instance, the system may infer that the cardinal can fly and breathe because the vectors for the words 'fly' and 'breathe' are both near to the vector for 'cardinal' and are situated along a direction in the space that separates behavioral 'can' properties from other property types (such as parts, names, colors, etc.). Such a perspective is captured by distributional semantic models that are not constrained to yield interpretable dimensions (e.g., latent semantic analysis [33], holistic analog to language [43], word2vec [34], and language neural networks [44]) (Box 1).</p>
<p>Self-contained approaches face a significant hurdle, however: retrieving the content of a representation requires a labeling scheme, without which it would be impossible to know which semantic content 'goes with' which representation vectors (sometimes called the symbol grounding problem [45]). The second approach to retrieval/inference ( Figure 1, right column) addresses this problem by proposing that semantic content is grounded in perception, action, and language systems Trends in Cognitive Sciences Regularization: a method of avoiding overfitting by finding classifier weights that jointly minimize classification error and an additional loss which is a function of the classifier weights. Representational similarity analysis (RSA): a method of investigating representational structure by comparing the similarity structure recorded to that hypothesized. Self-contained: (of a representation) encapsulating semantic information within itself such that mere activation of the representation brings about retrieval/ inference. Surface representation: a sensory representation of a stimulus that is modality-specificfor example, color (specific to the visual modality) or a paddling action (specific to the motor modality). Transcranial magnetic stimulation (TMS): the use of magnetic fields to temporarily and reversibly disrupt brain function. Vector space: (of a representation) composed of a pattern across representational units, the meanings of which cannot be independently interpreted. Figure 1. Computational hypotheses about semantic representation. There are three ways in which conceptual structure could be encoded. First, information may be encoded in discrete, independent category representations (top row). On this view, sensory inputs recruit discrete and independent category representations </p>
<p>Trends in Cognitive Sciences</p>
<p>OPEN ACCESS</p>
<p>that directly encode surface representations of the environment: shapes, colors, parts, movements, affordances, words, and so on [46][47][48]. On this view, the activation of a categorical, feature-based, or vector space representation does not in itself cause information retrieval/ inference. Instead, retrieval/inference arises when these structure-encoding representations activate modality-specific representations that are identical or intimately related to those that directly mediate perception and action. Thus the categorical/featural/vector space representation of canoe is meaningful only in virtue of its ability to generate mental images of what a canoe looks like (including shape, color, parts, etc.), motor actions associated with canoes (e.g., paddling), words used to describe canoes ('boat', 'light', 'floats'), and so on. which either encapsulate semantic information within themselves [15,20,36,105,106] (top left) or connect and bind modality-specific surface representations encoding characteristics of category members [49,50] (top right). Second, semantic information may be distributed across independent and interpretable semantic feature representations, with featural overlap indicating conceptual similarity (middle). Features may independently and intrinsically encode the presence of stipulated semantic features within a concept [22][23][24]75] (middle left) or gain meaning via connection to surface representations that directly encode such information [2,25,51,52] (middle right). Third, semantic information may be encoded by a continuous distributed representation space that expresses conceptual similarities among items even though its dimensions are not independently interpretable (bottom). Semantic information may be self-contained by the distances encoded in such a space [33,34,41,44] (bottom left) or grounded via mappings from the space to modality-specific surface representations of specific properties [9,53,54] (bottom right). Black arrows illustrate how information may flow through the network given the stimuli shown. Text on either side indicates well-known perspectives in the literature that characterize each view. For feature-based and vector space representations, representational spaces are schematized on a blue background. Blue arrows point to the type of representational similarity structure encoded by the corresponding layersnote that both self-contained and grounded approaches can encode the same representational space. Abbreviations: GRAPES, grounding representations in action, perception, and emotion systems; NNSE, non-negative sparse embeddings. Box 1. Ways of estimating semantic structure Category-based theories propose that distinct representations encode information about different semantic categories. Some have argued that different brain regions are specialized to represent categories that are important for survival over evolution, such as faces, tools, animals, foods, body parts, and shelter [73,90,107,108], but the general question of which categories are stored in memory and why remains controversial [109,110].</p>
<p>Feature-based theories cast semantic representations as vectors that denote the properties of a given item, such as is red, can fly, or has blood inside for the concept cardinal. Three methods have been used to construct such vectors.</p>
<p>(i) Semantic norming studies ask participants to list the properties that are true of a given concept. Properties generated and/or verified by many participants are compiled in a matrix with rows corresponding to the tested concepts and columns corresponding to the various properties generated by the participants across all study concepts [28,111] (J. Tanaka and L. Szechter, unpublished data).</p>
<p>(ii) Brain-inspired feature vectors identify semantic properties that, from univariate brain imaging, selectively engage different cortical areas. Participants then rate the strength of association between a given concept and each such property. The procedure produces many fewer features than norming studies, but still captures rich conceptual structure [26,52].</p>
<p>(iii) Non-negative sparse word embeddings (NNSE) estimate feature vectors from text corpora by exploiting the tendency for words with similar meanings to occur in similar contexts. Standard techniques {e.g., latent semantic analysis (LSA) [33,113,114] and word2vec [34]} generate embeddings with uninterpretable dimensions, but, when embeddings are constrained to be both sparse (zeros on most dimensions) and non-negative (only positive values on the rest), the resulting elements are more interpretable and each word can be viewed as a semantic feature vector [115].</p>
<p>Vector spaces cast semantic representations as points in a high-dimensional space where pairwise distances capture conceptual relatedness, but with uninterpretable dimensions. Two methods are used to compute such spaces.</p>
<p>(i) Unconstrained word embeddings adopt the same corpus-based approach as non-negative sparse embeddings without sparsity or positivity constraints. The resulting spaces express comparable structure to NNSE using fewer dimensions, but the dimensions are not typically independently interpretable.</p>
<p>(ii) Deep neural networks trained on natural language and/or large image datasets learn vector space representations for photographs, words, or larger units of language. Deep image classifiers represent color photographs with activation vectors across many serial processing layers [116,117]; sentence-processing networks represent words, phrases, or whole passages of text as activation vectors over internal units {e.g., bidirectional encoder representations from transformers (BERT) [44] and generative pretrained transformer 3 (GPT3) [118])}.</p>
<p>On a grounded category-based approach, a discrete category representation connects the surface representations encoding characteristics of category members, and binds these together so that they are understood as all inhering in the same concept. For example, bird connects surface representations of the visual appearance of feathers, the motion of flight, the word 'bird', and so on; the 'convergence zone' hypothesis provides an example of this view [49,50]. Under grounded feature-based approaches, the featural dimensions that encode the semantic representation are 'labeled' by virtue of their direct/preferential connectivity to surface representations that directly encode the corresponding contentfor instance, a semantic dimension encoding the color of an object may be directly connected to color-perception areas; a dimension encoding its associated action may be connected to motion-perception areas; and so on. Several proposals motivated by functional imaging data align with this view, including the GRAPES (grounding representations in action, perception, and emotion systems) framework [51] and the neurally inspired 'experiential features' view [26,52]. Finally, grounded vector-space models suggest that the representational ensemble that encodes conceptual similarity structure connects reciprocally to a variety of different surface representations such that the generation of an activity pattern across the ensemble activates surface representations that encode the specific, embodied properties associated with the corresponding itema view consistent with the hub-and-spokes model of semantic representation. [9,[53][54][55] In sum, considering how semantic representations might serve their defining functionsexpressing conceptual structure and supporting semantic retrieval/inferencedelineates a well-constrained space of hypotheses in which cognitive theories of semantic representation can be situated. The different views, and examples of theories aligning with each, are shown in Figure 1. Each cognitive hypothesis has implications for how neural data are best collected and analyzed; for instance, adjudicating grounded versus self-contained theories may require participants to semantically process stimuli in different modalities. The next section considers how these views constrain the search for neural systems that encode semantic information.</p>
<p>How might semantic representations be organized in the brain?</p>
<p>Next, we consider how these different computational schemes might be implemented in neural systems in ways that can be measured by functional brain imaging. All such technologies can be viewed as summarizing the responses of many different neural populations to a cognitive event. Different technologies such as functional magnetic resonance imaging (fMRI), electroencephalography (EEG), magnetoencephalography (MEG), and electrocorticography (ECoG) yield summary estimates at different spatial and temporal granularities (e.g., voxels, EEG sources, and electrodes). We will use the term 'unit' to refer to the summary estimate provided by a given technology over its characteristic window of space and time. Therefore, regardless of imaging modality, the neural response to a stimulus is characterized as a pattern of activation across many units over a particular window of time. Discovering the neural underpinnings of semantic representations then requires close consideration of (i) how the representational elements proposed by a cognitive theory are encoded in unit activation patterns within and across individuals, (ii) how the representational work might be divided among units participating in a representation, and (iii) how signal-carrying units might be anatomically organized within and across individuals.</p>
<p>Variation of the neural code Within an individual, the neuro-semantic codehow changes in unit activity express semantic informationcan be either homogeneous or heterogeneous (Figure 2A). In a homogeneous code, signal-carrying units all adopt the same activation when the represented information is presentfor instance, all voxels representing cat become more active when a cat is semantically activation changei.e., all become more active or all become less active) or a heterogeneous code (the units involved adopt different changes to activationi.e., some become more active than others, and/or some become more active and some less active). Across individuals the code may be consistent (the same magnitude and direction of change in all individuals) or inconsistent (different magnitudes and/or directions of change in different individuals). Spatial smoothing and cross-subject averaging can either help or hinder discovery depending on the code. (B) In the independent code shown, unit 1 activation indicates whether the item is animate, while unit 2 independently encodes whether it can fly. In the first conjoint code, the two units express the same similarity relations among the four items, but considered independently, neither unit clearly expresses either dimension. For instance, fish and plane both moderately activate unit 1, whereas bird and boat moderately activate unit 2. In the second conjoint example, unit 2 activation is difficult to interpret considered independently, but discriminates birds from fish when unit 1 is active, and fruits from vegetables when unit 1 is inactive. In both conjoint examples, understanding the neural code requires joint consideration of both units. (C) Anatomically, the units in a representation may be localized to a contiguous region or dispersed across multiple distal areas, and the units may occupy either the same or different locations across individuals. The two brains within each white box denote two different individuals. Abbreviation: Betw. individuals, between individuals. processed. In a heterogeneous code, different units express the same information differentlysome voxels representing cat may be greatly activated when a cat is present, some greatly suppressed, and some only moderately active, etc. Approaches that average unit activations within participants [e.g., via spatial smoothing or region of interest (ROI) averaging] favor the discovery of homogeneous over heterogeneous codes.</p>
<p>Trends in Cognitive Sciences</p>
<p>Across individuals, the neural code may be consistenta given piece of information is always expressed with the same activity change in homologous units (e.g., cat always being signaled by the same activation pattern across aligned voxels of different individuals)or inconsistent (cat being signaled by different activation patterns across aligned voxels of different individuals; Figure 2A). Methods that aggregate or summarize unit activation across individualsfor instance, fitting a single model to decode all participants, computing the mean blood oxygen level-dependent (BOLD) response at each voxel before applying a decoding model, or averaging predictions of encoding models across participants before passing the result to further analysisfavor the discovery of consistent over inconsistent codes. Likewise, methods that align voxels across individuals on the basis of their having similar activation patterns across stimuli (e.g., hyper-alignment) [56] implicitly assume a consistent code.</p>
<p>Independent and conjoint codes Categorical and feature-based approaches both suggest that each unit independently encodes a piece of semantic information: its activity expresses the presence or absence of that information (such as category membership or a semantic feature) regardless of the states of other units. For the example shown in the left panel of Figure 2B, unit 1 encodes whether the stimulus is living or non-living independently of unit 2, whereas unit 2 encodes whether the stimulus can fly independently of unit 1. For any stimulus, it is possible to determine whether the item is alive solely by inspecting the state of unit 1, without needing to consider the activation of other units.</p>
<p>By contrast, vector space hypotheses suggest that units conjointly encode a representational space, and that semantic information is expressed in the activity pattern considered across multiple units such that single-unit activation may not be interpretable without consideration of other units in the ensemble. Figure 2B shows two examples. In the middle panel, one cannot determine whether a stimulus is living or whether it can fly solely by inspecting the activation of unit 1 (because fish and plane elicit equal activation) or unit 2 (because boat and cardinal elicit equal activation). Considering the joint activation of both units clearly separates living and non-living things along one diagonal, and flying from non-flying things along the other. In the right panel, unit 1 clearly encodes whether a stimulus is a plant or animal, but the behavior of unit 2 considered independently might appear to be arbitrary (activating for banana and cardinal, but not for carrot or fish). Joint consideration of both units makes the interpretation of unit 2 clear: if unit 1 is active, it differentiates birds from fish; if inactive, it differentiates fruit from vegetables.</p>
<p>Variation of anatomical location</p>
<p>Within an individual, units representing a given semantic element may be anatomically contiguous (situated within the same brain region) or dispersed (residing in multiple separate regions; Figure 2C). Methods that analyze different areas separately (e.g., analysis of different ROIs) favor the discovery of contiguous over dispersed representations. Finally, irrespective of whether units are contiguous or dispersed within an individual, signal-carrying units may be anatomically localized in the same or different areas across individuals. Averaging data across anatomically aligned brains (e.g., in searchlight analyses) favors the discovery of similarly over differently localized representations, whereas techniques that align on the basis of similar responses to stimuli rather than anatomical location (e.g., hyper-alignment) relax the localization assumption.</p>
<p>Together these factors delineate 24 different possibilities for the organization of the neurosemantic code within and across individuals (Table 1). These are not mutually exclusivedifferent aspects of a representation, or representations in different conceptual domains, may be organized according to different principles. Understanding which principles best explain which aspects of representation thus requires methods capable of finding each variety of signal.</p>
<p>Assumptions implicit in analytic approaches</p>
<p>We next consider how different analytic approaches in functional brain imaging might favor the evaluation of some hypotheses over others. Such studies aim to find the units whose measured responses to stimuli encode the representational elements specified by the cognitive theory. a Each row indicates one hypothesis and the first five columns show corresponding combinations of key factors discussed in the text (code type, within-subject homogeneity and localization, and between-subject consistency and localization). The remaining columns summarize a review of 100 papers using multivariate methods to uncover neuro-semantic representations. Each column represents a common analysis step that entails an implicit assumption about the neural code, including independent analysis of single voxels (assuming an independent code), spatial blurring of BOLD (assuming a homogeneous code), independent consideration of different areas via ROI or searchlight (assuming contiguous localization within area), averaging the neural signal across subjects before model fitting (assuming a consistent code), and averaging of model fit data across subjects (assuming similar localization). The n indicates how many papers adopted the corresponding step. Emphasis shows hypotheses where the associated step will benefit (bold font) or hinder (italic) discovery. The numbers indicate how many reports are capable of detecting each possible neural code considering the analysis decisions taken at each step from left to right. The final column indicates the number of reports that adopt choices capable of finding each possible code. b Abbreviations: Hetero, heterogeneous; Homo, homogeneous.</p>
<p>Because all imaging methods yield thousands of noisy measurements for each stimulus in each participant, statistical models that seek informative units must be constrained in some way. Multivariate methods vary in their approach to this problem and thus in their ability to detect different types of representations. We consider three broad approaches and their variants (Figure 3) with an eye to highlighting their respective strengths and limitations. Box 2 additionally considers crucial but commonly overlooked issues for collecting the data that feed these different approaches.</p>
<p>Multivariate pattern classification (MVPC) fits models (Gaussian naive Bayes, support vector machines, logistic/multinomial regression, etc.) to categorize stimuli from the neural activity they evoke [57,58]. During a training phase, the model receives labeled data consisting of the neural responses across units to each of many stimuli (e.g., various images of objects) and, for each item, a label indicating the stimulus category. Training involves fitting classifier weights to output the correct label for each item in the training set. The trained model is then evaluated by assessing whether it outputs the correct category label when given neural responses for test stimuli that are not present in the training set. Where a fitted model reliably classifies held-out items, input units are interpreted as encoding information about the target categories. The approach is transparently consistent with category-based semantic representations but will also yield positive results for both feature-based and vector space representations provided that the target categories are separable in the corresponding neural activation patterns (i.e., it is possible to fit a flat hyperplane that reliably divides the target categories in the high-dimensional representation space). Because the output of a classifier depends on activation patterns across multiple units, MVPC can detect both independent and conjoint codes. Classifiers assign unique weights to each unit, and the approach can therefore detect both homogeneous and heterogeneous codes. Because separate classifiers are typically fitted for each participant, the method can potentially find inconsistent and variably localized representations as well.</p>
<p>A key challenge for MVPC concerns over-fitting. With more predictors (neural measurements) than datapoints (stimuli), model fitting is underdetermined without additional constrainteven with random data, an infinite set of coefficients will perfectly predict the category membership of training items [35]. MVPC variants differ in the constraints they impose to handle this issue; this has important implications for signal discovery ( Figure 3A).</p>
<p>One method is to reduce the number of neural features provided as the input to the model by applying an explicit anatomical constraint. For instance, ROI-based approaches look only at the units contained in a predefined ROIdiscovery therefore requires that the representation is anatomically contiguous and localized similarly across individuals, and also that a sufficient amount of the representation falls within the preselected region to drive classifier accuracy above chance. ROI selection also crucially determines how neural evidence can relate to the space of cognitive hypotheses. For instance, ROIs falling outside modality-specific areas cannot offer evidence relevant to testing grounded theories of representation, whereas those falling solely within a given modality-specific region cannot evaluate self-contained hypotheses.</p>
<p>Relatedly, searchlight approaches fit a separate classifier at each spatial location in each participant (e.g., each voxel, source, or electrode), including as predictors all units within a prespecified anatomical radius ('searchlight') [58,59]. Thus, different brain regions are analyzed separately. Typically cross-participant univariate statistics at each location assess where in the brain the classifier hold-out accuracy is reliably better than chance; this approach therefore requires that the representation is localized similarly across individuals. If this criterion is met, the searchlight can reveal anatomically dispersed codes, but only if each searchlight independently contains sufficient information to drive classifier accuracy above chance. If accurate classification depends , hold-out error or correlation) across participants differs reliably from chance. Searchlight methods independently evaluate model fit at many 'searchlights' throughout the brain in each participant, then find areas where searchlights produce above-chance fits reliably across participants. Regularization fits a single model in each participant using all neural features, but constrains the model to minimize prediction error jointly with an additional cost that prevents over-fitting (discussed in the main text). Nonzero coefficients in the decoding model of a subject indicate neural units that carry signal; these can be distributed across the brain and can be different for each participant. Group maps indicate areas where non-zero coefficients accumulate more than expected by chance across individuals. </p>
<p>Trends in Cognitive Sciences</p>
<p>Trends in Cognitive Sciences</p>
<p>OPEN ACCESS</p>
<p>on joint consideration of units that fall in separate searchlights, the code will be missed. In this sense, the searchlight may fail to find dispersed, conjoint codes [5,60].</p>
<p>Note that, in principle, classifier accuracy for searchlights and ROIs could be analyzed separately in each individual, relaxing the assumption of similar localization across participants. We are not aware of such an approach being applied to semantic decoding and we therefore focus on the more usual method of using cross-subject univariate statistics to create group-level information maps for these approaches.</p>
<p>A second approach chooses classifier inputs based on a summary univariate statistic that is computed independently for each unit (such as an F-statistic that contrasts unit activation for different category members [3], or a correlation-based metric that assesses the stability of the response of a voxel across stimuli [61]). This avoids the anatomical assumptions of ROI and searchlight fit models that predict the response of each neural unit to various stimuli. After fitting, the regression weights can be inspected to determine the information that each unit encodes, and novel brain responses can be 'decoded' by finding the semantic vector most likely to have generated the observed neural pattern and then comparing this to known semantic vectors. Abbreviations: acc., accuracy; Neg., negative; NSM, neural similarity matrix; Pos., positive; RSM, representational similarity matrix; S1-S3, brains from three different subjects; stim., stimulus.</p>
<p>Box 2. Implications for data acquisition</p>
<p>Hypotheses about the cognitive and neural systems supporting semantic cognition have crucial implications, not only for how neural data are analyzed, but also for how data are collected.</p>
<p>Stimulus selection</p>
<p>Each modality of stimulus has advantages and disadvantages. Words are easily presented in the scanner, allow all concept types to be probed, and have a perceptual/orthographic structure that is unconfounded with semantic structure. However, decoding is less successful with words than with picture stimuli generally [82] and written words generate a strongly asymmetric (left hemisphere) distribution of activation that contrasts with the bilateral pattern found for pictures and spoken words [119].</p>
<p>Task selection</p>
<p>Tasks used to elicit semantic activation vary across studies in ways that are known to strongly impact the engagement of underlying neural systems, including their overall difficulty [120], the specificity with which an item must be identified for good performance [121], reliance on strongly versus weakly encoded information [122], aspects of knowledge the task foregrounds [25,123], and the degree to which the task can be performed via alternative, non-semantic processing routes [124].</p>
<p>Temporal and spatial resolution</p>
<p>Neuroimaging methods vary in spatial and temporal resolution, limitations that may or may not affect discovery depending on the nature of the underlying code. For instance, the lag in BOLD means that successive stimuli blend into one another in fast event-related designs, which can hinder discovery if the neural code is heterogeneous. Slow event-related methods avoid temporal blending [125] but cannot be used for richer tasks such as connected speech or movie-viewing. EEG and MEG offer higher temporal resolution and thus avoid stimulus-to-stimulus blending, but at the cost of spatial blending that can compromise discovery if the neural code is heterogeneous or anatomically dispersed. ECoG offers temporal and spatial precision, but only a minority of regions are ever probed because the sensors are placed for clinical need and only in patients who need neurosurgical intervention.</p>
<p>Image acquisition</p>
<p>The possibility that semantic representations are anatomically dispersed must be tested with whole-brain imaging, thus posing a challenge for fMRI acquisition where the signal-to-noise ratio varies substantially across the brain [126]. Standard sequences yield especially poor signal in orbitofrontal and ventral anterior temporal regions that are thought to be crucial for semantic cognition [127]. Strategies for improving the signal, including distortion-corrected spin-echo [127,128] and multi-echo protocols [129,130], have been available for several years but have only rarely been applied in semantic studies [131]. Indeed, many studies have restricted the field of view to exclude ventral anterior temporal lobe (ATL) completely [132].</p>
<p>approaches but lacks a principled rationale for setting a cut-off threshold and may fail to discover conjoint representations because each included unit must independently survive the preselection criterion.</p>
<p>A third strategy employs model regularization: all units in the cortex provide input to the classifier, which avoids over-fitting by jointly minimizing classification error and an additional loss that is itself a function of the classifier weights [5]. Common losses include the sum of the squared coefficients (L2-norm, also known as 'ridge' regression [62]), the sum of their absolute values {L1-norm, also known as 'LASSO' (least absolute shrinkage and selection operator) [63]}, or a weighted average of these (also known as 'elastic net' [64]). The approach makes no assumption about the anatomical location of signal-carrying units within or across participants, can detect conjoint representations (because it does not require independent preselection of classifier units), and offers a principled way to guide parameterization via nested cross-validation of prediction error [5].</p>
<p>Crucially, however, different regularizers impose different constraints on model fitting, leading to wildly different solutions [5]. Regularization with the L1 norm zeros out as many predictors as possible while still maximizing predictive accuracy, and typically 'selects' (i.e., places non-zero coefficients on) a very small proportion of units. By contrast, the L2 norm spreads similar weights across correlated units and places non-zero weights on all units. The choice of regularizer thus implements an assumption about the likely nature of the true signal: that signal-carrying units are sparse and uncorrelated (L1) or that they are dense and highly redundant (L2). An alternative approach designs loss functions that explicitly incorporate prior knowledge about the likely neural and cognitive structure. For instance, the sparse overlapping sets (SOS) LASSO penalty encourages patterns of 'structured sparsity' where selected units reside in roughly similar locations across participants, promoting loose anatomical clustering that still permits some variation in signal location across participants [65,66].</p>
<p>These differences can yield radically different views of the neuro-semantic code when applied to the same data. In Figure 4A, neural representations of face stimuli appear to be increasingly widely distributed and heterogeneous as analytic methods progressively relax tacit assumptions about the independence, heterogeneity, and localization of the neural code. Standard univariate contrast (assuming a consistently localized, independent, and homogeneous code) replicates the classic finding of a right-lateralized posterior fusiform area that is more active for faces. Searchlight (assuming a similarly localized and contiguous but potentially conjoint and heterogeneous code) suggests a bilateral representation localized to posterior ventral temporal cortex. Wholebrain MVPC regularized with the L1 norm (assuming a sparse code that can be dispersed, heterogeneous, and differently localized) shows a bilateral face-to-nonface gradient in posterior ventral temporal cortex and a face-selective region in right lateral occipital cortex. Regularization with the SOS LASSO (allowing dispersed, heterogeneous, and differently localized codes, but preferring solutions with roughly similar anatomical distributions) suggests a much more broadly distributed code encompassing anterior temporal, parietal, and prefrontal regions in both hemispheres [5].</p>
<p>Representational similarity analysis (RSA) searches for sets of units whose responses express semantic similarities among stimuli [58,59,67]. The analysis first computes a target representational similarity matrix (RSM; sometimes defined in terms of dissimilarity where it is called a target representational dissimilarity matrix) that expresses semantic relatedness for all pairs of stimuli (Box 1). It then estimates a neural similarity matrix (NSM; sometimes called a neural representational dissimilarity matrix) that encodes pairwise similarities in stimulus-evoked neural activity across a set of units. The correlation between RSM and NSM indicates whether the selected units encode the target structure ( Figure 3C). to the same dataset. Participants made pleasantness judgments in response to images of faces, places, or objects, and each analysis sought voxel sets that differentiate face from non-face stimuli. Approaches that assume consistently localized signals (univariate and searchlight) suggest that representations are localized to posterior ventrotemporal cortex, whole-brain decoding with sparse regularization suggests a somewhat more distributed representation, whereas decoding with structured sparsity suggests a widely distributed representation [5]. (B) Searchlight representational similarity analysis (RSA) decoding of semantic structure from pictures, words, or both. </p>
<p>Trends Trends in in Cognitive Cognitive Sciences Sciences</p>
<p>Trends in Cognitive Sciences</p>
<p>OPEN ACCESS</p>
<p>Similarly to MVPC, RSA can detect categorical, feature-based, and vector space representations provided that the NSM and semantic RSM correlate positively. Because neural similarities are computed across multiple units, the technique can detect conjoint or independent codes and heterogeneous or homogeneous codes. A central challenge concerns how neural units are selected and evaluated for significance. Most studies employ either a prespecified ROI or a searchlight technique. The correlation between RSM and NSM is computed for each ROI or searchlight individually in each participant and, if these are reliably positive across individuals, the ROI/searchlight is interpreted as encoding semantic structure. As with MVPC, information maps could be analyzed separately in each individual, but RSA as typically practiced requires that (i) representations are localized similarity across individuals, (i) information is not conjointly encoded across different searchlights or ROIs, and (iii) individual searchlights contain sufficient information to drive correlations with the target matrix reliably above chance.</p>
<p>RSA views even small correlations as meaningful provided that they are reliably positive across participants. Because semantic structure covaries with many confounding factors, the results can be difficult to interpret. For instance, early studies using visual stimuli suggested that posterior temporo-occipital areas encode semantic structure [68], but a recent comparative analysis found that these areas more strongly encode high-order visual structure and semantic structure was better encoded in more anterior ventro-temporal regions ( Figure 4B, top) [69]. Studies that do not control for visual similarity suggest that semantic structure for both words and pictures is encoded within a left perisylvian network [70], but when stimuli orthogonally vary semantic and visual similarity, semantic structure for words appears to be localized to the medial-ventral anterior temporal lobe [71] ( Figure 4B, bottom). Thus, very different patterns are obtained depending upon the target RSMs, the selection of stimuli, and the input modality (Box 2).</p>
<p>Finally, encoder/decoder (also known as generative) approaches use regression to fit a separate encoding model for each unit, predicting its response to a stimulus from the semantic features of the item [72][73][74]. Successful prediction indicates that the corresponding unit independently encodes semantic information. A whole-brain response can be estimated by passing a stimulus feature vector forward through each encoder, yielding a predicted activation at every unit [72]. Alternatively, the whole-brain response generated by a new, unknown item can be decoded by inverting the encoding models to find the semantic vector most likely to have generated the observed neural response, and then interpreting the resulting vector [1,74] ( Figure 3D). Because separate models are fitted for each voxel and participant, generative approaches make no assumption about code homogeneity, cross-participant consistency, or anatomical organization within or across individuals. However, they do face two non-trivial challenges.</p>
<p>First, generative approaches can fail to predict the independent activity of a unit that forms part of a conjoint code. To see this, consider the second conjoint example in Figure 2B right, where two units both contribute to a semantic representation. If unit 1 is active, unit 2 differentiates fish from Results vary remarkably depending on several factors, including the representational similarity matrices (RSMs) considered (semantic similarity alone [68] produces different results from comparing semantic versus visual similarity; top two images [69]) and experimental control of stimulus properties (semantic structure for words appears to be encoded in perisylvian regions when visual structure is uncontrolled [70], but in ventral anterior temporal lobe (ATL) when controlled [71]). (C) Generative approaches for decoding semantic representations of narrative speech/sentences. When predictor vectors have semantically interpretable dimensions, and encoder weights are used to interpret the meaning of a voxel's activation, the results seem to show a mosaic of localized semantic features across cortex within each subject, but callouts show areas where the proposed semantic content is at odds with traditional understanding of function (top; images generated from online visualization tool at https:// gallantlab.org/huth2016/). Approaches that invert encoding models to decode whole-brain states (bottom) can recover sentence meanings with good accuracy, but the nature of the underlying code is difficult to discern because the approach selects thousands of voxels widely distributed across cortex in each participant (right), with approximately equal proportions residing in various pre-defined brain networks [1] (left). In both cases verbal semantic representations appear to be widely distributed across cortex and highly variable across individuals. For references see [1,5,[68][69][70][71]75]. Abbreviations: ant, anterior; LOC, lateral occipital complex; Pic, picture; post, posterior; pref, preference; PR, perirhinal cortex; Prop., proportion; reg., regularization; TP, temporal pole.</p>
<p>birds; if inactive, unit 2 instead differentiates fruits from vegetables. The 'meaning' of unit 2 is clear when unit 1 is taken into consideration, but might appear arbitrary when considered independently. An encoder model might struggle to predict the independent behavior of unit 2 from semantic features such as can move, has feathers, is sweet, etc., and thus might suggest that it is not involved in semantic representation.</p>
<p>The second challenge concerns interpretation. One strategy fits the encoders using semantic vectors whose elements are each individually interpretable (such as a semantic feature vector; Box 1), and then inspects the encoder weights for each unit to understand what content it encodes [2,75,76]. For instance, if the activation of a voxel is reliably predicted by semantic features such as can move, can grow, and has eyes, these features will receive non-zero weights in the regression model for that voxel, which might then be interpreted as encoding animacy. The goal is to understand each unit as independently encoding a subset of semantic features, thereby yielding an interpretable semantic feature map of cortex that is consistent with feature-based cognitive models. Because there are many potential semantic features, however, the encoder fit must be regularized using techniques such as those described earlier for MVPC (commonly L2 norm, e.g., [16], although other approaches are also popular, e.g., [77]). As we have seen, different regularizers can produce dramatically different configurations of weights, and the interpretation of encoder weights therefore hinges crucially upon the choice of the regularizer. Perhaps for this reason, approaches adopting this strategy have yielded puzzling findingssuggesting a mosaic-like organization of local semantic features across many cortical areas that is difficult to reconcile with the wealth of cognitive and clinical neuroscience information about the functions of these regions [75] ( Figure 4C, top).</p>
<p>An alternative strategy eschews the effort to identify a 'meaning' for individual units and instead decodes the full activation pattern evoked across cortical units by inverting the encoder models to find the semantic vector that is most likely to have generated the whole-brain response. The recovered vector is interpreted by comparing its similarity to vectors corresponding to known words or sentences [1,74]. For instance, if the decoded vector is near to the known vectors for grow, move, eat, eyes, legs, fur, it will be interpreted as encoding a meaning such as animal. Because no effort is made to interpret each dimension, this method is consistent with vector space approaches, but can also detect category or feature-based representations. One recent study showed remarkably good decoding of sentence-level meaning using this approach [1]but the implications of the study for understanding neural organization of semantics remain unclear because the results identified thousands of voxels scattered across the cortex in each individual, with approximately equal involvement of many different brain networks and no voxels selected in more than half of the participants ( Figure 4C, bottom).</p>
<p>It is worth noting that each general approach encompasses several variantsfor instance, in the particular classification model adopted by MVPC [58] and the specific similarity metric used by RSA [78,79]. Although a full characterization of each is beyond the scope of this review, it seems likely that such variation further contributes to the heterogeneity of the findings reported in the literature.</p>
<p>Analytic implications of grounded versus self-contained theories</p>
<p>The issues described above arise regardless of whether neuro-semantic representations are grounded or self-contained, but this important distinction in cognitive theories carries two additional implications for the design, analysis, and interpretation of multivariate imaging studies. First, primary and secondary perceptual and motor cortices conform to localization assumptions that are central to particular analytic choicesspecifically, such areas are both contiguous and localized similarly across individuals. Grounded approaches suggest that such areas can encode semantic information about stimuli, and studies designed specifically to assess whether semantic structure arises within a given modality [80,81] therefore have good motivation to employ ROI or searchlight-based feature selection. The anatomical organization of tertiary and association cortices is less well understood and may be more likely to vary across individuals, therefore studies seeking semantic structure outside the earlier modality-specific regions are better served by the adoption of approaches that loosen localization, homogeneity, and consistency assumptions. Assessment of self-contained hypotheses will depend crucially on such methods because they propose that semantic representations encode information in a modality-independent manner.</p>
<p>Second, adjudication of grounded versus self-contained hypotheses requires studies that probe semantic information through different stimulus modalities. Self-contained views hold that the same system of semantic representation is engaged regardless of whether the stimulus is a word, picture, image, sound, etc. Such a view cannot be disconfirmed by evidence that, for instance, semantic information is decodable from visual areas when a visual stimulus appears because such a result might also arise if the structure of purely perceptual visual representations is confounded with semantic structure (e.g., Figure 4B). Evaluating the proposal instead requires searching for neural systems from which semantic information can be decoded across multiple different stimulus modalities. Currently, the literature contains relatively few such studies, and these have yielded mixed findings [70,[82][83][84] (further details are given in the supplemental information online).</p>
<p>Toward best practices</p>
<p>To understand how the preceding issues may have shaped current thinking about semantic representation in mind and brain, we reviewed 100 papers applying multivariate techniques to the discovery of neuro-semantic representations in fMRI data (supplemental information). For each, we considered five analytic decisions, each reflecting a latent assumption about the neural code, and we evaluated which of the 24 representational possibilities the study was capable of detecting as each choice was made. The results are summarized in Table 1. All methods were capable of detecting neural representations that adopt an independent, homogeneous, and anatomically contiguous code that, across individuals, is consistent and similarly localizedthe type of representation sought by univariate analysis. Fewer could detect other types of representational structure, and very few were capable of finding representations that are dispersed in the brain, localized differently across participants, and/or encode semantic information conjointly across units rather than independently. In this sense, methodological choices made during data analysis determine which types of neural signal can and cannot be detectedthe analytic decisions effectively filter the empirical record.</p>
<p>A central question thus concerns how the field might best proceed given the complexity and heterogeneity of contemporary methods and the filtering that inevitably results. No analytic approach is assumption-free, and we doubt that the universal adoption of any single method will resolve the issues we have identified. Instead, we believe the field would be well served by adopting some best practices in the way that studies are designed and results are communicated.</p>
<p>Articulating explicit hypotheses about the neural code In laying out the motivation and design of a study, it is helpful for researchers to explicitly state their working hypothesis about the nature and structure of the neuro-semantic codewhat form the cognitive representation is hypothesized to take, how its neural instantiation is reflected in the measurements taken, and how it is expected to vary within and across individuals. The cognitive and neural possibilities developed in this review provide a frame of reference for such statements, which are important because they allow the reader to understand why a given analysis method was chosen and how the observed results relate to the working hypothesis.</p>
<p>Explicit consideration of alternative hypotheses When designing/motivating an analysis and when drawing conclusions from the results, it is helpful for researchers to consider other possible ways that the target information might be encoded in neural activity, beyond the working hypothesis. Before data collection, such habits can prompt new design or analysis ideas that allow adjudication of a richer variety of hypotheses. When drawing conclusions, explicit consideration of alternative possibilities and whether/how the current data can possibly disconfirm them can help the community to better understand seemingly heterogeneous patterns of results.</p>
<p>Connection to neurocognitive computational models One way to make working assumptions about representation explicit is to connect the experimental design and analysis plan to a neuro-computational model of the behavior [4,5,60,[85][86][87][88]. Figure 5 Figure 5. Recent examples of computational models informing neural decoding. (A) In recurrent models the activation patterns that encode semantic information change over the course of stimulus processing. In simulated electrocorticography (ECoG, left), classifiers fit to different temporal windows (colored dots) decode well within the same and neighboring time-windows, but poorly for more distal time-windows (colored lines). A similar pattern arises when the same approach is used to decode ECoG from human anterior temporal cortex while participants name pictures, suggesting rapid nonlinear change in the neuro-semantic code [133]. (B) Deep convolutional neural networks (DCNNs) may provide a useful framework for understanding visual object semantics [134,135]. A recent study assessed whether a trained DCNN could classify images when activations at a given model layer were replaced by neural responses (measured by fMRI) of different visual areas [136]. Neural patterns from each area were successfully decoded, but only when they were input to the deeper model layers (barplot)suggesting that the richer semantic structure encoded in such layers is reflected throughout the ventral visual stream. (C) Other work uses similar models to evaluate individual differences across parts of the vision-to-semantics system [137]. In the plot shown the authors trained several models, measured similarity in the representational geometry acquired in each layer across models, and embedded these in two dimensions. The proximity of colored circles indicates the similarity of the representational structure acquired by the corresponding layers. Lines connect layers in the same model. Shallower model layers (light colors) always learned relatively similar structure, whereas deeper layersthose most likely to express abstract semantic structurelearned more variable structure, suggesting that neural codes may differ more across individuals in the regions that are most likely to encode semantic structure. For references see [133,136,137]. Abbreviations: AUC, area under the curve; dim, dimension; LOC, lateral occipital complex; MDS, multidimensional scaling; V1-V4, visual cortex areas 1-4.</p>
<p>[ [89][90][91][92][93][94], (ii) methods for disrupting neural processing in healthy participants, which can provide crucial evidence about causality [95][96][97], (iii) structural and functional brain connectivity [98][99][100], (iv) patterns of behavior and functional activation arising over typical and atypical development [101,102], and (v) results of behavioral studies arising in cognitive science [30,103,104]. Box 3 considers how these sources of evidence can aid the interpretation of imaging data. Of course, not every paper can comprehensively review a large and complex literaturebut in drawing conclusions it can be helpful for authors to explicitly consider where these cohere with results from other methodologies, where they contradict such results, and where the relevant experiments have not yet been conducted.</p>
<p>Concluding remarks</p>
<p>Our review illustrates that methodological choices in multivariate neuroimaging analysis selectively filter data to promote discovery of some types of neuro-semantic codes over others. These considerations compel a re-evaluation of the literature. Over three decades many neuroimaging studies have reported cortical areas that locally encode a particular type of semantic information in a systematic way across individuals. The preponderance and replicability of such Box 3. The importance of converging evidence</p>
<p>The heterogeneity of imaging findings may be resolved by considering how conclusions from various studies relate to converging evidence from other methods. Some examples are given below.</p>
<p>Neuropsychology</p>
<p>Several varieties of brain damage cause semantic impairment and distinct deficits are observed depending on the neuropathology. Close consideration of these can illuminate brain imaging results. For instance, cross-modal semantic impairment can arise both from bilateral damage to the anterior temporal lobes (ATLs) [93,138] and from left frontoparietal or posterior-lateral temporal stroke [92,139], but whereas ATL damage erodes conceptual structure, frontoparietal/ posterior-lateral temporal damage instead disrupts the ability to shape semantic processing to the task context [54]. Thus, results implicating frontoparietal/posterior lateral temporal areas in semantics might best be interpreted by considering the demands on semantic control, whereas studies seeking conceptual structure in the brain should employ methods that are capable of resolving ATL signal.</p>
<p>Neural disruption</p>
<p>If imaging results suggest that a brain region selectively represents/processes a particular type of semantic information, transient disruption of the area via transcranial magnetic stimulation (TMS) should selectively affect retrieval of the target information. For instance, TMS applied to left or right ATL slows semantic judgments equally for animates and inanimates, but does not affect number judgments, supporting the view that bilateral ATLs encode semantic information across domains [95]. Such studies will be especially important for testing the implications of multivariate imaging studies indicative of highly unorthodox semantic functions for various cortical areas [75].</p>
<p>Neural connectivity</p>
<p>The neural response of a given area can reflect its broader connectivity, with implications for understanding its function. For instance, medial posterior fusiform cortex responds more to artifact than animal namesa pattern observed both in sighted and congenitally blind individuals [140,141]. One interpretation suggests that different brain areas natively specialize to represent distinct semantic categories [142]. However, the area of interest is functionally [98] and structurally [100] connected to dorsal areas that aid in object-directed actions, suggesting that the seeming category effect may instead arise from more effective interactions between this visual area and parts of the action system [98,143].</p>
<p>Neurocognitive development</p>
<p>Developmental trajectories can likewise aid the understanding of mature activation patterns. For instance, the right posterior fusiform responds strongly to face images in most literate adults, perhaps suggesting an innately dedicated system for face representation [144,145]. However, face perception engages the fusiform bilaterally in pre-literate children [146], and the left hemifield/right hemisphere advantage for face recognition emerges late in development as a child learns to read [147]. Such data suggest that the mature pattern reflects, not innate specialization for a visual category, but experienced-based tuning of visual perception [101]. </p>
<p>Trends in Cognitive Sciences</p>
<p>Outstanding questions</p>
<p>Which cognitive hypotheses best describe semantic representations?</p>
<p>The multivariate methods considered in this review do not indicate whether the underlying representation is categorical, feature-based, or a vector space, or is self-contained versus grounded. MVPC can produce a positive result even if neural representations are vector spaces rather than categories, and RSA can generate a positive result even if neural representations are categories and not vector spaces. How then can brain imaging adjudicate between these views?</p>
<p>When different brain areas all encode semantic structure, what data can determine whether they support the same or different functions? Semantic structure has been observed across multiple brain areas, but disruption caused by brain damage or transcranial magnetic stimulation (TMS) can produce qualitatively different patterns of impairmentsuggesting that these regions serve different functions in semantic cognition.</p>
<p>Can imaging data resolve which aspects of a target representational structure are, or are not, encoded within a neural system? Many studies report above-chance decoding that is nevertheless relatively weak (e.g., RSA correlations as small as r = 0.03, binary classification accuracy of 0.55, etc.). Such effects might arise because neural data are noisy, because the neural system encodes weak confounds with the target structure, or because it encodes only part of the target structure.</p>
<p>Can a combination of approaches overcome the individual limitations of each method? Each technique has strengths and limitations; perhaps the fullest picture of semantics in the brain will arise from a combination of approaches that will allow the community to evaluate the full space of representational possibilities outlined in this review.</p>
<p>findings suggest that some elements of neuro-semantic representation must indeed be independent, contiguous, and localized similarly across individuals. However, because this is precisely the one form of neuro-semantic code that, among many possibilities, is most robust to methodological choices, the ubiquity of such findings does not signify that these are the only, or even the most important, elements of semantic representation. On the contrary, neurocomputational models of healthy and disordered semantic cognition typically acquire internal representations that are conjoint rather than independent, are distributed across units that may be anatomically dispersed, are heterogeneous in code, and are potentially localized differently across individuals [5,60,85]. These latter forms of semantic representation are the least likely to be revealed by most current analytical methods. The few studies capable of finding such structure often reveal a more widely distributed, heterogeneous, and variable semantic code than other studies suggest [1,5,75]. Thus there exists an important lacuna in the empirical landscape that must be filled if we are to develop a mechanistic understanding of semantic cognition in the brain. We hope that this article provides a first step toward an organizing framework that can bring the current heterogeneity of findings under a common explanatory umbrella (see Outstanding questions).</p>
<p>in Cognitive Sciences, March 2023, Vol. 27, No. 3 change in activation across individualsfor example, homologous voxels in multiple individuals behave differently when representing cat, some becoming more active and others becoming less active. Independent: (of a representation) consisting of units that express the presence or absence of the same semantic information irrespective of the states of other units. Labeled data: a dataset specifying both input and output values for fitting an encoding or decoding model. Magnetoencephalography (MEG): a method of measuring brain activity by measuring magnetic fields generated by neural activity. Multivariate pattern classification (MVPC): the categorization of stimuli based on the neural patterns they evoke (a form of decoding). Region of interest (ROI): a subset of neural units, chosen in a hypothesisguided way, upon which an analysis is conducted.</p>
<p>(
Figure legend continued at the bottom of the next page.)</p>
<p>Figure 2 .
2Hypotheses about the neuro-semantic code. (A) Within individuals a representation may adopt a homogeneous code (all involved units adopt the same</p>
<p>Figure 3 .
3Approaches to neural decoding. (A) Different solutions to the over-fitting problem faced by multivariate pattern classification (MVPC) and representational similarity analysis (RSA) approaches. Region of interest (ROI) approaches look only at a prespecified area in each participant and evaluate whether the mean model fit (i.e.</p>
<p>(B) Multivariate pattern classification fits a model to predict a stimulus category label from the neural pattern it evokes across selected neural units. Mean hold-out accuracy across participants indicates whether the selected units carry category information and classifier weights can indicate whether category membership is signaled by increased or decreased neural activation. (C) RSA computes similarity in the neural responses generated across selected units by various stimuli, and then correlates this with a target semantic similarity matrix. Mean correlation across subjects indicates whether the selected neural units encode semantic structure. (D) Generative approaches use regression to (Figure legend continued at the bottom of the next page.)</p>
<p>Figure 4 .
4Example results from various decoding methods applied to fMRI data. (A) Four different multivariate pattern classification (MVPC) approaches applied</p>
<p>(
Figure legend continued at the bottom of the next page.)</p>
<p>Table 1 .
1Twenty-four hypotheses about the nature and anatomical organization of the neuro-semantic code aCode 
Within subject 
Across subjects 
Single 
voxel </p>
<p>Spatial 
blurring </p>
<p>ROI/SL 
Average before 
model fitting </p>
<p>Average after model 
fitting </p>
<p>Type 
Code b 
Location 
Code 
Location 
n = 46 
n = 40 
n = 63 
n = 45 
n = 64 </p>
<p>Independent 
Homo 
Contiguous 
Consistent 
Same 
100 
100 
100 
100 
100 </p>
<p>Independent 
Homo 
Contiguous 
Consistent 
Different 
100 
100 
100 
100 
10 </p>
<p>Independent 
Homo 
Contiguous 
Inconsistent 
Same 
100 
100 
100 
62 
62 </p>
<p>Independent 
Homo 
Contiguous 
Inconsistent 
Different 
100 
100 
100 
62 
9 </p>
<p>Independent 
Homo 
Dispersed 
Consistent 
Same 
100 
100 
42 
42 
42 </p>
<p>Independent 
Homo 
Dispersed 
Consistent 
Different 
100 
100 
42 
42 
9 </p>
<p>Independent 
Homo 
Dispersed 
Inconsistent 
Same 
100 
100 
42 
23 
23 </p>
<p>Independent 
Homo 
Dispersed 
Inconsistent 
Different 
100 
100 
42 
23 
8 </p>
<p>Independent 
Hetero 
Contiguous 
Consistent 
Same 
100 
60 
60 
60 
60 </p>
<p>Independent 
Hetero 
Contiguous 
Consistent 
Different 
100 
60 
60 
60 
9 </p>
<p>Independent 
Hetero 
Contiguous 
Inconsistent 
Same 
100 
60 
60 
36 
36 </p>
<p>Independent 
Hetero 
Contiguous 
Inconsistent 
Different 
100 
60 
60 
36 
8 </p>
<p>Independent 
Hetero 
Dispersed 
Consistent 
Same 
100 
60 
30 
30 
30 </p>
<p>Independent 
Hetero 
Dispersed 
Consistent 
Different 
100 
60 
30 
30 
8 </p>
<p>Independent 
Hetero 
Dispersed 
Inconsistent 
Same 
100 
60 
30 
17 
17 </p>
<p>Independent 
Hetero 
Dispersed 
Inconsistent 
Different 
100 
60 
30 
17 
7 </p>
<p>Conjoint 
Hetero 
Contiguous 
Consistent 
Same 
46 
23 
23 
23 
23 </p>
<p>Conjoint 
Hetero 
Contiguous 
Consistent 
Different 
46 
23 
23 
23 
2 </p>
<p>Conjoint 
Hetero 
Contiguous 
Inconsistent 
Same 
46 
23 
23 
15 
15 </p>
<p>Conjoint 
Hetero 
Contiguous 
Inconsistent 
Different 
46 
23 
23 
15 
2 </p>
<p>Conjoint 
Hetero 
Dispersed 
Consistent 
Same 
46 
23 
3 
3 
3 </p>
<p>Conjoint 
Hetero 
Dispersed 
Consistent 
Different 
46 
23 
3 
3 
1 </p>
<p>Conjoint 
Hetero 
Dispersed 
Inconsistent 
Same 
46 
23 
3 
3 
3 </p>
<p>Conjoint 
Hetero 
Dispersed 
Inconsistent 
Different 
46 
23 
3 
3 
1 </p>
<p>shows three recent examples. This connection serves several purposes. First, it provides a bridge between functional imaging results and explicit hypotheses about the mechanisms supporting the behavior of interest, rendering the neural data a supporting part of a broader set of ideas about how the system works. Second, such models can offer new hypotheses about the nature of the neural code that might not otherwise occur to the theorist. Third, neurocomputational models can be used to better understand the strengths and weaknesses of different analytic approaches: the theorist can probe model analogs of neural signals and evaluate whether a given technique is capable of discovering information of the type captured by the model. Fourth, models allow exploration of alternative possibilitiesthe strengths and limitations of a given approach can be illuminated by comparing and contrasting its results when applied to models that embody different assumptions about the neural signal.Simplified open data Multivariate imaging studies pose unique challenges for the open data movement. The path from raw data to published result is often complex, software-or system-dependent, contains default parameterizations that may go unexplained, and involves many intermediate data products between raw measurements and summary results that can be exceedingly large and difficult to document. Any single workflow can require extensive effort for outside scientists to fully understand and, because new approaches arrive with daunting frequency, it is difficult to know which bespoke pathways are worth mastering. Nevertheless, each method we have described makes use, at some level, of common data elements that are easy to understand and not too large to document and share. These include (i) the matrix that encodes, for each subject, the estimated response of each neural unit (voxel, electrode, source, etc.) to each stimulus, (ii) the coordinates of the units in a standard reference frame [e.g., Montreal Neurological Institute (MNI) coordinates of voxels, time and location information for ECoG, etc.], and (iii) meta-information about the stimuli (e.g., category labels used for decoding, semantic feature vectors used in an encoding model, the similarity matrix used for RSA, etc.). Sharing only these elements in standardized form would provide minimally sufficient information for scientists to apply a variety of different techniques to a dataset, thus promoting better understanding of how results vary with the method of analysis.Convergence with other forms of evidence Functional imaging alone will not resolve the quest for neuro-semantic representations. A fuller understanding will require relating multivariate imaging results to other diverse sources of evidence in cognitive neuroscience, including (i) the rich neuropsychology literature documenting patterns of verbal and nonverbal semantic impairment and their underlying neuropathologyTrends Trends in in Cognitive Cognitive SciencesSciences
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3 271
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
Trends in Cognitive Sciences, March 2023, Vol. 27, No. 3
AcknowledgmentsDeclaration of interestsThe authors declare no conflicts of interest.Supplemental informationSupplemental information associated with this article can be found online at https://doi.org/10.1016/j.tics.2022.12.006.
Toward a universal decoder of linguistic meaning from brain activation. F Pereira, Nat. Commun. 9Pereira, F. et al. (2018) Toward a universal decoder of linguistic meaning from brain activation. Nat. Commun. 9, 1-13</p>
<p>Visual and linguistic semantic representations are aligned at the border of human visual cortex. S F Popham, Nat. Neurosci. 24Popham, S.F. et al. (2021) Visual and linguistic semantic repre- sentations are aligned at the border of human visual cortex. Nat. Neurosci. 24, 1628-1636</p>
<p>Shared neural codes for visual and semantic information about familiar faces in a common representational space. M Visconti Di Oleggio Castello, Visconti, Proc. Natl. Acad. Sci. U. S. A. 1182110474118Visconti di Oleggio Castello, M. Visconti et al. (2021) Shared neural codes for visual and semantic information about familiar faces in a common representational space. Proc. Natl. Acad. Sci. U. S. A. 118, e2110474118</p>
<p>Deep neural networks: a new framework for modeling biological vision and brain information processing. N Kriegeskorte, Annu. Rev. Vis. Sci. 1Kriegeskorte, N. (2015) Deep neural networks: a new frame- work for modeling biological vision and brain information processing. Annu. Rev. Vis. Sci. 1, 417-446</p>
<p>2021) Finding distributed needles in neural haystacks. C R Cox, T T Rogers, J. Neurosci. 41Cox, C.R. and Rogers, T.T. (2021) Finding distributed needles in neural haystacks. J. Neurosci. 41, 1019-1032</p>
<p>The Foundations of Mind: Origins of Conceptual Thought. J M Mandler, Oxford University Press1st ednMandler, J.M. (2006) The Foundations of Mind: Origins of Conceptual Thought (1st edn), Oxford University Press</p>
<p>Evidence for knowledge-based category discrimination in infancy. S Pauen, Child Dev. 73Pauen, S. (2002) Evidence for knowledge-based category dis- crimination in infancy. Child Dev. 73, 1016-1033</p>
<p>The global-to-basic shift in infants' categorical thinking: first evidence from a longitudinal study. S Pauen, Int. J. Behav. Dev. 26Pauen, S. (2002) The global-to-basic shift in infants' categorical thinking: first evidence from a longitudinal study. Int. J. Behav. Dev. 26, 492-499</p>
<p>The structure and deterioration of semantic memory: a computational and neuropsychological investigation. T T Rogers, Psychol. Rev. 111Rogers, T.T. et al. (2004) The structure and deterioration of semantic memory: a computational and neuropsychological investigation. Psychol. Rev. 111, 205-235</p>
<p>The tree of life: universal and cultural features of folkbiological taxonomies and inductions. A Lopez, Cogn. Psychol. 32Lopez, A. et al. (1997) The tree of life: universal and cultural fea- tures of folkbiological taxonomies and inductions. Cogn. Psychol. 32, 251-295</p>
<p>Charting the progression in semantic dementia: implications for the organisation of semantic memory. J R Hodges, Memory. 3Hodges, J.R. et al. (1995) Charting the progression in semantic dementia: implications for the organisation of semantic memory. Memory 3, 463-495</p>
<p>Words as invitations to form categories: evidence from 12-to 13-month-old infants. S R Waxman, D B Markow, Cogn. Psychol. 29Waxman, S.R. and Markow, D.B. (1995) Words as invitations to form categories: evidence from 12-to 13-month-old infants. Cogn. Psychol. 29, 257-302</p>
<p>Taking stock as theories of word learning take shape. A E Booth, S R Waxman, Dev. Sci. 11Booth, A.E. and Waxman, S.R. (2008) Taking stock as theories of word learning take shape. Dev. Sci. 11, 185-194</p>
<p>Thematic relations in adults' concepts. E L Lin, G L Murphy, J. Exp. Psychol. Gen. 130Lin, E.L. and Murphy, G.L. (2001) Thematic relations in adults' concepts. J. Exp. Psychol. Gen. 130, 3-28</p>
<p>The adaptive nature of human categorization. J R Anderson, Psychol. Rev. 98Anderson, J.R. (1991) The adaptive nature of human categorization. Psychol. Rev. 98, 409-426</p>
<p>Basic objects in natural categories. E Rosch, Cogn. Psychol. 8Rosch, E. et al. (1976) Basic objects in natural categories. Cogn. Psychol. 8, 382-439</p>
<p>Retrieval time from semantic memory. A M Collins, M R Quillian, J. Verbal Learn. Verbal Behav. 8Collins, A.M. and Quillian, M.R. (1969) Retrieval time from se- mantic memory. J. Verbal Learn. Verbal Behav. 8, 240-247</p>
<p>Pictures and names: making the connection. P Jolicoeur, Cogn. Psychol. 19Jolicoeur, P. et al. (1984) Pictures and names: making the connection. Cogn. Psychol. 19, 31-53</p>
<p>Word learning as Bayesian inference. F Xu, J B Tenenbaum, Psychol. Rev. 114Xu, F. and Tenenbaum, J.B. (2007) Word learning as Bayesian inference. Psychol. Rev. 114, 245-272</p>
<p>A feedforward architecture accounts for rapid categorization. T Serre, Proc. Natl. Acad. Sci. 104Serre, T. et al. (2007) A feedforward architecture accounts for rapid categorization. Proc. Natl. Acad. Sci. 104, 6424-6429</p>
<p>Hierarchies, similarity, and interactivity in object-recognition: on the multiplicity of 'category-specific' deficits in neuropsychological populations. G W Humphreys, E M Forde, Behav. Brain Sci. 24Humphreys, G.W. and Forde, E.M. (2001) Hierarchies, similar- ity, and interactivity in object-recognition: on the multiplicity of 'category-specific' deficits in neuropsychological populations. Behav. Brain Sci. 24, 453-509</p>
<p>A computational model of semantic memory impairment: modality-specificity and emergent category-specificity. M J Farah, J L Mcclelland, J. Exp. Psychol. Gen. 120Farah, M.J. and McClelland, J.L. (1991) A computational model of semantic memory impairment: modality-specificity and emergent category-specificity. J. Exp. Psychol. Gen. 120, 339-357</p>
<p>An attractor model of lexical conceptual processing: simulating semantic priming. G Cree, Cogn. Sci. 23Cree, G. et al. (1999) An attractor model of lexical conceptual processing: simulating semantic priming. Cogn. Sci. 23, 371-414</p>
<p>Conceptual structure and the structure of concepts: a distributed account of category-specific deficits. L Tyler, Brain Lang. 75Tyler, L. et al. (2000) Conceptual structure and the structure of concepts: a distributed account of category-specific deficits. Brain Lang. 75, 195-231</p>
<p>The representation of object concepts in the brain. A Martin, Annu. Rev. Psychol. 58Martin, A. (2007) The representation of object concepts in the brain. Annu. Rev. Psychol. 58, 25-45</p>
<p>An integrated neural decoder of linguistic and experiential meaning. A J Anderson, J. Neurosci. 39Anderson, A.J. et al. (2019) An integrated neural decoder of lin- guistic and experiential meaning. J. Neurosci. 39, 8969-8987</p>
<p>On the nature and scope of featural representations of word meaning. K Mcrae, J. Exp. Psychol. Gen. 126McRae, K. et al. (1997) On the nature and scope of featural rep- resentations of word meaning. J. Exp. Psychol. Gen. 126, 99-130</p>
<p>Dutch norm data for 13 semantic categories and 338 exemplars. W Ruts, Behav. Res. Methods Instrum. Comput. 36Ruts, W. et al. (2004) Dutch norm data for 13 semantic catego- ries and 338 exemplars. Behav. Res. Methods Instrum. Comput. 36, 506-515</p>
<p>Categorization of natural objects. C B Mervis, E Rosch, Annu. Rev. Psychol. 32Mervis, C.B. and Rosch, E. (1981) Categorization of natural objects. Annu. Rev. Psychol. 32, 89-115</p>
<p>The timing of visual object categorization. M Mack, T Palmeri, Front. Psychol. 2165Mack, M. and Palmeri, T. (2011) The timing of visual object categorization. Front. Psychol. 2, 165</p>
<p>A spreading-activation theory of semantic processing. A M Collins, E F Loftus, Psychol. Rev. 82Collins, A.M. and Loftus, E.F. (1975) A spreading-activation the- ory of semantic processing. Psychol. Rev. 82, 407-428</p>
<p>Hierarchical models of object recognition in cortex. M Riesenhuber, T Poggio, Nat. Neurosci. 2Riesenhuber, M. and Poggio, T. (1999) Hierarchical models of object recognition in cortex. Nat. Neurosci. 2, 1019-1025</p>
<p>A solution to Plato's problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge. T K Landauer, S T Dumais, Psychol. Rev. 104Landauer, T.K. and Dumais, S.T. (1997) A solution to Plato's problem: the latent semantic analysis theory of acquisition, in- duction, and representation of knowledge. Psychol. Rev. 104, 211-240</p>
<p>Distributed representations of words and phrases and their compositionality. T Mikolov, Proceedings of the 26th International Conference on Neural Information Processing Systems. the 26th International Conference on Neural Information Processing SystemsCurran Associates Inc2Mikolov, T. et al. (2013) Distributed representations of words and phrases and their compositionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems (Vol. 2), pp. 3111-3119, Curran Associates Inc.</p>
<p>A comparative evaluation of off-the-shelf distributed semantic representations for modelling behavioural data. F Pereira, Cogn. Neuropsychol. 33Pereira, F. et al. (2016) A comparative evaluation of off-the-shelf distributed semantic representations for modelling behavioural data. Cogn. Neuropsychol. 33, 175-190</p>
<p>J Katz, Semantic Theory. Addison-Wesley Educational PublishersKatz, J. (1972) Semantic Theory, Addison-Wesley Educational Publishers</p>
<p>Principles of categorization. E Rosch, Cognition and Categorization (Lloyd, B. and Rosch, E.Lawrence Erlbaum AssociatesRosch, E. (1978) Principles of categorization. In Cognition and Categorization (Lloyd, B. and Rosch, E., eds), pp. 27-48, Lawrence Erlbaum Associates</p>
<p>Categories, prototype and exemplars. J A Hampton, The Routledge Handbook of Semantics. Riemer, N.RoutledgeHampton, J.A. (2015) Categories, prototype and exemplars. In The Routledge Handbook of Semantics (Riemer, N., ed.), pp. 141-157, Routledge</p>
<p>Modeling the structure and dynamics of semantic processing. A S Rotaru, Cogn. Sci. 42Rotaru, A.S. et al. (2018) Modeling the structure and dynamics of semantic processing. Cogn. Sci. 42, 2890-2917</p>
<p>A critical review of network-based and distributional approaches to semantic memory structure and processes. A A Kumar, Top. Cogn. Sci. 14Kumar, A.A. et al. (2022) A critical review of network-based and distributional approaches to semantic memory structure and processes. Top. Cogn. Sci. 14, 54-77</p>
<p>Topics in semantic representation. T L Griffiths, Psychol. Rev. 114Griffiths, T.L. et al. (2007) Topics in semantic representation. Psychol. Rev. 114, 211-244</p>
<p>Using sparse semantic embeddings learned from multimodal text and image data to model human conceptual knowledge. S Derby, 10.48550/arXiv.1809.02534ArXiv Published onlineDerby, S. et al. (2018) Using sparse semantic embeddings learned from multimodal text and image data to model human conceptual knowledge. ArXiv Published online September 7, 2018. https://doi.org/10.48550/arXiv.1809.02534</p>
<p>Modelling parsing constraints with high-dimensional context space. C Burgess, K Lund, Lang. Cogn. Process. 12Burgess, C. and Lund, K. (1997) Modelling parsing constraints with high-dimensional context space. Lang. Cogn. Process. 12, 177-210</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, 10.48550/arXiv.1810.04805ArXiv Published on. Devlin, J. et al. (2019) BERT: pre-training of deep bidirectional transformers for language understanding. ArXiv Published on- line May 24, 2019. https://doi.org/10.48550/arXiv.1810.04805</p>
<p>Grounded cognition. L W Barsalou, Anuual Rev. Psychol. 59Barsalou, L.W. (2008) Grounded cognition. Anuual Rev. Psychol. 59, 617-645</p>
<p>Situated simulation in the human conceptual system. L W Barsalou, Lang. Cogn. Process. 18Barsalou, L.W. (2003) Situated simulation in the human con- ceptual system. Lang. Cogn. Process. 18, 513-562</p>
<p>Symbol grounding and meaning: a comparison of high-dimensional and embodied theories of meaning. A M Glenberg, D A Robertson, J. Mem. Lang. 43Glenberg, A.M. and Robertson, D.A. (2000) Symbol grounding and meaning: a comparison of high-dimensional and embodied theories of meaning. J. Mem. Lang. 43, 379-401</p>
<p>Embodiment as a unifying perspective for psychology. A M Glenberg, Wiley Interdiscip. Rev. Cogn. Sci. 1Glenberg, A.M. (2010) Embodiment as a unifying perspective for psychology. Wiley Interdiscip. Rev. Cogn. Sci. 1, 586-596</p>
<p>The brain binds entities and events by multiregional activation from convergence zones. A R Damasio, Neural Comput. 1Damasio, A.R. (1989) The brain binds entities and events by multiregional activation from convergence zones. Neural Comput. 1, 123-132</p>
<p>Neural systems behind word and concept retrieval. H Damasio, Cognition. 92Damasio, H. et al. (2004) Neural systems behind word and con- cept retrieval. Cognition 92, 179-229</p>
<p>GRAPES -grounding representations in action, perception, and emotion systems: how object properties and categories are represented in the human brain. A Martin, Psychon. Bull. Rev. 23Martin, A. (2016) GRAPES -grounding representations in ac- tion, perception, and emotion systems: how object properties and categories are represented in the human brain. Psychon. Bull. Rev. 23, 979-990</p>
<p>Decoding the information structure underlying the neural representation of concepts. L Fernandino, Proc. Natl. Acad. Sci. Natl. Acad. Sci1192108091119Fernandino, L. et al. (2022) Decoding the information structure underlying the neural representation of concepts. Proc. Natl. Acad. Sci. 119, e2108091119</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, Nat. Rev. Neurosci. 8Patterson, K. et al. (2007) Where do you know what you know? The representation of semantic knowledge in the human brain. Nat. Rev. Neurosci. 8, 976-987</p>
<p>The neural and computational bases of semantic cognition. Lambon Ralph, M A , Nat. Rev. Neurosci. 18Lambon Ralph, M.A. et al. (2017) The neural and computational bases of semantic cognition. Nat. Rev. Neurosci. 18, 42-55</p>
<p>T T Rogers, J L Mcclelland, Semantic Cognition: A Parallel Distributed Processing Approach. MIT PressRogers, T.T. and McClelland, J.L. (2004) Semantic Cognition: A Parallel Distributed Processing Approach, MIT Press</p>
<p>A model of representational spaces in human cortex. J S Guntupalli, Cereb. Cortex. 26Guntupalli, J.S. et al. (2016) A model of representational spaces in human cortex. Cereb. Cortex 26, 2919-2934</p>
<p>Information mapping with pattern classifiers: a comparative study. F Pereira, M Botvinick, NeuroImage. 56Pereira, F. and Botvinick, M. (2011) Information mapping with pattern classifiers: a comparative study. NeuroImage 56, 476-496</p>
<p>Beyond mind-reading: multi-voxel pattern analysis of fMRI data. K A Norman, Trends Cogn. Sci. 10Norman, K.A. et al. (2006) Beyond mind-reading: multi-voxel pattern analysis of fMRI data. Trends Cogn. Sci. 10, 424-430</p>
<p>Information-based functional brain mapping. N Kriegeskorte, Proc. Natl. Acad. Sci. 103Kriegeskorte, N. et al. (2006) Information-based functional brain mapping. Proc. Natl. Acad. Sci. 103, 3863-3868</p>
<p>Connecting functional brain imaging and parallel distributed processing. C R Cox, Lang. Cogn. Neurosci. 30Cox, C.R. et al. (2015) Connecting functional brain imaging and parallel distributed processing. Lang. Cogn. Neurosci. 30, 380-394</p>
<p>Neural representations of abstract concepts: identifying underlying neurosemantic dimensions. R Vargas, M A Just, Cereb. Cortex. 30Vargas, R. and Just, M.A. (2020) Neural representations of abstract concepts: identifying underlying neurosemantic dimensions. Cereb. Cortex 30, 2157-2166</p>
<p>Ridge regression: biased estimation for nonorthogonal problems. A E Hoerl, R W Kennard, Technometrics. 42Hoerl, A.E. and Kennard, R.W. (2000) Ridge regression: biased estimation for nonorthogonal problems. Technometrics 42, 80-86</p>
<p>Regression shrinkage and selection via the lasso. R Tibshirani, J. R. Stat. Soc. Ser. B Methodol. 58Tibshirani, R. (1996) Regression shrinkage and selection via the lasso. J. R. Stat. Soc. Ser. B Methodol. 58, 267-288</p>
<p>On model selection consistency of the elastic net when p &gt;&gt; n. J Jia, B Yu, Stat. Sin. 20Jia, J. and Yu, B. (2008) On model selection consistency of the elastic net when p &gt;&gt; n. Stat. Sin. 20, 595-611</p>
<p>Sparse overlapping sets lasso for multitask learning and its application to fMRI analysis. N Rao, Adv. Neural Inf. Proces. Syst. 26Rao, N. et al. (2013) Sparse overlapping sets lasso for multitask learning and its application to fMRI analysis. Adv. Neural Inf. Proces. Syst. 26, 2202-2210</p>
<p>Classification with the sparse group lasso. N Rao, IEEE Trans. Signal Process. 64Rao, N. et al. (2016) Classification with the sparse group lasso. IEEE Trans. Signal Process. 64, 448-463</p>
<p>Machine learning classifiers and fMRI: a tutorial overview. F Pereira, NeuroImage. 45Pereira, F. et al. (2009) Machine learning classifiers and fMRI: a tutorial overview. NeuroImage 45, S199-S209</p>
<p>The representation of biological classes in the human brain. A C Connolly, J. Neurosci. 32Connolly, A.C. et al. (2012) The representation of biological classes in the human brain. J. Neurosci. 32, 2608-2618</p>
<p>Integrated deep visual and semantic attractor neural networks predict fMRI pattern-information along the ventral object processing pathway. B J Devereux, Sci. Rep. 8Devereux, B.J. et al. (2018) Integrated deep visual and se- mantic attractor neural networks predict fMRI pattern-infor- mation along the ventral object processing pathway. Sci. Rep. 8, 1-12</p>
<p>Representational similarity analysis reveals commonalities and differences in the semantic processing of words and objects. B J Devereux, J. Neurosci. 33Devereux, B.J. et al. (2013) Representational similarity analysis reveals commonalities and differences in the semantic process- ing of words and objects. J. Neurosci. 33, 18906-18916</p>
<p>Integrative and distinctive coding of visual and conceptual object features in the ventral visual stream. C B Martin, 731873Martin, C.B. et al. (2018) Integrative and distinctive coding of vi- sual and conceptual object features in the ventral visual stream. eLife 7, e31873</p>
<p>Predicting human brain activity associated with the meanings of nouns. T M Mitchell, Science. 320Mitchell, T.M. et al. (2008) Predicting human brain activity asso- ciated with the meanings of nouns. Science 320, 1191-1195</p>
<p>A neurosemantic theory of concrete noun representation based on the underlying brain codes. M A Just, PLoS One. 58622Just, M.A. et al. (2010) A neurosemantic theory of concrete noun representation based on the underlying brain codes. PLoS One 5, e8622</p>
<p>Generating text from functional brain images. F Pereira, Front. Hum. Neurosci. 572Pereira, F. et al. (2011) Generating text from functional brain images. Front. Hum. Neurosci. 5, 72</p>
<p>Natural speech reveals the semantic maps that tile human cerebral cortex. A G Huth, Nature. 532Huth, A.G. et al. (2016) Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453-458</p>
<p>A continuous semantic space describes the representation of thousands of object and action categories across the human brain. A G Huth, Neuron. 76Huth, A.G. et al. (2012) A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron 76, 1210-1224</p>
<p>Voxelwise encoding models with non-spherical multivariate normal priors. A O Nunez-Elizalde, NeuroImage. 197Nunez-Elizalde, A.O. et al. (2019) Voxelwise encoding models with non-spherical multivariate normal priors. NeuroImage 197, 482-492</p>
<p>Decoding neural representational spaces using multivariate pattern analysis. J V Haxby, Annu. Rev. Neurosci. 37Haxby, J.V. et al. (2014) Decoding neural representational spaces using multivariate pattern analysis. Annu. Rev. Neurosci. 37, 435-456</p>
<p>Representational models: a common framework for understanding encoding, pattern-component, and representational-similarity analysis. J Diedrichsen, N Kriegeskorte, PLoS Comput. Biol. 131005508Diedrichsen, J. and Kriegeskorte, N. (2017) Representational models: a common framework for understanding encoding, pattern-component, and representational-similarity analysis. PLoS Comput. Biol. 13, e1005508</p>
<p>Object-specific semantic coding in human perirhinal cortex. A Clarke, L K Tyler, J. Neurosci. 34Clarke, A. and Tyler, L.K. (2014) Object-specific semantic cod- ing in human perirhinal cortex. J. Neurosci. 34, 4766-4775</p>
<p>Category-specific representational patterns in left inferior frontal and temporal cortex reflect similarities and differences in the sensorimotor and distributional properties of concepts. F Carota, 10.1101/2021.09.03.458378BioRxiv Published onlineCarota, F. et al. (2021) Category-specific representational pat- terns in left inferior frontal and temporal cortex reflect similarities and differences in the sensorimotor and distributional properties of concepts. BioRxiv Published online September 3, 2021. https://doi.org/10.1101/2021.09.03.458378</p>
<p>Commonality of neural representations of words and pictures. S V Shinkareva, NeuroImage. 54Shinkareva, S.V. et al. (2011) Commonality of neural represen- tations of words and pictures. NeuroImage 54, 2418-2425</p>
<p>Modality-independent decoding of semantic information from the human brain. I Simanova, Cereb. Cortex. 24Simanova, I. et al. (2014) Modality-independent decoding of se- mantic information from the human brain. Cereb. Cortex 24, 426-434</p>
<p>How concepts are encoded in the human brain: a modality independent, category-based cortical organization of semantic knowledge. G Handjaras, NeuroImage. 135Handjaras, G. et al. (2016) How concepts are encoded in the human brain: a modality independent, category-based cortical organization of semantic knowledge. NeuroImage 135, 232-242</p>
<p>Neural networks as a critical level of description for cognitive neuroscience. T T Rogers, Curr. Opin. Behav. Sci. 32Rogers, T.T. (2020) Neural networks as a critical level of de- scription for cognitive neuroscience. Curr. Opin. Behav. Sci. 32, 167-173</p>
<p>From the neuron doctrine to neural networks. R Yuste, Nat. Rev. Neurosci. 16Yuste, R. (2015) From the neuron doctrine to neural networks. Nat. Rev. Neurosci. 16, 487-497</p>
<p>Task representations in neural networks trained to perform many cognitive tasks. G R Yang, Nat. Neurosci. 22Yang, G.R. et al. (2019) Task representations in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22, 297-306</p>
<p>A deep learning framework for neuroscience. B A Richards, Nat. Neurosci. 22Richards, B.A. et al. (2019) A deep learning framework for neuroscience. Nat. Neurosci. 22, 1761-1770</p>
<p>Semantic dementia: one window on the structure and organisation of semantic memory. K Patterson, J Hodges, Handbook of Neuropsychology. Cermak, J.Elsevier Science2Memory and Its DisordersPatterson, K. and Hodges, J. (2000) Semantic dementia: one window on the structure and organisation of semantic memory. In Handbook of Neuropsychology Vol. 2: Memory and Its Disor- ders (Cermak, J., ed.), pp. 313-333, Elsevier Science</p>
<p>The organization of conceptual knowledge: the evidence from category-specific semantic deficits. A Caramazza, B Z Mahon, Trends Cogn. Sci. 7Caramazza, A. and Mahon, B.Z. (2003) The organization of conceptual knowledge: the evidence from category-specific se- mantic deficits. Trends Cogn. Sci. 7, 354-361</p>
<p>Words and objects at the tip of the left temporal lobe in primary progressive aphasia. M M Mesulam, Brain J. Neurol. 136Mesulam, M.M. et al. (2013) Words and objects at the tip of the left temporal lobe in primary progressive aphasia. Brain J. Neurol. 136, 601-618</p>
<p>Semantic impairment in stroke aphasia versus semantic dementia: a caseseries comparison. E Jefferies, M A Ralph, Brain. 129Jefferies, E. and Lambon Ralph, M.A. (2006) Semantic impair- ment in stroke aphasia versus semantic dementia: a case- series comparison. Brain 129, 2132-2147</p>
<p>Atrophy, hypometabolism and white matter abnormalities in semantic dementia tell a coherent story. J Acosta-Cabronero, Brain. 134Acosta-Cabronero, J. et al. (2011) Atrophy, hypometabolism and white matter abnormalities in semantic dementia tell a co- herent story. Brain 134, 2025-2035</p>
<p>Revisiting domain-general accounts of category specificity in mind and brain. L Chen, T T Rogers, Wiley Interdiscip. Rev. Cogn. Sci. 5Chen, L. and Rogers, T.T. (2014) Revisiting domain-general ac- counts of category specificity in mind and brain. Wiley Interdiscip. Rev. Cogn. Sci. 5, 327-344</p>
<p>Category-specific versus categorygeneral semantic impairment induced by transcranial magnetic stimulation. G Pobric, Curr. Biol. 20Pobric, G. et al. (2010) Category-specific versus category- general semantic impairment induced by transcranial magnetic stimulation. Curr. Biol. 20, 964-968</p>
<p>Anterior temporal lobes mediate semantic representation: mimicking semantic dementia by using rTMS in normal participants. G Pobric, Proc. Natl. Acad. Sci. U. S. A. 104Pobric, G. et al. (2007) Anterior temporal lobes mediate seman- tic representation: mimicking semantic dementia by using rTMS in normal participants. Proc. Natl. Acad. Sci. U. S. A. 104, 20137-20141</p>
<p>Conceptual knowledge is underpinned by the temporal pole bilaterally: convergent evidence from rTMS. Lambon Ralph, M A , Cereb. Cortex. 19Lambon Ralph, M.A. et al. (2009) Conceptual knowledge is underpinned by the temporal pole bilaterally: convergent evi- dence from rTMS. Cereb. Cortex 19, 832-838</p>
<p>Action-related properties shape object representations in the ventral stream. B Z Mahon, Neuron. 55Mahon, B.Z. et al. (2007) Action-related properties shape object representations in the ventral stream. Neuron 55, 507-520</p>
<p>Convergent connectivity and graded specialization in the rostral human temporal lobe as revealed by diffusion-weighted imaging probabilistic tractography. R J Binney, J. Cogn. Neurosci. 24Binney, R.J. et al. (2012) Convergent connectivity and graded specialization in the rostral human temporal lobe as revealed by diffusion-weighted imaging probabilistic tractography. J. Cogn. Neurosci. 24, 1998-2014</p>
<p>A unified model of human semantic knowledge and its disorders. L Chen, Nat. Hum. Behav. 1Chen, L. et al. (2017) A unified model of human semantic knowl- edge and its disorders. Nat. Hum. Behav. 1, 1-10</p>
<p>Complementary neural representations for faces and words: a computational exploration. D C Plaut, M Behrmann, Cogn. Neuropsychol. 28Plaut, D.C. and Behrmann, M. (2011) Complementary neural representations for faces and words: a computational exploration. Cogn. Neuropsychol. 28, 251-275</p>
<p>Bilateral hemispheric processing of words and faces: evidence from word impairments in prosopagnosia and face impairments in pure alexia. M Behrmann, D C Plaut, Cereb. Cortex. 24Behrmann, M. and Plaut, D.C. (2012) Bilateral hemispheric pro- cessing of words and faces: evidence from word impairments in prosopagnosia and face impairments in pure alexia. Cereb. Cortex 24, 1102-1118</p>
<p>Is it a bird? Is it a plane? Ultra-rapid visual categorization of natural and artifactual objects. R Van Rullen, S J Thorpe, Perception. 30Van Rullen, R. and Thorpe, S.J. (2001) Is it a bird? Is it a plane? Ultra-rapid visual categorization of natural and artifactual objects. Perception 30, 655-668</p>
<p>Object categorization: reversals and explanations of the basic-level advantage. T T Rogers, K Patterson, J. Exp. Psychol. Gen. 136451Rogers, T.T. and Patterson, K. (2007) Object categorization: reversals and explanations of the basic-level advantage. J. Exp. Psychol. Gen. 136, 451</p>
<p>Cognitive representations of semantic categories. E Rosch, J. Exp. Psychol. Gen. 104105. Rosch, E. (1975) Cognitive representations of semantic categories. J. Exp. Psychol. Gen. 104, 192-233</p>
<p>What some concepts might not be. S L Armstrong, Cognition. 13Armstrong, S.L. et al. (1983) What some concepts might not be. Cognition 13, 263-308</p>
<p>Domain-specific knowledge systems in the brain: the animate-inanimate distinction. A Caramazza, J R Shelton, J. Cogn. Neurosci. 10Caramazza, A. and Shelton, J.R. (1998) Domain-specific knowl- edge systems in the brain: the animate-inanimate distinction. J. Cogn. Neurosci. 10, 1-34</p>
<p>Functional specificity in the human brain: a window into the functional architecture of the mind. N Kanwisher, Proc. Natl. Acad. Sci. U. S. A. 107Kanwisher, N. (2010) Functional specificity in the human brain: a window into the functional architecture of the mind. Proc. Natl. Acad. Sci. U. S. A. 107, 11163-11170</p>
<p>The Big Book of Concepts. G Murphy, MIT PressMurphy, G. (2002) The Big Book of Concepts, MIT Press</p>
<p>The role of theories in conceptual coherence. G Murphy, D L Medin, Psychol. Rev. 92Murphy, G. and Medin, D.L. (1985) The role of theories in con- ceptual coherence. Psychol. Rev. 92, 289-316</p>
<p>Semantic feature production norms for a large set of living and nonliving things. K Mcrae, Behav. Res. Methods Instrum. Comput. 37McRae, K. et al. (2005) Semantic feature production norms for a large set of living and nonliving things. Behav. Res. Methods Instrum. Comput. 37, 547-559</p>
<p>Learning and representing verbal meaning: the latent semantic analysis theory. T K Landauer, Curr. Dir. Psychol. Sci. 7Landauer, T.K. (1998) Learning and representing verbal meaning: the latent semantic analysis theory. Curr. Dir. Psychol. Sci. 7, 161-164</p>
<p>An introduction to latent semantic analysis. T K Landauer, Discourse Process. 25Landauer, T.K. et al. (1998) An introduction to latent semantic analysis. Discourse Process. 25, 259-284</p>
<p>Word2Sense: sparse interpretable word embeddings. A Panigrahi, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsPanigrahi, A. et al. (2019) Word2Sense: sparse interpret- able word embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 5692-5705, ACL</p>
<p>ImageNet classification with deep convolutional neural networks. A Krizhevsky, Commun. ACM. 60Krizhevsky, A. et al. (2017) ImageNet classification with deep convolutional neural networks. Commun. ACM 60, 84-90</p>
<p>Very deep convolutional networks for large-scale image recognition. K Simonyan, A Zisserman, 10.48550/arXiv.1409.1556ArXiv Published onlineSimonyan, K. and Zisserman, A. (2015) Very deep convolutional networks for large-scale image recognition. ArXiv Published online April 10, 2015. https://doi.org/10. 48550/arXiv.1409.1556</p>
<p>GPT-3: its nature, scope, limits, and consequences. L Floridi, M Chiriatti, Mind. Mach. 30Floridi, L. and Chiriatti, M. (2020) GPT-3: its nature, scope, limits, and consequences. Mind. Mach. 30, 681-694</p>
<p>Left perirhinal cortex codes for similarity in meaning between written words: comparison with auditory word input. A G Liuzzi, Neuropsychologia. 76Liuzzi, A.G. et al. (2015) Left perirhinal cortex codes for similarity in meaning between written words: comparison with auditory word input. Neuropsychologia 76, 4-16</p>
<p>Modulation of the semantic system by word imageability. D S Sabsevitz, NeuroImage. 27Sabsevitz, D.S. et al. (2005) Modulation of the semantic system by word imageability. NeuroImage 27, 188-200</p>
<p>Anterior temporal cortex and semantic memory: reconciling findings from neuropsychology and functional imaging. T T Rogers, Cogn. Affect. Behav. Neurosci. 6Rogers, T.T. et al. (2006) Anterior temporal cortex and se- mantic memory: reconciling findings from neuropsychology and functional imaging. Cogn. Affect. Behav. Neurosci. 6, 201-213</p>
<p>Going beyond inferior prefrontal involvement in semantic control: evidence for the additional contribution of dorsal angular gyrus and posterior middle temporal cortex. K A Noonan, J. Cogn. Neurosci. 25Noonan, K.A. et al. (2013) Going beyond inferior prefrontal in- volvement in semantic control: evidence for the additional con- tribution of dorsal angular gyrus and posterior middle temporal cortex. J. Cogn. Neurosci. 25, 1824-1850</p>
<p>Controlled semantic cognition relies upon dynamic and flexible interactions between the executive 'semantic control' and hub-and-spoke 'semantic representation' systems. R Chiou, Cortex. 103Chiou, R. et al. (2018) Controlled semantic cognition relies upon dynamic and flexible interactions between the executive 'semantic control' and hub-and-spoke 'semantic representation' systems. Cortex 103, 100-116</p>
<p>Neural systems for reading aloud: a multiparametric approach. W W Graves, Cereb. Cortex. 20Graves, W.W. et al. (2010) Neural systems for reading aloud: a multiparametric approach. Cereb. Cortex 20, 1799-1815</p>
<p>Temporary activation of long-term memory supports working memory. J A Lewis-Peacock, B R Postle, J. Neurosci. 28Lewis-Peacock, J.A. and Postle, B.R. (2008) Temporary activa- tion of long-term memory supports working memory. J. Neurosci. 28, 8765-8771</p>
<p>Noise contributions to the fMRI signal: an overview. T T Liu, NeuroImage. 143Liu, T.T. (2016) Noise contributions to the fMRI signal: an overview. NeuroImage 143, 141-151</p>
<p>Distortion correction for diffusionweighted MRI tractography and fMRI in the temporal lobes. K V Embleton, Hum. Brain Mapp. 31Embleton, K.V. et al. (2010) Distortion correction for diffusion- weighted MRI tractography and fMRI in the temporal lobes. Hum. Brain Mapp. 31, 1570-1587</p>
<p>The ventral and inferolateral aspects of the anterior temporal lobe are crucial in semantic memory: evidence from a novel direct comparison of distortioncorrected fMRI, rTMS, and semantic dementia. R J Binney, Cereb. Cortex. 20Binney, R.J. et al. (2010) The ventral and inferolateral aspects of the anterior temporal lobe are crucial in semantic memory: evidence from a novel direct comparison of distortion- corrected fMRI, rTMS, and semantic dementia. Cereb. Cortex 20, 2728-2738</p>
<p>A comparison of dual gradient-echo and spin-echo fMRI of the inferior temporal lobe. A D Halai, Hum. Brain Mapp. 35Halai, A.D. et al. (2014) A comparison of dual gradient-echo and spin-echo fMRI of the inferior temporal lobe. Hum. Brain Mapp. 35, 4118-4128</p>
<p>Multi-echo fMRI: a review of applications in fMRI denoising and analysis of BOLD signals. P Kundu, NeuroImage. 154Kundu, P. et al. (2017) Multi-echo fMRI: a review of applications in fMRI denoising and analysis of BOLD signals. NeuroImage 154, 59-80</p>
<p>Stimulus-independent neural coding of event semantics: evidence from cross-sentence fMRI decoding. A Asyraff, NeuroImage. 236118073Asyraff, A. et al. (2021) Stimulus-independent neural coding of event semantics: evidence from cross-sentence fMRI decoding. NeuroImage 236, 118073</p>
<p>Semantic processing in the anterior temporal lobes: a meta-analysis of the functional neuroimaging literature. M Visser, J. Cogn. Neurosci. 22Visser, M. et al. (2010) Semantic processing in the anterior temporal lobes: a meta-analysis of the functional neuroimaging literature. J. Cogn. Neurosci. 22, 1083-1094</p>
<p>Evidence for a deep, distributed and dynamic code for animacy in human ventral anterior temporal cortex. T T Rogers, 1066276Rogers, T.T. et al. (2021) Evidence for a deep, distributed and dynamic code for animacy in human ventral anterior temporal cortex. eLife 10, e66276</p>
<p>Matching categorical object representations in inferior temporal cortex of man and monkey. N Kriegeskorte, Neuron. 60Kriegeskorte, N. et al. (2008) Matching categorical object repre- sentations in inferior temporal cortex of man and monkey. Neuron 60, 1126-1141</p>
<p>Deep neural networks rival the representation of primate IT cortex for core visual object recognition. C F Cadieu, PLoS Comput. Biol. 101003963Cadieu, C.F. et al. (2014) Deep neural networks rival the repre- sentation of primate IT cortex for core visual object recognition. PLoS Comput. Biol. 10, e1003963</p>
<p>Reassessing hierarchical correspondences between brain and deep networks through direct interface. N J Sexton, B C Love, Sci. Adv. 82219Sexton, N.J. and Love, B.C. (2022) Reassessing hierarchical correspondences between brain and deep networks through direct interface. Sci. Adv. 8, eabm2219</p>
<p>Individual differences among deep neural network models. J Mehrer, Nat. Commun. 11Mehrer, J. et al. (2020) Individual differences among deep neu- ral network models. Nat. Commun. 11, 1-12</p>
<p>Semantic dementia and fluent primary progressive aphasia: two sides of the same coin. A.-L R Adlam, Brain. 129Adlam, A.-L.R. et al. (2006) Semantic dementia and fluent pri- mary progressive aphasia: two sides of the same coin? Brain 129, 3066-3080</p>
<p>Disorders of representation and control in semantic cognition: effects of familiarity, typicality, and specificity. T T Rogers, Neuropsychologia. 76Rogers, T.T. et al. (2015) Disorders of representation and con- trol in semantic cognition: effects of familiarity, typicality, and specificity. Neuropsychologia 76, 220-239</p>
<p>Category-specific organization in the human brain does not require visual experience. B Z Mahon, Neuron. 63Mahon, B.Z. et al. (2009) Category-specific organization in the human brain does not require visual experience. Neuron 63, 397-405</p>
<p>The representation of tools in left parietal cortex is independent of visual experience. B Z Mahon, Psychol. Sci. 21Mahon, B.Z. et al. (2010) The representation of tools in left pa- rietal cortex is independent of visual experience. Psychol. Sci. 21, 764-771</p>
<p>Insights into the origins of knowledge from the cognitive neuroscience of blindness. M Bedny, R Saxe, Cogn. Neuropsychol. 29Bedny, M. and Saxe, R. (2012) Insights into the origins of knowledge from the cognitive neuroscience of blindness. Cogn. Neuropsychol. 29, 56-84</p>
<p>A model of emergent category-specific activation in the posterior fusiform gyrus of sighted and congenitally blind populations. L Chen, T T Rogers, J. Cogn. Neurosci. 27Chen, L. and Rogers, T.T. (2015) A model of emergent category-specific activation in the posterior fusiform gyrus of sighted and congenitally blind populations. J. Cogn. Neurosci. 27, 1981-1999</p>
<p>Domain specificity in face perception. N Kanwisher, Nat. Neurosci. 3Kanwisher, N. (2000) Domain specificity in face perception. Nat. Neurosci. 3, 759-763</p>
<p>The fusiform face area: a module in human extrastriate cortex specialized for face perception. N Kanwisher, J. Neurosci. 17Kanwisher, N. et al. (1997) The fusiform face area: a module in human extrastriate cortex specialized for face perception. J. Neurosci. 17, 4302-4311</p>
<p>Neural mechanisms of face perception, their emergence over development, and their breakdown. M Behrmann, WIREs Cogn. Sci. 7Behrmann, M. et al. (2016) Neural mechanisms of face percep- tion, their emergence over development, and their breakdown. WIREs Cogn. Sci. 7, 247-263</p>
<p>The joint development of hemispheric lateralization for words and faces. E M Dundas, J. Exp. Psychol. Gen. 142Dundas, E.M. et al. (2013) The joint development of hemispheric lat- eralization for words and faces. J. Exp. Psychol. Gen. 142, 348-358</p>            </div>
        </div>

    </div>
</body>
</html>