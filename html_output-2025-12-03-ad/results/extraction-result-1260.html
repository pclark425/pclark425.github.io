<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1260 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1260</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1260</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-257378200</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2303.04077v1.pdf" target="_blank">Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation Using Scene Object Spectrum Grounding</a></p>
                <p><strong>Paper Abstract:</strong> The main challenge in vision-and-language navigation (VLN) is how to understand natural-language instructions in an unseen environment. The main limitation of conventional VLN algorithms is that if an action is mistaken, the agent fails to follow the instructions or explores unnecessary regions, leading the agent to an irrecoverable path. To tackle this problem, we propose Meta-Explore, a hierarchical navigation method deploying an exploitation policy to correct misled recent actions. We show that an exploitation policy, which moves the agent toward a well-chosen local goal among unvisited but observable states, outperforms a method which moves the agent to a previously visited state. We also highlight the demand for imagining regretful explorations with semantically meaningful clues. The key to our approach is understanding the object placements around the agent in spectral-domain. Specifically, we present a novel visual representation, called scene object spectrum (SOS), which performs category-wise 2D Fourier transform of detected objects. Combining exploitation policy and SOS features, the agent can correct its path by choosing a promising local goal. We evaluate our method in three VLN benchmarks: R2R, SOON, and REVERIE. Meta-Explore outperforms other baselines and shows significant generalization performance. In addition, local goal search using the proposed spectral-domain SOS features significantly improves the success rate by 17.1% and SPL by 20.6% for the SOON benchmark.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1260.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1260.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>R2R</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Room-to-Room (R2R)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A discrete, photorealistic indoor vision-and-language navigation benchmark where environments are represented as undirected graphs of panoramic viewpoint nodes; agents follow natural-language instructions to reach a goal point.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Room-to-Room (R2R)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Indoor household navigation dataset with panoramas as nodes and adjacency edges describing reachable view-to-view transitions; goal-directed VLN with natural-language route instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Undirected topological graph of panoramic nodes; connectivity is sparse and determined by viewpoint adjacency (edges correspond to reachable neighboring nodes). Adjacency encoded as matrix in the agent's map.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not specified in graph terms (nodes/edges); paper reports dataset episode counts and average ground-truth path length (average path length ~6 steps for R2R) but not node/edge counts.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Meta-Explore (hierarchical exploration + local goal search)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Hierarchical agent with a learned mode selector (explore vs exploit), exploration policy (cross-modal transformer + progress monitor trained with DAgger and A2C), exploitation via local goal search using a topological map and spectral Scene Object Spectrum (SOS) features; path planning to chosen local goal uses shortest-path planning (Dijkstra) on constructed graph.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Trajectory Length (TL), Success Rate (SR), Success weighted by inverse Path Length (SPL), Navigation Error (NE), Oracle Success Rate (OSR), and auxiliary normalized-distance-sum (nDS); paper also introduces a navigation score Snav to evaluate corrected trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Reported improvements: Meta-Explore test-unseen R2R: SR ≈ 71%, SPL ≈ 61% (as tabulated); paper states improvements over some baselines (e.g., increases in SR and SPL vs baselines by at least 16.4% and 8.9% in some comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Approximately 71% (R2R test unseen, as reported in the paper's table for Meta-Explore)</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Hierarchical, memory- and planning-based (topological map + local goal planning) with spectral semantic grounding (SOS) for exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Explicit: using a constructed topological map and searching for an unvisited but observable local goal (instead of naive backtracking) improves navigation success and SPL; the navigation score Snav computed from SOS features correlates with trajectory similarity to ground truth (linear relationship with nDS), indicating that semantic alignment in feature space (derived from observed nodes) predicts proximity to the global goal.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Policies that combine exploration with a map-based exploitation (local goal search + shortest-path planning) perform better than purely reactive or heuristic backtracking (homing); jump actions (teleporting to visited nodes) are unrealistic and can misrepresent true cost. Maintaining topological memory enables planning to unvisited reachable frontiers and reduces redundant revisits.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1260.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1260.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SOON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SOON (Scenario Oriented Object Navigation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Goal-oriented VLN benchmark where instructions describe target objects/locations; agent must navigate to a described location and find a target object, with relatively long instructions and object-focused language.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>SOON</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Indoor, goal-oriented object navigation dataset; instructions average ~47 words and emphasize object descriptions and surrounding context; discrete panoramic-view graph environment similar to other VLN benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Undirected topological graph of panoramic nodes, constructed on the fly by the agent; unvisited but observable nodes are those adjacent to any visited node.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not specified as nodes/edges in paper; dataset split sizes and average ground-truth path lengths (4–7 steps) are reported instead.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Meta-Explore (hierarchical exploration + SOS-guided local goal search)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same hierarchical architecture: cross-modal transformer encodings, mode selector deciding explore/exploit, exploration policy with progress monitor, exploitation selects local goal from unvisited observed nodes using SOS spectral features and navigation score Snav, then plans shortest path to that local goal.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SR, SPL, Oracle Success Rate (OSR), Trajectory Length (TL), FSPL (for object grounding), and navigation score Snav for candidate trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Reported improvements: On SOON test-unseen split, Meta-Explore local goal search using SOS yields +17.1% success rate and +20.6% SPL compared to the prior state-of-the-art (explicit numbers for absolute SR/SPL reported in paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Meta-Explore reported to outperform baselines in SOON test-unseen; absolute example in table: SR ≈ 39.1% and SPL ≈ 25.8% (test unseen) for Meta-Explore (as tabulated in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Hierarchical exploitation with semantic grounding: map-based planning to semantically scored local goals (SOS) is optimal for generalization in SOON.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Using topological map connectivity to expand candidate local goals (including unvisited but reachable nodes) improves escape from regretful local exploration; spectral SOS features give semantically meaningful signal that aligns corrected trajectories with language tokens, improving selection of local goals and thus SR and SPL.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Local goal search (planning to unvisited connected nodes) combined with SOS-based scoring outperforms homing/backtracking; spectral-domain features are particularly important for object-centric, goal-oriented instructions that require semantic matching.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1260.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1260.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>REVERIE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>REVERIE (Remote Embodied Visual Referring Expression)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A remote referring expression navigation benchmark: given an instruction referring to a remote object/location, the agent navigates to the described location and localizes the object bounding box among candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>REVERIE</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Indoor goal-oriented VLN dataset with instructions about remote objects and target locations; discrete panoramic-view graph environment where navigation and object localization are jointly evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Undirected topological graph of panoramic nodes; the agent builds a map of observed nodes and uses it for planning to local goals.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not specified as node/edge counts; paper reports average ground-truth trajectory length (∼9.5 steps) and dataset episode counts but not graph node counts.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Meta-Explore (hierarchical exploration + SOS)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Hierarchical agent using topological memory and SOS-driven local goal selection; also evaluates object grounding (FSR, FSPL) combining navigation and localization losses.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SR, SPL, FSR (finding success rate), FSPL (finding success weighted by inverse path length), OSR, TL.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Meta-Explore shows improvements in val unseen splits for navigation and grounding metrics, but improvements on test split are smaller due to noisy/misalabeled object categories in REVERIE dataset (paper quantifies dataset label noise). Exact numeric improvements vary; paper reports limited gains on test split.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Improves over baselines on val unseen according to paper; absolute values for splits are provided in tables but overall test-split improvement is limited.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Hierarchical map-based planning with spectral semantic grounding; object-token parsing + SOS alignment supports object grounding alongside navigation.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Topological map use for local goal search helps navigation and object grounding; however, dataset label noise (meaningless or inconsistent object categories) reduces effectiveness of object-based SOS matching and thus limits gains.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Map-based local goal planning remains more effective than naive homing; policies that rely on object-token parsing and SOS matching require consistent object category labels to fully exploit topology for grounding tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1260.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1260.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Habitat/Gibson (image-goal continuous)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Habitat simulator with Gibson scenes (image-goal navigation, continuous)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Continuous-action image-goal navigation task in photo-realistic indoor environments (Habitat simulator with Gibson scenes); agent receives panoramic RGBD and must navigate to a goal image/position under realistic actuation noise.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Habitat / Gibson (image-goal navigation)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Continuous indoor navigation simulator with dense photorealistic scenes; agent operates with discrete low-level continuous actions mapped to movement in metric space; topological graph is built from image-based waypoints during exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Image-based topological graph built online; connectivity depends on reachability and waypoint graph construction (sparse waypoint connectivity); Dijkstra used for path planning between nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td>Not specified as node/edge counts; evaluation uses 14 unseen scenes for testing and discretized episode difficulties (easy/medium/hard by geodesic distance).</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Meta-Explore (continuous variant)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Extended Meta-Explore for continuous environments: constructs image-based topological graph from panoramic RGBD, uses mode selector to detect stuck/regretful behavior, returns to a close visited node and searches for SOS-similar local goal among graph nodes, then navigates via shortest-path and a local low-level controller; exploration policy trained on seen scenes, exploit uses planning (not learned).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>Success Rate (SR), SPL, per-difficulty SR/SPL (easy/medium/hard), and improvements over baselines; also compares oracle and homing exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>Paper reports Meta-Explore improves overall SR by ~10.5% over VGM baseline; for easy episodes SR +9.3% and SPL +5.0%. For hard episodes, success is higher but SPL may be lower than some baselines (indicating more exploration).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Relative: +10.5% overall SR vs VGM (as reported); per-difficulty improvements noted (easy +9.3% SR). Absolute SR values vary by difficulty and are tabulated in the supplementary material.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Hierarchical map-based planning with SOS-guided local goal selection; returning-to-visited-nodes (homing) is less effective under noisy continuous actuation, so planning to unvisited reachable local goals is preferable.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Noisy actuation and continuous dynamics make pure homing/backtracking unreliable; constructing and using a topological graph for planning to semantically promising (SOS-similar) unvisited nodes leads to higher success, showing that topology-aware planning mitigates stuck/stochastic behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>In continuous, noisy settings, policies that rely on map-based re-planning to unvisited local goals outperform policies that attempt to reverse low-level action sequences; exploitation as planned travel on the graph is robust to actuation noise compared to naive reversal.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Self-monitoring navigation agent via auxiliary progress estimation <em>(Rating: 2)</em></li>
                <li>The Regretful Agent: Heuristic-aided Navigation through Progress Estimation <em>(Rating: 2)</em></li>
                <li>Tactical rewind: Self-correction via backtracking in vision-and-language navigation <em>(Rating: 2)</em></li>
                <li>Structured scene memory for vision-language navigation <em>(Rating: 2)</em></li>
                <li>Visual graph memory with unsupervised representation for visual navigation <em>(Rating: 2)</em></li>
                <li>Neural topological SLAM for visual navigation <em>(Rating: 2)</em></li>
                <li>Learning to explore using active neural SLAM <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1260",
    "paper_id": "paper-257378200",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "R2R",
            "name_full": "Room-to-Room (R2R)",
            "brief_description": "A discrete, photorealistic indoor vision-and-language navigation benchmark where environments are represented as undirected graphs of panoramic viewpoint nodes; agents follow natural-language instructions to reach a goal point.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "Room-to-Room (R2R)",
            "environment_description": "Indoor household navigation dataset with panoramas as nodes and adjacency edges describing reachable view-to-view transitions; goal-directed VLN with natural-language route instructions.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Undirected topological graph of panoramic nodes; connectivity is sparse and determined by viewpoint adjacency (edges correspond to reachable neighboring nodes). Adjacency encoded as matrix in the agent's map.",
            "environment_size": "Not specified in graph terms (nodes/edges); paper reports dataset episode counts and average ground-truth path length (average path length ~6 steps for R2R) but not node/edge counts.",
            "agent_name": "Meta-Explore (hierarchical exploration + local goal search)",
            "agent_description": "Hierarchical agent with a learned mode selector (explore vs exploit), exploration policy (cross-modal transformer + progress monitor trained with DAgger and A2C), exploitation via local goal search using a topological map and spectral Scene Object Spectrum (SOS) features; path planning to chosen local goal uses shortest-path planning (Dijkstra) on constructed graph.",
            "exploration_efficiency_metric": "Trajectory Length (TL), Success Rate (SR), Success weighted by inverse Path Length (SPL), Navigation Error (NE), Oracle Success Rate (OSR), and auxiliary normalized-distance-sum (nDS); paper also introduces a navigation score Snav to evaluate corrected trajectories.",
            "exploration_efficiency_value": "Reported improvements: Meta-Explore test-unseen R2R: SR ≈ 71%, SPL ≈ 61% (as tabulated); paper states improvements over some baselines (e.g., increases in SR and SPL vs baselines by at least 16.4% and 8.9% in some comparisons).",
            "success_rate": "Approximately 71% (R2R test unseen, as reported in the paper's table for Meta-Explore)",
            "optimal_policy_type": "Hierarchical, memory- and planning-based (topological map + local goal planning) with spectral semantic grounding (SOS) for exploitation.",
            "topology_performance_relationship": "Explicit: using a constructed topological map and searching for an unvisited but observable local goal (instead of naive backtracking) improves navigation success and SPL; the navigation score Snav computed from SOS features correlates with trajectory similarity to ground truth (linear relationship with nDS), indicating that semantic alignment in feature space (derived from observed nodes) predicts proximity to the global goal.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Policies that combine exploration with a map-based exploitation (local goal search + shortest-path planning) perform better than purely reactive or heuristic backtracking (homing); jump actions (teleporting to visited nodes) are unrealistic and can misrepresent true cost. Maintaining topological memory enables planning to unvisited reachable frontiers and reduces redundant revisits.",
            "uuid": "e1260.0"
        },
        {
            "name_short": "SOON",
            "name_full": "SOON (Scenario Oriented Object Navigation)",
            "brief_description": "Goal-oriented VLN benchmark where instructions describe target objects/locations; agent must navigate to a described location and find a target object, with relatively long instructions and object-focused language.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "SOON",
            "environment_description": "Indoor, goal-oriented object navigation dataset; instructions average ~47 words and emphasize object descriptions and surrounding context; discrete panoramic-view graph environment similar to other VLN benchmarks.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Undirected topological graph of panoramic nodes, constructed on the fly by the agent; unvisited but observable nodes are those adjacent to any visited node.",
            "environment_size": "Not specified as nodes/edges in paper; dataset split sizes and average ground-truth path lengths (4–7 steps) are reported instead.",
            "agent_name": "Meta-Explore (hierarchical exploration + SOS-guided local goal search)",
            "agent_description": "Same hierarchical architecture: cross-modal transformer encodings, mode selector deciding explore/exploit, exploration policy with progress monitor, exploitation selects local goal from unvisited observed nodes using SOS spectral features and navigation score Snav, then plans shortest path to that local goal.",
            "exploration_efficiency_metric": "SR, SPL, Oracle Success Rate (OSR), Trajectory Length (TL), FSPL (for object grounding), and navigation score Snav for candidate trajectories.",
            "exploration_efficiency_value": "Reported improvements: On SOON test-unseen split, Meta-Explore local goal search using SOS yields +17.1% success rate and +20.6% SPL compared to the prior state-of-the-art (explicit numbers for absolute SR/SPL reported in paper tables).",
            "success_rate": "Meta-Explore reported to outperform baselines in SOON test-unseen; absolute example in table: SR ≈ 39.1% and SPL ≈ 25.8% (test unseen) for Meta-Explore (as tabulated in paper).",
            "optimal_policy_type": "Hierarchical exploitation with semantic grounding: map-based planning to semantically scored local goals (SOS) is optimal for generalization in SOON.",
            "topology_performance_relationship": "Using topological map connectivity to expand candidate local goals (including unvisited but reachable nodes) improves escape from regretful local exploration; spectral SOS features give semantically meaningful signal that aligns corrected trajectories with language tokens, improving selection of local goals and thus SR and SPL.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Local goal search (planning to unvisited connected nodes) combined with SOS-based scoring outperforms homing/backtracking; spectral-domain features are particularly important for object-centric, goal-oriented instructions that require semantic matching.",
            "uuid": "e1260.1"
        },
        {
            "name_short": "REVERIE",
            "name_full": "REVERIE (Remote Embodied Visual Referring Expression)",
            "brief_description": "A remote referring expression navigation benchmark: given an instruction referring to a remote object/location, the agent navigates to the described location and localizes the object bounding box among candidates.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "REVERIE",
            "environment_description": "Indoor goal-oriented VLN dataset with instructions about remote objects and target locations; discrete panoramic-view graph environment where navigation and object localization are jointly evaluated.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Undirected topological graph of panoramic nodes; the agent builds a map of observed nodes and uses it for planning to local goals.",
            "environment_size": "Not specified as node/edge counts; paper reports average ground-truth trajectory length (∼9.5 steps) and dataset episode counts but not graph node counts.",
            "agent_name": "Meta-Explore (hierarchical exploration + SOS)",
            "agent_description": "Hierarchical agent using topological memory and SOS-driven local goal selection; also evaluates object grounding (FSR, FSPL) combining navigation and localization losses.",
            "exploration_efficiency_metric": "SR, SPL, FSR (finding success rate), FSPL (finding success weighted by inverse path length), OSR, TL.",
            "exploration_efficiency_value": "Meta-Explore shows improvements in val unseen splits for navigation and grounding metrics, but improvements on test split are smaller due to noisy/misalabeled object categories in REVERIE dataset (paper quantifies dataset label noise). Exact numeric improvements vary; paper reports limited gains on test split.",
            "success_rate": "Improves over baselines on val unseen according to paper; absolute values for splits are provided in tables but overall test-split improvement is limited.",
            "optimal_policy_type": "Hierarchical map-based planning with spectral semantic grounding; object-token parsing + SOS alignment supports object grounding alongside navigation.",
            "topology_performance_relationship": "Topological map use for local goal search helps navigation and object grounding; however, dataset label noise (meaningless or inconsistent object categories) reduces effectiveness of object-based SOS matching and thus limits gains.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "Map-based local goal planning remains more effective than naive homing; policies that rely on object-token parsing and SOS matching require consistent object category labels to fully exploit topology for grounding tasks.",
            "uuid": "e1260.2"
        },
        {
            "name_short": "Habitat/Gibson (image-goal continuous)",
            "name_full": "Habitat simulator with Gibson scenes (image-goal navigation, continuous)",
            "brief_description": "Continuous-action image-goal navigation task in photo-realistic indoor environments (Habitat simulator with Gibson scenes); agent receives panoramic RGBD and must navigate to a goal image/position under realistic actuation noise.",
            "citation_title": "",
            "mention_or_use": "use",
            "environment_name": "Habitat / Gibson (image-goal navigation)",
            "environment_description": "Continuous indoor navigation simulator with dense photorealistic scenes; agent operates with discrete low-level continuous actions mapped to movement in metric space; topological graph is built from image-based waypoints during exploration.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Image-based topological graph built online; connectivity depends on reachability and waypoint graph construction (sparse waypoint connectivity); Dijkstra used for path planning between nodes.",
            "environment_size": "Not specified as node/edge counts; evaluation uses 14 unseen scenes for testing and discretized episode difficulties (easy/medium/hard by geodesic distance).",
            "agent_name": "Meta-Explore (continuous variant)",
            "agent_description": "Extended Meta-Explore for continuous environments: constructs image-based topological graph from panoramic RGBD, uses mode selector to detect stuck/regretful behavior, returns to a close visited node and searches for SOS-similar local goal among graph nodes, then navigates via shortest-path and a local low-level controller; exploration policy trained on seen scenes, exploit uses planning (not learned).",
            "exploration_efficiency_metric": "Success Rate (SR), SPL, per-difficulty SR/SPL (easy/medium/hard), and improvements over baselines; also compares oracle and homing exploitation.",
            "exploration_efficiency_value": "Paper reports Meta-Explore improves overall SR by ~10.5% over VGM baseline; for easy episodes SR +9.3% and SPL +5.0%. For hard episodes, success is higher but SPL may be lower than some baselines (indicating more exploration).",
            "success_rate": "Relative: +10.5% overall SR vs VGM (as reported); per-difficulty improvements noted (easy +9.3% SR). Absolute SR values vary by difficulty and are tabulated in the supplementary material.",
            "optimal_policy_type": "Hierarchical map-based planning with SOS-guided local goal selection; returning-to-visited-nodes (homing) is less effective under noisy continuous actuation, so planning to unvisited reachable local goals is preferable.",
            "topology_performance_relationship": "Noisy actuation and continuous dynamics make pure homing/backtracking unreliable; constructing and using a topological graph for planning to semantically promising (SOS-similar) unvisited nodes leads to higher success, showing that topology-aware planning mitigates stuck/stochastic behavior.",
            "comparison_across_topologies": false,
            "topology_comparison_results": null,
            "policy_structure_findings": "In continuous, noisy settings, policies that rely on map-based re-planning to unvisited local goals outperform policies that attempt to reverse low-level action sequences; exploitation as planned travel on the graph is robust to actuation noise compared to naive reversal.",
            "uuid": "e1260.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Self-monitoring navigation agent via auxiliary progress estimation",
            "rating": 2,
            "sanitized_title": "selfmonitoring_navigation_agent_via_auxiliary_progress_estimation"
        },
        {
            "paper_title": "The Regretful Agent: Heuristic-aided Navigation through Progress Estimation",
            "rating": 2,
            "sanitized_title": "the_regretful_agent_heuristicaided_navigation_through_progress_estimation"
        },
        {
            "paper_title": "Tactical rewind: Self-correction via backtracking in vision-and-language navigation",
            "rating": 2,
            "sanitized_title": "tactical_rewind_selfcorrection_via_backtracking_in_visionandlanguage_navigation"
        },
        {
            "paper_title": "Structured scene memory for vision-language navigation",
            "rating": 2,
            "sanitized_title": "structured_scene_memory_for_visionlanguage_navigation"
        },
        {
            "paper_title": "Visual graph memory with unsupervised representation for visual navigation",
            "rating": 2,
            "sanitized_title": "visual_graph_memory_with_unsupervised_representation_for_visual_navigation"
        },
        {
            "paper_title": "Neural topological SLAM for visual navigation",
            "rating": 2,
            "sanitized_title": "neural_topological_slam_for_visual_navigation"
        },
        {
            "paper_title": "Learning to explore using active neural SLAM",
            "rating": 2,
            "sanitized_title": "learning_to_explore_using_active_neural_slam"
        }
    ],
    "cost": 0.01866275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation Using Scene Object Spectrum Grounding</p>
<p>Minyoung Hwang 
Electrical and Computer Engineering and ASRI
Seoul National University</p>
<p>Jaeyeon Jeong jaeyeon.jeong@rllab.snu.ac.kr 
Electrical and Computer Engineering and ASRI
Seoul National University</p>
<p>Minsoo Kim 
Interdisciplinary Major in Artificial Intelligence
Seoul National University</p>
<p>Yoonseon Oh 
Department of Electronic Engineering
Hanyang University</p>
<p>Songhwai Oh songhwai@snu.ac.kr 
Electrical and Computer Engineering and ASRI
Seoul National University</p>
<p>Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation Using Scene Object Spectrum Grounding</p>
<p>The main challenge in vision-and-language navigation (VLN) is how to understand natural-language instructions in an unseen environment. The main limitation of conventional VLN algorithms is that if an action is mistaken, the agent fails to follow the instructions or explores unnecessary regions, leading the agent to an irrecoverable path. To tackle this problem, we propose Meta-Explore, a hierarchical navigation method deploying an exploitation policy to correct misled recent actions. We show that an exploitation policy, which moves the agent toward a well-chosen local goal among unvisited but observable states, outperforms a method which moves the agent to a previously visited state. We also highlight the demand for imagining regretful explorations with semantically meaningful clues. The key to our approach is understanding the object placements around the agent in spectral-domain. Specifically, we present a novel visual representation, called scene object spectrum (SOS), which performs category-wise 2D Fourier transform of detected objects. Combining exploitation policy and SOS features, the agent can correct its path by choosing a promising local goal. We evaluate our method in three VLN benchmarks: R2R, SOON, and REVERIE. Meta-Explore outperforms other baselines and shows significant generalization performance. In addition, local goal search using the proposed spectral-domain SOS features significantly improves the success rate by 17.1% and SPL by 20.6% against the stateof-the-art method of the SOON benchmark. Project page: https://rllab-snu.github.io/projects/Meta-Explore/doc.html</p>
<p>Introduction</p>
<p>Visual navigation in indoor environments has been studied widely and shown that an agent can navigate in unex-   Figure 1. Hierarchical Exploration. At each episode, a naturallanguage instruction is given to the agent to navigate to a goal location. The agent explores the environment and constructs a topological map by recording visited nodes and next step reachable nodes . Each node consists of the position of the agent and visual features. ot denotes the observation at time t. The agent chooses an unvisited local goal to solve the regretful exploration problem. plored environments [1]. By recognizing the visual context and constructing a map, an agent can explore the environment and solve tasks such as moving towards a goal or following a desired trajectory. With the increasing development in human language understanding, vision-and-language navigation (VLN) [2] has enabled robots to communicate with humans using natural languages. The high degree of freedom in natural language instructions allows VLN to expand to various tasks, including (1) following fine-grained stepby-step instructions [2-13] and (2) reaching a target location described by goal-oriented language instructions [14][15][16][17][18][19][20].</p>
<p>A challenging issue in VLN is the case when an action is mistaken with respect to the given language instruction [21][22][23][24][25][26]. For instance, if the agent is asked to turn right at the end of the hallway but turns left, the agent may end up in irrecoverable paths. Several existing studies solve this issue via hierarchical exploration, where the high-level planner decides when to explore and the low-level planner chooses what actions to take. If the high-level planner chooses to explore, the agent searches unexplored regions, and if it chooses to exploit, the agent executes the best action based on the previous exploration. Prior work [21][22][23] returns the agent to the last successful state and resumes exploration. However, such methods take a heuristic approach because the agent only backtracks to a recently visited location. The agent does not take advantage of the constructed map and instead naively uses its recent trajectory for backtracking. Another recent work [26] suggests graph-based exploitation, which uses a topological map to expand the action space in global planning. Still, this method assumes that the agent can directly jump to a previously visited node. Since this method can perform a jump action at every timestep, there is no trigger that explicitly decides when to explore and when to exploit. Therefore, we address the importance of time scheduling for exploration-exploitation and efficient global planning using a topological map to avoid reexploring visited regions.</p>
<p>We expand the notion of hierarchical exploration by proposing Meta-Explore, which not only allows the highlevel planner to choose when to correct misled local movements but also finds an unvisited state inferred to be close to the global goal. We illustrate the overview of hierarchical exploration in Figure 1. Instead of backtracking, we present an exploitation method called local goal search. We show that it is more efficient to plan a path to a local goal, which is the most promising node from the unvisited but reachable nodes. We illustrate the difference between conventional backtracking and local goal search in Figure 2. Based on our method, we show that exploration and exploitation are not independent and can complement each other: (1) to overtake regretful explorations, the agent can perform exploitation and (2) the agent can utilize the constructed topological map for local goal search. We also highlight the demand for imagining regretful explorations with semantically meaningful clues. Most VLN tasks require a level of understanding objects nearby the agent, but previous studies simply encode observed panoramic or object images [2, 3, 16-18, 21 -35]. In this paper, we present a novel semantic representation of the scene called scene object spectrum (SOS), which is a matrix containing the arrangements and frequencies of objects from the visual observation at each location. Using SOS features, we can sufficiently estimate the context of the environment. We show that the proposed spectral-domain SOS features manifest better linguistic interpretability than conventional spatialdomain visual features. Combining exploitation policy and SOS features, we design a navigation score that measures the alignment between a given language instruction and a corrected trajectory toward a local goal. The agent compares local goal candidates and selects a near-optimal candidate with the highest navigation score from corrected trajectories. This involves high-level reasoning related to the landmarks (e.g., bedroom and kitchen) and objects (e.g., table and window) that appear in the instructions.</p>
<p>The main contributions of this paper are as follows:</p>
<p>• We propose a hierarchical navigation method called Meta-Explore, deploying an exploitation policy to cor-"Which visited node" "Which unvisited node"</p>
<p>"is the most likely to be a local goal?" rect misled recent actions. The agent searches for an appropriate local goal instead of reversing the recent action sequence. • In the exploitation mode, the agent uses a novel scene representation called scene object spectrum (SOS), which contains the spectral information of the object placements in the scene. SOS features provide semantically meaningful clues to choose a near-optimal local goal and help the agent to solve the regretful exploration problem. • </p>
<p>Related Work</p>
<p>Vision-and-Language Navigation</p>
<p>In VLN, an agent encodes the natural language instructions and follows the instructions, which can be either (1) a fine-grained step-by-step instruction the agent can follow [2-4], (2) a description of the target object and location [16, 17], or (3) additional guidance given to the agent [18,27]. These tasks require the agent to recognize its current location using some words in the natural-language instructions. Prior work [2, [28][29][30][31] show that an agent can align visual features to language instructions via neural networks and use the multimodal output embeddings to generate a suitable action at each timestep. Most VLN methods utilize cross-modal attention, either with recurrent neural networks [2,28] or with transformer-based architectures [29][30][31]. For sequential action prediction, Hong et al. [32] further use recurrent units inside transformer architectures, while Pashevich et al. [33] and Chen et al. [34] use additional transformers to embed past observations and actions.</p>
<p>Exploration-Exploitation</p>
<p>In an unseen environment, the agent must maximize the return without knowing the true value functions. One of the solutions to this problem is to switch back and forth between exploration and exploitation [36]. In the exploration mode, the agent gathers more information about the environment. On the other hand, the agent uses information collected during exploration and chooses the best action for exploitation. Ecoffet et al. [37] reduced the exploration step by archiving the states and exploring again from the successful states. Pislar et al. [38] addressed the various scheduling policies and demonstrated their method on Atari games. Recent work [39,40] successfully demonstrates the effectiveness of hierarchical exploration in image-goal navigation.</p>
<p>Like commonly used greedy navigation policies, VLN tasks also deal with the problem of maximizing the chance to reach the goal without knowing the ground truth map. Several VLN methods employ the concept of exploitation to tackle this problem. Ke et al. [35] look forward to several possible future trajectories and decide whether to backtrack or not and where to backtrack. Others [21-23] estimate the progress to tell whether the agent becomes lost and make the agent backtrack to a previously visited location to restart exploration. However, previous studies do not take into account what should be done in the exploitation mode. In order to handle this problem, we propose a hierarchical navigation method which determines the scheduling between exploration and exploitation.</p>
<p>Visual Representations</p>
<p>Popular visual encoding methods via ResNet [41] and ViT [42] can be trained to learn rotation-invariant visual features. Both methods learn to extract visual features with high information gain for global and local spatial information. The high complexity of the features leads to low interpretability of the scene and therefore requires the agent to use additional neural networks or complex processing to utilize them. On the other hand, traditional visual representation methods such as Fourier transform use spectral analysis, which is highly interpretable and computationally efficient. One drawback of the traditional methods is that they fail to maximize the information gain. Nonetheless, an appropriate use of essential information can be helpful for high-level decision making and enables more straightforward interpretation and prediction of the visual features. One traditional navigation method, Sturz et al. [43] used Fourier transform to generate rotation-invariant visual features. However, no research has transformed the spectral information of the detected objects to represent high-level semantics from visual observations. Focusing on the fact that 2D Fourier transform can extract morphological properties of images [44], we can find out the shape or structure of detected objects through 2D Fourier transform. In this paper, we decompose the object mask into binary masks by object categories and perform a 2D Fourier transform on each binary mask.</p>
<p>Method</p>
<p>Problem Formulation</p>
<p>We deal with VLN in discrete environments, where the environment is given as an undirected graph G e = {V, E}. V denotes a set of N navigable nodes,
{V i } N i=1
, and E is the adjacency matrix describing connectivity among the nodes in V . We denote the observation at node V i as O i . The agent uses a panoramic RGB image observation o t and current node v t , which are collected at time t. The agent either moves to a neighboring node or executes a stop action. a t denotes the action at time t. The objectives of VLN are categorized as follows: (1) to follow language instructions [2] and (2) to find a target object described by language instructions in a fixed time T [16, 17]. We present a general hierarchical exploration method that can be applied to both tasks. We also enhance the navigation policy by extracting cross-domain visual representations from the environments, i.e., spatial-domain and spectral-domain representations. To balance the information loss and interpretability of the visual feature, we adopt multi-channel fast Fourier transform (FFT) to encode semantic masks of the detected objects into category-wise spectral-domain features.</p>
<p>Meta-Explore</p>
<p>We design a learnable hierarchical exploration method for VLN called Meta-Explore, which decides (1) when to explore or exploit and (2) a new imagined local goal to seek during exploitation. The overall network architecture of the proposed Meta-Explore is shown in Figure 3. Given a language instruction L, the agent navigates in the environment until it finds the target described in L. Meta-Explore consists of a mode selector and two navigation modules corresponding to two modes: exploration and exploitation. At each timestep, the mode selector chooses to explore or exploit. At t = 0, the mode is initialized to exploration. In the exploration mode, the agent outputs an action toward a neighboring node to move the agent toward the goal. When the mode selector recognizes that the agent is not following the instruction successfully, the mode is switched to exploitation. In the exploitation mode, the agent seeks a new local goal with the highest correspondence against the language instructions from the previously unvisited candidate nodes using spectral-domain visual features. The agent moves toward the local goal by planning a path. After the agent arrives at the local goal, the mode is reset to exploration. The explore-exploit switching decision occurs through the mode selector by estimating the probability to explore. The agent repeats this explore-exploit behavior until it determines that the target is found and decides to stop.</p>
<p>Mode Selector</p>
<p>At time t, the agent observes visual features about the current node v t and several reachable nodes. We call the nodes reachable at the current timestep as candidate nodes. n cand "Lamp" "  Figure 3. Network Architecture. Three types of visual features: panoramic (yellow), object image (aquamarine), and object spectrum (red) are encoded. The color in each parenthesis denotes the color describing the corresponding feature. The cross-modal transformer encodes language and spatial visual features as hidden state Ht. A mode selector gives explore or exploit command to the agent by predicting the explore probability P explore . The selected navigation module outputs an action at from the possible n cand candidate nodes.</p>
<p>denotes the number of candidate nodes. We use a crossmodal transformer with n L layers to relate visual observations to language instructions. The cross-modal transformer takes the visual features of nodes in the constructed topological map at time t, G t , and outputs cross-modal embedding H t to encode visual observations with L. We concatenate location encoding and history encoding [24] to the visual features as node features to consider the relative pose from v t and the last visited timestep of each node, respectively. Each word is encoded via a pretrained language encoder [45], which is used for general vision-language tasks. The cross-modal transformer consists of cross-attention
layer L2V Attn(Ŵ ,V ) = Softmax(Ŵ Θ † q (V Θ † k ) T / √ d)V Θ † v and self-attention layer SelfAttn(X) = Softmax ((XΘ q (XΘ k ) T + AΘ e + b e )/ √ d)XΘ v ,
whereŴ ,V , X, and A denote word, visual, node representations and adjacency matrix of G t , respectively. The (query, key, value) weight matrices of self-attention and cross-attention layers are denoted as
(Θ q , Θ k , Θ v ) and (Θ † q , Θ † k , Θ † v ),
respectively. The final crossmodal embedding at time t after passing through n L transformer layers is denoted as H t . To encourage the monotonic increasing relationship between language and visual attentions at each timestep, we define a correlation loss L corr = T t=1 ||L2V Attn − I nx || 1 for training the crossmodal transformer, where n x denotes the dimension of the H t and I nx denotes an identity matrix of size n x × n x .</p>
<p>As illustrated in Figure 4, the mode selector estimates the probability to explore P explore given the cross-modal hidden state H t . We denote the mode selector as S mode and use a two-layer feed-forward neural network. Given H t , S mode outputs the exploration probability as P explore = 1 − S mode (H t ). If P explore ≥ 0.5, the exploration policy outputs a probability distribution for reachable nodes at the next step. At time t + 1, the agent moves to the node with the highest probability. If P explore &lt; 0.5, the agent determines that the current trajectory is regretful, so the agent should traverse to find a local goal, which is the most likely to be the closest node to the global goal. The exploitation policy mainly utilizes object-level features to search for the local goal with high-level reasoning. After the local goal is chosen, the path planning module outputs an action following the shortest path to the local goal.</p>
<p>To train the mode selector, we require additional demonstration data other than the ground truth trajectory, such that it switches between exploration and exploitation. We generate the demonstration data from the ground truth trajectories, with additional detours. For the detours, we stochastically select candidate nodes other than the ground truth paths and add the trajectory that returns to the current viewpoint. The imitation learning loss for training the mode selector is defined as L mode = T t=1 1(m t = gt t ), where m t is the mode of the agent, 0 for exploitation and 1 for exploration. gt t is 1 if the current node is in the shortest ground truth trajectory and gt t = 0, otherwise.</p>
<p>Exploration Module</p>
<p>In the exploration mode, the agent follows the following sequential operations: topological map construction, selfmonitoring, and an exploration policy. To improve the exploration, we adopt self-monitoring [21] to predict the current progress of exploration to enhance the exploration policy itself. Prior work [21,22] has shown that auxiliary loss using self-monitoring can regularize the exploration policy.</p>
<p>Topological Map Construction. The agent constructs graph G t by classifying nodes into two types: (1) visited nodes and (2) unvisited but observable nodes. At current </p>
<p>FFNN</p>
<p>Exploration Module</p>
<p>≥ . Figure 4. Navigation Modules. Mode selector estimates P explore , i.e., the probability to explore, and chooses between exploration and exploitation modules. The selected navigation module outputs the next action at.</p>
<p>time t, the agent at node v t ∈ {V i } N i=1 observes N (v t ) neighbor nodes as next step candidates at time t + 1. The visited nodes consist of visual features of their own and the neighboring nodes from panoramic RGB observations. The unvisited nodes can be observed only if they are connected to at least one visited node. The topological map records the positions and visual features of observed nodes at each timestep. By knowing the positions of nodes in G t , the agent can plan the shortest path trajectory between two nodes.</p>
<p>Self-Monitoring. We use a progress monitor to estimate the current navigation progress at each episode. Self-monitoring via estimating current progress helps the agent choose the next action that can increase the progress. The estimated progressp t = F progress (H t ) is the output of a feed-forward neural network, given H t as input. We measure the ground truth progress p t as the ratio between the current distance to the goal and the shortest path length of the episode subtracted from 1, described as 1 − dgeo(vt,v goal ) dgeo(v0,v goal ) , where d geo (a, b) is the geodesic distance between a and b. v 0 , v t , and v goal denote initial, current, and goal positions, respectively. We add progress loss L progress = T t=1 (p t − p t ) 2 to train the progress monitor while training the exploration policy.</p>
<p>Exploration Policy. The exploration policy F explore estimates the probability of moving to the candidate nodes at the next step. The agent chooses the action a t at time t based on the estimated probability distribution among candidate nodes, described as a t = arg max Vi (F explore ([H t ] i )). F explore is implemented via a two-layer feed-forward network with the cross-modal hidden state H t given as input. The output of F explore becomes a probability distribution over possible actions. To only consider unvisited nodes, we mask out the output for visited nodes. For training, we sample the next action from the probability distribution instead of choosing a node with the highest probability. We describe the training details in Section 3.3. </p>
<p>Exploitation Module</p>
<p>In the exploitation mode, the agent requires high-level reasoning with identifiable environmental clues to imagine regretful exploration cases. To find clues in an object-level manner, we present a novel visual representation by capturing object information in the spectral-domain. The novel representation is more easily predictable than spatial features such as RGB image embeddings. The agent can take advantage of the predictability by expanding the searchable area to find a local goal. We choose the local goal as the closest node to the global goal in the feature space.</p>
<p>Spectral-Domain Visual Representations. Common navigation policies can lead the agent toward the node with the highest similarity to the target. However, even with a good learned policy, the agent can act in a novice manner in unseen environments. In this paper, we seek extra information from the environment for generalizable high-level reasoning to resolve the issue. As illustrated in Figure 5, scene object spectrum (SOS) incorporates semantic information observed in a single panoramic image by generating a semantic mask for each object category and applying Fourier transform to each semantic mask. The semantic mask for object class k at time t is calculated as a binary mask [m k t ] ij that detects the object at pixel (i, j). Suppose there are a total of K object categories. When multiple objects are detected for one object category, the binary mask appears as a union of the bounding boxes of the detected objects. We define FFT as a channel-wise 2D fast Fourier transform that receives K binary semantic masks and outputs K spectraldomain features, where K is the number of object classes. Then, SOS feature S t = [s 1 t , ..., s K t ] T can be defined as
s k t = log |FFT(m k t )|.
For simplicity, we perform mean pooling on the vertical spectral axis and normalize the output. The final SOS feature has shape (K, η), where η is the maximum horizontal frequency. Local Goal Search Using Semantic Clues. We argue that returning to a previously visited node does not guarantee the agent escapes from the local optima. Instead of backtracking to a previously visited node, the agent searches for a local goal to move towards. If the agent plans a path and moves towards the local goal, the agent does not need to repeat unnecessary actions in visited regions after the exploitation ends. Additionally, searching for a local goal takes full advantage of the topological map by utilizing the connections among the observed nodes. To expand the searchable area further, we let the agent choose the local goal from previously unvisited and unchosen candidate nodes.</p>
<p>To choose a local goal, we first score the corrected trajectories to measure the alignment with the language instruction L. We use SOS features as semantic environmental clues to estimate the navigation score S nav of the corrected trajectory, which is the shortest path trajectory from the initial node to the local goal in the constructed topological map. To simplify, we convert the language instruction into a list of objects
W o = [w o 1 , ..., w o B ]
consisting of B[≤ K] object categories (e.g., desk, cabinet, and microwave). We approximate the corresponding reference SOS features as
[δ(w o 1 ), ...,δ(w o B )] where the i th row ofδ(w o k ) is defined as [δ(w o k )] i = 1(k = i)λ(δ(w o k )) sinc( j 2 − η 4 ). λ(δ(w o k )
) denotes the average width of detected bounding boxes of object w o k in the environment. A detailed approximation process is explained in the supplementary material. To simulate a corrected trajectory T = (v 1 , ..., v t ), we calculate the SOS features [ S 1 , ..., S t ] corresponding to the nodes in T . We measure the similarity between two object spectrum features via the cosine similarity of the flattened vectors. Finally, the navigation score S nav of T is computed as:
Snav(T ) = B i=1 t j=1 (δ (w o i ) |δ(w o i )| · S j | S j | )((δ(w o i ) −δ(w o )) · ( S j − S )) t B · B i=1 (δ(w o i ) −δ(w o )) 2 t j=1 ( S j − S ) 2 ,(1)
whereδ(w o ) and S denote the average values of SOS featuresδ(w o i ) and S j , respectively. This equation can also be interpreted as a pseudo correlation-coefficient function between object list W o and trajectory T . The exploitation policy selects the node with the highest navigation score as the local goal from the previously unvisited candidates. Figure 6 illustrates a simple scenario of entering a room. Suppose W o = [sculpture, door, bed] and the agent has to compare two trajectories
T 1 = (v 1 , v 2 , A) and T 1 = (v 1 , v 2 , B)
. Each similarity matrix in Figure 6 has the (t, j) element as the similarity between the SOS feature of V t and δ(w o j ), which is calculated asδ(w o j ) · S t . Notably, the similarity matrix shows monotonic alignment and the navigation score is higher when the next action is chosen correctly.</p>
<p>Training Details</p>
<p>We use [24] for pretraining the visual encoder with panoramic RGB observations. We use the DAgger algorithm [46] to pretrain the navigation policy and the mode selector. To prevent overfitting, we iteratively perform  teacher forcing and student forcing to choose the action from the exploration policy. Imitation learning loss is calculated as L IL = T t=1 − log p(a * t |a t ) and object grounding loss is calculated as L OG = − log p(obj * |obj pred ), where obj * denotes the ground truth and obj pred denotes the predicted object location. The total loss function is defined as L total = L mode + L progress + L corr + L IL + L OG .</p>
<p>We further finetune the agent via A2C [47]. The exploration policy selects the action a t with probability p a t . Reinforcement learning loss is defined as
L RL = − t a s t log(p a t )A t − λ t a * t log(p a t ).
To train the mode selector, progress monitor, and exploration policy in an endto-end manner, we use the total loss function as L f ine = L mode + L progress + L RL . The exploitation policy searches the path toward the local goal from the constructed navigation graph. Thus, the exploitation policy is not learned.</p>
<p>Navigation Experiments</p>
<p>Experiment Settings</p>
<p>We evaluate our method on three VLN benchmarks, Room-to-Room(R2R) [2], SOON [16], and REVERIE [17]. R2R evaluates the visually-grounded natural navigation performance of the agent. The agent must navigate to the predefined goal point given image observations and language instructions in an unseen environment. SOON is also a goal-oriented VLN benchmark. Natural language instructions in SOON have an average length of 47 words. The agent should locate the target location and detect the location of an object to find the target object. REVERIE is a goal-oriented VLN benchmark that provides natural language instruction about target locations and objects. In REVERIE, the agent is given an instruction referring to a remote object with an average length of 21 words. With this instruction and a panoramic observation from the environment, the agent should navigate to the location the instruction describes and find the correct object bounding box among the predefined object bounding boxes.</p>
<p>Evaluation Metrics</p>
<p>Navigation performance</p>
<p>We evaluate algorithms using the trajectory length (TL), success rate (SR), and success weighted by inverse path length (SPL) [48], and oracle success rate (OSR) for the navigation performance comparison. An episode is recorded as a success if the agent takes a stop action within 3 m of the target location. TL is the average path length in meters. SR is denoted as the number of successes divided by the total number of episodes, M . SPL is calculated as 1
M M i=1 S i li max(pi,li)
, where S i denotes the success as a binary value. p i and l i denote the shortest path and actual path lengths for the i th episode. OSR uses the oracle stop policy instead of the stop policy of the agent.</p>
<p>Object grounding performance</p>
<p>We also evaluate the object grounding performance of the agent by the success rate of finding the target object (FSR) and the target finding success weighted by inverse path length (FSPL) [16,17]. FSPL is calculated as
FSPL = 1 N N i=1 S nav i S loc i · l nav i /max(l nav i , l gt i ), where S nav i
is whether the agent navigates to the target, S loc i is whether the agent finds a target object bounding box, and l nav i and l gt i are the navigation trajectory length and ground truth trajectory length, respectively.</p>
<p>Baselines and Implementation Details</p>
<p>We compare our method with several other baselines as follows. For each task, we compare our method with a number of baselines that use various types of memory (recurrent, sequential, and topological map). For methods implemented with a hierarchical navigation framework, we compare the specific exploitation methods: homing, jump, and local goal search. Homing makes the agent backtrack, and jump makes the agent jump to a previously visited node. The hyperparameters and detailed model architecture of Meta-Explore are described in the supplementary material.</p>
<p>Comparison with Navigation Baselines</p>
<p>We compare our method with navigation baselines. We focus on the success rate and SPL. Rendered results and detailed analyses with other evaluation metrics are provided in the supplementary material. R2R. Table 1  rate and SPL by at least 16.4% and 8.9%, respectively. The main difference is that Meta-Explore constructs a topological map during exploration and uses the map for local goal search in exploitation. On the contrary, homing exploitation policies in SMNA, Regretful-Agent, and FAST only rely on the current trajectory, instead of taking advantage of the constructed memory. Jump exploitation in SSM uses a topological map to search a successful previous node, but it makes an unrealistic assumption that the agent can directly jump to a previously visited distant node and unfairly saves time. In our approach, we plan a path to the local goal based on the topological map. The experiment results reveal that even if we design a hierarchical navigation framework, exploration and exploitation are not entirely separate but they can complement each other. SOON, REVERIE. Table 2 compares Meta-Explore with baselines in the SOON navigation task. While the proposed method does not improve performance in val seen split, Meta-Explore outperforms other baselines in the test unseen split of SOON for success rate by 17.1% and SPL by 20.6%. The result implies that for the goal-oriented VLN task, high performance in train or val seen splits can be the overfitted result. Because the agent can be easily overfitted to the training data, making a generalizable model or providing a deterministic error-correction module for inference is essential. Meta-Explore chooses the latter approach by correcting the trajectory via exploitation in regretful cases. The evaluation results in the REVERIE navigation task are described in the supplementary material. Meta-Explore shows improvement in the val split of REVERIE for success rate and SPL, but the improvement in the test split is lower than the results in R2R and SOON. We found 252 meaningless object categories (e.g., verbs, adjectives, and prepositions) and 418 replaceable object categories (e.g., typographical errors and synonyms) in the REVERIE dataset. Because our exploitation method utilizes object-based parsing of the given instruction to match with the detected object categories, the effectiveness of the proposed method is lessened due to inaccuracies and inconsistencies in the dataset. We expect to have higher performance if the mistakes in the dataset are fixed.</p>
<p>Local Goal Search using SOS Features</p>
<p>To discuss the significance of modeling exploitation policy, we conduct specific experiments about choosing the local goal for R2R and SOON. We evaluate our method using different types of local goal search, as shown in Table 3 and 4. Oracle denotes a method which selects a local goal using the ground truth trajectory. The performance of the oracle provides the achievable performance for each dataset. The results imply that local goal search using either 10.7% and 41.2% of a total of 46,476 words in the bounding box dataset correspond to meaningless and replaceable object categories, respectively. spatial or spectral visual representations is more effective than random local goal search. The results show that local goal search using spectral visual representations, i.e., SOS features, lead the agent to desirable nodes the most. We also compare local goal search with homing and the difference between the performance of the two methods is most noticeable in the test split of the SOON navigation task. As shown in  </p>
<p>Methods</p>
<p>Memory</p>
<p>Ablation Study</p>
<p>We conduct an ablation study to compare the proposed method against language-triggered hierarchical exploration. Results in the supplementary material show that among the three representation domains, spatial, spectral, and language, the spectral-domain features enhance navigation performance the most. Additionally, to implicate further applications of Meta-Explore in continuous environments, we evaluate our method on the photo-realistic Habitat [50] simulator to solve image-goal navigation and vision-andlanguage navigation tasks. Implementation details and results are included in the supplementary material. Results show that our method outperforms baselines in both tasks.</p>
<p>Conclusion</p>
<p>We have proposed Meta-Explore, a hierarchical navigation method for VLN, by correcting mistaken short-term actions via efficient exploitation. In the exploitation mode, the agent is directed to a local goal which is inferred to be the closest to the target. A topological map constructed during exploration helps the agent to search and plan the shortest path toward the local goal. To further search beyond the frontier of the map, we present a novel visual representation called scene object spectrum (SOS), which compactly encodes the arrangements and frequencies of nearby objects. Meta-Explore achieves the highest generalization performance for test splits of R2R, SOON, and val split of REVERIE navigation tasks by showing less overfitting and high success rates. We plan to apply Meta-Explore for VLN tasks in continuous environments in our future work. Supplementary Material for "Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation Using Scene Object Spectrum Grounding"</p>
<p>We provide additional details and analyses of the proposed method in this supplementary material. Section A provides model details. Section B provides detailed settings and data preprocessing for experiments. Section C provides evaluation results with detailed analyses. Section D provides implementation details and detailed results for the ablation study.</p>
<p>A. Model Details</p>
<p>A.1. Algorithm Details</p>
<p>Algorithm 1 summarizes the overall hierarchical exploration process. The mode selector supervises the process and chooses whether the agent should explore or exploit at each time step.</p>
<p>A.2. Exploitation Module</p>
<p>A.2.1 Reference SOS Features.</p>
<p>In the proposed method, we approximate the reference SOS feature of an object token by using prior information about objects in the training data. For instance, for the 'chair' object, we collected the widths and heights of the detected bounding boxes as shown in Figure 7. Figure 8 shows two representative values: median and mean for each distribution. We choose the median values, which minimizes the L1 error, to represent the reference bounding box of each object. To generate rotation-invariant SOS features, we convert the four vertices of the bounding box detected from the front view image of size 640 × 480 to the vertices of a bounding box detected from the panoramic view image of size 2048 × 512 using coordinate transformations. To simplify the implementation, we assume that the converted bounding box has a rectangle shape with the vertices transformed into coordinates in a panoramic view. The reference SOS feature is calculated as the logarithmic magnitude of the Fourier transform of the panoramic mask with mean pooling on the vertical spectral axis. Considering that the shift in the spatial-domain only affects the phase of the Fourier transform, the location of a reference bounding box does not matter.</p>
<p>A.2.2 Navigation Score</p>
<p>To compare local goal candidates, we design a navigation score of a corrected trajectory τ as equation 2. This metric can also be interpreted as a weighted correlation coefficient among SOS features and object tokens weighted by the similarities between them.  Figure 7. Bounding box coordinate transformation. Front-view visual observations from different angles at the same location. Each bounding box shows the 'chair' detection. We use coordinate transformation to convert coordinates into panoramic view.</p>
<p>Algorithm 1: Meta-Explore
P explore ← 1 Success ← F alse Initialize G t and node features while t &lt; T do Update G t Update node features H t ← cross-modal embedding at time t if P explore ≥ 0.5 then a t ← arg max Vi (F explore ([H t ] i )) p t ← F progress (H t ) t ← t + 1 else V local ← unvisited but observed nodes in G t v local ← arg max v ∈V local (S nav (τ (v 0 , v ))) τ ← P athP lanning(v t , v local ) while not arrived at v local do a t ← pop(τ ) t ← t + 1 end end P explore ← 1 − S mode (H t ) if a t is stop and d(v t , v goal ) &lt; dSnav(T ) = B i=1 t j=1 (δ (w o i ) |δ(w o i )| · S j | S j | )((δ(w o i ) −δ(w o )) · ( S j − S )) t B · B i=1 (δ(w o i ) −δ(w o )) 2 t j=1 ( S j − S ) 2
(2) Dataset Instruction Object Tokens Target Object</p>
<p>R2R</p>
<p>"Walkthrough the kitchen. Go past the sink and stove stand in front of ["kitchen", "sink", "stove", "stand", "dish", "table", "chair"] "chair" thedining table on the bench side." SOON "Thisisa brand new white, rectangular wooden table, which is above a ["book", "chair", "pitcher", "flower", " table", "table"]  "table" fewchairs, under a pot of flowers. It is in a very neat study with many books." REVERIE "Gotothe bedroom with the fireplace and bring me the lowest hanging ["bedroom", "fireplace", "bed", "table", "stand", "art"] "art" smallpicture on the right wall across from the bedside table with the lamp on it" Table 5. Object Parsing Examples. For each dataset, object tokens are extracted from the instructions. Target objects are inferred from the instructions using VQA. Words that have similar meanings are unified into a single object word for categorization.  Figure 9. Relationship between navigation score (Snav) and normalized distance sum (nDS) in R2R. We measure navigation scores for augmented trajectories which include both successful and failed trajectories. R and Q illustrate an example case of a ground truth trajectory and a query trajectory. Maximum hop of a query trajectory is 15. Trajectories with high nDS scores also have high navigation scores. Figure 9 shows the relationship between the navigation score and an evaluation metric in the R2R navigation task. Both metrics measure how similar the current trajectory is to the ground truth trajectory. We generate 49,986 augmented trajectories with an average length of 8.23m based on 5596 ground truth trajectories. To generate various samples, we separate each augmented trajectory (v 1 , v 2 , ..., v t ) into t augmented trajectories (v 1 ), (v 1 , v 2 ), ..., and (v 1 , v 2 , ..., v t ). The final 421,383 augmented trajectories include trajectories with 1 to 15 nodes and include both successful and unsuccessful trajectories. We classify the trajectories with the normalized distance sum (nDS) between ground truth trajectory R and a query trajectory Q as follows:
nDS(R, Q) = exp − v i ∈R min u j ∈Q d(vi, uj ) + u j ∈Q min v i ∈R d(uj , vi) |R|+|Q| 2 dsuccess ,(3)
which requires the ground truth information of R. d(u, v) denotes the geodesic distance between two nodes, u and v, and d success denotes the success distance. The plot in Figure 9 shows a linear relationship between the nDS and the navigation score. The results imply that the proposed navigation score effectively scores the augmented trajectories even though it only relies on the given target instruction and observation from the augmented paths, without any location information about the nodes on the ground truth trajectory.</p>
<p>A.3. Implementation Details</p>
<p>We use ViT-B/16 [42] pretrained on ImageNet to extract features from the viewpoint panoramic images. We use pretrained LXMERT [45] for the language encoder and crossmodal transformer. We implement the mode selector as a two-layer feed-forward network. </p>
<p>B. Experiment Setup</p>
<p>B.2. Data Preprocessing</p>
<p>To calculate reference SOS features, we preprocess object tokens from language instructions. Using a pretrained visual question answering (VQA) model [51] with the question "What is the target object? Answer in one word.", we extract target objects from the instructions in R2R and REVERIE datasets. For SOON dataset, the target object names are already given. After extracting target objects, we perform object parsing for the instructions as shown in Table 5. The final object tokens are sorted by order of appearance in the instructions for R2R and REVERIE. For SOON, considering that the full instruction is divided into 5 parts: object name, object attribute, object relationship, target area, and neighbor areas, we sort the object tokens by reversed order of sentences.</p>
<p>B.3. Baselines</p>
<p>Seq2Seq [2] uses sequence-to-sequence action prediciton to generate actions from the agent trajectory. Speaker-Follower [28] uses the speaker model to augment natural language instructions and evaluate the candidate action sequence. FAST [35] uses both local and global signals to look forward the unobserved environment during exploration and backtrack to the originally visited nodes when needed. SMNA [21] uses visual-textual co-grounding module that encodes the past instructions and the instructions and actions to be done. SMNA also uses a progress monitor to estimate the current progress of the agent relative to the total instructions. Regretful-Agent [22] improves SMNA via two modules. The regret module decides whether to continue to explore or rollback to previous state by a learned policy, and the progress marker decides the direction the agent should head to by selecting visited nodes with progress estimates. RCM [49] applies reinforcement learning to enforce the global matching between the agent trajectory and the given natural language instruction. Via cycle-reconstruction reward, RCM allows the agent to comprehend the natural language instruction and penalize paths that do not match with the given instructions. FAST-MATTN [17] introduces a Navigator-Pointer model to both navigate to the target point and to localize the object from the navigation point according to the language guidance. AuxRN [23] introduces four auxiliary tasks that help learning the navigation policy: a trajectory retelling task, a progress estimation task, an angle prediction task, and cross-modal matching task, and improves navigation success by aligning representations in these unseen domains with seen domain. HAMT [34] uses transformer instead of a recurrent unit to predict actions from a long-range trajectory of observations and actions. Airbert [31] uses ViLBert [30] to measure the correlation between the language instructions and the viewpoint trajectories. VLN BERT [32] adds a recurrent unit in the transformer to predict the action from the trajectory. SIA [52] first pretrains the agent to learn the cross-modality between object grounding task and scene grounding task, and then generates real action sequences with memorybased attention. SSM [26] integrates information during exploration and constructs a scene memory and chooses the most probable node among visited nodes during backtracking. GBE [16] models the navigation state as a graph and explores the environment based on the navigation graph. DUET [24] uses two models, a local encoder and a global map planner, to fuse the local observations and coarse scale encoding for planning actions.</p>
<p>C. Navigation Experiments</p>
<p>In this section, we analyze the evaluation results of navigation experiments with different evaluation metrics. The results are provided in the paper.</p>
<p>C.1. Detailed Analyses in R2R</p>
<p>Navigation Error (NE). Navigation error (NE) is measured as the average distance between the final location of the agent and the target location of episode in meters. Because each episode is recorded as success if NE is less than 3m, NE is strongly related with the success rate. Meta-Explore shows the lowest NE in the val seen and test unseen splits of the R2R navigation task. The results imply that hierarchical exploration with local goal search helps the agent arrive to the target location closer than other baselines. Trajectory Length (TL). Among all the R2R navigation baselines, Seq2Seq shows the lowest TL. However, Seq2Seq shows low success rate and low SPL in all data splits. Compared to navigation baselines with SPL higher than 50% in the test split, VLN BERT, SMNA, and HAMT-e2e show lower TL than Meta-Explore. However, all three of these methods show a lower success rate, SPL, and NE than Meta-Explore. According to R2R [2], train episodes show a wide range of average trajectory length from 5m to 25m, while the test episodes have an average trajectory length of 9.93m. This implies that the agent is trained with longer trajectories than the test split trajectories, thereby the navigation policy might have learned to navigate longer paths better than shorter paths.</p>
<p>C.2. Detailed Analyses in SOON</p>
<p>Oracle Success Rate (OSR). In the SOON navigation task, Meta-Explore achieves the highest OSR in the test split while it does not improve the OSR in the val seen instruction and val seen house splits. The proposed method shows a significant generalization result compared to the baselines. AuxRN shows the highest OSR in both the val seen instruction split and the val seen house split as 78.5% and 97.8%, respectively, but shows the OSR in the test unseen split as 11.0%. On the other hand, Meta-Explore shows OSR as 96.0%, 52.7%, and 48.7% in the val seen instruction, val seen house, and test unseen splits, respectively. Meta-Explore outperforms AuxRN on OSR by 442.7% in the test</p>
<p>Methods</p>
<p>Memory</p>
<p>Exploit Val Seen  Val Unseen  Test Unseen  SR↑ SPL↑ OSR↑ TL↓  SR↑ SPL↑ FSR↑ FSPL↑ OSR↑ TL↓  SR↑ SPL↑ OSR↑ TL↓   Human  ------------ Table 6 compares Meta-Explore with the baselines in the REVERIE navigation task. While the proposed method does not improve performance in the val seen split, Meta-Explore outperforms other baselines in the val unseen on success rate, SPL, FSR, FSPL, and OSR. However, the improvement of performance is lower than the improvements shown in R2R and SOON benchmarks. We found 252 meaningless object categories (e.g., verbs, adjectives, and prepositions) and 418 replaceable object categories (e.g., typographical errors and synonyms) in the REVERIE dataset. 10.7% and 41.2% of a total of 46,476 words in the bounding box dataset correspond to meaningless and replaceable object categories, respectively. Because our exploitation method utilizes object-based parsing of the given instruction to match with the detected object categories, the effectiveness of the proposed method is lessened due to inaccuracies and inconsistencies in the dataset. We expect to have higher performance if the mistakes in the dataset are fully fixed. To provide evidence for this hypothesis, we evaluate Meta-Explore with a modified dataset, which is partially fixed. Typographical errors are fixed and words that have similar meanings are unified into a single object category. For instance, 'blackboard', 'whiteboard', and 'bulletin' are all unified into 'board'. The results are shown as the performance of Meta-Explore * in Table 6. The results imply that the proposed method can effectively enhance the SPL by classifying the detected objects correctly, using the modified dataset.</p>
<p>C.3. Evaluation Results in REVERIE benchmark</p>
<p>Comparison between exploitation policies in the REVERIE navigation task is shown in Table 7. Among the four exploitation methods: random, spatial, spectral local goal search and homing, spectral-domain local goal search shows the highest performance. The results in Table 7 </p>
<p>C.4. Local Goal Search</p>
<p>In this section, we provide sample local goal search scenarios. Figure 10 shows two scenarios of choosing the local goal when the agent moves to a wrong direction. The agent is given an instruction "Turn right and turn right again after the desk on the right. Wait next to the cabinets and microwave.". In both scenarios, we assume that the agent chooses the local goal as the node with the highest navigation score among the possible candidates. If the local goal is chosen from the previously visited nodes, the agent has to move back toward the explored regions. In contrast, if the local goal is chosen from unvisited but observered nodes, the agent can choose a local goal which is close to the global goal. The two scenarios imply that the local goal search in Meta-Explore is more effective than exploitation methods that return the agent to a previously visited node. </p>
<p>D. Ablation Study</p>
<p>D.1. Language-triggered Hierarchical Exploration</p>
<p>In the proposed method, the target instruction and local goal candidates are compared in spectral-domain using SOS features. Since semantic information can also be expressed in language-domain, we further experiment with the local goal search method using synthesized language captions from visual observations in the R2R navigation task. We compare three types of representation domains: spatial, spectral, and language, which are implemented as panoramic RGB image embeddings, SOS features, and sentence embeddings, respectively. To compare features in different domains, we transfer the source domain to another using augmentation or cross-domain similarity.</p>
<p>D.1.1 Implementation Details</p>
<p>We address that the agent can use image captioning to extract contextual information from visual observations such as room type, color, and object placements. To compare local goal candidates and target instruction in language domain, we use pretrained ViT [42] and GPT-2 [53] to generate the caption for each viewpoint as Figure 11. The Figure shows four successful cases and two failure cases of image captions. To find a local goal using the generated captions, we calculated the similarities between the captions corresponding to local goal candidates and the target instruction using a fine-tuned sentence transformer 'all-MiniLM-L6-v2' [54]. The local goal is chosen as the candidate with the highest similarity. Additionally, we use pretrained CLIP [55] to evaluate local goal search based on cross-modal similarities between the visual observations of local goal candidates and the target instruction.    Figure 12. Exploitation by searching a local goal. In the exploit mode, the agent aims to escape from the stranded local area. It first searches for the most similar node to the goal. Then, it finds an optimal local goal which is unexplored and also similar to the goal image. We use SOS features to compare with the target image.</p>
<p>D.1.2 Experiment Results</p>
<p>VLN, initially given as language. Lang. Aug. denotes language captions generated from images. Spectral Aug. denotes reference SOS features generated from language instructions. Among the three representation domains, the spectral-domain features enhance navigation performance the most. This implies that hierarchical exploration is most effective when used with spectral visual features. Table 1 and Table 2 in the paper also show the improvement of navigation performance by using both hierarchical exploration and spectral visual features over DUET [56], which uses the same ViT-B/16 to extract spatial visual features, resulting in 17.1% increase in SR and 20.6% increase in SPL in the SOON test unseen split.</p>
<p>D.2. Image-Goal Navigation in Continuous Domain</p>
<p>To implicate further applications of Meta-Explore in a continuous domain, we evaluate our method on the photo-realistic Habitat [50] simulator with continuous action space with realistic noises to solve an image-goal navigation task. The objective is to arrive at the target location of the given goal image in an unseen environment. We mainly focus on the effectiveness of hierarchical exploration using local goal search in this experiment. The results are shown in Table 9.</p>
<p>D.2.1 Exploration-Exploitation Selection</p>
<p>We extend Meta-Explore to continuous environments to address the impact of hierarchical exploration in realistic environments. The mode selector decides when to explore and exploit. In the exploration mode, the agent explores around a local area until the meta-controller decides to stop the exploration. The exploration module consists of graph con-struction module and navigation module. We use recurrent action policy that takes the current and target image features and outputs low-level actions for exploration. We illustrate that the explore-exploit switching decision occurs in stuck scenarios, such as entering a small place or getting stranded in a corner. Figure 12 shows the overview of exploitation in image-goal navigation by searching a local goal. When the control mode is changed to exploitation mode, the agent returns to the closest previously visited node. Then, the agent finds a local goal among the nodes in the constructed topological map and moves toward the local goal using dijkstra's algorithm [57]. The local goal is chosen as the node which has the most similar SOS feature with the SOS feature of the target image based on cosine similarity. The agent repeats this explore-exploit behavior until it finds the goal. This explore-exploit switching decision increases the navigation success rate.</p>
<p>D.2.2 Experiment Details</p>
<p>We evaluate Meta-Explore in the Gibson dataset [61] with Habitat [50] simulator to solve an image-goal navigation task. Habitat simulator allows the agent to navigate in photo-realistic indoor environments. The exploration policy of the agent is trained using 72 scenes. We evaluate Meta-Explore using 14 unseen scenes. We use panoramic RGBD observations and construct image-based graph memory. To construct a context frequency vector, we detect objects via Mask2Former [62] pretrained in ADE-20K dataset [63], to effectively detect the objects that are generally located in indoor scenes. We use a discrete action space, {stop, move forward, turn left, turn right} for navigation. With move forward action, an agent moves forward by 0.25 m, while turn left and turn right denotes a 10 • rotation, counter-clockwise and clockwise, respectively. The difficulty of each episode is determined by the geodesic distance between the initial and the goal location; easy: 1.5 m∼3 m, medium: 3 m∼5 m, and hard: 5 m∼10 m. The actuation noise model [39] is also applied to the agent in order to evaluate in realistic situations. We also demonstrated navigation experiments in the real world using a Jackal robot. The episodes are sampled from simulation point goal episodes with all difficulties; easy, medium and hard. We demonstrate both straight and curved trajectories to evaluate that our model is not task-specific. We used the model only trained in Habitat simulator with Gibson dataset. To collect panoramic RGBD observations, we use one panoramic RGB camera and four front-view RGBD cameras. In order to implement collision avoidance similar to the construction of navigable mesh in Habitat simulator, we implemented a collision avoidance module by clipping the action value based on the depth image observation.  Table 9. Evaluation results for Image-goal Navigation Task.</p>
<p>(SR: success rate, SPL: success weighted by path length)</p>
<p>D.2.3 Baselines</p>
<p>We compare our image-goal navigation policy with various baselines. Active Neural SLAM (ANS) constructs a top-down metric map and uses a hierarchical structure consisting of global and local policies. The global policy outputs long-term goals, which are used to generate short-term goals. The local policy uses a geometric path planner to navigate to a short-term goal. NTS [60] constructs a topological graph during exploration and plans subgoals with graph localization and planning, while navigating to the node with local point goal navigation policy. Neural Planner [59] constructs a graph using an estimated connectivity probability calculated from the neural network. VGM [58] uses unsupervised image-based graph memory representation to compare the similarity between goal image and the current observation image. We adapt VGM for graph construction and local navigation policy. PCL [64] encoder with ResNet18 [41] backbone network is used as the visual encoder for VGM [58].</p>
<p>D.2.4 Evaluation Metrics</p>
<p>We evaluate both success rate (SR) and success weighted by inverse path length (SPL) [48]. An episode is recorded as success if the agent takes a stop action within 1 m of the target location. SR is denoted as the number of successes divided by the total number of episodes, E. SPL is calculated as 1 E E i=1 S i li max(pi,li) . S i denotes the success as a binary value. p i and l i denote the shortest path and actual path length for the i th episode. For each task difficulty, SR and SPL are measured separately.</p>
<p>D.2.5 Experiment Results</p>
<p>Detailed comparisons with the baseline methods are shown in Table 9. The results show that the continuous version Meta-Explore and SOS features help navigation and the exploitation mode provides corrections for misled exploration or undesirable actions. Compared with the exploration policy baseline VGM [58], Meta-Explore shows an enhancement in the overall success rate by 10.5%. The results imply that local goal search helps the agent escape from the current location when the agent recurrently explores a local area but cannot find the target location. Exploitation can reduce unnecessary exploration and help the agent reach the target goal before the maximum time horizon. Among two methods of exploitation, local goal search outperforms homing, presumably because of the noisy actuation model used in the simulator. Due to the noisy actions, the agent can hardly return to a previously visited location by directly reversing the action sequence.</p>
<p>Comparing our method with other graph-based hierarchical navigation methods, Meta-Explore outperforms ANS, Neural Planner, and NTS in the success rate. Our model shows lower performance in SPL for hard episodes while the success rate is higher than the baselines. This implies that the exploitation mode of the proposed method allows the agent to explore more uncovered areas. Meanwhile, the proposed method appears to yield a positive impact for easy episodes, with the increase on both success rate by 9.3% and SPL by 5.0%. Specifically, our method outperforms ANS in terms of both success rate and SPL across all episodes. When compared to Neural Planner and NTS, our approach shows better performance in both success rate and SPL for easy and medium episodes, while outperforming Neural Planner and NTS in success rate for hard episodes. On the other hand, the proposed method shows lower SPL for hard episodes than NTS and Neural Planner. This implies that Meta-Explore tends to explore uncovered areas in both successful and unsuccessful episodes, which could be the result of using the SOS features to understand scenes. Comparing the proposed method using different exploitation methods (homing and local goal search) shows that searching for a local goal leads the agent to better escape from a local area. Figure 13 shows a simple scenario of image-goal navigation using Meta-Explore. The mode selector detects a regretful situation when the agent is recurrently exploring a local area but cannot find the target location. Hierarchical exploration via local goal search helps the agent overcome the situation and move toward the global goal in fixed time.</p>
<p>D.3. VLN in Continuous Domain</p>
<p>Image-goal navigation results in complex settings (continuous environments with noisy actions, max∼300 steps) imply that our model can be transferred to long-horizon t=23 t=76 t=90 t=120 t=230 explore exploit explore stuck global goal local goal agent visual node localized node Figure 13. Experiment visualization for image-goal navigation task in continuous environment. The mode selector detects stuck event at t = 76 and switches the explore mode to exploit mode. Then, the agent returns toward the local goal, which is chosen as a position nearby one of the nodes in the previously constructed graph.   [66], SASRA [67], and Conti-CMA † [65]. We evaluate algorithms using the success rate (SR), success weighted by inverse path length (SPL), oracle success rate (OSR), trajectory length (TL), and navigation error (NE), following the definitions of the evaluation metrics in the paper. Table 10 show that our method outperforms other baselines by at least 19.5% in the success rate, 8.6% in SPL, and 5.9% in OSR. We excluded the results of HCM for SR and SPL because HCM measures SR, SPL using oracle stop in the official code, which is not allowed in other baselines. We address that our model can be transferred to long-horizon (max. step 300) VLN with noisy actions in complex settings, as demonstrated by image-goal navigation results in Sec. D.2.</p>
<p>D.3.1 Experiment Results</p>
<p>Results in</p>
<p>This work was supported by Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-01190, [SW Star Lab] Robot Learning: Efficient, Safe, and Socially-Acceptable Machine Learning). This work was partly supported by Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government(MSIT) (No.2022-0-00907, Development of AI Bots Collaboration Platform and Self-organizingAI)(Corresponding authors: Yoonseon Oh and Songhwai Oh.)</p>
<p>forward, keeping the long table to the left. Exit the room via the white door to the left of the stairs. Descend a narrow circular stairwell and wait, facing two windows with circular stained glass in their centers."</p>
<p>Figure 2 .
2Local Goal Search for Exploitation. The local goal is likely to be chosen as the closest node to the global goal. Existing methods only backtrack to a visited node (left). We expand the searchable area by including unvisited but reachable nodes (right).</p>
<p>Figure 5 .
5Scene Object Spectrum (SOS). The agent calculates scene object spectrum (SOS) features for efficient exploitation. SOS features incorporate semantic information observed in a single panoramic image by performing category-wise 2D FFT.</p>
<p>Figure 6 .
6Toy Example. Monotonic alignment between language instruction and visual observation is desirable. Yellow dots in the nodes describe the ground truth trajectory. Based on the node at t = 3, the similarity matrix can show either monotonic or nonmonotonic alignment between object tokens and SOS features. The green circles describe the possible candidates A, B for next action.</p>
<p>Figure 8 .
8Bounding box statistics. We collect width, height, and size of detected bounding boxes. The histograms show statistics for 'chair' objects. Yellow line and red line show the median and average values of each distribution, respectively.nDS</p>
<p>The average length of instructions is 32 words. The average path length of the ground truth trajectory of each instruction is six steps. The number of train, val seen, val unseen, and test episodes are 14,025, 1020, 2349, and 4173. SOON. The average path length of the ground truth trajectory of each instruction is four to seven steps. The number of train, validation seen instruction, validation seen house, validation unseen house episodes are 3085, 245, 195, and 205. REVERIE. The average path length of the ground truth trajectory of each instruction is 9.5 steps. The number of train, val seen, val unseen, and test episodes are 10,466, 1423, 3521, and 6292.</p>
<p>Figure 10 .Figure 11 .
1011Local goal search scenarios in R2R. Ground truth trajectory (orange) and current trajectory at time t = 6 (blue) are shown in the left. Traj. denotes trajectory. The number next to each node denotes the navigation score Snav of the shortest path trajectory from the start node to the corresponding node. If the local goal is chosen from the previously visited nodes, the local goal becomes the node with Snav = 0.11. If the local goal is chosen from the unvisited but observed nodes, the local goal becomes the node with Snav = 0.22. Sample image captions. (a), (b), (c), and (d) show captions that successfully describe the scenes. (e) and (f) shows failure cases of caption generation. For successful language-triggered hierchical exploration, image captions should correctly describe the scenes. However, current image captioning methods often generates misdescribed captions, thereby leading to a low navigation performance.</p>
<p>We evaluate our method on three VLN benchmarks:R2R [2], SOON [16], and REVERIE [17]. The exper-
imental results show that the proposed method, Meta-
Explore, improves the success rate and SPL in test 
splits of R2R, SOON and val split of REVERIE. The 
proposed method shows better generalization results 
compared to all baselines. </p>
<p>Table " "
"Curtain" "Chair"Mode Selector </p>
<p>object 
spectrum </p>
<p>object image 
feature </p>
<p>or </p>
<p>Cross-
Attention </p>
<p>Self-
Attention </p>
<p>action </p>
<p>t </p>
<p>current node </p>
<p>next step 
reachable nodes </p>
<p>Exploitation Module </p>
<p>Exploration Module </p>
<p>object detection </p>
<p>candidate 1 candidate 2 
candidate </p>
<p>"Walk forward, keeping the long table to the left. Exit the room via the white door to the left of the stairs. 
Descend a narrow circular stairwell and wait, facing two windows with circular stained glass in their centers." </p>
<p>compares the proposed Meta-Explore with baselines for the R2R navigation task. We categorize the baseline methods based on the type of constructed memory and the type of exploitation. Our method outperforms other exploration-only baselines over all types of validation and test splits in success rate and SPL. Compared with hierarchical baselines SMNA [21], Regretful-Agent [22], FAST [35], and SSM [26], Meta-Explore improves success Identical with its original term, Remote Grounding Success (RGS). † indicates reproduced results.</p>
<p>Table 1. Comparison and evaluation results of the baselines and our model in the R2R Navigation Task.Table 2. Comparison and evaluation results of the baselines and our model in the SOON Navigation Task.Exploit 
Val Seen 
Val Unseen 
Test Unseen 
SR↑ SPL↑ 
TL↓ 
NE↓ SR↑ SPL↑ 
TL↓ 
NE↓ 
SR↑ SPL↑ 
TL↓ 
NE↓ 
Random 
-
-
16 
-
9.58 
9.45 
16 
-
9.77 
9.23 
13 
12 
9.89 
9.79 
Human 
-
-
-
-
-
-
-
-
-
-
11.85 1.61 
86 
76 
Seq2Seq [2] 
Rec </p>
<p>6.0 
39 
11.33 
-
22 
-
8.39 
7.84 
20 
18 
8.13 
7.85 
VLN BERT [32] 
Rec </p>
<p>72 
68 
11.13 
2.90 
63 
57 
12.01 
3.93 
63 
57 
12.35 
4.09 
SMNA  † [21] 
Rec 
homing 
69 
63 
11.69 
3.31 
47 
41 
12.61 
5.48 
61 
56 
-
4.48 
Regretful-Agent [22] 
Rec 
homing 
69 
63 
-
3.23 
50 
41 
-
5.32 
48 
40 
-
5.69 
FAST (short) [35] 
Rec 
homing 
-
-
-
-
56 
43 
21.17 
4.97 
54 
41 
22.08 
5.14 
FAST (long) [35] 
Rec 
homing 
70 
04 
188.06 3.13 
63 
02 
224.42 4.03 
61 
03 
196.53 4.29 
HAMT-e2e [34] 
Seq </p>
<p>76 
72 
11.15 
2.51 
66 
61 
11.46 
2.29 
65 
60 
12.27 
3.93 
DUET [24] 
Top. Map </p>
<p>79 
73 
12.32 
2.28 
72 
60 
13.94 
3.31 
69 
59 
14.73 
3.65 
SSM [26] 
Top. Map 
jump 
71 
62 
14.7 
3.10 
62 
45 
20.7 
4.32 
61 
46 
20.4 
4.57 
Meta-Explore (Ours) Top. Map local goal 
81 
75 
11.95 
2.11 
72 
62 
13.09 
3.22 
71 
61 
14.25 
3.57 </p>
<p>Gray shaded rows describe hierarchical navigation baselines. Three memory types: Rec(recurrent), Seq(sequential), and Top. Map(topological map) </p>
<p>Methods 
Memory 
Exploit 
Val Seen Instruction 
Val Seen House 
Test Unseen House 
SR↑ SPL↑ OSR↑ FSPL↑ SR↑ SPL↑ OSR↑ FSPL↑ SR↑ SPL↑ OSR↑ FSPL↑ 
Human 
-
-
-
-
-
-
-
-
-
-
90.4 59.2 
91.4 
51.1 
Random 
Rec </p>
<p>0.0 
1.5 
0.1 
1.4 
0.1 
0.0 
0.4 
0.9 
2.1 
0.4 
2.7 
0.0 
Speaker-Follower [28] 
Rec </p>
<p>97.9 
97.7 
97.8 
24.5 
61.2 60.4 
69.4 
9.1 
7.0 
6.1 
9.8 
0.6 
RCM [49] 
Rec </p>
<p>84.0 
82.6 
89.1 
10.9 
62.4 60.9 
72.7 
7.8 
7.4 
6.2 
12.4 
0.7 
AuxRN [23] 
Rec </p>
<p>98.4 
97.4 
98.7 
13.7 
68.8 67.3 
78.5 
8.3 
8.1 
6.7 
11.0 
0.5 
GBE w/o GE 
Top. Map </p>
<p>89.5 
88.3 
91.8 
24.2 
62.5 60.8 
73.0 
6.7 
11.4 
8.7 
18.8 
0.8 
GBE [16] 
Top. Map </p>
<p>98.4 
97.9 
98.6 
44.2 
76.3 62.5 
64.1 
7.3 
11.9 10.2 
19.5 
1.4 
GBE  † 
Top. Map </p>
<h2>-</h2>
<h2>-</h2>
<p>19.5 13.3 
28.5 
1.2 
12.9 
9.2 
21.5 
0.5 
DUET [24] 
Top. Map </p>
<p>94.0 
91.6 
90.0 
31.1 
36.3 22.6 
50.9 
3.8 
33.4 21.4 
43.0 
4.2 
Meta-Explore (Ours) Top. Map local goal 100.0 99.1 
96.0 
33.9 
44.7 34.8 
52.7 
8.9 
39.1 25.8 
48.7 
4.0 </p>
<p>Table 4 ,
4choosing the local goal with only spatial-domain 
features, the navigation performance does not improve com-
pared to homing. On the contrary, spectral-domain local 
goal search shows significant improvement against homing 
by 10.4% in success rate, 34.5% on SPL, and 27.4% on 
FSPL. The results imply that using spectral-domain SOS 
features helps high-level decision making, thereby enhanc-
ing the navigation performance. To further show the ef-
fectiveness of SOS features, we provide sample local goal 
search scenarios in the supplementary material. </p>
<p>Local 
Val Seen 
Val Unseen 
Goal 
SR↑ SPL↑ OSR↑ TL↓ NE↓ SR↑ SPL↑ OSR↑ TL↓ NE↓ 
Oracle 81.88 74.12 87.46 13.06 1.93 75.95 62.53 84.16 14.00 2.71 
Random 79.33 72.67 85.31 13.19 2.22 70.97 59.45 80.16 14.92 3.34 
Homing 80.22 73.63 85.60 12.51 2.14 71.65 60.60 80.33 13.91 3.26 
Spatial 79.63 73.14 85.60 12.99 2.22 71.56 60.01 80.33 14.90 3.27 
Spectral 80.61 75.15 85.80 11.95 2.11 71.78 61.68 80.76 13.09 3.22 </p>
<p>Table 3 .
3Comparison of Exploitation Policies. (R2R)Local 
Val Seen House 
Test Unseen House 
Goal 
SR↑ SPL↑ OSR↑ FSPL↑ SR↑ SPL↑ OSR↑ FSPL↑ 
Oracle 
54.42 37.96 63.72 
11.01 
48.38 28.45 62.98 
4.74 
Random 24.78 11.97 34.96 
3.08 
24.19 7.41 
35.84 
1.29 
Homing 42.04 27.72 48.23 
10.18 
35.40 19.18 51.62 
3.14 
Spatial 
32.30 11.60 39.38 
1.90 
26.11 10.58 39.23 
1.43 
Spectral 44.69 34.84 52.65 
8.89 
39.09 25.80 48.67 
4.01 </p>
<p>Table 4. Comparison of Exploitation Policies. (SOON) </p>
<p>[ 2 ]
2Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Eugene Ie, and Jason Baldridge. Stay on the path: Instruction fidelity in vision-and-language navigation. In Transactions of the Association for Computational Linguistics, pages 1862-1872, Florence, Italy, July 2019. Association for Computational Linguistics. 1Johnson, Niko Sünderhauf, Ian Reid, Stephen Gould, and An-
ton Van Den Hengel. Vision-and-language navigation: In-
terpreting visually-grounded navigation instructions in real 
environments. In Proceedings of the IEEE Conference on 
Computer Vision and Pattern Recognition, pages 3674-3683, 
2018. 1, 2, 3, 6, 8, 14, 15 </p>
<p>[3] Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, 
and Yoav Artzi. Touchdown: Natural language navigation and 
spatial reasoning in visual street environments. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and 
Pattern Recognition, pages 12538-12547, 2019. 1, 2 </p>
<p>[4] Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and 
Jason Baldridge. Room-Across-Room: Multilingual vision-
and-language navigation with dense spatiotemporal ground-
ing. In Conference on Empirical Methods for Natural Lan-
guage Processing, 2020. 1, 2 </p>
<p>[5] Vihan Jain, Gabriel Magalhaes, Alexander Ku, Ashish 
Vaswani, [6] An Yan, Xin Eric Wang, Jiangtao Feng, Lei Li, and 
William Yang Wang. Cross-lingual vision-language naviga-
tion. arXiv preprint arXiv:1910.11301, 2019. 1 </p>
<p>[7] Keji He, Yan Huang, Qi Wu, Jianhua Yang, Dong An, Shuan-
glin Sima, and Liang Wang. Landmark-rxr: Solving vision-
and-language navigation with fine-grained alignment supervi-
sion. In Proceedings of the International Conference on Neu-
ral Information Processing Systems, volume 34, pages 652-
663. Curran Associates, Inc., 2021. 1 </p>
<p>[8] Jacob Krantz, Erik Wijmans, Arjun Majundar, Dhruv Batra, 
and Stefan Lee. Beyond the nav-graph: Vision and language 
navigation in continuous environments. In Proceedings of the 
European Conference on Computer Vision, 2020. 1, 19 </p>
<p>[9] Piotr Mirowski, Andras Banki-Horvath, Keith Anderson, 
Denis Teplyashin, Karl Moritz Hermann, Mateusz Mali-
nowski, Matthew Koichi Grimes, Karen Simonyan, Koray 
Kavukcuoglu, Andrew Zisserman, et al. The streetlearn envi-
ronment and dataset. arXiv preprint arXiv:1903.01292, 2019. 
1 </p>
<p>[10] Karl Moritz Hermann, Mateusz Malinowski, Piotr Mirowski, 
Andras Banki-Horvath, Keith Anderson, and Raia Hadsell. 
Learning to follow directions in street view. In Proceedings 
of the AAAI Conference on Artificial Intelligence, volume 34, 
pages 11773-11781, Apr. 2020. 1 </p>
<p>[11] Arun Balajee Vasudevan, Dengxin Dai, and Luc Van Gool. 
Talk2nav: Long-range vision-and-language navigation with 
dual attention and spatial memory. In Proceedings of the </p>
<p>IEEE/CVF International Conference on Computer Vision, 
volume 129, pages 246-266. Springer, 2021. 1 </p>
<p>[12] Dipendra Misra, Andrew Bennett, Valts Blukis, Eyvind 
Niklasson, Max Shatkhin, and Yoav Artzi. Mapping instruc-
tions to actions in 3D environments with visual goal prediction. 
In Proceedings of the Conference on Empirical Methods for 
Natural Language Processing, pages 2667-2678, Brussels, 
Belgium, October-November 2018. Association for Compu-
tational Linguistics. 1 </p>
<p>[13] Ta-Chung Chi, Minmin Shen, Mihail Eric, Seokhwan Kim, 
andDilekHakkani-tur. Justask: Aninteractivelearningframe-
work for vision and language navigation. In Proceedings of the 
AAAI Conference on Artificial Intelligence, volume 34, pages 
2459-2466, 2020. 1 </p>
<p>[14] Yi Wu, Yuxin Wu, Georgia Gkioxari, and Yuandong Tian. 
Building generalizable agents with a realistic and rich 3d envi-
ronment. arXiv preprint arXiv:1801.02209, 2018. 1 </p>
<p>[15] Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, 
Devi Parikh, and Dhruv Batra. Embodied question answering. 
In Proceedings of the IEEE/CVF Conference on Computer 
Vision and Pattern Recognition, pages 1-10, 2018. 1 </p>
<p>[16] Fengda Zhu, Xiwen Liang, Yi Zhu, Qizhi Yu, Xiaojun Chang, 
and Xiaodan Liang. Soon: Scenario oriented object nav-
igation with graph-based exploration. In Proceedings of 
the IEEE/CVF Conference on Computer Vision and Pattern 
Recognition, pages 12689-12699, 2021. 1, 2, 3, 6, 7, 8, 14, 15 </p>
<p>[17] Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William Yang 
Wang, Chunhua Shen, and Anton van den Hengel. Reverie: 
Remote embodied visual referring expression in real indoor 
environments. In Proceedings of the IEEE/CVF Conference 
on Computer Vision and Pattern Recognition, pages 9982-
9991, 2020. 1, 2, 3, 6, 7, 14, 15 </p>
<p>[18] Khanh Nguyen and Hal Daumé III. Help, anna! visual nav-
igation with natural multimodal assistance via retrospective 
curiosity-encouraging imitation learning. In Proceedings of 
the Conference on Empirical Methods for Natural Language 
Processing, November 2019. 1, 2 </p>
<p>[19] Khanh Nguyen, Debadeepta Dey, Chris Brockett, and Bill 
Dolan. Vision-based navigation with language-based assis-
tance via imitation learning with indirect intervention. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision 
and Pattern Recognition, June 2019. 1 </p>
<p>[20] Alane Suhr, Claudia Yan, Jack Schluger, Stanley Yu, Hadi 
Khader, Marwa Mouallem, Iris Zhang, and Yoav Artzi. Ex-
ecuting instructions in situated collaborative interactions. In 
Proceedings of the Conference on Empirical Methods for 
Natural Language Processing, pages 2119-2130, 2019. 1 </p>
<p>[21] Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt 
Kira, Richard Socher, and Caiming Xiong. Self-monitoring 
navigation agent via auxiliary progress estimation. In Pro-
ceedings of the International Conference on Learning Rep-
resentations, 2019. 1, 2, 3, 4, 7, 8, 14, 15 </p>
<p>[22] Chih-Yao Ma, Zuxuan Wu, Ghassan AlRegib, Caiming Xiong, 
andZsoltKira. Theregretfulagent: Heuristic-aidednavigation </p>
<p>through progress estimation. In Proceedings of the IEEE/CVF 
Conference on Computer Vision and Pattern Recognition, 
pages 6732-6740, 2019. 1, 2, 3, 4, 7, 8, 14 </p>
<p>[23] Fengda Zhu, Yi Zhu, Xiaojun Chang, and Xiaodan Liang. 
Vision-language navigation with self-supervised auxiliary 
reasoning tasks. In Proceedings of the IEEE/CVF Conference 
on Computer Vision and Pattern Recognition, pages 10012-
10022, 2020. 1, 2, 3, 8, 14 </p>
<p>[24] Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, 
Cordelia Schmid, and Ivan Laptev. Think global, act local: 
Dual-scale graph transformer for vision-and-language naviga-
tion. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition, pages 16537-16547, 
2022. 1, 2, 4, 6, 8, 14, 15 </p>
<p>[25] Zhiwei Deng, Karthik Narasimhan, and Olga Russakovsky. 
Evolving graphical planner: Contextual global planning for 
vision-and-language navigation. In Proceedings of the Inter-
national Conference on Neural Information Processing Sys-
tems, volume 33, pages 20660-20672, 2020. 1, 2 </p>
<p>[26] Hanqing Wang, Wenguan Wang, Wei Liang, Caiming Xiong, 
and Jianbing Shen. Structured scene memory for vision-
language navigation. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition, pages 
8455-8464, June 2021. 1, 2, 7, 8, 14 </p>
<p>[27] Jesse Thomason, Michael Murray, Maya Cakmak, and Luke 
Zettlemoyer. Vision-and-dialog navigation. In Proceedings 
of the Conference on Robot Learning, pages 394-406, 2020. 
2 </p>
<p>success then Success ← T rue endViewindex 13 
Viewindex 15 
Viewindex 16 
Viewindex 14 </p>
<p>Front View Object Detection </p>
<p>Panoramic View Object Detection </p>
<p>Comparison and evaluation results of the baselines and our model in REVERIE Navigation Task.81.51 53.66 86.83 21.18 
Seq2Seq [2] 
Rec </p>
<p>29.59 24.01 35.70 12.88 4.20 
2.84 
2.16 
1.63 
8.07 
11.07 6.88 
3.99 
10.89 
3.09 
VLN BERT [32] 
Rec </p>
<p>51.79 47.96 53.90 13.44 30.67 24.90 18.77 
15.27 
35.02 16.78 29.61 23.99 32.91 15.86 
RCM[49] 
Rec </p>
<p>23.33 21.82 29.44 10.70 9.29 
6.97 
4.89 
3.89 
14.23 11.98 7.84 
6.67 
11.68 10.60 
SMNA[21] 
Rec 
homing 
41.25 39.61 43.29 
7.54 
8.15 
6.44 
4.54 
3.61 
11.28 
9.07 
5.80 
4.53 
8.39 
9.23 
FAST-MATTN[17] 
Rec. </p>
<p>50.53 45.50 55.17 16.35 14.40 7.19 
7.84 
4.67 
28.20 45.28 19.88 11.61 30.63 39.05 
HAMT[34] 
Seq </p>
<p>43.29 40.19 47.65 12.79 32.95 30.20 18.92 
17.28 
36.84 14.08 30.40 26.67 33.41 13.62 
SIA[52] 
Seq. </p>
<p>61.91 57.08 65.85 13.61 31.53 16.28 22.41 
11.56 
44.67 41.53 30.80 14.85 44.56 48.61 
Airbert[31] 
Seq. </p>
<p>47.01 42.34 48.98 15.16 27.89 21.88 18.23 
14.18 
34.51 18.71 30.28 23.61 34.20 17.91 
DUET[24] 
Top. Map </p>
<p>71.75 63.94 73.86 13.86 46.98 33.73 32.15 
23.03 
51.07 22.11 52.51 36.06 56.91 21.30 
Meta-Explore (Ours) 
Top. Map local goal 71.68 63.90 73.79 13.84 47.49 34.03 32.32 
23.30 
51.21 22.12 
-
-
-
-
Meta-Explore  *  (Ours) Top. Map local goal 71.89 65.71 73.44 13.03 47.66 40.27 32.15 
27.21 
50.55 18.48 51.18 44.04 
53.8 
10.23 </p>
<p>Table 6. Gray shaded rows describe hierarchical navigation baselines. Three memory types: Rec(recurrent), Seq(sequential), and Top. Map(topological map) </p>
<p>split. 
Object Grounding Performance (FSPL). Following [16], 
we measure the object grounding performance with the tar-
get finding success weighted by path length (FSPL). Al-
though Meta-Explore show the highest success rate and 
SPL in the val seen instruction and test splits, it does not 
improve FSPL over baseline methods. We expect to achieve 
better performance on FSPL if the agent uses the SOS fea-
tures as deterministic clues to find the target object at the 
end of each episode. </p>
<p>are consistent with the results in R2R and SOON.Local 
Val Seen 
Val Unseen 
Goal 
SR↑ SPL↑ FSR↑ OSR↑ TL↓ SR↑ SPL↑ FSR↑ OSR↑ TL↓ </p>
<p>Oracle 79.20 64.17 62.83 84.05 18.53 59.07 38.23 40.36 66.86 26.71 
Random 0.21 0.04 0.00 20.31 46.02 1.11 0.18 0.34 26.70 0.05 
Homing 68.45 50.54 55.24 73.23 17.95 43.60 28.25 29.59 49.28 25.64 
Spatial 67.53 40.21 54.25 70.91 26.92 40.90 23.25 27.61 45.84 26.92 
Spectral 71.68 63.90 57.34 73.79 13.84 47.49 34.03 32.32 51.21 22.12 </p>
<p>Table 7. Comparison of Exploitation Policies. (REVERIE) </p>
<p>Table 8
8shows the evaluation results of the local goal search methods using different target and candidate domains in R2R navigation task. Nav. Target denotes the target ofDomains </p>
<p>Val Seen 
Val Unseen 
Nav. Target 
Local Goal 
SR 
SPL 
SR 
SPL </p>
<p>Lang. </p>
<p>79.92 
72.79 
70.63 
59.81 
Lang. 
Spatial 
78.84 
71.96 
71.05 
58.86 
Lang. 
Lang. Aug. 
77.96 
70.77 
69.52 
57.26 
SpectralAug. 
Spectral 
80.61 
75.15 
71.78 
61.68 </p>
<p>Table 8 .
8Comparison and evaluation results of the local goal search methods using different target and candidate domains. (R2R)</p>
<p>Table 10 .
10Evaluation results in the VLN-CE val unseen split.VLN with noisy actions. We further extend the proposed method in continuous environments to solve the VLN-CE [8] task. In the VLN-CE [8] task, our agent constructs a topological map by using Conti-CMA[65] as a baseline to find reachable nodes (i.e., waypoints) and reuses the map in the exploitation mode. We compare our continuous version Meta-Explore with various navigation baselines: VLN-CE [8], HCM
† indicates reproduced results.</p>
<p>Deep learning for embodied vision navigation: A survey. Fengda Zhu, Yi Zhu, Vincent Lee, Xiaodan Liang, Xiaojun Chang, arXiv:2108.04097arXiv preprintFengda Zhu, Yi Zhu, Vincent Lee, Xiaodan Liang, and Xiao- jun Chang. Deep learning for embodied vision navigation: A survey. arXiv preprint arXiv:2108.04097, 2021. 1</p>
<p>Speaker-follower models for vision-and-language navigation. Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas, Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, Trevor Darrell, Proceedings of the International Conference on Neural Information Processing Systems. the International Conference on Neural Information Processing Systems814Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas, Louis-Philippe Morency, Taylor Berg- Kirkpatrick, Kate Saenko, Dan Klein, and Trevor Darrell. Speaker-follower models for vision-and-language navigation. In Proceedings of the International Conference on Neural In- formation Processing Systems, 2018. 2, 8, 14</p>
<p>Robust navigation with language pretraining and stochastic sampling. Xiujun Li, Chunyuan Li, Qiaolin Xia, Yonatan Bisk, Asli Celikyilmaz, Jianfeng Gao, A Noah, Yejin Smith, Choi, Proceedings of the Conference on Empirical Methods for Natural Language Processing. the Conference on Empirical Methods for Natural Language ProcessingXiujun Li, Chunyuan Li, Qiaolin Xia, Yonatan Bisk, Asli Ce- likyilmaz, Jianfeng Gao, Noah A Smith, and Yejin Choi. Ro- bust navigation with language pretraining and stochastic sam- pling. In Proceedings of the Conference on Empirical Meth- ods for Natural Language Processing, pages 1494-1499, 2019. 2</p>
<p>Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee, Proceedings of the International Conference on Neural Information Processing Systems. the International Conference on Neural Information Processing Systems214Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. Vil- bert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. In Proceedings of the Inter- national Conference on Neural Information Processing Sys- tems, 2019. 2, 14</p>
<p>Airbert: In-domain pretraining for vision-and-language navigation. Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev, Cordelia Schmid, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision15Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev, and Cordelia Schmid. Airbert: In-domain pretrain- ing for vision-and-language navigation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1634-1643, 2021. 2, 14, 15</p>
<p>Vln bert: A recurrent vision-andlanguage bert for navigation. Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, Stephen Gould, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition1415Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, and Stephen Gould. Vln bert: A recurrent vision-and- language bert for navigation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1643-1653, 2021. 2, 8, 14, 15</p>
<p>Episodic transformer for vision-and-language navigation. Alexander Pashevich, Cordelia Schmid, Chen Sun, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionAlexander Pashevich, Cordelia Schmid, and Chen Sun. Episodic transformer for vision-and-language navigation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 15942-15952, 2021. 2</p>
<p>History aware multimodal transformer for visionand-language navigation. Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, Ivan Laptev, Proceedings of the International Conference on Neural Information Processing Systems. the International Conference on Neural Information Processing Systems1415Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, and Ivan Laptev. History aware multimodal transformer for vision- and-language navigation. In Proceedings of the Interna- tional Conference on Neural Information Processing Sys- tems, pages 5834-5847, 2021. 2, 8, 14, 15</p>
<p>Tactical rewind: Self-correction via backtracking in vision-and-language navigation. Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi, Siddhartha Srinivasa, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition814Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi, and Siddhartha Srinivasa. Tactical rewind: Self-correction via backtrack- ing in vision-and-language navigation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6741-6749, 2019. 2, 3, 7, 8, 14</p>
<p>Exploration and exploitation in organizational learning. G James, March, Organization science. 21James G March. Exploration and exploitation in organiza- tional learning. Organization science, 2(1):71-87, 1991. 3</p>
<p>First return, then explore. Adrien Ecoffet, Joost Huizinga, Joel Lehman, O Kenneth, Jeff Stanley, Clune, Nature. 5907847Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O Stanley, and Jeff Clune. First return, then explore. Nature, 590(7847):580-586, 2021. 3</p>
<p>When should agents explore?. Miruna Pislar, David Szepesvari, Georg Ostrovski, Diana L Borsa, Tom Schaul, Proceedings of the International Conference on Learning Representations. the International Conference on Learning Representations2022Miruna Pislar, David Szepesvari, Georg Ostrovski, Diana L Borsa, and Tom Schaul. When should agents explore? In Pro- ceedings of the International Conference on Learning Rep- resentations, 2022. 3</p>
<p>Learning to explore using active neural slam. Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, Ruslan Salakhutdinov, Proceedings of the International Conference on Learning Representations. the International Conference on Learning Representations1718Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Ab- hinav Gupta, and Ruslan Salakhutdinov. Learning to explore using active neural slam. In Proceedings of the International Conference on Learning Representations, 2020. 3, 17, 18</p>
<p>No rl, no simulation: Learning to navigate without navigating. Meera Hahn, Devendra Singh Chaplot, Shubham Tulsiani, Mustafa Mukadam, M James, Abhinav Rehg, Gupta, Proceedings of the International Conference on Neural Information Processing Systems. the International Conference on Neural Information Processing SystemsCurran Associates, Inc343Meera Hahn, Devendra Singh Chaplot, Shubham Tulsiani, Mustafa Mukadam, James M Rehg, and Abhinav Gupta. No rl, no simulation: Learning to navigate without navigating. In Proceedings of the International Conference on Neural Information Processing Systems, volume 34, pages 26661- 26673. Curran Associates, Inc., 2021. 3</p>
<p>Deep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition318Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition, pages 770-778, 2016. 3, 18</p>
<p>Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Proceedings of the International Conference on Learning Representations. the International Conference on Learning Representations1316Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In Proceedings of the International Conference on Learning Representations, 2021. 3, 13, 16</p>
<p>Efficient visual homing based on fourier transformed panoramic images. Wolfgang Stürzl, A Hanspeter, Mallot, Robotics and Autonomous Systems. 544Wolfgang Stürzl and Hanspeter A Mallot. Efficient vi- sual homing based on fourier transformed panoramic images. Robotics and Autonomous Systems, 54(4):300-313, 2006. 3</p>
<p>. Jean Serra. Mathematical Morphology. 3Springer International PublishingJean Serra. Mathematical Morphology, pages 1-16. Springer International Publishing, Cham, 2020. 3</p>
<p>Lxmert: Learning cross-modality encoder representations from transformers. Hao Tan, Mohit Bansal, Proceedings of the Conference on Empirical Methods for Natural Language Processing. the Conference on Empirical Methods for Natural Language Processing413Hao Tan and Mohit Bansal. Lxmert: Learning cross-modality encoder representations from transformers. In Proceedings of the Conference on Empirical Methods for Natural Language Processing, pages 5100-5111, 2019. 4, 13</p>
<p>Noregret reductions for imitation learning and structured prediction. Stéphane Ross, Geoffrey J Gordon, J Andrew Bagnell, arXiv:1011.0686arXiv preprintStéphane Ross, Geoffrey J Gordon, and J Andrew Bagnell. No- regret reductions for imitation learning and structured predic- tion. arXiv preprint arXiv:1011.0686, 2010. 6</p>
<p>Asynchronous methods for deep reinforcement learning. Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu, Proceedings of the International Conference on Machine Learning. the International Conference on Machine LearningVolodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep rein- forcement learning. In Proceedings of the International Con- ference on Machine Learning, pages 1928-1937, 2016. 6</p>
<p>On evaluation of embodied navigation agents. Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, arXiv:1807.06757718arXiv preprintPeter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, et al. On evaluation of embodied navigation agents. arXiv preprint arXiv:1807.06757, 2018. 7, 18</p>
<p>Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation. Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, Lei Zhang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition1415Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, and Lei Zhang. Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation. In Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6629-6638, 2019. 8, 14, 15</p>
<p>Manolis Savva, and Dhruv Batra. Habitat 2.0: Training home assistants to rearrange their habitat. Andrew Szot, Alex Clegg, Eric Undersander, Erik Wijmans, Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam, Devendra Chaplot, Oleksandr Maksymets, Aaron Gokaslan, Vladimir Vondrus, Sameer Dharur, Franziska Meier, Wojciech Galuba, Angel Chang, Zsolt Kira, Vladlen Koltun, Jitendra Malik, Proceedings of the International Conference on Neural Information Processing Systems. the International Conference on Neural Information Processing Systems817Andrew Szot, Alex Clegg, Eric Undersander, Erik Wijmans, Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam, Devendra Chaplot, Oleksandr Maksymets, Aaron Gokaslan, Vladimir Vondrus, Sameer Dharur, Franziska Meier, Wojciech Galuba, Angel Chang, Zsolt Kira, Vladlen Koltun, Jitendra Malik, Manolis Savva, and Dhruv Batra. Habitat 2.0: Train- ing home assistants to rearrange their habitat. In Proceedings of the International Conference on Neural Information Pro- cessing Systems, 2021. 8, 17</p>
<p>Vqa: Visual question answering. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, Lawrence Zitnick, Devi Parikh, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision14Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. Vqa: Visual question answering. In Proceedings of the IEEE International Conference on Computer Vision, pages 2425- 2433, 2015. 14</p>
<p>Scene-intuitive agent for remote embodied visual grounding. Xiangru Lin, Guanbin Li, Yizhou Yu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition1415Xiangru Lin, Guanbin Li, and Yizhou Yu. Scene-intuitive agent for remote embodied visual grounding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition, pages 7036-7045, June 2021. 14, 15</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1816Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsuper- vised multitask learners. OpenAI blog, 1(8):9, 2019. 16</p>
<p>Sentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics16Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Lan- guage Processing. Association for Computational Linguis- tics, 11 2019. 16</p>
<p>Learning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Proceedings of the International Conference on Machine Learning. the International Conference on Machine Learning16Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In Proceedings of the International Conference on Machine Learning, pages 8748-8763, 2021. 16</p>
<p>Think global, act local: Dual-scale graph transformer for vision-and-language navigation. S Chen, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition17S. Chen et al. Think global, act local: Dual-scale graph trans- former for vision-and-language navigation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. 17</p>
<p>A note on two problems in connexion with graphs. W Edsger, Dijkstra, Numerische mathematik. 1117Edsger W Dijkstra. A note on two problems in connexion with graphs. Numerische mathematik, 1(1):269-271, 1959. 17</p>
<p>Visual graph memory with unsupervised representation for visual navigation. Obin Kwon, Nuri Kim, Yunho Choi, Hwiyeon Yoo, Jeongho Park, Songhwai Oh, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision18Obin Kwon, Nuri Kim, Yunho Choi, Hwiyeon Yoo, Jeongho Park, and Songhwai Oh. Visual graph memory with unsu- pervised representation for visual navigation. In Proceedings of the IEEE/CVF International Conference on Computer Vi- sion, pages 15890-15899, 2021. 18</p>
<p>Learning to plan with uncertain topological maps. Edward Beeching, Jilles Dibangoye, Olivier Simonin, Christian Wolf, Proceedings of the European Conference on Computer Vision. the European Conference on Computer VisionSpringer18Edward Beeching, Jilles Dibangoye, Olivier Simonin, and Christian Wolf. Learning to plan with uncertain topological maps. In Proceedings of the European Conference on Com- puter Vision, pages 473-490. Springer, 2020. 18</p>
<p>Neural topological slam for visual navigation. Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh Gupta, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition18Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, and Saurabh Gupta. Neural topological slam for vi- sual navigation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12875- 12884, 2020. 18</p>
<p>Gibson env: Real-world perception for embodied agents. Fei Xia, Zhiyang Amir R Zamir, Alexander He, Jitendra Sax, Silvio Malik, Savarese, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition17Fei Xia, Amir R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio Savarese. Gibson env: Real-world percep- tion for embodied agents. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9068-9079, 2018. 17</p>
<p>Masked-attention mask transformer for universal image segmentation. Bowen Cheng, Ishan Misra, Alexander G Schwing, Alexander Kirillov, Rohit Girdhar, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition17Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexan- der Kirillov, and Rohit Girdhar. Masked-attention mask trans- former for universal image segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. 17</p>
<p>Scene parsing through ade20k dataset. Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, Antonio Torralba, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition17Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Bar- riuso, and Antonio Torralba. Scene parsing through ade20k dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 633-641, 2017. 17</p>
<p>Prototypical contrastive learning of unsupervised representations. Junnan Li, Pan Zhou, Caiming Xiong, Steven Hoi, Proceedings of the International Conference on Learning Representations. the International Conference on Learning Representations18Junnan Li, Pan Zhou, Caiming Xiong, and Steven Hoi. Proto- typical contrastive learning of unsupervised representations. In Proceedings of the International Conference on Learning Representations, 2021. 18</p>
<p>Bridging the gap between learning in discrete and continuous environments for vision-and-language navigation. Zunwang Yiconghong, Qiwu , Stephen Gould, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition19YicongHong, ZunWang, QiWu, and Stephen Gould. Bridging the gap between learning in discrete and continuous environ- ments for vision-and-language navigation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022. 19</p>
<p>Hierarchical cross-modal agent for robotics vision-and-language navigation. Chih-Yao Muhammad Zubair Irshad, Zsolt Ma, Kira, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE19Muhammad Zubair Irshad, Chih-Yao Ma, and Zsolt Kira. Hi- erarchical cross-modal agent for robotics vision-and-language navigation. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pages 13238-13246. IEEE, 2021. 19</p>
<p>Semantically-aware spatio-temporal reasoning agent for vision-and-language navigation in continuous environments. Niluthpol Muhammad Zubair Irshad, Zachary Chowdhury Mithun, Han-Pang Seymour, Supun Chiu, Rakesh Samarasekera, Kumar, Proceedings of the International Conference on Pattern Recognition (ICPR). the International Conference on Pattern Recognition (ICPR)19Muhammad Zubair Irshad, Niluthpol Chowdhury Mithun, Zachary Seymour, Han-Pang Chiu, Supun Samarasekera, and Rakesh Kumar. Semantically-aware spatio-temporal reason- ing agent for vision-and-language navigation in continuous en- vironments. Proceedings of the International Conference on Pattern Recognition (ICPR), 2021. 19</p>            </div>
        </div>

    </div>
</body>
</html>