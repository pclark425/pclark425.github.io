<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8702 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8702</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8702</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-216386690</p>
                <p><strong>Paper Title:</strong> Brain Activation During Conceptual Processing of Action and Sound Verbs</p>
                <p><strong>Paper Abstract:</strong> Grounded cognition approaches to conceptual representations postulate a close link between conceptual knowledge and the sensorimotor brain systems. The present fMRI study tested, whether a feature-specific representation of concepts, as previously demonstrated for nouns, can also be found for action- and sound-related verbs. Participants were presented with action- and soundrelated verbs along with pseudoverbs while performing a lexical decision task. Sound-related verbs activated auditory areas in the temporal cortex, whereas action-related verbs activated brain regions in the superior frontal gyrus and the cerebellum, albeit only at a more liberal threshold. This differential brain activation during conceptual verb processing partially overlapped with or was adjacent to brain regions activated during the functional localizers probing sound perception or action execution. Activity in brain areas involved in the processing of action information was parametrically modulated by ratings of action relevance. Comparisons of action- and sound-related verbs with pseudoverbs revealed activation for both verb categories in auditory and motor areas. In contrast to proposals of strong grounded cognition approaches, our study did not demonstrate a considerable overlap of activations for action- and sound-related verbs and for the corresponding functional localizer tasks. However, in line with weaker variants of grounded cognition theories, the differential activation pattern for action- and sound-related verbs was near corresponding sensorimotor brain regions depending on conceptual feature relevance. Possibly, action-sound coupling resulted in a mutual activation of the motor and the auditory system for both action- and sound-related verbs, thereby reducing the effect sizes for the differential contrasts.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8702.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8702.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal (classical) semantic-hub</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amodal (classical) semantic hub / abstract symbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional-level account that conceptual knowledge is stored in an abstract, symbolic format independent of sensorimotor systems, often localized to a heteromodal 'semantic hub' (e.g., anterior temporal pole). Sensorimotor activations during conceptual tasks are treated as epiphenomenal (imagery, elaboration).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Amodal semantic-hub / abstract-symbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are encoded as abstract, amodal symbols (or compressed representations) in a semantic hub; original sensory/motor information is transformed into modality-independent representations used for language, reasoning and retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / hub-based / amodal</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Used as a contrasting framework in interpreting fMRI/ERP/TMS/lesion evidence; discussed with respect to semantic retrieval, lexical decision, and lesion-deficit patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper cites prior work supporting amodal hub proposals and frames them as an alternative to grounded accounts; in the present study, regions associated with heteromodal semantic retrieval (inferior frontal and inferior parietal cortex) were more active for real verbs than pseudoverbs, consistent with hub-mediated semantic access, but the study did not find a pure anterior temporal hub activation in the differential contrasts used.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted explicitly with grounded/embodied accounts; amodal hub predicts no necessary reactivation of modality-specific cortex for conceptual processing, whereas grounded accounts predict modality-specific reenactment; the paper's data favor a hybrid/weak-grounded view rather than a strict amodal-only view.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Multiple prior behavioral, lesion, and neuroimaging results (and some aspects of the present data, e.g., modality-specific activations to verbs vs pseudoverbs) challenge a purely amodal account; the present study's observation of modality-adjacent activation and parametric effects of feature relevance argue against a purely amodal-only functional format.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>The paper treats the amodal hub as a plausible complement to modality-specific representations: heteromodal hubs (e.g., inferior frontal/parietal regions and possibly anterior temporal lobe) likely integrate distributed modality-specific information rather than replace it.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8702.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Strong grounded cognition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Strong grounded cognition (strong embodied / sensorimotor identity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional claim that conceptual processing reuses the identical neural substrate as perception/action, including primary and secondary modality-specific cortex — conceptual meaning depends on reenactment of sensorimotor areas.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Strong grounded cognition (sensorimotor identity)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual representations consist of reenactments of distributed sensorimotor neural patterns; retrieving a concept entails the same functional activation patterns as actual perception or action in the corresponding modality.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / modality-embedded (strong embodiment)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Predictions tested with fMRI conjunctions/masking against sensorimotor localizers, ERP timing (rapid feature access), TMS and lesion paradigms.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The present fMRI study did NOT find considerable overlap between action- or sound-related verb activations and the corresponding functional localizers (only small overlaps or adjacent activations), which challenges the strong claim of full identity of substrates; some prior studies (cited) found primary/secondary modality cortex activation for nouns, but current data do not support full equivalence for verbs in an implicit lexical decision task.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Directly contrasted with amodal hub and weaker grounded/hybrid accounts; the paper's data disfavor the strong grounded view (full neural identity) but are compatible with weaker/hybrid grounded models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Lack of substantial anatomical overlap in this study (and only limited overlap in others) constitutes counter-evidence; task demands (implicit vs explicit), motor responses during task, and action-sound coupling may alter overlap and thus complicate straightforward support for strong embodiment.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>The paper concludes that strong grounded cognition — which requires identical functional substrates for conceptual and sensorimotor processing — is not supported by their data for action- and sound-related verbs in this implicit task.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8702.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Weak grounded / hierarchical hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Weak grounded cognition / hierarchical hybrid (modality-specific association + multimodal + heteromodal hub)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of functional models proposing that conceptual knowledge recruits a hierarchy of circuits: modality-specific association areas and adjacent higher-level multimodal cortices, plus heteromodal hubs that integrate information — but not full reuse of primary sensorimotor cortices in all conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Weak grounded cognition / hierarchical hybrid representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are represented across a hierarchy: modality-specific association regions contain feature information; higher-level multimodal association areas and heteromodal hubs integrate features into concept-level representations; activation during conceptual access may be near but not identical to primary sensorimotor activations and is task-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid / distributed-hierarchical / feature-integrative</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Evaluated via fMRI contrasts (feature-specific verbs vs pseudoverbs and vs each other), parametric modulation by subjective feature ratings, masking with modality localizers, ERP timing, and lesion/TMS studies in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The study's fMRI results are compatible with weak/hierarchical models: sound-related verbs activated auditory-association temporal cortex (partial overlap with acoustic localizer); action-related verbs activated premotor/superior frontal and cerebellar regions only at liberal thresholds and activations were near (but not identical to) motor localizer regions; parametric modulation by action-relevance ratings engaged precuneus and medial fusiform, consistent with graded hierarchical feature representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Favored by the present data over the strong grounded account; differs from purely amodal hub models by positing modality-linked feature representations but allows heteromodal hubs to contribute — the paper interprets its partial overlaps as support for this hybrid view.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Small effect sizes and overlap (often < 20 voxels) limit strength of claims; action-sound coupling and task constraints (implicit lexical decision, button-press motor response) likely reduce observable sensorimotor reactivation and can mask feature-specific activations; heteromodal hub (anterior temporal) activation was not robustly observed in differential contrasts.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors conclude that conceptual representations likely depend on a hierarchical system where modality-specific feature circuits and heteromodal integration hubs jointly contribute; task demands modulate the degree and locus of sensorimotor reactivation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8702.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Modality-specific feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modality-specific feature-based representation (sensory-motor feature encoding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional representation in which conceptual knowledge is composed of modality-linked features (e.g., action, sound, visual) that can be selectively accessed and recruit corresponding sensory or motor processing systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Modality-specific feature-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally structured as sets of perceptual and motor feature representations (sound, action, vision, taste, etc.); accessing a concept selectively reinstates or activates features relevant to that concept, with graded strength depending on feature relevance and task.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>feature-based / distributed</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Tested with lexical decision (this study), ERP feature-specific effects, masked priming, parametric modulation analyses correlating subjective feature ratings with brain activity, and lesion/TMS interference paradigms.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This study: sound-related verbs activated superior/middle temporal auditory-association areas; action-related verbs showed activation in superior frontal/presupplementary and cerebellum (at liberal thresholds); parametric modulation showed action-relevance ratings predicted activity in precuneus and medial fusiform; both verb categories > pseudoverbs activated auditory and motor areas (consistent with mixed feature content). Prior ERP and masked-priming results (cited) show rapid feature-specific effects (~180 ms) suggesting automatic access to modality features.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Provides mechanistic detail compared to amodal hub (which predicts no modality-specific reinstatement) and is compatible with weak grounded/hybrid hierarchies (which situate modality features in association areas rather than requiring primary cortex overlap).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Overlap between categories (action and sound) and action-sound coupling reduced differential effects; motor demands of the task (button press) may contaminate motor activations; feature ratings and distributions (e.g., dichotomous sound ratings) can limit parametric sensitivity; full primary-sensorimotor overlap predicted by strong embodiment was not consistently observed.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors view concept meaning as at least partly feature-based and modality-linked, with activation strength and anatomical locus shaped by feature relevance and task demands, supporting graded and distributed feature encoding rather than strictly amodal symbols.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8702.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed cell-assembly reenactment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed cell-assembly reenactment (Pulvermüller-style sensorimotor assemblies)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mechanistic functional proposal that conceptual access involves partial reactivation of distributed cell assemblies in sensorimotor networks that were engaged during experience with the referent, thereby constituting conceptual meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Distributed cell-assembly reenactment</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are constituted by distributed assemblies spanning sensory, motor and higher-order areas; conceptual retrieval reinstates (reenacts) portions of these assemblies in modality-specific and association cortices that participated in prior experience.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / neural-assembly / embodied</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Supported by rapid ERP feature-specific signatures, masked priming (unconscious activation), TMS/lesion interference, and fMRI localization relative to functional localizers.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper cites ERP and masked-priming studies showing early and automatic feature-specific activation consistent with quick reenactment of assemblies; present fMRI results show partial/nearby activations that could reflect reactivation of higher-level parts of cell assemblies (association cortices) rather than primary sensorimotor cortex.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>This mechanistic account underlies many grounded cognition explanations; the present data argue for partial reenactment in higher-level association zones (consistent with a weaker reenactment claim) and not for complete replay in primary cortices (arguing against the strongest form).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>fMRI conjunctions did not show large-scale identical activation with localizers; task and stimulus particulars (implicit lexical decision, action-sound coupling) and limitations of fMRI spatial resolution complicate demonstration of full assembly reenactment.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors interpret their partial overlaps and parametric effects as consistent with reenactment models that operate primarily via higher-level association components of distributed assemblies, complemented by heteromodal hubs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8702.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heteromodal semantic hub / retrieval network</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heteromodal semantic hub / semantic retrieval network (anterior temporal + inferior frontal/parietal components)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional architecture positing heteromodal regions (anterior temporal lobe and a semantic retrieval network including inferior frontal and inferior parietal cortex) that integrate distributed modality-specific features into coherent conceptual representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Heteromodal semantic hub / semantic retrieval network</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual knowledge is functionally supported by heteromodal integrative nodes that bind modality-specific feature information from distributed sensory/motor association areas and mediate controlled semantic retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hub-and-spokes / hybrid / integrative</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Inferred from contrasts of real words versus pseudowords (lexical decision), from fMRI meta-analyses, and from lesion findings; the present study used verb vs pseudoverb contrasts to probe hub recruitment.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>In this study, both action- and sound-related verbs (vs pseudoverbs) activated inferior frontal and inferior parietal regions, consistent with engagement of a semantic retrieval network; the anterior temporal hub was not robustly revealed in the differential contrasts here, possibly due to task design.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Serves as a complement to modality-specific representations (spokes): the hub integrates features rather than replacing modality-linked feature stores; the paper places heteromodal hubs alongside modality-specific/sensorimotor circuits as part of a hierarchical representation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Anterior temporal activation was not evident in the present differential contrasts (possibly a methodological issue), so the study cannot strongly confirm the ATL hub's role; the relative contribution of hub vs modality circuits depends on task demands and was not fully disentangled here.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>The authors argue that heteromodal hubs likely complement modality-specific circuits in conceptual representation and that semantic retrieval network regions (inferior frontal/parietal) are engaged during verb processing, supporting a hybrid, integrative functional architecture.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8702.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8702.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Task-related conceptual flexibility</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Task-related conceptual flexibility (context- and task-dependent recruitment)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional claim that the format and locus of conceptual activation depend on task demands: implicit tasks elicit weaker sensorimotor reactivation (higher-level association areas), while explicit semantic tasks elicit stronger modality-specific activation and imagery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Task-dependent conceptual activation / conceptual flexibility</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual representations are not retrieved in a fixed locus or format; task context (implicit lexical decision vs explicit semantic judgement) dynamically modulates whether lower-level modality-specific areas or higher-level integrative regions are engaged.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>processual / dynamic / context-dependent</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Supported by comparisons between implicit (lexical decision) and explicit semantic tasks, task-modulated motor activation studies, and by analyses here showing limited sensorimotor overlap during an implicit task.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper reports that the implicit lexical decision task produced weaker or more adjacent sensorimotor activation than might be observed with explicit semantic tasks; prior and cited TMS/behavioral work also indicates task-dependence of motor/language coupling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Explains variability in results that otherwise might support or contradict grounded or amodal views: strong embodiment predictions may hold in explicit tasks but not in implicit ones; hence task-flexibility mediates apparent support for different formats.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Task-related explanations do not by themselves specify the representational format; they demand experiments systematically varying task type to disambiguate whether lack of overlap is due to representational format or task-induced modulation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Authors suggest that weaker/hierarchical grounded models plus task-dependent recruitment best account for observed data: degree of modality-specific reactivation depends on the semantic demands of the task.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Grounded cognition. <em>(Rating: 2)</em></li>
                <li>Brain reflections of words and their meaning. <em>(Rating: 2)</em></li>
                <li>The neural and computational bases of semantic cognition. <em>(Rating: 2)</em></li>
                <li>Concept representation reflects multimodal abstraction: A framework for embodied semantics. <em>(Rating: 2)</em></li>
                <li>Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs. <em>(Rating: 2)</em></li>
                <li>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. <em>(Rating: 2)</em></li>
                <li>The sound of concepts: Four markers for a link between auditory and conceptual brain systems. <em>(Rating: 2)</em></li>
                <li>In defense of abstract conceptual representations. <em>(Rating: 1)</em></li>
                <li>Are the motor features of verb meanings represented in the precentral motor cortices? Yes, but within the context of a flexible, multilevel architecture for conceptual knowledge. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8702",
    "paper_id": "paper-216386690",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Amodal (classical) semantic-hub",
            "name_full": "Amodal (classical) semantic hub / abstract symbolic representation",
            "brief_description": "A functional-level account that conceptual knowledge is stored in an abstract, symbolic format independent of sensorimotor systems, often localized to a heteromodal 'semantic hub' (e.g., anterior temporal pole). Sensorimotor activations during conceptual tasks are treated as epiphenomenal (imagery, elaboration).",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Amodal semantic-hub / abstract-symbolic representation",
            "representational_format_description": "Concepts are encoded as abstract, amodal symbols (or compressed representations) in a semantic hub; original sensory/motor information is transformed into modality-independent representations used for language, reasoning and retrieval.",
            "format_type": "symbolic / hub-based / amodal",
            "cognitive_task_or_phenomenon": "Used as a contrasting framework in interpreting fMRI/ERP/TMS/lesion evidence; discussed with respect to semantic retrieval, lexical decision, and lesion-deficit patterns.",
            "key_findings": "The paper cites prior work supporting amodal hub proposals and frames them as an alternative to grounded accounts; in the present study, regions associated with heteromodal semantic retrieval (inferior frontal and inferior parietal cortex) were more active for real verbs than pseudoverbs, consistent with hub-mediated semantic access, but the study did not find a pure anterior temporal hub activation in the differential contrasts used.",
            "comparison_with_other_formats": "Contrasted explicitly with grounded/embodied accounts; amodal hub predicts no necessary reactivation of modality-specific cortex for conceptual processing, whereas grounded accounts predict modality-specific reenactment; the paper's data favor a hybrid/weak-grounded view rather than a strict amodal-only view.",
            "limitations_or_counter_evidence": "Multiple prior behavioral, lesion, and neuroimaging results (and some aspects of the present data, e.g., modality-specific activations to verbs vs pseudoverbs) challenge a purely amodal account; the present study's observation of modality-adjacent activation and parametric effects of feature relevance argue against a purely amodal-only functional format.",
            "theoretical_claims_or_implications": "The paper treats the amodal hub as a plausible complement to modality-specific representations: heteromodal hubs (e.g., inferior frontal/parietal regions and possibly anterior temporal lobe) likely integrate distributed modality-specific information rather than replace it.",
            "uuid": "e8702.0"
        },
        {
            "name_short": "Strong grounded cognition",
            "name_full": "Strong grounded cognition (strong embodied / sensorimotor identity)",
            "brief_description": "A functional claim that conceptual processing reuses the identical neural substrate as perception/action, including primary and secondary modality-specific cortex — conceptual meaning depends on reenactment of sensorimotor areas.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Strong grounded cognition (sensorimotor identity)",
            "representational_format_description": "Conceptual representations consist of reenactments of distributed sensorimotor neural patterns; retrieving a concept entails the same functional activation patterns as actual perception or action in the corresponding modality.",
            "format_type": "distributed / modality-embedded (strong embodiment)",
            "cognitive_task_or_phenomenon": "Predictions tested with fMRI conjunctions/masking against sensorimotor localizers, ERP timing (rapid feature access), TMS and lesion paradigms.",
            "key_findings": "The present fMRI study did NOT find considerable overlap between action- or sound-related verb activations and the corresponding functional localizers (only small overlaps or adjacent activations), which challenges the strong claim of full identity of substrates; some prior studies (cited) found primary/secondary modality cortex activation for nouns, but current data do not support full equivalence for verbs in an implicit lexical decision task.",
            "comparison_with_other_formats": "Directly contrasted with amodal hub and weaker grounded/hybrid accounts; the paper's data disfavor the strong grounded view (full neural identity) but are compatible with weaker/hybrid grounded models.",
            "limitations_or_counter_evidence": "Lack of substantial anatomical overlap in this study (and only limited overlap in others) constitutes counter-evidence; task demands (implicit vs explicit), motor responses during task, and action-sound coupling may alter overlap and thus complicate straightforward support for strong embodiment.",
            "theoretical_claims_or_implications": "The paper concludes that strong grounded cognition — which requires identical functional substrates for conceptual and sensorimotor processing — is not supported by their data for action- and sound-related verbs in this implicit task.",
            "uuid": "e8702.1"
        },
        {
            "name_short": "Weak grounded / hierarchical hybrid",
            "name_full": "Weak grounded cognition / hierarchical hybrid (modality-specific association + multimodal + heteromodal hub)",
            "brief_description": "A family of functional models proposing that conceptual knowledge recruits a hierarchy of circuits: modality-specific association areas and adjacent higher-level multimodal cortices, plus heteromodal hubs that integrate information — but not full reuse of primary sensorimotor cortices in all conditions.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Weak grounded cognition / hierarchical hybrid representation",
            "representational_format_description": "Concepts are represented across a hierarchy: modality-specific association regions contain feature information; higher-level multimodal association areas and heteromodal hubs integrate features into concept-level representations; activation during conceptual access may be near but not identical to primary sensorimotor activations and is task-dependent.",
            "format_type": "hybrid / distributed-hierarchical / feature-integrative",
            "cognitive_task_or_phenomenon": "Evaluated via fMRI contrasts (feature-specific verbs vs pseudoverbs and vs each other), parametric modulation by subjective feature ratings, masking with modality localizers, ERP timing, and lesion/TMS studies in the literature.",
            "key_findings": "The study's fMRI results are compatible with weak/hierarchical models: sound-related verbs activated auditory-association temporal cortex (partial overlap with acoustic localizer); action-related verbs activated premotor/superior frontal and cerebellar regions only at liberal thresholds and activations were near (but not identical to) motor localizer regions; parametric modulation by action-relevance ratings engaged precuneus and medial fusiform, consistent with graded hierarchical feature representations.",
            "comparison_with_other_formats": "Favored by the present data over the strong grounded account; differs from purely amodal hub models by positing modality-linked feature representations but allows heteromodal hubs to contribute — the paper interprets its partial overlaps as support for this hybrid view.",
            "limitations_or_counter_evidence": "Small effect sizes and overlap (often &lt; 20 voxels) limit strength of claims; action-sound coupling and task constraints (implicit lexical decision, button-press motor response) likely reduce observable sensorimotor reactivation and can mask feature-specific activations; heteromodal hub (anterior temporal) activation was not robustly observed in differential contrasts.",
            "theoretical_claims_or_implications": "Authors conclude that conceptual representations likely depend on a hierarchical system where modality-specific feature circuits and heteromodal integration hubs jointly contribute; task demands modulate the degree and locus of sensorimotor reactivation.",
            "uuid": "e8702.2"
        },
        {
            "name_short": "Modality-specific feature-based",
            "name_full": "Modality-specific feature-based representation (sensory-motor feature encoding)",
            "brief_description": "A functional representation in which conceptual knowledge is composed of modality-linked features (e.g., action, sound, visual) that can be selectively accessed and recruit corresponding sensory or motor processing systems.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Modality-specific feature-based representation",
            "representational_format_description": "Concepts are functionally structured as sets of perceptual and motor feature representations (sound, action, vision, taste, etc.); accessing a concept selectively reinstates or activates features relevant to that concept, with graded strength depending on feature relevance and task.",
            "format_type": "feature-based / distributed",
            "cognitive_task_or_phenomenon": "Tested with lexical decision (this study), ERP feature-specific effects, masked priming, parametric modulation analyses correlating subjective feature ratings with brain activity, and lesion/TMS interference paradigms.",
            "key_findings": "This study: sound-related verbs activated superior/middle temporal auditory-association areas; action-related verbs showed activation in superior frontal/presupplementary and cerebellum (at liberal thresholds); parametric modulation showed action-relevance ratings predicted activity in precuneus and medial fusiform; both verb categories &gt; pseudoverbs activated auditory and motor areas (consistent with mixed feature content). Prior ERP and masked-priming results (cited) show rapid feature-specific effects (~180 ms) suggesting automatic access to modality features.",
            "comparison_with_other_formats": "Provides mechanistic detail compared to amodal hub (which predicts no modality-specific reinstatement) and is compatible with weak grounded/hybrid hierarchies (which situate modality features in association areas rather than requiring primary cortex overlap).",
            "limitations_or_counter_evidence": "Overlap between categories (action and sound) and action-sound coupling reduced differential effects; motor demands of the task (button press) may contaminate motor activations; feature ratings and distributions (e.g., dichotomous sound ratings) can limit parametric sensitivity; full primary-sensorimotor overlap predicted by strong embodiment was not consistently observed.",
            "theoretical_claims_or_implications": "Authors view concept meaning as at least partly feature-based and modality-linked, with activation strength and anatomical locus shaped by feature relevance and task demands, supporting graded and distributed feature encoding rather than strictly amodal symbols.",
            "uuid": "e8702.3"
        },
        {
            "name_short": "Distributed cell-assembly reenactment",
            "name_full": "Distributed cell-assembly reenactment (Pulvermüller-style sensorimotor assemblies)",
            "brief_description": "A mechanistic functional proposal that conceptual access involves partial reactivation of distributed cell assemblies in sensorimotor networks that were engaged during experience with the referent, thereby constituting conceptual meaning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Distributed cell-assembly reenactment",
            "representational_format_description": "Concepts are constituted by distributed assemblies spanning sensory, motor and higher-order areas; conceptual retrieval reinstates (reenacts) portions of these assemblies in modality-specific and association cortices that participated in prior experience.",
            "format_type": "distributed / neural-assembly / embodied",
            "cognitive_task_or_phenomenon": "Supported by rapid ERP feature-specific signatures, masked priming (unconscious activation), TMS/lesion interference, and fMRI localization relative to functional localizers.",
            "key_findings": "The paper cites ERP and masked-priming studies showing early and automatic feature-specific activation consistent with quick reenactment of assemblies; present fMRI results show partial/nearby activations that could reflect reactivation of higher-level parts of cell assemblies (association cortices) rather than primary sensorimotor cortex.",
            "comparison_with_other_formats": "This mechanistic account underlies many grounded cognition explanations; the present data argue for partial reenactment in higher-level association zones (consistent with a weaker reenactment claim) and not for complete replay in primary cortices (arguing against the strongest form).",
            "limitations_or_counter_evidence": "fMRI conjunctions did not show large-scale identical activation with localizers; task and stimulus particulars (implicit lexical decision, action-sound coupling) and limitations of fMRI spatial resolution complicate demonstration of full assembly reenactment.",
            "theoretical_claims_or_implications": "Authors interpret their partial overlaps and parametric effects as consistent with reenactment models that operate primarily via higher-level association components of distributed assemblies, complemented by heteromodal hubs.",
            "uuid": "e8702.4"
        },
        {
            "name_short": "Heteromodal semantic hub / retrieval network",
            "name_full": "Heteromodal semantic hub / semantic retrieval network (anterior temporal + inferior frontal/parietal components)",
            "brief_description": "A functional architecture positing heteromodal regions (anterior temporal lobe and a semantic retrieval network including inferior frontal and inferior parietal cortex) that integrate distributed modality-specific features into coherent conceptual representations.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Heteromodal semantic hub / semantic retrieval network",
            "representational_format_description": "Conceptual knowledge is functionally supported by heteromodal integrative nodes that bind modality-specific feature information from distributed sensory/motor association areas and mediate controlled semantic retrieval.",
            "format_type": "hub-and-spokes / hybrid / integrative",
            "cognitive_task_or_phenomenon": "Inferred from contrasts of real words versus pseudowords (lexical decision), from fMRI meta-analyses, and from lesion findings; the present study used verb vs pseudoverb contrasts to probe hub recruitment.",
            "key_findings": "In this study, both action- and sound-related verbs (vs pseudoverbs) activated inferior frontal and inferior parietal regions, consistent with engagement of a semantic retrieval network; the anterior temporal hub was not robustly revealed in the differential contrasts here, possibly due to task design.",
            "comparison_with_other_formats": "Serves as a complement to modality-specific representations (spokes): the hub integrates features rather than replacing modality-linked feature stores; the paper places heteromodal hubs alongside modality-specific/sensorimotor circuits as part of a hierarchical representation.",
            "limitations_or_counter_evidence": "Anterior temporal activation was not evident in the present differential contrasts (possibly a methodological issue), so the study cannot strongly confirm the ATL hub's role; the relative contribution of hub vs modality circuits depends on task demands and was not fully disentangled here.",
            "theoretical_claims_or_implications": "The authors argue that heteromodal hubs likely complement modality-specific circuits in conceptual representation and that semantic retrieval network regions (inferior frontal/parietal) are engaged during verb processing, supporting a hybrid, integrative functional architecture.",
            "uuid": "e8702.5"
        },
        {
            "name_short": "Task-related conceptual flexibility",
            "name_full": "Task-related conceptual flexibility (context- and task-dependent recruitment)",
            "brief_description": "A functional claim that the format and locus of conceptual activation depend on task demands: implicit tasks elicit weaker sensorimotor reactivation (higher-level association areas), while explicit semantic tasks elicit stronger modality-specific activation and imagery.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Task-dependent conceptual activation / conceptual flexibility",
            "representational_format_description": "Conceptual representations are not retrieved in a fixed locus or format; task context (implicit lexical decision vs explicit semantic judgement) dynamically modulates whether lower-level modality-specific areas or higher-level integrative regions are engaged.",
            "format_type": "processual / dynamic / context-dependent",
            "cognitive_task_or_phenomenon": "Supported by comparisons between implicit (lexical decision) and explicit semantic tasks, task-modulated motor activation studies, and by analyses here showing limited sensorimotor overlap during an implicit task.",
            "key_findings": "The paper reports that the implicit lexical decision task produced weaker or more adjacent sensorimotor activation than might be observed with explicit semantic tasks; prior and cited TMS/behavioral work also indicates task-dependence of motor/language coupling.",
            "comparison_with_other_formats": "Explains variability in results that otherwise might support or contradict grounded or amodal views: strong embodiment predictions may hold in explicit tasks but not in implicit ones; hence task-flexibility mediates apparent support for different formats.",
            "limitations_or_counter_evidence": "Task-related explanations do not by themselves specify the representational format; they demand experiments systematically varying task type to disambiguate whether lack of overlap is due to representational format or task-induced modulation.",
            "theoretical_claims_or_implications": "Authors suggest that weaker/hierarchical grounded models plus task-dependent recruitment best account for observed data: degree of modality-specific reactivation depends on the semantic demands of the task.",
            "uuid": "e8702.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Grounded cognition.",
            "rating": 2,
            "sanitized_title": "grounded_cognition"
        },
        {
            "paper_title": "Brain reflections of words and their meaning.",
            "rating": 2,
            "sanitized_title": "brain_reflections_of_words_and_their_meaning"
        },
        {
            "paper_title": "The neural and computational bases of semantic cognition.",
            "rating": 2,
            "sanitized_title": "the_neural_and_computational_bases_of_semantic_cognition"
        },
        {
            "paper_title": "Concept representation reflects multimodal abstraction: A framework for embodied semantics.",
            "rating": 2,
            "sanitized_title": "concept_representation_reflects_multimodal_abstraction_a_framework_for_embodied_semantics"
        },
        {
            "paper_title": "Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs.",
            "rating": 2,
            "sanitized_title": "conceptual_grounding_of_language_in_action_and_perception_a_neurocomputational_model_of_the_emergence_of_category_specificity_and_semantic_hubs"
        },
        {
            "paper_title": "Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies.",
            "rating": 2,
            "sanitized_title": "where_is_the_semantic_system_a_critical_review_and_metaanalysis_of_120_functional_neuroimaging_studies"
        },
        {
            "paper_title": "The sound of concepts: Four markers for a link between auditory and conceptual brain systems.",
            "rating": 2,
            "sanitized_title": "the_sound_of_concepts_four_markers_for_a_link_between_auditory_and_conceptual_brain_systems"
        },
        {
            "paper_title": "In defense of abstract conceptual representations.",
            "rating": 1,
            "sanitized_title": "in_defense_of_abstract_conceptual_representations"
        },
        {
            "paper_title": "Are the motor features of verb meanings represented in the precentral motor cortices? Yes, but within the context of a flexible, multilevel architecture for conceptual knowledge.",
            "rating": 1,
            "sanitized_title": "are_the_motor_features_of_verb_meanings_represented_in_the_precentral_motor_cortices_yes_but_within_the_context_of_a_flexible_multilevel_architecture_for_conceptual_knowledge"
        }
    ],
    "cost": 0.01997525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Brain Activation During Conceptual Processing of Action and Sound Verbs</p>
<p>Margot Popp 
Department of Psychiatry
Ulm University
UlmGermany</p>
<p>Natalie M Trumpp 
Department of Psychiatry
Ulm University
UlmGermany</p>
<p>Eun-Jin Sim 
Department of Psychiatry
Ulm University
UlmGermany</p>
<p>Markus Kiefer markus.kiefer@uni-ulm.de 
Department of Psychiatry
Ulm University
UlmGermany</p>
<p>Markus Kiefer 
Department of Psychiatry, Section for Cognitive Electrophysiology
Ulm University
Leimgrubenweg 1289075UlmGermany</p>
<p>Brain Activation During Conceptual Processing of Action and Sound Verbs</p>
<p>ADVANCES IN COGNITIVE PSYCHOLOGY
10.5709/acp-0272-4RESEARCH ARTICLE http://www.ac-psych.org 2019 • volume 15(4) • 236-255 236 Corresponding author: ABSTRACT KEYWORDS
embodied cognition grounded cognition theory action-related concepts sound-related concepts language functional magnetic resonance imagingGrounded cognition approaches to conceptual representations postulate a close link between conceptual knowledge and the sensorimotor brain systems. The present fMRI study tested, whether a feature-specific representation of concepts, as previously demonstrated for nouns, can also be found for action-and sound-related verbs. Participants were presented with action-and soundrelated verbs along with pseudoverbs while performing a lexical decision task. Sound-related verbs activated auditory areas in the temporal cortex, whereas action-related verbs activated brain regions in the superior frontal gyrus and the cerebellum, albeit only at a more liberal threshold. This differential brain activation during conceptual verb processing partially overlapped with or was adjacent to brain regions activated during the functional localizers probing sound perception or action execution. Activity in brain areas involved in the processing of action information was parametrically modulated by ratings of action relevance. Comparisons of action-and sound-related verbs with pseudoverbs revealed activation for both verb categories in auditory and motor areas. In contrast to proposals of strong grounded cognition approaches, our study did not demonstrate a considerable overlap of activations for action-and sound-related verbs and for the corresponding functional localizer tasks. However, in line with weaker variants of grounded cognition theories, the differential activation pattern for action-and sound-related verbs was near corresponding sensorimotor brain regions depending on conceptual feature relevance. Possibly, action-sound coupling resulted in a mutual activation of the motor and the auditory system for both action-and sound-related verbs, thereby reducing the effect sizes for the differential contrasts.</p>
<p>Grounded cognition approaches to conceptual representations postulate a close link between conceptual knowledge and the sensorimotor brain systems. The present fMRI study tested, whether a feature-specific representation of concepts, as previously demonstrated for nouns, can also be found for action-and sound-related verbs. Participants were presented with action-and soundrelated verbs along with pseudoverbs while performing a lexical decision task. Sound-related verbs activated auditory areas in the temporal cortex, whereas action-related verbs activated brain regions in the superior frontal gyrus and the cerebellum, albeit only at a more liberal threshold. This differential brain activation during conceptual verb processing partially overlapped with or was adjacent to brain regions activated during the functional localizers probing sound perception or action execution. Activity in brain areas involved in the processing of action information was parametrically modulated by ratings of action relevance. Comparisons of action-and sound-related verbs with pseudoverbs revealed activation for both verb categories in auditory and motor areas. In contrast to proposals of strong grounded cognition approaches, our study did not demonstrate a considerable overlap of activations for action-and sound-related verbs and for the corresponding functional localizer tasks. However, in line with weaker variants of grounded cognition theories, the differential activation pattern for action-and sound-related verbs was near corresponding sensorimotor brain regions depending on conceptual feature relevance. Possibly, action-sound coupling resulted in a mutual activation of the motor and the auditory system for both action-and sound-related verbs, thereby reducing the effect sizes for the differential contrasts.</p>
<p>INTRODUCTION</p>
<p>Concepts are important mental building blocks that provide categorical factual knowledge for cognitive functions like language, action, and thought (Humphreys, Price, &amp; Riddoch, 1999;. It is generally accepted that concepts, which also constitute the meaning of words, are stored in semantic long-term memory (Tulving, 1972). Despite the general agreement concerning the characterization and function of concepts within semantic memory, their representational format is still a matter of controversial debate .</p>
<p>Classical amodal theories propose that conceptual knowledge is represented independent of the sensorimotor systems (Anderson, 1983;McClelland &amp; Rogers, 2003;Pylyshyn, 1980) in an amodal semantic hub, neuroanatomically located within the temporal pole (de Zubicaray, Wilson, McMahon, &amp; Muthiah, 2001;Lambon Ralph, Jefferies, Patterson, &amp; Rogers, 2017;Patterson, Nestor, &amp; Rogers, 2007;Visser, Jefferies, &amp; Lambon Ralph, 2010). The original sensory and motor conceptual information is transformed into an abstract and symbolic representation format. Activation in sensorimotor brain systems in conceptual tasks is seen as concomitant, reflecting semantic elabo-This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). http://www.ac-psych.org 2019 • volume 15(4) • 236-255 237 ration or imagery (Machery, 2007;Mahon, Anzellotti, Schwarzbach, Zampini, &amp; Caramazza, 2009).</p>
<p>Challenging this classical view, the grounded cognition framework proposes that access to conceptual knowledge depends on a reenactment of cell assemblies in sensory and motor brain networks, which were also active during former physical experiences with these objects (Barsalou, 2008;Pulvermüller &amp; Fadiga, 2010). Thus, activity in sensory and motor brain regions during conceptual processing is crucially involved in constituting conceptual meaning (De Grauwe, Willems, Rueschemeyer, Lemhofer, &amp; Schriefers, 2014;Hauk, Johnsrude, &amp; Pulvermüller, 2004). For example, conceptual processing of the word to throw activates sensory and motor brain areas that would also be activated during the execution of a throwing action. Grounded cognition theories vary depending on their explanations of the precise relationship between the sensorimotor systems and the conceptual system (for a review, see Meteyard, Cuadrado, Bahrami, &amp; Vigliocco, 2012): While strong grounded cognition accounts assume an identical neural substrate between conceptual and sensorimotor processing including primary and secondary modality-specific cortex (Gallese &amp; Lakoff, 2005;Pulvermüller, 2001), weaker variants of grounded cognition theories assume a hierarchy of neural circuits involving various levels of modality-specific (primary, secondary, or modality-specific association cortex), adjacent higherlevel multimodal cortices, as well as heteromodal semantic hub regions to be involved in the processing of conceptual information (Garagnani &amp; Pulvermüller, 2016;Kiefer, Sim, Herrnberger, Grothe, &amp; Hoenig, 2008;Pulvermüller, 2018;Simmons &amp; Barsalou, 2003). These latter weaker grounded cognition accounts do not claim an identical neural substrate and a functional equivalence of conceptual and sensorimotor processing and can be thus considered as hybrid theories.</p>
<p>Although several studies provided evidence for amodal theories (Lambon Ralph et al., 2017;Mahon et al., 2009;Peelen et al., 2013;Striem-Amit, Vannuscorps, &amp; Caramazza, 2017), a growing number of behavioral (Glenberg &amp; Kaschak, 2002;Rueschemeyer, Pfeiffer, &amp; Bekkering, 2010;Shebani &amp; Pulvermüller, 2013), neuroimaging (Hauk et al., 2004;James &amp; Gauthier, 2003;van Dam, van Dijk, Bekkering, &amp; Rueschemeyer, 2012), electrophysiological (Hoenig, Sim, Bochev, Herrnberger, &amp; Kiefer, 2008;Kiefer et al., 2008;Trumpp, Traub, &amp; Kiefer, 2013) and lesion studies (Dreyer et al., 2015;Trumpp, Kliese, Hoenig, Haarmaier, &amp; Kiefer 2013;Warrington &amp; McCarthy, 1987) support the assumption of a modality-specific representation of conceptual knowledge in line with the grounded cognition framework.</p>
<p>Previous neuroimaging studies on object-related nouns showed that visual-related words such as bulldozer activate visual brain regions (Chao &amp; Martin, 1999), sound-related words like telephone activate auditory brain areas , action-related nouns like hammer activate motor and motion-related brain areas (Chao &amp; Martin, 2000;, and odor-or taste-related words (cinnamon or salt) activate olfactory or gustatory brain regions (Barros-Loscertales et al., 2012;Damasio, Grabowski, Tranel, Hichwa, &amp; Damasio, 1996;Gonzalez et al., 2006). Although some studies found activity in primary or secondary modality-specific cortex in accord-ance with strong grounded cognition theories (Hauk et al., 2004), other studies observed activity in modality-specific association areas  or putatively multimodal areas (Fernandino et al., 2016).</p>
<p>In electrophysiological experiments, feature-specific event-related potential (ERP) patterns were evoked by action-and sound-related nouns Pulvermüller, Lutzenberger, &amp; Preissl, 1999;Trumpp, Traub et al., 2013;Trumpp, Traub, Pulvermüller, &amp; Kiefer, 2014). Modality-specific ERP differences were detected starting 200 ms from stimulus onset, indicating a rapid processing of conceptual features and render it unlikely that effects are attributable to imagery . Masked feature priming and repetition priming experiments (Trumpp, Traub et al., 2013;Trumpp et al., 2014), in which the critical prime words could not be consciously identified, revealed a corresponding modulation of feature-specific ERP patterns for sound-and action-related nouns. This suggests that access to conceptual information automatically activates auditory and motor areas.</p>
<p>Source analyses of ERP effects of action-related nouns revealed source activity in frontal and parietal brain areas, whereas sources of soundrelated noun ERPs were referred to temporal brain regions (Trumpp, Traub et al., 2013;Trumpp et al., 2014). The causal relation between the sensorimotor systems and conceptual representations has been demonstrated by several lesion studies (Bak et al., 2006;Humphreys &amp; Forde, 2001;Neininger &amp; Pulvermüller, 2003;Trumpp, Kliese et al., 2013;Warrington &amp; Shallice, 1984) or studies using transcranial magnetic stimulation (TMS, Buccino et al., 2005;Pulvermüller, Hauk, Nikulin, &amp; Ilmoniemi, 2005).</p>
<p>Feature-specific conceptual processing has also been investigated in verbs, in particular in comparison to nouns. Previous studies suggest that nouns have a strong visual-related semantic content (Jones &amp; Smith, 1993;Setti, Caramelli, &amp; Borghi, 2009), whereas verbs have a dominant action-related semantic content (Moseley &amp; Pulvermüller, 2014). Although differences in processing of nouns and verbs might also reflect grammatical category (Bedny, Caramazza, Grossman, Pascual-Leone, &amp; Saxe, 2008;Shapiro &amp; Caramazza, 2003), recent findings substantiated a differential semantic content of nouns vs. verbs independent of lexical category effects (Moseley &amp; Pulvermüller, 2014). However, as indicated above, the meaning of nouns does not only refer to visual semantic features, but also to action and auditory features. It is conceivable that, in an analogue way, verbs are not only constituted by action semantic features but also by visual and auditory semantic features. Several factors, however, render a direct comparison of nouns and verbs difficult. For example, compared to nouns, verbs have a delayed age of acquisition (Gentner, 1982) and are more likely associated with multiple meanings and, therefore, more difficult to process (Ehrlich &amp; Rayner, 1981;Zola, 1984). It is thus important to examine feature-specific effects during conceptual processing within each word class and not between word classes. This also has the advantage to exclude the possibility of different grammatical classes as potential confounds for word category effects. Though some conceptual features might be differentially relevant for nouns versus verbs (e.g., visual features might be more important for nouns than for verbs), grounded cognition theories assume comparable processing of conceptual feature types for both verbs and nouns: Feature-specific processing of both word classes is supposed to be associated with activation in corresponding sensory and motor brain regions (Moseley &amp; Pulvermüller, 2014).</p>
<p>However, evidence for feature-specific processing within the category of verbs is relatively scarce and largely based on distinctions between action-related verbs. Some studies on patients with neurodegenerative diseases affecting the motor system reported specific deficits in action-related verb processing (Bak, 2013;Garcia &amp; Ibanez, 2014).</p>
<p>Extending these findings, an imaging study showed that effectorspecific action-related verbs (e.g., to kick, to pick or to lick) specifically activate the same motor regions that are activated during real bodypart-specific movements in a somatotopic fashion (Hauk et al., 2004).</p>
<p>Another imaging study showed a fine-grained distinction of sensorimotor activations during the processing of different action-related verb categories (Kemmerer, Castillo, Talavage, Patterson, &amp; Wiley, 2008).</p>
<p>While feature-specific processing of action-and sound-related words for nouns has been well documented by ERP and fMRI studies, as described above, a similar dissociation for verbs has only been demonstrated by a recent ERP study during a lexical decision task (Popp, Trumpp, &amp; Kiefer, 2016). A comparison between action-and sound-related verbs revealed differential ERP patterns similar to earlier observations with nouns: Action-related verbs elicited more positive scalp potentials within a parietal electrode cluster, whereas soundrelated verbs elicited more negative scalp potentials within a central electrode cluster. Differential ERP effects started early at about 180 ms after stimulus presentation, suggesting that the effects reflect rapid access to auditory and action-related conceptual features. While this earlier ERP study (Popp, et al. 2016) tracked the time course of actionand sound-related verb processing with a high temporal resolution, the precise neuroanatomical location of activated brain areas could not been determined.</p>
<p>Using the high spatial resolution of functional magnetic resonance imaging (fMRI), the present study aimed at substantiating the notion of modality-specific feature processing within the lexical category of verbs. In particular, this study aimed to test whether processing for action-and sound-related verbs involves a corresponding modalityspecific cortex. We therefore asked whether differential activation patterns for action-and sound-related verbs during an implicit task, which does not foster explicit imagery, were comparable to previous neuroimaging findings on action-and sound-related nouns (Chao &amp; Martin, 2000;Kiefer et al., 2008;Rueschemeyer, van Rooij, Lindemann, Willems, &amp; Bekkering, 2010;Trumpp, Kliese et al., 2013). Therefore, in the present study, we presented our participants with one experimental task and two functional localizer tasks. The first task was a lexical decision task in which participants were presented with action-and sound-related verbs in order to obtain brain activations specific for each feature category. In line with recent theoretical proposals of task-related conceptual flexibility Pulvermüller, 2018;Sato, Mengarelli, Riggio, Gallese, &amp; Buccino, 2008), implicit tasks such as the lexical decision task, for which retrieval of conceptual information is not directly relevant for task performance, might induce less activation within the modality-specific sensorimotor cortex than tasks requiring explicit semantic retrieval (Binder, Desai, Graves, &amp; Conant, 2009;Kemmerer, 2015). Correspondingly, a direct comparison of explicit versus implicit task revealed a weaker activation of the motor system by action-related verbs during an implicit task (Popp et al., in press;Sato et al., 2008).</p>
<p>Although sensorimotor activations during explicit tasks may be stronger, they are also more likely to be confounded by attention to specific conceptual stimulus features (Pulvermüller, 2018) or by additional elaborative semantic processes like explicit semantic retrieval (Binder et al., 2009) or imagery (Chatterjee, 2010). Using an implicit lexical decision task, we were able to investigate the neural correlates of conceptual processing of different feature categories without possible influences of imagery or semantic elaboration processes (Chatterjee, 2010;Machery, 2007). Furthermore, we implemented functional acoustic and motor localizer tasks where participants listened to real sounds or performed real movements, respectively. In order to examine the assumptions of strong grounded cognition approaches, we related activation for action-and sound-related verb processing during the lexical decision task to activation obtained during the acoustic and motor localizer, respectively.</p>
<p>Based on the proposals of weaker grounded cognition theories, we assumed that conceptual processing of action-and sound-related verbs activates the same or adjacent sensory and motor areas that are also activated during real sensorimotor experiences. As indicated above, weaker variants of modality-specific theories assume a hierarchy of neural circuits involving various levels of modality-specific (primary, secondary, or modality-specific association cortex) as well as adjacent higher-level multimodal cortices to be involved in the processing of conceptual information (Garagnani &amp; Pulvermüller, 2016;Kiefer et al., 2008;Pulvermüller, 2018;Simmons &amp; Barsalou, 2003). These higherlevel sensorimotor or multimodal areas might not be strongly activated by all types of sensory stimuli in a given modality or by simple motor actions as typically realized in functional localizer tasks, thereby limiting the extent of the potential functional anatomical overlap (for a discussion, see Kiefer et al., 2008). We expected that sound-related verbs would more strongly activate auditory association areas within the left posterior superior and middle temporal gyri than action-related verbs, comparable to previous findings for sound-related nouns (e.g., Kiefer et al., 2008). Action-related verbs should more strongly activate motor and premotor areas than sound-related verbs according to previous findings on action-related nouns (e.g., Rueschemeyer, Pfeiffer et al., 2010). Activity in these auditory and motor brain regions should parametrically increase as a function of subjective ratings of sound and action feature relevance (Fernandino et al., 2015;Kiefer et al., 2008).</p>
<p>As differential contrasts between action-and sound-related verbs conceal common activity in semantic hub regions such as the anterior temporal lobe as well as in sensorimotor areas, activity to both action-related and sound-related verbs was compared with activity to pseudoverbs. These contrasts control for visual stimulation and motor response, but render the full set of activated conceptual brain areas visible. As the semantic content of action-and sound-related verbs is comprised of both action and sound features, albeit to varying degrees (Popp et al., 2016), both action-and sound-related verbs should elicit greater activity within auditory and motor regions compared with pseudoverbs. Furthermore, in line with weaker grounded cognition accounts (Garagnani &amp; Pulvermüller, 2016;Kiefer et al., 2008;Pulvermüller, 2018;Simmons &amp; Barsalou, 2003), we assume that heteromodal semantic hub regions such as the anterior temporal lobe or the semantic retrieval network, comprised of inferior parietal and inferior frontal areas (Binder, 2016;Binder et al., 2009), are more strongly engaged in the processing of both action-and sound-related verbs compared with pseudoverbs.</p>
<p>MATERIALS AND METHODS</p>
<p>Participants</p>
<p>Twenty-four volunteers (12 females) participated in the study (M age : 24.09 years). Two subjects were excluded from analyses due to exceeding fMRI head motion parameters (exclusion criteria: translation &gt; +/-3 mm and/or rotation &gt; +/-1.5 mm). Final analyses included imaging data of 22 (M age : 23.9 years, range: 19 -29 years; 12 female) healthy, right-handed and native German-speaking undergraduates.</p>
<p>They had no history of neurological or psychiatric disorders and normal or corrected-to-normal vision. Participants gave written informed consent and obtained 17 € for participation. Procedures were approved by the Ethical Committee of Ulm University.</p>
<p>General Procedure</p>
<p>Visual stimuli, which were used during the lexical decision task and the motor localizer, were delivered via magnetic resonance-compatible video glasses (Resonance Technology, Los Angeles, CA, USA). They were presented as white letters in the middle of a black background (font size: 16 points character height). Acoustic stimuli of the acoustic localizer task were binaurally presented through magnetic resonance-compatible headphones (Resonance Technology, Los Angeles, CA, USA). Before the fMRI study started, the sound intensity was adjusted individually for each subject (approximately 70 dB). Implementation of the paradigm, stimulus presentation, and behavioral data acquisition were performed within the Experimental Runtime System software package (BeriSoft, Frankfurt, Germany). All participants first performed a lexical decision task followed by the acoustic and the motor localizer. After completing all tasks, structural T1-weighted images were recorded. Participants had the opportunity to practice the lexical decision task outside the scanner using practice stimuli, which were not used in the main experiment and were carefully instructed outside the scanner as well as directly before each task inside the scanner. Preceding the motor localizer task, participants were provided with one elastic hand training ball for each hand.</p>
<p>LEXICAL DECISION TASK</p>
<p>In the lexical decision task, the stimulus set contained 40 actionrelated verbs and 40 sound-related verbs in their infinitive form (see Appendix), which were drawn from a previous study (Popp et al., 2016). In this study, stimuli were chosen based on independent conceptual feature ratings on 569 verbs. The verbs were rated by 30 volunteers on a six-point Likert scale (1 -low feature relevance/familiarity; 6 -high feature relevance/familiarity) with respect to their conceptual features (action, sound, visual, emotion) as well as familiarity. The ratings were performed in two questionnaires, given the high number of items: One for conceptual action, sound, and visual feature relevance ("How strongly do you associate the verb with actions/sounds/visual features?") and the other for emotional feature relevance and the familiarity of the verbs ("How strongly do you associate the verb with emotions?", "How familiar are you with the verb?"). Fifteen subjects completed each type of questionnaire. Ratings for the different variables were probed in a fixed order. Action-and sound-related verbs (e.g., to throw/to roar) used in the present study had specific high feature ratings of action or sound (i.e., &gt; 4), respectively, and comparable low content of the respective other features. However, action-related verbs had a slight, but significantly higher relevance of visual features than sound-related verbs, p &lt; .008; t(78) = -2.72, presumably due to the importance of visual features for action execution (Johansson, Westling, Backstrom, &amp; Flanagan, 2001;Popp et al., 2016) making a perfect match difficult. Stimuli were carefully matched for psycholinguistic parameters (word length, i.e., number of letters, word frequency, type frequency, lemma frequency, bigram frequency, and trigram frequency) and for familiarity (see Table 1). A complete list of these stimuli is provided in the Appendix. Eighty pronounceable but meaningless pseudoverbs (e.g., spoigen) were additionally created for the lexical decision task by substituting one vowel and one consonant of real verbs that were different from stimuli used in the lexical decision task with another vowel and consonant, respectively. Finally, pseudoverbs were matched with action-and sound-related verbs for word length.</p>
<p>Action-and sound-related verbs as well as pseudoverbs were visually presented once in an event-related design in randomized order.</p>
<p>At the beginning of each trial, a fixation cross was presented for 500 ms followed by a verb for 400 ms. Beginning with the onset of the stimulus, participants had to respond within a time window of 1800 ms. Before the next trial started, an intertrial interval (ITI) with a mean duration of approximately 3 s (range: 0-11700 ms) was inserted.</p>
<p>A pseudo-randomized sequence of stimulus categories (action-related verb, sound-related verb, or pseudoverb) in dependence of an optimal scanning rate of the hemodynamic response function (Dale, 1999) and the associated ITI was created using OPTSEQ2 (https://surfer.nmr. mgh.harvard.edu/optseq/). Within the fixed sequence of all stimulus categories, the presentation of each verb was randomized for each participant. In the lexical decision task, subjects responded on a response keyboard by pressing the left button with their right index finger to respond to a real verb and by pressing the right button with their right middle finger to respond to a pseudoverb. They were instructed to decide as fast and accurately as possible. The duration of the lexical decision task was approximately 14 minutes and comprised the acquisition of 435 consecutive brain volume images.</p>
<p>FUNCTIONAL LOCALIZER TASKS</p>
<p>During the acoustic localizer task, two blocks consisting of 10 sounds from natural categories (e.g., barking of dogs) or 10 sounds from manmade categories (e.g., hammer strikes), respectively, were presented together with silence blocks in an alternating order (24 s duration per block). Each sound was binaurally presented with a mean duration of 1468 ms (range: 1050-1980 ms). After sound presentation, a jittered pause was inserted with a mean duration of 932 ms (range: 383-1481 ms). During sound presentation, the screen remained black and participants were instructed to attentively listen to the sounds. The duration of the acoustic localizer was approximately 7 minutes (214 volumes acquired in total). In the motor localizer task, resting and movement blocks were implemented in alternating order similar to the acoustic localizer (24 s duration per block). In the movement blocks, two small arrows were presented in the middle of the screen, which both pointed either to the right or to the left direction. The arrows indicated the respective hand, with which participants had to press an elastic hand training ball.</p>
<p>A sequence of 10 arrow pictures was presented, each lasting 300 ms, followed by a clear screen with a mean duration of 2100 ms (range: 1255-2752 ms). Accordingly, participants had to press the hand training ball within one block either 10 times with their right hand or 10 times with their left hand. Participants were instructed to press the ball during the motor localizer task with even strength while keeping the rest of the body motionless. During resting blocks, the arrows were replaced by a fixation cross, whereas the other event parameters were identical. Participants were instructed to look at the fixation crosses.</p>
<p>Like the acoustic localizer, the motor localizer task lasted about 7 minutes (214 volumes acquired).</p>
<p>Data Acquisition and Analysis</p>
<p>For behavioral data, mean reaction times (RTs) for correct responses and mean error rates (ERs) were calculated for each subject and each feature category (sound and action). At the subject level, RTs +/− 2 SDs from the mean value were rejected as outliers. Calculation of ERs comprised wrong and missing responses.</p>
<p>Magnetic resonance images were recorded with a 3-tesla scanning system (Siemens Prisma, Erlangen, Germany). Structural T1-weighted images were obtained using a MPRAGE sequence (TR = 2300 ms; TE We performed the fMRI analyses separately for each task. After preprocessing, first-level analyses were performed with the general linear model. The design matrix of the first-level-analyses for the lexical decision task included regressors for sound-related verbs, actionrelated verbs, pseudoverbs, and errors from all conditions, resulting in a design matrix with altogether four experimental regressors and six additional regressors for the motion parameters for each participant.</p>
<p>The second-level analysis was specified with a flexible factorial design with subjects as a random factor and the two conditions, action-and sound-related verbs from the first-level analysis, as fixed effects. In order to investigate feature-specific effects, we calculated the t-contrasts between action-related verbs and sound-related verbs and between sound-related verbs and action-related verbs. A statistical threshold of p &lt; .001 (uncorrected) was applied at the voxel level (cluster-forming threshold), and a statistical threshold of p &lt; .05 family-wise error (FEW) corrected for multiple comparisons was applied at the clusterlevel (Eklund, Nichols, &amp; Knutsson, 2016). To investigate action-and sound-specific feature processing independent from verb category, a second analysis was set up including the semantic ratings of acoustic and action verb features as parametric modulators of the canonical hemodynamic response function. This model included verbs, pseudoverbs, and errors as conditions, parametrically modulated by the acoustic and action feature ratings. Pseudoverbs were included as a condition in order to model activity to these stimuli and to keep the analyses comparable, but were not further analyzed. Since pseudoverbs do not have a semantic content and semantic feature ratings are thus not meaningful, a null-vector was inserted. Please note that parametric modulation analyses expect a parametric modulator for all specified regressors, hence also for pseudoverbs. To account for effects of order of the parametric modulators, two models were set up in this analysis.</p>
<p>In the first model, the acoustic feature ratings were inserted first and the action feature ratings were inserted second. In the other model, the order was reversed. The second-level analysis was specified with a flexible factorial design with subjects as a random factor and the two parametric modulator acoustic and action feature ratings as fixed effects. For the parametric modulation analysis, we used the identical statistical thresholds as described above.</p>
<p>In order to capture activation for verb categories while correcting for visual stimulation and the motor response, a third model was specified in an additional analysis, with a flexible factorial design with subjects as a random factor and the three conditions, action-related verbs, sound-related verbs, and pseudoverbs from the first-level analy- For both functional localizer tasks, sound and action events were timed block-wise and convolved with the canonical hemodynamic response function together with the six motion parameters from realignment (effects of no interest), respectively. Activations for all participants were assessed in a second-level analysis by one-sample t-tests. Sound and movement blocks were compared with the implicit baseline. The statistical threshold for the motor and the acoustic localizer task was set at voxel-level to p &lt; .05 FWE (cluster-forming threshold) corrected for multiple comparisons. Anatomical locations of peak activations of significant clusters were determined by probabilistic cytoarchitectonic mapping using the SPM Anatomy toolbox (Eickhoff et al., 2007).</p>
<p>RESULTS</p>
<p>Behavioral Results</p>
<p>Participants performed in the lexical decision task with a mean error rate of 4.6 % (SD = 2.56%). A repeated-measures analysis of variance    threshold. However, at a statistical threshold at the cluster level uncorrected for multiple comparisons (p &lt; .05), greater activation in the left superior frontal gyrus and in the right cerebellum was found (see Table   3, Figure 1, Panel A).</p>
<p>Neuroimaging Results</p>
<p>LEXICAL DECISION TASK</p>
<p>Conceptual acoustic and action feature relevance ratings were related to brain activation during verb processing in parametric modulation analyses. When acoustic ratings were entered first as a parametric modulator and action ratings as a second parametric modulator, greater activity to action versus acoustic ratings was found in the precuneus in both hemispheres and in the left medial fusiform gyrus (see Table   4, Figure 2). The reversed contrast of acoustic versus action ratings revealed no suprathreshold clusters. When the parametric modulators were inserted in the reversed order, no significant results were obtained at the applied statistical threshold.   Activation peaks during the lexical decision task for verb categories overlaid with activations obtained during the localizer tasks. In order to determine the anatomical vicinity of activations during action execution/sound perception and conceptual processing, activations obtained during the functional localizer tasks were overlaid with activations for the differential contrasts action-related versus sound-related verbs and sound-related versus action-related verbs, respectively. Color range bars indicate T-scores. Overlapping activations are marked in yellow. Panel A: Action-related versus sound-related verbs (green) overlaid with the motor localizer (red). Adjacent activations were found in the right cerebellum, the left superior frontal gyrus and in the white matter. Panel B: Sound-related versus action-related verbs (pink) overlaid with the acoustic localizer (blue). Overlapping activations were bilaterally found in the superior temporal gyrus (left: 12 overlapping voxels, right: 1 voxel). Panel C: Multislice image of overlapping activation for sound-related versus action-related verbs and activations obtained during the acoustic localizer in the left superior temporal gyrus (12 overlapping voxels).</p>
<p>Brain region MNI Coordinates</p>
<p>Results of action-related versus sound-related verbs are reported at p &lt; .001 (uncorrected) at the voxel level and at p &lt; .05 (uncorrected) at the cluster level and results of sound-related versus action-related verbs are reported at p &lt; .001 (uncorrected) at the voxel level and at a p &lt; .05 FWE corrected at cluster-level. Results of the localizer tasks were reported FWE corrected (p &lt; .05) at the voxel-level. </p>
<p>FUNCTIONAL LOCALIZER TASKS</p>
<p>Comparing sound perception with the implicit baseline, we found bilateral activations in the temporal cortex extending to the insula, with peak activations in the superior temporal gyrus and in the insula in both hemispheres (see Table 5). Masking sound-versus action-related verbs with the results of the acoustic localizer revealed no common activations, which were significant at the cluster level. However, similar to earlier studies, we computed a quantitative overlap between the activations for the conceptual task and the localizer tasks (Hauk et al., 2004;Kiefer et al., 2008;Simmons et al., 2007) at a descriptive level.</p>
<p>Activations for the contrast of sound-versus action-related verbs overlapped with the acoustic localizer mainly in the left superior temporal gyrus (12 overlapping voxels). In the right hemisphere, quantitative overlap was nearly absent (one overlapping voxel, see Figure 1, Panels B and C). Activations for the contrast of action-versus sound-related verbs did not overlap with the acoustic localizer.</p>
<p>Comparing the execution of hand movements with the implicit baseline revealed activation within the frontal, parietal, temporal, and occipital cortex as well as within the basal ganglia (see Table 5).  </p>
<p>Masking activations for action-versus sound</p>
<p>DISCUSSION</p>
<p>In the present fMRI study, we investigated brain activation during the processing of action-and sound-related verbs during a lexical decision task, a task that implicitly probes semantic processing. Sound-related   action-related verbs was only found at a more lenient statistical threshold, our findings only partially support the view of grounded cognition theories that sensorimotor systems are involved in semantic word processing (Barsalou, 2008;Gallese &amp; Lakoff, 2005;Martin, 2007).</p>
<p>The present study confirms the previous observation of differential ERP effects for action-and sound-related verbs using the same stimulus set (Popp et al., 2016). This earlier study revealed feature-specific ERP effects to action-versus sound-related verbs already at about 110 ms after verb onset. This ERP effect indicates that feature-specific activation indexes rapid access to conceptual features and not later strategic semantic processing or imagery. The present fMRI study provides precise anatomical information for the neural generators underlying the scalp ERP effects and demonstrates an involvement of brain regions within or close to sensory and motor areas in these feature-specific effects.</p>
<p>The functional localizer tasks revealed activations in the expected modality-specific brain areas. Peak activations obtained during the motor localizer task were mainly located in the motor cortex, the primary somatosensory cortex and visuo-motor coordination areas within the cerebellum, occipital visual areas, and in motor areas of parietal cortex (Brown, Kessler, Hefter, Cooke, &amp; Freund, 1993;Georgopoulos &amp; Grillner, 1989;Glickstein, 2000;Hauk et al., 2004;Jeannerod, Arbib, Rizzolatti, &amp; Sakata, 1995;Lotze et al., 1999). The perception of real sounds during the acoustic localizer task was associated with activations in the primary and secondary auditory cortex as well as in the auditory association cortex within the superior temporal gyrus (Belin, Zatorre, Lafaille, Ahad, &amp; Pike, 2000;Leaver &amp; Rauschecker, 2010;Lewis et al., 2004).</p>
<p>Processing of action-versus sound-related verbs in the lexical decision task was associated with activations in the cerebellum and in the superior frontal gyrus, however, only at a more liberal statistical threshold uncorrected for multiple comparisons. Activation in the cerebellum bordered directly on cerebellar activations obtained during the motor localizer, but was not overlapping. Activation in the left superior frontal cortex by action-related verbs during the lexical decision task in the present work is located close to premotor cortex and has also been described in a previous study (Willems, Toni, Hagoort, &amp; Casasanto, 2010). A region of interest (ROI) analysis of the present data at the peak coordinates obtained in this earlier study (x: −14, y: 34, z: 54; spherical ROI with 8 mm radius) revealed higher activity for action-than for sound-related verbs, t(21) = 1.89; p &lt; .05, one-tailed. Voxels of this superior frontal cluster caudally reached into the presupplementary motor area, a cortical region that is involved in several motor functions like motor selection and planning of movements (Kim et al., 2010) or awareness of action discrepancy (Farrer et al., 2008). Previous studies also demonstrated that the dorsolateral part of the superior frontal gyrus is, amongst others, functionally connected to the precuneus and the posterior cingulate cortex (Li et al., 2013), regions that are known to be involved in the retrieval of object-related action information (Wang et al., 2019). This indicates that the superior frontal gyrus is involved in action processing. However, greater activation for action-versus sound-related verbs was only detected, when lowering the statistical threshold at the cluster level. This is partly owed to the fact that sound-related verbs elicited considerable activity within motor areas (see Supplementary Figure 1 and the discussion below), thereby reducing feature-specific effects for action-related verbs.</p>
<p>Thus, the validity of the contrast of action-versus sound-related verbs to investigate feature-specific effects for action-related verbs is limited.</p>
<p>This suggests that conceptual feature ratings provide only an approximate quantitative estimate of the semantic content of words and linked concepts. Furthermore, the motor response of the button press could have influenced motor activation for action-related verbs by interfering with feature-specific processing of conceptual action-related information (Pulvermüller, 2018;Schomers &amp; Pulvermüller, 2016). This is also indicated by the increased activation in motor areas for pseudoverbs compared to real verbs. Possibly, a task without a concomitant motor response would yield stronger activity to action-related verbs in motor areas as observed previously (Carota, Moseley, &amp; Pulvermüller, 2012;Kemmerer, 2015;Schomers &amp; Pulvermüller, 2016).</p>
<p>Sound-versus action-related verb processing elicited activations in a network of auditory, but also of visuo-motor areas. Sound-related verbs activated auditory association areas in the middle temporal gyrus and the superior temporal gyrus, in vicinity of activations obtained in previous studies on sound-related nouns . However, the anatomical location of the present activation was somewhat more superior and posterior than in these previous studies . Other studies on processing of perceptual or conceptual sound-related information found activations in the left posterior superior temporal gyrus in close vicinity to the presently observed activations (e.g., Kellenbach, Brett, &amp; Patterson, 2001;Lewis, et al., 2004). Activation in response to conceptual, but also to perceptual sound-related information in posterior temporal cortex appears to be variable to some extent. Possibly, these variations in the precise anatomical locus of higher-level sound processing in posterior temporal areas are due to word class differences or differences in the spectral properties of the sounds, to which the concepts refer (sounds caused by actions vs.</p>
<p>sounds elicited by objects).</p>
<p>In the present study, activation for sound-related verbs partially overlapped with activity during the acoustic localizer within the superior temporal gyrus, although the masking analysis did not yield significant common activations at the cluster level due to the small cluster size (12 voxels) of the overlapping activation. It should be noted at this place that the size of the overlapping cluster was comparable with the earlier study on sound-related nouns . Furthermore, several earlier studies in the field of grounded cognition (Hauk et al., 2004;Hoenig et al., 2011;Kemmerer et al., 2008;Kiefer et al., 2008;Simmons et al., 2007) only determined a quantitative overlap between conceptual and sensorimotor processing without demonstrating common activations in a conjunction or masking analysis. In support of a functional role of this posterior superior temporal region in higher-level sound processing, a previous study on sound perception and sound imagery also reported activation in this area (Bunzeck, Wuestenberg, Lutz, Heinze, &amp; Jancke, 2005). A formal ROI analysis of the present data based on the peak coordinate from this earlier study (Bunzeck et al., 2005) in the left posterior superior temporal gyrus (x: −52, y: −36, z: 20; spherical ROI with 8 mm radius) revealed a significantly higher magnetic resonance signal for sound than for action -related verbs, t(21) = 1.75; p &lt; .05, one-tailed.</p>
<p>Further activations for sound-related verbs were observed in the inferior frontal gyrus and in visuo-motor coordination areas within the parietal and occipital brain regions, which are known to be involved in visuo-motor control (Georgopoulos &amp; Grillner, 1989;Glickstein, 2000).</p>
<p>Sound-related verbs might have induced activation in motor regions due to their salient action content. A closer look at the conceptual feature ratings (see Table 1) of sound-related verbs reveals that sound-related verbs also had a relatively high action feature relevance, in addition to a high acoustic feature relevance. For example, the verb to knock has a strong association with sound, but at the same time implies a certain action that is essential for generating the sound. In fact, a recent study provided evidence for such an action-sound coupling leading to mutual activation of the auditory and motor systems (Lemaitre et al., 2018). This linkage between sound and action may explain why sound-related verbs elicited stronger activations in parietal and frontal motor areas than action-related verbs, in addition to greater activity in auditory areas of the temporal cortex: It is possible that action-sound coupling leads to an amplification of activation within the motor system through input from the auditory system, which was absent in action-related verbs.</p>
<p>This additional input from auditory areas may have resulted in even stronger activity in various parts of the motor system for sound than for action-related verbs. Relating activations for sound-versus actionrelated verbs to activations obtained during the motor localizer indicated that processing of sound-related verbs involved areas also activated by executing hand movements (see Supplementary Figure 1). Hence, activity to sound-related verbs outside auditory temporal areas most likely does not arise from unspecific or amodal word processing, but reflects sound-related action processing. In support of this interpretation, earlier studies on sound-related nouns also revealed activity not only in auditory areas, but also in motor-related regions of the parietal cortex Trumpp, Traub et al., 2013;Trumpp et al., 2014). With regard to this action-sound-coupling in sound-related verbs (Lemaitre et al., 2018), which could not be completely bypassed by matching the conceptual stimulus features, a stimulus category other than sound-related verbs might provide a better contrast to investigate feature-specific activations for action-related verbs. To investigate the activation of actionand sound-related verbs during the lexical decision task as a function of acoustic and action feature ratings, parametric modulation analyses were conducted. For the model in which the modulator for acoustic feature ratings was inserted first, significant activation for the contrast of action versus acoustic feature ratings was found in the precuneus and the medial fusiform gyrus. While the precuneus is connected to motor brain regions and associated with processing object-related action information (Wang et al., 2019), the medial fusiform gyrus has been implicated in the representation of manipulable tools (Martin &amp; Chao, 2001). This indicates a role of the precuneus and the medial fusiform gyrus in the processing of conceptual action-related information. Results of the parametric modulation analyses revealed a contribution of action-related brain areas to action-related verb processing, even though these effects were not visible in the differential contrasts of action-versus sound-related verbs. For sound ratings, we failed to find a significant relation to brain activity. This might be explained by the more dichotomous distribution of sound ratings compared with the more continuous distribution of action ratings. The distribution of the former ratings might have prevented significant parametric modulation effects. A parametric modulation effect for action ratings was only found when acoustic feature ratings were entered as the first modulator and action feature ratings as the second modulator. Possibly, due to the mutual influence of acoustic and action feature ratings based on action-sound-coupling (Lemaitre et al., 2018) on brain activity, the parametric modulation effect of action feature ratings is only visible when the influence of acoustic ratings is removed by entering it as first modulator.</p>
<p>It is also noteworthy that error rates and reaction times for actionand sound-related verbs did not differ significantly in the present study.</p>
<p>This indicates that the verb sets exhibited a comparable level of difficulty.</p>
<p>Although we matched our stimuli with regard to conceptual stimulus features, it was not possible to keep the visual content of action-related verbs at a comparable low level as for sound-related verbs. This was owed by the fact that action-related verbs consistently had a relatively high visual feature relevance because actions are typically associated with visual properties of objects or situations (Tyler &amp; Moss, 2001). We had to accept this increased visual feature content of action-related verbs to avoid selection of untypical word material.</p>
<p>In order to capture activation for verb categories, while correcting for visual stimulation and the motor response, activations for action-and sound-related verbs were compared with activations for pseudoverbs and inclusively masked with both functional localizers. The comparison with pseudoverbs demonstrates that both verb categories elicit partially similar activations. Both action-and sound-related verbs versus pseudoverbs activated not only general language areas (Binder et al., 2009) but also auditory and motor brain areas, possibly due to action-sound coupling (Lemaitre et al., 2018). Masking analyses revealed activations for soundrelated verbs versus pseudoverbs masked with the acoustic localizer in the superior temporal gyrus (21 commonly activated voxels) to be somewhat more prominent than activations in the same brain area by action-related verbs (15 commonly activated voxels). Masking analyses with the motor localizer revealed that both verb categories also activated a more posterior part of the superior/middle temporal gyrus as shown in previous studies on action-versus sound-related concepts . This activity in auditory and action-related areas was specific for action-and sound-related verbs because processing pseudoverbs did not recruit these areas in the present study. Hence, both verb categories elicited significant activation in auditory and motor areas, in support of grounded cognition theories. This common sensorimotor activation for both verb categories explains why differential contrasts did not yield significant clusters in the corresponding modality-specific cortex.</p>
<p>Findings of the present study parallel results of earlier studies on action-and sound-related nouns in many respects, as shown above, although feature-specific activation for action-related verbs was relatively weak and only obtained at a more liberal statistical threshold. As demonstrated by the comparisons with the pseudoverbs, activations found in the differential contrasts of action-versus sound-related verbs and vice versa showed small effect sizes because both verb categories elicited considerable activations in the auditory and motor areas. Nevertheless, the present study shows that category-specific effects for conceptual feature types can also be obtained for verbs. The present results at least partially confirm the assumption of a modality-specific representation of action and sound features for concepts expressed by verbs similar to previous findings on action-and sound-related nouns Moseley &amp; Pulvermüller, 2014;Rueschemeyer, van Rooij et al., 2010).</p>
<p>However, as only differential contrasts between action-and soundrelated verbs as well as between verbs and pseudoverbs were calculated, activation of the anterior temporal lobe, an area presumably involved in amodal conceptual integration, was not revealed by these analyses.</p>
<p>Possibly semantic retrieval processes in this area might contribute to the processing of both verbs and pseudoverbs (Kutas &amp; Van Petten, 1994).</p>
<p>Therefore, the present study does not preclude the existence of a heteromodal semantic hub in the anterior temporal lobe, which integrates information from different modalities in addition to modality-specific systems (Lambon Ralph et al., 2017). However, greater activity to both verb categories versus pseudoverbs was observed in presumably heteromodal regions of the inferior frontal and inferior parietal cortex (see Supplementary Table 1). These regions can also be considered as semantic hub regions, because they are parts of a frequently documented semantic retrieval network (Binder, 2016;Binder et al., 2009).</p>
<p>As neuroimaging studies only provide correlational evidence, the present findings do not rule out that sensorimotor activations during conceptual processing are just epiphenomenal (Mahon &amp; Caramazza, 2003). A functional relation between the sensorimotor systems and conceptual processing could be tested in future studies in behavioral interference paradigms (Klepp et al., 2017;Shebani &amp; Pulvermüller, 2013;Vermeulen, Corneille, &amp; Niedenthal, 2008), transcranial magnetic stimulation (Buccino et al., 2005;Pulvermüller et al., 2005) or lesion studies (Kemmerer, Rudrauf, Manzel, &amp; Tranel, 2012;Neininger &amp; Pulvermüller, 2003;Trumpp, Kliese et al., 2013).</p>
<p>The present fMRI results with action-and sound-related verbs are similar, but not identical to findings with corresponding noun categories.</p>
<p>Activation for sound-related verbs in the present study was found in a slightly different anatomical location in the posterior temporal cortex than for sound-related nouns (cf.: x: −62, y: −42, z: − 3) in the earlier study . As already discussed above, it must remain open whether this difference reflects word category, spectral properties of the sounds to which the concepts refer, or interindividual anatomical variation. Furthermore, processing of sound-related verbs elicited substantial activity in action-related brain areas, which can be explained by the relatively high action feature content of sound-related verbs.</p>
<p>It might be possible that the processing of visually presented actionrelated verbs is more akin to activations for action observation than the actual execution of real movements (Rueschemeyer, Ekman, van Ackeren, &amp; Kilner, 2014). Rueschemeyer et al. (2014) argue that reading actionrelated words is more similar to action observation rather than to the actual execution of movements. Therefore, it is conceivable that activation during a localizer, which requires the observation of action, shows a better functional anatomical overlap with activations elicited by action-related verb processing as compared to the present localizer involving real movements. Furthermore, a greater functional anatomic overlap could also be possibly obtained by using a localizer requiring different object-directed hand actions. Similarly, the acoustic localizer only included a small variety of sounds, which could have limited overlapping activations with processing of sound-related verbs in the temporal cortex. Future studies could therefore test the possibility that the functional-anatomical overlap between conceptual and sensorimotor processing depends on the stimuli and actions used in the localizer tasks.</p>
<p>As described in the introduction, only strong grounded cognition theories (Gallese &amp; Lakoff, 2005;Pulvermüller, 2001) assume a full equivalence of the neural substrate of conceptual and sensorimotor processing. Weaker variants of grounded cognition theories, however, assume a hierarchy of neural circuits involving various levels of modalityspecific (primary, secondary, or modality-specific association cortex), adjacent multimodal cortices as well as heteromodal semantic hub areas to be involved in the processing of conceptual information (Garagnani &amp; Pulvermüller, 2016;Kiefer et al., 2008;Pulvermüller, 2018;Simmons &amp; Barsalou, 2003). Hence, these weaker variants of grounded cognition theories predict activation in a conceptual task to be close to or overlapping with a region involved in sensory-or motor processing but do not necessarily imply a full or considerable anatomical overlap. Reactivation of sensorimotor experiences during conceptual processing in implicit tasks requiring only superficial access to semantics might predominantly take place in parts of higher-level sensory and motor association areas as well as adjacent multimodal areas in addition to semantic hub regions. Higherlevel modality-specific and multimodal areas might not be strongly activated by the functional localizer tasks, thereby limiting the extent of the potential functional anatomical overlap. Future studies could test whether the overlap between conceptual and sensorimotor processing would be more extended when a more explicit semantic task such as a categorization (Kemmerer, 2015) or property verification task (Simmons, Hamann, Harenski, Hu, &amp; Barsalou, 2008) is administered instead of the implicit lexical decision task in the present study.</p>
<p>CONCLUSIONS</p>
<p>The present study obtained differential activations for action-and sound-related verbs in an implicit lexical decision task. Featurespecific brain activation for action-and sound-related verbs partly overlapped with or was near to brain regions involved in action or perception. It should be noted that comparisons of action-and sound-related verbs with pseudoverbs revealed activation for both verb categories in auditory and action-related areas, presumably due to action-sound coupling (Lemaitre et al., 2018). The present results contradict strong variants of grounded cognition theories (Gallese &amp; Lakoff, 2005;Pulvermüller, 2001), in which an identical neural substrate of conceptual and sensorimotor processing is assumed. However, the present findings are compatible with weaker variants of grounded cognition theories (Garagnani &amp; Pulvermüller, 2016;Kiefer et al., 2008;Pulvermüller, 2018;Simmons &amp; Barsalou, 2003) Note. Reported are significant results at a statistical threshold of p = .05 FWEcorrected for the whole brain at voxel-level. Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart.</p>
<p>To reduce complexity, we only report clusters &gt; 10 voxels. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI:</p>
<p>Montréal Neurological Institute, FWE = Family wise error rate, R = right, L = left. Pseudoverbs versus action-related verbs masked with the motor localizer -Note. Reported are significant results at a statistical threshold of p = .05 FWEcorrected for the whole brain at voxel-level. Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart. To reduce complexity, we only report clusters &gt; 10 voxels. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI = Montréal Neurological Institute, FWE = Family wise error rate, R = right, L = left.</p>
<p>Popp, Natalie M. Trumpp, Eun-Jin Sim, and Markus Kiefer    Ulm University, Department of Psychiatry, Ulm, Germany.</p>
<p>Natick, USA). During preprocessing, head motion artifacts were corrected by rigid-body-transformation of all images per series by orienting on the first image for three rotation and three translation parameters. Slice time correction was based on the middle slice and co-registration was performed using structural T1-weighted images for each participant individually. Anatomical structures were normalized to the Montreal Neurological Institute (MNI) template (resampled voxel size: 2 × 2 × 2 mm). Normalized images were smoothed with an isotropic 8 mm FWHM Gaussian kernel. Data were filtered with a temporal high-pass filter (1/128 Hz) and an autoregressive model was used regarding intrinsic temporal autocorrelation of the image series.</p>
<p>ANOVA) revealed that mean ERs differed between action-related verbs (5.45 %; SD = 4.27 %), sound-related verbs (5.91 %; SD = 3.74%), and pseudoverbs (3.52 %; SD = 2.77 %), F(2, 24) = 4.71; p = .014.Significant effects were further analyzed using Tukey's honestly significant difference (HSD) post-hoc tests. Post-hoc tests showed larger ERs for sound-related verbs than for pseudoverbs, p = .016. Mean ERs between sound and action-related verbs (p = .85) and between actionrelated verbs and pseudoverbs (p = .061) did not significantly differ.A repeated-measures ANOVA on reaction times yielded a significant difference between action-related verbs (687 ms; SD = 93 ms), soundrelated verbs (693 ms; SD = 98 ms) and pseudoverbs (757 ms; SD = 106 ms), F(2, 42) = 50.61; p &lt; .0001. According to post-hoc tests, participants reacted significantly faster to action-and sound-related verbs compared with pseudoverbs (both ps &lt; .001). Reaction times did not significantly differ between action-and sound-related verbs (p = .71).</p>
<p>Note.
Reported are significant results at a statistical threshold of p &lt; .001 (uncorrected) at the voxel level and at p &lt; .05 (FWE-corrected) at the cluster-level.Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI = Montréal Neurological Institute, FWE = family wise error rate, R = right, L = left.</p>
<p>TABLE 3 .
3Peak Activations for the Contrast of Action-Versus Sound-Related Verbs in the Lexical Decision Task Note. Reported are significant results at a statistical threshold of p &lt; .001 (uncorrected) at the voxel level and at p &lt; .05 (uncorrected) at the cluster level. Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI = Montréal Neurological Institute, R = right, L = left.</p>
<p>FIGURE 1 .
1FIGURE 1.</p>
<p>-related verbs with the results of the motor localizer did not reveal significant common activations at the cluster level. Relating the activations for the contrast of action-versus sound-related verbs (at the more liberal uncorrected threshold) with activations obtained during the motor localizer also did not reveal overlapping clusters. However, activations associated with the processing of action-related verbs border directly on activations for the motor localizer in the right cerebellum (see Figure 1, Panel A). Interestingly, there were common activations for the contrast of sound-versus action-related verbs with the motor localizer (action execution vs. baseline) at the descriptive level in a visual-The reported results were obtained with the model, in which the modulator for acoustic feature ratings was inserted first. Reported are significant results at a statistical threshold of p &lt; .001 (uncorrected) at the voxel level and at p &lt; .05 (FWEcorrected) at the cluster-level. Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI: Montréal Neurological Institute, FWE = Family wise error rate, R = right, L = left.</p>
<p>FIGURE 2 .
2Peak activations for action versus acoustic feature ratings as modulators in the parametric modulation analyses of the lexical decision task. Left: The depicted results were obtained with the model, in which the modulator for acoustic feature ratings was inserted first. The color range bar indicates T-scores. Reported are significant results at a statistical threshold of p &lt; .001 (uncorrected) at the voxel level and at p &lt; .05 (FWE-corrected) at the cluster-level. Right: Effect sizes are depicted for the contributions of conceptual acoustic and action features at the precuneus and the left medial fusiform gyrus. Vertical bars indicate standard error of the mean. the results of the comparison of sound-related versus pseudoverbs with the acoustic localizer revealed significant common activations in the right superior temporal gyrus. The comparison of action-related versus pseudoverbs masked with the acoustic localizer also yielded common activation in the right superior temporal gyrus (15 commonly activated voxels), however, to a smaller extentcompared with masking the results of sound-related verbs versus pseudoverbs (21 commonly activated voxels). The comparisons of pseudoverbs versus sound-related verbs and pseudoverbs versus actionrelated verbs masked with the acoustic localizer revealed no significant overlapping voxels (see Supplementary Table 2, Supplementary Figure 2). Masking analyses of sound-related versus pseudoverbs with the motor localizer revealed significant common activations in middle occipital, middle temporal, and middle cingulate cortex in both hemispheres. The fusiform gyrus, the caudate nucleus, and the precuneus were also commonly activated in both hemispheres. Further common activations were found in the right inferior occipital, the right superior temporal, the left pre-and post-central gyrus, in the left supramarginal gyrus, as well as in the right rolandic operculum, the left insula, and the right putamen. Masking the contrast of action-related verbs versus pseudoverbs with the motor localizer revealed common activations in middle and inferior occipital as well as in the middle and inferior temporal cortex in both hemispheres. Further common activations were found in the right fusiform gyrus, the right superior temporal gyrus, the left posterior medial frontal gyrus, the left paracentral lobule, bilateral precuneus, the left supramarginal gyrus, the right calcarine sulcus, the left mid cingulate cortex, the right rolandic operculum, the caudate nucleus in both hemispheres, the left and right thalamus, and in the left insula. The comparisons of pseudoverbs versus sound-related verbs and pseudoverbs versus action-related verbs masked with the motor localizer revealed no significant overlapping voxels (see Supplementary Table 2, Supplementary Figure 2).</p>
<p>verbs bilaterally elicited activations in the superior temporal cortex, partially overlapping with activation during the perception of real sounds obtained in the functional localizer in the left hemisphere, although formal masking analyses did not yield a significant common activation. Sound-related verbs elicited, in addition to this auditory area, activation in the visual and motor areas. Action-related verbs recruited motor regions within the frontal cortex and the cerebellum, albeit only at a more liberal statistical threshold. These activations in response to action-related verbs were partly located in vicinity (i.e., &lt; 14 mm apart,Sepulcre et al., 2010) of activations obtained during the execution of real movements obtained in the functional localizer. Given that activation for</p>
<p>TABLE 4 .
4Peak Activations for the Acoustic and the Motor Localizer TasksNote. Reported are significant brain regions contrasting sound and movement blocks against an implicit baseline at a statistical threshold of p &lt; .05 FWE-corrected for multiple comparisons at the voxel level. Listed are peak voxels with highest t-values for significant clusters and their local maxima more than 8 mm apart. To reduce complexity, we only report clusters &gt; 10 voxels. Peak activations that could not be assigned to specific brains region are indicated by " -". MNI = Montréal Neurological Institute, FWE = Family wise error rate, R = right, L = left.</p>
<p>TABLE 1 .
1Average Values (SD) of Semantic Ratings and Psycholinguistic Stimulus Features for the Critical Action-and Sound-Related Verbs, Together with p-values of Two-Tailed t-TestsNote. Verbs were evaluated with regard to conceptual action, visual, emotion and sound features as well as with regard to familiarity on a six-point Likert-scale (based onPopp et al., 2016).Action-
related verbs </p>
<p>Sound-related 
verbs </p>
<p>Action-versus 
sound-related 
verbs 
Action 
5.14 (.42) 
3.03 (.80) 
&lt; .0001 
Sound 
1.93 (.58) 
4.97 (.56) 
&lt; .0001 
Visual 
2.74 (.46) 
2.32 (.87) 
.008 
Familiarity 
4.00 (.80) 
3.65 (.81) 
.06 
Emotion 
2.64 (.79) 
2.78 (.76) 
.43 
Word length 
7.28 (1.67) 
7.30 (1.45) 
.94 </p>
<p>Word frequency 
194.98 
(405.80) </p>
<p>145.93 
(581.85) 
.66 </p>
<p>Lemma frequency 
p.Mio. 
32.97 (75.06) 23.39 (80.93) 
.58 </p>
<p>Character bigram 
frequency p.Mio </p>
<p>996151.77 
(308584.05) </p>
<p>957488.78 
(266070.34) 
.55 </p>
<p>Character trigram 
frequency p.Mio. </p>
<p>486060.42 
(899993.00) </p>
<p>468888.67 
(113753.97) 
.46 </p>
<p>sis (for results, seeSupplementary Table 1). For this third model, as it involved a comparison with pseudoverbs as baseline condition, the statistical threshold of p &lt; .05 FWE-corrected for multiple comparisons was applied at the voxel level (cluster-forming threshold). Functional activations for action-versus sound-related verbs and by sound-versus action-related verbs as well as the comparisons with pseudoverbs were inclusively masked with activations for the respective localizer task (statistical threshold: p &lt; .05 FWE-corrected), in order to reveal common activations.</p>
<p>Table 2 ,
2Figure 1, Panel B). Contrasting action-versus sound-related verbs revealed no suprathreshold voxels for the applied statistical Peak Activations for the Contrast of Sound-Versus Action-Related Verbs in the Lexical Decision TaskBrain region 
MNI 
Coordinates </p>
<p>Peak 
T </p>
<p>Cluster 
size </p>
<p>Cluster p 
(FWE-
corrected) 
Inferior occipital L 
-30 -76 -6 
6.74 1711 
&lt; .0001 
Middle occipital L 
-22 -58 40 6.20 
Superior temporal L 
-48 -38 22 5.56 
Inferior temporal R 
40 -60 -6 
6.40 1040 
&lt; .0001 
-
26 -84 0 
6.24 
Superior occipital R 
24 -90 18 
5.88 
-
36 20 16 
5.88 
670 
&lt; .0001 
Inferior frontal pars 
triangularis R 
52 18 22 
5.09 </p>
<p>-
30 22 26 
5.06 
Middle temporal R 
50 -54 12 
5.13 
389 
&lt; .0001 
-
44 -44 10 
4.79 
Superior temporal R 
38 -32 10 
4.71 
Inferior frontal pars 
opercularis L 
-56 14 32 
4.71 
155 
.041 </p>
<p>Inferior frontal pars 
triangularis L 
-50 16 26 
4.65 </p>
<p>Inferior frontal pars 
opercularis L 
-58 10 22 
4.48 </p>
<p>Cuneus R 
18 -72 28 
4.34 
193 
.017 
-
22 -56 44 
4.13 
Superior occipital R 
24 -60 32 
3.94 </p>
<p>TABLE 2. </p>
<p>The comparison of sound-related verbs with pseudoverbs revealed activations in several brain areas including middle and superior temporal, occipital, inferior parietal, and inferior frontal cortex. Further activations were found in the cerebellum, the caudate nucleus, the putamen, and the insula (seeSupplementary Table 1). Compared with sound-related verbs, pseudoverbs elicited greater activations near the right calcarine sulcus. The comparison of action-related verbs with pseudoverbs also yielded activations in several brain regions compris-ing the middle and superior temporal, inferior frontal, inferior parietal, </p>
<p>and middle occipital cortex. Further activations were found in the cer-</p>
<p>ebellum, the caudate nucleus, the thalamus, the insula, the hippocam-</p>
<p>pus, and the cingulate cortex (see Supplementary Table 1). Compared </p>
<p>with action-related verbs, pseudoverbs elicited greater activation in the </p>
<dl>
<dt>left precentral gyrus (see Supplementary Table 1). </dt>
<dd>
<p>Our study suggests that conceptual processing depends on a hierarchy of neural circuits involving various levels of modality-specific or adjacent higher-level multimodal cortices supporting representation of action and sound features. Processing in these feature-specific neural circuits is most likely complemented by heteromodal semantic hub regions, which integrate distributed conceptual information.Action-related verbs vs. pseudoverbsSUPPLEMENTARY TABLE 1.Peak Activations for the Comparisons of Action-and Sound-Related Verbs with Pseudoverbs in the Lexical Decision TaskSUPPLEMENTARY MATERIAL </p>
</dd>
</dl>
<p>Brain region </p>
<p>MNI </p>
<p>Coordinates 
Peak T 
Cluster </p>
<p>size </p>
<p>Cluster p </p>
<p>(FWE-</p>
<p>corrected) </p>
<p>Sound-related vs. versus 
pseudoverbs </p>
<p>Caudate R </p>
<p>10 10 6 10.41 411 &lt; .0001 </p>
<p>Caudate L </p>
<p>−6 8 4 
8.76 </p>
<p>-</p>
<p>8 0 12 
6 </p>
<p>Middle occipital R </p>
<p>36 −90 6 10.3 1236 &lt; .0001 </p>
<p>Superior occipital R </p>
<p>26 −96 10 10.08 </p>
<p>Inferior occipital R </p>
<p>38 −82 −4 8.53 </p>
<p>Middle temporal L </p>
<p>−46 −60 10 9.51 290 &lt; .0001 </p>
<p>Middle temporal L </p>
<p>−48 −68 20 6.22 </p>
<p>Middle temporal L </p>
<p>−50 −52 18 6.1 </p>
<p>Anterior cingulate L </p>
<p>−2 16 26 8.74 2071 &lt; .0001 </p>
<p>Mid cingulate L </p>
<p>−6 −2 44 8.55 </p>
<p>Mid cingulate R </p>
<p>8 −26 46 
7.56 </p>
<p>Middle temporal R </p>
<p>52 −58 12 8.44 1299 &lt; .0001 </p>
<p>Rolandic operculum R </p>
<p>56 −24 22 8.15 </p>
<p>Superior temporal R </p>
<p>48 −44 16 
7.8 </p>
<p>Middle occipital L </p>
<p>−20 −92 6 8.41 306 &lt; .0001 </p>
<p>Middle temporal R </p>
<p>48 −16 −12 8.17 
97 &lt; .0001 </p>
<p>Superior temporal R </p>
<p>46 −6 −16 7.33 </p>
<p>Supramarginal L </p>
<p>−60 −42 30 7.75 158 &lt; .0001 </p>
<p>Supramarginal L </p>
<p>−62 −52 26 6.5 </p>
<p>Cerebellum R </p>
<p>38 −66 −42 7.26 142 &lt; .0001 </p>
<p>Cerebellum R </p>
<p>12 −48 −38 7.14 
37 &lt; .0001 
Inferior frontal pars triangularis R 60 20 10 
7.09 
87 &lt; .0001 
Inferior frontal pars opercularis R 54 8 18 
6.17 </p>
<p>Lingual L </p>
<p>−22 −74 −10 6.93 
39 &lt; .0001 </p>
<p>Fusiform L </p>
<p>−32 −46 −18 6.86 
44 &lt; .0001 </p>
<p>Cerebellum L </p>
<p>−10 −48 −42 6.5 
52 &lt; .0001 </p>
<p>Middle occipital L </p>
<p>−26 −60 38 6.47 
26 &lt; .0001 </p>
<p>Middle occipital L </p>
<p>−28 −68 38 5.79 </p>
<p>Insula L </p>
<p>−30 14 6 6.46 
28 &lt; .0001 </p>
<p>Fusiform R </p>
<p>34 −44 −18 6.45 
18 
.001 </p>
<p>Inferior parietal L </p>
<p>−52 −50 48 6.28 
40 &lt; .0001 </p>
<p>Postcentral L </p>
<p>−40 −18 48 6.25 
32 &lt; .0001 </p>
<p>Precentral L </p>
<p>−26 −28 62 6.24 
21 
.001 </p>
<p>Precuneus L </p>
<p>−10 −70 38 6.12 
18 
.001 </p>
<p>Precuneus R </p>
<p>16 −72 46 5.89 
23 &lt; .0001 </p>
<p>Pseudoverbs vs. sound-related verbs </p>
<p>-</p>
<p>32 −46 4 
8.79 
47 &lt; .0001 </p>
<p>Middle occipital R </p>
<p>28 −96 6 10.79 796 &lt; .0001 </p>
<p>Middle occipital R </p>
<p>36 −90 6 10.43 </p>
<p>Calcarine R </p>
<p>18 −96 −4 9.14 </p>
<p>Middle temporal L </p>
<p>−44 −62 10 9.82 724 &lt; .0001 </p>
<p>Middle temporal L </p>
<p>−50 −68 22 8.28 </p>
<p>Middle occipital L </p>
<p>−34 −68 32 6.25 </p>
<p>Mid cingulate L </p>
<p>−2 −2 34 8.85 2594 &lt; .0001 </p>
<p>Mid cingulate L </p>
<p>−6 −2 44 8.22 </p>
<p>Precuneus R </p>
<p>8 −44 58 
8.16 </p>
<p>Sound-related verbs versus pseudoverbs masked with the acoustic localizerPseudoverbs versus sound-related verbs masked with the acoustic localizerAction-related verbs versus pseudoverbs masked with the acoustic localizerPseudoverbs versus action-related verbs masked with the acoustic localizerSound-related verbs versus pseudoverbs masked with the motor localizerSUPPLEMENTARY TABLE 2. Peak Activations for the Comparisons of Action-and Sound-Related Verbs with Pseudoverbs in the Lexical Decision Task Inclusively Masked with the Functional LocalizationPseudoverbs versus sound-related verbs masked with the motor localizer Action-related verbs versus pseudoverbs masked with the motor localizerBrain region </p>
<p>MNI </p>
<p>Coordinates 
Peak T 
Cluster </p>
<p>size </p>
<p>Cluster p </p>
<p>(FWE-</p>
<p>corrected) </p>
<p>Supramarginal R </p>
<p>56 −24 24 8.34 1112 &lt; .0001 </p>
<p>Supramarginal R </p>
<p>56 −32 32 7.84 </p>
<p>Middle temporal R </p>
<p>50 −60 10 7.56 </p>
<p>Caudate R </p>
<p>10 10 6 
8.17 
85 &lt; .0001 </p>
<p>Middle occipital L </p>
<p>−24 −96 10 7.86 328 &lt; .0001 </p>
<p>Middle occipital L </p>
<p>−24 −90 −2 6.68 </p>
<p>Calcarine L </p>
<p>−12 −100 −4 6.37 </p>
<p>ParaHippocampal R </p>
<p>30 −32 −12 7.75 
54 &lt; .0001 </p>
<p>Middle temporal R </p>
<p>48 −16 −12 7.47 
34 &lt; .0001 </p>
<p>Cerebellum R </p>
<p>40 -66 -40 7.35 136 &lt; .0001 </p>
<p>Middle occipital R </p>
<p>34 −82 32 6.91 
77 &lt; .0001 </p>
<p>Calcarine L </p>
<p>−2 −62 10 6.87 111 &lt; .0001 </p>
<p>Precuneus L </p>
<p>−4 −50 10 6.31 </p>
<p>Fusiform R </p>
<p>34 −46 −18 6.72 
20 
.001 </p>
<p>Superior frontal L </p>
<p>−14 64 20 6.69 
43 &lt; .0001 </p>
<p>Superior frontal L </p>
<p>−14 56 16 5.97 </p>
<p>Superior medial L </p>
<p>-8 64 26 
5.81 </p>
<p>Fusiform L </p>
<p>−28 −42 −18 6.66 
53 &lt; .0001 </p>
<p>Fusiform L </p>
<p>−34 −50 −20 5.9 </p>
<p>Cerebellum L </p>
<p>12 −48 −40 6.65 
36 &lt; .0001 </p>
<p>Supramarginal L </p>
<p>−62 −52 28 6.64 
45 &lt; .0001 </p>
<p>Supramarginal L </p>
<p>−62 −42 32 6.16 </p>
<p>Lingual L </p>
<p>−22 −74 −10 6.41 
16 
.001 </p>
<p>Superior medial R </p>
<p>12 58 8 
6.41 
15 
.002 </p>
<p>Mid orbital R </p>
<p>4 50 −4 
6.4 
107 &lt; .0001 </p>
<p>Mid orbital L </p>
<p>−2 56 −8 6.06 </p>
<p>Precuneus R </p>
<p>14 -74 44 6.35 
59 &lt; .0001 </p>
<p>Middle temporal L </p>
<p>−60 −56 −2 6.34 
15 
.002 
Thalamus L 
−14 −32 4 6.28 
19 
.001 
Hippocampus R 
20 −34 −2 6.22 
19 
.001 
Cerebellum L 
−8 −50 −40 6.21 
25 &lt; .0001 
Cuneus L 
−14 −72 26 6.14 
24 &lt; .0001 
Caudate L 
−8 10 6 
6.14 
17 
.001 
Postcentral L 
−44 −18 46 6.05 
14 
.002 
Thalamus R 
14 −14 10 6.01 
15 
.002 
Middle frontal L 
−32 28 40 
6 
17 
.001 
Middle temporal R 
48 −68 22 
5.8 
11 
.003 
Pseudoverbs vs. action-
related verbs 
Precentral L 
−50 0 50 
7.45 
15 
.002 
Brain region 
MNI 
Coordinates 
Peak T 
Cluster 
size </p>
<p>Cluster p 
(FWE-
corrected) </p>
<p>Superior temporal R 
62 -42 16 
7.06 
21 
.001 </p>
<p>-</p>
<p>Superior temporal R 
62 -42 16 
7.13 
15 
.002 </p>
<p>-</p>
<p>Middle occipital R 
26 -96 8 
9.76 
299 
&lt; .0001 </p>
<p>Middle occipital R 
32 -86 6 
9.25 </p>
<p>Inferior occipital R 
38 -82 -4 
8.53 </p>
<p>Middle temporal L 
-46 -60 10 
9.51 
76 
&lt; .0001 </p>
<p>Anterior cingulate L 
-2 16 26 
8.74 
1190 
&lt; .0001 </p>
<p>Mid cingulate L 
-6 -2 44 
8.55 </p>
<p>Mid cingulate R 
8 -26 46 
7.56 </p>
<p>Caudate R 
12 10 2 
8.66 
24 
&lt; .0001 </p>
<p>Middle temporal R 
52 -58 10 
8.26 
703 
&lt; .0001 </p>
<p>Rolandic Operculum R 
54 -22 22 
7.86 </p>
<p>Superior temporal R 
48 -44 16 
7.8 </p>
<p>Middle occipital L 
-22 -94 4 
8.07 
108 
&lt; .0001 </p>
<p>Caudate L 
-8 6 6 
8.07 
27 
&lt; .0001 </p>
<p>Fusiform L 
-32 -46 -18 
6.86 
31 
&lt; .0001 </p>
<p>Insula L 
-30 14 6 
6.46 
28 
&lt; .0001 </p>
<p>Fusiform R 
34 -44 -18 
6.45 
12 
.003 </p>
<p>-
8 4 10 
6.26 
19 
.001 </p>
<p>Precuneus L 
-6 -52 62 
6.21 
16 
.001 </p>
<p>Precuneus R 
2 -54 62 
5.73 </p>
<p>Precuneus L 
-10 -70 38 
6.12 
13 
.002 </p>
<p>Brain region 
MNI 
Coordinates 
Peak T 
Cluster 
size </p>
<p>Cluster p 
(FWE-
corrected) </p>
<p>-</p>
<p>Middle occipital R 
26 -96 8 
10.1 
86 
&lt; .0001 </p>
<p>Calcarine R 
20 -94 -2 
8.69 </p>
<p>Middle temporal L 
-44 -62 10 
9.82 
83 
&lt; .0001 </p>
<p>Mid cingulate L 
-2 -2 34 
8.85 
1085 
&lt; .0001 </p>
<p>Mid cingulate L 
-6 -2 44 
8.22 </p>
<p>Paracentral R 
10 -36 50 
7.76 </p>
<p>Inferior occipital R 
38 -86 -4 
8.32 
128 
&lt; .0001 </p>
<p>Middle occipital R 
32 -86 6 
7.67 </p>
<p>Inferior temporal R 
44 -72 -8 
5.99 </p>
<p>Rolandic operculum R 
54 -22 22 
7.6 
55 
&lt; .0001 </p>
<p>Middle temporal R 
50 -60 10 
7.56 
368 
&lt; .0001 </p>
<p>Superior temporal R 
64 -44 16 
7.48 </p>
<p>Middle temporal R 
46 -46 18 
6.95 </p>
<p>Middle occipital L 
-22 -94 4 
7.21 
111 
&lt; .0001 </p>
<p>Inferior occipital L 
-20 -90 -4 
6.38 </p>
<p>Middle occipital L 
-14 -98 0 
5.86 </p>
<p>Fusiform R 
34 -46 -18 
6.72 
14 
.002 </p>
<p>Fusiform L 
-30 -44 -18 
6.37 
20 
.001 </p>
<p>Precuneus R 
6 -50 62 
6.32 
11 
.003 </p>
<p>Thalamus R 
14 -14 10 
6.01 
15 
.002 </p>
<p>• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
• volume 15(4) • 236-255
APPENDIX: STIMULUS LISTSSUPPLEMENTARY FIGURE 1.Activations for sound-related versus action-related verbs overlaid with activations obtained during the motor localizer. In order to determine the anatomical vicinity of activations during action execution/sound perception and conceptual processing, activations obtained during the functional localizer tasks were overlaid with activations obtained from the differential contrasts action-related versus sound-related verbs and sound-related versus action-related verbs, respectively. Overlapping activations are colored in yellow.Color range bars indicate T-scores. For sound versus action verbs, cluster p was set to &lt; .001 (uncorrected) at the voxel level and p &lt; .05 (FWE-corrected) at the cluster levelSUPPLEMENTARY FIGURE 2.Activations for sound-related verbs versus pseudoverbs and for action-related verbs versus pseudoverbs inclusively masked with the functional localizers. As masking analyses with the acoustic localizer only revealed common activations in the right hemisphere, to facilitate comparisons, this figure displays only right hemisphere activity for the masking analyses including the motor localizer. Left hemisphere activation in the masking analyses with the motor localizer can be found inSupplementary Table 2. Panel A: Soundrelated verbs versus pseudoverbs masked with the acoustic localizer. Panel B: Action-related verbs versus pseudoverbs masked with the acoustic localizer. Panel C: Sound-related verbs versus pseudoverbs masked with the motor localizer. Panel D: Action-related verbs versus pseudoverbs masked with the motor localizer. For the differential contrasts and the functional localizer tasks, the statistical threshold was set to p &lt; .05 FWE-corrected at the voxel level.
The architecture of cognition. J R Anderson, Lawrence Erlbaum Associates, IncHillsdale, NJAnderson, J. R. (1983). The architecture of cognition. Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.</p>
<p>The neuroscience of action semantics in neurodegenerative brain diseases. T H Bak, 10.1097/WCO.0000000000000039Current Opinion in Neurology. 26Bak, T. H. (2013). The neuroscience of action semantics in neuro- degenerative brain diseases. Current Opinion in Neurology, 26, 671-677. doi: 10.1097/WCO.0000000000000039</p>
<p>Clinical, imaging and pathological correlates of a hereditary deficit in verb and action processing. T H Bak, D Yancopoulou, P J Nestor, J H Xuereb, M G Spillantini, F Pulvermüller, J R Hodges, 10.1093/brain/awh701Brain. 129Bak, T. H., Yancopoulou, D., Nestor, P. J., Xuereb, J. H., Spillantini, M. G., Pulvermüller, F., &amp; Hodges, J. R. (2006). Clinical, imaging and pathological correlates of a hereditary deficit in verb and action processing. Brain, 129, 321-332. doi:10.1093/brain/awh701</p>
<p>. A Barros-Loscertales, J Gonzalez, F Pulvermüller, N Ventura-Campos, J C Bustamante, V Costumero, . . Avila, C , Barros-Loscertales, A., Gonzalez, J., Pulvermüller, F., Ventura- Campos, N., Bustamante, J. C., Costumero, V., . . . Avila, C. (2012).</p>
<p>Reading salt activates gustatory brain regions: fMRI evidence for semantic grounding in a novel sensory modality. 10.1093/cercor/bhr324Cerebral Cortex. 22Reading salt activates gustatory brain regions: fMRI evidence for semantic grounding in a novel sensory modality. Cerebral Cortex, 22, 2554-2563. doi: 10.1093/cercor/bhr324</p>
<p>Grounded cognition. L W Barsalou, 10.1146/annurev.psych.59.103006.093639Annual Review of Psychology. 59Barsalou, L. W. (2008). Grounded cognition. Annual Review of Psychology, 59, 617-645. doi: 10.1146/annurev. psych.59.103006.093639</p>
<p>Concepts are more than percepts: The case of action verbs. M Bedny, A Caramazza, E Grossman, A Pascual-Leone, R Saxe, doi: 10.1523/ Jneurosci.3039-08.2008Journal of Neuroscience. 28Bedny, M., Caramazza, A., Grossman, E., Pascual-Leone, A., &amp; Saxe, R. (2008). Concepts are more than percepts: The case of action verbs. Journal of Neuroscience, 28, 11347-11353. doi: 10.1523/ Jneurosci.3039-08.2008</p>
<p>Voiceselective areas in human auditory cortex. P Belin, R J Zatorre, P Lafaille, P Ahad, B Pike, 10.1038/35002078Nature. 403Belin, P., Zatorre, R. J., Lafaille, P., Ahad, P., &amp; Pike, B. (2000). Voice- selective areas in human auditory cortex. Nature, 403, 309-312. doi: 10.1038/35002078</p>
<p>In defense of abstract conceptual representations. J R Binder, 10.3758/s13423-015-0909-1Psychonomic Bulletin &amp; Review. 23Binder, J. R. (2016). In defense of abstract conceptual represen- tations. Psychonomic Bulletin &amp; Review, 23, 1096-1108. doi: 10.3758/s13423-015-0909-1</p>
<p>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. J R Binder, R H Desai, W W Graves, L L Conant, 10.1093/cercor/bhp055Cerebral Cortex. 19Binder, J. R., Desai, R. H., Graves, W. W., &amp; Conant, L. L. (2009). Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. Cerebral Cortex, 19, 2767-2796. doi: 10.1093/cercor/bhp055</p>
<p>Role of the cerebellum in visuomotor coordination. I. Delayed eye and arm initiation in patients with mild cerebellar ataxia. S H Brown, K R Kessler, H Hefter, J D Cooke, H J Freund, doi: 10.1007/ bf00230206Experimental Brain Research. 94Brown, S. H., Kessler, K. R., Hefter, H., Cooke, J. D., &amp; Freund, H. J. (1993). Role of the cerebellum in visuomotor coordination. I. Delayed eye and arm initiation in patients with mild cerebellar ataxia. Experimental Brain Research, 94, 478-488. doi: 10.1007/ bf00230206</p>
<p>Listening to action-related sentences modulates the activity of the motor system: A combined TMS and behavioral study. G Buccino, L Riggio, G Melli, F Binkofski, V Gallese, G Rizzolatti, 10.1016/j.cog-brainres.2005.02.020Cognitive Brain Research. 24Buccino, G., Riggio, L., Melli, G., Binkofski, F., Gallese, V., &amp; Rizzolatti, G. (2005). Listening to action-related sentences modulates the activity of the motor system: A combined TMS and behavioral study. Cognitive Brain Research, 24, 355-363. doi: 10.1016/j.cog- brainres.2005.02.020</p>
<p>Scanning silence: mental imagery of complex sounds. N Bunzeck, T Wuestenberg, K Lutz, H J Heinze, L Jancke, 10.1016/j.neuroim-age.2005.03.013NeuroImage. 26Bunzeck, N., Wuestenberg, T., Lutz, K., Heinze, H. J., &amp; Jancke, L. (2005). Scanning silence: mental imagery of complex sounds. NeuroImage, 26, 1119-1127. doi: 10.1016/j.neuroim- age.2005.03.013</p>
<p>Body-partspecific representations of semantic noun categories. F Carota, R Moseley, F Pulvermüller, doi: 10.1162/ jocn_a_00219Journal of Cognitive Neuroscience. 24Carota, F., Moseley, R., &amp; Pulvermüller, F. (2012). Body-part- specific representations of semantic noun categories. Journal of Cognitive Neuroscience, 24, 1492-1509. doi: 10.1162/ jocn_a_00219</p>
<p>Cortical regions associated with perceiving, naming and knowing about colors. L L Chao, A Martin, 10.1162/089892999563229Journal of Cognitive Neuroscience. 11Chao, L. L., &amp; Martin, A. (1999). Cortical regions associated with per- ceiving, naming and knowing about colors. Journal of Cognitive Neuroscience, 11, 25-35. doi: 10.1162/089892999563229</p>
<p>Representation of manipulable man-made objects in the dorsal stream. L L Chao, A Martin, 10.1006/nimg.2000.0635NeuroImage. 12Chao, L. L., &amp; Martin, A. (2000). Representation of manipulable man-made objects in the dorsal stream. NeuroImage, 12, 478- 484. doi: 10.1006/nimg.2000.0635</p>
<p>Disembodying cognition. A Chatterjee, 10.1515/LANGCOG.2010.004Language and Cognition. 2Chatterjee, A. (2010). Disembodying cognition. Language and Cognition, 2, 79-116. doi: 10.1515/LANGCOG.2010.004</p>
<p>Optimal experimental design for eventrelated fMRI. A M Dale, doi: 10.1002/ (SICI)1097-0193Human Brain Mapping. 82/3&lt;109::AID-HBM7&gt;3.0.CO;2-WDale, A. M. (1999). Optimal experimental design for event- related fMRI. Human Brain Mapping, 8, 109-114. doi: 10.1002/ (SICI)1097-0193(1999)8:2/3&lt;109::AID-HBM7&gt;3.0.CO;2-W</p>
<p>A neural basis for lexical retrieval. H Damasio, T J Grabowski, D Tranel, R D Hichwa, A R Damasio, 10.1038/380499a0Nature. 380Damasio, H., Grabowski, T. J., Tranel, D., Hichwa, R. D., &amp; Damasio, A. R. (1996). A neural basis for lexical retrieval. Nature, 380, 499-505. doi: 10.1038/380499a0</p>
<p>Embodied language in first-and secondlanguage speakers: Neural correlates of processing motor verbs. S De Grauwe, R M Willems, S A Rueschemeyer, K Lemhofer, H Schriefers, 10.1016/j.neuropsy-chologia.2014.02.003Neuropsychologia. 56De Grauwe, S., Willems, R. M., Rueschemeyer, S. A., Lemhofer, K., &amp; Schriefers, H. (2014). Embodied language in first-and second- language speakers: Neural correlates of processing motor verbs. Neuropsychologia, 56, 334-349. doi:10.1016/j.neuropsy- chologia.2014.02.003</p>
<p>The semantic interference effect in the picture-word paradigm: An event-related fMRI study employing overt responses. G I De Zubicaray, S J Wilson, K L Mcmahon, S Muthiah, 10.1002/hbm.1054Human Brain Mapping. 14de Zubicaray, G. I., Wilson, S. J., McMahon, K. L., &amp; Muthiah, S. (2001). The semantic interference effect in the picture-word paradigm: An event-related fMRI study employing overt responses. Human Brain Mapping, 14, 218-227. doi: 10.1002/hbm.1054</p>
<p>Is the motor system necessary for processing action and abstract emotion words? Evidence from focal brain lesions. F R Dreyer, D Frey, S Arana, S Von Saldern, T Picht, P Vajkoczy, F Pulvermüller, doi:10.3389/ Fpsyg.2015.01661Frontiers in Psychology. 6Dreyer, F. R., Frey, D., Arana, S., von Saldern, S., Picht, T., Vajkoczy, P., &amp; Pulvermüller, F. (2015). Is the motor system necessary for processing action and abstract emotion words? Evidence from focal brain lesions. Frontiers in Psychology, 6. doi:10.3389/ Fpsyg.2015.01661</p>
<p>Contextual effects on word perception and eye-movements during reading. S F Ehrlich, K Rayner, 10.1016/S0022-5371Journal of Verbal Learning and Verbal Behavior. 2081Ehrlich, S. F., &amp; Rayner, K. (1981). Contextual effects on word per- ception and eye-movements during reading. Journal of Verbal Learning and Verbal Behavior, 20, 641-655. doi:10.1016/S0022- 5371(81)90220-6</p>
<p>Assignment of functional activations to probabilistic cytoarchitectonic areas revisited. S B Eickhoff, T Paus, S Caspers, M H Grosbras, A C Evans, K Zilles, K Amunts, 10.1016/j.neuroimage.2007.03.060NeuroImage. 36Eickhoff, S. B., Paus, T., Caspers, S., Grosbras, M. H., Evans, A. C., Zilles, K., &amp; Amunts, K. (2007). Assignment of functional activations to probabilistic cytoarchitectonic areas revisited. NeuroImage, 36, 511-521. doi: 10.1016/j.neuroimage.2007.03.060</p>
<p>Cluster failure: Why fMRI inferences for spatial extent have inflated falsepositive rates. A Eklund, T E Nichols, H Knutsson, doi: 10.1073/ pnas.1602413113Proceedings of the National Academy of Sciences of the United States of America. the National Academy of Sciences of the United States of America113Eklund, A., Nichols, T. E., &amp; Knutsson, H. (2016). Cluster failure: Why fMRI inferences for spatial extent have inflated false- positive rates. Proceedings of the National Academy of Sciences of the United States of America, 113, 7900-7905. doi: 10.1073/ pnas.1602413113</p>
<p>. C Farrer, S H Frey, J D Van Horn, E Tunik, D Turk, S Inati, Farrer, C., Frey, S. H., Van Horn, J. D., Tunik, E., Turk, D., Inati, S., &amp; http://www.ac-psych.org</p>
<p>The angular gyrus computes action awareness representations. S T Grafton, doi: 10.1093/ cercor/bhm050Cerebral Cortex. 18Grafton, S. T. (2008). The angular gyrus computes action aware- ness representations. Cerebral Cortex, 18, 254-261. doi: 10.1093/ cercor/bhm050</p>
<p>Concept representation reflects multimodal abstraction: A framework for embodied semantics. L Fernandino, J R Binder, R H Desai, S L Pendl, C J Humphries, W L Gross, . . Seidenberg, M S , doi: 10.1093/ cercor/bhv020Cerebral Cortex. 26Fernandino, L., Binder, J. R., Desai, R. H., Pendl, S. L., Humphries, C. J., Gross, W. L., . . . Seidenberg, M. S. (2016). Concept repre- sentation reflects multimodal abstraction: A framework for em- bodied semantics. Cerebral Cortex, 26, 2018-2034. doi: 10.1093/ cercor/bhv020</p>
<p>Predicting brain activation patterns associated with individual lexical concepts based on five sensory-motor attributes. L Fernandino, C J Humphries, M S Seidenberg, W L Gross, L L Conant, J R Binder, 10.1016/j.neuropsychologia.2015.04.009Neuropsychologia. 76Fernandino, L., Humphries, C. J., Seidenberg, M. S., Gross, W. L., Conant, L. L., &amp; Binder, J. R. (2015). Predicting brain activation patterns associated with individual lexical concepts based on five sensory-motor attributes. Neuropsychologia, 76, 17-26. doi: 10.1016/j.neuropsychologia.2015.04.009</p>
<p>The brain's concepts: The role of the sensory-motor system in conceptual knowledge. V Gallese, G Lakoff, 10.1080/02643290442000310Cognitive Neuropsychology. 22Gallese, V., &amp; Lakoff, G. (2005). The brain's concepts: The role of the sensory-motor system in conceptual knowl- edge. Cognitive Neuropsychology, 22, 455-479. doi: 10.1080/02643290442000310</p>
<p>Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs. M Garagnani, F Pulvermüller, 10.1111/ejn.13145The European Journal of Neuroscience. 43Garagnani, M., &amp; Pulvermüller, F. (2016). Conceptual grounding of language in action and perception: a neurocomputational model of the emergence of category specificity and semantic hubs. The European Journal of Neuroscience, 43, 721-737. doi: 10.1111/ejn.13145</p>
<p>Words in motion: Motor-language coupling in Parkinson's disease. A M Garcia, A Ibanez, 10.2478/s13380-014-0218-6Translational Neuroscience. 5Garcia, A. M., &amp; Ibanez, A. (2014). Words in motion: Motor-language coupling in Parkinson's disease. Translational Neuroscience, 5, 152-159. doi: 10.2478/s13380-014-0218-6</p>
<p>Why nouns are learned before verbs: Linguistic relativity versus natural partitioning. D Gentner, Center for the Study of ReadingTechnical ReportGentner, D. (1982). Why nouns are learned before verbs: Linguistic relativity versus natural partitioning. Center for the Study of Reading Technical Report, no. 257.</p>
<p>Visuomotor coordination in reaching and locomotion. A P Georgopoulos, S Grillner, 10.1126/science.2675307Science. 245Georgopoulos, A. P., &amp; Grillner, S. (1989, September). Visuomotor coordination in reaching and locomotion. Science, 245, 1209- 1210. doi: 10.1126/science.2675307</p>
<p>Grounding language in action. A M Glenberg, M P Kaschak, doi: 10.3758/ BF03196313Psychonomic Bulletin &amp; Review. 9Glenberg, A. M., &amp; Kaschak, M. P. (2002). Grounding language in action. Psychonomic Bulletin &amp; Review, 9, 558-565. doi: 10.3758/ BF03196313</p>
<p>How are visual areas of the brain connected to motor areas for the sensory guidance of movement?. M Glickstein, 10.1016/S0166-2236(00)01681-7Trends in Neurosciences. 23Glickstein, M. (2000). How are visual areas of the brain connected to motor areas for the sensory guidance of movement? Trends in Neurosciences, 23, 613-617. doi: 10.1016/S0166-2236(00)01681-7</p>
<p>Reading cinnamon activates olfactory brain regions. J Gonzalez, A Barros-Loscertales, F Pulvermüller, V Meseguer, A Sanjuan, V Belloch, C Avila, 10.1016/j.neuroimage.2006.03.037NeuroImage. 32Gonzalez, J., Barros-Loscertales, A., Pulvermüller, F., Meseguer, V., Sanjuan, A., Belloch, V., &amp; Avila, C. (2006). Reading cinnamon activates olfactory brain regions. NeuroImage, 32, 906-912. doi: 10.1016/j.neuroimage.2006.03.037</p>
<p>Somatotopic representation of action words in human motor and premotor cortex. O Hauk, I Johnsrude, F Pulvermüller, Hauk, O., Johnsrude, I., &amp; Pulvermüller, F. (2004). Somatotopic repre- sentation of action words in human motor and premotor cortex.</p>
<p>. 10.1016/S0896-6273(03)00838-9Neuron. 41Neuron, 41, 301-307. doi: 10.1016/S0896-6273(03)00838-9</p>
<p>Neuroplasticity of semantic maps for musical instruments in professional musicians. K Hoenig, C Müller, B Herrnberger, M Spitzer, G Ehret, M Kiefer, 10.1016/j.neuroimage.2011.02.065NeuroImage. 56Hoenig, K., Müller, C., Herrnberger, B., Spitzer, M., Ehret, G., &amp; Kiefer, M. (2011). Neuroplasticity of semantic maps for musical instru- ments in professional musicians. NeuroImage, 56, 1714-1725. doi: 10.1016/j.neuroimage.2011.02.065</p>
<p>. K Hoenig, E.-J Sim, V Bochev, B Herrnberger, M Kiefer, Hoenig, K., Sim, E.-J., Bochev, V., Herrnberger, B., &amp; Kiefer, M. (2008).</p>
<p>Conceptual flexibility in the human brain: Dynamic recruitment of semantic maps from visual, motion and motor-related areas. 10.1162/jocn.2008.20123Journal of Cognitive Neuroscience. 20Conceptual flexibility in the human brain: Dynamic recruitment of seman- tic maps from visual, motion and motor-related areas. Journal of Cognitive Neuroscience, 20, 1799-1814. doi: 10.1162/jocn.2008.20123</p>
<p>Hierarchies, similarity, and interactivity in object recognition. G W Humphreys, E M E Forde, Behavioral and Brain Sciences. 24Category-specific" neuropsychological deficitsHumphreys, G. W., &amp; Forde, E. M. E. (2001). Hierarchies, similar- ity, and interactivity in object recognition: "Category-specific" neuropsychological deficits. Behavioral and Brain Sciences, 24, 453-509.</p>
<p>From objects to names: A cognitive neuroscience approach. G W Humphreys, C J Price, M J Riddoch, 10.1007/s004260050046Psychological Research. 62Humphreys, G. W., Price, C. J., &amp; Riddoch, M. J. (1999). From objects to names: A cognitive neuroscience approach. Psychological Research, 62, 118-130. doi: 10.1007/s004260050046</p>
<p>Auditory and action semantic features activate sensory-specific perceptual brain regions. T W James, I Gauthier, 10.1016/j.cub.2003.09.039Current Biology. 13James, T. W., &amp; Gauthier, I. (2003). Auditory and action semantic fea- tures activate sensory-specific perceptual brain regions. Current Biology, 13, 1792-1796. doi: 10.1016/j.cub.2003.09.039</p>
<p>. M Jeannerod, M A Arbib, G Rizzolatti, H Sakata, Jeannerod, M., Arbib, M. A., Rizzolatti, G., &amp; Sakata, H. (1995).</p>
<p>Grasping objects: The cortical mechanisms of visuomotor transformation. 10.1016/0166-2236(95)93921-JTrends in Neurosciences. 18Grasping objects: The cortical mechanisms of visuomotor transformation. Trends in Neurosciences, 18, 314-320. doi: 10.1016/0166-2236(95)93921-J</p>
<p>Eye-hand coordination in object manipulation. R S Johansson, G Westling, A Backstrom, J R Flanagan, doi: 10.1523/ JNEUROSCI.21-17-06917.2001Journal of Neuroscience. 21Johansson, R. S., Westling, G., Backstrom, A., &amp; Flanagan, J. R. (2001). Eye-hand coordination in object manipula- tion. Journal of Neuroscience, 21, 6917-6932. doi: 10.1523/ JNEUROSCI.21-17-06917.2001</p>
<p>The place of perception in children's concepts. S S Jones, L B Smith, 10.1016/0885-2014(93)90008-SCognitive Development. 8Jones, S. S., &amp; Smith, L. B. (1993). The place of perception in children's concepts. Cognitive Development, 8, 113-139. doi: 10.1016/0885-2014(93)90008-S</p>
<p>Large, colorful, or noisy? Attribute-and modality-specific activations during retrieval of perceptual attribute knowledge. M L Kellenbach, M Brett, K Patterson, 10.3758/CABN.1.3.207Cognitive, Affective &amp; Behavioral Neuroscience. 1Kellenbach, M. L., Brett, M., &amp; Patterson, K. (2001). Large, colorful, or noisy? Attribute-and modality-specific activations during retrieval of perceptual attribute knowledge. Cognitive, Affective &amp; Behavioral Neuroscience, 1, 207-221. doi: 10.3758/CABN.1.3.207</p>
<p>Are the motor features of verb meanings represented in the precentral motor cortices? Yes, but within the context of a flexible, multilevel architecture for conceptual knowledge. D Kemmerer, 10.3758/s13423-014-0784-1Psychonomic Bulletin &amp; Review. 22Kemmerer, D. (2015). Are the motor features of verb meanings represented in the precentral motor cortices? Yes, but within the context of a flexible, multilevel architecture for conceptual knowledge. Psychonomic Bulletin &amp; Review, 22, 1068-1075. doi: 10.3758/s13423-014-0784-1</p>
<p>Neuroanatomical distribution of five semantic components of verbs: Evidence from fMRI. D Kemmerer, J G Castillo, T Talavage, S Patterson, C Wiley, 10.1016/j.bandl.2007.09.003Brain and Language. 107Kemmerer, D., Castillo, J. G., Talavage, T., Patterson, S., &amp; Wiley, C. (2008). Neuroanatomical distribution of five semantic compo- nents of verbs: Evidence from fMRI. Brain and Language, 107, 16-43. doi: 10.1016/j.bandl.2007.09.003</p>
<p>Behavioral patterns and lesion sites associated with impaired processing of lexical and conceptual knowledge of actions. D Kemmerer, D Rudrauf, K Manzel, D Tranel, 10.1016/j.cortex.2010.11.001Cortex. 48Kemmerer, D., Rudrauf, D., Manzel, K., &amp; Tranel, D. (2012). Behavioral patterns and lesion sites associated with impaired processing of lexical and conceptual knowledge of actions. Cortex, 48, 826- 848. doi: 10.1016/j.cortex.2010.11.001</p>
<p>Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions. M Kiefer, F Pulvermüller, 10.1016/j.cor-tex.2011.04.006Cortex. 48Kiefer, M., &amp; Pulvermüller, F. (2012). Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions. Cortex, 48, 805-825. doi: 10.1016/j.cor- tex.2011.04.006</p>
<p>The sound of concepts: Four markers for a link between auditory and conceptual brain systems. M Kiefer, E.-J Sim, B Herrnberger, J Grothe, K Hoenig, 10.1523/JNEUROSCI.3579-08.2008The Journal of Neuroscience. 28Kiefer, M., Sim, E.-J., Herrnberger, B., Grothe, J., &amp; Hoenig, K. (2008). The sound of concepts: Four markers for a link between audi- tory and conceptual brain systems. The Journal of Neuroscience, 28, 12224-12230. doi: 10.1523/JNEUROSCI.3579-08.2008</p>
<p>Dissociating the representation of action-and sound-related concepts in middle temporal cortex. M Kiefer, N M Trumpp, B Herrnberger, E.-J Sim, K Hoenig, F Pulvermüller, doi: 10.1016/j. bandl.2012.05.007Brain and Language. 122Kiefer, M., Trumpp, N. M., Herrnberger, B., Sim, E.-J., Hoenig, K., &amp; Pulvermüller, F. (2012). Dissociating the representation of action-and sound-related concepts in middle temporal cortex. Brain and Language, 122, 120-125. doi: 10.1016/j. bandl.2012.05.007</p>
<p>. J H Kim, J M Lee, H J Jo, S H Kim, J H Lee, S T Kim, . . Saad, Kim, J. H., Lee, J. M., Jo, H. J., Kim, S. H., Lee, J. H., Kim, S. T., . . . Saad, http://www.ac-psych.org</p>
<p>Defining functional SMA and pre-SMA subregions in human MFC using resting state fMRI: Functional connectivity-based parcellation method. Z S , 10.1016/j.neuroimage.2009.10.016NeuroImage. 49Z. S. (2010). Defining functional SMA and pre-SMA subregions in human MFC using resting state fMRI: Functional connectivi- ty-based parcellation method. NeuroImage, 49, 2375-2386. doi: 10.1016/j.neuroimage.2009.10.016</p>
<p>Body-part specific interactions of action verb processing with motor behaviour. A Klepp, V Niccolai, J Sieksmeyer, S Arnzen, P Indefrey, A Schnitzler, K Biermann-Ruben, Klepp, A., Niccolai, V., Sieksmeyer, J., Arnzen, S., Indefrey, P., Schnitzler, A., &amp; Biermann-Ruben, K. (2017). Body-part specific interactions of action verb processing with motor behaviour.</p>
<p>. doi: 10.1016/j. bbr.2017.04.002Behavioural Brain Research. 328Behavioural Brain Research, 328, 149-158. doi: 10.1016/j. bbr.2017.04.002</p>
<p>Psycholinguistics electrified. M Kutas, C K Van Petten, Handbook of psycholinguistics. M. A. GernsbacherNew YorkAcademic PressKutas, M., &amp; Van Petten, C. K. (1994). Psycholinguistics electrified. In M. A. Gernsbacher (Ed.), Handbook of psycholinguistics (pp. 83-143). New York: Academic Press.</p>
<p>The neural and computational bases of semantic cognition. Lambon Ralph, M A Jefferies, E Patterson, K Rogers, T T , doi: 10.1038/ nrn.2016.150Nature Reviews Neuroscience. 18Lambon Ralph, M. A., Jefferies, E., Patterson, K., &amp; Rogers, T. T. (2017). The neural and computational bases of semantic cog- nition. Nature Reviews Neuroscience, 18, 42-55. doi: 10.1038/ nrn.2016.150</p>
<p>Cortical representation of natural complex sounds: Effects of acoustic features and auditory object category. A M Leaver, J P Rauschecker, 10.1523/JNEUROSCI.0296-10.2010Journal of Neuroscience. 30Leaver, A. M., &amp; Rauschecker, J. P. (2010). Cortical representation of natural complex sounds: Effects of acoustic features and audi- tory object category. Journal of Neuroscience, 30, 7604-7612. doi: 10.1523/JNEUROSCI.0296-10.2010</p>
<p>Who's that knocking at my door? Neural bases of sound source identification. G Lemaitre, J A Pyles, A R Halpern, N Navolio, M Lehet, L M Heller, 10.1093/cercor/bhw397Cerebral Cortex. 28Lemaitre, G., Pyles, J. A., Halpern, A. R., Navolio, N., Lehet, M., &amp; Heller, L. M. (2018). Who's that knocking at my door? Neural bas- es of sound source identification. Cerebral Cortex, 28, 805-818. doi: 10.1093/cercor/bhw397</p>
<p>Human brain regions involved in recognizing environmental sounds. J W Lewis, F L Wightman, J A Brefczynski, R E Phinney, J R Binder, E A Deyoe, 10.1093/cercor/bhh061Cerebral Cortex. 14Lewis, J. W., Wightman, F. L., Brefczynski, J. A., Phinney, R. E., Binder, J. R., &amp; DeYoe, E. A. (2004). Human brain regions involved in rec- ognizing environmental sounds. Cerebral Cortex, 14, 1008-1021. doi: 10.1093/cercor/bhh061</p>
<p>Subregions of the human superior frontal gyrus and their connections. W Li, W Qin, H Liu, L Fan, J Wang, T Jiang, C Yu, 10.1016/j.neuroim-age.2013.04.011NeuroImage. 78Li, W., Qin, W., Liu, H., Fan, L., Wang, J., Jiang, T., &amp; Yu, C. (2013). Subregions of the human superior frontal gyrus and their connections. NeuroImage, 78, 46-58. doi: 10.1016/j.neuroim- age.2013.04.011</p>
<p>. M Lotze, P Montoya, M Erb, E Hulsmann, H Flor, U Klose, Lotze, M., Montoya, P., Erb, M., Hulsmann, E., Flor, H., Klose, U., . . .</p>
<p>Activation of cortical and cerebellar motor areas during executed and imagined hand movements: An fMRI study. W Grodd, 10.1162/089892999563553Journal of Cognitive Neuroscience. 11Grodd, W. (1999). Activation of cortical and cerebellar motor areas during executed and imagined hand movements: An fMRI study. Journal of Cognitive Neuroscience, 11, 491-501. doi: 10.1162/089892999563553</p>
<p>Concept empiricism: A methodological critique. E Machery, Machery, E. (2007). Concept empiricism: A methodological critique.</p>
<p>. 10.1016/j.cognition.2006.05.002Cognition. 104Cognition, 104, 19-46. doi: 10.1016/j.cognition.2006.05.002</p>
<p>Category-specific organization in the human brain does not require visual experience. B Z Mahon, S Anzellotti, J Schwarzbach, M Zampini, A Caramazza, 10.1016/j.neuron.2009.07.012Neuron. 63Mahon, B. Z., Anzellotti, S., Schwarzbach, J., Zampini, M., &amp; Caramazza, A. (2009). Category-specific organization in the human brain does not require visual experience. Neuron, 63, 397-405. doi: 10.1016/j.neuron.2009.07.012</p>
<p>Constraining questions about the organisation and representation of conceptual knowledge. B Z Mahon, A Caramazza, 10.1080/02643290342000014Cognitive Neuropsychology. 20Mahon, B. Z., &amp; Caramazza, A. (2003). Constraining questions about the organisation and representation of concep- tual knowledge. Cognitive Neuropsychology, 20, 433-450. doi: 10.1080/02643290342000014</p>
<p>The representation of object concepts in the brain. A Martin, 10.1146/an-nurev.psych.57.102904.190143Annual Review of Psychology. 58Martin, A. (2007). The representation of object concepts in the brain. Annual Review of Psychology, 58, 25-45. doi: 10.1146/an- nurev.psych.57.102904.190143</p>
<p>Semantic memory and the brain: Structure and processes. A Martin, L L Chao, 10.1016/S0959-4388(00)00196-3Current Opinion in Neurobiology. 11Martin, A., &amp; Chao, L. L. (2001). Semantic memory and the brain: Structure and processes. Current Opinion in Neurobiology, 11, 194-201. doi: 10.1016/S0959-4388(00)00196-3</p>
<p>The parallel distributed processing approach to semantic cognition. J L Mcclelland, T T Rogers, 10.1038/nrn1076Nature Reviews Neuroscience. 4McClelland, J. L., &amp; Rogers, T. T. (2003). The parallel distributed processing approach to semantic cognition. Nature Reviews Neuroscience, 4, 310-322. doi: 10.1038/nrn1076</p>
<p>Coming of age: A review of embodiment and the neuroscience of semantics. L Meteyard, S R Cuadrado, B Bahrami, G Vigliocco, 10.1016/j.cor-tex.2010.11.002Cortex. 48Meteyard, L., Cuadrado, S. R., Bahrami, B., &amp; Vigliocco, G. (2012). Coming of age: A review of embodiment and the neurosci- ence of semantics. Cortex, 48, 788-804. doi: 10.1016/j.cor- tex.2010.11.002</p>
<p>Nouns, verbs, objects, actions, and abstractions: Local fMRI activity indexes semantics, not lexical categories. R L Moseley, F Pulvermüller, 10.1016/j.bandl.2014.03.001Brain and Language. 132Moseley, R. L., &amp; Pulvermüller, F. (2014). Nouns, verbs, objects, ac- tions, and abstractions: Local fMRI activity indexes semantics, not lexical categories. Brain and Language, 132, 28-42. doi: 10.1016/j.bandl.2014.03.001</p>
<p>Word-category specific deficits after lesions in the right hemisphere. B Neininger, F Pulvermüller, 10.1016/S0028-3932(02)00126-4Neuropsychologia. 41Neininger, B., &amp; Pulvermüller, F. (2003). Word-category specific deficits after lesions in the right hemisphere. Neuropsychologia, 41, 53-70. doi: 10.1016/S0028-3932(02)00126-4</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, P J Nestor, T T Rogers, 10.1038/nrn2277Nature Reviews Neuroscience. 8Patterson, K., Nestor, P. J., &amp; Rogers, T. T. (2007). Where do you know what you know? The representation of semantic knowledge in the human brain. Nature Reviews Neuroscience, 8, 976-987. doi: 10.1038/nrn2277</p>
<p>Tool selectivity in left occipitotemporal cortex develops without vision. M V Peelen, S Bracci, X Lu, C He, A Caramazza, Y Bi, 10.1162/jocn_a_00411Journal of Cognitive Neuroscience. 25Peelen, M. V., Bracci, S., Lu, X., He, C., Caramazza, A., &amp; Bi, Y. (2013). Tool selectivity in left occipitotemporal cortex develops with- out vision. Journal of Cognitive Neuroscience, 25, 1225-1234. doi: 10.1162/jocn_a_00411</p>
<p>Feature-specific eventrelated potential effects to action-and sound-related verbs during visual word recognition. M Popp, N M Trumpp, M Kiefer, 10.3389/fnhum.2016.00637Frontiers in Human Neuroscience. 10637Popp, M., Trumpp, N. M., &amp; Kiefer, M. (2016). Feature-specific event- related potential effects to action-and sound-related verbs dur- ing visual word recognition. Frontiers in Human Neuroscience, 10, 637. doi: 10.3389/fnhum.2016.00637</p>
<p>Processing of action and sound verbs in context: An fMRI study. M Popp, N M Trumpp, M Kiefer, Translational Neuroscience. in pressPopp, M., Trumpp, N. M., &amp; Kiefer, M. (in press). Processing of ac- tion and sound verbs in context: An fMRI study. Translational Neuroscience.</p>
<p>Brain reflections of words and their meaning. F Pulvermüller, 10.1016/S1364-6613(00Trends in Cognitive Sciences. 5Pulvermüller, F. (2001). Brain reflections of words and their mean- ing. Trends in Cognitive Sciences, 5, 517-524. doi: 10.1016/S1364- 6613(00)01803-9</p>
<p>Neurobiological mechanisms for semantic feature extraction and conceptual flexibility. F Pulvermüller, 10.1111/tops.12367Topics in Cognitive Science. 10Pulvermüller, F. (2018). Neurobiological mechanisms for semantic feature extraction and conceptual flexibility. Topics in Cognitive Science, 10, 590-620. doi: 10.1111/tops.12367</p>
<p>The word processing deficit in Semantic Dementia: All categories are equal but some categories are more equal than others. F Pulvermüller, E Cooper-Pye, C Dine, O Hauk, P Nestor, K Patterson, 10.1162/jocn.2009.21339Journal of Cognitive Neuroscience. 22Pulvermüller, F., Cooper-Pye, E., Dine, C., Hauk, O., Nestor, P., &amp; Patterson, K. (2010). The word processing deficit in Semantic Dementia: All categories are equal but some categories are more equal than others. Journal of Cognitive Neuroscience, 22, 2027-2041. doi: 10.1162/jocn.2009.21339</p>
<p>Active perception: Sensorimotor circuits as a cortical basis for language. F Pulvermüller, L Fadiga, 10.1038/nrn2811Nature Reviews Neuroscience. 11Pulvermüller, F., &amp; Fadiga, L. (2010). Active perception: Sensorimotor circuits as a cortical basis for language. Nature Reviews Neuroscience, 11, 351-360. doi: 10.1038/nrn2811</p>
<p>Functional links between motor and language systems. F Pulvermüller, O Hauk, V V Nikulin, R J Ilmoniemi, 10.1111/j.1460-9568.2005.03900.xEuropean Journal of Neuroscience. 21Pulvermüller, F., Hauk, O., Nikulin, V. V., &amp; Ilmoniemi, R. J. (2005). Functional links between motor and language sys- tems. European Journal of Neuroscience, 21, 793-797. doi: 10.1111/j.1460-9568.2005.03900.x</p>
<p>Nouns and verbs in the intact brain: Evidence from event-related potentials and high-frequency cortical responses. F Pulvermüller, W Lutzenberger, H Preissl, 10.1093/cercor/9.5.497Cerebral Cortex. 9Pulvermüller, F., Lutzenberger, W., &amp; Preissl, H. (1999). Nouns and verbs in the intact brain: Evidence from event-related poten- tials and high-frequency cortical responses. Cerebral Cortex, 9, 497-506. doi: 10.1093/cercor/9.5.497</p>
<p>Computation and cognition: Issues in the foundation of cognitive science. Z W Pylyshyn, 10.1017/S0140525X00002053Behavioral and Brain Sciences. 3Pylyshyn, Z. W. (1980). Computation and cognition: Issues in the foundation of cognitive science. Behavioral and Brain Sciences, 3, 111-132. doi: 10.1017/S0140525X00002053</p>
<p>. S A Rueschemeyer, M Ekman, M Van Ackeren, J Kilner, Rueschemeyer, S. A., Ekman, M., van Ackeren, M., &amp; Kilner, J. (2014).</p>
<p>Observing, performing, and understanding actions: Revisiting the role of cortical motor areas in processing of action words. doi: 10.1162/ jocn_a_00576Journal of Cognitive Neuroscience. 26Observing, performing, and understanding actions: Revisiting the role of cortical motor areas in processing of action words. Journal of Cognitive Neuroscience, 26, 1644-1653. doi: 10.1162/ jocn_a_00576</p>
<p>Body schematics: On the role of the body schema in embodied lexicalsemantic representations. S A Rueschemeyer, C Pfeiffer, H Bekkering, 10.1016/j.neuropsychologia.2009.09.019Neuropsychologia. 48Rueschemeyer, S. A., Pfeiffer, C., &amp; Bekkering, H. (2010). Body sche- matics: On the role of the body schema in embodied lexical- semantic representations. Neuropsychologia, 48, 774-781. doi: 10.1016/j.neuropsychologia.2009.09.019</p>
<p>The function of words: Distinct neural correlates for words denoting differently manipulable objects. S A Rueschemeyer, D Van Rooij, O Lindemann, R M Willems, H Bekkering, doi: 10.1162/ jocn.2009.21310Journal of Cognitive Neuroscience. 22Rueschemeyer, S. A., van Rooij, D., Lindemann, O., Willems, R. M., &amp; Bekkering, H. (2010). The function of words: Distinct neural correlates for words denoting differently manipulable objects. Journal of Cognitive Neuroscience, 22, 1844-1851. doi: 10.1162/ jocn.2009.21310</p>
<p>Task related modulation of the motor system during language processing. M Sato, M Mengarelli, L Riggio, V Gallese, G Buccino, doi: 10.1016/j. bandl.2007.10.001Brain and Language. 105Sato, M., Mengarelli, M., Riggio, L., Gallese, V., &amp; Buccino, G. (2008). Task related modulation of the motor system during language processing. Brain and Language, 105, 83-90. doi: 10.1016/j. bandl.2007.10.001</p>
<p>Is the sensorimotor cortex relevant for speech perception and understanding? An integrative review. M R Schomers, F Pulvermüller, 10.3389/Fnhum.2016.00435Frontiers in Human Neuroscience. 10Schomers, M. R., &amp; Pulvermüller, F. (2016). Is the sensorimotor cortex relevant for speech perception and understanding? An integrative review. Frontiers in Human Neuroscience, 10. doi: 10.3389/Fnhum.2016.00435</p>
<p>The organization of local and distant functional connectivity in the human brain. J Sepulcre, H Liu, T Talukdar, I Martincorena, B T Yeo, R L Buckner, 10.1371/journal.pcbi.1000808PLoS Computational Biology. 61000808Sepulcre, J., Liu, H., Talukdar, T., Martincorena, I., Yeo, B. T., &amp; Buckner, R. L. (2010). The organization of local and distant func- tional connectivity in the human brain. PLoS Computational Biology, 6, e1000808. doi: 10.1371/journal.pcbi.1000808</p>
<p>Conceptual information about size of objects in nouns. A Setti, N Caramelli, A M Borghi, 10.1080/09541440802469499European Journal of Cognitive Psychology. 21Setti, A., Caramelli, N., &amp; Borghi, A. M. (2009). Conceptual informa- tion about size of objects in nouns. European Journal of Cognitive Psychology, 21, 1022-1044. doi: 10.1080/09541440802469499</p>
<p>The representation of grammatical categories in the brain. K Shapiro, A Caramazza, 10.1016/S1364-6613(03)00060-3Trends in Cognitive Sciences. 7Shapiro, K., &amp; Caramazza, A. (2003). The representation of gram- matical categories in the brain. Trends in Cognitive Sciences, 7, 201-206. doi: 10.1016/S1364-6613(03)00060-3</p>
<p>Moving the hands and feet specifically impairs working memory for arm-and legrelated action words. Z Shebani, F Pulvermüller, 10.1016/j.cor-tex.2011.10.005Cortex. 49Shebani, Z., &amp; Pulvermüller, F. (2013). Moving the hands and feet specifically impairs working memory for arm-and leg- related action words. Cortex, 49, 222-231. doi: 10.1016/j.cor- tex.2011.10.005</p>
<p>The similarity-intopography principle: Reconciling theories of conceptual deficits. W K Simmons, L W Barsalou, 10.1080/02643290342000032Cognitive Neuropsychology. 20Simmons, W. K., &amp; Barsalou, L. W. (2003). The similarity-in- topography principle: Reconciling theories of concep- tual deficits. Cognitive Neuropsychology, 20, 451-486. doi: 10.1080/02643290342000032</p>
<p>fMRI evidence for word association and situated simulation in conceptual processing. W K Simmons, S B Hamann, C L Harenski, X P Hu, L W Barsalou, 10.1016/j.jphysparis.2008.03.014Journal of Physiology. 102Simmons, W. K., Hamann, S. B., Harenski, C. L., Hu, X. P., &amp; Barsalou, L. W. (2008). fMRI evidence for word association and situated simulation in conceptual processing. Journal of Physiology, 102, 106-119. doi: 10.1016/j.jphysparis.2008.03.014</p>
<p>A common neural substrate for perceiving and knowing about color. W K Simmons, V Ramjee, M S Beauchamp, K Mcrae, A Martin, L W Barsalou, 10.1016/j.neuropsychologia.2007.05.002Neuropsychologia. 45Simmons, W. K., Ramjee, V., Beauchamp, M. S., McRae, K., Martin, A., &amp; Barsalou, L. W. (2007). A common neural substrate for perceiv- ing and knowing about color. Neuropsychologia, 45, 2802-2810. doi: 10.1016/j.neuropsychologia.2007.05.002</p>
<p>. E Striem-Amit, G Vannuscorps, A Caramazza, Striem-Amit, E., Vannuscorps, G., &amp; Caramazza, A. (2017).</p>
<p>Sensorimotor-independent development of hands and tools selectivity in the visual cortex. 10.1073/pnas.1620289114Proceedings of the National Academy of Sciences of the United States of America. the National Academy of Sciences of the United States of America114Sensorimotor-independent development of hands and tools selectivity in the visual cortex. Proceedings of the National Academy of Sciences of the United States of America, 114, 4787- 4792. doi: 10.1073/pnas.1620289114</p>
<p>Losing the sound of concepts: Damage to auditory association cortex impairs the processing of sound. N M Trumpp, D Kliese, K Hoenig, T Haarmaier, M Kiefer, related conceptsTrumpp, N. M., Kliese, D., Hoenig, K., Haarmaier, T., &amp; Kiefer, M. (2013). Losing the sound of concepts: Damage to auditory asso- ciation cortex impairs the processing of sound-related concepts.</p>
<p>. doi.10.1016/j.cortex.2012.02.002Cortex. 49Cortex, 49, 474-486. doi. 10.1016/j.cortex.2012.02.002</p>
<p>Masked priming of conceptual features reveals differential brain activation during unconscious access to conceptual action and sound information. N M Trumpp, F Traub, M Kiefer, Trumpp, N. M., Traub, F., &amp; Kiefer, M. (2013). Masked priming of conceptual features reveals differential brain activation during unconscious access to conceptual action and sound information.</p>
<p>. 65910.61371/journal.pone.0065910PLoS ONE. 865910PLoS ONE 8, e65910. doi: 65910.61371/journal.pone.0065910.</p>
<p>Unconscious automatic brain activation of acoustic and actionrelated conceptual features during masked repetition priming. N M Trumpp, F Traub, F Pulvermüller, M Kiefer, doi: 10.1162/ jocn_a_00473Journal of Cognitive Neuroscience. 26Trumpp, N. M., Traub, F., Pulvermüller, F., &amp; Kiefer, M. (2014). Unconscious automatic brain activation of acoustic and action- related conceptual features during masked repetition priming. Journal of Cognitive Neuroscience, 26, 352-364. doi: 10.1162/ jocn_a_00473</p>
<p>Episodic and semantic memory. E Tulving, Organization of memory. E. Tulving &amp; W. DonaldsonTulving, E. (1972). Episodic and semantic memory. In E. Tulving &amp; W. Donaldson (Eds.), Organization of memory (pp. 381-403).</p>
<p>Flexibility in embodied lexical-semantic representations. L K Tyler, H E. ; W O Moss, M Van Dijk, H Bekkering, S A Rueschemeyer, 10.1016/S1364-6613(00)01651-XvanDamdoi: 10.1002/ hbm.21365Trends in Cognitive Sciences. 5Human Brain MappingTyler, L. K., &amp; Moss, H. E. (2001). Towards a distributed account of conceptual knowledge. Trends in Cognitive Sciences, 5, 244-252. doi: 10.1016/S1364-6613(00)01651-X van Dam, W. O., van Dijk, M., Bekkering, H., &amp; Rueschemeyer, S. A. (2012). Flexibility in embodied lexical-semantic represen- tations. Human Brain Mapping, 33, 2322-2333. doi: 10.1002/ hbm.21365</p>
<p>Sensory load incurs conceptual processing costs. N Vermeulen, O Corneille, P M Niedenthal, 10.1016/j.cognition.2008.09.004Cognition. 109Vermeulen, N., Corneille, O., &amp; Niedenthal, P. M. (2008). Sensory load incurs conceptual processing costs. Cognition, 109, 287- 294. doi: 10.1016/j.cognition.2008.09.004</p>
<p>Semantic processing in the anterior temporal lobes: A meta-analysis of the functional neuroimaging literature. M Visser, E Jefferies, M A Ralph, 10.1162/jocn.2009.21309Journal of Cognitive Neuroscience. 22Visser, M., Jefferies, E., &amp; Lambon Ralph, M. A. (2010). Semantic processing in the anterior temporal lobes: A meta-analysis of the functional neuroimaging literature. Journal of Cognitive Neuroscience, 22, 1083-1094. doi: 10.1162/jocn.2009.21309</p>
<p>The role of the precuneus and posterior cingulate cortex in the neural routes to action. Z Wang, F Liu, Y Sun, J Li, F Wang, Z Lu, 10.1080/24699322.2018.1560098Computer Assisted Surgery. Wang, Z., Liu, F., Sun, Y., Li, J., Wang, F., &amp; Lu, Z. (2019). The role of the precuneus and posterior cingulate cortex in the neural routes to action. Computer Assisted Surgery, 1-8. doi: 10.1080/24699322.2018.1560098</p>
<p>Categories of knowledge: Further fractionations and an attempted integration. E K Warrington, R Mccarthy, 10.1093/brain/110.5.1273Brain. 110Warrington, E. K., &amp; McCarthy, R. (1987). Categories of knowledge: Further fractionations and an attempted integration. Brain, 110, 1273-1296. doi: 10.1093/brain/110.5.1273</p>
<p>Category specific semantic impairments. E K Warrington, T Shallice, 10.1093/brain/107.3.829Brain. 107Warrington, E. K., &amp; Shallice, T. (1984). Category specific semantic im- pairments. Brain, 107, 829-854. doi: 10.1093/brain/107.3.829</p>
<p>Neural dissociations between action verb understanding and motor imagery. R M Willems, I Toni, P Hagoort, D Casasanto, 10.1162/jocn.2009.21386Journal of Cognitive Neuroscience. 22Willems, R. M., Toni, I., Hagoort, P., &amp; Casasanto, D. (2010). Neural dissociations between action verb understanding and motor imagery. Journal of Cognitive Neuroscience, 22, 2387-2400. doi: 10.1162/jocn.2009.21386</p>
<p>Redundancy and word perception during reading. D Zola, doi: 10.3758/ Bf03206369 RECEIVED 10.12.2018 | ACCEPTED 13.09.2019Perception &amp; Psychophysics. 36Zola, D. (1984). Redundancy and word perception during read- ing. Perception &amp; Psychophysics, 36, 277-284. doi: 10.3758/ Bf03206369 RECEIVED 10.12.2018 | ACCEPTED 13.09.2019</p>            </div>
        </div>

    </div>
</body>
</html>