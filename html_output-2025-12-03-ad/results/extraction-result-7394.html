<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7394 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7394</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7394</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-276318057</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2502.09385v1.pdf" target="_blank">APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Advanced Persistent Threats (APTs) pose a ma-jor cybersecurity challenge due to their stealth and ability to mimic normal system behavior, making detection particularly difficult in highly imbalanced datasets. Traditional anomaly detection methods struggle to effectively differentiate APT-related activities from benign processes, limiting their applicability in real-world scenarios. This paper introduces APT-LLM, a novel embedding-based anomaly detection framework that integrates large language models (LLMs)-BERT, ALBERT, DistiIBERT, and RoBERTa-with autoencoder architectures to detect APTs. Unlike prior approaches, which rely on manually engineered features or conventional anomaly detection models, APT-LLM leverages LLMs to encode process-action provenance traces into semantically rich embeddings, capturing nuanced behavioral patterns. These embeddings are analyzed using three autoencoder architectures-Baseline Autoencoder (AE), Variational Autoen-coder (VAE), and Denoising Autoencoder (DAE)-to model normal process behavior and identify anomalies. The best-performing model is selected for comparison against traditional methods. The framework is evaluated on real-world, highly imbalanced provenance trace datasets from the DARPA Trans-parent Computing program, where APT-like attacks constitute as little as 0.004 % of the data across multiple operating systems (Android, Linux, BSD, and Windows) and attack scenarios. Results demonstrate that APT-LLM significantly improves detection performance under extreme imbalance conditions, outperforming existing anomaly detection methods and highlighting the effectiveness of LLM-based feature extraction in cybersecurity.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7394.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7394.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>APT-LLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end framework that converts process provenance records into short textual sentences, extracts dense embeddings using pre-trained LLMs (BERT, ALBERT, DistilBERT, RoBERTa, MiniLM), and applies autoencoder-based reconstruction anomaly detection (AE, VAE, DAE with optional attention) to flag APT-related anomalies in highly imbalanced provenance/tabular datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT, ALBERT, DistilBERT, RoBERTa, MiniLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-style pre-trained transformer models (BERT-family and compressed MiniLM variants) used as fixed feature extractors to produce sentence/process embeddings (mean-pooled or [CLS] pooling).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embedding-based reconstruction: LLM sentence embeddings fed to autoencoders (Baseline AE, Variational VAE, Denoising DAE) trained on normal data; anomalies scored by reconstruction error.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Autoencoders trained in an unsupervised way on embeddings of predominantly normal process-action traces derived from DARPA Transparent Computing (ADAPT ingester). No LLM fine-tuning reported.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Process provenance rows encoded as Boolean-valued tabular vectors (process × attributes) converted into short textual sentences; embeddings are dense numeric vectors (e.g., 768-dim, 1024-dim, 384-dim depending on LLM).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing (Transparent Computing TC program) processed via ADAPT ingester; 40 datasets across 4 OS (Android, Linux, BSD, Windows), 2 attack scenarios (Pandex, Bovia), and 5 aspects (PE, PX, PP, PN, PA).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC (area under ROC curve); also reconstruction error distributions / MSE used as anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Best-performing LLM+autoencoder combinations per dataset were selected. Example results: ALBERT + VAE achieved AUC = 0.95 on the PE Linux (Bovia) dataset; MiniLM + VAE best observed AUC = 0.74 on that dataset; DistilBERT + VAE peaked at AUC = 0.59. Across datasets APT-LLM reached as high as AUC = 0.97 on PX Windows (Pandex) in one reported case.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to classical anomaly detectors on the same datasets: OC-SVM (example: 0.85 on PX Windows Pandex), Isolation Forest (example: 0.23), DBSCAN (example: 0.51). APT-LLM combinations generally outperformed these baselines in most datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoders trained only on normal data; no supervised labels for anomalies used in training).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors note high computational cost and need for domain adaptation of LLMs, interpretability concerns for LLM-derived embeddings in high-stakes security settings, and variable performance across LLM architectures (e.g., BERT and RoBERTa underperformed in many configurations). Extreme class imbalance (attacks as low as 0.004%) remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7394.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7394.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALBERT (A Lite BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parameter-efficient variant of BERT (factorized embeddings and cross-layer parameter sharing) used to extract process-sentence embeddings which, when paired with a VAE, produced the best anomaly detection performance in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ALBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-only transformer pre-trained with masked language modeling, optimized for parameter efficiency via embedding factorization and layer parameter sharing.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embed process-event sentences with ALBERT, then detect anomalies via reconstruction error from autoencoders (best result with VAE).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No ALBERT fine-tuning reported; autoencoders trained on ALBERT embeddings of normal samples from DARPA Transparent Computing datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Boolean-valued provenance rows converted to short sentences; embeddings (model-dependent dimensionality) used as continuous input vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing (PE Linux Bovia example where best result reported); full suite of 40 datasets used for systematic evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ALBERT paired with VAE significantly outperformed other combinations on PE Linux (Bovia), achieving AUC = 0.95 (reported as the highest for that dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Beaten baseline methods (OC-SVM, Isolation Forest, DBSCAN) on multiple datasets; specific comparative numbers given for select datasets (see main paper).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoder trained on normal embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>While ALBERT-VAE was top-performing on several datasets, authors note overall sensitivity to LLM choice and dataset aspect; domain adaptation and interpretability remain open issues.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7394.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7394.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MiniLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MiniLM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A compact transformer model that compresses the self-attention mechanism to produce lightweight sentence embeddings (reported as 384-dimensional in the paper) and showed consistent, efficient performance when combined with autoencoders.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MiniLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Compressed encoder-only transformer that reduces attention complexity to provide smaller, efficient embeddings suitable for lower-latency inference.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Use MiniLM to embed process sentences, then apply AE/VAE/DAE to detect anomalies via reconstruction error; MiniLM+VAE was the best MiniLM configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No MiniLM fine-tuning reported; autoencoders trained on MiniLM embeddings of normal traces from the DARPA datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Provenance/tabular process records converted to sentences and embedded (reported 384-dim embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing collection (example: PE Linux Bovia where MiniLM achieved its best reported AUC).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>MiniLM exhibited consistent performance across autoencoder types; its best result reported is AUC = 0.74 (with VAE) on the PE Linux (Bovia) dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperformed some classical methods on various datasets though ALBERT-VAE was superior in top cases; detailed heatmaps compare MiniLM combinations to OC-SVM, Isolation Forest, DBSCAN.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoders trained on normal data).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Although lightweight and consistent, MiniLM did not reach the top AUC values of the best ALBERT-VAE pairing; performance varies by dataset/aspect.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7394.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7394.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DistilBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DistilBERT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distilled (smaller) variant of BERT providing efficiency gains; used to produce embeddings which were evaluated with AE/VAE/DAE—peaking at modest anomaly detection performance in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DistilBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Compressed encoder-only transformer produced by knowledge distillation of BERT, retaining much of BERT's performance with fewer parameters and faster inference.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Embed process sentences using DistilBERT and detect anomalies by reconstruction error from autoencoders (best performance reported with VAE).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No DistilBERT fine-tuning; autoencoders trained on DistilBERT embeddings of normal provenance records from DARPA TC datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Boolean/tabular provenance rows converted to sentences, then to 768-dim embeddings (paper notes DistilBERT sentence vectors similar to BERT dimensionality).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing datasets (evaluated across all 40 dataset variants).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>DistilBERT's best reported AUC was 0.59 (when paired with VAE) on the presented example dataset (PE Linux Bovia), indicating moderate performance relative to other LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against other LLM+AE combinations and classical baselines (OC-SVM, Isolation Forest, DBSCAN); DistilBERT combinations trailed top ALBERT-VAE results.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoder trained on normal data).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Moderate performance indicates DistilBERT embeddings may be less discriminative for these provenance anomaly tasks than some alternatives; authors note variable results across LLM choices.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7394.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7394.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT (Bidirectional Encoder Representations from Transformers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The original bidirectional transformer encoder used to create contextual embeddings for process-event sentences (paper describes tokenization and 768-dimensional token outputs aggregated to sentence embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-only transformer pre-trained via masked language modeling to capture bidirectional context; used here as a fixed encoder for sentence-level process traces.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Generate BERT embeddings for process sentences and feed them to AE/VAE/DAE; detect anomalies by high reconstruction error.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No BERT fine-tuning; autoencoders trained on BERT embeddings from DARPA provenance datasets (normal samples).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Boolean-valued provenance rows turned into short textual sentences; embeddings (reported 768-dim for sentence-level pooling).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing datasets (multiple OS, scenarios, and aspects).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>BERT generally underperformed compared to ALBERT and MiniLM in the experiments on the example datasets; exact AUC values for BERT combinations are not enumerated in the text beyond qualitative remarks.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Evaluated against other LLM+autoencoder combinations and classical anomaly detectors; BERT-based combos were not top-ranked in presented heatmaps.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoders trained on normal data).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors report BERT and RoBERTa generally underperformed in many configurations; implies potential mismatch between general-purpose BERT embeddings and the provenance/tabular encoding used.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7394.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7394.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa (Robustly Optimized BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An optimized BERT variant (training tweaks like dynamic masking and longer training) used to generate sentence embeddings for provenance traces; reported to underperform relative to ALBERT in many experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder-only transformer similar to BERT but trained with improved optimization strategies (no next-sentence prediction, dynamic masking) producing richer embeddings in general NLP tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>RoBERTa embeddings of process sentences used as inputs to AE/VAE/DAE; anomalies identified via reconstruction error.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No RoBERTa fine-tuning reported; autoencoders trained on RoBERTa embeddings from the DARPA datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Provenance/tabular rows converted to sentences and embedded (paper mentions RoBERTa large uses 1024-dim token vectors for large model variants).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>DARPA Transparent Computing datasets (across OS and scenarios).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>AUC-ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>RoBERTa generally underperformed in most tested configurations with only slight improvements in some cases; no single top AUC reported for RoBERTa in the paper's examples.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared within the LLM×autoencoder grid and against classical baselines; RoBERTa combinations were not the top performers in reported heatmaps.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Unsupervised (autoencoders trained on normal data).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Did not consistently produce the most discriminative embeddings for these provenance anomaly tasks according to reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large language models in cybersecurity: State-of-the-art. <em>(Rating: 2)</em></li>
                <li>A survey of large language models for cyber threat detection. <em>(Rating: 2)</em></li>
                <li>Cysecbert: A domain-adapted language model for the cybersecurity domain. <em>(Rating: 2)</em></li>
                <li>A baseline for unsupervised advanced persistent threat detection in system-level provenance. <em>(Rating: 2)</em></li>
                <li>Hack me if you can: Aggregating autoencoders for countering persistent access threats within highly imbalanced data. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7394",
    "paper_id": "paper-276318057",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "APT-LLM",
            "name_full": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
            "brief_description": "An end-to-end framework that converts process provenance records into short textual sentences, extracts dense embeddings using pre-trained LLMs (BERT, ALBERT, DistilBERT, RoBERTa, MiniLM), and applies autoencoder-based reconstruction anomaly detection (AE, VAE, DAE with optional attention) to flag APT-related anomalies in highly imbalanced provenance/tabular datasets.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BERT, ALBERT, DistilBERT, RoBERTa, MiniLM",
            "model_description": "Encoder-style pre-trained transformer models (BERT-family and compressed MiniLM variants) used as fixed feature extractors to produce sentence/process embeddings (mean-pooled or [CLS] pooling).",
            "model_size": null,
            "anomaly_detection_approach": "Embedding-based reconstruction: LLM sentence embeddings fed to autoencoders (Baseline AE, Variational VAE, Denoising DAE) trained on normal data; anomalies scored by reconstruction error.",
            "prompt_template": null,
            "training_data": "Autoencoders trained in an unsupervised way on embeddings of predominantly normal process-action traces derived from DARPA Transparent Computing (ADAPT ingester). No LLM fine-tuning reported.",
            "data_type": "Process provenance rows encoded as Boolean-valued tabular vectors (process × attributes) converted into short textual sentences; embeddings are dense numeric vectors (e.g., 768-dim, 1024-dim, 384-dim depending on LLM).",
            "dataset_name": "DARPA Transparent Computing (Transparent Computing TC program) processed via ADAPT ingester; 40 datasets across 4 OS (Android, Linux, BSD, Windows), 2 attack scenarios (Pandex, Bovia), and 5 aspects (PE, PX, PP, PN, PA).",
            "evaluation_metric": "AUC-ROC (area under ROC curve); also reconstruction error distributions / MSE used as anomaly score.",
            "performance": "Best-performing LLM+autoencoder combinations per dataset were selected. Example results: ALBERT + VAE achieved AUC = 0.95 on the PE Linux (Bovia) dataset; MiniLM + VAE best observed AUC = 0.74 on that dataset; DistilBERT + VAE peaked at AUC = 0.59. Across datasets APT-LLM reached as high as AUC = 0.97 on PX Windows (Pandex) in one reported case.",
            "baseline_comparison": "Compared to classical anomaly detectors on the same datasets: OC-SVM (example: 0.85 on PX Windows Pandex), Isolation Forest (example: 0.23), DBSCAN (example: 0.51). APT-LLM combinations generally outperformed these baselines in most datasets.",
            "zero_shot_or_few_shot": "Unsupervised (autoencoders trained only on normal data; no supervised labels for anomalies used in training).",
            "limitations_or_failure_cases": "Authors note high computational cost and need for domain adaptation of LLMs, interpretability concerns for LLM-derived embeddings in high-stakes security settings, and variable performance across LLM architectures (e.g., BERT and RoBERTa underperformed in many configurations). Extreme class imbalance (attacks as low as 0.004%) remains challenging.",
            "computational_cost": null,
            "uuid": "e7394.0",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "ALBERT",
            "name_full": "ALBERT (A Lite BERT)",
            "brief_description": "A parameter-efficient variant of BERT (factorized embeddings and cross-layer parameter sharing) used to extract process-sentence embeddings which, when paired with a VAE, produced the best anomaly detection performance in the paper's experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ALBERT",
            "model_description": "Encoder-only transformer pre-trained with masked language modeling, optimized for parameter efficiency via embedding factorization and layer parameter sharing.",
            "model_size": null,
            "anomaly_detection_approach": "Embed process-event sentences with ALBERT, then detect anomalies via reconstruction error from autoencoders (best result with VAE).",
            "prompt_template": null,
            "training_data": "No ALBERT fine-tuning reported; autoencoders trained on ALBERT embeddings of normal samples from DARPA Transparent Computing datasets.",
            "data_type": "Boolean-valued provenance rows converted to short sentences; embeddings (model-dependent dimensionality) used as continuous input vectors.",
            "dataset_name": "DARPA Transparent Computing (PE Linux Bovia example where best result reported); full suite of 40 datasets used for systematic evaluation.",
            "evaluation_metric": "AUC-ROC",
            "performance": "ALBERT paired with VAE significantly outperformed other combinations on PE Linux (Bovia), achieving AUC = 0.95 (reported as the highest for that dataset).",
            "baseline_comparison": "Beaten baseline methods (OC-SVM, Isolation Forest, DBSCAN) on multiple datasets; specific comparative numbers given for select datasets (see main paper).",
            "zero_shot_or_few_shot": "Unsupervised (autoencoder trained on normal embeddings).",
            "limitations_or_failure_cases": "While ALBERT-VAE was top-performing on several datasets, authors note overall sensitivity to LLM choice and dataset aspect; domain adaptation and interpretability remain open issues.",
            "computational_cost": null,
            "uuid": "e7394.1",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "MiniLM",
            "name_full": "MiniLM",
            "brief_description": "A compact transformer model that compresses the self-attention mechanism to produce lightweight sentence embeddings (reported as 384-dimensional in the paper) and showed consistent, efficient performance when combined with autoencoders.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "MiniLM",
            "model_description": "Compressed encoder-only transformer that reduces attention complexity to provide smaller, efficient embeddings suitable for lower-latency inference.",
            "model_size": null,
            "anomaly_detection_approach": "Use MiniLM to embed process sentences, then apply AE/VAE/DAE to detect anomalies via reconstruction error; MiniLM+VAE was the best MiniLM configuration.",
            "prompt_template": null,
            "training_data": "No MiniLM fine-tuning reported; autoencoders trained on MiniLM embeddings of normal traces from the DARPA datasets.",
            "data_type": "Provenance/tabular process records converted to sentences and embedded (reported 384-dim embeddings).",
            "dataset_name": "DARPA Transparent Computing collection (example: PE Linux Bovia where MiniLM achieved its best reported AUC).",
            "evaluation_metric": "AUC-ROC",
            "performance": "MiniLM exhibited consistent performance across autoencoder types; its best result reported is AUC = 0.74 (with VAE) on the PE Linux (Bovia) dataset.",
            "baseline_comparison": "Outperformed some classical methods on various datasets though ALBERT-VAE was superior in top cases; detailed heatmaps compare MiniLM combinations to OC-SVM, Isolation Forest, DBSCAN.",
            "zero_shot_or_few_shot": "Unsupervised (autoencoders trained on normal data).",
            "limitations_or_failure_cases": "Although lightweight and consistent, MiniLM did not reach the top AUC values of the best ALBERT-VAE pairing; performance varies by dataset/aspect.",
            "computational_cost": null,
            "uuid": "e7394.2",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "DistilBERT",
            "name_full": "DistilBERT",
            "brief_description": "A distilled (smaller) variant of BERT providing efficiency gains; used to produce embeddings which were evaluated with AE/VAE/DAE—peaking at modest anomaly detection performance in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "DistilBERT",
            "model_description": "Compressed encoder-only transformer produced by knowledge distillation of BERT, retaining much of BERT's performance with fewer parameters and faster inference.",
            "model_size": null,
            "anomaly_detection_approach": "Embed process sentences using DistilBERT and detect anomalies by reconstruction error from autoencoders (best performance reported with VAE).",
            "prompt_template": null,
            "training_data": "No DistilBERT fine-tuning; autoencoders trained on DistilBERT embeddings of normal provenance records from DARPA TC datasets.",
            "data_type": "Boolean/tabular provenance rows converted to sentences, then to 768-dim embeddings (paper notes DistilBERT sentence vectors similar to BERT dimensionality).",
            "dataset_name": "DARPA Transparent Computing datasets (evaluated across all 40 dataset variants).",
            "evaluation_metric": "AUC-ROC",
            "performance": "DistilBERT's best reported AUC was 0.59 (when paired with VAE) on the presented example dataset (PE Linux Bovia), indicating moderate performance relative to other LLMs.",
            "baseline_comparison": "Compared against other LLM+AE combinations and classical baselines (OC-SVM, Isolation Forest, DBSCAN); DistilBERT combinations trailed top ALBERT-VAE results.",
            "zero_shot_or_few_shot": "Unsupervised (autoencoder trained on normal data).",
            "limitations_or_failure_cases": "Moderate performance indicates DistilBERT embeddings may be less discriminative for these provenance anomaly tasks than some alternatives; authors note variable results across LLM choices.",
            "computational_cost": null,
            "uuid": "e7394.3",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "BERT",
            "name_full": "BERT (Bidirectional Encoder Representations from Transformers)",
            "brief_description": "The original bidirectional transformer encoder used to create contextual embeddings for process-event sentences (paper describes tokenization and 768-dimensional token outputs aggregated to sentence embeddings).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT",
            "model_description": "Encoder-only transformer pre-trained via masked language modeling to capture bidirectional context; used here as a fixed encoder for sentence-level process traces.",
            "model_size": null,
            "anomaly_detection_approach": "Generate BERT embeddings for process sentences and feed them to AE/VAE/DAE; detect anomalies by high reconstruction error.",
            "prompt_template": null,
            "training_data": "No BERT fine-tuning; autoencoders trained on BERT embeddings from DARPA provenance datasets (normal samples).",
            "data_type": "Boolean-valued provenance rows turned into short textual sentences; embeddings (reported 768-dim for sentence-level pooling).",
            "dataset_name": "DARPA Transparent Computing datasets (multiple OS, scenarios, and aspects).",
            "evaluation_metric": "AUC-ROC",
            "performance": "BERT generally underperformed compared to ALBERT and MiniLM in the experiments on the example datasets; exact AUC values for BERT combinations are not enumerated in the text beyond qualitative remarks.",
            "baseline_comparison": "Evaluated against other LLM+autoencoder combinations and classical anomaly detectors; BERT-based combos were not top-ranked in presented heatmaps.",
            "zero_shot_or_few_shot": "Unsupervised (autoencoders trained on normal data).",
            "limitations_or_failure_cases": "Authors report BERT and RoBERTa generally underperformed in many configurations; implies potential mismatch between general-purpose BERT embeddings and the provenance/tabular encoding used.",
            "computational_cost": null,
            "uuid": "e7394.4",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "RoBERTa",
            "name_full": "RoBERTa (Robustly Optimized BERT)",
            "brief_description": "An optimized BERT variant (training tweaks like dynamic masking and longer training) used to generate sentence embeddings for provenance traces; reported to underperform relative to ALBERT in many experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RoBERTa",
            "model_description": "Encoder-only transformer similar to BERT but trained with improved optimization strategies (no next-sentence prediction, dynamic masking) producing richer embeddings in general NLP tasks.",
            "model_size": null,
            "anomaly_detection_approach": "RoBERTa embeddings of process sentences used as inputs to AE/VAE/DAE; anomalies identified via reconstruction error.",
            "prompt_template": null,
            "training_data": "No RoBERTa fine-tuning reported; autoencoders trained on RoBERTa embeddings from the DARPA datasets.",
            "data_type": "Provenance/tabular rows converted to sentences and embedded (paper mentions RoBERTa large uses 1024-dim token vectors for large model variants).",
            "dataset_name": "DARPA Transparent Computing datasets (across OS and scenarios).",
            "evaluation_metric": "AUC-ROC",
            "performance": "RoBERTa generally underperformed in most tested configurations with only slight improvements in some cases; no single top AUC reported for RoBERTa in the paper's examples.",
            "baseline_comparison": "Compared within the LLM×autoencoder grid and against classical baselines; RoBERTa combinations were not the top performers in reported heatmaps.",
            "zero_shot_or_few_shot": "Unsupervised (autoencoders trained on normal data).",
            "limitations_or_failure_cases": "Did not consistently produce the most discriminative embeddings for these provenance anomaly tasks according to reported experiments.",
            "computational_cost": null,
            "uuid": "e7394.5",
            "source_info": {
                "paper_title": "APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large language models in cybersecurity: State-of-the-art.",
            "rating": 2,
            "sanitized_title": "large_language_models_in_cybersecurity_stateoftheart"
        },
        {
            "paper_title": "A survey of large language models for cyber threat detection.",
            "rating": 2,
            "sanitized_title": "a_survey_of_large_language_models_for_cyber_threat_detection"
        },
        {
            "paper_title": "Cysecbert: A domain-adapted language model for the cybersecurity domain.",
            "rating": 2,
            "sanitized_title": "cysecbert_a_domainadapted_language_model_for_the_cybersecurity_domain"
        },
        {
            "paper_title": "A baseline for unsupervised advanced persistent threat detection in system-level provenance.",
            "rating": 2,
            "sanitized_title": "a_baseline_for_unsupervised_advanced_persistent_threat_detection_in_systemlevel_provenance"
        },
        {
            "paper_title": "Hack me if you can: Aggregating autoencoders for countering persistent access threats within highly imbalanced data.",
            "rating": 2,
            "sanitized_title": "hack_me_if_you_can_aggregating_autoencoders_for_countering_persistent_access_threats_within_highly_imbalanced_data"
        }
    ],
    "cost": 0.01363325,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models
13 Feb 2025</p>
<p>Sidahmed Benabderrahmane sidahmed.benabderrahmane@nyu.edu 
Division of Science
New York University</p>
<p>Petko Valtchev valtchev.petko@uqam.ca 
University of Montreal
UQAM</p>
<p>James Cheney jcheney@inf.ed.ac.uk 
School of Informatics
The University of Edinburgh</p>
<p>Talal Rahwan talal.rahwan@nyu.edu 
Division of Science
New York University</p>
<p>APT-LLM: Embedding-Based Anomaly Detection of Cyber Advanced Persistent Threats Using Large Language Models
13 Feb 2025B9AFD829A4EA49E3A8666483C35CB287arXiv:2502.09385v1[cs.CR]Anomaly DetectionDeep LearningTransformersLarge Language ModelsAutoEncodersCyber-security
Advanced Persistent Threats (APTs) pose a major cybersecurity challenge due to their stealth and ability to mimic normal system behavior, making detection particularly difficult in highly imbalanced datasets.Traditional anomaly detection methods struggle to effectively differentiate APT-related activities from benign processes, limiting their applicability in real-world scenarios.This paper introduces APT-LLM, a novel embedding-based anomaly detection framework that integrates large language models (LLMs)-BERT, ALBERT, DistilBERT, and RoBERTa-with autoencoder architectures to detect APTs.Unlike prior approaches, which rely on manually engineered features or conventional anomaly detection models, APT-LLM leverages LLMs to encode process-action provenance traces into semantically rich embeddings, capturing nuanced behavioral patterns.These embeddings are analyzed using three autoencoder architectures-Baseline Autoencoder (AE), Variational Autoencoder (VAE), and Denoising Autoencoder (DAE)-to model normal process behavior and identify anomalies.The bestperforming model is selected for comparison against traditional methods.The framework is evaluated on real-world, highly imbalanced provenance trace datasets from the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004% of the data across multiple operating systems (Android, Linux, BSD, and Windows) and attack scenarios.Results demonstrate that APT-LLM significantly improves detection performance under extreme imbalance conditions, outperforming existing anomaly detection methods and highlighting the effectiveness of LLM-based feature extraction in cybersecurity.</p>
<p>I. INTRODUCTION</p>
<p>Advanced Persistent Threats (APTs) are a class of cyberattacks characterized by their stealth, sophistication, and long-term presence within targeted networks [1].Rather than executing quick, indiscriminate hits, APT campaigns carefully exploit system weaknesses, maintain persistence, and exfiltrate sensitive data over extended periods.Their persistent nature and ability to evade traditional detection methods-often by blending in with legitimate system processes-make APTs particularly challenging to identify and mitigate [2].</p>
<p>In recent years, Pre-trained Large Language Models (LLMs) have emerged as a groundbreaking approach across numerous domains [3].LLMs such as BERT, RoBERTa, GPT, or recently DeepSeek utilize enormous amounts of unlabeled text to learn rich contextual embeddings, enabling them to capture semantic nuances far beyond the capabilities of earlier, taskspecific models.This success in natural language processing has inspired researchers to leverage LLM-based embeddings for novel applications-including cybersecurity-where the ability to represent complex "behavioral signatures" or "event sequences" as textual embeddings can potentially detect malicious patterns [4].</p>
<p>Building on these advances, we propose an LLM-driven APT detection framework designed to enhance the identification of stealthy behaviors within system logs and network traces.Our core idea is to convert low-level process events (e.g., file operations, network connections) into descriptive textual phrases, then extract embeddings using state-of-the-art LLMs.By combining these semantic-rich embeddings with an anomaly detection model-such as an autoencoder-we aim to detect hidden APT attacks in traces more effectively than conventional, signature-based methods.We evaluate our approach on real-world APT datasets, highlighting the potential of LLM embeddings to uncover subtle and malicious sequences often overlooked by standard methods.</p>
<p>II. RELATED WORK</p>
<p>APT detection has long relied on a combination of rulebased approaches, signature matching, and heuristic analysis [2].Classical solutions frequently inspect network traffic, system calls, or event logs to identify suspicious patterns.However, attackers often disguise APT behavior within normal operating system activities, rendering purely signaturebased methods insufficient.In the context of stealthy campaigns, conventional detection frameworks often fail to capture low-frequency or polymorphic events leading to data exfiltration.Recent works have introduced machine learning techniques-ranging from supervised classifiers to anomaly detection algorithms-aimed at capturing novel or stealthy behaviors [5], [6], [7], [8], [9], [10].For example, intrusion detection systems (IDS) increasingly adopt textual, time series or graph-based models that encode dependencies between system events.Despite these advancements, the sophistication of APT tactics continues to outpace purely traditional approaches.In recent years, pre-trained LLMs have demonstrated remarkable capability in capturing semantic and contextual nuances across vast domains.Although they have primarily excelled in natural language processing tasks such as translation, summarization, and question-answering, researchers have begun to apply LLM-based embeddings to cybersecurity problems as well [11].By transforming logs or system traces into textual narratives, LLMs can learn richer representations of process behaviors.These embeddings allow anomaly detection algorithms to isolate subtle deviations indicative of malicious activity.Despite their potential, these methods are still in the early stages, facing challenges such as high computational cost and the need for extensive domain adaptation [12].Although LLMs have shown promise in detecting anomalies, most studies remain in the proof-of-concept stage, lacking large-scale evaluations on real data or heterogeneous operating systems (OS).In addition, limited attention has been paid to the interpretability of LLM-derived features, which are critical in high-stakes environments, where security analysts need clear rationales for flagged anomalies.To address these gaps, our work proposes a comprehensive pipeline for APT detection that fuses LLM-based embeddings with robust anomaly detection, systematically evaluated across multiple OS datasets and real-world threat scenarios.</p>
<p>III. PROPOSED FRAMEWORK</p>
<p>In this section, we present our APT-LLM detection framework, which leverages a provenance database of process events and netflow activities, pre-trained Large Language Models (LLMs) for embedding generation, and three autoencoder architectures for anomaly detection.The following paragraphs include key details to clarify each stage of our approach.</p>
<p>A. Provenance Database</p>
<p>Let D = {r 1 , r 2 , . . ., r N } represent the provenance database of size N , where each record r i captures:</p>
<p>• A process ID, p i .</p>
<p>• A set of events, {e i1 , e i2 , . . .}.These records collectively define a high-level, system-wide trace that can be converted into textual descriptions for embedding extraction.</p>
<p>B. Textual Representation and LLM Embeddings</p>
<p>To harness LLM-based embeddings, we convert each record r i into a short sentence s i .For instance, if r i corresponds to a process with events [open, write, send], we map it to: s i = "Process p i has event open and event write and event send."a) Embedding Extraction.We apply a pre-trained LLM, denoted generically by a function f LM (•) : Sentence → R d , which transforms the textual sentence s i into a d-dimensional dense embedding x i .In our study, we experiment with several LLMs: 1) BERT (Bidirectional Encoder Representations from Transformers) : Learns bidirectional context via masked language modeling.2) DistilBERT : A distilled (compressed) variant of BERT with fewer parameters.It is produced via knowledge distillation, maintaining a good balance between accuracy and computational efficiency.3) ALBERT (A Lite BERT): Reduces model size through parameter sharing and factorized embeddings.4) RoBERTa (Robustly Optimized BERT): An optimized variant of BERT trained with longer sequences and dynamic masking.5) MiniLM : Compresses self-attention to achieve a small yet effective model.Each model outputs a high-dimensional vector (e.g., 768 dimensions) encapsulating the process's behavior in semantic form.By testing multiple LLMs, our framework evaluates how architectural differences (e.g., distillation, parameter sharing, encoder-decoder) impact the detection of stealthy APT.Hence, for record i we have the embedding:
x i = f LM (s i ) ∈ R d .</p>
<p>C. Anomaly Detection with AutoEncoders</p>
<p>Autoencoders (AEs) are unsupervised learning models that aim to encode input data into a compressed latent representation and reconstruct the original input from it.They are widely used for anomaly detection, where high reconstruction errors indicate data that deviates from the normal distribution.In our APT-LLM framework, we extend a baseline AutoEncoder (AE) to its variants-Variational Autoencoders (VAEs) and Denoising Autoencoders (DAEs)-and introduce the use of attention mechanisms to enhance their performance.The motivation behind using a Variational Autoencoder (VAE) is to introduce a probabilistic latent space, enabling the model to better capture the underlying data distribution and generalize beyond reconstruction, while a Denoising Autoencoder (DAE) is designed to improve robustness by learning to reconstruct clean inputs from noisy data; both extend the baseline Autoencoder (AE), which focuses solely on deterministic compression and reconstruction without addressing probabilistic modeling (VAE) or noise resilience (DAE).</p>
<p>1) Baseline Autoencoder (AE)</p>
<p>The baseline autoencoder consists of two main components: The objective of AE is to minimize the reconstruction loss: 2 .This ensures that z captures the most relevant features of x while enabling accurate reconstruction.
• Encoder E(x; θ E ): Maps the input LLM embedding x ∈ R d to a latent representation z ∈ R k , where k ≪ d: z = E(x; θ E ) = f (W E x + b E ) where f (•)L AE = ∥x− x∥
2) Variational Autoencoder (VAE) Unlike AE, VAE introduces a probabilistic approach to the latent space by modeling z as a random variable: z ∼ N (µ, σ 2 ).The encoder outputs the mean µ and log-variance log σ 2 , which parameterize the latent Gaussian distribution: µ, log σ 2 = E(x; θ E ).The decoder reconstructs x by sampling from the latent distribution using the reparameterization trick:z = µ + σ ⊙ ϵ, ϵ ∼ N (0, I).The VAE objective combines the Reconstruction Loss: L recon = ∥x − x∥ 2 , and KL Divergence that regularizes the latent space to follow a standard Gaussian prior: L KL = D KL N (µ, σ 2 )∥N (0, I) .The total loss is: L VAE = L recon + βL KL where β controls the weight of the KL divergence term.</p>
<p>3) Denoising Autoencoder (DAE) DAE extends AE by introducing noise into the input data during training.The noisy input x is generated by adding Gaussian noise or masking random features: x = x+η, η ∼ N (0, σ 2 ).The encoder maps x to a latent representation: z = E(x; θ E ).The decoder reconstructs the original clean input x: x = D(z; θ D ).The loss function minimizes the reconstruction error between x and x:
L DAE = ∥x − x∥ 2 .
This encourages the model to learn robust representations that ignore irrelevant noise.</p>
<p>4) Attention Mechanisms</p>
<p>To enhance the representational power of AE, VAE and DAE autoencoders, we incorporate self-attention layers into the encoder.Self-attention enables the model to learn dependencies between different features, allowing it to focus on the most relevant aspects of the input.</p>
<p>Given an input X ∈ R n×d (the LLM embeddings), the attention mechanism computes:
Attention(Q, K, V ) = softmax QK T √ d k
V where Q, K, and V are the query, key, and value matrices, respectively, derived from X. Multi-head attention extends this by using multiple attention mechanisms in parallel: MultiHead(Q, K, V ) = Concat(head 1 , . . ., head h )W O .Integrating attention layers allows the encoder to capture complex relationships within LLM embeddings, improving anomaly detection performance.</p>
<p>D. Experimental Plan</p>
<p>During training, we use predominantly normal data, ensuring the autoencoders (AE, DAE, VAE) learn a compact representation of typical (non-APT) process embeddings.</p>
<p>To evaluate the different architectures in APT-LLM, we compare their effectiveness in anomaly detection using embeddings generated from LLMs (BERT, ALBERT, RoBERTa, DistilBert and MiniLM).Each model is trained on embeddings from normal process-action traces and tested on both normal and anomalous samples.Performance is measured using:</p>
<p>• Reconstruction Error: Distribution of reconstruction errors for normal vs. anomalous data.• Anomaly Detection Metrics: AUC-ROC.</p>
<p>The results will highlight the relative strengths of each architecture and the impact of attention layers on anomaly detection.</p>
<p>1) Anomaly Scoring</p>
<p>After training on normal embeddings, the reconstruction error serves as an anomaly score.r i = ∥x i − xi ∥</p>
<p>IV. EXPERIMENTAL SETTINGS, RESULTS AND ANALYSIS</p>
<p>A. Provenance Datasets</p>
<p>The datasets used in this study are derived from DARPA's Transparent Computing TC program1 , processed through the ADAPT 2 (Automatic Detection of Advanced Persistent Threats) project's ingester.These datasets span four OS -Android, Linux, BSD, and Windows-and include two attack scenarios: Pandex and Bovia [8], [9], [10].Provenance graph data is processed into graph databases, followed by data integration and deduplication, resulting in Boolean-valued datasets that represent various aspects of system process behaviors.Each dataset row corresponds to a process and is encoded as a Boolean vector, where a value of 1 indicates the presence of a specific attribute or event.Five data aspects are constructed for each OS and attack scenario: ProcessEvent (PE), which captures event types performed by processes; ProcessExec (PX), representing executable names starting the processes; ProcessParent (PP), denoting executables of parent processes; ProcessNetflow (PN), detailing IP addresses and port names accessed by processes; and Proces-sAll (PA), a union of all attribute sets.With two scenarios, four OS, and five data aspect, a total of 40 datasets are created.Table I summarizes them, where the last column illustrates their highly imbalanced nature, with APT attacks constituting as little as 0.004% of the data in some cases.</p>
<p>B. Illustrative Examples of LLM Embeddings</p>
<p>To explain the embedding generation process, we convert a sample process trace into textual representations and pass it through the LLMs.Each model uses its unique architecture and training strategy but outputs dense embeddings that capture the semantic meaning of the input.</p>
<p>Suppose a process (id:123) performs the following events:</p>
<p>• Open a file • Write to the file • Send network data This trace is represented as a sentence:</p>
<p>''Process 123 has event open a file and event write to the file and event send network data.''We pass this sentence into the different LLMs, which tokenize it, process it through their architectures, and produce dense embeddings.Initially, BERT runs a tokenization process by splitting the input sentence into tokens, e.g., [CLS, Process, 123, has, event, open, .., event, write, .., event, send, .., [SEP]].Each token is converted into a numeric ID.Then BERT uses bidirectional attention to learn the context of each token based on both preceding and following tokens.For example, the embedding for event open a file incorporates its relationships to event write to the file and event send network data.The final output is a 768-dimensional vector for each token.To get a single vector for the sentence, we use mean pooling over all token embeddings or select the embedding of the [CLS] token.ALBERT on the other hand-side reduces model size by factorizing embedding parameters, and cross-layer parameter sharing.Similar to BERT, ALBERT tokenizes the input and generates embeddings using bidirectional attention.Despite its smaller size, ALBERT captures semantic relationships effectively.RoBERTa improves BERT by removing the next-sentence prediction task.It processes the input sentence similarly to BERT but achieves richer embeddings due to better training optimizations.Each token is represented by a 1024-dimensional vector (for the large model), and sentence embeddings are derived through pooling.DistilBERT is a lighter, faster version of BERT, trained using knowledge distillation to retain 97% of BERT's performance with 40% fewer parameters.The input is tokenized and passed through a smaller Transformer network, reducing computation time while still generating high-quality embeddings.Sentence embeddings are derived as 768-dimensional vectors, like BERT, but computed more efficiently.MiniLM compresses the attention mechanism in Transformers, significantly reducing the model size while maintaining strong performance on semantic tasks.MiniLM tokenizes the input and uses a highly compressed Transformer network to generate embeddings.</p>
<p>Its efficiency makes it ideal for real-time applications.Embeddings are 384-dimensional vectors, smaller than BERT, making it computationally lightweight.</p>
<p>C. Comparison of LLMs</p>
<p>Using these multiple LLMs allows us to compare:</p>
<p>• Embedding Quality: Larger models like RoBERTa might capture richer semantic nuances, while smaller models like DistilBERT and MiniLM provide efficiency.• Detection Performance: We evaluate how different embeddings impact anomaly detection performance (e.g., reconstruction error, AUC).</p>
<p>D. Embeddings visualization</p>
<p>Figure 1 provides T-SNE visualizations of the embeddings generated using five large language models (LLMs), showcasing the projection of normal data (blue points, label 0) and anomalies (orange points, label 1).In this example, the data points correspond to the PE data set of the Linux OS under the Bovia attack scenario.The embeddings highlight how LLM-based representations capture nuanced differences between normal and anomalous patterns.We generated these T-SNE visualizations for the entire collection of datasets for providing a clear clustering of normal points while isolating anomalies.This visualization demonstrates the potential of LLMs in embedding provenance trace data for effective anomaly detection.</p>
<p>E. AutoEncoders training and reconstruction errors</p>
<p>The embedding vectors generated in the previous step with the five LLMs are used to train AE, VAE and DAE.effectiveness of reconstruction error for anomaly detection.</p>
<p>Given the combination of 5 LLMs and 3 autoencoder architectures (AE, VAE, and DAE), we conducted extensive experiments by systematically testing all configurations (5×3) to identify the best-performing model for anomaly detection.For each combination, we generated ROC curves and calculated the corresponding AUC scores to comprehensively evaluate their performance.The heatmap in Figure 4 provides an overview of the AUC scores achieved by combinations of the five language models, and the autoencoder architectures (AE, DAE, and VAE) for the PE Linux Bovia dataset.ALBERT paired with VAE significantly outperforms other combinations, achieving the highest AUC score of 0.95, highlighting its ability to capture and reconstruct patterns effectively in this architecture.MiniLM also exhibits consistent performance across all autoencoder types, with its best result (AUC = 0.74) observed when combined with the VAE, demonstrating its lightweight yet robust capabilities.While DistilBERT shows moderate performance, peaking with VAE (AUC = 0.59), BERT and RoBERTa generally underperform except for slight improvements in certain configurations.The analysis underscores the importance of selecting the right pairing of LLMs and autoencoders to optimize anomaly detection performance, with ALBERT-VAE emerging as the clear winner for the considered dataset.</p>
<p>Figure 5 illustrates the ROC curves of the top-6 bestperforming combinations identified from the heatmap, highlighting their superior anomaly detection capabilities.The ROC curves provide a comparative analysis of the performance of the different combinations of LLMs paired with three autoencoder architectures.Each curve represents the true positive rate (TPR) against the false positive rate (FPR) for a specific LLM-autoencoder pairing, with the area under the curve (AUC) indicating the overall performance.We generated heatmaps of the AUC scores for all combinations of LLMs and autoencoder architectures across the remaining datasets (5×3×40), and for each dataset, we identified the combination yielding the maximum AUC to serve as the baseline APT-LLM for comparison with existing anomaly detection methods.Indeed, for each dataset, the best-performing combination (LLM × AE) was evaluated against three classical anomaly detection approaches-OC-SVM, DBSCAN, and Isolation Forest.The resulting AUC scores are presented in Heatmap 6.The results reveal significant differences in the AUC per-formance of various anomaly detection methods-APT-LLM, OC-SVM, Isolation Forest, and DBSCAN-across datasets spanning multiple OS (Windows, Linux, BSD, and Android) and provenance trace aspects.APT-LLM consistently outperforms the baseline methods in most datasets, achieving the highest AUC scores.For example, in PX Windows Pandex, APT-LLM scores 0.97, compared to OC-SVM (0.85), Isolation Forest (0.23), and DBSCAN (0.51).Baseline methods such as OC-SVM show competitive performance in a few cases, particularly in BSD datasets, while Isolation Forest and DB-SCAN often show weaker results.These findings highlight the robustness and superior detection capabilities of the APT-LLM framework across diverse datasets and scenarios.</p>
<p>V. CONCLUSION</p>
<p>In this paper, we presented APT-LLM, an embedding-based anomaly detection framework that leverages large language models and autoencoders to identify advanced APT cyber threats.By transforming process behaviors into textual representations, our approach introduces a novel perspective for anomaly detection tasks.Experimental results highlight significant improvements in APT detection performance, particularly in highly imbalanced scenarios, demonstrating the effectiveness and potential of LLM-based embeddings in advancing cybersecurity practices.</p>
<p>is a nonlinear activation function, and θ E = {W E , b E } are the encoder parameters.• Decoder D(z; θ D ): Reconstructs the input x from z: x = D(z; θ D ) = g(W D z+b D ) where g(•) is another nonlinear activation function, and θ D = {W D , b D } are the decoder parameters.</p>
<p>Fig. 1 :
1
Fig. 1: T-SNE Visualizations of Embeddings Using Different LLMs.Blue points (label 0) represent normal data, whereas orange points (label 1) represent anomalies.In this example, data belongs to PE dataset of Linux OS and Bovia scenario.</p>
<p>Fig. 2 :
2
Fig. 2: Training and Validation Loss Curve for the Autoencoder: The figure shows the decrease in training and validation loss (MSE) over 100 epochs, demonstrating the model's convergence and generalization during training.</p>
<p>Fig. 3 :
3
Fig. 3: Scatter Plot of the AutoEncoder Reconstruction Errors by Sample Index: The figure illustrates the reconstruction errors (MSE) for each sample, with the red dashed line indicating the anomaly detection threshold.Points above the threshold represent detected anomalies.</p>
<p>Figure 2
2
Figure2shows the training and validation loss curves for the baseline autoencoder over 100 epochs, using the previous dataset (PE, Linux, Bovia).Both curves exhibit a steep decline during the initial epochs, indicating rapid learning and optimization.After approximately 20 epochs, the losses stabilize and decrease gradually, suggesting convergence of the model.The training loss remains slightly lower than the validation loss, highlighting a well-generalized model with minimal overfitting.The consistent alignment between the two curves over time reflects the autoencoder's ability to learn meaningful representations of the input data while maintaining robustness on unseen validation samples.Figure3presents a scatter plot of reconstruction errors (MSE) from the baseline autoencoder.Each point represents a sample, with anomalies (red) identified when errors exceed the red dashed threshold.Most data points fall below this threshold, indicating normal samples, while a few outliers exceed it, demonstrating the</p>
<p>Fig. 4 :
4
Fig. 4: Heatmap of AUC Scores for LLM and Autoencoder Combinations: The figure shows the performance of five language models (LLMs) paired with three autoencoder architectures (AE, DAE, VAE) on anomaly detection tasks, with darker shades indicating higher AUC scores.Data belongs to PE dataset of Linux OS and Bovia scenario.</p>
<p>Fig. 5 :
5
Fig. 5: ROC Curve Comparison for the Best performing models (PE dataset of Linux OS and Bovia scenario).</p>
<p>Fig. 6 :
6
Fig. 6: AUC heatmap comparing the performance of APT-LLM, OC-SVM, Isolation Forest, and DBSCAN across datasets from multiple OS (Windows, Linux, BSD, and Android) and provenance trace aspects.APT-LLM consistently achieves higher AUC scores, demonstrating its superior anomaly detection capabilities</p>
<p>2 2
2
If r i exceeds a threshold τ , the record is flagged as a potential Extract a provenance database {r 1 , . . ., r N } containing process actions, system calls, and other metadata.2) Sentence Generation: Map each record r i to a sentence s i .3) LLM Embedding: Compute x i = f LM (s i ) for each record, where f LM is one of our chosen LLMs (BERT, DistilBERT, ALBERT, RoBERTa, or MiniLM).4) Noise Injection &amp; Encoding: Obtain xi by adding noise to x i , then encode xi to latent vector z i .5) Training: Use normal data and train AE, VAE and DAE. 6) Decoding &amp; Reconstruction: Decode z i back to xi , training on normal embeddings to minimize ∥x i − xi ∥
APT: flag(x i ) =1, if r i &gt; τ, 0, otherwise..Choosing τ can be based on a percentile of r i among knownnormal samples or tuned via validation metrics.E. Workflow Summary1) Data Collection: 2 2 .7) Anomaly Detection: For new (test) samples, computereconstruction errors r
i .If r i &gt; τ , label the sample as anomalous.</p>
<p>TABLE I :
I
Experimental datasets of DARPA's TC program used in our study.A dataset entry (columns 4 to 8) is described by a number of rows (processes) / number of columns (attributes).For instance, with ProcessAll (PA) obtained from the second scenario using Linux, the dataset has 282104 rows and 6435 attributes with 46 APT attacks (0.01%).</p>
<p>https://www.darpa.mil/program/transparent-computing
https://gitlab.com/adaptdata</p>
<p>Strategically-motivated advanced persistent threat: Definition, process, tactics and a disinformation model of counterattack. A Ahmad, J Webb, Computers &amp; Security. 862019</p>
<p>A systematic literature review on advanced persistent threat behaviors and its detection strategy. N I Che Mat, N Jamil, Y Yusoff, M L Mat, Kiah , Journal of Cybersecurity. 101232024</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, Y Wu, L Yang, K Zhu, H Chen, X Yi, C Wang, Y Wang, ACM Transactions on Intelligent Systems and Technology. 1532024</p>
<p>Large language models in cybersecurity: State-of-the-art. F N Motlagh, M Hajizadeh, M Majd, P Najafi, F Cheng, C Meinel, arXiv:2402.008912024arXiv preprint</p>
<p>A scalable and efficient outlier detection strategy for categorical data. A Koufakou, 19th IEEE Int Conf on Tools with Artificial Intelligence(ICTAI 2007). IEEEOct. 2007</p>
<p>The odd one out: Identifying and characterising anomalies. K Smets, J Vreeken, Proceedings of the 2011 SIAM international conference on data mining. the 2011 SIAM international conference on data miningSIAM2011</p>
<p>Outlier detection for transaction databases using association rules. K Narita, H Kitagawa, 2008 The 9th Int Conf on Web-Age Information Management. 2008</p>
<p>A baseline for unsupervised advanced persistent threat detection in system-level provenance. G Berrada, Future Generation Computer Systems. 1082020</p>
<p>A rule mining-based advanced persistent threats detection system. S Benabderrahmane, Proc of IJCAI21. Z Zhou, of IJCAI21Montreal, Canada2021</p>
<p>Hack me if you can: Aggregating autoencoders for countering persistent access threats within highly imbalanced data. S Benabderrahmane, N Hoang, Future Gener. Comput. Syst. 1602024</p>
<p>A survey of large language models for cyber threat detection. Y Chen, Computers &amp; Security. 1040162024</p>
<p>Cysecbert: A domain-adapted language model for the cybersecurity domain. M Bayer, ACM Transactions on Privacy and Security. 2722024</p>            </div>
        </div>

    </div>
</body>
</html>