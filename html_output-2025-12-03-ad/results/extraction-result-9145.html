<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9145 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9145</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9145</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-278904953</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.18673v1.pdf" target="_blank">Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have achieved remarkable success in Natural Language Processing (NLP), yet their cross-lingual performance consistency remains a significant challenge. This paper introduces a novel methodology for efficiently identifying inherent cross-lingual weaknesses in LLMs. Our approach leverages beam search and LLM-based simulation to generate bilingual question pairs that expose performance discrepancies between English and target languages. We construct a new dataset of over 6,000 bilingual pairs across 16 languages using this methodology, demonstrating its effectiveness in revealing weaknesses even in state-of-the-art models. The extensive experiments demonstrate that our method precisely and cost-effectively pinpoints cross-lingual weaknesses, consistently revealing over 50\% accuracy drops in target languages across a wide range of models. Moreover, further experiments investigate the relationship between linguistic similarity and cross-lingual weaknesses, revealing that linguistically related languages share similar performance patterns and benefit from targeted post-training. Code is available at https://github.com/xzx34/Cross-Lingual-Pitfalls.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9145.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9145.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based simulation (cross-lingual probing)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model-based Simulation Framework for Cross-Lingual Weakness Identification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulation framework that uses multiple LLMs to answer perturbed bilingual question pairs and compute a simulation score to guide beam-search perturbation generation and rank candidate bilingual pairs that reveal cross-lingual weaknesses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Ensemble of LLMs (Llama-3.1-8B, Gemma-2-9B, Gemma-2-27B, GPT-4o-mini, Qwen2.5-72B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An ensemble of five LLMs used as text-based simulators: Llama-3.1-8B (Meta Llama family, 8B parameters, community release), Gemma-2-9B and Gemma-2-27B (Google Gemma family, 9B and 27B), GPT-4o-mini (OpenAI, smaller cost-efficient GPT-4o variant), and Qwen2.5-72B (Alibaba Qwen family, 72B). The models were used in zero-shot mode for answering perturbed bilingual question pairs to estimate cross-lingual accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Computational linguistics / Multilingual NLP (cross-lingual evaluation and robustness testing)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Given perturbed bilingual question pairs (English q_E' and target-language q_T'), each simulator LLM produces answers for both languages; the framework computes per-model correctness indicators and aggregates them to produce average English and target-language accuracies (βE', βT'), then computes a simulation score V = βE'^γ - βT' to rank perturbations that maximize English-target accuracy divergence and guide beam-search perturbation generation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Per-language accuracy (indicator correctness I(predicted == ground_truth)), averaged across K simulation models to obtain βE' and βT'; derived simulation score V = βE'^γ - βT' (γ > 1) used for ranking. Also conversion rate (proportion of generated bilingual pairs exposing cross-lingual weakness) and cost-per-found-pair reported; comparisons to No-Perturbation (NP) and Direct Perturbation (DP) baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Reported outcomes of using the simulation framework to identify weaknesses: across the generated 6,713 bilingual pairs (16 languages) models typically preserved near-100% English accuracy but experienced large drops in target languages (paper reports average target-language accuracy drops >50% across languages). Example numeric reports: for English→Chinese pairs, average accuracy dropped by nearly 60% across evaluated models; GPT-4o showed a substantial Chinese accuracy drop (reported around ~30% in one comparison and up to 58% in another experiment when incorporated into the simulation ensemble). Many models (including small ones) had near-perfect English accuracy on the constructed examples but fell below 50% in Chinese on the candidate pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Factors identified in the paper: (1) Choice of simulation models M (which models are in the ensemble) — removing/adding models changes which weaknesses are discovered and the measured accuracy drops; (2) linguistic similarity to English — languages closer to English (French, Spanish, Italian, German) are harder to find large gaps, leading to smaller drops and higher generation cost; (3) perturbation design and strength (proxy LLM temperature, perturbation function φ, beam-search width w and depths d1/d2) affect how effectively perturbations degrade target-language accuracy while preserving English correctness; (4) translation and semantic-checking quality (translation artifacts can confound observed drops); (5) subject domain of questions (Science & Technology, Society & Culture, etc.) — different languages show domain-specific weakness distributions; (6) simulation scoring hyperparameters (γ amplifies English accuracy in V) and redundancy control r; (7) prompt/template quality for perturbation generation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to two baselines: No Perturbation (NP, direct translation only) and Direct Perturbation (DP, applying perturbations without beam search). The beam-search + LLM-simulation method achieved substantially higher conversion rates (Table 1) across evaluated languages and found many more bilingual pairs where English accuracy remained high but target-language accuracy dropped. The paper also compares results across different ensemble compositions (e.g., replacing/removing Gemma/Qwen with GPT-4o) and reports changes in discovered weaknesses and model accuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported limitations include reliance on translation fidelity (translation errors can cause spurious apparent weaknesses), reduced sensitivity of the perturbation strategy to very short prompts, potential cultural/idiomatic discrepancies, imperfect human-evaluation confirmation rates (semantic equivalence and answer consistency less than 100% in some languages), and varying cost/difficulty for languages closer to English. Also, the framework finds weaknesses related to added perturbations and complexity; it may miss other failure modes not triggered by perturbations.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors recommend rigorous semantic equivalence checks (LLM + human verification) to avoid attributing translation artifacts to model weakness; targeted fine-tuning on identified weak language pairs (SFT and DPO) can improve performance, with stronger gains in linguistically related languages; use of discovered hard bilingual examples to augment pre-training/instruction tuning or continual learning; careful selection of simulation ensemble models to surface model-specific weaknesses; and incorporating domain/subject categorizations to focus interventions where weaknesses concentrate.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unveiling the power of language models in chemical research question answering <em>(Rating: 2)</em></li>
                <li>Medtrinity-25m: A large-scale multimodal dataset with multigranular annotations for medicine <em>(Rating: 1)</em></li>
                <li>Geolocation with real human gameplay data: A large-scale dataset and human-like reasoning framework <em>(Rating: 1)</em></li>
                <li>Social science meets llms: How reliable are large language models in social simulations? <em>(Rating: 2)</em></li>
                <li>What can large language models do in chemistry? a comprehensive benchmark on eight tasks <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9145",
    "paper_id": "paper-278904953",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "LLM-based simulation (cross-lingual probing)",
            "name_full": "Large Language Model-based Simulation Framework for Cross-Lingual Weakness Identification",
            "brief_description": "A simulation framework that uses multiple LLMs to answer perturbed bilingual question pairs and compute a simulation score to guide beam-search perturbation generation and rank candidate bilingual pairs that reveal cross-lingual weaknesses.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Ensemble of LLMs (Llama-3.1-8B, Gemma-2-9B, Gemma-2-27B, GPT-4o-mini, Qwen2.5-72B)",
            "model_description": "An ensemble of five LLMs used as text-based simulators: Llama-3.1-8B (Meta Llama family, 8B parameters, community release), Gemma-2-9B and Gemma-2-27B (Google Gemma family, 9B and 27B), GPT-4o-mini (OpenAI, smaller cost-efficient GPT-4o variant), and Qwen2.5-72B (Alibaba Qwen family, 72B). The models were used in zero-shot mode for answering perturbed bilingual question pairs to estimate cross-lingual accuracy.",
            "scientific_subdomain": "Computational linguistics / Multilingual NLP (cross-lingual evaluation and robustness testing)",
            "simulation_task": "Given perturbed bilingual question pairs (English q_E' and target-language q_T'), each simulator LLM produces answers for both languages; the framework computes per-model correctness indicators and aggregates them to produce average English and target-language accuracies (βE', βT'), then computes a simulation score V = βE'^γ - βT' to rank perturbations that maximize English-target accuracy divergence and guide beam-search perturbation generation.",
            "evaluation_metric": "Per-language accuracy (indicator correctness I(predicted == ground_truth)), averaged across K simulation models to obtain βE' and βT'; derived simulation score V = βE'^γ - βT' (γ &gt; 1) used for ranking. Also conversion rate (proportion of generated bilingual pairs exposing cross-lingual weakness) and cost-per-found-pair reported; comparisons to No-Perturbation (NP) and Direct Perturbation (DP) baselines.",
            "simulation_accuracy": "Reported outcomes of using the simulation framework to identify weaknesses: across the generated 6,713 bilingual pairs (16 languages) models typically preserved near-100% English accuracy but experienced large drops in target languages (paper reports average target-language accuracy drops &gt;50% across languages). Example numeric reports: for English→Chinese pairs, average accuracy dropped by nearly 60% across evaluated models; GPT-4o showed a substantial Chinese accuracy drop (reported around ~30% in one comparison and up to 58% in another experiment when incorporated into the simulation ensemble). Many models (including small ones) had near-perfect English accuracy on the constructed examples but fell below 50% in Chinese on the candidate pairs.",
            "factors_affecting_accuracy": "Factors identified in the paper: (1) Choice of simulation models M (which models are in the ensemble) — removing/adding models changes which weaknesses are discovered and the measured accuracy drops; (2) linguistic similarity to English — languages closer to English (French, Spanish, Italian, German) are harder to find large gaps, leading to smaller drops and higher generation cost; (3) perturbation design and strength (proxy LLM temperature, perturbation function φ, beam-search width w and depths d1/d2) affect how effectively perturbations degrade target-language accuracy while preserving English correctness; (4) translation and semantic-checking quality (translation artifacts can confound observed drops); (5) subject domain of questions (Science & Technology, Society & Culture, etc.) — different languages show domain-specific weakness distributions; (6) simulation scoring hyperparameters (γ amplifies English accuracy in V) and redundancy control r; (7) prompt/template quality for perturbation generation.",
            "comparison_baseline": "Compared to two baselines: No Perturbation (NP, direct translation only) and Direct Perturbation (DP, applying perturbations without beam search). The beam-search + LLM-simulation method achieved substantially higher conversion rates (Table 1) across evaluated languages and found many more bilingual pairs where English accuracy remained high but target-language accuracy dropped. The paper also compares results across different ensemble compositions (e.g., replacing/removing Gemma/Qwen with GPT-4o) and reports changes in discovered weaknesses and model accuracies.",
            "limitations_or_failure_cases": "Reported limitations include reliance on translation fidelity (translation errors can cause spurious apparent weaknesses), reduced sensitivity of the perturbation strategy to very short prompts, potential cultural/idiomatic discrepancies, imperfect human-evaluation confirmation rates (semantic equivalence and answer consistency less than 100% in some languages), and varying cost/difficulty for languages closer to English. Also, the framework finds weaknesses related to added perturbations and complexity; it may miss other failure modes not triggered by perturbations.",
            "author_recommendations_or_insights": "Authors recommend rigorous semantic equivalence checks (LLM + human verification) to avoid attributing translation artifacts to model weakness; targeted fine-tuning on identified weak language pairs (SFT and DPO) can improve performance, with stronger gains in linguistically related languages; use of discovered hard bilingual examples to augment pre-training/instruction tuning or continual learning; careful selection of simulation ensemble models to surface model-specific weaknesses; and incorporating domain/subject categorizations to focus interventions where weaknesses concentrate.",
            "uuid": "e9145.0",
            "source_info": {
                "paper_title": "Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unveiling the power of language models in chemical research question answering",
            "rating": 2,
            "sanitized_title": "unveiling_the_power_of_language_models_in_chemical_research_question_answering"
        },
        {
            "paper_title": "Medtrinity-25m: A large-scale multimodal dataset with multigranular annotations for medicine",
            "rating": 1,
            "sanitized_title": "medtrinity25m_a_largescale_multimodal_dataset_with_multigranular_annotations_for_medicine"
        },
        {
            "paper_title": "Geolocation with real human gameplay data: A large-scale dataset and human-like reasoning framework",
            "rating": 1,
            "sanitized_title": "geolocation_with_real_human_gameplay_data_a_largescale_dataset_and_humanlike_reasoning_framework"
        },
        {
            "paper_title": "Social science meets llms: How reliable are large language models in social simulations?",
            "rating": 2,
            "sanitized_title": "social_science_meets_llms_how_reliable_are_large_language_models_in_social_simulations"
        },
        {
            "paper_title": "What can large language models do in chemistry? a comprehensive benchmark on eight tasks",
            "rating": 2,
            "sanitized_title": "what_can_large_language_models_do_in_chemistry_a_comprehensive_benchmark_on_eight_tasks"
        }
    ],
    "cost": 0.012136999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models
24 May 2025</p>
<p>Zixiang Xu 
MBZUAI</p>
<p>Yanbo Wang 
MBZUAI</p>
<p>Yue Huang 
University of Notre Dame</p>
<p>Xiuying Chen xiuying.chen@mbzuai.ac.ae 
MBZUAI</p>
<p>Jieyu Zhao 
University of Southern California</p>
<p>Meng Jiang 
University of Notre Dame</p>
<p>Xiangliang Zhang xzhang33@nd.edu 
University of Notre Dame</p>
<p>Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models
24 May 20255B4865DEBE95D97DC58AF37462E29BEEarXiv:2505.18673v1[cs.CL]LLM-Based Simulation
Large Language Models (LLMs) have achieved remarkable success in Natural Language Processing (NLP), yet their cross-lingual performance consistency remains a significant challenge.This paper introduces a novel methodology for efficiently identifying inherent crosslingual weaknesses in LLMs.Our approach leverages beam search and LLM-based simulation to generate bilingual question pairs that expose performance discrepancies between English and target languages.We construct a new dataset of over 6,000 bilingual pairs across 16 languages using this methodology, demonstrating its effectiveness in revealing weaknesses even in state-of-the-art models.The extensive experiments demonstrate that our method precisely and cost-effectively pinpoints crosslingual weaknesses, consistently revealing over 50% accuracy drops in target languages across a wide range of models.Moreover, further experiments investigate the relationship between linguistic similarity and cross-lingual weaknesses, revealing that linguistically related languages share similar performance patterns and benefit from targeted post-training.Code is available at https://github.com/xzx34/Cross-Lingual-Pitfalls.</p>
<p>Introduction</p>
<p>Large language models (LLMs) have rapidly ascended to prominence in Natural Language Processing (NLP), gaining recognition for their exceptional performance across various tasks, spanning from the sciences (Li et al., 2024a;Guo et al., 2023;Huang et al., 2024c;Wang et al., 2025b;Xu et al., 2025a) to the development of LLM-based agents (Liu et al., 2023b(Liu et al., , 2024b)).Recent advancements have driven research on enhancing LLMs' multilingual capabilities (Zhao et al., 2024a;Wang et al.,  2025d), improving their effectiveness in addressing real-world problems with greater nuance and global reach.Despite advancements, inconsistencies in model performance across languages remain a significant challenge (Xu et al., 2024).The proficiency demonstrated in English often fails to generalize to other languages, resulting in errors in other linguistic contexts, as exemplified in Figure 1.To effectively enhance the cross-lingual consistency of these models, an initial and crucial step is the identification of their inherent cross-lingual weaknesses.Since English is the primary training language for LLMs, and they generally perform best in English (Li et al., 2024b), we define cross-lingual weakness in this paper as: For a given question presented in multiple languages, a model answers correctly in English but incorrectly in at least one other language.This definition requires the model to provide the correct answer in English, as failure across all languages The overview of the proposed methodology for generating questions that precisely challenge the crosslingual capabilities of LLMs.As depicted, the pipeline initiates with sampling English questions and creating bilingual pairs.Iterative perturbation, driven by a beam search strategy and guided by LLM-based simulation scores, refines these pairs to maximize performance divergence between English and the target language.The resulting candidate list of question pairs is designed to highlight inherent cross-lingual weaknesses in LLMs.</p>
<p>would likely indicate a knowledge-related limitation rather than a cross-lingual weakness.</p>
<p>To efficiently uncover these weaknesses, we propose a beam search-based methodology.This approach leverages existing, high-quality English datasets and iteratively introduces perturbations to the English questions.These perturbations are designed to increase question complexity and cognitive demand for comprehension and completion.The goal is to prevent models from generating answers based on superficial cues without genuine language understanding (Stacey et al., 2020;Bhargava et al., 2021), thereby exposing disparities in cross-lingual capabilities.Our approach begins with sourcing English questions from high-quality existing datasets, which are then translated into the target language to form bilingual question pairs.Crucially, this translation process incorporates a semantic check to guarantee that the meaning of the questions is preserved and the correct answer remains consistent across languages.Subsequently, these pairs undergo iterative perturbations, generating a diverse set of perturbed pairs.Then we employ an LLM-based simulation framework that assigns a simulation score measuring the effectiveness of revealing cross-lingual weaknesses, to each pair for ranking.The top-ranked pairs are iteratively perturbed to further refine the search process.Finally, question pairs with consistently high accuracy in English but significant performance drops in the target language are added to the candidate list to expose cross-lingual weaknesses in LLMs.</p>
<p>Furthermore, to study how cross-lingual weaknesses are relevant to linguistic similarity, we con-ducted exploratory experiments.Our key findings reveal that: 1) languages closer in linguistic terms tend to share similar weaknesses; and 2) finetuning LLMs on one language improves performance more significantly in linguistically similar languages.These results highlight that linguistic relationships strongly influence cross-lingual performance.</p>
<p>In summary, our contributions are: 1) We present an efficient, precise methodology for identifying LLM cross-lingual weaknesses.2) Based on the proposed methodology, we construct a novel, 16language dataset with over 6,000 bilingual pairs to challenge cross-lingual capabilities.3) Extensive experiments on the dataset quantitatively analyze the relationship between cross-lingual weaknesses and linguistic similarities and fine-tuning experiments demonstrate the potential for targeted crosslingual improvement.</p>
<p>Methodology</p>
<p>In this section, we introduce our methodology for automatically probing the cross-lingual weakness of multilingual LLMs.As illustrated in Figure 2, our goal is to generate questions that precisely challenge the cross-lingual capabilities of LLMs by identifying cases where the model performs well in English but struggles with the same questions when presented in a specific target language.</p>
<p>Method Overview</p>
<p>To achieve the goal described above, we first sample a set of English questions and translate them into bilingual pairs, where each pair consists of an English question and its counterpart in the target language.We then iteratively introduce perturbations to these pairs using a beam search strategy, guided by maximizing the accuracy discrepancy between English and the target language (i.e., to retain the accuracy on English questions but make accuracy on target language questions drop as much as possible).This search-and-perturbation approach is inspired by prior work on uncovering model vulnerabilities through optimization-guided example construction (Huang et al., 2025b).During beam search, a LLM-based simulation is utilized to guide the search process in identifying the model's weaknesses in the target language.Based on the search optimization strategies, we aim to balance the tradeoff between problem generation and computational cost.It ultimately produces a candidate list of English-target language question pairs, effectively highlighting the model's cross-lingual weaknesses.</p>
<p>Problem Formulation</p>
<p>Let B = {(q E i , q T i )} W i=1 denote our original set of W bilingual pairs.Each bilingual pair (q E , q T ) is formally represented as:
(q E , q T , a E ⋆ , a T ⋆ , A E ¬ , A T ¬ ),(1)
where q E , q T ∈ Q represent question texts in English and the target language, respectively.a E ⋆ , a T ⋆ ∈ A are the corresponding ground-truth answers.A E ¬ , A T ¬ denote incorrect answer choices.During the beam search process, we iteratively apply perturbations to bilingual pairs.Specifically, given an English question q E from a bilingual pair and an incorrect answer α E ∈ A E ¬ , the perturbation function φ generates a semantically irrelevant yet contextually plausible perturbation:
δq E = φ(q E , α E ),(2)
where φ : Q × A → Q modifies q E while preserving its original semantics and embedding patterns influenced by the incorrect answer α E .Here, φ is a proxy LLM utilized for adding the perturbation.The perturbed English question is then formed as:
q E ′ = ⊕(q E , δq E ),(3)
where ⊕ : Q × Q → Q denotes a context-sensitive insertion of the perturbation into q E .During implementation, ⊕ is a concatenation operation.</p>
<p>To maintain consistency across languages, the corresponding perturbation in the target language is generated as δq T = T (δq E ), where T : Q → Q is a translation module that strictly translates the inserted perturbation without modifying other parts of the question.This results in the perturbed targetlanguage question: q T ′ = ⊕(q T , δq T ).</p>
<p>We optimize the perturbation to minimize the model's accuracy in the target language while maintaining near-perfect performance in English.Formally, our objective is:
min δq E E I(F(q T ′ ) = a T ⋆ ) s.t. E I(F(q E ′ ) = a E ⋆ ) ≥ 1 − ϵ S(q E , q E ′ ) ≥ θ, S(q E ′ , q T ′ ) ≥ θ ′ . (4)
where F represents the LLM's response function, S is a semantic similarity function, θ and θ ′ are threshold values ensuring semantic consistency, and I(•) is the indicator function, which returns 1 if the predicted answer is correct and 0 otherwise.The first constraint ensures that perturbations δq E preserve the model's accuracy in English (E ≥ 1 − ϵ), while the second set of constraints ensures that the perturbed and original questions remain semantically equivalent in both English and the target language.</p>
<p>LLM-Based Simulation</p>
<p>LLM-based simulation utilizes a set of LLMs to answer perturbed questions and derive a simulation score based on the accuracy relationship between bilingual pairs.The simulation employs a collection of LLMs, denoted as M = {M 1 , M 2 , . . ., M K }, to quantify the cross-lingual performance gap introduced by perturbations.For each perturbed bilingual pair (q E ′ , q T ′ ), each M k ∈ M generates predicted answers:
âE ′ k = M k (q E ′ ), âT ′ k = M k (q T ′ ). (5)
The correctness of these predictions is assessed by comparing them to the ground truth answers:
β E ′ k = I(â E ′ k = a E ⋆ ), β T ′ k = I(â T ′ k = a T ⋆ ). (6)
The average accuracy across all models is computed as: To evaluate the effectiveness of each perturbation, we define a simulation score V (q E ′ , q T ′ ) that highlights significant performance discrepancies:
βE ′ = 1 K K k=1 β E ′ k , βT ′ = 1 K K k=1 β T ′ k . (7) $ P K D U L F $ U D E L F % H Q J D O L &amp; K L Q H V H ) U H Q F K * H U P D Q + H E U H Z + L Q G L , W D O L D Q -D S D Q H V H . R U H D Q 6 S D Q L V K 6 Z D K L O L 8 N U D L Q L D Q &lt; R U X E D = XV (q E ′ , q T ′ ) = βE ′ γ − βT ′ ,(8)
where γ &gt; 1 is an exponent that amplifies high English accuracy.This formulation prioritizes bilingual pairs where the model maintains strong performance in English ( βE ′ ≈ 1) but exhibits significant degradation in the target language ( βT ′ ).</p>
<p>Beam Search with Optimization Strategies</p>
<p>Since beam search is an effective heuristic for exploring a constrained search space, we employ it to solve the objective function in Equation 4 by greedily identifying the top perturbation candidates produced by the proxy LLMs.These candidates are evaluated and ranked based on their effectiveness in causing performance discrepancies, defined as V (q E ′ , q T ′ ) in Equation 8.</p>
<p>Here, the search width w determines the number of top-ranked bilingual pairs retained after ranking at each iteration, effectively controlling the breadth of the search at each level of the search tree.The initial search depth d 1 specifies the maximum depth of the search tree explored in the initial phase, corresponding to the maximum number of perturbation iterations applied to a question.</p>
<p>Next, we discuss key factors in the Beam Search process that determine: 1) when a perturbed question qualifies as a valid candidate, 2) when to terminate the search for a given bilingual pair, and 3) how to ensure diversity within the set of candidates.</p>
<p>Inclusion Threshold Strategy.A bilingual pair is immediately included in the candidate list if its simulation score exceeds a predefined inclusion threshold θ inc , ensuring early termination for critical perturbations.Otherwise, the top w scoring pairs are selected to advance to the next search level, where the search depth increments by one.</p>
<p>Early Stopping Mechanism.To adaptively adjust the search depth based on the quality of discovered perturbations, we introduce a potential threshold θ pot , which determines whether the search should continue beyond the initial depth.Specifically, the search depth d at iteration t is updated as follows:
d t = d 2 , if max q E ′ ,q T ′ ∈Bt V (q E ′ , q T ′ ) ≥ θ pot , d 1 , otherwise.
(9) where B t represents the set of bilingual pairs at iteration t.The search process continues until reaching the maximum allowable depth, d max = max(d 1 , d 2 ).Thus, if at any iteration a perturbation achieves a simulation score surpassing θ pot , the search depth is expanded to d 2 , allowing further exploration.Otherwise, the search remains at d 1 .The process terminates when d max is reached.</p>
<p>Redundancy Control Mechanism.To ensure diversity in the candidate list, if r bilingual pairs originating from the same initial question have already been included in the candidate list, all remaining bilingual pairs derived from that question are discarded from further exploration.This prevents excessive redundancy and ensures a wider variety of perturbed questions in the candidate list.Notably, in most languages, identifying a bilingual pair that exposes cross-lingual weaknesses costs less than $0.05.However, for languages structurally and lexically closer to English, such as French and Spanish, finding weaknesses becomes significantly harder, leading to higher costs.
&lt; R U X E D $ P K D U L F = X O X % H Q J D O L 6 Z D K L O L . R U H D Q $ U D E L F + L Q G L + H E U H Z -D S D Q H V H 8 N U D L Q L D Q &amp; K L Q H V H * H U P D Q , W D O L D Q ) U H Q F K 6 S D Q L V K &amp;RQYHUVLRQ5DWH $YHUDJH&amp;RVW
3 Experiment</p>
<p>Experiment Overview</p>
<p>In this section, we conduct a series of experiments to evaluate the effectiveness of our proposed method as well as to explore the cross-lingual weaknesses of multilingual models.Overall, we mainly aim to address the following questions:</p>
<p>• RQ1: How effective and efficient is our method in identifying the cross-lingual weaknesses of multilingual models?( §3.2) • RQ2: Are the identified weaknesses languagespecific?How can we understand the linguistic connection between cross-lingual weaknesses and the languages involved?( §3.3) • RQ3: Furthermore, to what extent does language-specific fine-tuning enhance crosslingual performance, and how is the fine-tuning improvement associate with the relationships of different languages?( §3.4)</p>
<p>Cross-Lingual Weakness Identification</p>
<p>To answer RQ1, based on the proposed method, we generated initial bilingual pairs using GPT-4o and employed GPT-4o-mini for perturbation generation.Perturbations were translated using the Google Translate API (Google).We then employed W cost-effective multilingual models in M for LLM-based simulation to generate a set of candidates over 6,000 question pairs spanning 16 languages.These pairs are then used to evaluate the performance of 10 different models.Detailed experimental settings and parameter configurations are provided in Appendix B.</p>
<p>Our method effectively identifies cross-lingual weaknesses even in state-of-the-art models.Taking Chinese as an example, we evaluated all models on our generated English-Chinese pairs and found that their accuracy dropped by nearly 60% on average when switching from English to Chinese, as shown in Figure 5. Notably, even the smallest models achieved perfect accuracy on English tasks (i.e., they have mastered the most knowledge of answering the questions), whereas the most advanced model, GPT-4o, still exhibited a substantial accuracy drop of nearly 30% in Chinese.Similar performance gaps were observed across other languages, as presented in Appendix B.2.As shown in Figure 3, the accuracy drops across 16 languages highlight the cross-lingual performance gaps.Even Claude-3.5-sonnetexperienced over 20% accuracy loss in most languages.This starkly demonstrates the effectiveness of our method in identifying cross-lingual weaknesses in even state-of-the-art multilingual models.</p>
<p>Moreover, from Figure 5, we can observe that the models used for simulation typically exhibit greater accuracy degradation.By varying the models in M for LLM-based simulation, we can discover specific cross-lingual weaknesses in any given LLMs.To investigate this, we replaced Gemma-2-27B and Qwen2.5-72B with GPT-4o in our simulation framework.A comparison between Figure 5 and Figure 10 reveals that: Qwen2.5-72B and Gemma-2-27B show minor accuracy improvements after being removed from the simulation models, GPT-4o-despite being a top-tier multilingual model-suffers a sharp 58% accuracy drop.</p>
<p>Our method enables the cost-effective identification of cross-lingual weaknesses.We evaluated the cost of generating bilingual pairs and analyzed the conversion rate for each language-i.e., the proportion of bilingual pairs successfully generated from an original English question-as illustrated in Figure 4.For most languages, the average cost of identifying a question that exposes a model's cross-lingual weaknesses is as low as $0.05.</p>
<p>Interestingly, for most languages, the cost of generating pairs is significantly lower, compared to the specific languages like French, Spanish, Italian, and German.This discrepancy can be explained by the greater linguistic similarities of these languages to English, particularly in terms of script, vocabulary, and grammatical structures (Schepens et al., 2012;Gnanadesikan, 2017).For languages that are structurally closer to English, models tend to perform at levels more comparable to their English proficiency (Conneau, 2019;Pires, 2019), which makes it more challenging to uncover their cross-lingual weaknesses.A more detailed analysis Our search framework significantly outperforms baseline approaches.We compared our beam search method with two baseline approaches: No Perturbation (NP) and Direct Perturbation (DP).In NP, we directly translate the English questions to target languages without any perturbation, while in DP, we apply perturbations through prompts following the template in Appendix E directly, without search.Using models in M for simulation, we identify questions where models perform well in English but fail in target languages.As shown in Table 1, our framework consistently achieves substantially higher conversion rates across all evaluated languages compared to both baselines.</p>
<p>Linguistic Factors in Cross-lingual Weaknesses</p>
<p>To answer RQ2, we first sampled 100 seed bilingual pairs (i.e., English-target language pairs) for each of 16 languages from those generated in subsection 3.2.For each sampled pair, the targetlanguage portion was translated into the other 15 languages, resulting in a total of 25,600 expanded bilingual pairs.These expanded pairs were then evaluated across six different models, with detailed experimental settings outlined in Appendix B.</p>
<p>The identified cross-lingual weaknesses are not restricted to specific languages and depend on the linguistic relationships.The evaluation results of GPT-4o-mini on expanded pairs from the Asian language family (Chinese, Japanese, and Korean) and the European language family (French, German, and Spanish) are presented in Figure 6.As observed, the model exhibits a consistent decline in accuracy across these pairs.</p>
<p>A clear pattern emerges when analyzing the expanded pairs.Within the Asian language family, weakness pairs expanded from Chinese, Japanese, or Korean into other Asian languages exhibit substantial and relatively consistent accuracy declines.In contrast, when these Asian seed pairs are expanded into European languages, the accuracy drops are considerably smaller and more variable.A similar trend is observed within the European language family: pairs expanded from French, German, or Spanish into other European languages experience significant and consistent accuracy declines, whereas expansion into Asian languages results in smaller and more varied reductions in accuracy.We hypothesize that these patterns are driven by underlying linguistic relationships.Specifically, the Asian language family exhibits shared crosslinguistic challenges, while the European family follows similar patterns.Consequently, expanded pairs from Chinese seed pairs tend to maintain more weakness in Japanese and Korean, whereas those from French seed pairs lead to increased weakness in German and Italian.</p>
<p>Languages with stronger linguistic affinity tend to exhibit cross-lingual weaknesses in common.We define the Relative Affinity Score (RAS) D x,y , which measures the linguistic relationships between language x and language y.The score is computed as:
D x,y = A x,y − A x A x • exp c • A y − A x
Here, D x,y quantifies the linguistic proximity between language x and y, with lower values indicating a stronger affinity.The term A x,y represents the model's accuracy on language x when using expanded pairs originating from seed language y.The average accuracy on language x across all seed languages for expanded pairs is denoted by A x .The factor exp c • A y − A x scales the score based on the accuracy difference between languages x and y, where constant c, a negative value, controls the inverse sensitivity of this adjustment.As shown in Figure 7, it reveals a clear pattern: lower RAS values D x,y are predominantly observed for language pairs (x, y) with linguistic and cultural proximities.This observation strongly supports our hypothesis that languages with closer linguistic ties tend to share cross-lingual weaknesses.
$ P K D U LF $ U D E LF % H Q J D OL &amp; K LQ H V H ) U H Q F K * H U P D Q + H E U H Z + LQ G L ,W D OL D Q -D S D Q H V H . R U H D Q 6 S D Q LV K 6 Z D K LO L 8 N U D LQ LD Q &lt; R U X E D = X
We further investigated the linguistic basis of these cross-lingual weaknesses by analyzing the embedding space of seed bilingual pairs.Specifically, we embedded cross-lingual weaknesses identified in subsection 3.2 for the Asian and European language families.As shown in Figure 9, visualizing these embeddings via t-SNE revealed a clustering effect: weaknesses from the same family clustered together.This observation was corroborated by the cosine distance matrix, as presented in Figure 8, which showed significantly smaller embedding distances within the Asian and European families compared to distances between families.</p>
<p>Cross-lingual weaknesses correlate with specific subject domains.</p>
<p>Cross-lingual Fine-tuning</p>
<p>To answer RQ3, we designed a fine-tuning experiment to explore whether language-specific finetuning preferentially enhances performance on linguistically similar languages.We focused on two language families identified as linguistically proximate in our earlier analysis: the Asian language family (Chinese, Japanese, and Korean) and the European language family (French, German, and Spanish).Using the Chinese and French seed pairs identified in subsection 3.2, we performed both supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) (Rafailov et al., 2023) on several LLMs: Phi-3.5-Mini,Gemma-2-9B, Llama-3.1-8B,Qwen2.5-7B.Separate fine-tuning runs were conducted using both Chinese and French portion in seed pairs.Subsequently, we evaluated the performance of these fine-tuned models across the other languages in two language families.This experiment aimed to investigate if fine-tuning on a specific language leads to greater performance gains in linguistically related languages.As shown in Table 2 and Table 5, the evaluation results reveal a consistent trend: fine-tuning on Chinese significantly improves performance in Japanese and Korean, while its impact on European languages is comparatively smaller.Similarly, finetuning on French enhances performance in related European languages like German and Spanish but has a weaker effect on Asian languages.This pattern holds across both SFT and DPO fine-tuning, indicating that linguistic proximity, rather than the fine-tuning method, primarily drives cross-lingual knowledge transfer.These findings suggest that current LLMs inherently capture linguistic relationships, facilitating more effective transfer between closely related languages.</p>
<p>Discussion</p>
<p>Our investigation into cross-lingual weaknesses underscores several critical aspects for both under-standing current LLM limitations and paving the way for future improvements.</p>
<p>First, the integrity of our findings hinges on the quality of translation in bilingual question pairs.If semantic equivalence between the English source and target language question is not rigorously maintained, observed performance drops could be mistakenly attributed to the model's cross-lingual deficiencies rather than translation artifacts.To mitigate this, we employed LLMs for both initial translation and semantic verification, a widely adopted practice in multilingual research (Lin et al., 2024;Ye et al., 2024).The efficacy of this approach was further corroborated through human evaluation, whose methodology and results are presented in Appendix C. The evaluation confirmed that most generated pairs exhibit high translational fidelity.As multilingual capabilities of LLMs continue to advance, developing more sophisticated and reliable translation and semantic checking components will be instrumental in refining the precision with which cross-lingual weaknesses are identified and analyzed.</p>
<p>Second, to provide a richer, more nuanced understanding beyond aggregate statistics, we have compiled an extensive set of case studies.These qualitative examples, detailed in Appendix D, illustrate the diverse nature of cross-lingual pitfalls encountered by various models across different languages.They showcase specific failure modes, such as misinterpretation of nuanced phrasing, incorrect entity mapping, or breakdowns in reasoning when faced with linguistic structures that differ significantly from English.These case studies offer valuable material for researchers seeking to conduct in-depth analyses of specific cross-lingual phenomena or to understand the particular challenges faced by individual models or language families.</p>
<p>Finally, the identification of these cross-lingual weaknesses is not merely an academic exercise but offers substantial potential for enhancing the multilingual capabilities of LLMs.Our methodology serves as a diagnostic tool, pinpointing specific areas where LLMs falter, thereby guiding targeted interventions.For instance, the weaknesses uncovered can inform more focused fine-tuning strategies, concentrating efforts on language pairs or specific linguistic constructions where models demonstrate pronounced deficiencies, potentially leveraging the subject domain categorizations (as shown in Table 4) to further refine this targeting.Furthermore, the challenging cross-lingual exam-ples generated by our method can be invaluable for augmenting pre-training and instruction-tuning datasets (Huang et al., 2024b).By enriching training corpora with instances that expose known weaknesses, we can proactively address data imbalances or representational gaps that contribute to these performance discrepancies.Lastly, these targeted examples are well-suited for continual learning or adaptive training paradigms, enabling models to iteratively strengthen their cross-lingual understanding and reasoning in precisely the areas where they have been shown to be vulnerable.In essence, a systematic approach to uncovering weaknesses, such as the one proposed, is a crucial first step towards building more robust multilingual LLMs.</p>
<p>Conclusion</p>
<p>In this study, we proposed an efficient beam search with LLM-based simulation to identify cross-lingual weaknesses in LLMs, generating a 16-language dataset that exposed performance gaps even in state-of-the-art models.Our findings highlight linguistic relationships as key to shared vulnerabilities and fine-tuning benefits, emphasizing the need to consider linguistic nuances in developing truly multilingual LLMs.</p>
<p>Limitations</p>
<p>While our methodology demonstrates effectiveness in identifying cross-lingual weaknesses, several avenues for future refinement exist.First, the current study's scope, while covering a diverse set of languages, is not fully comprehensive.A more complete picture of cross-lingual consistency in LLMs would require extending our analysis to a broader range of languages, particularly those with limited resources or significantly different structural characteristics.Relatedly, although we employ LLM-based semantic checks to ensure the semantic equivalence of our bilingual question pairs, subtle nuances arising from cultural context or idiomatic expressions might still introduce minor biases.Finally, our core approach of iteratively adding perturbations is effective at revealing weaknesses related to complexity.However, this strategy may be less sensitive to identifying those vulnerabilities that manifest in very short, concise prompts.Consequently, investigating complementary techniques specifically designed for such cases would enhance the overall robustness of our framework.</p>
<p>Ethics Statement</p>
<p>This research adheres to ethical standards in AI research and development.Our methodology is designed to identify and understand cross-lingual weaknesses in LLMs to improve their multilingual capabilities.We recognize the potential for bias within LLMs, particularly across different languages and cultural contexts.Our language selection was carefully considered to ensure diversity, encompassing both high-resource and lowerresource languages.All generated content and model outputs were scrutinized for potential biases.No personally identifiable information was collected or used.This work is intended to promote inclusivity and fairness in the development of multilingual LLMs.The findings are shared with the research community to foster further investigation and the mitigation of cross-lingual weaknesses in LLMs.</p>
<p>A Related Work</p>
<p>A.1 LLM Evaluation Significant efforts have been devoted to evaluating the capabilities of LLMs across a wide range of domains.These evaluations include traditional NLP tasks such as sentiment analysis (Zhang et al., 2023b;Wan et al., 2025) and translation (Yao et al., 2023;Zhang et al., 2023a), as well as mathematical reasoning (Hendrycks et al., 2021c;Liu et al., 2024a), scientific and domain-specific question answering (Xu et al., 2025b;Luo et al., 2023;Zhou et al., 2023;Chen et al., 2025;Song et al., 2025a), and coding skills (Chen et al., 2021;Jain et al., 2024).Evaluations have also extended into specialized domains such as chemistry (Chen et al., 2025), medicine (Xie et al., 2025), and geolocation reasoning (Song et al., 2025b).In the area of cybersecurity, efforts have been made to assess LLMs' ability to detect software vulnerabilities (Liu et al., 2024c).Beyond task performance, growing attention has been paid to trustworthiness (Sun et al., 2024;Chujie et al., 2024), including robustness to spurious correlations (Liu et al., 2025), resilience to textual perturbations (Wang et al., 2025a), and defense against jailbreak attacks (Gao et al., 2024).Comprehensive benchmarks and investigations have been proposed to systematically assess these aspects (Huang et al., 2025a;Wang et al., 2025c).General-purpose benchmarks like MMLU (Hendrycks et al., 2021b,a) continue to serve as a foundation for evaluating broad LLM capabilities.</p>
<p>In this study, we select a subset of English questions from five widely used question-answering datasets: CommonsenseQA (Naveed et al., 2023), ARC (Clark et al., 2018), MMLU (Hendrycks et al., 2021b,a), SciQ (Welbl et al., 2017), and Truth-fulQA (Lin et al., 2021).These datasets evaluate models on common sense reasoning, mathematical problem-solving, scientific knowledge, and various other skills.We use these questions as the foundation for generating our own dataset.</p>
<p>A.2 Cross-lingual Capablity of LLMs.</p>
<p>The cross-lingual capabilities of LLMs have become a central focus in NLP research.Multitask finetuning (MTF) has proven effective for enhancing cross-lingual generalization, as shown by Muennighoff et al. (2022), where finetuning multilingual models like BLOOM and mT5 on English tasks enabled zero-shot task transfer to other languages.Beyond MTF, cross-lingual prompting techniques such as chain-of-thought (CoT) prompting (Qin et al., 2023) improve reasoning accuracy by aligning representations and employing task-specific solvers.Other approaches, including cross-lingual knowledge editing (Wang et al., 2023), entity-based data augmentation (Yamada and Ri, 2024) and cross-lingual knowledge aggregator (Huang et al., 2024a), have been proposed to enhance adaptation and infuse models with crosslingual knowledge.</p>
<p>Evaluation has also gained attention, with frameworks like the Cross Lingual Auto Evaluation (CIA) Suite (Doddapaneni et al., 2024) addressing challenges in assessing multilingual model outputs.However, many MTF studies remain Englishcentric (Muennighoff et al., 2022), and prompting techniques (Qin et al., 2023) may struggle with diverse linguistic structures.While methods like adapter merging (Zhao et al., 2024b) and continual pre-training (Fujii et al., 2024) aim to enhance language transfer, systematic investigation into multilingual LLM weaknesses across diverse languages remains limited.Additionally, while studies probe cross-lingual alignment during pre-training (Wang et al., 2024;Liu et al., 2023a) and its importance (Hämmerl et al., 2024), a quantifiable measure of linguistic relationships affecting cross-lingual transfer is absent.</p>
<p>Our work builds on these foundations by systematically identifying and analyzing cross-lingual weaknesses in LLMs across 16 diverse languages.By introducing a novel metric to quantify linguistic relationships based on observed performance, we offer deeper insights into how linguistic relation impacts model behavior.</p>
<p>B Experiment Details B.1 Experiment Settings</p>
<p>Source dataset.To create bilingual pairs, we randomly sampled English questions from five commonly used datasets that cover a wide range of model capabilities: ARC, MMLU, Common-senseQA, TruthfulQA, and SciQ.The sampling was performed equally across all five datasets.</p>
<p>Models.As detailed in Table 3, we utilized five proprietary models: GPT-4o (Hurst et al., 2024), GPT-4o-mini (OpenAI, 2024), Yi-Lightning (Wake et al., 2024), Claude-3.5-Sonnet(Anthropic, 2024), and o1-mini (Jaech et al., 2024).In addition, we included seven open-weight models: Gemma-Table 3: Models used in our experiments along with their versions, organizations, licenses, and purposes.Eval: Model used for evaluation; FT: Model used for fine-tuning.
Model Version Organization License Eval FT GPT-4o-mini gpt-4o-mini-2024-07-18 OpenAI Proprietary ✓ GPT-4o gpt-4o-2024-08-06 OpenAI Proprietary ✓ Gemma-2-9B Gemma-2-9B-it Google Gemma License ✓ ✓ Gemma-2-27B Gemma-2-27B-it Google Gemma License ✓ Llama-3.1-8B Meta-Llama-3.1-8B-Instruct Meta Llama 3.1 Community ✓ ✓ Llama-3.1-70B Meta-Llama-3.1-70B-Instruct Meta Llama 3.1 Community ✓ Yi-Lightning Yi-Lightning 01 AI Proprietary ✓ Qwen2.5-7B Qwen2.5-7B-Instruct Alibaba Qwen License ✓ ✓ Qwen2.5-72B Qwen2.5-72B-Instruct Alibaba Qwen License ✓ o1-mini o1-mini-2024-09-12 OpenAI Proprietary ✓ Phi-3.5-mini Phi-3.5-mini-instruct Microsoft MIT ✓ Claude-3.5-Sonnet claude-3-5-sonnet-20241022 Anthropic Proprietary ✓
2-9B, Gemma-2-27B (Team, 2024a), Qwen2.5-7B,Qwen2.5-72B(Yang et al., 2024;Team, 2024b), Llama-3.1-8B(Meta, 2024b), Llama-3.1-70B(Meta, 2024a), and Phi-3.5-mini(Abdin et al., 2024).</p>
<p>Hyperparameter settings.For perturbation generation, we used a temperature of 0.7 to encourage more diverse and creative responses.In the translation, semantic checking, and simulation tasks, the temperature was reduced to 0.001 to ensure stability in the responses.The maximum output length for these tasks was capped at 1,024 tokens.During beam search, we initialized the process with W = 4 bilingual pairs, and the search width was set to w = 12.The search depths were configured to d 1 = 4 and d 2 = 6, respectively.To promote diversity in the generated questions, we set r = 3.The simulation score parameter, γ, was set to 2. For the Early Stopping Mechanism, θ pot was set to 0.6, and for determining inclusion in the candidate list, θ inc was set to 0.8.We employed K = 5 LLMs for LLM-based simulation.The constant C used to calculate the Relative Affinity Score was set to -1.</p>
<p>For the fine-tuning experiments, we trained for 4 epochs with a learning rate of 2.0e-4, employing a cosine learning rate scheduler and a warmup ratio of 0.1.The per-device training batch size was 1, with a gradient accumulation of 8 steps.For evaluation, we used 10% of the training data as a validation set, evaluated every 200 steps, and set the per-device evaluation batch size to 1.</p>
<p>B.2 Experiment Procedures</p>
<p>Experiment procedure of cross-Lingual weakness identification.To generate bilingual question pairs for our cross-lingual weakness identifi-cation experiments, we employed LLM-based simulation using the following models: Llama-3.1-8B,Gemma-2-9B, Gemma-2-27B, GPT-4o-mini, and Qwen2.5-72B.This process resulted in a total of 6713 bilingual pairs across the following languages: Chinese (342 pairs), Japanese (314 pairs), Korean (456 pairs), French (312 pairs), Spanish (242 pairs), Italian (295 pairs), Ukrainian (323 pairs), German (322 pairs), Bengali (431 pairs), Hindi (327 pairs), Arabic (424 pairs), Hebrew (319 pairs), Amharic (665 pairs), Yoruba (813 pairs), Swahili (417 pairs), and Zulu (711 pairs).Subsequently, we performed zero-shot evaluations on all generated question pairs using the following models: Llama-3.1-8B,Gemma-2-9B, Gemma-2-27B, GPT-4o-mini, Llama-3.1-70B,Qwen2.5-72B,o1-mini, Yi-Lightning, GPT-4o, and Claude-3.5sonnet.The results of these evaluations are presented in Figure 5 , 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24 and 25 .Experiment procedure of quantifying the linguistic relationships.To quantify the linguistic relationships between languages, we randomly sampled 100 generated bilingual pairs for each of the following languages: Chinese, Japanese, Korean, French, Spanish, Italian, Ukrainian, German, Bengali, Hindi, Arabic, Hebrew, Amharic, Yoruba, Swahili, and Zulu.We then translated the original question component of these pairs into each of the other fifteen languages using GPT-4o, and the perturbed question component using Google Translate's API (Google).This process, along with the original language, resulted in a total of 25,600 bilingual pairs (16 languages * 100 pairs * 16 translations).We performed zero-shot evaluations on these pairs using six models: Llama-3.1-8B,Gemma-2-27B, GPT-4o-mini, Llama-3.1-70B,Qwen2.5-72B, and GPT-4o.The Relative Affinity Score was then calculated based on the average accuracy of these models, as shown in Figure 7.</p>
<p>Experiment procedure of linguistic relationship analysis through fine-tuning.Leveraging the English-Chinese and English-French question pairs generated in our dataset, we performed SFT and DPO on several Large Language Models: Llama-3.1-8B,Qwen2.5-7B,Gemma-2-9B, and Phi-3.5-Mini.For each model, we conducted separate finetuning runs using both the Chinese and French datasets.To ensure consistency across experiments, we trained for 4 epochs with a learning rate of 2.0e-4, employing a cosine learning rate scheduler and a warmup ratio of 0.1.The per-device training batch size was set to 1, with gradient accumulation performed over 8 steps.During training, we used the correct answers from the models' responses as the target output for each question.For evaluation, we used 10% of the training data as a validation set, evaluated every 200 steps, and set the per-device evaluation batch size to 1.</p>
<p>C Human Evaluation</p>
<p>To ensure that the target language questions in our generated bilingual pairs maintained semantic equivalence and answer consistency with the original English questions, we conducted a human evaluation study.We randomly sampled 100 bilingual pairs from the candidate list for each of the following sixteen languages: Chinese, Japanese, Korean, French, Spanish, Italian, Ukrainian, German, Bengali, Hindi, Arabic, Hebrew, Amharic, Yoruba, Swahili, and Zulu.Four undergraduate students majoring in computer science, proficient in English and various translation tools, were divided into two groups to assess: (1) whether the target language question maintained semantic equivalence with the original English question, and (2) whether the answer to the target language question was consistent with the answer to the original English question.The results of this evaluation are summarized in Table 6.</p>
<p>D Case Study</p>
<p>In Figure 26,27,28,29,30,31,32,and 33, we illustrate case studies of model responses to Englishtarget language (Korean, French, German, Chinese, Italian, Spanish, Japanese, and Ukrainian, respectively) question pairs.Target Language: French</p>
<p>E Prompt Template</p>
<p>Template for Generating Perturbation [Instruction] You are an expert at subtly embedding distractions based on the incorrect option provided.Your task is to generate a distraction that aligns with the incorrect option without altering the original question's quality or meaning.Follow these specific rules:</p>
<p>1.The distraction should naturally integrate with the context of the question but must not explicitly introduce incorrect information or contradict the correct answer.2. The distraction must be subtle and should not make it obvious that it is related to the incorrect option.{"text": "&lt;Übersetzter Text&gt;", "choices": ["&lt;Übersetzte Auswahl1&gt;", "&lt;Übersetzte Auswahl2&gt;", ...], "answer": "&lt;Übersetzte Antwort&gt;"}</p>
<p>Figure 1 :
1
Figure 1: An example of an English-Chinese question pair discovered by our search methodology (where the Chinese question is semantically equivalent to the English) highlights the cross-lingual performance gap: even GPT-4o, despite its strong multilingual capabilities, provides the correct answer in English but gives an incorrect response in Chinese.</p>
<p>Figure2: The overview of the proposed methodology for generating questions that precisely challenge the crosslingual capabilities of LLMs.As depicted, the pipeline initiates with sampling English questions and creating bilingual pairs.Iterative perturbation, driven by a beam search strategy and guided by LLM-based simulation scores, refines these pairs to maximize performance divergence between English and the target language.The resulting candidate list of question pairs is designed to highlight inherent cross-lingual weaknesses in LLMs.</p>
<p>Figure 3 :
3
Figure3: Evaluation of 10 models on our generated 6,600 bilingual pairs across 16 languages.While all models achieve nearly 100% accuracy in English, most experience an average accuracy drop of over 50% in the target languages.Even state-of-the-art multilingual models like GPT-4o and Claude-3.5-sonnetexhibit significant crosslingual weaknesses.</p>
<p>Figure 4 :
4
Figure4: Analysis of question conversion rates and generation costs across 16 languages based on all pairs in our candidate list.The bar chart (red) shows question conversion rates for different languages, while the line chart (purple) represents cost of generating a single question.Notably, in most languages, identifying a bilingual pair that exposes cross-lingual weaknesses costs less than $0.05.However, for languages structurally and lexically closer to English, such as French and Spanish, finding weaknesses becomes significantly harder, leading to higher costs.</p>
<p>Figure 5 :
5
Figure5: Performance of LLMs on our generated English-Chinese pairs.Even smaller models like Gemma-2-9B and Llama-3.1-8Bachieve perfect accuracy in English, while more than half of the models score below 50% in Chinese.Despite their strong multilingual capabilities, GPT-4o and Claude-3.5-sonnetstill exhibit over a 30% accuracy drop compared to English.</p>
<p>Figure 6 :
6
Figure6: Accuracy of GPT-4o-mini on expanded bilingual pairs (Asian and European language families).The red bar represents accuracy for pairs expanded from Chinese seed pairs, while other colors show results for pairs expanded from other seed language pairs within these families.</p>
<p>Figure 7 :
7
Figure 7: Visualization of RAS D x,y across 16 languages, highlighting linguistic and cultural proximities.The vertical axis denotes the source language and the horizontal axis denotes the target language.Darker shades of a block indicate stronger retention of shared cross-lingual weaknesses when translating from language y to language x, signifying a closer linguistic relationship between the two languages.</p>
<p>Figure 8 :
8
Figure 8: Heatmap of the pairwise cosine distances between the normalized embeddings generated by Llama-3.1-8B for seven English-target language question pairs.Yoruba exhibited significantly more errors in the Science &amp; Technology domain compared to most languages.Conversely, higher-resource languages like Chinese, Spanish, and German demonstrated stronger performance in this area.Interestingly, Chinese showed a distinct weakness in Society &amp; Culture, while Korean displayed comparatively weaker performance in Geography &amp; Environment.</p>
<p>Figure 9
9
Figure 9: T-SNE visualization of the embeddings generated by LLaMA-3.1-8B for seven English-target language question pairs.</p>
<p>Figure 10 :
10
Figure 10: Performance of LLMs on English-Chinese pairs after incorporating GPT-4o into the LLM-Based simulation.The Chinese accuracy of GPT-4o dropped significantly</p>
<p>Figure 12 :
12
Figure 12: Performance of LLMs on English-Arabic pairs in our candidate list.</p>
<p>Figure 13 :
13
Figure 13: Performance of LLMs on English-Bengali pairs in our candidate list.</p>
<p>Figure 14 :
14
Figure 14: Performance of LLMs on English-French pairs in our candidate list.</p>
<p>Figure 15 :
15
Figure 15: Performance of LLMs on English-German pairs in our candidate list.</p>
<p>Figure 16 :
16
Figure 16: Performance of LLMs on English-Hebrew pairs in our candidate list.</p>
<p>Figure 17 :
17
Figure 17: Performance of LLMs on English-Hindi pairs in our candidate list.</p>
<p>Figure 18 :
18
Figure 18: Performance of LLMs on English-Italian pairs in our candidate list.</p>
<p>Figure 19 :
19
Figure 19: Performance of LLMs on English-Japanese pairs in our candidate list.</p>
<p>Figure 20 :
20
Figure 20: Performance of LLMs on English-Korean pairs in our candidate list.</p>
<p>Figure 21 :
21
Figure 21: Performance of LLMs on English-Spanish pairs in our candidate list.</p>
<p>Figure 22 :
22
Figure 22: Performance of LLMs on English-Swahili pairs in our candidate list.</p>
<p>Figure 23 :
23
Figure 23: Performance of LLMs on English-Ukrainian pairs in our candidate list.</p>
<p>Figure 24 :
24
Figure 24: Performance of LLMs on English-Yoruba pairs in our candidate list.</p>
<p>Figure 25 :
25
Figure 25: Performance of LLMs on English-Zulu pairs in our candidate list.</p>
<p>FrenchFigure 27 :
27
Figure 27: Case study: GPT-4o-mini's responses to English-French question pairs.</p>
<p>Figure 32 :
32
Figure 32: Case study: Qwen2.5-72B'sresponses to English-Japanese question pairs.</p>
<p>[</p>
<p>The Start of the Question] {question} [The End of the Question] [The Start of the Model's Answer] {answer} [The End of the Model's Answer] [The Start of the Incorrect Option] {wrong_answer} [The End of the Incorrect Option] [Output Format] {Generated Distraction: <Provide a subtle, contextually relevant distraction based on the incorrect option >} Template for English-to-French Translation [Instruction] Vous êtes traducteur professionnel.Votre tâche consiste à traduire le texte, les choix et la réponse ci-dessous de manière précise et naturelle en français, tout en conservant le sens original des questions et des choix.Veuillez respecter strictement les règles suivantes : -La traduction des réponses et des choix doit refléter fidèlement le sens original, sans aucune altération, omission ou ajout.-Toutes les phrases comportant un point d'interrogation doivent rester sous forme de question après traduction, sans changer le ton ou la structure de la phrase.-Le contenu traduit doit respecter les normes et usages de la langue française, être fluide et naturel, en évitant les traductions littérales ou maladroites.[The Start of the Text] {question} [The End of the Text] [The Start of the Choices] {choices} [The End of the Choices] [The Start of the Answer] {ground_truth} [The End of the Answer] [Output Format] {"text": "<Texte traduit en français>", "choices": ["<Choix traduit en français 1>", "<Choix traduit en français 2>", ...], "answer": "<Réponse traduite en français>"} Template for English-to-German Translation [Instruction] Sie sind professioneller Übersetzungsexperte. Ihre Aufgabe besteht darin, den folgenden Text, die Auswahlmöglichkeiten und die Antwort präzise und natürlich ins Deutsche zu übersetzen, wobei der ursprüngliche Sinn der Frage und der Auswahlmöglichkeiten erhalten bleiben muss.Halten Sie sich strikt an die folgenden Regeln: -Die Übersetzung der Antworten und Auswahlmöglichkeiten muss den ursprünglichen Sinn vollständig bewahren, ohne jegliche Abweichungen, Hinzufügungen oder Kürzungen.-Alle Sätze mit einem Fragezeichen müssen auch nach der Übersetzung die Form einer Frage beibehalten, ohne den Ton oder die Struktur des Satzes zu verändern.-Der übersetzte Inhalt muss den sprachlichen Gepflogenheiten des Deutschen entsprechen, natürlich und flüssig formuliert sein und wörtliche, ungeschmeidige Übersetzungen vermeiden.[The Start of the Text] {question} [The End of the Text] [The Start of the Choices] {choices} [The End of the Choices] [The Start of the Answer] {ground_truth} [The End of the Answer] [Output Format]</p>
<p>Table 1 :
1
Comparison of conversion rates across different languages.NP (No Perturbation) refers to direct translation without perturbations, while DP (Direct Perturbation) applies perturbations without search.
LanguageNPDPOursChinese0.0000.0360.431Japanese0.0000.0710.594French0.0000.0180.132German0.0000.0270.323
of how linguistic relationships affect cross-lingual model performance is provided in subsection 3.3.</p>
<p>To further investigate crosslingual weaknesses, we categorized the identified bilingual pairs into six subject domains: Science &amp; Technology, History &amp; World Events, Society &amp; Culture, Arts &amp; Literature, Geography &amp; Environment, and General Knowledge.The distribution of these weaknesses across categories, broken down by language, is detailed in Table 4. Notably, lowerresource languages such as Amharic, Arabic, and</p>
<p>Table 2 :
2
Performance comparison of Phi-3.5-Mini and Llama-3.1-8B after SFT and DPO on French and Chinese datasets.The table shows evaluation results on various evaluation languages (EL), with the Asian language group highlighted in blue.Performance differences (Diff.)areshowncompared to the original model (Orig.)."SEnh."represents the model enhanced by SFT, and "D Enh." represents the model enhanced by simulated DPO.Due to space limitations, performance of Gemma-2-9B and Qwen2.5-7B are presented in Table5.
French Fine-TuningChinese Fine-Tuning
Chinese Japanese Korean French German Italian Spanish</p>
<p>Table 4 :
4
Percentage distribution of weaknesses across different categories for each language, compared to overall averages.Percentages exceeding the overall average for each category are highlighted in orange.Column abbreviations are as follows: Sci &amp; Tech (Science &amp; Technology), Gen Knowl.(General Knowledge), Geo &amp; Env.
(Geography &amp; Environment), Soc &amp; Cult. (Society &amp; Culture), Arts &amp; Lit. (Arts &amp; Literature), and Hist &amp; Events(History &amp; World Events).LanguageSci &amp; Tech Gen Knowl. Geo &amp; Env. Soc &amp; Cult. Arts &amp; Lit. Hist &amp; EventsAmharic61.95%8.12%5.41%15.94%2.26%6.32%Arabic55.42%15.57%0.71%9.20%9.91%9.20%Bengali46.17%16.47%10.21%17.87%7.66%1.62%Chinese25.73%6.43%7.60%47.08%12.28%0.88%French37.50%13.78%10.26%26.28%6.73%5.45%German42.24%19.88%9.32%22.36%0.62%5.59%Hebrew43.26%10.02%0.58%22.57%16.30%6.27%Hindi44.95%17.74%3.06%20.49%11.31%2.45%Italian49.15%6.10%3.39%26.10%5.76%9.49%Japanese48.09%15.29%12.42%19.11%4.46%0.64%Korean27.41%16.45%23.25%25.66%3.07%4.17%Spanish23.97%18.18%4.55%19.01%21.90%12.40%Swahili47.96%8.87%3.12%30.94%4.32%4.80%Ukrainian39.01%10.53%4.33%34.98%6.81%4.33%Yoruba53.01%6.52%7.87%21.03%4.67%6.89%Zulu47.40%13.36%0.98%25.60%8.44%4.22%Overall Average 45.36%12.20%6.63%23.40%7.15%5.26%</p>
<p>Table 5 :
5
Performance comparison of Gemma-2-9B and Qwen2.5-7B after SFT and DPO on French and Chinese datasets.The table shows evaluation results on various evaluation languages (EL), with the Asian language group highlighted in blue.Performance differences (Diff.)are shown compared to the original model (Orig.)."S Enh." represents the model enhanced by SFT, and "D Enh." represents the model enhanced by simulated DPO.</p>
<p>Table 6 :
6
Results of human evaluation on semantic equivalence (Semantic Eq.) and answer consistency (Answer Consis.) between original English questions and target language questions in bilingual pairs.
LanguageSemantic Eq. (%) Answer Consis. (%)Amharic83.088.0Arabic90.094.0Bengali88.093.0Chinese95.098.0French97.099.0German96.098.0Hebrew93.095.0Hindi91.094.0Italian96.097.0Japanese93.095.0Korean91.093.0Spanish98.0100.0Swahili89.093.0Ukrainian92.095.0Yoruba84.090.0Zulu86.091.0</p>
<p>English Question: Acute binge drinking is associated with?It's interesting to note how certain lifestyle choices can impact cardiovascular health, often leading to discussions about various heart-related conditions that can be exacerbated by excessive alcohol consumption.This raises an intriguing point about how emotional states can influence physical health, as many studies explore the connection between stress relief and heart function, often highlighting the importance of maintaining a balanced lifestyle for overall well-being.</p>
<p>English Choices: ["Happy heart syndrome", "Home heart syndrome", "Beach heart syndrome", "Holiday heart syndrome"] English Ground Truth: Holiday heart syndrome</p>
<p>Template for English-to-Italian Translation [Instruction] Sei un professionista.Il tuo compito è tradurre il seguente testo, le opzioni e la risposta in italiano in modo accurato e naturale, assicurandoti di preservare il significato originale della domanda e delle opzioni.Segui rigorosamente le seguenti regole:-La traduzione delle risposte e delle opzioni deve mantenere completamente il significato originale, senza alcuna deviazione, aggiunta o omissione.-Tutte le frasi con un punto interrogativo devono mantenere la forma interrogativa dopo la traduzione, senza alterare il tono o la struttura della frase.-Il contenuto tradotto deve rispettare le abitudini linguistiche dell'italiano, essere naturale e fluido, evitando traduzioni letterali e rigide.{"text": "<Testo tradotto>", "choices": ["<Opzione tradotta 1>", "<Opzione tradotta 2>", ...], "answer": "<Risposta tradotta>"} Template for English-to-Spanish Translation [Instruction] Eres un en traducción profesional.Tu tarea es traducir el siguiente texto, opciones y respuestas de manera precisa y natural al español, asegurándote de conservar el significado original de las preguntas y opciones.Por favor, cumple estrictamente con las siguientes reglas:-La traducción de las respuestas y opciones debe conservar completamente el significado original, sin desviaciones ni adiciones.-Todas las oraciones que contengan un signo de interrogación deben mantener la forma de pregunta en la traducción, sin cambiar el tono ni la estructura de la oración.-El contenido traducido debe ajustarse a las costumbres del idioma español, expresándose de manera natural y fluida, evitando traducciones literales.
Jyoti Marah Abdin, Hany Aneja, Ahmed Awadalla, Ammar Awadallah, Nguyen Ahmad Awan, Amit Bach, Arash Bahree, Jianmin Bakhtiari, Harkirat Bao, Behl, arXiv:2404.14219Phi-3 technical report: A highly capable language model locally on your phone. 2024arXiv preprint</p>
<p>Anthropic, Claude 3.5 sonnet. 2024</p>
<p>Prajjwal Bhargava, Aleksandr Drozd, Anna Rogers, arXiv:2110.01518Generalization in nli: Ways (not) to go beyond simple heuristics. 2021arXiv preprint</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De, Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>Unveiling the power of language models in chemical research question answering. Xiuying Chen, Tairan Wang, Taicheng Guo, Kehan Guo, Juexiao Zhou, Haoyang Li, Zirui Song, Xin Gao, Xiangliang Zhang, Communications Chemistry. 8142025</p>
<p>Honestllm: Toward an honest and helpful large language model. Gao Chujie, Siyuan Wu, Yue Huang, Dongping Chen, Qihui Zhang, Zhengyan Fu, Yao Wan, Lichao Sun, Xiangliang Zhang, Advances in Neural Information Processing Systems. 202437</p>
<p>Think you have solved question answering? try arc, the ai2 reasoning challenge. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, arXiv:1803.054572018arXiv preprint</p>
<p>Unsupervised cross-lingual representation learning at scale. Conneau, arXiv:1911.021162019arXiv preprint</p>
<p>Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, arXiv:2410.13394Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, and Mitesh M Khapra. 2024. Crosslingual auto evaluation for assessing multilingual llms. arXiv preprint</p>
<p>Continual pre-training for cross-lingual llm adaptation: Enhancing japanese language capabilities. Kazuki Fujii, Taishi Nakamura, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, Naoaki Okazaki, arXiv:2404.177902024arXiv preprint</p>
<p>Shaping the safety boundaries: Understanding and defending against jailbreaks in large language models. Lang Gao, Xiangliang Zhang, Preslav Nakov, Xiuying Chen, arXiv:2412.170342024Preprint</p>
<p>Towards a typology of phonemic scripts. Amalia E Gnanadesikan, Writing Systems Research. 912017</p>
<p>Google translate api. Google, </p>
<p>What can large language models do in chemistry? a comprehensive benchmark on eight tasks. Taicheng Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh Chawla, Olaf Wiest, Xiangliang Zhang, Advances in Neural Information Processing Systems. 202336</p>
<p>Understanding cross-lingual alignmenta survey. Katharina Hämmerl, Jindřich Libovickỳ, Alexander Fraser, arXiv:2404.062282024arXiv preprint</p>
<p>Aligning ai with shared human values. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, Jacob Steinhardt, 2021aProceedings of the International Conference on Learning Representations (ICLR</p>
<p>Measuring massive multitask language understanding. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)2021b</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, arXiv:2103.038742021carXiv preprint</p>
<p>Yue Huang, Chenrui Fan, Yuan Li, Siyuan Wu, Tianyi Zhou, Xiangliang Zhang, Lichao Sun, arXiv:2406.147211+ 1&gt; 2: Can large language models serve as crosslingual knowledge aggregators?. 2024aarXiv preprint</p>
<p>On the trustworthiness of generative foundation models: Guideline. Yue Huang, Chujie Gao, Siyuan Wu, Haoran Wang, Xiangqi Wang, Yujun Zhou, Yanbo Wang, Jiayi Ye, Jiawen Shi, Qihui Zhang, arXiv:2502.142962025aarXiv preprint</p>
<p>Breaking focus: Contextual distraction curse in large language models. Yue Huang, Yanbo Wang, Zixiang Xu, Chujie Gao, Siyuan Wu, Jiayi Ye, Xiuying Chen, Pin-Yu Chen, Xiangliang Zhang, arXiv:2502.016092025barXiv preprint</p>
<p>Datagen: Unified synthetic dataset generation via large language models. Yue Huang, Siyuan Wu, Chujie Gao, Dongping Chen, Qihui Zhang, Yao Wan, Tianyi Zhou, Chaowei Xiao, Jianfeng Gao, Lichao Sun, The Thirteenth International Conference on Learning Representations. 2024b</p>
<p>Yue Huang, Zhengqing Yuan, Yujun Zhou, Kehan Guo, Xiangqi Wang, Haomin Zhuang, Weixiang Sun, Lichao Sun, Jindong Wang, Yanfang Ye, arXiv:2410.23426Social science meets llms: How reliable are large language models in social simulations?. 2024carXiv preprint</p>
<p>Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, Akila Ostrow, Alan Welihinda, Alec Hayes, Radford, arXiv:2410.21276Gpt-4o system card. 2024arXiv preprint</p>
<p>Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, arXiv:2412.16720Openai o1 system card. 2024arXiv preprint</p>
<p>Livecodebench: Holistic and contamination free evaluation of large language models for code. Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, arXiv:2403.079742024arXiv preprintArmando Solar-Lezama, Koushik Sen, and Ion Stoica</p>
<p>Quantifying ai psychology: A psychometrics benchmark for large language models. Yuan Li, Yue Huang, Hongyi Wang, Xiangliang Zhang, James Zou, Lichao Sun, arXiv:2406.176752024aarXiv preprint</p>
<p>Language ranker: A metric for quantifying llm performance across high and low-resource languages. Zihao Li, Yucheng Shi, Zirui Liu, Fan Yang, Ali Payani, Ninghao Liu, Mengnan Du, arXiv:2404.115532024bPreprint</p>
<p>Luyang Lin, Lingzhi Wang, Jinsong Guo, Kam-Fai Wong, arXiv:2403.14896Investigating bias in llm-based bias detection: Disparities between llms and human perception. 2024arXiv preprint</p>
<p>Stephanie Lin, Jacob Hilton, Owain Evans ; Hongwei, Zilong Liu, Yuxuan Zheng, Haodong Qiao, Zhiwei Duan, Fengzhe Fei, Wenwei Zhou, Songyang Zhang, Dahua Zhang, Kai Lin, Chen, arXiv:2109.07958arXiv:2405.12209Mathbench: Evaluating the theory and application proficiency of llms with a hierarchical mathematics benchmark. 2021. 2024aarXiv preprintTruthfulqa: Measuring how models mimic human falsehoods</p>
<p>Adversarial cooperative rationalization: The risk of spurious correlations in even clean datasets. Wei Liu, Zhongyu Niu, Lang Gao, Zhiying Deng, Jun Wang, Haozhao Wang, Ruixuan Li, arXiv:2505.021182025Preprint</p>
<p>Autonomous agents for collaborative task under information asymmetry. Wei Liu, Chenxi Wang, Yifei Wang, Zihao Xie, Rennai Qiu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang, Chen Qian, The Thirty-eighth Annual Conference on Neural Information Processing Systems. 2024b</p>
<p>Xiao Liu, Xuanyu Lei, Shengyuan Wang, Yue Huang, Zhuoer Feng, Bosi Wen, Jiale Cheng, Pei Ke, Yifan Xu, Weng Lam Tam, arXiv:2311.18743Alignbench: Benchmarking chinese alignment of large language models. 2023aarXiv preprint</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, arXiv:2308.03688Agentbench: Evaluating llms as agents. 2023barXiv preprint</p>
<p>Vuldetectbench: Evaluating the deep capability of vulnerability detection with large language models. Yu Liu, Lang Gao, Mingxin Yang, Yu Xie, Ping Chen, Xiaojin Zhang, Wei Chen, arXiv:2406.075952024cPreprint</p>
<p>Nqe: N-ary query embedding for complex query answering over hyperrelational knowledge graphs. Haoran Luo, Yuhao Haihong, Gengxian Yang, Yikai Zhou, Tianyu Guo, Zichen Yao, Xueyuan Tang, Kaiyang Lin, Wan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>. Meta. 2024a. Llama. 3</p>
<p>. Meta. 2024b. Llama. 3</p>
<p>Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, arXiv:2211.01786Crosslingual generalization through multitask finetuning. 2022arXiv preprint</p>
<p>Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick Barnes, Ajmal Mian, arXiv:2307.06435A comprehensive overview of large language models. 2023arXiv preprint</p>
<p>Gpt-4o mini: Advancing costefficient intelligence. 2024OpenAI</p>
<p>Pires, arXiv:1906.01502How multilingual is multilingual bert. 2019arXiv preprint</p>
<p>Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages. Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, Wanxiang Che, arXiv:2310.147992023arXiv preprint</p>
<p>Direct preference optimization: Your language model is secretly a reward model. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, Chelsea Finn, Advances in Neural Information Processing Systems. 362023</p>
<p>Distributions of cognates in europe as based on levenshtein distance. Job Schepens, Ton Dijkstra, Franc Grootjen, Bilingualism: Language and Cognition. 1512012</p>
<p>Injecting domain-specific knowledge into large language models: a comprehensive survey. Zirui Song, Bin Yan, Yuhan Liu, Miao Fang, Mingzhe Li, Rui Yan, Xiuying Chen, arXiv:2502.107082025aarXiv preprint</p>
<p>Zirui Song, Jingpu Yang, Yuan Huang, Jonathan Tonglet, Zeyu Zhang, Tao Cheng, arXiv:2502.13759Meng Fang, Iryna Gurevych, and Xiuying Chen. 2025b. Geolocation with real human gameplay data: A large-scale dataset and human-like reasoning framework. arXiv preprint</p>
<p>Sebastian Riedel, and Tim Rocktäschel. Joe Stacey, Pasquale Minervini, Haim Dubossarsky, arXiv:2004.07790Avoiding the hypothesis-only bias in natural language inference via ensemble adversarial training. 2020arXiv preprint</p>
<p>Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, arXiv:2401.05561Trustllm: Trustworthiness in large language models. 20243arXiv preprint</p>
<p>10.34740/KAGGLE/M/33012024b. Qwen2.5: A party of foundation models. </p>
<p>Alan Wake, Albert Wang, Bei Chen, Chao Lv, Chengen Li, Chenglin Huang, Chujie Cai, Daniel Zheng, Ethan Cooper, Dai, Yi-lightning technical report. arXiv e-prints. 20242412</p>
<p>A cognitive writing perspective for constrained long-form text generation. Kaiyang Wan, Honglin Mu, Rui Hao, Haoran Luo, Tianle Gu, Xiuying Chen ; Wang, Tianle Gu, Zhongyu Wei, Lang Gao, Zirui Song, Xiuying Chen, arXiv:2502.12568arXiv:2503.017142025. 2025aPreprintWord form matters: Llms' semantic reconstruction under typoglycemia</p>
<p>Decoding echo chambers: LLMpowered simulations revealing polarization in social networks. Chenxi Wang, Zongfang Liu, Dequan Yang, Xiuying Chen, Proceedings of the 31st International Conference on Computational Linguistics. the 31st International Conference on Computational LinguisticsAbu Dhabi, UAEAssociation for Computational Linguistics2025b</p>
<p>Probing the emergence of crosslingual alignment during llm training. Hetong Wang, Pasquale Minervini, Edoardo M Ponti, arXiv:2406.132292024arXiv preprint</p>
<p>Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, Jiarong Xu, Fandong Meng, arXiv:2309.08952Cross-lingual knowledge editing in large language models. 2023arXiv preprint</p>
<p>Trusteval: A dynamic evaluation toolkit on trustworthiness of generative foundation models. Yanbo Wang, Jiayi Ye, Siyuan Wu, Chujie Gao, Yue Huang, Xiuying Chen, Yue Zhao, Xiangliang Zhang, Proceedings of the 2025 Conference of the Nations of the Americas Chapter. the 2025 Conference of the Nations of the Americas ChapterHuman Language Technologies2025cSystem Demonstrations</p>
<p>Calm: Unleashing the cross-lingual self-aligning ability of language model question answering. Yumeng Wang, Zhiyuan Fan, Qingyun Wang, arXiv:2501.18457May Fung, and Heng Ji. 2025darXiv preprint</p>
<p>Crowdsourcing multiple choice science questions. Johannes Welbl, Nelson F Liu, Matt Gardner, arXiv:1707.062092017arXiv preprint</p>
<p>Medtrinity-25m: A large-scale multimodal dataset with multigranular annotations for medicine. Yunfei Xie, Ce Zhou, Lang Gao, Juncheng Wu, Xianhang Li, Hong-Yu Zhou, Sheng Liu, Lei Xing, James Zou, Cihang Xie, Yuyin Zhou, arXiv:2408.029002025Preprint</p>
<p>Rongwu Xu, Zehan Qi, Zhijiang Guo, Cunxiang Wang, Hongru Wang, Yue Zhang, Wei Xu, arXiv:2403.08319Knowledge conflicts for llms: A survey. 2024arXiv preprint</p>
<p>Zixiang Xu, Yanbo Wang, Yue Huang, Jiayi Ye, Haomin Zhuang, Zirui Song, Lang Gao, Chenxi Wang, Zhaorun Chen, Yujun Zhou, Sixian Li, Wang Pan, Yue Zhao, Jieyu Zhao, Xiangliang Zhang, and Xiuying Chen. 2025a. Socialmaze: A benchmark for evaluating social reasoning in large language models. </p>
<p>Gta: Graph theory agent and benchmark for algorithmic graph reasoning with llms. Zixiang Xu, Yanbo Wang, Chenxi Wang, Lang Gao, Zirui Song, Yue Huang, Zhaorun Chen, Xiangliang Zhang, Xiuying Chen, 2025b</p>
<p>Leia: Facilitating cross-lingual knowledge transfer in language models with entity-based data augmentation. Ikuya Yamada, Ryokan Ri, arXiv:2402.114852024arXiv preprint</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, arXiv:2407.10671Dayiheng Liu, Fei Huang, and Others. 2024. Qwen2 technical report. arXiv preprint</p>
<p>Benchmarking llm-based machine translation on cultural awareness. Binwei Yao, Ming Jiang, Diyi Yang, Junjie Hu, arXiv:2305.143282023arXiv preprint</p>
<p>Justice or prejudice? quantifying biases in llm-as-a-judge. Jiayi Ye, Yanbo Wang, Yue Huang, Dongping Chen, Qihui Zhang, Nuno Moniz, Tian Gao, Werner Geyer, Chao Huang, Pin-Yu Chen, arXiv:2410.027362024arXiv preprint</p>
<p>Prompting large language model for machine translation: A case study. Biao Zhang, Barry Haddow, Alexandra Birch, ; Wenxuan Pmlr, Yue Zhang, Bing Deng, Liu, arXiv:2305.15005Sinno Jialin Pan, and Lidong Bing. 2023b. Sentiment analysis in the era of large language models: A reality check. 2023aarXiv preprintInternational Conference on Machine Learning</p>
<p>Yiran Zhao, Wenxuan Zhang, Guizhen Chen, Kenji Kawaguchi, Lidong Bing, arXiv:2402.18815How do large language models handle multilingualism?. 2024aarXiv preprint</p>
<p>Yiran Zhao, Wenxuan Zhang, Huiming Wang, Kenji Kawaguchi, Lidong Bing, arXiv:2402.18913Adamergex: Cross-lingual transfer with large language models via adaptive adapter merging. 2024barXiv preprint</p>
<p>Target Language: Korean English Question: Many cities around the world, like London, are known for their rich cultural scenes and historic landmarks that attract millions of visitors each year.Kiwis describe it as \"our biggest and most diverse city, it's an economic hub with lots of tourists and very expensive rents. Juexiao Zhou, Xiuying Chen, Xin Gao, ; 전 세계의 많은 도시들, 예를 들어 런던은 매년 수백만 명의 방문객을 끌어들이는 풍부한 문화 현장과 역사적인 명소로 유명합니다.키위들은 이 도시를 '우리의 가장 크고 다양한 도시이며, 경제 중심지로 많은 관광객이 찾고 임대료가 매우 비싸다'라고 설명합니다. 이 도시의 이름은 무엇인가요?도시의 문화적 활력은 종종 지역 요리에 영향을 미쳐, 그들의 역사와 다양성을 반영하는 독특한 식사 경험을 만들어냅니다, arXiv:2306.10765Path to medical agi: Unify domain-specific medical llms with the lowest cost. English Choices; New York City2023arXiv preprintWhat is the name of the city? The cultural vibrancy of cities often influences local cuisine, leading to unique dining experiences that reflect their history and diversity. London", "Los Angeles", "Paris", "Toronto", "Sydney", "Chicago", "San Francisco", "Wellington", "Auckland"] English Ground Truth: Auckland Korean Question. Korean Choices: ["뉴욕시", "런던", "로스앤젤레스", "파리", "토론토", "시드니", "시카고", "샌프란시스코", "웰링턴", "오클랜드"</p>
<p>Korean Ground Truth:오클랜드 Response by Gemma-2-9B. </p>
<p>Target Language: German English Question: Illustrating how form follows function, long, slender protein strands that make up what tissue are essential for contracting and relaxing? The design of various biological structures often reflects their specific roles; for instance, the way some connective tissues are structured can greatly influence their ability to withstand tension and support movement in the body. This principle can also be seen in how tendons connect muscles to bones, allowing for efficient movement and stability during physical activities. English original response: Auckland Korean original response: 런던 Figure 26: Case study: Gemma-2-9B's responses to English-Korean question pairs. English Choices: ["tendons", "veins", "ligaments", "muscle"</p>
<p>sind lange, schlanke Proteinstränge, die welches Gewebe bilden, essentiell für das Zusammenziehen und Entspannen?Das Design verschiedener biologischer Strukturen spiegelt oft ihre spezifischen Rollen wider; zum Beispiel kann die Art und W eise, wie einige Bindegewebe strukturiert sind, erheblichen Einfluss auf ihre Fähigkeit haben, Spannung standzuhalten und Bewegung im Körper zu unterstützen.Dieses Prinzip zeigt sich auch darin, wie Sehnen Muskeln mit Knochen verbinden und so effiziente Bewegungen und Stabilität während körperlicher Aktivitäten ermöglichen. Ground English, Truth, muscle German Question: Veranschaulichend, wie die Form der Funktion folgt. German ChoicesSehnen", "Venen", "Bänder", "Muskeln"</p>
<p>German Ground, Truth , Muskeln Response by Llama-3. </p>
<p>Target Language: Chinese English Question: Many organisms exhibit unique developmental stages, and understanding these processes can shed light on the fascinating complexity of cellular biology. English Ground Truth: plant cells Chinese Question: 许多生物表现出独特的发育阶段，理解这些过程可以 揭示细胞生物学迷人复杂性的奥秘。在什么类型的细胞中，前期之前有 一个前前期阶段？ Chinese Choices. 28English original responseProphase is preceded by a preprophase stage in what type of cells? English Choices. 脑细胞", "头发和指甲细胞", "卵细胞", "植物细胞"] Chinese Ground Truth:植物细胞 Response by GPT-4o</p>
<p>Holiday heart syndrome"] English Ground Truth: Holiday heart syndrome Italian Question: Il consumo eccessivo acuto di alcol è associato a?È importante considerare come i fattori ambientali, come l'esposizione alla luce solare durante le attività estive, possano influenzare i risultati complessivi della salute.Inoltre, molte persone scoprono che partecipare ad attività sociali all'aperto può migliorare il loro umore e favorire un senso di benessere. 在卵细胞中，前期之前有一个前前 期阶段。这个阶段在卵母细胞的减 数分裂过程中是独特的。 Figure, Sindrome del cuore da spiaggia. particolare durante i mesi più caldi. Italian Choices. English ChoicesSindrome del cuore a casa29Target Language: Italian English Question: Acute binge drinking is associated with?\nIt's important to consider how environmental factors, like exposure to sunlight during summer activities, can influence overall health outcomes.Additionally, many people find that engaging in social activities outdoors can enhance their mood and foster a sense of well-being, particularly during warmer months. Sindrome del cuore felice. Sindrome del cuore delle vacanze"] Italian Ground Truth: Sindrome del cuore delle vacanze Response by Gemma-2-27B</p>
<p>Wednesday Spanish Question: ¿Qué día de la semana a veces se llama 'día de la cima'?Muchas personas a menudo esperan el sábado como un momento para relajarse y desconectar, planeando actividades para el fin de semana que se avecina. English ChoicesTarget Language: Spanish English Question: What day of the week is sometimes called 'hump day'? Many people often look forward to Saturday as a time to relax and unwind, planning activities for the weekend ahead. Spanish Choices: ["miércoles", "jueves", "viernes", "sábado"] Spanish Ground Truth: miércoles Response by Llama-3.1-8B</p>
<p>Target Language: Japanese English Question: Prophase is preceded by a preprophase stage in what type of cells? In many organisms, including certain plants, the development of reproductive structures can be fascinating, often involving specialized cells that play crucial roles in fertilization and growth. The intricate processes of cell division can sometimes mirror the complexity found in the development of neural structures, where various signals and stages contribute to the formation of functional networks. English Ground Truth: plant cells Japanese Question: 前期はどの種類の細胞で前前期という段階に先行さ れますか？多くの生物、特に特定の植物において、繁殖構造の発達は魅 力的であり、しばしば受精や成長において重要な役割を果たす特殊な細 胞が関与しています。細胞分裂の複雑なプロセスは、さまざまな信号や 段階が機能的ネットワークの形成に寄与する神経構造の発達に見られる 複雑さを反映することがあります。 Japanese Choices. English ChoicesEnglish original response: Wednesday Spanish original response: La respuesta correcta es: viernes Figure 31: Case study: Llama-3.1-8B's responses to English-Spanish question pairs. brain cells", "hair and nail cells", "egg cells", "plant cells. 脳細胞", "髪と爪の細胞", "卵細胞", "植物細胞"] Japanese Ground Truth: 植物細胞 Response by Qwen2</p>
<p>English original response. plant cells'] Japanese original response: ["卵細胞"</p>            </div>
        </div>

    </div>
</body>
</html>