<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2071 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2071</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2071</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-53.html">extraction-schema-53</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <p><strong>Paper ID:</strong> paper-280227872</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2507.17209v1.pdf" target="_blank">HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Modern scientific discovery faces growing challenges in integrating vast and heterogeneous knowledge critical to breakthroughs in biomedicine and drug development. Traditional hypothesis-driven research, though effective, is constrained by human cognitive limits, the complexity of biological systems, and the high cost of trial-and-error experimentation. Deep learning models, especially graph neural networks (GNNs), have accelerated prediction generation, but the sheer volume of outputs makes manual selection for validation unscalable. Large language models (LLMs) offer promise in filtering and hypothesis generation, yet suffer from hallucinations and lack grounding in structured knowledge, limiting their reliability. To address these issues, we propose HypoChainer, a collaborative visualization framework that integrates human expertise, LLM-driven reasoning, and knowledge graphs (KGs) to enhance hypothesis generation and validation. HypoChainer operates in three stages: First, exploration and contextualization -- experts use retrieval-augmented LLMs (RAGs) and dimensionality reduction to navigate large-scale GNN predictions, assisted by interactive explanations. Second, hypothesis chain formation -- experts iteratively examine KG relationships around predictions and semantically linked entities, refining hypotheses with LLM and KG suggestions. Third, validation prioritization -- refined hypotheses are filtered based on KG-supported evidence to identify high-priority candidates for experimentation, with visual analytics further strengthening weak links in reasoning. We demonstrate HypoChainer's effectiveness through case studies in two domains and expert interviews, highlighting its potential to support interpretable, scalable, and knowledge-grounded scientific discovery.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2071.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2071.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HypoChainer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid human-AI system introduced in this paper that integrates retrieval-augmented LLMs, GNN-based predictions, large biomedical knowledge graphs, and interactive visual analytics to generate, iteratively refine, and prioritize hypothesis chains for scientific discovery (drug repurposing and synthetic lethality).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HypoChainer</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>hybrid (retrieval-augmented large language model + knowledge graph + GNN + visual analytics)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>drug discovery, synthetic lethality, biomedical research</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>structured hypothesis chains (textual hypotheses linked to KG entities), prioritized model predictions, interpretative KG paths</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel — designed to surface overlooked predictions and produce hypothesis chains that extend beyond direct KG triplets (authors report discovery of overlooked links in case studies)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM-driven generation (RAG mode) that synthesizes retrieved KG subgraphs, GNN prediction outputs, and external knowledge to produce hypotheses and textual explanations; experts iteratively refine chains using the system's suggestions</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Multi-step: (1) automated RAG retrieval against the local KG to find KG triplets and interpretative paths aligned with hypotheses; (2) scoring/alignment of retrieved entities (RAG-judged alignment); (3) visual analytic inspection (Prediction / Hypothesis / Chain views); (4) expert human review and iterative refinement; (5) where available, cross-referencing to curated external datasets (e.g., DrugMechDB) or literature</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>No direct generation accuracy metric reported for hypothesis text generation; system-level user-study signals improved generation usefulness: HypoChainer group had higher task completion (4/6 participants, 66.7%) vs Baseline LLM-only (2/6, 33.3%); questionnaire showed significantly higher scores on 'Ease of Identifying Research Directions' (M=5.50 vs 4.17, p<0.05), 'Logical Coherence of Hypothesis Chains' (M=5.67 vs 4.17, p<0.05) and other informativeness/understandability metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation is primarily alignment-based (how many retrieved triplets satisfy hypotheses). No single numeric validation accuracy for hypothesis-level validation reported; system uses counts and UpSet visualizations to show degrees of alignment. External dataset validation used for drug repurposing (472 drug-disease pairs from DrugMechDB) but no aggregate predictive metric for HypoChainer end-to-end provided.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Authors report that validity/alignment declines when hypotheses refer to relations not well represented in the KG (novel / out-of-KG assertions require manual KG augmentation and expert review); increasing novelty increases need for human validation and KG enrichment.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper explicitly notes an asymmetry: LLMs and GNNs can generate many novel predictions/hypotheses, but validation (especially experimental wet-lab validation) lags substantially; RAG/KG grounding reduces hallucinations but does not eliminate generation > validation gap.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Limited: GNN predictions include confidence / rank scores; the system surface 'prediction confidence scores' for model outputs. LLM outputs are not presented with calibrated uncertainty estimates. Authors recommend future fact-verification modules and confidence thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not quantified numerically; qualitative observations suggest calibration is imperfect — users noticed hallucinations and LLM inconsistency prior to KG grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not quantitatively reported. Authors state system generalizes across domains in principle but performance depends strongly on KG coverage; OOD (novel mechanisms not captured in KG) require manual KG augmentation and expert review.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Yes — uses proxies such as: model prediction rank/score, interpretative path coherence, entity-alignment counts (how many KG triplets satisfy chain hypotheses), and UpSet-derived intersection counts rather than direct experimental confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Frequent: experts iteratively validate during hypothesis construction and before selecting candidates for downstream experimental validation; frequency increases for novel or low-KG-coverage outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (drug discovery and cancer biology) — domain requires experimental wet-lab validation, which amplifies the generation-validation gap.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>KG grounding of LLM outputs (local-KG-only RAG mode), interactive human-in-the-loop iterative refinement, visualization to prioritize high-alignment predictions, limited and verified text-to-KG updates, filtering by interpretative-path granularity, and recommended future fact-verification/confidence-threshold modules.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Multiple textual statements: (1) LLM hallucinations and inconsistency intensify with complexity; (2) model predictions outpace experts' ability to manually validate due to volume; (3) wet-lab validation for SL takes months, making exhaustive validation infeasible; (4) case study examples where predictions lacked KG links (e.g., Trinucleotide Repeat Expansion not present in predictions) requiring manual KG augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>RAG grounding to local KG and the HypoChainer workflow enabled discovery of KG-supported subpaths and alignment for many predictions; in user study HypoChainer participants found and aligned more reference predictions than Baseline, indicating mitigation of some gap via KG grounding and visualization.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not numerically specified. Qualitative statements: automated generation (LLM/RAG/GNN inference) is relatively cheap/fast compared to experimental validation (wet-lab). RAG retrieval cost increases with retrieval limit (more tokens and latency), creating a trade-off between retrieval-driven validation accuracy and computational/token cost.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2071.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2071.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LightRAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LightRAG: Simple and fast retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented generation (RAG) approach used as the retrieval/reasoning backbone in HypoChainer for lower cost and faster responses versus other RAG variants; employed in a local-KG mode to minimize hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LightRAG: Simple and fast retrieval-augmented generation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LightRAG (local-KG RAG mode)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>retrieval-augmented generation (RAG) system</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical knowledge retrieval and hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>retrieved evidence passages/subgraphs and LLM-conditioned explanations/hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>in-distribution to the local KG for safe retrieval; can be used with external LLM for more novel/out-of-KG reasoning (but that increases hallucination risk)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>retrieves KG-backed passages/subgraphs and conditions an LLM to generate explanations and hypotheses; supports local-only retrieval mode to force grounding in KG</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Grounding outputs in local KG (restricting RAG to local database) to reduce hallucinations; entity-alignment scoring (RAG-judged alignment) for hypothesis validation; provides tokens of retrieved KG evidence for traceability</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Described as 'lower cost and faster response compared to GraphRAG' (no numeric throughput/latency given). Authors note perceived lower hallucination when operating in local-KG-only mode.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Qualitative: grounding in local KG improves trustworthiness of generated outputs; authors report that increasing retrieval limit improves retrieval accuracy but also increases token consumption and latency.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Accuracy improves when retrieval stays in-distribution (local KG). When asked to reason beyond the KG (external LLM access), hallucination risk and validation difficulty increase.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper states LightRAG reduces generation that cannot be validated by forcing local-KG evidence, narrowing the generation-validation gap relative to unconstrained LLM generation.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not specified; no calibrated uncertainty outputs reported from LightRAG in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not quantified; authors warn that OOD reasoning (external LLM use) increases hallucinations and validation difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Uses retrieval alignment (presence of KG triplets) and RAG-judged alignment scores as proxy validation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Often required for outputs that go beyond local KG coverage; RAG-local mode reduces but doesn't eliminate need for expert review.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (biomedical KG retrieval) — relies on curated KG coverage for reliable validation.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Use of local-KG-only retrieval mode to avoid external hallucinations; limiting integration to verified, small KG updates; visually surfacing retrieved KG evidence for human inspection.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors observed trade-offs: increasing retrieval scope (to capture more evidence) improves accuracy but raises computational/token costs; unrestricted LLM retrieval introduces hallucinations that are hard to validate.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>When constrained to local KG, LightRAG produced more traceable outputs and reduced hallucinations according to expert feedback in the study.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Authors describe a trade-off: larger retrieval limits increase token consumption and query times; no numeric cost ratio reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2071.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2071.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM (ChatBot / RAG-driven LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model used as ChatBot and reasoning engine (LLM conditioned by RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transformer-based large language models (unnamed) are used to generate explanations, initial hypotheses, paraphrase descriptions, and to provide heuristic and external-information-enhanced guidance; integrated into a RAG pipeline for grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Large language model (RAG-conditioned, deployed in ChatBot)</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>large language model (transformer-based)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>hypothesis generation and explanation in biomedicine (drug repurposing, synthetic lethality)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>textual hypotheses, explanations, suggestions for refinement, entity recommendations</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>can propose novel ideas beyond KG content (moderately to highly novel), but novelty comes with increased hallucination risk</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>prompt-driven text generation, conditioned on retrieved KG evidence (RAG) or external sources (when permitted); generates initial hypotheses and paraphrases that experts refine</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Outputs are validated via KG retrieval (RAG), entity-alignment scoring, visualization for expert inspection, and domain expert review; some external literature checks performed on demand</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>No automatic numeric generation-quality metrics reported; user feedback indicates LLMs aid idea generation but can produce hallucinations and inconsistencies without KG grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Validation relies on RAG and human review; no numeric validation accuracy for LLM outputs reported.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Authors note: hallucination risk and inconsistency increase with novelty/out-of-KG reasoning; local-KG grounding reduces but does not eliminate errors.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Paper highlights asymmetry: LLMs readily generate novel hypotheses but validating these (via KG alignment or experiments) is harder and often manual.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not implemented for LLM outputs in the system as reported; authors recommend adding fact-verification modules and confidence thresholds in future.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported; anecdotal observations suggest poor/unquantified calibration for novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not quantified; qualitative cautions: OOD outputs are more likely to be hallucinatory and require human/ KG-based checks.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Plausibility, coherence, and KG alignment via RAG are used as practical proxies for validity.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Frequent — especially for novel hypotheses or external-information-enhanced explanations; experts iteratively refine LLM outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (biomedical) — LLM outputs need experimental or curated-KG corroboration to be actionable.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Ground LLMs with local KG via RAG, limit external retrieval to expert-controlled modes, show retrieved evidence inline, interactive workflows to let experts correct and expand KG.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Multiple statements on hallucinations, need for KG grounding, and experts' experience that LLMs 'often struggle to maintain consistency and coherence in handling complex hypotheses.'</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>When combined with RAG and KG grounding, LLM outputs became more useful and enabled identification of relevant entities and hypotheses in case studies.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not provided; authors note trade-offs between retrieval depth (cost) and accuracy/trustworthiness.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2071.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2071.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KGML-xDTD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A drug repurposing prediction and mechanism-of-action (MOA) inference model that frames drug-disease prediction as link prediction using GraphSAGE embeddings and an adversarial actor-critic reinforcement learning module to extract biologically plausible MOA paths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KGML-xDTD</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>graph neural network (GraphSAGE) + reinforcement learning (adversarial actor-critic) for link prediction and path inference</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>drug repurposing / pharmacology</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>predicted drug-disease links and inferred mechanism-of-action (MOA) paths</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel — predicts candidate repurposing links and MOA paths not always present in KG; authors claim enhanced prediction vs baselines (Appendix Tab.1)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>GraphSAGE node embeddings from KG + PubMedBERT-derived attributes, link prediction pipeline for candidate tail entities, and adversarial actor-critic RL to generate MOA paths from curated demonstration paths</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Model performance validated using curated datasets and external validation set: 472 drug-disease pairs from DrugMechDB for external validation; interpretability assessed via MOA path plausibility</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Described as 'enhances prediction' relative to baselines (Appendix Tab.1) — no specific aggregate metrics reported in main text; authors claim improved interpretability via MOA path extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>External validation via DrugMechDB used; no numeric accuracy/precision/recall reported in main text (metrics referenced to Appendix Tab.1).</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not specifically quantified; authors note that quality depends on KG coverage and curated demonstration paths for RL training — novel MOA paths outside training distribution likely harder to validate.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Model provides interpretable MOA paths that can be compared to curated mechanisms (e.g., DrugMechDB), narrowing generation-validation gap at the mechanistic-path level, but experimental validation still required for real-world claims.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Model outputs include ranked scores for predicted links and path weights; no calibrated uncertainty estimates reported.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported; dependence on curated demonstration paths implies OOD MOA generation quality may decline.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Uses path plausibility, path weights, and ranking scores as proxies for validity; also uses external curated pairs for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Recommended before experimental follow-up; domain experts inspect MOA paths and filter candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (drug discovery) — requires biological experiments for confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Generates interpretable MOA paths to facilitate expert inspection and prioritization; uses curated demonstration paths in RL to bias toward biologically plausible mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Authors note that despite improved MOA extraction, the expanding volume of predictions makes manual validation impractical and experimental testing costly/time-consuming.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Interpretability (MOA paths) provides a clearer route for expert triage and comparison to curated mechanisms, helping reduce but not eliminate the gap.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not specified; model training/inference has computational cost but authors emphasize the larger time/cost expense of experimental (wet-lab) validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2071.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2071.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or automated systems that generate novel outputs (scientific hypotheses, molecules, proofs, predictions) and how those outputs are validated, including performance metrics, false positive rates, and differences between generation and validation capabilities.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KR4SL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A heterogeneous-knowledge-graph GNN encoder-decoder model used for synthetic lethality (SL) gene-pair prediction that outputs ranked candidate SL pairs along with three-hop interpretative paths and path weights.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>KR4SL</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>heterogeneous graph neural network (encoder-decoder) with path-tracing explanation</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>cancer genomics / synthetic lethality prediction</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>predicted SL gene pairs and corresponding three-hop interpretative paths with path weights</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_level</strong></td>
                            <td>moderately novel — predicts candidate SL pairs beyond existing validated interactions; provides interpretable paths to assist validation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>GNN-based encoder-decoder on a heterogeneous KG that traces relational paths and assigns weights to capture strength of candidate SL interactions; ranks candidates by likelihood</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Reported model precision on SL prediction (Appendix Tab.2); each prediction accompanied by a three-hop interpretative path for explanatory inspection by experts</td>
                        </tr>
                        <tr>
                            <td><strong>generation_performance</strong></td>
                            <td>Reported precision = 59% (Appendix Tab.2) — authors state KR4SL outperforms comparable models on their SL dataset; each prediction includes a three-hop interpretative path.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performance</strong></td>
                            <td>Precision 59% implies many predictions are correct at top ranks under their evaluation setup; no recall / F1 or dataset-level false negative rates reported in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td>Not directly reported; implied false-positive proportion ≈ 41% under the usual definition (FPR ~ 1 - precision) given precision=59% — this is an inference based on standard precision definition.</td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_novelty</strong></td>
                            <td>Not explicitly studied; interpretative paths help experts triage novel predictions, but actual validation (wet-lab) remains costly and slow.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_validation_comparison</strong></td>
                            <td>Model provides generation (predictions + explanatory paths) but validation relies on held-out datasets and expert inspection; the authors note precision is moderate, indicating a non-trivial generation-validation gap for less-likely predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Model outputs include ranking scores and path weights indicating confidence; no calibrated uncertainty metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_quality</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not reported explicitly; performance likely depends on KG completeness and heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_proxy_metrics</strong></td>
                            <td>Uses precision on curated SL datasets and interpretative path plausibility as proxies for real-world validity.</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_required</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>human_validation_frequency</strong></td>
                            <td>Recommended — experts inspect interpretative paths and select candidates for costly experimental validation; frequency scales with number of novel predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>formal_verification_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_formalization_level</strong></td>
                            <td>empirical (genomics / wet-lab biology) — experimental validation essential to confirm computational predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_mitigation_strategies</strong></td>
                            <td>Provides three-hop interpretative paths and path weights to improve explainability and aid expert triage; integrates with HypoChainer visualization for iterative refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_supporting_gap</strong></td>
                            <td>Moderate model precision (59%) shows many computational predictions are plausible but not definitive; experts must filter and experimentally validate candidates — authors explicitly note manual validation is infeasible at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_contradicting_gap</strong></td>
                            <td>Providing interpretative paths and reasonable precision suggests that computational predictions can be useful for prioritization and reduce some validation burden.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_ratio</strong></td>
                            <td>Not quantified. Authors emphasize experimental wet-lab validation (months-long for SL) is orders of magnitude more costly/time-consuming than in-silico generation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description <em>(Rating: 2)</em></li>
                <li>KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality <em>(Rating: 2)</em></li>
                <li>LightRAG: Simple and fast retrieval-augmented generation <em>(Rating: 2)</em></li>
                <li>SLInterpreter: An exploratory and iterative Human-AI collaborative system for GNN-based synthetic lethal prediction <em>(Rating: 2)</em></li>
                <li>KNOWNET: Guided health information seeking from LLMs via knowledge graph integration <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2071",
    "paper_id": "paper-280227872",
    "extraction_schema_id": "extraction-schema-53",
    "extracted_data": [
        {
            "name_short": "HypoChainer",
            "name_full": "HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery",
            "brief_description": "A hybrid human-AI system introduced in this paper that integrates retrieval-augmented LLMs, GNN-based predictions, large biomedical knowledge graphs, and interactive visual analytics to generate, iteratively refine, and prioritize hypothesis chains for scientific discovery (drug repurposing and synthetic lethality).",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "HypoChainer",
            "system_type": "hybrid (retrieval-augmented large language model + knowledge graph + GNN + visual analytics)",
            "scientific_domain": "drug discovery, synthetic lethality, biomedical research",
            "output_type": "structured hypothesis chains (textual hypotheses linked to KG entities), prioritized model predictions, interpretative KG paths",
            "novelty_level": "moderately novel — designed to surface overlooked predictions and produce hypothesis chains that extend beyond direct KG triplets (authors report discovery of overlooked links in case studies)",
            "generation_method": "LLM-driven generation (RAG mode) that synthesizes retrieved KG subgraphs, GNN prediction outputs, and external knowledge to produce hypotheses and textual explanations; experts iteratively refine chains using the system's suggestions",
            "validation_method": "Multi-step: (1) automated RAG retrieval against the local KG to find KG triplets and interpretative paths aligned with hypotheses; (2) scoring/alignment of retrieved entities (RAG-judged alignment); (3) visual analytic inspection (Prediction / Hypothesis / Chain views); (4) expert human review and iterative refinement; (5) where available, cross-referencing to curated external datasets (e.g., DrugMechDB) or literature",
            "generation_performance": "No direct generation accuracy metric reported for hypothesis text generation; system-level user-study signals improved generation usefulness: HypoChainer group had higher task completion (4/6 participants, 66.7%) vs Baseline LLM-only (2/6, 33.3%); questionnaire showed significantly higher scores on 'Ease of Identifying Research Directions' (M=5.50 vs 4.17, p&lt;0.05), 'Logical Coherence of Hypothesis Chains' (M=5.67 vs 4.17, p&lt;0.05) and other informativeness/understandability metrics.",
            "validation_performance": "Validation is primarily alignment-based (how many retrieved triplets satisfy hypotheses). No single numeric validation accuracy for hypothesis-level validation reported; system uses counts and UpSet visualizations to show degrees of alignment. External dataset validation used for drug repurposing (472 drug-disease pairs from DrugMechDB) but no aggregate predictive metric for HypoChainer end-to-end provided.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Authors report that validity/alignment declines when hypotheses refer to relations not well represented in the KG (novel / out-of-KG assertions require manual KG augmentation and expert review); increasing novelty increases need for human validation and KG enrichment.",
            "generation_validation_comparison": "Paper explicitly notes an asymmetry: LLMs and GNNs can generate many novel predictions/hypotheses, but validation (especially experimental wet-lab validation) lags substantially; RAG/KG grounding reduces hallucinations but does not eliminate generation &gt; validation gap.",
            "uncertainty_quantification": "Limited: GNN predictions include confidence / rank scores; the system surface 'prediction confidence scores' for model outputs. LLM outputs are not presented with calibrated uncertainty estimates. Authors recommend future fact-verification modules and confidence thresholds.",
            "calibration_quality": "Not quantified numerically; qualitative observations suggest calibration is imperfect — users noticed hallucinations and LLM inconsistency prior to KG grounding.",
            "out_of_distribution_performance": "Not quantitatively reported. Authors state system generalizes across domains in principle but performance depends strongly on KG coverage; OOD (novel mechanisms not captured in KG) require manual KG augmentation and expert review.",
            "validation_proxy_metrics": "Yes — uses proxies such as: model prediction rank/score, interpretative path coherence, entity-alignment counts (how many KG triplets satisfy chain hypotheses), and UpSet-derived intersection counts rather than direct experimental confirmation.",
            "human_validation_required": true,
            "human_validation_frequency": "Frequent: experts iteratively validate during hypothesis construction and before selecting candidates for downstream experimental validation; frequency increases for novel or low-KG-coverage outputs.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (drug discovery and cancer biology) — domain requires experimental wet-lab validation, which amplifies the generation-validation gap.",
            "gap_mitigation_strategies": "KG grounding of LLM outputs (local-KG-only RAG mode), interactive human-in-the-loop iterative refinement, visualization to prioritize high-alignment predictions, limited and verified text-to-KG updates, filtering by interpretative-path granularity, and recommended future fact-verification/confidence-threshold modules.",
            "evidence_supporting_gap": "Multiple textual statements: (1) LLM hallucinations and inconsistency intensify with complexity; (2) model predictions outpace experts' ability to manually validate due to volume; (3) wet-lab validation for SL takes months, making exhaustive validation infeasible; (4) case study examples where predictions lacked KG links (e.g., Trinucleotide Repeat Expansion not present in predictions) requiring manual KG augmentation.",
            "evidence_contradicting_gap": "RAG grounding to local KG and the HypoChainer workflow enabled discovery of KG-supported subpaths and alignment for many predictions; in user study HypoChainer participants found and aligned more reference predictions than Baseline, indicating mitigation of some gap via KG grounding and visualization.",
            "computational_cost_ratio": "Not numerically specified. Qualitative statements: automated generation (LLM/RAG/GNN inference) is relatively cheap/fast compared to experimental validation (wet-lab). RAG retrieval cost increases with retrieval limit (more tokens and latency), creating a trade-off between retrieval-driven validation accuracy and computational/token cost.",
            "uuid": "e2071.0"
        },
        {
            "name_short": "LightRAG",
            "name_full": "LightRAG: Simple and fast retrieval-augmented generation",
            "brief_description": "A retrieval-augmented generation (RAG) approach used as the retrieval/reasoning backbone in HypoChainer for lower cost and faster responses versus other RAG variants; employed in a local-KG mode to minimize hallucinations.",
            "citation_title": "LightRAG: Simple and fast retrieval-augmented generation",
            "mention_or_use": "use",
            "system_name": "LightRAG (local-KG RAG mode)",
            "system_type": "retrieval-augmented generation (RAG) system",
            "scientific_domain": "biomedical knowledge retrieval and hypothesis generation",
            "output_type": "retrieved evidence passages/subgraphs and LLM-conditioned explanations/hypotheses",
            "novelty_level": "in-distribution to the local KG for safe retrieval; can be used with external LLM for more novel/out-of-KG reasoning (but that increases hallucination risk)",
            "generation_method": "retrieves KG-backed passages/subgraphs and conditions an LLM to generate explanations and hypotheses; supports local-only retrieval mode to force grounding in KG",
            "validation_method": "Grounding outputs in local KG (restricting RAG to local database) to reduce hallucinations; entity-alignment scoring (RAG-judged alignment) for hypothesis validation; provides tokens of retrieved KG evidence for traceability",
            "generation_performance": "Described as 'lower cost and faster response compared to GraphRAG' (no numeric throughput/latency given). Authors note perceived lower hallucination when operating in local-KG-only mode.",
            "validation_performance": "Qualitative: grounding in local KG improves trustworthiness of generated outputs; authors report that increasing retrieval limit improves retrieval accuracy but also increases token consumption and latency.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Accuracy improves when retrieval stays in-distribution (local KG). When asked to reason beyond the KG (external LLM access), hallucination risk and validation difficulty increase.",
            "generation_validation_comparison": "Paper states LightRAG reduces generation that cannot be validated by forcing local-KG evidence, narrowing the generation-validation gap relative to unconstrained LLM generation.",
            "uncertainty_quantification": "Not specified; no calibrated uncertainty outputs reported from LightRAG in paper.",
            "calibration_quality": null,
            "out_of_distribution_performance": "Not quantified; authors warn that OOD reasoning (external LLM use) increases hallucinations and validation difficulty.",
            "validation_proxy_metrics": "Uses retrieval alignment (presence of KG triplets) and RAG-judged alignment scores as proxy validation metrics.",
            "human_validation_required": true,
            "human_validation_frequency": "Often required for outputs that go beyond local KG coverage; RAG-local mode reduces but doesn't eliminate need for expert review.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (biomedical KG retrieval) — relies on curated KG coverage for reliable validation.",
            "gap_mitigation_strategies": "Use of local-KG-only retrieval mode to avoid external hallucinations; limiting integration to verified, small KG updates; visually surfacing retrieved KG evidence for human inspection.",
            "evidence_supporting_gap": "Authors observed trade-offs: increasing retrieval scope (to capture more evidence) improves accuracy but raises computational/token costs; unrestricted LLM retrieval introduces hallucinations that are hard to validate.",
            "evidence_contradicting_gap": "When constrained to local KG, LightRAG produced more traceable outputs and reduced hallucinations according to expert feedback in the study.",
            "computational_cost_ratio": "Authors describe a trade-off: larger retrieval limits increase token consumption and query times; no numeric cost ratio reported.",
            "uuid": "e2071.1"
        },
        {
            "name_short": "LLM (ChatBot / RAG-driven LLM)",
            "name_full": "Large Language Model used as ChatBot and reasoning engine (LLM conditioned by RAG)",
            "brief_description": "Transformer-based large language models (unnamed) are used to generate explanations, initial hypotheses, paraphrase descriptions, and to provide heuristic and external-information-enhanced guidance; integrated into a RAG pipeline for grounding.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Large language model (RAG-conditioned, deployed in ChatBot)",
            "system_type": "large language model (transformer-based)",
            "scientific_domain": "hypothesis generation and explanation in biomedicine (drug repurposing, synthetic lethality)",
            "output_type": "textual hypotheses, explanations, suggestions for refinement, entity recommendations",
            "novelty_level": "can propose novel ideas beyond KG content (moderately to highly novel), but novelty comes with increased hallucination risk",
            "generation_method": "prompt-driven text generation, conditioned on retrieved KG evidence (RAG) or external sources (when permitted); generates initial hypotheses and paraphrases that experts refine",
            "validation_method": "Outputs are validated via KG retrieval (RAG), entity-alignment scoring, visualization for expert inspection, and domain expert review; some external literature checks performed on demand",
            "generation_performance": "No automatic numeric generation-quality metrics reported; user feedback indicates LLMs aid idea generation but can produce hallucinations and inconsistencies without KG grounding.",
            "validation_performance": "Validation relies on RAG and human review; no numeric validation accuracy for LLM outputs reported.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Authors note: hallucination risk and inconsistency increase with novelty/out-of-KG reasoning; local-KG grounding reduces but does not eliminate errors.",
            "generation_validation_comparison": "Paper highlights asymmetry: LLMs readily generate novel hypotheses but validating these (via KG alignment or experiments) is harder and often manual.",
            "uncertainty_quantification": "Not implemented for LLM outputs in the system as reported; authors recommend adding fact-verification modules and confidence thresholds in future.",
            "calibration_quality": "Not reported; anecdotal observations suggest poor/unquantified calibration for novelty.",
            "out_of_distribution_performance": "Not quantified; qualitative cautions: OOD outputs are more likely to be hallucinatory and require human/ KG-based checks.",
            "validation_proxy_metrics": "Plausibility, coherence, and KG alignment via RAG are used as practical proxies for validity.",
            "human_validation_required": true,
            "human_validation_frequency": "Frequent — especially for novel hypotheses or external-information-enhanced explanations; experts iteratively refine LLM outputs.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (biomedical) — LLM outputs need experimental or curated-KG corroboration to be actionable.",
            "gap_mitigation_strategies": "Ground LLMs with local KG via RAG, limit external retrieval to expert-controlled modes, show retrieved evidence inline, interactive workflows to let experts correct and expand KG.",
            "evidence_supporting_gap": "Multiple statements on hallucinations, need for KG grounding, and experts' experience that LLMs 'often struggle to maintain consistency and coherence in handling complex hypotheses.'",
            "evidence_contradicting_gap": "When combined with RAG and KG grounding, LLM outputs became more useful and enabled identification of relevant entities and hypotheses in case studies.",
            "computational_cost_ratio": "Not provided; authors note trade-offs between retrieval depth (cost) and accuracy/trustworthiness.",
            "uuid": "e2071.2"
        },
        {
            "name_short": "KGML-xDTD",
            "name_full": "KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description",
            "brief_description": "A drug repurposing prediction and mechanism-of-action (MOA) inference model that frames drug-disease prediction as link prediction using GraphSAGE embeddings and an adversarial actor-critic reinforcement learning module to extract biologically plausible MOA paths.",
            "citation_title": "KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description",
            "mention_or_use": "use",
            "system_name": "KGML-xDTD",
            "system_type": "graph neural network (GraphSAGE) + reinforcement learning (adversarial actor-critic) for link prediction and path inference",
            "scientific_domain": "drug repurposing / pharmacology",
            "output_type": "predicted drug-disease links and inferred mechanism-of-action (MOA) paths",
            "novelty_level": "moderately novel — predicts candidate repurposing links and MOA paths not always present in KG; authors claim enhanced prediction vs baselines (Appendix Tab.1)",
            "generation_method": "GraphSAGE node embeddings from KG + PubMedBERT-derived attributes, link prediction pipeline for candidate tail entities, and adversarial actor-critic RL to generate MOA paths from curated demonstration paths",
            "validation_method": "Model performance validated using curated datasets and external validation set: 472 drug-disease pairs from DrugMechDB for external validation; interpretability assessed via MOA path plausibility",
            "generation_performance": "Described as 'enhances prediction' relative to baselines (Appendix Tab.1) — no specific aggregate metrics reported in main text; authors claim improved interpretability via MOA path extraction.",
            "validation_performance": "External validation via DrugMechDB used; no numeric accuracy/precision/recall reported in main text (metrics referenced to Appendix Tab.1).",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "performance_vs_novelty": "Not specifically quantified; authors note that quality depends on KG coverage and curated demonstration paths for RL training — novel MOA paths outside training distribution likely harder to validate.",
            "generation_validation_comparison": "Model provides interpretable MOA paths that can be compared to curated mechanisms (e.g., DrugMechDB), narrowing generation-validation gap at the mechanistic-path level, but experimental validation still required for real-world claims.",
            "uncertainty_quantification": "Model outputs include ranked scores for predicted links and path weights; no calibrated uncertainty estimates reported.",
            "calibration_quality": "Not reported.",
            "out_of_distribution_performance": "Not reported; dependence on curated demonstration paths implies OOD MOA generation quality may decline.",
            "validation_proxy_metrics": "Uses path plausibility, path weights, and ranking scores as proxies for validity; also uses external curated pairs for validation.",
            "human_validation_required": true,
            "human_validation_frequency": "Recommended before experimental follow-up; domain experts inspect MOA paths and filter candidates.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (drug discovery) — requires biological experiments for confirmation.",
            "gap_mitigation_strategies": "Generates interpretable MOA paths to facilitate expert inspection and prioritization; uses curated demonstration paths in RL to bias toward biologically plausible mechanisms.",
            "evidence_supporting_gap": "Authors note that despite improved MOA extraction, the expanding volume of predictions makes manual validation impractical and experimental testing costly/time-consuming.",
            "evidence_contradicting_gap": "Interpretability (MOA paths) provides a clearer route for expert triage and comparison to curated mechanisms, helping reduce but not eliminate the gap.",
            "computational_cost_ratio": "Not specified; model training/inference has computational cost but authors emphasize the larger time/cost expense of experimental (wet-lab) validation.",
            "uuid": "e2071.3"
        },
        {
            "name_short": "KR4SL",
            "name_full": "KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality",
            "brief_description": "A heterogeneous-knowledge-graph GNN encoder-decoder model used for synthetic lethality (SL) gene-pair prediction that outputs ranked candidate SL pairs along with three-hop interpretative paths and path weights.",
            "citation_title": "KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality",
            "mention_or_use": "use",
            "system_name": "KR4SL",
            "system_type": "heterogeneous graph neural network (encoder-decoder) with path-tracing explanation",
            "scientific_domain": "cancer genomics / synthetic lethality prediction",
            "output_type": "predicted SL gene pairs and corresponding three-hop interpretative paths with path weights",
            "novelty_level": "moderately novel — predicts candidate SL pairs beyond existing validated interactions; provides interpretable paths to assist validation",
            "generation_method": "GNN-based encoder-decoder on a heterogeneous KG that traces relational paths and assigns weights to capture strength of candidate SL interactions; ranks candidates by likelihood",
            "validation_method": "Reported model precision on SL prediction (Appendix Tab.2); each prediction accompanied by a three-hop interpretative path for explanatory inspection by experts",
            "generation_performance": "Reported precision = 59% (Appendix Tab.2) — authors state KR4SL outperforms comparable models on their SL dataset; each prediction includes a three-hop interpretative path.",
            "validation_performance": "Precision 59% implies many predictions are correct at top ranks under their evaluation setup; no recall / F1 or dataset-level false negative rates reported in main text.",
            "false_positive_rate": "Not directly reported; implied false-positive proportion ≈ 41% under the usual definition (FPR ~ 1 - precision) given precision=59% — this is an inference based on standard precision definition.",
            "false_negative_rate": null,
            "performance_vs_novelty": "Not explicitly studied; interpretative paths help experts triage novel predictions, but actual validation (wet-lab) remains costly and slow.",
            "generation_validation_comparison": "Model provides generation (predictions + explanatory paths) but validation relies on held-out datasets and expert inspection; the authors note precision is moderate, indicating a non-trivial generation-validation gap for less-likely predictions.",
            "uncertainty_quantification": "Model outputs include ranking scores and path weights indicating confidence; no calibrated uncertainty metrics reported.",
            "calibration_quality": "Not reported.",
            "out_of_distribution_performance": "Not reported explicitly; performance likely depends on KG completeness and heterogeneity.",
            "validation_proxy_metrics": "Uses precision on curated SL datasets and interpretative path plausibility as proxies for real-world validity.",
            "human_validation_required": true,
            "human_validation_frequency": "Recommended — experts inspect interpretative paths and select candidates for costly experimental validation; frequency scales with number of novel predictions.",
            "formal_verification_used": false,
            "domain_formalization_level": "empirical (genomics / wet-lab biology) — experimental validation essential to confirm computational predictions.",
            "gap_mitigation_strategies": "Provides three-hop interpretative paths and path weights to improve explainability and aid expert triage; integrates with HypoChainer visualization for iterative refinement.",
            "evidence_supporting_gap": "Moderate model precision (59%) shows many computational predictions are plausible but not definitive; experts must filter and experimentally validate candidates — authors explicitly note manual validation is infeasible at scale.",
            "evidence_contradicting_gap": "Providing interpretative paths and reasonable precision suggests that computational predictions can be useful for prioritization and reduce some validation burden.",
            "computational_cost_ratio": "Not quantified. Authors emphasize experimental wet-lab validation (months-long for SL) is orders of magnitude more costly/time-consuming than in-silico generation.",
            "uuid": "e2071.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description",
            "rating": 2
        },
        {
            "paper_title": "KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality",
            "rating": 2
        },
        {
            "paper_title": "LightRAG: Simple and fast retrieval-augmented generation",
            "rating": 2
        },
        {
            "paper_title": "SLInterpreter: An exploratory and iterative Human-AI collaborative system for GNN-based synthetic lethal prediction",
            "rating": 2
        },
        {
            "paper_title": "KNOWNET: Guided health information seeking from LLMs via knowledge graph integration",
            "rating": 1
        }
    ],
    "cost": 0.01983,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery
21 October 2024</p>
<p>Haoran Jiang 0009-0009-5717-4208
Shaohan Shi 0009-0004-3384-8304
Yunjie Yao 0009-0000-8371-6984
Chang Jiang jiangchang@shanghaitech.edu.cn.haoran 0000-0002-7468-3372
Quan Li liquan@shanghaitech.edu.cn 
Y Jie 
C Jiang </p>
<p>7 5 8 9 12 13 15 16 11 10</p>
<p>School of Information Science and Technology
ShanghaiTech University</p>
<p>Shanghai Engineering Research Center of Intelligent Vision and Imaging
China</p>
<p>Shanghai Clinical Research and Trial Center
ShanghaiChina</p>
<p>HypoChainer: A Collaborative System Combining LLMs and Knowledge Graphs for Hypothesis-Driven Scientific Discovery
21 October 2024D6F23BD852CA89E3BD26F2125C527ACAarXiv:2507.17209v1[cs.HC]received 1 April 2024; accepted 15 July 2024. Date of PublicationLarge Language ModelVisual AnalyticsIterative Human-AI CollaborationKnowledge GraphHypothesis Construction
Fig.1: In the presented case study, the biologist's analytical workflow unfolds as follows: 1 Upload Drug Repurposing data. 2 Pose a target question to the RAG model.3 RAG identifies Episodic Ataxia Type 5 as the top candidate.4 Lasso the clustered diseases.5 Observe that the CACNA1C often appeared among the top-ranked predictions.6 Select the interpretative path of Episodic Ataxia Type 5. 7 The LLM explains the selected prediction path and generates base hypotheses.8 Construct the hypothesis chain.9 Hypothesis chain is validated for entity alignment.10 KG integration reveals novel paths in the lower layer.11 Observe multiple interpretative paths consistent with the hypothesis.12 Inconsistent predictions for Huntington's disease trigger afterwards exploration.13 Expand the retrieval results.14 -15 Filtered predictions confirm relevance to Parkinson's disease and Amyotrophic Lateral Sclerosis (ALS). 16Identify overlooked predictions of Huntington's disease aligning with the refined hypothesis chain.</p>
<p>INTRODUCTION</p>
<p>Modern scientific discovery faces a critical challenge in synthesizing exponentially growing [60], heterogeneous knowledge to drive breakthroughs in data-intensive domains [16], like biomedicine and drug development [77].Traditional hypothesis-driven research (Fig. 2-A ) relies on domain experts to manually formulate theories through exhaustive literature reviews, iterative experimentation, and reasoning grounded in specialized knowledge [51].While this paradigm has yielded significant advances, it's inherently constrained by cognitive limits [7], combinatorial complexity of biological systems [6], and resource-intensive nature of experimental validation (e.g., months-long wet-lab studies for a single hypothesis) [66].These limitations highlight the need for computational frameworks that enhance human expertise by reducing information overload and reliance on trial-and-error.</p>
<p>Advances in deep learning, particularly graph neural networks (GNNs) and transformer-based models [70,72], have revolutionized hypothesis prioritization-the process of ranking and selecting the most promising hypotheses-in biological discovery.These methods effectively model biological interactions-such as protein-ligand binding [13], synthetic lethality (SL) relationships 1  [72], and drug candidate prediction [41]-to generate predictive outcomes that guide hypothesis validation.While these tools have greatly streamlined the scientific discovery process, their effectiveness is increasingly constrained by the rapid expansion of biological and biomedical datasets.As model predictions grow in volume [41], manual evaluation and validation by domain experts becomes impractical, creating a critical bottleneck in translating computational insights into scientific breakthroughs.To address this challenge, previous studies have proposed using the comparative analysis of similar predictive outcomes [27] to identify promising yet unverified predictions.Although these methods have shown success in identifying results that align with established mechanisms, they are limited in their ability to detect predictions that lack prior validated analogs.As a result, the identification and validation of novel mechanisms from predictive outcomes remain a significant challenge, hindering the discovery of groundbreaking scientific insights.Recent efforts [1,69,76] have extended to leveraging large language models (LLMs) to analyze and interpret large-scale predictive outcomes.LLMs offer unique advantages in integrating multimodal and heterogeneous data, enabling preliminary reasoning frameworks to address complex biological questions [25,44]-from hypothesis generation and information retrieval [64] to evidence-based explanations [55].Yet, as data complexity grows, their propensity for hallucinations or inaccuracies intensifies [50], raising concerns about reliability despite their multi-perspective reasoning capabilities.This tension has spurred interest in grounding LLM outputs in structured knowledge [14,39] to enhance trustworthiness, where GNNs and knowledge graphs (KGs) have emerged as critical solutions.Particularly, GNNs, renowned for accuracy through structured relational modeling, synergize with 1 Synthetic lethality is a genetic interaction where the simultaneous inhibition of two genes causes specific cell death while inhibiting either gene alone does not.</p>
<p>KGs-which encode precise, standardized relationships-to improve feature representation and prediction robustness [73].For instance, KR4SL [72] integrates KG reasoning with GNNs to predict synthetic lethality, combining semantic relationships and structural patterns to boost both accuracy and explainability.However, challenges persist: textual data alone may inadequately contextualize predictions, while gaps in commonsense knowledge or overly simplistic edge relationships in KGs can limit their comprehensiveness [48].</p>
<p>To leverage the complementary strengths and mitigate the limitations of existing methods (LLMs, KGs, and manual workflows), we focus on a critical challenge: integrating human expertise, LLM-driven reasoning, and KG-structured knowledge into a unified hypothesis-driven framework that breaks information silos and streamlines the discovery of novel mechanisms.Through a formative study conducted in collaboration with domain experts, we identified six key design requirements, emphasizing collaborative exploration, interpretability, and iterative hypothesis refinement.Guided by these requirements, we propose a collaborative framework that synergizes human intuition, LLMs, and KGs through the construction of hypothesis chains-structured reasoning paths composed of multiple interrelated hypotheses connected by logical links.The workflow unfolds in three stages: I Contextual Exploration: Domain experts raise research questions, prompting a retrieval-augmented LLM (RAG) to surface relevant research objects from GNN predictions.Interactive visualizations and LLM-generated explanations contextualize results, enabling experts to better analyze predictions while addressing gaps in the missing commonsense knowledge and details within structured information.II Hypothesis Construction: As experts iteratively analyze predictions, they construct hypothesis chains-semantically linked sequences of insights-supported by LLM-generated refinements and KG relationships.III Validation Selection: The workflow filters predictions against refined hypothesis chains, identifying candidates for experimental validation based on alignment with KG-supported evidence.Weak points in the hypothesis chain are further optimized through visual analytics of the retrieval results.To demonstrate the effectiveness of HypoChainer (Fig. 2-B ), we conducted expert interviews and a case study in the field of drug repurposing.In summary, the contributions of this study are as follows:</p>
<p>• We conducted in-depth expert interviews and a thorough literature analysis, identifying six key design requirements for integrating LLMs with structured knowledge in scientific discovery.• We developed a collaborative framework, HypoChainer, linking LLMs and KGs, enabling experts to explore model predictions, construct and refine hypothesis chains, uncover underlying mechanisms, and prioritize validations through interactive visualization.• We validated HypoChainer through a comprehensive case study and expert interviews, demonstrating its effectiveness and generalizability in hypothesis construction and scientific discovery.</p>
<p>RELATED WORK</p>
<p>Hypothesis Generation and Refinement</p>
<p>Hypothesis generation involves proposing new concepts or scientific mechanisms [78], playing a vital role in advancing scientific research [53], which relies heavily on researchers' accumulated knowledge and intuition, introducing limitations and uncertainties.To address these challenges, researchers began leveraging extensive existing knowledge to support hypothesis construction.Early hypothesis generation efforts primarily focused on predicting relationships between concepts, based on the assumption that new ideas emerged from connections with established ones [23,32].However, with advancements in language models [9,74], open-ended idea generation has gained increasing attention [33,58].Recent AI-driven hypothesis generation methods employ diverse approaches to conceptualizing research ideas.For instance, MOOSE [66] and IdeaSynth [52] integrate LLMs into interactive frameworks, facilitating the transition from inspiration to hypothesis construction.Many studies [31,57,62] have also combined hypothesis-driven frameworks with visualization-based designs.Moreover, hypothesis generation is rarely a one-step process, particularly when constructing complex hypothesis chains that require logical consistency and adherence to fundamental principles.Therefore, hypothesis refinement-driven by feedback and iterative improvementsis equally critical.Methods such as HypoGeniC [77] and MOOSE [66] emphasize iterative enhancement through feedback mechanisms, including direct responses to hypothesis [4], experimental result evaluations [42,71], and automated peer-review commentary [40].Beyond feedback-driven refinements, collaborative hypothesis generation has also gained traction, leading to the development of multi-agent systems [16,45].For instance, VIRSCI [59] optimizes hypothesis construction by customizing knowledge for each agent, while Nova [24] incorporates outputs from other research efforts to refine hypothesis generation.However, such multi-agent frameworks also introduce challenges, including hallucinations [50], inaccuracies, and errors in agent-generated outputs.If left unchecked, these errors can propagate through the reasoning process, leading to misleading or incorrect conclusions.Recently, a multi-agent system based on Gemini 2.0 was proposed [17], designed to generate and refine novel research hypotheses through a "generate-debate-evolve" framework, utilizing test-time compute to improve hypothesis quality.However, this system does not incorporate constraints from structured knowledge sources and experts still remain limited to guiding AI in knowledge discovery, lacking intuitive visualizations to independently explore and uncover insights.</p>
<p>To address these challenges, we propose combining LLM-driven hypothesis generation with AI-expert collaborative optimization process.By enabling timely human intervention and error correction, it ensures both the logical consistency of the hypothesis and the effective utilization of LLM's vast knowledge and reasoning capabilities, ultimately enhancing hypothesis construction and iterative refinement.</p>
<p>Graph-Structured Knowledge Exploration</p>
<p>With the continuous expansion and enrichment of structured knowledge, increasingly complex graphs have emerged across various domains.These graphs encode rich information about entities and their relationships, facilitating reasoning and novel knowledge prediction through propagation.However, as graph data rapidly expands, effectively identifying patterns within large-scale graphs and exploring vast prediction results within the same large-scale KG has become increasingly challenging.Researchers have addressed these issues by developing various visualizations, particularly in biological networks [27,65], neural networks [29], and social networks [10].For example, Paley et al. [46] used force-directed layouts and clustering to reveal key biological pathways and drug targets in complex datasets, facilitating discoveries in molecular interactions and metabolic pathways that drive advancements in drug discovery and synthetic biology.</p>
<p>While these visualization methods have demonstrated significant effectiveness, the challenges of graph exploration and information retrieval extend beyond static representations.Many interactive approaches [75] have been developed to tackle these challenges, such as Biolinker [13], an interactive visualization system that supports bottomup exploration of complex protein interaction networks.However, when analyzing predictive model outputs, researchers must navigate large volumes of predictions and interpret extensive graph structures-often with subtle yet critical distinctions.These challenges are further exacerbated when investigating intricate and extended chains of interpretative paths and patterns, making graph analysis increasingly demanding.</p>
<p>Building upon previous research in graph-structured knowledge exploration and leveraging the analytical reasoning capabilities of LLMs, this study integrates graph exploration with text-based prompts.We employ a hierarchical layout to organize one-hop entities along prediction paths and hypothesis-aligned entities-defined as those complying with or related to the given hypothesis descriptions-where hypotheses are initially generated by the LLM and iteratively refined by experts, using Voronoi treemaps [5], enhancing spatial efficiency and clarity.Simultaneously, existing edges within the KG are visualized between entities to highlight structural relationships between predictions and entities from different sources.This dual approach enables users to explore relationships among structurally related and hypothesis-aligned entities, evaluate the coherence between model predictions and proposed hypotheses, and uncover insights through comparative analysis.</p>
<p>Collaboration Between Human, LLM, and KG</p>
<p>As AI advances and the modes of interaction diversify, the dynamics of both human-AI and AI-to-AI cooperation are continuously evolving.Within the framework of Collaboration Between Human, LLMs, and KG, the pairwise interactions [2,30] can be categorized into three key relationships: Human-LLM, Human-KG, and LLM-KG.</p>
<p>Human-LLM.The interaction between humans and LLMs forms a continuous learning loop.In this collaborative paradigm, humans serve as both users and critical coordinators, guiding context-specific outputs through structured mechanisms.Additionally, reinforcement learning [54] from human feedback further refines LLM outputs to align with ethical considerations and domain-specific objectives [30].</p>
<p>Human-KG.Humans engage with KGs to retrieve, structure, and refine information through queries [49], natural language [56], and visualization tools [3].By leveraging KGs as structured repositories of factual knowledge, users can enhance information accessibility and explainability in AI applications.For instance, DrugExplorer [65] employs explainable AI (XAI) techniques to interpret GNN-based predictions and refine biomedical KGs, while SLInterpreter [27] introduces an iterative human-AI collaboration system for SL prediction, which enables experts to enhance KG interpretability and align AI outputs with expertise via metapath strategies and iterative path refinement.</p>
<p>LLM-KG.The bidirectional integration between LLMs and KGs unfolds through two key paradigms: LLM-enhanced KG [2] and KGenhanced LLM [47].LLMs enhance KGs by automating entity extraction via prompt-driven mining [28], refining entity parsing and matching through synthetic labeled data generation [63], and improving link prediction with joint text-KG embeddings [67].Conversely, KGs enrich LLMs by injecting structured knowledge during pre-training [21], optimizing fine-tuning with knowledge-aware objectives [37], enhancing retrieval through hybrid neural-symbolic architectures [26], and refining prompt-based reasoning via KG-guided subgraph extraction and logic-aware chained inference [11].</p>
<p>Recent studies have begun exploring the Collaboration Between Human, LLMs, and KG, such as KNOWNET [68], which combines LLMs with KGs to enhance the quality and efficiency of human-AI interaction through structured knowledge validation and iterative query refinement.While integrating LLMs with KGs can enhance knowledge coverage and reasoning, existing approaches often fail to apply LLMs' reasoning capabilities to KGs directly and underestimate the role of human experts in decision-making, limiting collaborative efficacy.To address this, we propose a hypothesis validation framework that harnesses the complementary strengths of LLMs, KGs, and human experts.By leveraging each component's strengths and mitigating limitations, our framework promotes transparent, controllable collaboration, enhancing hypothesis validation and discovery outcomes.</p>
<p>FORMATIVE STUDY</p>
<p>In this study, we aimed to understand researchers' challenges, expectations, and requirements for collaborating with AI across various domains comprehensively.To achieve this, semi-structured interviews (see Appendix E for details) with institutional IRB approval were conducted with two researchers specializing in cancer therapy (E1-E2), and two researchers focusing on drug research (E3-E4) (Mean Age = 39.75, SD = 5.4, 2 males, 2 females).Among them, E1-E2 specialize in screening SL pairs using the CRISPR/Cas9 technique, focusing on thyroid cancer (E1) and breast cancer (E2), respectively.E3-E4 are engaged in drug research, with E3 focusing on drug repurposing, while E4 specializes in discovering new drug targets through pharmacogenomics.Each participant has significant research experience in their respective fields and expertise in AI-assisted prediction.Through inductive coding and thematic analysis [12], we extracted valuable insights into the challenges faced by domain experts and summarized the design requirements.Each interview session lasted approximately 45 minutes.</p>
<p>Experts' Conventional Practices</p>
<p>E3, specializing in drug repurposing, outlined their conventional approach to mechanistic investigations [20].The process begins with selecting a research domain, followed by an extensive review of background literature to establish foundational knowledge.Combining this information and their domain expertise, they formulate initial hypotheses through logical reasoning, which are then tested experimentally via methods like high-throughput sequencing.However, E3 highlighted limitations in this traditional workflow: Research directions are often restricted to familiar fields to reduce uncertainty, and hypothesis development requires laborious literature reviews to balance novelty with plausibility.This is particularly challenging in less familiar domains, where limited expertise can undermine confidence in hypothesis design.Additionally, over-relying on trial-and-error experiments without theoretical grounding wastes resources and limits progress.</p>
<p>E1 noted that the similar workflows are also applied to SL mechanistic studies, but with one critical distinction: Wet-lab experiments in SL research take around six months to complete, dramatically increasing the cost of trial-and-error.This necessitates rigorous hypothesis evaluation and meticulous experimental planning prior to testing.To facilitate this process, researchers now employ GNN models to predict potential SL pairs.Predictions are filtered using two criteria: (1) the interpretability of interpretative paths2 and (2) the model's prediction confidence scores.While this approach reduces reliance on purely familiarity-driven hypothesis, significant challenges remain: Human intervention is still required to evaluate predictions, and generating truly novel hypotheses continues to demand substantial creativity and domain insight.Given the large volume of predicted results, the experts have explored the use of LLMs for direct reasoning and filtering [55,64].However, when attempting to integrate LLMs into their research, they found it challenging to effectively incorporate local data (e.g., KG).Moreover, their practical use revealed that LLMs often struggle to maintain consistency and coherence in handling complex hypotheses.</p>
<p>Experts' Concerns and Expectations</p>
<p>Initially, domain experts expressed concerns that structured knowledge-often represented as triplets, the basic units of KGs describing relationships between entities (e.g., Primaquine-Affects-IKBKG)-lacks commonsense details and explanatory text.They also noted that the granularity of edge relationships is sometimes too coarse, making it difficult to interpret different paths.As one expert pointed out: "... some GNNs do give us interpretative paths, but honestly, the information these paths contain is pretty limited.You know, even when different groups of entities are linked by the same label, the actual meaning can be very different.[Point at CYLC1 and DAB1] They are both labeled as being involved in cell differentiation, but I'd bet their actual roles are pretty different.All these missing details make interpretative paths hard to understand and, honestly, it just makes me not trust them as much."This reveals the first challenge: C1.Insufficient detail and inadequate granularity in interpretative paths.To address the issue of limited detail and insufficient granularity in interpretative paths [C1], it is crucial to provide reliable and comprehensive information.This leads to our first design requirement: DR1.Enriching interpretative paths with reliable and sufficient detail.</p>
<p>Experts have also expressed concerns about the potential inadequacy of relevant information for hypothesis construction.When formulating hypotheses, domain experts often require supplementary knowledge to integrate diverse information and generate novel insights.Acquiring such knowledge typically involves extensive literature reviews, which can be burdensome and prone to overlooking critical insights.As E1 emphasized, "...When aiming to construct novel hypotheses, relying solely on our existing knowledge is often insufficient.We need to gather as much relevant information as possible to inspire new ideas and facilitate reasoning.However, this process is time-consuming and mentally demanding...Sometimes, extensive reading may not always help us grasp key points, and prolonged reading sessions can be distracting."This highlights the second challenge: C2.Inefficiency in acquiring relevant knowledge for novel hypothesis construction.Building on this, experts further emphasized the need for more effective methods, such as KG-based information retrieval, semantic search, and recommendation to aid information retrieval, ultimately facilitating hypothesis construction.This leads to the second design requirement: DR2.Providing efficient methods to obtain relevant information for hypothesis construction.</p>
<p>Managing large-scale model predictions presents another significant challenge.The most reliable method currently involves domain experts manually analyzing and filtering predictions to identify novel research focuses or by some visualization methods [57].However, as the volume of predictions increases, this manual or visual-assisted approach becomes unsustainable, placing a heavy burden on experts and potentially affecting their judgment.E2 illustrated this difficulty: "Prediction models are pretty impressive-they do get some things right.But with so many results, it's like going from finding a needle in the ocean to a needle in a pond.Trying to sort through everything on our own without a clear direction is still overwhelming and just not realistic."This highlights the third challenge: C3.Impracticality of manually filtering and analyzing large-scale predictions.In light of the above challenge, E1 highlighted, "It's practically infeasible and really limits how much we can focus.Rule-based methods?Yeah, they can simplify things, but they'll definitely miss a lot of results that don't fit perfectly.We really need something smarter and more intuitive to quickly zero in on the results that actually matter."This insight leads us to our third design requirement: DR3.Streamlining and optimizing evaluation and insight extraction in massive predictions.</p>
<p>Experts also noted that while existing tools can help uncover simple patterns, they often reinforce known results rather than discovering novel insights.As E2 explained: "...Some tools can help us with simple patterns, but they just find results that look like what we already know.The problem is, if a model predicts something different-even if it's right-we might not even notice.That keeps us stuck in a loop, always going for the easy, obvious predictions.Suppose we really want to dig deeper and uncover complex mechanisms, then it's not just about finding similar predictions...We need better ways to build logical connections with hypotheses through observations, refine them, and search for patterns that actually lead us to new insights that we might've missed before."This reveals the fourth challenge: C4.Lack of tools to construct hypothesis chains for exploring complex mechanisms.As E3 noted, "When we're building a hypothesis, every step needs to make sense.If one part doesn't, the [whole] thing falls apart.That's why we need something to help us catch [any] flaws.And expanding the hypothesis is tricky too-it can feel pretty random and really depends on what we already know.A tool that suggests reasonable hypotheses and explains them?Yeah, I'd definitely be interested in trying that."This leads to the fourth design requirement: DR4.Supporting interactive construction and continuous optimization of hypothesis chains.</p>
<p>Even with tools for constructing hypothesis chains, experts found it difficult to retrieve relevant predictions that align with their hypotheses.They emphasized the need for better integration between model predictions and KG to refine hypotheses.E4 explained, "If we construct a hypothesis chain based on certain observations and our expertise but are unable to retrieve similar predictions or relevant evidence from the KG, it does not seem to help us come up with more solid hypotheses or further gain new insights".This highlights the fifth challenge: C5.Absence of retrieval methods for hypothesis-aligned predictions.As E2 and E4 noted, "It's exciting to find known paths or predictions closely aligning with our hypotheses."However, designing search logic or rules for each hypothesis proves difficult, they added, "and on top of that, it is impossible to experimentally validate every emerging hypothesis."This highlights the fifth design requirement: DR5.Providing effective retrieval methods for hypothesis-aligned predictions.</p>
<p>Experts have also raised concerns about the information flow between LLMs, KGs, and domain experts, particularly based on their prior experiences with LLM integration.Despite efforts to bridge these components, significant challenges and barriers remain in ensuring that information is effectively transmitted and utilized.As E3 noted after the discussion, "I'm hoping LLMs and KGs can better share information with each other.Right now, when I use an LLM with a KG, the LLM often relies too much on external knowledge and doesn't fully use the KG information unless I explicitly highlight the details.At the same time, the KG struggles to recognize entities when the LLM describes them differently, making the whole interaction awkward and fragmented.I want to make this smoother, improve how they understand each other, and help them combine their strengths to reach stronger conclusions."This highlights the last challenge: C6.Information transmission barriers between LLMs, KGs, and domain experts.Accordingly, we introduce the last design requirement: DR6.Ensuring seamless and lossless transmission of information between LLMs, KGs, and domain experts.This requirement aims to consistently maintain the quality of information, ensuring that when accurate information is transmitted between different parties, its completeness and precision are always preserved.Reflecting the perspectives of E3, "Sure, we obviously want the info to be reliable when it's passed between the LLM, KG, and us.If there's any mix-up or something gets left out, it's definitely gonna mess with our judgments.I think this is really the key to making sure we can work together smoothly."</p>
<p>HYPOCHAINER</p>
<p>To ensure a seamless flow of information among different parties and enable experts to efficiently explore the system, the pipeline has been meticulously designed and iteratively refined.It comprises three key modules: Contextual Exploration, Hypothesis Construction, and Validation Selection, aligning with the conventional workflow while improving overall coherence, rationality, and efficiency (Fig. 2) (DR6).This section first provides a detailed overview of the backend algorithms implemented, followed by an introduction to the system's visual design.Finally, a walkthrough case study is presented to offer a concrete and comprehensible introduction to the entire pipeline.</p>
<p>Data and Backend Engine</p>
<p>We provide an overview of the data utilized in our approach.To assess the effectiveness and generalizability of our method, we employ two types of biological data: Drug Repurposing and Cancer Research.</p>
<p>Drug Repurposing.A large-scale biomedical knowledge graph [41] was utilized, derived from RTX-KG2c (v2.7.3), which integrates data from 70 public sources, with 6.4 million entities and 39.3 million edges.The graph is standardized using the Biolink model [61].To tailor it for drug repurposing, the dataset was refined into a streamlined graph with 3, 659, 165 entities and 18, 291, 237 edges.Key data sources include MyChem, SemMedDB, NDF-RT, and RepoDB, providing both positive (indications) and negative (contraindications/no-effect) samples.Furthermore, 472 drug-disease pairs are leveraged from DrugMechDB for external validation, enhancing the dataset's reliability and applicability.</p>
<p>KGML-xDTD [41] is a drug repurposing prediction and mechanism of action (MOA) inference model, integrating graph-based learning with reinforcement learning.The module formulates the task as a link prediction problem, which employs GraphSAGE, to generate node embeddings by leveraging structural and attribute information from Pub-MedBERT.The MOA module identifies biologically plausible MOA paths using an adversarial actor-critic reinforcement model, which is trained using curated demonstration paths.KGML-xDTD enhances prediction (Appendix Tab. 1) while maintaining interpretability.</p>
<p>Cancer Research.This dataset [72] focuses on SL relationships, where the simultaneous inactivation of a gene pair leads to the death of a specific cancer cell.The cancer research knowledge graph is constructed using data from two primary repositories: SynLethDB, which catalogs validated gene SL interactions, and ProteinKG25, a biomedical knowledge dataset containing information on gene functions, pathways, and biological processes.The resulting KG comprises 42, 547 entities, 33 edge types, and a total of 396, 619 triplets.</p>
<p>For SL gene pair prediction, we utilize the KR4SL model [72], which follows an encoder-decoder architecture and employs a GNN-based approach with a heterogeneous KG.The model predicts SL pairs by tracing relational paths, assigning weights to these paths to capture the strength of SL interactions and uncover potential relationships between unconnected genes.Candidates are ranked based on their likelihood of forming an SL relationship.Each prediction is accompanied by a three-hop interpretative path.The model achieves a precision of 59% (Appendix Tab. 2), outperforming comparable models.</p>
<p>Frontend Interface</p>
<p>Working alongside domain experts, we have designed a frontend interface to support scientific discovery workflows through a set of dedicated modules, namely Control Panel, Embedding View, Chatbot, Prediction View, Hypothesis View, Chain View, and Retrieval View.</p>
<p>Control Panel.The Control Panel (Fig. 1-A ) includes three search boxes to streamline prediction selection across hierarchical levels.The Category search box displays categories to assist in selecting specific types of Head Entities or narrowing the scope of subsequent searches, while the Head search box leverages an auto-complete function for direct Head Entity queries.Upon selecting a Head Entity, the Tail Entity table positioned below the search boxes automatically populates with the top 50 predicted Tail Entities, sorted in ascending order by rank and annotated with their Name, Score, and Rank.However, given that not all datasets contain predefined categories, users can define new categories encompassing relevant entities through the ChatBot during the Contextual Exploration phase.Each query is logged in the Category search box for convenient reuse in subsequent explorations.</p>
<p>Embedding View.The Embedding View (Fig. 1-C ) displays cluster summaries derived from entity features, with methodologies tailored to distinct datasets.For instance, dimensionality reduction for gene data incorporates gene descriptions, nucleotide sequences, and other pertinent information, whereas drug data reduction utilizes attributes like drug descriptions, indications, and mechanisms of action through UMAP [43] (Comparison in Appendix).This aids domain experts in analyzing prediction patterns, offering an intuitive framework to identify research focuses within large-scale predictions (DR3).Additionally, the Embedding View interacts with the ChatBot during the Contextual Exploration phase: when the RAG suggests entities relevant to the query, Embedding View highlights them for lasso selection.</p>
<p>ChatBot.The ChatBot (Fig. 1-B ) serves as the central hub of the system, orchestrating seamless interactions across all interface components by integrating reasoning models ( LLM) and retrieval mechanisms, which is based on LightRAG [19] for its lower cost and faster response compared to GraphRAG [15] ( RAG), to synchronize KG data, AI-generated insights, and expert input (DR6).The interface ensures intuitive usability through features such as a left history section that logs and summarizes the dialogue, a bottom input box with retrieval mode selector ( Search in KG &amp; Search by LLM ), upper-right</p>
<p>Previous &amp; Next buttons that activate phase-specific LLMs.For instance, during the Contextual Exploration, RAG and the entity filtering and recommendation are invoked to ensure that the information comes solely from the local database, thus minimizing the risk of recommending entities not present in the KG or generating hallucinations.The chatbox dynamically adapts its color scheme to signal active retrieval modes, serving as a reminder to domain experts of the current model in use.Furthermore, the responses generated by the LLM include suggestions for further exploration, which are based on neighboring entities in the KG or relevant information related to the topic, and are displayed beneath each chatbox.Also, entities that appear in both the ChatBot and the corresponding view are color-matched to ensure consistency, helping experts quickly locate and associate relevant entities.</p>
<p>Prediction View.The Prediction View (Fig. 1-D ) is designed to empower users in distilling valuable insights from a substantial volume of predictions (DR3), enabling targeted identification of results aligned with their research objectives.Building on the foundational principle of LineUp [18], this view adopts a tabular visualization that balances domain experts' familiarity with advanced analytical capabilities.The design optimizes spatial efficiency by binding entities to their subsequent edge relationships, compressing horizontal layouts without sacrificing contextual continuity.To streamline exploration, the system provides two key features: auto-completion-enabled filtering, which supports multi-hop queries across entities and edge relations, and dynamic highlighting mechanisms that enhance analytical precision.When users hover over entities, the system highlights the full corresponding interpretative path (Fig. 1-6 ), aiding the exploration of connection patterns.A persistent anchoring bar at the bottom of the view displays the hovered path and fixes the selected one, reducing visual tracking effort and supporting path comparison.Once a hypothesis chain is submitted for analysis in the Chain view, hypothesis-aligned predictions are marked by ★ (Fig. 1-10 ) to enable users to quantify the consistency between theoretical assumptions and empirical outcomes.Additionally, experts are able to perform single-column sorting based on path scores and edge weights.These features collectively enable domain experts to iteratively refine insights-from macro-level pattern discovery to granular path analysis-by systematically prioritizing paths through sortable confidence scores, cross-validating hypotheses against prediction, and exporting candidate paths for validation.</p>
<p>Hypothesis View.The Hypothesis View (Fig. 1-E ) presents KG entities aligned with a selected prediction path (DR2), enrich structured information (DR1), and assist domain experts in hypothesis refinement through iterative optimization (DR4).The view dynamically retrieves entities through RAG and organize directly connected 1-hop neighbors in KG (Appendix Fig. 1-1 ) and hypothesis-aligned entities (Appendix Fig. 1-2 ) retrieved from the generated hypotheses and the subsequent iterative refined hypotheses in a hierarchical architecture.To optimize layout clarification and scalability for large biomedical datasets, entities within each layer are arranged using a Voronoi treemap [5], a technique proven effective in reducing visual clutter while preserving spatial efficiency, making it particularly suitable for visualizing large-scale knowledge graphs [27].Entities of the same type are clustered within layers to highlight structural patterns and simplify analysis.When users hover over a node in the Voronoi treemap, the node and its connected edges are highlighted in red, directing attention to relevant relationships.</p>
<p>The view further dynamically establishes plausible KG-derived links between entities across adjacent layers.This approach enables domain experts to progressively and intuitively analyze potential connections between 1-hop entities the predicted path and hypothesis-aligned semantic matches, fostering a structured understanding of both KG proximity and semantic relevance.By visualizing potential connection patterns, experts can assess whether these connections align with similar underlying hypotheses, thereby refining validation processes and guiding the construction of logically coherent hypothesis chains.</p>
<p>Chain View.The Chain View supports domain experts in systematically constructing, previewing, and refining hypotheses (DR4).It facilitates the iterative analysis and optimization of individual hypotheses through integration with LLMs, enabling users to chain hypotheses into a cohesive structure for subsequent retrieval and validation.</p>
<p>The Input Area (Fig. 1-F1 ) enables hypothesis chain construction and review.Each hypothesis node features a text area above for hypothesis description, with additional fields below to define relationships between entities.Clicking the lower right Submit button triggers targeted RAG retrieval to validate the hypothesis against the KG, displaying relevant entities in the Entity Preview (Fig. 1-F2 ), including entity names, types, and descriptions of how they align with the hypothesis, ordered by their degree of alignment, which is judged by the RAG through a systematically designed prompt.This preview facilitates rapid hypothesis evaluation and refinement without resource-intensive full-scale RAG retrievals.At the top-right corner, the button LLM capabilities to evaluate the hypothesis chain for logical coherence, identifying potential inconsistencies or optimization opportunities.Once validated, the Retrieve button initiates the formal retrieval process for downstream tasks.To clarify functionality, the Retrieve button (linked to KG-grounded RAG retrieval) and the Analyse (LLM-driven reasoning) are differentiated through the icons in ChatBot.</p>
<p>Retrieval View.The Retrieval View provides an overview of all hypothesis chain retrievals and corresponding results.It highlights the quantities of retrieval outcomes aligned with the hypothesis chain at varying matching levels, alongside detailed retrieved results (DR5).</p>
<p>The Retrieval List (Fig. 1-G1 ) catalogs hypothesis chains and their retrieval outcomes, organized into collapsible records.Below, the UpSet Plot (Fig. 1-G2 ) [35] visualizes the degree to which retrieval results for the currently selected hypothesis chain satisfy the hypothesis, assisting experts in identifying which hypotheses require refinement or commonly appear in predictions.Specifically, the UpSet Plot includes three rows (Fig. 3-1 ) representing the three hypotheses within the chain, with an adjacent bar chart (Fig. 3-2 ) showing the count of triplets satisfying individual hypotheses.A central dot matrix and bar chart (Fig. 3-3 ) represent combinatorial hypothesis satisfaction.For example, the fifth column highlights triplets fulfilling both Hypothesis 2 and 3 in the hypothesis chain.Hovering over a row or column (Fig. 3-4 ) dynamically highlights intersecting sets and displays their proportional contributions within the corresponding hypothesis (Fig. 3-5 ).Clicking bars filters the Retrieval List accordingly, with intersections indicated at the upper-right corner (Fig. 1-15 ).The resets the view to the default display of complete retrieval results.</p>
<p>Rows can also be hovered on # of triplets that fully align the entire hypothesis chain on column Hypothesis 2 ∩ 3</p>
<p>Pipeline Walkthrough</p>
<p>To clarify the pipeline's structure, we walked through an SL prediction example together with E1 and E2, systematically demonstrating how Contextual Exploration, Hypothesis Generation, and Validation Selection are applied in sequence, with detailed steps and explanations.</p>
<p>Contextual Exploration.At this stage (Fig. 4-I ), the system provides experts with comprehensive and relevant information about their selected research focuses.It explains predictions with supplementary information on edge relationship granularity and integrates structured KG knowledge to support predictions.This structured information facilitates further mechanism exploration, potentially revealing the underlying mechanisms behind the predictions.</p>
<p>The process begins with training the GNN model on full-scale KG (Fig. 4-1 ), generating predictions along with interpretative paths.To assist experts in identifying research focuses matching their expertise and interest, while also filtering the most relevant predictions from vast results (DR3) (Fig. 4-2 ), the system incorporates a RAG-based retrieval framework with two modes: 1) Online LLM retrieval tailored to the biomedical domain.2) RAG retrieval exclusively using local knowledge to prevent external data interference.Domain experts can engage with the RAG system (Fig. 4-B ) by formulating queries based on their interests.For example, E1, an expert in breast cancer SL mechanisms, was interested in exploring SL in salivary gland cancer to identify potential mechanisms or patterns similar to breast cancer.To initiate this research, he queried RAG: "I would like to conduct research on salivary gland cancer, and I am an expert in breast cancer.Could you suggest some relevant predictions to facilitate the commencement of my study?" (Fig. 4-3 ) The system then returned recommendations for each research focus with the most relevant entities (Fig. 4-4 ), highlighted in the Embedding View (Fig. 4-C ).Domain experts can refine their selection by integrating insights from RAG recommendations and the Embedding View using lasso selections (Fig. 4-5 ).As exemplified in the case, RAG first performed reasoning and local retrieval to generate a list of recommended genes.Among these, RAG recommended the gene BRCA1 due to its association with both salivary gland cancer and breast cancer.Despite extensive focus on BRCA1, numerous unverified predictions persisted.Consequently, E1 implemented a lasso selection on the cluster containing BRCA1, subsequently filtering BRCA1 in the Prediction View (Fig. 4-D ).Noticing many top-ranked predictions relied primarily on the sl_gsg relationship, which he considered biologically less meaningful, E1 filtered out predictions whose interpretative paths consisted exclusively of sl_gsg connections.After that, he noticed that the prediction involving BRCA1 and USP1, which was originally Once a research focus is chosen, experts can explore specific prediction paths (Fig. 4-6 ) in the Hypothesis View (Fig. E ).This view further displays selected paths along with their adjacent graph structures, offering contextual insights into the research topic (Fig. 4-7 ), aiding experts in comprehending the interpretative KG path and exploring additional related information.For example, E1 queried for additional details regarding DNA_repair in the interpretative path (Fig. 4-8 ), obtaining a detailed explanation enhanced by external knowledge.</p>
<p>Then the LLM, with external information access, enriches interpretative paths by providing additional details in the ChatBot, allowing experts to bridge gaps in structured data by integrating common knowledge and cutting-edge insights not yet present in the KG.Experts can validate this information and, if valuable, integrate it into KG using text-to-KG methods within RAG, ensuring seamless KG expansion.Iterative querying and exploration allow experts to progressively refine their understanding of the predictions and the associated KG knowledge, laying the groundwork for subsequent hypothesis construction.</p>
<p>Hypothesis Construction.With prediction paths selected, domain experts require a solid basis to formulate hypotheses.Hence, the Hypothesis View leverages the LLM to generate an initial hypothesis regarding the underlying mechanisms.At this stage (Fig. 4-II ), the Hypothesis View presents entities retrieved via RAG that align with the given hypothesis (Fig. 4-8 , 9 ).Additionally, RAG paraphrases these descriptions, allowing domain experts to iteratively refine the reasoning until fully satisfied, ensuring an accurate understanding [36].As demonstrated in the example, E1 wished to explore further, so he shifted to the Hypothesis View.The LLM generated a potential hypothesis in the ChatBot that the target gene likely shares SL relationship with DNA_repair-related genes through interactions involving known SL genes.E1 found this consistent with his domain knowledge and proposed that if DNA_repair could connect to different SL genes, similar entities might also yield similar predictions (Fig. 4-8 ).Consequently, the hypothesis was refined to encompass analogous entities related to DNA_repair.Then, the RAG retrieved three closely related entities: Mismatch_repair, Double_strand_repair, and DNA_dealkylation_repair (Fig. 4-9 ).E1 then observed that these entities were also linked to many analogous predicted entities (Fig. 4-10 ), thus strengthening his belief in the hypothesis.</p>
<p>By leveraging these aligned entities, experts can concretize their hypothesis, examine related entities, and explore potential connection patterns predicted by the model (Fig. 4-E ).This iterative process (DR4) deepens their insights, allowing them to refine and adjust hypotheses based on emerging findings (Fig. 4-11 , 12 ).As the hypothesis evolves, the displayed entities update accordingly.</p>
<p>Throughout the iterative refinement, the LLM using external information provides heuristic guidance (Fig. 4-12 ) in the ChatBot, helping domain experts assess hypothesis validity, identify potential inconsistencies, and enhance logical coherence.Once satisfied with a constructed hypothesis (Fig. 4-15 ), experts can integrate it into a hypothesis chain within the Chain View (Fig. 4-F ) for further retrieval.</p>
<p>A hypothesis chain links multiple hypotheses, forming a structure similar to a triplet (Fig. 4-16 ).However, it extends beyond simple entity-relationship pairs by incorporating textual descriptions to facilitate communication and encoding of hypotheses.Experts can continually refine existing hypotheses or develop new ones with LLMgenerated suggestions (Fig. [4][5][6][7][8][9][10][11][12][13][14][15][16][17], With each submission of hypothesis analysis, aligned predictions are marked by ★ in the prediction view, helping experts refine the chain.By constructing complex chains, they move beyond merely summarizing patterns or drawing simple analogies from model predictions.Instead, experts integrate expertise and insights into a flexible and targeted Validation Selection process, enabling deeper exploration of intricate underlying mechanisms.</p>
<p>As shown in the case, E1 recalled that some RNA transcriptions are important for DNA_repair.To explore further, he queried LLM whether the proposed hypothesis held water (Fig. [4][5][6][7][8][9][10][11].The LLM confirmed a strong association between RNA and DNA_repair (Fig. 4-12 ).However, subsequent analysis using RAG revealed a particular relationship: Transcription-Coupled Nucleotide-Excision-Repair (TC-NER) (Fig. 4-13 ), a pathway where RNA polymerase triggers DNA_repair during transcription.Surprisingly, this relationship wasn't directly linked to DNA_repair or analogous entities in KG.This prompted E1 to ask the LLM for clarification.The LLM confirmed this was indeed a scientifically valid connection.Further exploration showed this relationship was only associated with a specific subset of genes, devoid of any discernible connections to other entities.E1 then incorporated the relationship into the KG through the text-to-KG integration within RAG and adjusted the hypothesis chain to (Fig. 4-14 ): [genes associated with salivary gland cancer] → [biological processes related to RNA construction] → [biological processes related to DNA_repair] → [genes relevant to this study] (Fig. 4-16 ), querying the LLM to ascertain the reasonableness of this chain (Fig. 4-17 ).After reasoning, the LLM recommended refining the relationship between RNA and DNA_repair, suggesting that the chain should be rephrased to indicate that RNA transcription is "related to" or "supports" DNA_repair-related entities, which is predicated on the observation that, in certain instances, the inactivation of specific genes actually stimulate RNA transcription, which might not result in an SL pair.E1 considered this suggestion reasonable and refined the hypothesis chain accordingly.</p>
<p>Validation Selection.At this stage (Fig. 4-III ), after domain experts have formulated coherent and well-reasoned hypotheses, these hypotheses are retrieved based on all the entities identified through RAG to ensure retrieval accuracy and comprehensiveness (Fig. [4][5][6][7][8][9][10][11][12][13][14][15][16][17][18] and are then compared against predictions and the KG (Fig. 4-19 , 20 ) within the Retrieval View (Fig. 4-G ).This process helps determine whether similar conclusions have been previously validated or if relevant paths exist within the predictions.</p>
<p>Particularly, the retrieval process is guided by the entities proposed by RAG in the hypothesis chain (Fig. 4-19 ), with the retrieved predictions grouped based on their alignment with the hypothesis (Fig. [4][5][6][7][8][9][10][11][12][13][14][15][16][17][18][19][20].Domain experts can then examine these results to identify candidates for further experimental validation.Additionally, they can leverage the UpSet Plot (Fig. 1-G2 ) to detect potential inconsistencies in the hypothesis during retrieval, gaining insights for further refinement and optimization.As reflected in the case, following the construction of the hypothesis chain, E1 conducted a targeted retrieval (Fig. 4-18 ) based on the refined hypothesis chain.Analysis of the results revealed that while many predictions included RNA transcription entities as intermediates and linked to final outcomes via DNA_repair, none of them fully aligned with the intermediate hypothesis criteria (Fig. 4-21 ).Drawing from prior observations that certain RNA processes in the KG were predominantly connected to genes, E1 expanded the hypothesis to incorporate gene-centric biological processes related to DNA_repair.Subsequent retrievals demonstrated strong alignment between predictions and the revised hypothesis chain (Fig. 4-22 ).Notably, the gene EP300-highly associated with salivary gland cancer-was connected to predicted entities CYP2C9 and RAD23B through RNA-transcriptionrelated entities transcription-coupled_nucleotide-excision_repair and DNA_repair-related genes GTF2H1, GTF2H4, and GTF2H5.This reinforced the hypothesis that DNA_repair mechanisms may exhibit SL correlations across disease contexts, with RNA transcription acting as a potential extension of these mechanisms.However, the current KG lacked robust representations of RNA transcriptions-DNA_repair relationships, underscoring the need for supplemental data integration.These findings revealed areas for improvement in the KG and provided a novel perspective for further research into mechanistic synergies.</p>
<p>EVALUATION</p>
<p>We conducted a case study and a user study to evaluate the effectiveness, workflow, and usability of HypoChainer.</p>
<p>Case Study: Drug Repurposing Exploration</p>
<p>E3 and E4, specialists in drug mechanisms and gene therapy, focus on repurposing antiepileptic drugs (e.g., those treating spasms) to address other diseases and evaluate novel therapies.Their goals are twofold: (1) identify new applications for existing drugs and (2) assess their potential in mitigating complex diseases.They followed the Co-discovery Learning Protocol [38], with one author guiding the session, E3 operating the system, and E4 discussing insights in real time.</p>
<p>To initiate this process, E3 uploaded a drug repurposing dataset (Fig. 1-1 ) and queried the RAG module: "I am researching antiepileptic drug repurposing.Can you suggest potentially related diseases?"(Fig. 2 ) The system performed a multi-faceted analysis of disease relationships, identifying 5 high-relevance candidates, including Huntington's disease, Episodic ataxia type 5, Parkinson's disease, Photosensitive tonic-clonic seizures, and Generalized tonic-clonic seizures.These results were prioritized in both textual Embedding View, with Episodic ataxia 5 flagged as a top recommendation 1-3 ).While E3 had prior expertise in Photosensitive tonic-clonic used the Embedding View's lasso tool to isolate the Episodic ataxia cluster (Fig. 1-4 opting explore RAG's novel suggestion.In the Prediction View, E3 observed frequent top-ranked associations with the CACNA1C gene (Fig. 1-5 ), E4 noted that this is a known regulator of voltage-gated calcium channels and a common target in epilepsyrelated drug mechanisms.To deepen E3's investigation, he selected the less familiar Episodic ataxia type 5 prediction (Fig. 1-6 ), leveraging the system to bridge knowledge gaps and validate hypotheses.1-7 ).E3 first validated this chain (Fig. 1-8 ) by confirming that retrieved entities aligned with the hypothesis and were supported by contextual KG evidence (Fig. 1-9 ).He observed that integrating existing KG edges revealed novel sub-paths (Fig. 1-10 ) and multiple connections between hypothesis-aligned entities and one-hop neighbors, reinforcing the chain's coherence.Cross-referencing the Prediction View, he noted consistency between the hypothesis and most interpretative paths (Fig. 1-11 ).E3 considered this as evidence that the hypothesis chain explains most repurposing predictions.</p>
<p>Critical Insight and Hypothesis Revision.However, E3 noted a misalignment between the hypothesis and high-score predictions for Huntington's disease (Fig. 1-12 ).By filtering and examining these predictions, he observed that the original hypothesis aligned only partially.Guided by the LLM's explanations, E4's further analysis of the remaining predictions revealed that some drugs were indicated for depression, while others were linked to neurodegenerative diseases.This finding led E3 to infer that the model's predictions regarding Huntington's disease primarily reflect the symptomatic alleviation effects rather than an influence on or delay of its underlying etiology.To reconcile this,   Hypothesis Challenge and Iterative Refinement.During hypothesis validation, E3 noted that the revised chain obscured the majority of the predictions.However, in the Hypothesis View, he identified a link between Huntington's disease and the Trinucleotide Repeat Expansion entity-a genetic mechanism associated with neurodegenerative disorders, as noted by E4 (Fig. 5-1 ).Intrigued by its absence in the Prediction View, E3 queried the LLM, which explained that Trinucleotide Repeat Expansion is a well-established genetic cause of Huntington's disease, yet it did not surface in any Huntington's predictions.Intrigued by this discrepancy, E3 revised the hypothesis chain to prioritize predictions involving Trinucleotide Repeat Expansion and submitted the updated hypothesis chain via the Analyse for LLM validation.The LLM provided critical feedback: while Trinucleotide Repeat Expansion refers to abnormal DNA sequence elongations that disrupt gene expression or protein function, its absence in predictions likely reflects the lack of direct therapeutics.However, the LLM emphasized indirect associations in literature, linking the entity to broader processes like DNA_repair and histone deacetylase (HDAC) regulation.</p>
<p>Insight-Driven Revision.Guided by this feedback, E3 refined the hypothesis to focus on therapeutic targets.A subsequent retrieval (Fig. 1-13 ) identified therapies modulating HDAC activity in diseases involving abnormal repeat expansions, such as Parkinson's disease [34] and Amyotrophic Lateral Sclerosis (ALS) (Fig. 1-16 ).This alignment validated the revised chain (Fig. 1 This HDAC-associated interpretative path aligned with literature suggesting HDAC's role in disease progression [22].Synthesizing these insights, E3 and E4 proposed the design of a novel cocktail therapy combining three symptom-alleviating drugs with HDAC inhibitors to potentially delay Huntington's progression.He further considered exploring HDAC-targeted gene therapies as a complementary avenue for further research.</p>
<p>Takeaway Message.In the case study, E3 and E4 iteratively revised initial hypotheses as new insights emerged, reflecting a dynamic reasoning process.Although the final hypotheses diverged from the original, they represented logical extensions informed by system-driven exploration.For example, in repurposing drugs for Huntington's disease, the expert initially focused on antiepileptic mechanisms for symptomatic relief.However, analysis of high-confidence predictions outside this scope revealed links to broader neurodegenerative pathways, prompting a shift toward a more integrative hypothesis.E3 reported maintaining control over hypothesis development, with HypoChainer offering timely support when exploration stalled-clarifying complex predictions, suggesting new directions, and highlighting supporting KG evidence.E4 praised the system's alignment with conventional workflows, flexible entity categorization, and context-aware knowledge integration, which streamlined hypothesis refinement.They also noted that the system helped transcend initial cognitive frames and uncover unanticipated, yet scientifically valuable associations.This iterative refinement process underscores the system's potential to support deeper and more structured hypothesis generation in complex discovery tasks.</p>
<p>User Study</p>
<p>We Participants completed a drug repurposing task targeting Hemophilia B. To ensure objective evaluation, all were screened to confirm no prior knowledge of the disease or its mechanisms.Five system-generated interpretative paths were selected based on partial alignment with DrugMechDB-curated mechanisms of actions (MOAs) for Eptacog Alfa and Nonacog Alfa.The Baseline system (Appendix Fig. 8) used an LLM-only setup, omitting the Hypothesis View, to isolate the contributions of RAG and the view's design while maintaining the overall workflow.Both drugs were excluded from training data to better simulate real-world discovery conditions.Participants received a 30-minute training session on task goals, system usage, and evaluation criteria, followed by 90 minutes to explore predictions, formulate hypotheses, and submit results.The process was screen-recorded.A task was deemed successful if participants retrieved ≤300 predictions and identified ≥3 of 5 reference predictions.A post-task questionnaire (Fig. 6) adapted from the System Usability Scale [8] assessed perceived system effectiveness, workflow, and usability.In the Baseline group, 2 PhD participants (33.3%) completed the task within the time limit, compared to 4 in the HypoChainer group (3 PhDs, 1 Master's; 66.7%).PhD participants generally outperformed Master's students, likely due to stronger research backgrounds and faster system adaptation.HypoChainer showed clear advantages in Effectiveness, with significantly higher scores for Ease of Identifying Research Directions (M = 5.50, SD = 1.38, p &lt; 0.05) and Logical Coherence of Hypothesis Chains (M = 5.67, SD = 0.52, p &lt; 0.05) compared to the Baseline (M = 4.17, SD = 1.47;M = 4.17, SD = 0.75).Both groups scored similarly on Clarity of Interpretative Paths (HypoChainer: M = 5.33, SD = 1.03;Baseline: M = 5.00, SD = 0.89).For Workflow, HypoChainer scored higher on Rationality (M = 5.17, SD = 1.33, p &lt; 0.05) and Flexibility (M = 5.00, SD = 0.89, p &lt; 0.05), supported by user feedback indicating fewer hallucinations.However, its integrated features-transitioning among LLM, RAG, and the Hypothesis View-were perceived as more complex (M = 6.00,SD = 0.89) than the Baseline (M = 4.83, SD = 0.75).In Usability, HypoChainer had a slightly lower score in Learnability (M = 4.50, SD = 0.55) than the Baseline (M = 5.00, SD = 0.63), suggesting a steeper learning curve.Nevertheless, it received significantly higher ratings for Informativeness (M = 5.83, SD = 0.75, p &lt; 0.05) and Understandability (M = 5.17, SD = 0.75, p &lt; 0.05), due to its clear reasoning structure and entitylevel explanations.Overall, HypoChainer provided more effective, transparent, and insightful support for hypothesis generation, despite a slightly higher learning threshold.</p>
<p>DISCUSSION AND LIMITATION</p>
<p>Lessons Learned.During the evaluation of RAGs, we identified critical trade-offs between accuracy and computational cost.Tests revealed that response accuracy depends on the scale of the local KG and the entity retrieval limit per query.Increasing the retrieval limit from the default to more entities markedly improved accuracy but incurred higher token consumption and prolonged query times.This highlights the necessity of balancing query performance and cost in large-scale RAG-based workflows.Additionally, while model predictions occasionally diverged from the constructed hypothesis chains, domain experts emphasized that such discrepancies do not diminish the validity of the chains themselves.They highlighted that rigorously derived hypotheses-even without full alignment with retrieval results-retain significant values, particularly in uncovering novel insights.Generalization and Scalability.The hypothesis-driven architecture has demonstrated broad applicability across diverse research domains, particularly in scientific discovery tasks involving KG-based node and link prediction.When integrated with RAG, the system offers a cost-effective and flexible alternative to domain-specific fine-tuning, enabling more efficient adaptation to new research areas.Given the generalizability of RAG and the system's modular KG-based design, most components are transferable across domains, requiring only the substitution of domain-specific KGs and predictive models.Domain experts have also identified promising applications in areas such as protein structure and function prediction via interaction networks, as well as novel materials discovery.However, the system's performance is largely dependent on the quality of the underlying KGs and the effectiveness of the associated predictive models.As advances in textbased KG extraction continue to improve accuracy and robustness, the system's cross-domain applicability is expected to expand further.Limitations.While RAG supports text-to-KG conversion, the process remains resource-intensive and prone to inaccuracies, especially in data-rich domains.To reduce risk, we restricted integration to small, verified updates using public KGs.However, the slow pace of KG updates compared to rapid scientific progress highlights the need for more accurate, automated extraction methods.Although RAG helps mitigate hallucinations by retrieving from traceable sources, such issues persist.Future improvements could include fact-verification modules-e.g., cross-referencing authoritative sources or applying confidence thresholds to flag uncertain outputs.Given the complexity of hypothesisdriven discovery, some interaction complexity is unavoidable, though we anticipate continued simplification as AI reliability advances.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>This study introduces HypoChainer, a collaborative framework that synergizes LLMs and KGs to advance hypothesis-driven scientific discovery.HypoChainer provides three main functionalities: Contextual Exploration, Hypothesis Construction and Validation Selection.A case study and expert interviews demonstrate HypoChainer's capability to synthesize context-aware knowledge efficiently, construct and refine hypothesis chains systematically, and facilitate informed validation selections.Future work includes enhancing text-KG integration through more robust methods and accelerating knowledge discovery via more workflow automation, while preserving critical human oversight to ensure scientific rigor and actionable insights.</p>
<p>Fig. 2 :
2
Fig. 2: Comparison of Traditional Practice A and HypoChainer Pipeline B : Both follow the I Contextual Exploration, II Hypothesis Construction, and III Validation Selection workflow.</p>
<p>Fig. 3 :
3
Fig. 3: UpSet Plot: Visualization of entity triplets alignment organized by intersections and inclusion relationships among hypotheses.</p>
<p>21 Fig. 4 :
214
Fig. 4: The pipeline comprises three main components: I Contextual Exploration, II Hypothesis Construction, and III Validation Selection.ranked 25 th , had moved up to the 2 nd position.Additionally, E1 noticed experimentally validated genes FANCA and PARP1 connected through two paths containing DNA_repair.Consequently, he identified USP1 as a valuable prediction for further validation, completing research focus selection in the Contextual Exploration phase.Once a research focus is chosen, experts can explore specific prediction paths (Fig.4-6) in the Hypothesis View (Fig.E).This view further displays selected paths along with their adjacent graph structures, offering contextual insights into the research topic (Fig.4-7), aiding experts in comprehending the interpretative KG path and exploring additional related information.For example, E1 queried for additional details regarding DNA_repair in the interpretative path (Fig.4-8), obtaining a detailed explanation enhanced by external knowledge.Then the LLM, with external information access, enriches interpretative paths by providing additional details in the ChatBot, allowing experts to bridge gaps in structured data by integrating common knowledge and cutting-edge insights not yet present in the KG.Experts can validate this information and, if valuable, integrate it into KG using text-to-KG methods within RAG, ensuring seamless KG expansion.Iterative querying and exploration allow experts to progressively refine their understanding of the predictions and the associated KG knowledge, laying the groundwork for subsequent hypothesis construction.Hypothesis Construction.With prediction paths selected, domain experts require a solid basis to formulate hypotheses.Hence, the Hypothesis View leverages the LLM to generate an initial hypothesis regarding the underlying mechanisms.At this stage (Fig.4-II ), the Hypothesis View presents entities retrieved via RAG that align with the given hypothesis (Fig.4-8 , 9).Additionally, RAG paraphrases these descriptions, allowing domain experts to iteratively refine the reasoning until fully satisfied, ensuring an accurate understanding[36].As demonstrated in the example, E1 wished to explore further, so he shifted to the Hypothesis View.The LLM generated a potential hypothesis in the ChatBot that the target gene likely shares SL relationship with DNA_repair-related genes through interactions involving known SL genes.E1 found this consistent with his domain knowledge and proposed that if DNA_repair could connect to different SL genes, similar entities might also yield similar predictions (Fig.4-8).Consequently, the hypothesis was refined to encompass analogous entities related to DNA_repair.Then, the RAG retrieved three closely related entities: Mismatch_repair, Double_strand_repair, and DNA_dealkylation_repair (Fig.4-9).E1 then observed that these entities were also linked to many analogous predicted entities (Fig.4-10 ), thus strengthening his belief in the hypothesis.By leveraging these aligned entities, experts can concretize their hypothesis, examine related entities, and explore potential connection patterns predicted by the model (Fig.4-E).This iterative process (DR4) deepens their insights, allowing them to refine and adjust hypotheses based on emerging findings (Fig.4-11 , 12 ).As the hypothesis</p>
<p>Hypothesis Refinement Workflow.In the Hypothesis View, the generated an initial mechanistic hypothesis via the LLM: [Modulating agent alters ion channel function] → [Impacts] → [Gene regulatory pathways (affected by calcium channels)] → [Drives] → [Neuronal network dynamics] → [Manifests as] → [Episodic neural dysfunction] (Fig.</p>
<p>E3 refined the hypothesis chain to: [Drugs treating motor dysfunction, depression, or neurodegeneration] → [related to] → [Interacting genes or pathways] → [Participated in] → [Processes related to motor dysfunction, depression, or neurodegeneration] → [Led to] → [Diseases associated with Huntington's disease].</p>
<p>1
1</p>
<p>Fig. 5 : 1
51
Fig. 5: 1 E3 noticed a link to Huntington's disease from Trinucleotide Repeat Expansion, a 1-hop entity of neurodegenerative disease.</p>
<p>-14 , 15 ).Critical Discovery and Therapeutic Proposal.Re-examining Huntington's predictions, E3 uncovered a previously overlooked interpretative path: [Entinostat → [decreases activity of] → [HDAC1 gene] → [interacts with] → [Histone H4] → [gene associated with condition] → [Huntington's disease].</p>
<p>Fig. 6 :
6
Fig.6: The questionnaire results of the two systems in terms of system effectiveness, workflow and usability ( * : p &lt; 0.05).</p>
<p>recruited 12 graduate students (Mean Age = 26.33,SD = 1.93; 6 males, 6 females) from bioinformatics or biomedical engineering backgrounds, including 6 PhD and 6 Master's students.Participants were randomly assigned to either the Baseline or HypoChainer group, balanced degree level (3 PhD and 3 Master's per group).</p>
<p>The sequence of entities and edges connecting a head entity (e.g., a gene) to a predicted SL partner via biologically meaningful relationships.
ACKNOWLEDGMENTSWe gratefully acknowledge Dr. Jia Liu and Dr. Yifeng Yang from the Institute of Immunochemistry at ShanghaiTech University for their valuable collaboration, as well as the anonymous reviewers for their insightful feedback.This research was supported by the National Natural Science Foundation of China (No. 62372298), the "AI Technologies for Accelerating Biopharmaceutical R&amp;D -School of Information Science and Technology" (No. 2024X0203-902-01), the Shanghai Engineering Research Center of Intelligent Vision and Imaging, the Shanghai Frontiers Science Center of Human-centered Artificial Intelligence (ShangHAI), and the MoE Key Laboratory of Intelligent Perception and Human-Machine Collaboration (KLIP-HuMaCo).Part of the experimental work was conducted with support from the Core Facility Platform of Computer Science and Communication, SIST, ShanghaiTech University.
Leveraging large language models to enhance machine learning interpretability and predictive performance: A case study on emergency department returns for mental health patients. A Ahmed, M Saleem, M Alzeen, ttps://doi.org/10.48550/arXiv.2502.000252025</p>
<p>From large language models to databases and back: A discussion on research and education. S Amer-Yahia, A Bonifati, L Chen, G Li, X Shim, Kyuseok, 10.1145/3631504.3631518Nov. 2023SIGMOD Rec52</p>
<p>Patternbased visualization of knowledge graphs. L Asprino, C Colonna, M Mongiovì, M Porena, V Presutti, 10.48550/arXiv.2106.128572021</p>
<p>ResearchAgent: Iterative research idea generation over scientific literature with large language models. J Baek, S K Jauhar, S Cucerzan, S J Hwang, 10.48550/arXiv.2404.077382025</p>
<p>Voronoi treemaps. M Balzer, O Deussen, 10.1109/INFVIS.2005.1532128IEEE Symposium on Information Visualization. 2005. 2005. 200536</p>
<p>Analytical reduction of combinatorial complexity arising from multiple protein modification sites. M R Birtwistle, 10.1098/rsif.2014.1215Journal of The Royal Society Interface. 1210320141215. 2015</p>
<p>Jurassic mark: Inattentional blindness for a datasaurus reveals that visualizations are explored, not seen. T Boger, S B Most, S L Franconeri, 10.1109/VIS49827.2021.96232732021 IEEE Visualization Conference (VIS). 2021</p>
<p>SUS: a retrospective. J Brooke, Journal of Usability Studies. 8901 2013</p>
<p>A survey on evaluation of large language models. Y Chang, X Wang, J Wang, Y Wu, L Yang, K Zhu, 10.1145/3641289ACM transactions on intelligent systems and technology. 1532024</p>
<p>R-Map: A map metaphor for visualizing information reposting process in social media. S Chen, S Li, S Chen, X Yuan, 10.1109/TVCG.2019.2934263IEEE Transactions on Visualization and Computer Graphics. 2612020</p>
<p>Complex logical reasoning over knowledge graphs using large language models. N Choudhary, C K Reddy, 10.48550/arXiv.2305.011572024</p>
<p>Thematic analysis. The journal of positive psychology. V Clarke, V Braun, 10.1080/17439760.2016.1262613201712</p>
<p>BioLinker: Bottom-up exploration of protein interaction networks. T Dang, P Murray, A Forbes, 10.1109/PACIFICVIS.2017.80316032017 IEEE Pacific Visualization Symposium (PacificVis). IEEE201723</p>
<p>Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction. S Deng, S Wang, H Rangwala, L Wang, Y Ning, 10.1145/3340531.3411975Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management, CIKM '20, 10 pages. the 29th ACM International Conference on Information &amp; Knowledge Management, CIKM '20, 10 pages2020</p>
<p>From Local to Global: A graph RAG approach to query-focused summarization. D Edge, H Trinh, N Cheng, 10.48550/arxiv.2404.161302025</p>
<p>SciAgents: Automating scientific discovery through bioinspired multi-agent intelligent graph reasoning. A Ghafarollahi, M J Buehler, 10.1002/adma.202413523Advanced Materials. 23</p>
<p>Towards an AI co-scientist. J Gottweis, W.-H Weng, A Daryin, 10.48550/arXiv.2502.188642025</p>
<p>LineUp: Visual analysis of multi-attribute rankings. S Gratzl, A Lex, N Gehlenborg, H Pfister, M Streit, 10.1109/TVCG.2013.173IEEE Transactions on Visualization and Computer Graphics. 19122013</p>
<p>LightRAG: Simple and fast retrieval-augmented generation. Z Guo, L Xia, Y Yu, T Ao, C Huang, 10.48550/arXiv.2410.057792024</p>
<p>Multi-omics approaches to disease. Y Hasin, M Seldin, A Lusis, 10.1186/s13059-017-1215-1Genome biology. 182017</p>
<p>KLMo: Knowledge graph enhanced pretrained language model with fine-grained relationships. L He, S Zheng, T Yang, F Zhang, 10.18653/v1/2021.findings-emnlp.384Findings of the Association for Computational Linguistics: EMNLP 2021. Association for Computational LinguisticsNov. 2021</p>
<p>The effects of selective inhibition of histone deacetylase 1 and 3 in Huntington's disease mice. K Hecklau, S Mueller, S P Koch, 10.3389/fnmol.2021.616886Frontiers in molecular neuroscience. 142021</p>
<p>Literature based discovery: models, methods, and trends. S Henry, B T Mcinnes, 10.1016/j.jbi.2017.08.011Journal of biomedical informatics. 742017</p>
<p>Nova: An iterative planning and search approach to enhance novelty and diversity of LLM generated ideas. X Hu, H Fu, J Wang, Y Wang, Z Li, R Xu, Y Lu, Y Jin, L Pan, Z Lan, 10.48550/arXiv.2410.142552024</p>
<p>From large language models to large multimodal models: A literature review. D Huang, C Yan, Q Li, X Peng, 10.3390/app14125068Applied Sciences. 14122024</p>
<p>Leveraging passage retrieval with generative models for open domain question answering. G Izacard, E Grave, 10.18653/v1/2021.eacl-main.74Proceedings of the 16th Conference of the European Chapter. the 16th Conference of the European ChapterAssociation for Computational LinguisticsApr. 2021</p>
<p>SLInterpreter: An exploratory and iterative Human-AI collaborative system for GNN-based synthetic lethal prediction. H Jiang, S Shi, S Zhang, J Zheng, Q Li, 10.1109/TVCG.2024.3456325IEEE Transactions on Visualization and Computer Graphics. 31162025</p>
<p>How can we know what language models know? Transactions of the. Z Jiang, F F Xu, J Araki, G Neubig, 10.1162/tacl_a_003242020Association for Computational Linguistics8</p>
<p>GNNLens: A visual analytics approach for prediction error diagnosis of graph neural networks. Z Jin, Y Wang, Q Wang, Y Ming, T Ma, H Qu, 10.1109/TVCG.2022.3148107IEEE Transactions on Visualization and Computer Graphics. 2962023</p>
<p>A survey of reinforcement learning from human feedback. T Kaufmann, P Weng, V Bengs, E Hüllermeier, 10.48550/arXiv.2312.149252024</p>
<p>Hypothesis generation in climate research with interactive visual data exploration. J Kehrer, F Ladstädter, P Muigg, H Doleisch, A Steiner, H Hauser, 10.1109/TVCG.2008.139IEEE Transactions on Visualization and Computer Graphics. 1462008</p>
<p>Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network. M Krenn, L Buffoni, B Coutinho, 10.1038/s42256-023-00735-0Nature Machine Intelligence. 5112023</p>
<p>Can large language models unlock novel scientific research ideas?. S Kumar, T Ghosal, V Goyal, A Ekbal, 10.48550/arXiv.2409.061852024</p>
<p>Understanding the role of histone deacetylase and their inhibitors in neurodegenerative disorders: Current targets and future perspective. V Kumar, 10.2174/1570159X19666210609160017Current Neuropharmacology. 2012022</p>
<p>Upset: Visualization of intersecting sets. A Lex, N Gehlenborg, H Strobelt, R Vuillemot, H Pfister, 10.1109/TVCG.2014.2346248IEEE Transactions on Visualization and Computer Graphics. 20122014</p>
<p>Linkq: An LLM-assisted visual interface for knowledge graph question-answering. H Li, G Appleby, A Suh, 10.1109/VIS55277.2024.000312024 IEEE Visualization and Visual Analytics (VIS). 2024</p>
<p>Boosting LLMs in professional domains via knowledge augmented generation. L Liang, M Sun, Z Gui, 10.48550/arXiv.2409.137312024</p>
<p>An empirical study of computer system learning: Comparison of co-discovery and self-discovery methods. K H Lim, L M Ward, I Benbasat, 10.1287/isre.8.3.254Information Systems Research. 831997</p>
<p>KGNN: Knowledge graph neural network for drug-drug interaction prediction. X Lin, Z Quan, Z.-J Wang, T Ma, X Zeng, 10.24963/ijcai.2020/380Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. C Bessiere, the Twenty-Ninth International Joint Conference on Artificial Intelligence202020Main track</p>
<p>The AI scientist: Towards fully automated open-ended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, 10.48550/arXiv.2408.062922024</p>
<p>KGML-xDTD: a knowledge graph-based machine learning framework for drug treatment prediction and mechanism description. C Ma, Z Zhou, H Liu, D Koslicki, 10.1093/gigascience/giad057GigaScience. 125</p>
<p>LLM and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery. P Ma, T.-H Wang, M Guo, Z Sun, J B Tenenbaum, D Rus, C Gan, W Matusik, 10.48550/arXiv.2405.097832024</p>
<p>UMAP: Uniform manifold approximation and projection for dimension reduction. L Mcinnes, J Healy, 10.21105/joss.008612018</p>
<p>A comprehensive overview of large language models. H Naveed, A U Khan, S Qiu, M Saqib, S Anwar, M Usman, N Akhtar, N Barnes, A Mian, 10.48550/arXiv.2307.064352024</p>
<p>Acceleron: A tool to accelerate research ideation. H Nigam, M Patwardhan, L Vig, G Shroff, 10.48550/arXiv.2403.043822024</p>
<p>Pathway tools visualization of organism-scale metabolic networks. S Paley, R Billington, J Herson, M Krummenacker, P D Karp, 10.3390/metabo11020064Metabolites. 1122021</p>
<p>Unifying large language models and knowledge graphs: A roadmap. S Pan, L Luo, Y Wang, C Chen, J Wang, X Wu, 10.48550/arXiv.2306.08302IEEE Transactions on Knowledge and Data Engineering. 2024</p>
<p>Knowledge graphs: Opportunities and challenges. C Peng, F Xia, M Naseriparsa, F Osborne, 10.1007/s10462-023-10465-9Artificial Intelligence Review. 5611November 2023</p>
<p>Semantics and complexity of sparql. J Pérez, M Arenas, C Gutierrez, 10.1145/1567274.1567278ACM Trans. Database Syst. 34345Sept. 2009</p>
<p>Hallucinations in LLMs: Understanding and addressing challenges. G Perković, A Drobnjak, I Botički, 10.1109/MIPRO60963.2024.105692382024 47th MIPRO ICT and Electronics Convention (MIPRO). 202423</p>
<p>The logic of scientific discovery. K Popper, 10.4324/97802039946272005Routledge</p>
<p>IdeaSynth: Iterative research idea development through evolving and composing idea facets with literaturegrounded feedback. K Pu, K J K Feng, T Grossman, T Hope, B D Mishra, M Latzke, J Bragg, J C Chang, P Siangliulue, 10.48550/arXiv.2410.040252024</p>
<p>Large language models are zero shot hypothesis proposers. B Qi, K Zhang, H Li, K Tian, S Zeng, Z.-R Chen, B Zhou, 10.48550/arXiv.2311.059652023</p>
<p>Reinforcement learning model, algorithms and its application. W Qiang, Z Zhongli, 10.1109/MEC.2011.60256692011 International Conference on Mechatronic Science. 2011Electric Engineering and Computer (MEC)</p>
<p>Towards faithful and robust LLM specialists for evidence-based question-answering. T Schimanski, J Ni, M Kraus, E Ash, M Leippold, 10.18653/v1/2024.acl-long.105Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsAug. 202414</p>
<p>From data to dialogue: Leveraging the structure of knowledge graphs for conversational exploratory search. P Schneider, N Rehtanz, K Jokinen, F Matthes, 10.48550/arXiv.2310.051502023</p>
<p>MedChemLens: An interactive visual tool to support direction selection in interdisciplinary experimental research of medicinal chemistry. C Shi, F Nie, Y Hu, Y Xu, L Chen, X Ma, Q Luo, 10.1109/TVCG.2022.3209434IEEE Transactions on Visualization and Computer Graphics. 29142022</p>
<p>Can LLMs generate novel research ideas? a large-scale human study with 100+ NLP researchers. C Si, D Yang, T Hashimoto, 10.48550/arXiv.2409.041092024</p>
<p>Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation. H Su, R Chen, S Tang, X Zheng, J Li, Z Yin, W Ouyang, N Dong, 10.1109/TCDS.2025.3530945IEEE Transactions on Cognitive and Developmental Systems. 2024</p>
<p>The Fourth Paradigm: Data-intensive Scientific Discovery. K M Tolle, D S W Tansley, A J G Hey, 10.1109/JPROC.2011.21551302009</p>
<p>Biolink model: A universal schema for knowledge graphs in clinical, biomedical, and translational science. D R Unni, S A T Moxon, M Bada, 10.1111/cts.13302Clinical and Translational Science. 1582022</p>
<p>A visual interface for exploring hypotheses about neural circuits. S K Vohra, P Harth, Y Isoe, A Bahl, H Fotowat, F Engert, H.-C Hege, D Baum, 10.1109/TVCG.2023.3243668IEEE Transactions on Visualization and Computer Graphics. 3072024</p>
<p>Wikidata: a free collaborative knowledgebase. D Vrandečić, M Krötzsch, 10.1145/2629489Communications of the ACM. 57102014</p>
<p>LLM assists hypothesis generation and testing for deliberative questions. 13 pages. F Wang, X Zhou, W Hu, Z Luo, W Luo, X Bai, 10.1007/978-981-97-9434-8_332024Springer-Verlag</p>
<p>Extending the nested model for user-centric XAI: A design study on GNN-based drug repurposing. Q Wang, K Huang, P Chandak, M Zitnik, N Gehlenborg, 10.1109/TVCG.2022.3209435IEEE Transactions on Visualization and Computer Graphics. 2912023</p>
<p>From in Silico to in Vitro: A comprehensive guide to validating bioinformatics findings. T Wang, S Chen, Y Wang, 10.48550/arXiv.2410.0707623</p>
<p>KEPLER: A unified model for knowledge embedding and pre-trained language representation. X Wang, T Gao, Z Zhu, Z Zhang, Z Liu, J Li, J Tang, 10.1162/tacl_a_00360Transactions of the Association for Computational Linguistics. 92021</p>
<p>KNOWNET: Guided health information seeking from LLMs via knowledge graph integration. Y Yan, Y Hou, Y Xiao, R Zhang, Q Wang, 10.1109/TVCG.2024.3456364IEEE Transactions on Visualization and Computer Graphics. 2024</p>
<p>Unleashing the potential of large language models for predictive tabular tasks in data science. Y Yang, Y Wang, Y Li, S Sen, L Li, Q Liu, 10.18653/v1/2024.findings-emnlp.2242024</p>
<p>Knowledge mapping of graph neural networks for drug discovery: a bibliometric and visualized analysis. R Yao, Z Shen, X Xu, G Ling, R Xiang, T Song, F Zhai, Y Zhai, 10.3389/fphar.2024.1393415Frontiers in Pharmacology. 152024</p>
<p>Dolphin: Closed-loop open-ended auto-research through thinking, practice, and feedback. J Yuan, X Yan, B Shi, T Chen, W Ouyang, B Zhang, 10.48550/arXiv.2501.039162025</p>
<p>KR4SL: knowledge graph reasoning for explainable prediction of synthetic lethality. K Zhang, M Wu, Y Liu, Y Feng, J Zheng, 10.1093/bioinformatics/btad261Bioinformatics. 395</p>
<p>Multi-domain knowledge graph collaborative pre-training and prompt tuning for diverse downstream tasks. Y Zhang, B Hu, Z Chen, L Guo, Z Liu, Z Zhang, L Liang, H Chen, W Zhang, 10.48550/arXiv.2405.130852024</p>
<p>A survey of large language models. W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, Y Du, C Yang, Y Chen, Z Chen, 10.48550/arXiv.2303.182232025</p>
<p>Disciplink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration. C Zheng, Y Zhang, Z Huang, C Shi, M Xu, X Ma, 10.1145/3654777.3676366Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology. the 37th Annual ACM Symposium on User Interface Software and Technology2024</p>
<p>From automation to autonomy: A survey on large language models in scientific discovery. T Zheng, Z Deng, H T Tsang, W Wang, J Bai, Z Wang, Y Song, 2025</p>
<p>Hypothesis generation with large language models. Y Zhou, H Liu, T Srivastava, H Mei, C Tan, 10.18653/v1/2024.nlp4science-1.10202423</p>
<p>From hypothesis to publication: A comprehensive survey of AI-driven research support systems. Z Zhou, X Feng, L Huang, 10.48550/arXiv.2310.051502025</p>            </div>
        </div>

    </div>
</body>
</html>