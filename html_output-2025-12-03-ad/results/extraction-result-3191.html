<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3191 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3191</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3191</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-bddb9d818b73de0a06197a6966673c7eb63c9146</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/bddb9d818b73de0a06197a6966673c7eb63c9146" target="_blank">Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes a novel memory mechanism called TiM (Think-in-Memory) that enables LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream and introduces Locality-Sensitive Hashing into TiM to achieve efficient retrieval for the long-term conversations.</p>
                <p><strong>Paper Abstract:</strong> Memory-augmented Large Language Models (LLMs) have demonstrated remarkable performance in long-term human-machine interactions, which basically relies on iterative recalling and reasoning of history to generate high-quality responses. However, such repeated recall-reason steps easily produce biased thoughts, \textit{i.e.}, inconsistent reasoning results when recalling the same history for different questions. On the contrary, humans can keep thoughts in the memory and recall them without repeated reasoning. Motivated by this human capability, we propose a novel memory mechanism called TiM (Think-in-Memory) that enables LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream. The TiM framework consists of two crucial stages: (1) before generating a response, a LLM agent recalls relevant thoughts from memory, and (2) after generating a response, the LLM agent post-thinks and incorporates both historical and new thoughts to update the memory. Thus, TiM can eliminate the issue of repeated reasoning by saving the post-thinking thoughts as the history. Besides, we formulate the basic principles to organize the thoughts in memory based on the well-established operations, (\textit{i.e.}, insert, forget, and merge operations), allowing for dynamic updates and evolution of the thoughts. Furthermore, we introduce Locality-Sensitive Hashing into TiM to achieve efficient retrieval for the long-term conversations. We conduct qualitative and quantitative experiments on real-world and simulated dialogues covering a wide range of topics, demonstrating that equipping existing LLMs with TiM significantly enhances their performance in generating responses for long-term interactions.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3191.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3191.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TiM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Think-in-Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory mechanism introduced in this paper that stores LLM-generated 'thoughts' (inductive relation triples) in an LSH-indexed external hash table and supports recall-before-generation and post-thinking updates (insert/forget/merge).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>TiM-augmented LLM (TiM)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A memory-augmented agent paradigm (LLM-agnostic) where a pre-trained LLM recalls stored thoughts from an external LSH-indexed memory before generating a response and then performs a post-thinking step to generate and insert new thoughts; memory supports insert/forget/merge operations and LSH + within-bucket similarity retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external memory (thoughts-based, LSH-indexed)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Memory stores 'inductive thoughts' (relation triples / short reasoning outputs) as values keyed by LSH hash indices computed from embeddings; retrieval is two-stage (LSH to find bucket, then similarity-ranking within bucket to return top-k thoughts); after response generation a post-thinking step produces new thoughts which are inserted, and periodic forgetting/merging prompts remove contradictions and merge similar thoughts; LSH implemented via random projection argmax scheme.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term multi-turn dialogue (GVD, KdConv) and real-world medical conversations (RMD)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-horizon dialogue tasks requiring recall of earlier conversational context or facts across many turns/days (simulated virtual users, multi-domain knowledge-driven chat, and medical diagnosis dialogues).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / long-horizon conversational memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Multiple reported improvements across datasets (examples): GVD English (ChatGLM+TiM) Retrieval Accuracy 0.820, Response Correctness 0.450, Contextual Coherence 0.735; KdConv (ChatGLM, Film) Retrieval Accuracy 0.920, Response Correctness 0.827, Contextual Coherence 0.943; RMD (ChatGLM) Retrieval Accuracy 0.900, Response Correctness 0.843, Contextual Coherence 0.943.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Baselines (examples): GVD English (ChatGLM+SiliconFriend) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; KdConv (ChatGLM, Film) no-memory baseline Response Correctness 0.657, Contextual Coherence 0.923; RMD (ChatGLM) no-memory Response Correctness 0.806, Contextual Coherence 0.893.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Storing and recalling LLM-generated 'thoughts' improves retrieval accuracy, response correctness and contextual coherence across simulated and real-world long-term dialogue datasets compared to raw-text memory baselines; TiM also reduces retrieval time (~0.6287 ms -> 0.5305 ms reported) due to LSH-based indexing.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Obtaining high-quality inductive thoughts requires reliable extraction or LLM prompts; LSH is approximate so bucketing may miss some relevant items; quality of stored thoughts depends on LLM post-thinking and can introduce redundant or contradictory facts (necessitating forget/merge); experiments rely on human evaluation for scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3191.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3191.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM + TiM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGLM augmented with Think-in-Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source bilingual LLM (ChatGLM) used in experiments combined with TiM external memory to improve long-term conversational performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGLM</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An open-source bilingual transformer-based LLM (6.2B parameters) optimized for dialogue; in this paper it is used as the LLM agent combined with TiM memory and optionally LoRA fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external thoughts memory (TiM)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>ChatGLM retrieves top-k thoughts from the TiM LSH-hash table (LSH bucket then within-bucket similarity) prior to response generation, uses them to produce a reply, and then executes a post-thinking step to generate and insert/update thoughts (insert/forget/merge) in memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GVD (English & Chinese), KdConv (film/music/travel), RMD (medical)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term conversational benchmarks requiring recall of past user information and multi-turn context to produce correct and coherent responses (simulated multi-day dialogues, multi-domain knowledge-driven conversations, and medical patient-doctor dialogues).</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / long-horizon conversational memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Examples from Table 2: GVD English: Retrieval Accuracy 0.820, Response Correctness 0.450, Contextual Coherence 0.735; GVD Chinese: Retrieval Accuracy 0.850, Response Correctness 0.605, Contextual Coherence 0.665; KdConv Film: Retrieval Accuracy 0.920, Response Correctness 0.827, Contextual Coherence 0.943; RMD: Retrieval Accuracy 0.900, Response Correctness 0.843, Contextual Coherence 0.943.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Examples: GVD English (SiliconFriend baseline) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; KdConv Film no-memory Response Correctness 0.657, Contextual Coherence 0.923; RMD no-memory Response Correctness 0.806, Contextual Coherence 0.893.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Augmenting ChatGLM with TiM raises retrieval accuracy and substantially improves response correctness and contextual coherence across all tested datasets, with larger gains on some languages/topics (e.g., Chinese GVD showed a notable correctness increase).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Performance gains depend on ChatGLM's baseline capabilities; quality of stored thoughts and post-thinking correctness influence downstream responses; evaluation uses human raters which can introduce subjectivity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3191.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3191.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baichuan2 + TiM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Baichuan2 augmented with Think-in-Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source 13B multilingual LLM (Baichuan2) used with TiM memory in experiments, showing large gains in retrieval and response metrics across KdConv and RMD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Baichuan2</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A 13B-parameter multilingual LLM trained on large-scale data, used here as the LLM agent combined with TiM memory and LoRA fine-tuning for long-term conversational tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external thoughts memory (TiM)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Baichuan2 queries the TiM LSH-indexed thoughts memory to recall top-k thoughts (LSH bucket + similarity within bucket), conditions its response on recalled thoughts, and then uses a post-thinking step to generate and insert/update thoughts in memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>KdConv (film/music/travel), RMD (medical)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multi-turn knowledge-driven dialogue (KdConv) and real-world medical dialogues requiring recall of prior conversational facts to produce correct responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / long-horizon conversational memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Examples from Table 2: KdConv Film: Retrieval Accuracy 0.913, Response Correctness 0.743, Contextual Coherence 0.870; KdConv Music: Retrieval Accuracy 0.900, Response Correctness 0.710, Contextual Coherence 0.780; RMD: Retrieval Accuracy 0.873, Response Correctness 0.538, Contextual Coherence 0.663.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Baselines (no memory shown in table as 'X'): KdConv Film no-memory Response Correctness 0.360, Contextual Coherence 0.413; KdConv Music no-memory Response Correctness 0.253, Contextual Coherence 0.283; RMD no-memory Response Correctness 0.506, Contextual Coherence 0.538.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>TiM substantially improves Baichuan2's retrieval accuracy, response correctness, and contextual coherence on KdConv and RMD; large relative gains observed compared to no-memory baselines, particularly on KdConv topics where baseline correctness was low.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Baseline model weaknesses limit absolute performance even with TiM; improvements vary by domain/topic; as with other agents, memory quality and retrieval precision (LSH approximation) affect outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3191.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3191.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SiliconFriend</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SiliconFriend (baseline memory mechanism referenced as SiliconFriend / MemoryBank in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A classical memory mechanism used as a baseline in experiments (referenced in the paper; stores raw text Q-R pairs as memory and supports reading operations).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SiliconFriend (memory baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A prior external memory mechanism that stores raw question-response (Q-R) text into a memory cache and retrieves relevant raw text to augment an LLM; used as a baseline for GVD comparisons in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented external memory (raw Q-R text)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Stores raw dialogue turns (Q-R pairs) and retrieves relevant history by pairwise similarity search across stored entries (no thoughts abstraction); retrieval is comparatively more expensive because it computes similarities across many raw entries.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>GVD (English & Chinese) comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term virtual-user dialogue dataset evaluating memory recall and correctness across languages.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / long-horizon conversational memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>GVD English (ChatGLM + SiliconFriend) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; GVD Chinese Retrieval Accuracy 0.840, Response Correctness 0.418, Contextual Coherence 0.428.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>SiliconFriend (raw text memory) improves over no-memory in some metrics but is outperformed by TiM, especially in contextual coherence and response correctness in several settings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Requires repeated reasoning over raw history (can lead to inconsistent reasoning paths), pairwise similarity retrieval across the whole memory is time-consuming for long histories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3191.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3191.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior long-term memory mechanism (referenced) that stores Q-R pairs and introduces forgetting inspired by human memory; mentioned in related work as an alternative external memory approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Memorybank: Enhancing large language models with long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoryBank (referenced mechanism)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An external memory mechanism that stores question-response pairs and includes forgetting operations inspired by human forgetting curves; referenced as prior work in long-term memory for LLMs (not used in this paper's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external memory storing Q-R pairs</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Stores raw dialogue entries and applies strategies for retention/forgetting; retrieval typically via similarity search across stored Q-R pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term conversation benchmarks (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Mechanisms for maintaining and retrieving long-term conversational memory.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / long-horizon conversational memory</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as prior work that supports insert and forget operations but not merge, and stores Q-R pairs rather than abstracted thoughts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Because it stores raw text, models still need to repeatedly reason over history; pairwise retrieval over full memory can be costly.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Memorybank: Enhancing large language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>Augmenting language models with long-term memory. <em>(Rating: 2)</em></li>
                <li>Improving language models by retrieving from trillions of tokens. <em>(Rating: 1)</em></li>
                <li>Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3191",
    "paper_id": "paper-bddb9d818b73de0a06197a6966673c7eb63c9146",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "TiM",
            "name_full": "Think-in-Memory",
            "brief_description": "A memory mechanism introduced in this paper that stores LLM-generated 'thoughts' (inductive relation triples) in an LSH-indexed external hash table and supports recall-before-generation and post-thinking updates (insert/forget/merge).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "TiM-augmented LLM (TiM)",
            "agent_description": "A memory-augmented agent paradigm (LLM-agnostic) where a pre-trained LLM recalls stored thoughts from an external LSH-indexed memory before generating a response and then performs a post-thinking step to generate and insert new thoughts; memory supports insert/forget/merge operations and LSH + within-bucket similarity retrieval.",
            "memory_used": true,
            "memory_type": "retrieval-augmented external memory (thoughts-based, LSH-indexed)",
            "memory_mechanism_description": "Memory stores 'inductive thoughts' (relation triples / short reasoning outputs) as values keyed by LSH hash indices computed from embeddings; retrieval is two-stage (LSH to find bucket, then similarity-ranking within bucket to return top-k thoughts); after response generation a post-thinking step produces new thoughts which are inserted, and periodic forgetting/merging prompts remove contradictions and merge similar thoughts; LSH implemented via random projection argmax scheme.",
            "task_name": "Long-term multi-turn dialogue (GVD, KdConv) and real-world medical conversations (RMD)",
            "task_description": "Long-horizon dialogue tasks requiring recall of earlier conversational context or facts across many turns/days (simulated virtual users, multi-domain knowledge-driven chat, and medical diagnosis dialogues).",
            "task_type": "dialogue / long-horizon conversational memory",
            "performance_with_memory": "Multiple reported improvements across datasets (examples): GVD English (ChatGLM+TiM) Retrieval Accuracy 0.820, Response Correctness 0.450, Contextual Coherence 0.735; KdConv (ChatGLM, Film) Retrieval Accuracy 0.920, Response Correctness 0.827, Contextual Coherence 0.943; RMD (ChatGLM) Retrieval Accuracy 0.900, Response Correctness 0.843, Contextual Coherence 0.943.",
            "performance_without_memory": "Baselines (examples): GVD English (ChatGLM+SiliconFriend) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; KdConv (ChatGLM, Film) no-memory baseline Response Correctness 0.657, Contextual Coherence 0.923; RMD (ChatGLM) no-memory Response Correctness 0.806, Contextual Coherence 0.893.",
            "has_performance_comparison": true,
            "key_findings": "Storing and recalling LLM-generated 'thoughts' improves retrieval accuracy, response correctness and contextual coherence across simulated and real-world long-term dialogue datasets compared to raw-text memory baselines; TiM also reduces retrieval time (~0.6287 ms -&gt; 0.5305 ms reported) due to LSH-based indexing.",
            "limitations_or_challenges": "Obtaining high-quality inductive thoughts requires reliable extraction or LLM prompts; LSH is approximate so bucketing may miss some relevant items; quality of stored thoughts depends on LLM post-thinking and can introduce redundant or contradictory facts (necessitating forget/merge); experiments rely on human evaluation for scoring.",
            "uuid": "e3191.0",
            "source_info": {
                "paper_title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ChatGLM + TiM",
            "name_full": "ChatGLM augmented with Think-in-Memory",
            "brief_description": "An open-source bilingual LLM (ChatGLM) used in experiments combined with TiM external memory to improve long-term conversational performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGLM",
            "agent_description": "An open-source bilingual transformer-based LLM (6.2B parameters) optimized for dialogue; in this paper it is used as the LLM agent combined with TiM memory and optionally LoRA fine-tuning.",
            "memory_used": true,
            "memory_type": "retrieval-augmented external thoughts memory (TiM)",
            "memory_mechanism_description": "ChatGLM retrieves top-k thoughts from the TiM LSH-hash table (LSH bucket then within-bucket similarity) prior to response generation, uses them to produce a reply, and then executes a post-thinking step to generate and insert/update thoughts (insert/forget/merge) in memory.",
            "task_name": "GVD (English & Chinese), KdConv (film/music/travel), RMD (medical)",
            "task_description": "Long-term conversational benchmarks requiring recall of past user information and multi-turn context to produce correct and coherent responses (simulated multi-day dialogues, multi-domain knowledge-driven conversations, and medical patient-doctor dialogues).",
            "task_type": "dialogue / long-horizon conversational memory",
            "performance_with_memory": "Examples from Table 2: GVD English: Retrieval Accuracy 0.820, Response Correctness 0.450, Contextual Coherence 0.735; GVD Chinese: Retrieval Accuracy 0.850, Response Correctness 0.605, Contextual Coherence 0.665; KdConv Film: Retrieval Accuracy 0.920, Response Correctness 0.827, Contextual Coherence 0.943; RMD: Retrieval Accuracy 0.900, Response Correctness 0.843, Contextual Coherence 0.943.",
            "performance_without_memory": "Examples: GVD English (SiliconFriend baseline) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; KdConv Film no-memory Response Correctness 0.657, Contextual Coherence 0.923; RMD no-memory Response Correctness 0.806, Contextual Coherence 0.893.",
            "has_performance_comparison": true,
            "key_findings": "Augmenting ChatGLM with TiM raises retrieval accuracy and substantially improves response correctness and contextual coherence across all tested datasets, with larger gains on some languages/topics (e.g., Chinese GVD showed a notable correctness increase).",
            "limitations_or_challenges": "Performance gains depend on ChatGLM's baseline capabilities; quality of stored thoughts and post-thinking correctness influence downstream responses; evaluation uses human raters which can introduce subjectivity.",
            "uuid": "e3191.1",
            "source_info": {
                "paper_title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Baichuan2 + TiM",
            "name_full": "Baichuan2 augmented with Think-in-Memory",
            "brief_description": "An open-source 13B multilingual LLM (Baichuan2) used with TiM memory in experiments, showing large gains in retrieval and response metrics across KdConv and RMD.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "Baichuan2",
            "agent_description": "A 13B-parameter multilingual LLM trained on large-scale data, used here as the LLM agent combined with TiM memory and LoRA fine-tuning for long-term conversational tasks.",
            "memory_used": true,
            "memory_type": "retrieval-augmented external thoughts memory (TiM)",
            "memory_mechanism_description": "Baichuan2 queries the TiM LSH-indexed thoughts memory to recall top-k thoughts (LSH bucket + similarity within bucket), conditions its response on recalled thoughts, and then uses a post-thinking step to generate and insert/update thoughts in memory.",
            "task_name": "KdConv (film/music/travel), RMD (medical)",
            "task_description": "Multi-turn knowledge-driven dialogue (KdConv) and real-world medical dialogues requiring recall of prior conversational facts to produce correct responses.",
            "task_type": "dialogue / long-horizon conversational memory",
            "performance_with_memory": "Examples from Table 2: KdConv Film: Retrieval Accuracy 0.913, Response Correctness 0.743, Contextual Coherence 0.870; KdConv Music: Retrieval Accuracy 0.900, Response Correctness 0.710, Contextual Coherence 0.780; RMD: Retrieval Accuracy 0.873, Response Correctness 0.538, Contextual Coherence 0.663.",
            "performance_without_memory": "Baselines (no memory shown in table as 'X'): KdConv Film no-memory Response Correctness 0.360, Contextual Coherence 0.413; KdConv Music no-memory Response Correctness 0.253, Contextual Coherence 0.283; RMD no-memory Response Correctness 0.506, Contextual Coherence 0.538.",
            "has_performance_comparison": true,
            "key_findings": "TiM substantially improves Baichuan2's retrieval accuracy, response correctness, and contextual coherence on KdConv and RMD; large relative gains observed compared to no-memory baselines, particularly on KdConv topics where baseline correctness was low.",
            "limitations_or_challenges": "Baseline model weaknesses limit absolute performance even with TiM; improvements vary by domain/topic; as with other agents, memory quality and retrieval precision (LSH approximation) affect outcomes.",
            "uuid": "e3191.2",
            "source_info": {
                "paper_title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "SiliconFriend",
            "name_full": "SiliconFriend (baseline memory mechanism referenced as SiliconFriend / MemoryBank in paper)",
            "brief_description": "A classical memory mechanism used as a baseline in experiments (referenced in the paper; stores raw text Q-R pairs as memory and supports reading operations).",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "SiliconFriend (memory baseline)",
            "agent_description": "A prior external memory mechanism that stores raw question-response (Q-R) text into a memory cache and retrieves relevant raw text to augment an LLM; used as a baseline for GVD comparisons in this paper.",
            "memory_used": true,
            "memory_type": "retrieval-augmented external memory (raw Q-R text)",
            "memory_mechanism_description": "Stores raw dialogue turns (Q-R pairs) and retrieves relevant history by pairwise similarity search across stored entries (no thoughts abstraction); retrieval is comparatively more expensive because it computes similarities across many raw entries.",
            "task_name": "GVD (English & Chinese) comparisons",
            "task_description": "Long-term virtual-user dialogue dataset evaluating memory recall and correctness across languages.",
            "task_type": "dialogue / long-horizon conversational memory",
            "performance_with_memory": "GVD English (ChatGLM + SiliconFriend) Retrieval Accuracy 0.809, Response Correctness 0.438, Contextual Coherence 0.680; GVD Chinese Retrieval Accuracy 0.840, Response Correctness 0.418, Contextual Coherence 0.428.",
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "SiliconFriend (raw text memory) improves over no-memory in some metrics but is outperformed by TiM, especially in contextual coherence and response correctness in several settings.",
            "limitations_or_challenges": "Requires repeated reasoning over raw history (can lead to inconsistent reasoning paths), pairwise similarity retrieval across the whole memory is time-consuming for long histories.",
            "uuid": "e3191.3",
            "source_info": {
                "paper_title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "MemoryBank",
            "name_full": "MemoryBank",
            "brief_description": "A prior long-term memory mechanism (referenced) that stores Q-R pairs and introduces forgetting inspired by human memory; mentioned in related work as an alternative external memory approach.",
            "citation_title": "Memorybank: Enhancing large language models with long-term memory.",
            "mention_or_use": "mention",
            "agent_name": "MemoryBank (referenced mechanism)",
            "agent_description": "An external memory mechanism that stores question-response pairs and includes forgetting operations inspired by human forgetting curves; referenced as prior work in long-term memory for LLMs (not used in this paper's experiments).",
            "memory_used": true,
            "memory_type": "external memory storing Q-R pairs",
            "memory_mechanism_description": "Stores raw dialogue entries and applies strategies for retention/forgetting; retrieval typically via similarity search across stored Q-R pairs.",
            "task_name": "Long-term conversation benchmarks (referenced)",
            "task_description": "Mechanisms for maintaining and retrieving long-term conversational memory.",
            "task_type": "dialogue / long-horizon conversational memory",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "Mentioned as prior work that supports insert and forget operations but not merge, and stores Q-R pairs rather than abstracted thoughts.",
            "limitations_or_challenges": "Because it stores raw text, models still need to repeatedly reason over history; pairwise retrieval over full memory can be costly.",
            "uuid": "e3191.4",
            "source_info": {
                "paper_title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Memorybank: Enhancing large language models with long-term memory.",
            "rating": 2
        },
        {
            "paper_title": "Augmenting language models with long-term memory.",
            "rating": 2
        },
        {
            "paper_title": "Improving language models by retrieving from trillions of tokens.",
            "rating": 1
        },
        {
            "paper_title": "Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system.",
            "rating": 1
        }
    ],
    "cost": 0.012048999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory</h1>
<p>Lei Liu*<br>liulei1497@gmail.com<br>CUHK-Shenzhen, Ant Group<br>Binbin Hu, Zhiqiang Zhang<br>{bin.hbb,lingyao.zzq}@antfin.com<br>Ant Group</p>
<p>Xiaoyan Yang<br>joyce.yxy@antgroup.com<br>Ant Group<br>Jinjie Gu<br>jinjie.gjj@antfin.com<br>Ant Group</p>
<p>Yue Shen ${ }^{\dagger}$<br>zhanying@antgroup.com<br>Ant Group<br>Guannan Zhang<br>zgn138592@antfin.com<br>Ant Group</p>
<h2>ABSTRACT</h2>
<p>Memory-augmented Large Language Models (LLMs) have demonstrated remarkable performance in long-term human-machine interactions, which basically relies on iterative recalling and reasoning of history to generate high-quality responses. However, such repeated recall-reason steps easily produce biased thoughts, i.e., inconsistent reasoning results when recalling the same history for different questions. On the contrary, humans can keep thoughts in the memory and recall them without repeated reasoning. Motivated by this human capability, we propose a novel memory mechanism called TiM (Think-in-Memory) that enables LLMs to maintain an evolved memory for storing historical thoughts along the conversation stream. The TiM framework consists of two crucial stages: (1) before generating a response, a LLM agent recalls relevant thoughts from memory, and (2) after generating a response, the LLM agent post-thinks and incorporates both historical and new thoughts to update the memory. Thus, TiM can eliminate the issue of repeated reasoning by saving the post-thinking thoughts as the history. Besides, we formulate the basic principles to organize the thoughts in memory based on the well-established operations, (i.e., insert, forget, and merge operations), allowing for dynamic updates and evolution of the thoughts. Furthermore, we introduce Locality-Sensitive Hashing into TiM to achieve efficient retrieval for the long-term conversations. We conduct qualitative and quantitative experiments on real-world and simulated dialogues covering a wide range of topics, demonstrating that equipping existing LLMs with TiM significantly enhances their performance in generating responses for long-term interactions.</p>
<h2>KEYWORDS</h2>
<p>Large Language Model, Response Generation, Long-term Memory</p>
<h2>1 INTRODUCTION</h2>
<p>Impressive advancements in Large Language Models (LLMs) have revolutionized the interaction between human beings and artificial intelligence (AI) systems. These advancements have particularly showcased superior performance in human-agent conversations, as demonstrated by ChatGPT [1] and GPT-4 [2]. From finance [3] and healthcare [4] to business and customer service [5], these advanced LLMs exhibit a remarkable ability to understand questions and generate corresponding responses. Notably, the large model scale,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>reaching up to hundreds of billions of parameters, enables the emergence of such human-like abilities within LLMs [6].</p>
<p>Despite the remarkable abilities of LLMs pre-trained on large corpora, LLM-based AI agents still face a significant limitation in long-term scenarios, i.e., inability to process exceptionally lengthy inputs [7]. This is particularly important in some specific tasks, e.g., medical AI assistants [4] rely on the symptoms of past conversations to provide accurate clinical diagnosis. Thus, LLMs without the capability of dealing with long-term inputs may hinder the diagnosis accuracy due to forgetting important disease symptoms (see in Section 4.4). Therefore, it is necessary to develop AI systems with long-term capabilities for more accurate and reliable interactions.</p>
<p>There have been various studies conducted to improve the capabilities of LLMs to handle long-term inputs. Overall, these studies can be roughly divided into two types: (1) Internal memory based methods [8] aims to reduce the computational costs of self-attention for expanding the sequence length. To accommodate longer input texts, special positional encoding should be exploited to learn relative positions. For example, [9] explored a block-local Transformer with global encoder tokens, combined with additional long input pre-training. (2) External memory based methods (also called long-term memory mechanism [10]) generally utilize a physical space as a memory cache to store historical information, where relevant history can be read from the memory cache to augment LLMs without forgetting. In particular, both token and raw text can be maintained as history in the memory. For instance, [11] demonstrated a significant performance improvement by augmenting LLMs with an external memory cache containing trillions of tokens assisted by BERT embeddings [12]. It should be noticed that token-based memory mechanism requires to adjust the LLM's architecture for adaption, which is hard to be combined with different LLMs. By accessing an external memory cache, the augmented LLMs have achieved new state-of-the-art records in various language modeling benchmarks, which generally performs better than internal memory based methods. Therefore, this work focuses on designing an LLM-agnostic external memory mechanism to enhanced the memorization capacity of LLMs.</p>
<p>In general, the utility of memory-augmented LLMs primarily hinges on their ability for iterative recalling and repeated reasoning over the history in an external memory cache. In detail, for conversations after the $n$-th turn, LLMs are required to re-understand and re-reason the history from 0 -th to $(n-1)$-th conversations. For example, as shown in Figure 1, to answer the questions of 2-th and 3-th turns, LLMs recall 1-th turn and reason over it for twice.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Comparisons between previous memory mechanisms with our proposed TiM. (Left): Existing memory mechanisms mainly save raw text of previous turns, which require repeated reasoning over the same history. This easily leads to the inconsistent reasoning path (i.e., red part of the left) with wrong response. (Right): The proposed TiM stores the thoughts of LLMs for previous turns, which can avoid such inconsistency without repeated reasoning (i.e., red part of the right).</p>
<p>Unfortunately, this paradigm is prone to encountering several issues and potentially causes a performance bottleneck in real-world applications. The main issues are shown in follows:</p>
<ul>
<li>Inconsistent reasoning paths. Prior studies [13, 14] has shown that LLMs easily generate diverse reasoning paths for the same query. As shown in Figure 1 (Left), LLMs give a wrong response due to inconsistent reasoning over the context.</li>
<li>Unsatisfying retrieval cost. To retrieve relevant history, previous memory mechanisms need to calculate pairwise similarity between the question and each historical conversation, which is time-consuming for long-term dialogue.</li>
</ul>
<p>To address these concerns, we would like to advance one step further in memory-augmented LLMs with the analogy to the typical process of metacognition [15], where the brain saves thoughts as memories rather than the details of original events. Thus, in this work, we propose a Think-in-Memory (TiM) framework to model the human-like memory mechanism, which enables LLMs to remember and selectively recall historical thoughts in long-term interaction scenarios. Specifically, as shown in Figure 2, the TiM framework is divided into two stages: (1) In the recalling stage, LLMs generate the response for the new query with recalling relevant thoughts in the memory; (2) In the post-thinking stage, the LLM engages in reasoning and thinking over the response and saves new thoughts into an external memory. Besides, to mirror the cognitive process of humans, we formulate some basic principles to organize the thoughts in memory based on the well-established operations (e.g., insert, forget, and merge operations), allowing for dynamic updates and evolution of the thoughts. Specifically, TiM is built on
a hash-based retrieval mechanism (i.e., Locality-Sensitive Hashing [16]) to support efficient hand-in (i.e., insert thoughts) and hand-out (i.e., recall thoughts) operations. Additionally, TiM is designed to be LLM-agnostic, which means it can be combined with various types of language models. This includes closed-source LLMs such as ChatGPT [1], as well as open-source LLMs like ChatGLM[17].</p>
<p>The key contributions of this work are summarized as follows:</p>
<ul>
<li>We propose a novel human-like long-term memory mechanism called TiM, enabling LLMs to remember and selectively recall thoughts. TiM can let LLM think in memory without repeated reasoning over the long-term history.</li>
<li>We formulate some basic principles to organize the thoughts in memory based on the well-established operations, which mirrors human cognitive process to empower dynamic updates and evolution for the thoughts in memory. Besides, a hash-based retrieval mechanism is introduced for efficient utilization of TiM.</li>
<li>We conducted extensive experiments on multi-turn dialogue datasets. The results indicate that our method can substantially enhance LLM's performance across various dimensions: (1) It enables diverse topics ranging from open to specific domains; (2) It supports bilingual languages in both Chinese and English; (3) It improves response correctness and coherence.</li>
</ul>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The overview of TiM framework. LLMs firstly recall history and give response for the question. Then new thoughts can be generated via the post-thinking step. These thoughts are saved as the memory to avoid repeated reasoning on the history.</p>
<h2>2 RELATED WORK</h2>
<h3>2.1 Large Language Models</h3>
<p>Recently, Large Language Models (LLMs) have attracted significant attention for their superior performance on a wide range of Natural Language Processing tasks, such as machine translation [18], sentiment analysis [19], and question answering systems [20]. These advancements are indeed supported by the developments of deep learning techniques and the availability of vast amounts of text data. From the perspective of open source, existing LLMs can roughly divided into two types: (1) cutting-edge closed-source LLMs, e.g., PaLM [21], GPT-4 [2], and ChatGPT [1]; (2) open-source LLMs, e.g., LLaMa [22], ChatGLM [17], and Alpaca [23]. Researchers have studied various methods for the applications of these popular LLMs. For example, many strategies are proposed to fine-tune pre-trained LLM models on specific tasks [24], which can further improve their capabilities in specific domains. Besides, some efforts have been made to enhance the quality of the generated content of LLMs, e.g., generating more diverse and creative text while maintaining coherence and fluency [25]. Overall, recent developments of LLMs cover a broad range of topics, including model architecture [17], training methods [26], fine-tuning strategies [27], as well as ethical considerations [21]. All these methods aim to enhance the understanding capabilities of LLMs for real-world applications. However, these powerful LLM models still have some shortcomings. One notable limitation of LLMs is their lack of a strong long-term memory, which hinders their ability to process lengthy context and retrieve relevant historical information.</p>
<h3>2.2 Long-term Memory</h3>
<p>Numerous efforts have been conducted to enhance the memory capabilities of LLMs. One approach is to utilize memory-augmented
networks (MANNs) [28], such as Neural Turing Machines (NTMs) [29], which is designed to utilize more context information for dialogue. In general, MANNs are proposed with an external memory cache via the storage and manipulation of information, which can well handle tasks of long-term period by interacting with memory. In addition, many studies focused on long-term conversations [3033]. For example, Xu et al. [30] introduced a new English dataset consisting of multi-session human-human crowdworker chats for long-term conversations. Zhong et al. [32] proposed a MemoryBank mechanism inspired by Ebbinghaus' forgetting curve theory. However, these methods still face some great challenges to achieve a reliable and adaptable long-term memory mechanism for Language and Learning Models (LLMs). Concretely, these methods only considered storing the raw dialogue text, requiring repeated reasoning of the LLM agent over the same history. Besides, these models need to calculate pairwise similarity for recalling relevant information, which is time-consuming for the long-term interactions.</p>
<h2>3 METHODOLOGY</h2>
<p>In this section, we first introduce the overall workflow of our proposed framework. Then we provide a detailed description for each stage of TiM, involving storage for memory cache, organization principle for memory updating, and retrieval for memory recalling.</p>
<h3>3.1 Framework Overview</h3>
<p>Given a sequence of conversation turns, each turn is denoted by a tuple $(Q, R)$, representing the user's query $(Q)$ and the agent's response (R) at that specific turn. The main objective is to generate a more accurate response $R_{y}$ like a human for a new coming query $Q_{x}$, while remembering the contextual information of historical conversation turns. The proposed TiM allows the agent to process</p>
<p>long-term conversation and retain useful historical information after multiple conversations with the user.
3.1.1 Main Components. As illustrated in Figure 2, our TiM comprises the following components, working together to provide more accurate and coherent responses for long-term conversation:</p>
<ul>
<li>Agent $\mathcal{A}: \mathcal{A}$ is a pre-trained LLM model to facilitate dynamic conversations, such as ChatGPT [1] and ChatGLM [17].</li>
<li>Memory Cache $\mathcal{M}: \mathcal{M}$ a continually growing hash table of keyvalue pairs, where key is the hash index and value is a single thought. More details of $\mathcal{M}$ can refer to Section 3.2. To be clear, $\mathcal{M}$ supports varying operations as shown in Table 1.</li>
<li>Hash-based Mapping $\mathbf{F}(\cdot)$ : Locality-sensitive Hashing is introduced to quickly save and find the relevant thoughts in $\mathcal{M}$.
3.1.2 Workflow. Overall framework is divided into two stages:</li>
<li>Stage-1: Recall and Generation. Given a new question from the user, LLM agent $\mathcal{A}$ retrieves relevant thoughts for generating accurate responses. Since we save the self-generated reasoning thoughts as external memory, this stage can directly recall and answer the question without repeated reasoning over the raw historical conversation text.</li>
<li>Stage-2: Post-think and Update. After answering the question, we let the LLM agent post-think upon $Q-R$ pair and insert the newly self-generated reasoning thoughts into memory cache $\mathcal{M}$.</li>
</ul>
<h3>3.2 Storage for Memory Cache</h3>
<p>3.2.1 Thoughts-based System. TiM's storage system $\mathcal{M}$ aims to save the knowledge of AI-user interactions via self-generated inductive thoughts (Definition 3.1) upon the conversations. Each piece of thought $T$ is stored in the format of the tuple $\left(H_{i d x}, T\right)$, where $H_{i d x}$ is the hash index obtained by hash function $\mathbf{F}(T)$. This hash-based storage not only aids in quick memory retrieval but also facilitates the memory updating, providing a detailed index of historical thoughts.</p>
<p>Definition 3.1. Inductive Thought. The inductive thought is defined as the text which contains the relation between two entities, i.e., satisfying a relation triple $\left(E_{h}, r_{i}, E_{t}\right) . E_{h}$ is head entity connected with tail entity $E_{t}$ via the relation $r_{i}$, where $i \in[0, N]$ and $N$ is the relation number. Conceptually, $R_{h}=\left{r_{1}, \cdots, r_{N}\right}$ consists of all the one-hop relations for the entity $E_{h}$.</p>
<p>The main challenge of utilizing inductive thoughts for LLM is obtaining high-quality sentences matching relation triples. Here we provide two kinds of solutions to obtain inductive thoughts: (1) pre-trained model for open information extraction, such as OpenIE [34]; (2) In-context learning with few-shot prompts based on LLM. In this work, we utilize the second solution, i.e., utilizing LLM Agent $\mathcal{A}$ to generate inductive thoughts, as shown in Figure 3.
3.2.2 Hash-based Storage. We aim to save inductive thoughts into the memory following a certain rule, i.e., similar thoughts should be stored in the same group in the memory for efficiency. To this end, we adopt a hash table as the architecture of TiM's storage system, where similar thoughts are assigned with the same hash index.</p>
<p>Given a query, we propose to quickly search its nearest thoughts in a high-dimensional embedding space, which can be solved by the locality-sensitive hashing (LSH) method. The hashing scheme</p>
<h2>Prompt for Generating Thoughts</h2>
<p>Given the following question and response pairs, please extract the relation (subject, relation, object) with corresponding text:</p>
<h2>Example 1.</h2>
<p>Input:
Question: Do you have any company recommendations for me? Response: I recommend Google.
Output:
(Company, Recommended, Google).
Recommended company is Google.
Example 2.
Input:
Question: Which City is the capital of China?
Response: Beijing.
Output:
(China, Capital, Beijing).
The capital of China is Beijing.</p>
<h2>Input:</h2>
<p>Question: Do you have any book recommendations for me? Response: I recommend "The Little Prince". Output:</p>
<p>Figure 3: An example of prompts for generating thoughts.
of LSH is to assign each $d$-dimension embedding vector $x \in \mathbf{R}^{d}$ to a hash index $\mathbf{F}(x)$, where nearby vectors get the same hash index with higher probability. We achieve this by exploiting a random projection as follows:</p>
<p>$$
\mathbf{F}(x)=\arg \max ([x R ;-x R])
$$</p>
<p>where $R$ is a random matrix of size $(d, b / 2)$ and $b$ is the number of groups in the memory. $[u ; v]$ denotes the concatenation of two vectors. This LSH method is a well known LSH scheme [16] and is easy to implement. Figure 2 shows a schematic exhibition of TiM's storage system based on LSH.</p>
<h3>3.3 Retrieval for Memory Recalling</h3>
<p>Built on the memory storage, the memory retrieval operates a two-stage retrieval task for the most relevant thoughts, i.e., LSHbased retrieval followed by similarity-based retrieval. The paradigm involves the following detailed points.</p>
<ul>
<li>Stage-1: LSH-based Retrieval. For a new query $Q$, we first obtain its embedding vector $x$ based on LLM agent. Then LSH function (i.e., Eq. 1) can produce the hash index of the query. This hash index also indicates the its nearest group for similar thoughts in the memory cache according to the property of LSH.</li>
<li>Stage-2: Similarity-based Retrieval. Within the nearest group, we calculate the pairwise similarity between the query and each piece of thought in the group. Then top-k thoughts are recalled as the relevant history for accurately answering the query. It</li>
</ul>
<p>Given the following thoughts, please remove the counterfactual thoughts or contradictory thoughts:</p>
<p>Example 1.
Input:
The capital of China is Beijing.
The capital of China is Shanghai.
The capital of the United States is Washington.
The capital of the United States is New York.
Output:
The capital of China is Beijing.
The capital of the United States is Washington.
Example 2.
Input:
Michael likes to play football.
Michael does not like to play football.
James likes to swim.
Mary likes to read books.
Output:
James likes to swim.
Mary likes to read books.</p>
<p>Input:
[A group of thoughts]
Output:</p>
<p>Figure 4: An example of prompts for forgetting thoughts.
should be noticed that pairwise similarity is calculated within a group rather than the whole memory cache, which can achieve more efficient retrieval than previous memory mechanisms.</p>
<h3>3.4 Organization for Memory Updating</h3>
<p>With the above-discussed memory storage and retrieval, the longterm memory capability of LLMs can be well enhanced. Motivated by the human memory, there needs some organization principles based on the well-established operations for dynamic updates and evolution of the thoughts, e.g., insert new thoughts, forget less important thoughts, and merge repeated thoughts, which can make the memory mechanism more natural and applicable.</p>
<p>Beginning with the architecture of the storage for memory cache, TiM adopts the hash table to store the self-generated thoughts, where each hash index corresponds a group containing similar thoughts. Within same group, TiM supports the following operations to organize the thoughts in the memory:</p>
<ul>
<li>Insert, i.e., store new thoughts into the memory. The prompt for generating thoughts is shown in Figure 3.</li>
<li>Forget, i.e., remove unnecessary thoughts from the memory, such as contradictory thoughts. The prompt of this operation is shown in Figure 4.</li>
<li>Merge, i.e., merge similar thoughts in the memory, such as thoughts with the same head entity. The prompt of this operation is shown in Figure 5.</li>
</ul>
<p>Given the following thoughts, please merge the similar thoughts with the same entity:</p>
<p>Example 1.
Input:
John works as an actor.
John works as a director.
John works as a writer.
Mike works as a teacher.
Output:
John works as an actor, a director, and a writer.
Mike works as a teacher.
Example 2.
Input:
Michael likes to play football.
Michael likes to play basketball.
James likes to swim.
Mary likes to read books.
Output:
Michael likes to play football and basketball.
James likes to swim.
Mary likes to read books.
Input:
[A group of thoughts]
Output:</p>
<p>Figure 5: An example of prompts for merging thoughts.</p>
<p>Table 1: Organization comparisons between previous memory mechanisms and ours. KG denotes the knowledge graph and Q-R denotes the question and response pairs.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Content</th>
<th style="text-align: center;">LLM-agnostic</th>
<th style="text-align: center;">Insert</th>
<th style="text-align: center;">Forget</th>
<th style="text-align: center;">Merge</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SCM [33]</td>
<td style="text-align: center;">Q-R</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
</tr>
<tr>
<td style="text-align: left;">RelationLM [7]</td>
<td style="text-align: center;">KG</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
</tr>
<tr>
<td style="text-align: left;">LongMem [10]</td>
<td style="text-align: center;">Token</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
</tr>
<tr>
<td style="text-align: left;">MemoryBank [32]</td>
<td style="text-align: center;">Q-R</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\boldsymbol{x}$</td>
</tr>
<tr>
<td style="text-align: left;">Ours (TiM)</td>
<td style="text-align: center;">Thoughts</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
<td style="text-align: center;">$\checkmark$</td>
</tr>
</tbody>
</table>
<h3>3.5 Parameter-efficient Tuning</h3>
<p>We adopt a computation-efficient fine-tuning approach called LowRank Adaptation (LoRA) [27] for the scenarios with limited computational resources. LoRA [27] optimizes pairs of rank-decomposition matrices while keeping the original weights frozen, which can effectively reduce the number of trainable parameters. Specifically, considering a linear layer defined as $y=W x$, LoRA fine-tunes it according to $y=W x+B A x$, where $W \in \mathbf{R}^{d \times k}, B \in \mathbf{R}^{d \times r}, A \in \mathbf{R}^{r \times k}$, and $r \ll \min (d ; k)$. Essentially, this fine-tuning stage can adapt LLMs to multi-turn conversations, providing appropriately and effectively response to users. For all experiments, we set LoRA rank $r$ as 16 and train the LLM models for 10 epochs.</p>
<h3>3.6 Insightful Discussion</h3>
<p>Here we make a summary for previous memory mechanisms and our method in Table 1, including memory content, LLM-agnostic, and organization operations. There are several important observations from Table 1: (1) Previous memory mechanisms only save raw conversation text (Q-R pairs) as the memory, which requires repeated reasoning over the history. Our method maintains thoughts in the memory cache and can directly recall them without repeated reasoning. (2) Previous memory mechanisms only support simple read and write (insert) operations, while our method provides more manipulate way for the memory. (3) Some previous memory mechanisms store the tokens in the memory, which requires adjusting LLM architecture (LLM-aware) for applications. Our method is deigned as a LLM-agnostic module, which can be easily combined with other LLMs.</p>
<h2>4 EXPERIMENT</h2>
<h3>4.1 Experimental Settings</h3>
<p>4.1.1 Dataset. Three datasets are used to demonstrate the effectiveness of the proposed method.</p>
<ul>
<li>KdConv: KdConv is a Chinese multi-domain knowledge-driven conversation benchmark [35] grounding the topics to knowledge graphs, which involves 4.5 K conversations and 86 K utterances from three domains (film, music, and travel). The average turn number is 19 .</li>
<li>Generated Virtual Dataset (GVD): GVD is a long-term conversation dataset [32] involving 15 virtual users (ChatGPT) over 10 days. Conversations are synthesized using pre-defined topics, including both English and Chinese languages. For the test set, [32] manually constructed 194 query questions ( 97 in English and 97 in Chinese) to evaluate whether the LLM could accurately recall the memory and produce the appropriate answers.</li>
<li>Real-world Medical Dataset (RMD): To evaluate the effectiveness of the proposed memory mechanism in the real-world scenarios, we manually collect and construct a dataset containing 1,800 conversations for medical healthcare consumer. For the test set, 80 conversations are used to evaluate whether the LLM could provide the accurate diagnosis.
4.1.2 LLM. We integrate two powerful LLMs to demonstrate the effectiveness of the proposed TiM mechanism. These LLMs originally lack long-term memory and specific adaptability to the long-term conversations. The detailed introduction of these LLMs are follows.</li>
<li>ChatGLM [17]: ChatGLM is an open-source bilingual language model based on the General Language Model (GLM) framework [17]. This model contains 6.2 billion parameters with specific optimization, involves supervised fine-tuning, feedback bootstrap, and reinforcement learning with human feedback.</li>
<li>Baichuan2 [36]: Baichuan2 is an open-source large-scale multilingual language model containing 13 billion parameters, which is trained from scratch on 2.6 trillion tokens. This model excels at dialogue and context understanding.
4.1.3 Baseline. One baseline is to answer questions without using any memory mechanism. Another baseline is SiliconFriend [32], a
classical memory mechanism, which can store the raw text into the memory and support reading operation.
4.1.4 Evaluation Protocol. Following [32], three metrics are adopted to evaluate the performance of the proposed method.</li>
<li>Retrieval Accuracy evaluates whether the relevant memory is successfully recalled (labels: ${0:$ no; 1: yes $}$ ).</li>
<li>Response Correctness evaluates if correctly answering the probing question (labels: ${0:$ wrong; 0.5 : partial; 1 : correct $}$ ).</li>
<li>Contextual Coherence evaluates whether the response is naturally and coherently generated, e.g., connecting the dialogue context and retrieved memory (labels: ${0:$ not coherent; 0.5 : partially coherent; 1 : coherent $}$.
To be fair, during evaluation, the prediction results of all LLMs are firstly shuffled, ensuring the human evaluator does not know which LLM the results come from. Then the final evaluation results are obtained by the human evaluation.</li>
</ul>
<h3>4.2 Comparison Results</h3>
<p>4.2.1 Results on GVD dataset. We evaluate our method on both English and Chinese test sets of GVD dataset. The following insights are observed from Table 2: (1) Compared with SiliconFriend [32], our method exhibits superior performance for all metric, especially for the contextual coherence, indicating the effectiveness of TiM mechanism. (2) TiM delivers better results on both languages. The performance improvement on Chinese is larger than English, which may be attributed to the abilities of the LLMs.
4.2.2 Results on KdConv dataset. Table 2 illustrates the comparison results on KdConv dataset. We evaluate 2 different LLMs with TiM over different topics (film, music, and travel). As shown in Table 2 , it is observed that our method can obtain best results across all topics. Our method can achieve high retrieval accuracy to recall the relevant thoughts. When without the memory mechanism, these LLMs usually exhibit lower response correctness due to lack of long-term memory capability, while TiM can well eliminate such negative issue. Furthermore, TiM can also help to improve the contextual coherence of the response.
4.2.3 Results on RMD dataset. Table 2 reports the comparison results on RMD dataset, which contains the realistic conversations between the doctors and patients. As shown in Table 2, our method can improve the overall response performance for the real-world medical conversations. In detail, using TiM, both ChatGLM and Baichuan2 can improve their capability for long-term conversations, i.e., significant improvements on the response correctness and the contextual coherence. The main reason is that TiM is more similar to the workflow of human memory, which can enhance the ability of LLMs to produce more human-like responses.</p>
<h3>4.3 More Analysis</h3>
<p>4.3.1 Retrieval Time. We report the comparison results of retrieval time. The baseline is to calculate pairwise similarity between the question and the whole memory, which is utilized as the default retrieval way for most previous mechanisms. For both baseline and our method, the memory length is as 140 and the memory context is fixed. Table 2 shows the time cost for making a single retrieval. It</p>
<p>Table 2: Comparison Results on Three Datasets. Top-5 thoughts are recalled from the memory cache.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">LLM</th>
<th style="text-align: center;">Language/Topic</th>
<th style="text-align: center;">Memory</th>
<th style="text-align: center;">Retrieval Accuracy</th>
<th style="text-align: center;">Response Correctness</th>
<th style="text-align: center;">Contextual Coherence</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GVD</td>
<td style="text-align: center;">ChatGLM</td>
<td style="text-align: center;">English/Open</td>
<td style="text-align: center;">SiliconFriend</td>
<td style="text-align: center;">0.809</td>
<td style="text-align: center;">0.438</td>
<td style="text-align: center;">0.680</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.820</td>
<td style="text-align: center;">0.450</td>
<td style="text-align: center;">0.735</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Chinese/Open</td>
<td style="text-align: center;">SiliconFriend</td>
<td style="text-align: center;">0.840</td>
<td style="text-align: center;">0.418</td>
<td style="text-align: center;">0.428</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.850</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.665</td>
</tr>
<tr>
<td style="text-align: center;">Kdconv</td>
<td style="text-align: center;">ChatGLM</td>
<td style="text-align: center;">Chinese/Film</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.657</td>
<td style="text-align: center;">0.923</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.920</td>
<td style="text-align: center;">0.827</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Chinese/Music</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.666</td>
<td style="text-align: center;">0.910</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.970</td>
<td style="text-align: center;">0.826</td>
<td style="text-align: center;">0.926</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Chinese/Travel</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.735</td>
<td style="text-align: center;">0.906</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.940</td>
<td style="text-align: center;">0.766</td>
<td style="text-align: center;">0.912</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Baichuan2</td>
<td style="text-align: center;">Chinese/Film</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.360</td>
<td style="text-align: center;">0.413</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.913</td>
<td style="text-align: center;">0.743</td>
<td style="text-align: center;">0.870</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Chinese/Music</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.253</td>
<td style="text-align: center;">0.283</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.710</td>
<td style="text-align: center;">0.780</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Chinese/Travel</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.207</td>
<td style="text-align: center;">0.280</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.833</td>
<td style="text-align: center;">0.757</td>
<td style="text-align: center;">0.807</td>
</tr>
<tr>
<td style="text-align: center;">RMD</td>
<td style="text-align: center;">ChatGLM</td>
<td style="text-align: center;">Chinese/Medical</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.806</td>
<td style="text-align: center;">0.893</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.900</td>
<td style="text-align: center;">0.843</td>
<td style="text-align: center;">0.943</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Baichuan2</td>
<td style="text-align: center;">Chinese/Medical</td>
<td style="text-align: center;">$\boldsymbol{X}$</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.506</td>
<td style="text-align: center;">0.538</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">TiM (Ours)</td>
<td style="text-align: center;">0.873</td>
<td style="text-align: center;">0.538</td>
<td style="text-align: center;">0.663</td>
</tr>
</tbody>
</table>
<p>Table 3: Comparisons of Retrieval Time. Baseline calculates pairwise similarity between the question and memory.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: center;">Retrieval Time (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Baseline</td>
<td style="text-align: center;">0.6287</td>
</tr>
<tr>
<td style="text-align: left;">Ours (TiM)</td>
<td style="text-align: center;">0.5305</td>
</tr>
</tbody>
</table>
<p>is observed that our method can reduce about 0.1 ms retrieval time compared with baseline method.
4.3.2 Top-k Recall. We report the retrieval accuracy using different values of $k$ on Kdconv dataset (Travel). As shown in Figure 6, top-1 retrieval accuracy is higher than 0.7 . The overall retrieval accuracy is improved with increasing value of $k$, where top- 10 can achieve 0.973 retrieval accuracy. Besides, as shown in Table 2, top-5 recall can significantly improve the performance of existing LLMs for long-term conversations.</p>
<h3>4.4 Industry Application</h3>
<p>In this section, based on the ChatGLM and TiM, we develop a medical agent (named TiM-LLM) in the context of patient-doctor
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 6: Tendency of retrieval accuracy with different $k$.
conversations (as shown in Figure 7). Note that TiM-LLM is only an auxiliary tool for the clinical doctors to give treatment options and medical suggestions for patients' needs.</p>
<p>Figure 7 illustrates a real-world conversation between a patient and a doctor, where the clinical diagnosis results are given by the medical agent with and without TiM. As shown in Figure 7, without TiM, the medical agent may struggle to recall previous symptoms,</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 7: The application of TiM. The left is the background of TiM-LLM application and the right is user interface.
resulting in incomplete or incorrect assessments (red part), i.e., the agent has forgotten previous symptoms so it is uncertain whether oral mucosal inflammation is the only cause. Assisted by TiM, the medical agent can recall relevant symptoms and make a comprehensive understanding of a patient's diseases. Thus it provide accurate diagnosis and treatment (bold part).</p>
<h2>5 CONCLUSION</h2>
<p>In this work, we propose a novel memory mechanism called TiM to address the issue of biased thoughts in Memory-augmented LLMs. By storing historical thoughts in an evolved memory, TiM enables LLMs to recall relevant thoughts and incorporate them into the conversations without repeated reasoning. TiM consists of two key stages: recalling thoughts before generation and post-thinking after generation. Besides, TiM works with the several basic principles to organize the thoughts in memory, which can achieve dynamic updates of the memory. Furthermore, we introduce Locality-Sensitive</p>
<p>Hashing into TiM to achieve efficient retrieval for the long-term conversations. The qualitative and quantitative experiments conducted on real-world and simulated dialogues demonstrate the significant benefits of equipping LLMs with TiM. Overall, TiM is designed as an approach to improve the quality and consistency of responses for long-term human-AI interactions.</p>
<h2>REFERENCES</h2>
<p>[1] OpenAI. Chatgpt. 2022.
[2] OpenAI. Gpt-4 technical report. 2023.
[3] Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. Fingpt: Open-source financial large language models. arXiv preprint arXiv:2306.06031, 2023.
[4] Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan Li, Guiming Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, et al. Huatuogpt, towards taming language model to be a doctor. arXiv preprint arXiv:2305.15075, 2023.
[5] Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. Gpts are gpts: An early look at the labor market impact potential of large language models. arXiv preprint arXiv:2303.10130, 2023.
[6] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in Neural Information Processing Systems, 35:22199-22213, 2022.
[7] Qi Liu, Dani Yogatama, and Phil Blunsom. Relational memory-augmented language models. Transactions of the Association for Computational Linguistics, 10:555-572, 2022.
[8] Quentin Fournier, Gatan Marceau Caron, and Daniel Aloise. A practical survey on faster and lighter transformers. ACM Computing Surveys, 55(14s):1-40, 2023.
[9] Jason Phang, Yao Zhao, and Peter J Liu. Investigating efficiently extending transformers for long input summarization. arXiv preprint arXiv:2208.04347, 2022.
[10] Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, and Furu Wei. Augmenting language models with long-term memory. arXiv preprint arXiv:2306.07174, 2023.
[11] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. Improving language models by retrieving from trillions of tokens. In International Conference on Machine Learning, pages 22062240. PMLR, 2022.
[12] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pretraining of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, volume 1, page 2, 2019.
[13] Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, et al. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977, 2020.
[14] Xuezhi Wang, Jason Wei, Dale Schnurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowolhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022.
[15] John Dunlosky and Janet Metcalfe. Metacognition. Sage Publications, 2008.
[16] Alexandr Andoni, Piotr Indyk, Thijs Laarhoven, Ilya Razenshteyn, and Ludwig Schmidt. Practical and optimal lsh for angular distance. Advances in Neural Information Processing Systems, 28, 2015.
[17] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414, 2022.
[18] Biao Zhang, Barry Haddow, and Alexandra Birch. Prompting large language model for machine translation: A case study. arXiv preprint arXiv:2301.07069, 2023.
[19] Boyu Zhang, Hongyang Yang, Tianyu Zhou, Ali Babar, and Xiao-Yang Liu. Enhancing financial sentiment analysis via retrieval augmented large language models. arXiv preprint arXiv:2310.04027, 2023.
[20] Jiaxian Guo, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Boyang Li, Dacheng Tao, and Steven Hoi. From images to textual prompts: Zero-shot visual question answering with frozen large language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1086710877, 2023.
[21] Aakanksha Chowolhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
[22] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.
[23] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Stanford alpaca: An instruction-following llama model, 2023.
[24] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained language models: A survey. ACM Computing Surveys, 56(2):1-40, 2023.
[25] Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. Plug and play language models: A simple approach to controlled text generation. arXiv preprint arXiv:1912.02164,</p>
<p>2019
[26] Tomasz Korbak, Kejian Shi, Angelica Chen, Rasika Vinayak Bhalerao, Christopher Buckley, Jason Phang, Samuel R Bowman, and Ethan Perez. Pretraining language models with human preferences. In International Conference on Machine Learning, pages 17506-17533. PMLR, 2023.
[27] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.
[28] Lian Meng and Minlie Huang. Dialogue intent classification with long short-term memory networks. In Natural Language Processing and Chinese Computing: 6th CCF International Conference, NLPCC 2017, Dalian, China, November 8-12, 2017, Proceedings 6, pages 42-50. Springer, 2018.
[29] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv preprint arXiv:1410.5401, 2014.
[30] Jing Xu, Arthur Szlam, and Jason Weston. Beyond goldfish memory: Long-term open-domain conversation. arXiv preprint arXiv:2107.07567, 2021.
[31] Xinchao Xu, Zhihin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, and Shihang Wang. Long time no see! open-domain conversation with long-term persona memory. arXiv preprint arXiv:2203.05797, 2022.
[32] Wanjun Zhong, Lianghong Guo, Qiuj Gao, and Yanlin Wang. Memorybank: Enhancing large language models with long-term memory. arXiv preprint arXiv:2305.10250, 2023.
[33] Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, and Zhoujun Li. Unleashing infinite-length input capacity for largescale language models with self-controlled memory system. arXiv preprint arXiv:2304.13343, 2023.
[34] Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D Manning. Leveraging linguistic structure for open domain information extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 344-354, 2015.
[35] Hao Zhou, Chujie Zheng, Kaili Huang, Minlie Huang, and Xiaoyan Zhu. KdConv: A Chinese multi-domain dialogue dataset towards multi-turn knowledge-driven conversation. In ACL, 2020.
[36] Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, et al. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305, 2023.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Work was done when Lei Liu was a research intern at Ant Group.
${ }^{\dagger}$ Corresponding Author.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>