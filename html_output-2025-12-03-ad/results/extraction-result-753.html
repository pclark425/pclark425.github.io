<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-753 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-753</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-753</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-273963251</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2411.06040v1.pdf" target="_blank">CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization</a></p>
                <p><strong>Paper Abstract:</strong> Improving generalization and achieving highly predictive, robust machine learning models necessitates learning the underlying causal structure of the variables of interest. A prominent and effective method for this is learning invariant predictors across multiple environments. In this work, we introduce a simple yet powerful approach, CGLearn, which relies on the agreement of gradients across various environments. This agreement serves as a powerful indication of reliable features, while disagreement suggests less reliability due to potential differences in underlying causal mechanisms. Our proposed method demonstrates superior performance compared to state-of-the-art methods in both linear and nonlinear settings across various regression and classification tasks. CGLearn shows robust applicability even in the absence of separate environments by exploiting invariance across different subsamples of observational data. Comprehensive experiments on both synthetic and real-world datasets highlight its effectiveness in diverse scenarios. Our findings underscore the importance of leveraging gradient agreement for learning causal invariance, providing a significant step forward in the field of robust machine learning. The source code of the linear and nonlinear implementation of CGLearn is open-source and available at: https://github.com/hasanjawad001/CGLearn.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e753.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e753.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CGLearn</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Consistent Gradient-Based Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gradient-consistency based invariant-learning method that identifies and updates only features whose gradients agree across environments (or subsamples), thereby reducing reliance on spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>CGLearn</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Computes per-feature gradients in each environment (or batch), forms the mean and standard deviation (or mean and std of L2-norms in the nonlinear case) across environments, then forms a consistency ratio C_ratio = mean / std for each feature; applies a threshold C_thresh to produce a binary consistency mask per feature and only updates weights for features with mask=1 (all other feature weights are left unchanged). Implementations: (1) linear — computes gradients per feature directly; (2) nonlinear (MLP) — computes L2-norms of gradients w.r.t. first hidden layer per feature. The goal is to detect invariant (causal) features and avoid updating weights for inconsistent/spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic multi-environments (e in {0.2,2,5}), single-environment via batch-subsampling, and K-means partitioned real-world datasets</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Not interactive/active: (a) synthetic linear environments created by intervening on scalar e to produce three distributions; (b) single-environment setup creates multiple batches from observational data to act as pseudo-environments; (c) real-world tasks use K-means clustering to produce multiple environments. These are observational / simulated partitions rather than open-ended or interactive virtual labs.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detection via gradient-consistency (mean/std of per-environment gradients or L2-norms); variable selection-like masking (binary mask) that prevents updates to features deemed inconsistent across environments, effectively downweighting their influence.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/noncausal variables (spurious predictors), environment-dependent noise/heteroskedasticity; fails when spurious feature is invariant across training environments (invariant spurious).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Compute per-feature gradients (or their L2-norms) across environments, derive mean and standard deviation, then compute C_ratio = mean/std as a detector of invariance; large C_ratio => considered invariant.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Binary consistency mask: if C_ratio < C_thresh then mask=0 and the model does not apply gradient updates to that feature's weights (effectively freezing or not adapting those weights), otherwise the feature is updated normally.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No explicit statistical refutation procedure is provided; refutation is implicit via the consistency test (features failing consistency are ignored). The method cannot refute spurious features that are invariant across training environments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Across synthetic linear multi-environment experiments CGLearn achieves the lowest MSE compared to ERM, IRM, and ICP. Example (linear single-env case FOU): causal MSE 1.28 ± 0.40 (CGLearn) vs 1.57 ± 0.13 (ERM). In nonlinear real-world tasks (Boston, Yacht) CGLearn shows significantly lower test RMSE than baselines; in Wine-quality classification CGLearn attains higher test accuracy and F1 (statistically significant in some cases). In Colored MNIST (invariant spurious present) CGLearn: training acc 93.1 ± 0.8, test acc 29.1 ± 0.8.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>ERM baseline typically has higher test error and relies on spurious correlations (example Colored MNIST: ERM train acc 87.4 ± 0.2, test acc 17.1 ± 0.6). IRM sometimes better than ERM but worse than CGLearn on many settings; on Colored MNIST IRM obtained train acc 70.8 ± 0.9 and test acc 66.9 ± 2.5 (higher test than CGLearn in that case).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td>5 noncausal features in synthetic linear experiments (X6–X10); Colored MNIST uses a single color spurious feature that is invariant across training envs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Gradient-consistency (agreement of gradients across environments/batches) effectively identifies invariant (causal) features and reduces reliance on spurious correlates, improving OOD generalization in many linear and nonlinear tasks. Method fails when spurious features are themselves invariant across the training environments (e.g., Colored MNIST color), because the consistency detector treats invariant spurious signals as causal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e753.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An invariant-learning approach that seeks a data representation and classifier whose optimal classifier is the same across multiple environments, typically enforced by an invariance penalty during training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Invariant risk minimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Risk Minimization (IRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Optimizes for predictors that are simultaneously optimal across multiple environments by adding a penalty encouraging an invariant optimal classifier (practically implemented via a gradient-penalty or game between representation and classifier). The objective discourages solutions that exploit environment-specific spurious correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same synthetic and real-world partitioned environments used for evaluation in this paper (synthetic e environments; K-means clustered real data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational multi-environment datasets (synthetic interventions or clustered partitions). Not interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Enforcing invariance of predictor across environments via penalty term; discourages feature use that leads to environment-specific optimal classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables and environment-specific correlations; aims to remove features whose predictive relationship is not invariant.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Imposes an invariance criterion (through penalty) rather than an explicit detector; features causing environment-specific optimality are penalized indirectly.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Regularization/penalty that reduces reliance on features that break invariance; learned representation is optimized to make a single classifier optimal across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No explicit refutation test described in this paper; invariance objective serves as the mechanism to rule out features that vary across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Generally better than ERM on many OOD tasks in the paper; in linear experiments IRM often outperforms ERM but is outperformed by CGLearn. On Colored MNIST (classic invariant spurious task) IRM reported train acc 70.8 ± 0.9 and test acc 66.9 ± 2.5 (reported from IRM paper results quoted in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>ERM baseline typically shows much worse OOD performance; IRM improves over ERM in many settings but can overfit in nonlinear cases (cited limitations).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>IRM reduces reliance on spurious correlations by enforcing cross-environment invariance, improving OOD generalization relative to ERM in many scenarios; however, IRM can overfit in nonlinear settings and may not match CGLearn in the reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e753.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Causal Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constraint-based invariant method that finds subsets of covariates whose conditional distribution of the target is invariant across environments, treating those subsets as causal parents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Invariant Causal Prediction (ICP)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Iterates over covariate subsets and tests whether the conditional distribution of the target given the subset is stable across environments; subsets that pass invariance tests are considered possible causal parents and accepted while others are rejected.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic multi-environments (as in linear experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational/synthetic environments partitioned by intervention on e; not interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit invariance testing / subset selection based on conditional distribution stability (conservative variable selection).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Noncausal covariates (spurious predictors) and environment-dependent associations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Conditional invariance tests across environments; rejects covariates that induce changes in conditional distribution of Y.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Does not downweight continuously; instead it rejects (omits) covariates that fail invariance tests (conservative selection).</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Hypothesis testing for invariance of conditional distributions used to rule out non-invariant covariates.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Per paper: ICP performs well in noncausal scenarios (i.e., detecting and rejecting noncausal covariates) but poorly in causal scenarios; compared to CGLearn and IRM, ICP is conservative and may reject many covariates, leading to higher causal errors in some setups.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td>5 noncausal features in the synthetic linear setups (X6–X10) where comparisons were made</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ICP's conservative invariance testing can successfully reject spurious covariates in some settings but may overly reject covariates and perform poorly on causal estimation in other configurations; performs differently from IRM and CGLearn depending on data configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e753.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fishr</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fishr: Invariant gradient variances for out-of-distribution generalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An algorithm that aligns per-environment gradient covariances (or variances) across environments to encourage invariance and reduce reliance on spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Fishr</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Matches gradient second-order statistics (variance/covariance) across environments via an objective that penalizes differences in gradient variances, encouraging representations whose gradient statistics are invariant across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Gradient-variance alignment (regularization) to discourage environment-specific gradient patterns associated with spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific spurious correlations manifesting as differing gradient variances.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Not an explicit detector; uses difference in gradient variances as the signal to align and thus implicitly detect environment-specific signals.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Regularization penalty that reduces the influence of features causing differing gradient-variance across envs.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as a related method that uses environment-specific gradients to improve generalization; aligns gradient variances to reduce spurious reliance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e753.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AND-mask</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AND-mask</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gradient-based method that uses an AND-like masking rule on environment-specific gradients to stabilize updates and improve generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>AND-mask</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses environment-specific gradients and applies a masking rule that only allows parameter updates when gradients from multiple environments agree (an AND condition across envs) to reduce learning of spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Agreement-based mask on environment gradients (update only when gradients agree), functioning as variable selection/downweighting of inconsistent features.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific spurious correlations and features with inconsistent gradients across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Gradient agreement check across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Binary masking of updates when gradients disagree.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as related work using environment-specific gradient agreement to improve OOD generalization; conceptually similar to CGLearn's gradient-consistency masking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e753.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IGA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Invariant Gradient Alignment (IGA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method leveraging environment-specific gradients to align or regularize model updates for better generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>IGA</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses environment-wise gradients and encourages alignment across them (via objectives or constraints) so that learned updates are not dominated by environment-specific spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Gradient alignment/regularization across environments to prevent overfitting to spurious, environment-specific signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-dependent spurious correlations; features that cause gradient disagreement.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Gradient misalignment across environments signals spurious influence.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Regularize or alter update rules to reduce effect of misaligned gradients.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Listed among gradient-based invariant learners in related work; conceptually relevant to CGLearn though not used in experiments here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e753.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BIRM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Invariant Risk Minimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian variant of IRM that incorporates Bayesian inference to mitigate overfitting of IRM in nonlinear/deep settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bayesian IRM (BIRM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extends IRM with Bayesian inference/priors to better control model complexity and reduce overfitting in nonlinear models, improving OOD generalization in deep settings.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Nonlinear real-world experiments (regression and classification) where K-means was used to generate environments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational real datasets partitioned into environments by clustering (not interactive).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Invariance objective (like IRM) combined with Bayesian regularization to avoid overfitting to spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Environment-specific spurious correlations and nonlinear overfitting artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Implicit via invariance objective and Bayesian model evidence/control.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Bayesian regularization plus invariance penalty reduces reliance on spurious features.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Included as a baseline in nonlinear experiments; improves over IRM in some nonlinear cases (mitigates IRM's overfitting), but CGLearn outperformed BIRM on the tested regression and classification tasks per paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BIRM alleviates IRM's overfitting in nonlinear settings but was still outperformed by CGLearn on the presented real-world regression/classification benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e753.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NOTEARS (continuous optimization for DAG learning)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A score-based causal structure learning approach that converts combinatorial DAG search into continuous optimization via a differentiable acyclicity constraint.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>NOTEARS</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Formulates DAG learning as a continuous constrained optimization problem by adding a smooth acyclicity constraint; enables gradient-based optimization for structure learning.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Not specified in this paper with respect to distractors; NOTEARS is primarily a structural discovery method and has known sensitivity to assumptions (linearity, noise).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as an important continuous-optimization approach for causal graph learning; the paper notes limitations of many causal discovery methods when assumptions do not hold.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e753.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e753.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GSNR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gradient Signal-to-Noise Ratio (GSNR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A metric/approach that measures gradient alignment or signal-to-noise in gradients, used to understand/generalize and stabilize training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Gradient Signal-to-Noise Ratio (GSNR) approaches</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Measures alignment (signal-to-noise) of gradients across samples or batches; has been used to improve training stability and is related to measuring gradient agreement across environments.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Referenced as related work measuring gradient alignment/GSNR; conceptually connected to CGLearn's use of gradient agreement.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Invariant risk minimization <em>(Rating: 2)</em></li>
                <li>Causal inference by using invariant prediction: identification and intervals <em>(Rating: 2)</em></li>
                <li>Fishr: Invariant gradient variances for out-of-distribution generalization <em>(Rating: 2)</em></li>
                <li>Gradient matching for domain generalization <em>(Rating: 1)</em></li>
                <li>The Risks of Invariant Risk Minimization <em>(Rating: 2)</em></li>
                <li>Invariant Structure Learning for Better Generalization and Causal Explainability <em>(Rating: 2)</em></li>
                <li>Dags with no tears: Continuous optimization for structure learning <em>(Rating: 1)</em></li>
                <li>On the impact of spurious correlation for out-of-distribution detection <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-753",
    "paper_id": "paper-273963251",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CGLearn",
            "name_full": "Consistent Gradient-Based Learning",
            "brief_description": "A gradient-consistency based invariant-learning method that identifies and updates only features whose gradients agree across environments (or subsamples), thereby reducing reliance on spurious correlations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "CGLearn",
            "method_description": "Computes per-feature gradients in each environment (or batch), forms the mean and standard deviation (or mean and std of L2-norms in the nonlinear case) across environments, then forms a consistency ratio C_ratio = mean / std for each feature; applies a threshold C_thresh to produce a binary consistency mask per feature and only updates weights for features with mask=1 (all other feature weights are left unchanged). Implementations: (1) linear — computes gradients per feature directly; (2) nonlinear (MLP) — computes L2-norms of gradients w.r.t. first hidden layer per feature. The goal is to detect invariant (causal) features and avoid updating weights for inconsistent/spurious features.",
            "environment_name": "Synthetic multi-environments (e in {0.2,2,5}), single-environment via batch-subsampling, and K-means partitioned real-world datasets",
            "environment_description": "Not interactive/active: (a) synthetic linear environments created by intervening on scalar e to produce three distributions; (b) single-environment setup creates multiple batches from observational data to act as pseudo-environments; (c) real-world tasks use K-means clustering to produce multiple environments. These are observational / simulated partitions rather than open-ended or interactive virtual labs.",
            "handles_distractors": true,
            "distractor_handling_technique": "Detection via gradient-consistency (mean/std of per-environment gradients or L2-norms); variable selection-like masking (binary mask) that prevents updates to features deemed inconsistent across environments, effectively downweighting their influence.",
            "spurious_signal_types": "Irrelevant/noncausal variables (spurious predictors), environment-dependent noise/heteroskedasticity; fails when spurious feature is invariant across training environments (invariant spurious).",
            "detection_method": "Compute per-feature gradients (or their L2-norms) across environments, derive mean and standard deviation, then compute C_ratio = mean/std as a detector of invariance; large C_ratio =&gt; considered invariant.",
            "downweighting_method": "Binary consistency mask: if C_ratio &lt; C_thresh then mask=0 and the model does not apply gradient updates to that feature's weights (effectively freezing or not adapting those weights), otherwise the feature is updated normally.",
            "refutation_method": "No explicit statistical refutation procedure is provided; refutation is implicit via the consistency test (features failing consistency are ignored). The method cannot refute spurious features that are invariant across training environments.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Across synthetic linear multi-environment experiments CGLearn achieves the lowest MSE compared to ERM, IRM, and ICP. Example (linear single-env case FOU): causal MSE 1.28 ± 0.40 (CGLearn) vs 1.57 ± 0.13 (ERM). In nonlinear real-world tasks (Boston, Yacht) CGLearn shows significantly lower test RMSE than baselines; in Wine-quality classification CGLearn attains higher test accuracy and F1 (statistically significant in some cases). In Colored MNIST (invariant spurious present) CGLearn: training acc 93.1 ± 0.8, test acc 29.1 ± 0.8.",
            "performance_without_robustness": "ERM baseline typically has higher test error and relies on spurious correlations (example Colored MNIST: ERM train acc 87.4 ± 0.2, test acc 17.1 ± 0.6). IRM sometimes better than ERM but worse than CGLearn on many settings; on Colored MNIST IRM obtained train acc 70.8 ± 0.9 and test acc 66.9 ± 2.5 (higher test than CGLearn in that case).",
            "has_ablation_study": false,
            "number_of_distractors": "5 noncausal features in synthetic linear experiments (X6–X10); Colored MNIST uses a single color spurious feature that is invariant across training envs.",
            "key_findings": "Gradient-consistency (agreement of gradients across environments/batches) effectively identifies invariant (causal) features and reduces reliance on spurious correlates, improving OOD generalization in many linear and nonlinear tasks. Method fails when spurious features are themselves invariant across the training environments (e.g., Colored MNIST color), because the consistency detector treats invariant spurious signals as causal.",
            "uuid": "e753.0",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "IRM",
            "name_full": "Invariant Risk Minimization",
            "brief_description": "An invariant-learning approach that seeks a data representation and classifier whose optimal classifier is the same across multiple environments, typically enforced by an invariance penalty during training.",
            "citation_title": "Invariant risk minimization",
            "mention_or_use": "use",
            "method_name": "Invariant Risk Minimization (IRM)",
            "method_description": "Optimizes for predictors that are simultaneously optimal across multiple environments by adding a penalty encouraging an invariant optimal classifier (practically implemented via a gradient-penalty or game between representation and classifier). The objective discourages solutions that exploit environment-specific spurious correlations.",
            "environment_name": "Same synthetic and real-world partitioned environments used for evaluation in this paper (synthetic e environments; K-means clustered real data)",
            "environment_description": "Observational multi-environment datasets (synthetic interventions or clustered partitions). Not interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Enforcing invariance of predictor across environments via penalty term; discourages feature use that leads to environment-specific optimal classifiers.",
            "spurious_signal_types": "Irrelevant variables and environment-specific correlations; aims to remove features whose predictive relationship is not invariant.",
            "detection_method": "Imposes an invariance criterion (through penalty) rather than an explicit detector; features causing environment-specific optimality are penalized indirectly.",
            "downweighting_method": "Regularization/penalty that reduces reliance on features that break invariance; learned representation is optimized to make a single classifier optimal across environments.",
            "refutation_method": "No explicit refutation test described in this paper; invariance objective serves as the mechanism to rule out features that vary across environments.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Generally better than ERM on many OOD tasks in the paper; in linear experiments IRM often outperforms ERM but is outperformed by CGLearn. On Colored MNIST (classic invariant spurious task) IRM reported train acc 70.8 ± 0.9 and test acc 66.9 ± 2.5 (reported from IRM paper results quoted in this paper).",
            "performance_without_robustness": "ERM baseline typically shows much worse OOD performance; IRM improves over ERM in many settings but can overfit in nonlinear cases (cited limitations).",
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "IRM reduces reliance on spurious correlations by enforcing cross-environment invariance, improving OOD generalization relative to ERM in many scenarios; however, IRM can overfit in nonlinear settings and may not match CGLearn in the reported experiments.",
            "uuid": "e753.1",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "ICP",
            "name_full": "Invariant Causal Prediction",
            "brief_description": "A constraint-based invariant method that finds subsets of covariates whose conditional distribution of the target is invariant across environments, treating those subsets as causal parents.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Invariant Causal Prediction (ICP)",
            "method_description": "Iterates over covariate subsets and tests whether the conditional distribution of the target given the subset is stable across environments; subsets that pass invariance tests are considered possible causal parents and accepted while others are rejected.",
            "environment_name": "Synthetic multi-environments (as in linear experiments)",
            "environment_description": "Observational/synthetic environments partitioned by intervention on e; not interactive.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit invariance testing / subset selection based on conditional distribution stability (conservative variable selection).",
            "spurious_signal_types": "Noncausal covariates (spurious predictors) and environment-dependent associations.",
            "detection_method": "Conditional invariance tests across environments; rejects covariates that induce changes in conditional distribution of Y.",
            "downweighting_method": "Does not downweight continuously; instead it rejects (omits) covariates that fail invariance tests (conservative selection).",
            "refutation_method": "Hypothesis testing for invariance of conditional distributions used to rule out non-invariant covariates.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Per paper: ICP performs well in noncausal scenarios (i.e., detecting and rejecting noncausal covariates) but poorly in causal scenarios; compared to CGLearn and IRM, ICP is conservative and may reject many covariates, leading to higher causal errors in some setups.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": "5 noncausal features in the synthetic linear setups (X6–X10) where comparisons were made",
            "key_findings": "ICP's conservative invariance testing can successfully reject spurious covariates in some settings but may overly reject covariates and perform poorly on causal estimation in other configurations; performs differently from IRM and CGLearn depending on data configuration.",
            "uuid": "e753.2",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Fishr",
            "name_full": "Fishr: Invariant gradient variances for out-of-distribution generalization",
            "brief_description": "An algorithm that aligns per-environment gradient covariances (or variances) across environments to encourage invariance and reduce reliance on spurious features.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "Fishr",
            "method_description": "Matches gradient second-order statistics (variance/covariance) across environments via an objective that penalizes differences in gradient variances, encouraging representations whose gradient statistics are invariant across environments.",
            "environment_name": "",
            "environment_description": "",
            "handles_distractors": true,
            "distractor_handling_technique": "Gradient-variance alignment (regularization) to discourage environment-specific gradient patterns associated with spurious features.",
            "spurious_signal_types": "Environment-specific spurious correlations manifesting as differing gradient variances.",
            "detection_method": "Not an explicit detector; uses difference in gradient variances as the signal to align and thus implicitly detect environment-specific signals.",
            "downweighting_method": "Regularization penalty that reduces the influence of features causing differing gradient-variance across envs.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as a related method that uses environment-specific gradients to improve generalization; aligns gradient variances to reduce spurious reliance.",
            "uuid": "e753.3",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "AND-mask",
            "name_full": "AND-mask",
            "brief_description": "A gradient-based method that uses an AND-like masking rule on environment-specific gradients to stabilize updates and improve generalization.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "AND-mask",
            "method_description": "Uses environment-specific gradients and applies a masking rule that only allows parameter updates when gradients from multiple environments agree (an AND condition across envs) to reduce learning of spurious features.",
            "environment_name": "",
            "environment_description": "",
            "handles_distractors": true,
            "distractor_handling_technique": "Agreement-based mask on environment gradients (update only when gradients agree), functioning as variable selection/downweighting of inconsistent features.",
            "spurious_signal_types": "Environment-specific spurious correlations and features with inconsistent gradients across environments.",
            "detection_method": "Gradient agreement check across environments.",
            "downweighting_method": "Binary masking of updates when gradients disagree.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as related work using environment-specific gradient agreement to improve OOD generalization; conceptually similar to CGLearn's gradient-consistency masking.",
            "uuid": "e753.4",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "IGA",
            "name_full": "Invariant Gradient Alignment (IGA)",
            "brief_description": "A method leveraging environment-specific gradients to align or regularize model updates for better generalization.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "IGA",
            "method_description": "Uses environment-wise gradients and encourages alignment across them (via objectives or constraints) so that learned updates are not dominated by environment-specific spurious signals.",
            "environment_name": "",
            "environment_description": "",
            "handles_distractors": true,
            "distractor_handling_technique": "Gradient alignment/regularization across environments to prevent overfitting to spurious, environment-specific signals.",
            "spurious_signal_types": "Environment-dependent spurious correlations; features that cause gradient disagreement.",
            "detection_method": "Gradient misalignment across environments signals spurious influence.",
            "downweighting_method": "Regularize or alter update rules to reduce effect of misaligned gradients.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Listed among gradient-based invariant learners in related work; conceptually relevant to CGLearn though not used in experiments here.",
            "uuid": "e753.5",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "BIRM",
            "name_full": "Bayesian Invariant Risk Minimization",
            "brief_description": "A Bayesian variant of IRM that incorporates Bayesian inference to mitigate overfitting of IRM in nonlinear/deep settings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Bayesian IRM (BIRM)",
            "method_description": "Extends IRM with Bayesian inference/priors to better control model complexity and reduce overfitting in nonlinear models, improving OOD generalization in deep settings.",
            "environment_name": "Nonlinear real-world experiments (regression and classification) where K-means was used to generate environments",
            "environment_description": "Observational real datasets partitioned into environments by clustering (not interactive).",
            "handles_distractors": true,
            "distractor_handling_technique": "Invariance objective (like IRM) combined with Bayesian regularization to avoid overfitting to spurious signals.",
            "spurious_signal_types": "Environment-specific spurious correlations and nonlinear overfitting artifacts.",
            "detection_method": "Implicit via invariance objective and Bayesian model evidence/control.",
            "downweighting_method": "Bayesian regularization plus invariance penalty reduces reliance on spurious features.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Included as a baseline in nonlinear experiments; improves over IRM in some nonlinear cases (mitigates IRM's overfitting), but CGLearn outperformed BIRM on the tested regression and classification tasks per paper.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "BIRM alleviates IRM's overfitting in nonlinear settings but was still outperformed by CGLearn on the presented real-world regression/classification benchmarks.",
            "uuid": "e753.6",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "NOTEARS",
            "name_full": "NOTEARS (continuous optimization for DAG learning)",
            "brief_description": "A score-based causal structure learning approach that converts combinatorial DAG search into continuous optimization via a differentiable acyclicity constraint.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "NOTEARS",
            "method_description": "Formulates DAG learning as a continuous constrained optimization problem by adding a smooth acyclicity constraint; enables gradient-based optimization for structure learning.",
            "environment_name": "",
            "environment_description": "",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Not specified in this paper with respect to distractors; NOTEARS is primarily a structural discovery method and has known sensitivity to assumptions (linearity, noise).",
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as an important continuous-optimization approach for causal graph learning; the paper notes limitations of many causal discovery methods when assumptions do not hold.",
            "uuid": "e753.7",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "GSNR",
            "name_full": "Gradient Signal-to-Noise Ratio (GSNR)",
            "brief_description": "A metric/approach that measures gradient alignment or signal-to-noise in gradients, used to understand/generalize and stabilize training.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "method_name": "Gradient Signal-to-Noise Ratio (GSNR) approaches",
            "method_description": "Measures alignment (signal-to-noise) of gradients across samples or batches; has been used to improve training stability and is related to measuring gradient agreement across environments.",
            "environment_name": "",
            "environment_description": "",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Referenced as related work measuring gradient alignment/GSNR; conceptually connected to CGLearn's use of gradient agreement.",
            "uuid": "e753.8",
            "source_info": {
                "paper_title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Invariant risk minimization",
            "rating": 2,
            "sanitized_title": "invariant_risk_minimization"
        },
        {
            "paper_title": "Causal inference by using invariant prediction: identification and intervals",
            "rating": 2,
            "sanitized_title": "causal_inference_by_using_invariant_prediction_identification_and_intervals"
        },
        {
            "paper_title": "Fishr: Invariant gradient variances for out-of-distribution generalization",
            "rating": 2,
            "sanitized_title": "fishr_invariant_gradient_variances_for_outofdistribution_generalization"
        },
        {
            "paper_title": "Gradient matching for domain generalization",
            "rating": 1,
            "sanitized_title": "gradient_matching_for_domain_generalization"
        },
        {
            "paper_title": "The Risks of Invariant Risk Minimization",
            "rating": 2,
            "sanitized_title": "the_risks_of_invariant_risk_minimization"
        },
        {
            "paper_title": "Invariant Structure Learning for Better Generalization and Causal Explainability",
            "rating": 2,
            "sanitized_title": "invariant_structure_learning_for_better_generalization_and_causal_explainability"
        },
        {
            "paper_title": "Dags with no tears: Continuous optimization for structure learning",
            "rating": 1,
            "sanitized_title": "dags_with_no_tears_continuous_optimization_for_structure_learning"
        },
        {
            "paper_title": "On the impact of spurious correlation for out-of-distribution detection",
            "rating": 1,
            "sanitized_title": "on_the_impact_of_spurious_correlation_for_outofdistribution_detection"
        }
    ],
    "cost": 0.015805,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization
9 Nov 2024</p>
<p>Jawad Chowdhury 
Department of Computer Science
University of North Carolina at Charlotte
CharlotteNCUSA</p>
<p>Gabriel Terejanu gabriel.terejanu@uncc.edu 
Department of Computer Science
University of North Carolina at Charlotte
CharlotteNCUSA</p>
<p>CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization
9 Nov 20244A6BEF674CBC079760F467E9FB6585F4arXiv:2411.06040v1[cs.LG]
Improving generalization and achieving highly predictive, robust machine learning models necessitates learning the underlying causal structure of the variables of interest.A prominent and effective method for this is learning invariant predictors across multiple environments.In this work, we introduce a simple yet powerful approach, CGLearn, which relies on the agreement of gradients across various environments.This agreement serves as a powerful indication of reliable features, while disagreement suggests less reliability due to potential differences in underlying causal mechanisms.Our proposed method demonstrates superior performance compared to state-of-the-art methods in both linear and nonlinear settings across various regression and classification tasks.CGLearn shows robust applicability even in the absence of separate environments by exploiting invariance across different subsamples of observational data.Comprehensive experiments on both synthetic and real-world datasets highlight its effectiveness in diverse scenarios.Our findings underscore the importance of leveraging gradient agreement for learning causal invariance, providing a significant step forward in the field of robust machine learning.The source code of the linear and nonlinear implementation of CGLearn is opensource and available at: https://github.com/hasanjawad001/CGLearn.</p>
<p>Introduction</p>
<p>Machine learning models have achieved remarkable success in various domains driven by the recent availability of large datasets, sophisticated algorithms, and highly advanced complex models.However, these models perform well only when the test data follows the same distribution as the training data (i.i.d.), but they often suffer from overfitting due to overparametrization, learning spurious correlations from training data (Sagawa et al. 2020;Wang et al. 2021;Ming, Yin, and Li 2022).This issue arises because traditional models focus on predictive power without considering the causal relationships underlying the data.As a result, when the training and test distributions differ, models that rely on spurious correlations can perform very poorly, compromising their robustness, leading to poor generalization on out-of-distribution (OOD) test data (Arjovsky et al. 2019;He, Shen, and Cui 2021).</p>
<p>Preprint.Copyright 2024 by the author(s).</p>
<p>Learning causal relationships is the key to model explainability and enhancing generalization and robustness (Shin 2021; Wang et al. 2022;Santillan 2023).Although the ideal method for learning causal structures is through Randomized Control Trials (RCTs), these are often expensive, unethical, or impractical.Various methods have been developed for causal discovery.Constraint-based methods use conditional independence tests to identify causal directions (Spirtes, Glymour, and Scheines 2001;Pearl 2009;Colombo et al. 2012).This however often results in the Markov Equivalence Class (MEC) of causal structures.Score-based methods optimize causal graphs over Directed Acyclic Graphs (DAGs) (Chickering 2002;Ramsey et al. 2017;Huang et al. 2018), but the combinatorial nature of the search space can make it computationally expensive.Advances like NOTEARS (Zheng et al. 2018) transform this combinatorial challenge into continuous optimization, leading to various effective variants (Zheng et al. 2020;Yu et al. 2019;Lachapelle et al. 2019;Wei, Gao, and Yu 2020;Ng, Ghassami, and Zhang 2020;Ng et al. 2022).However, learning causal structures purely from observational data can be challenging due to issues like selection bias, measurement errors, and confounding factors (Zadrozny 2004;Torralba and Efros 2011).Moreover, relying solely on empirical risk optimization can result in models highly dependent on spurious relationships.To tackle this problem, researchers often use prior domain knowledge to improve causal discovery (O'Donnell et al. 2006;Gencoglu and Gruber 2020;Andrews, Spirtes, and Cooper 2020;Liu, Chen, and Zhao 2021;Chowdhury., Rashid., and Terejanu. 2023;Chowdhury and Terejanu 2023).Unfortunately, many causal discovery methods depend on specific assumptions (e.g., linearity, non-Gaussian noise) that do not always hold in real-world data.In addition to that some of these methods exploit variance scales e.g.var-sortability to identify causal orderings, performing well on unstandardized data but poorly after standardization (Reisach, Seiler, and Weichwald 2021;Kaiser and Sipos 2022;Reisach et al. 2024;Ormaniec et al. 2024).</p>
<p>A recent line of study focuses on exploiting the invariance property of causal relationships across different environments.Methods like Invariant Causal Prediction (ICP) (Peters, Bühlmann, and Meinshausen 2016) aim to identify causal predictors by ensuring the conditional distribution of the target given these predictors remains stable across envi- ronments.This method leverages the invariance of causal relationships under different interventions, iterating over feature subsets to find those invariant across environments, considering them as potential causal parents of the target variable.Another study, IRM (Arjovsky et al. 2019) optimizes a penalty function to achieve OOD generalization for predictive models, ensuring robust performance across environments.These methods significantly reduce the absorption of spurious correlations by focusing on stable and invariant relationships.The invariant learning framework provides a promising approach to improve model robustness and generalization in the presence of distribution shifts, with various domains exploiting invariance to learn better predictors and robust models (Montavon et al. 2012;Wang et al. 2017;Chowdhury et al. 2024;Bose and Roy 2024).Some relevant works such as AND-mask (Parascandolo et al. 2020), Fishr (Rame, Dancette, and Cord 2022), Fish (Shi et al. 2021), IGA (Koyama and Yamaguchi 2020) use environment-specific gradients to improve generalization in diverse settings.Moreover, approaches examining the signal-to-noise ratio (GSNR) in gradients, such as the work by Liu et al. (Liu et al. 2020), measure the alignment of gradient directions across samples, while a similar strategy has been employed in large-batch training scenarios to improve model stability (Jiang et al. 2023).</p>
<p>Motivated by this line of work and the current drawbacks of existing methods in structure learning and OOD generalization, we introduce CGLearn, a general framework designed to improve the generalization of machine learning models by leveraging gradient consistency across different environments.CGLearn does not require extensive domain knowledge or assumptions over data linearity or noise, making it a versatile and practical approach for learning robust predictive models.By focusing on feature invariance, emphasizing on reliable features, and reducing dependence on spurious correlations, CGLearn enhances the reliability and robustness of the models.The main contributions of this study are stated as follows:</p>
<p>• We propose a novel general framework, CGLearn, which improves consistency in learning robust predictors by focusing on features that show consistent behavior across environments.</p>
<p>• We provide both linear and nonlinear implementations of CGLearn, demonstrating its versatility and applicability across different model architectures.</p>
<p>• We demonstrate that CGLearn achieves superior predictive power and generalization, even without multiple environments, unlike most state-of-the-art methods in this arena that require diverse environments for effective generalization.</p>
<p>• Our empirical evaluations on synthetic and real-world datasets, covering both linear and nonlinear settings, as well as regression and classification tasks, validate the effectiveness and robustness of the proposed method.</p>
<p>The remainder of this paper is organized as follows: First, we delve into the methodology of CGLearn, detailing its linear and nonlinear implementations.Next, we present our experimental settings and evaluations.Finally, we encapsulate our conclusions, highlight the significant takeaways, and discuss future directions.</p>
<p>Methodology</p>
<p>In this section, we present the methodology of CGLearn, detailing both its linear and nonlinear implementations.We start by explaining the regular Empirical Risk Minimization (ERM) approach and then introduce the concept of gradient consistency used in CGLearn.The primary concept of CGLearn is to enforce gradient consistency for each factor of our variable of interest across multiple environments to identify and utilize invariant features, thereby enhancing generalization and reducing dependence on spurious correlations.</p>
<p>Figure 2: Nonlinear MLP implementation of CGLearn.X 1 (causal) and X 2 (spurious) feed into the first hidden layer h 1 .Weight updates in h 1 are performed based on gradient consistency (using L 2 -norm) for each feature across all training environments.The rest of the weights such as weights in h 2 , are updated similarly to ERM (without imposing any consistency constraints).</p>
<p>Empirical Risk Minimization (ERM)</p>
<p>Let's consider a simple linear problem where the goal is to predict the target variable Y using two features X 1 (causal) and X 2 (spurious) across multiple environments.Let e 1 , e 2 , . . ., e m represent different environments.Environments can be considered as distinct distributions generated by different interventions, all of which share similar underlying causal mechanisms (see Fig. 1).</p>
<p>In the ERM framework, the weights for the features are updated by minimizing the empirical risk or the cost function (L), which is typically the mean squared error (MSE) between the predicted and actual values for a regression problem and cross-entropy loss for a classification task.Suppose the weights for the features at step t are w t 1 for X 1 and w t 2 for X 2 .The gradient of the loss (L) with respect to the weight associated with the j-th feature X j in environment e i is given by ∇L ei j , where j ∈ {1, 2} and i ∈ {1, . . ., m}.The aggregated gradient across all environments can be calculated as the mean of the gradients:
µ grad j = 1 m m i=1 ∇L ei j for j ∈ {1, 2}(1)
Using this aggregated gradient, the weights are updated as follows:
w t+1 j = w t j − ηµ grad j for j ∈ {1, 2}(2)
where η is the learning rate.In this setup of a standard Empirical Risk Minimization, the weights for both X 1 and X 2 get updated in each step regardless of their consistency across environments.</p>
<p>Linear Implementation of CGLearn</p>
<p>CGLearn modifies this approach by introducing a consistency check for the gradients.The idea is to update the weights only if the gradients are consistent across the available environments.This strategy focuses on invariant features and ignores spurious ones, expecting better generalization.</p>
<p>First, we calculate the gradient of each feature in every environment, as described in the previous section.The mean of the gradients can be calculated as described in Eq. 1. Next, we compute the standard deviation of the gradients for each feature across all environments as follows:
σ grad j = 1 m m i=1 ∇L ei j − µ grad j 2 (3)
We then calculate the consistency ratio, which is the absolute value of the ratio of the mean gradient to the standard deviation of the gradients:
C ratio j = µ grad j σ grad j (4)
The consistency ratio, C ratio j defined in Eq. 4, is considered to be an indicator of the invariance of the gradient of variable X j across all the training environments.A relatively larger mean compared to the standard deviation would indicate more similar or invariant gradients across the environments for the feature X j , resulting in a higher value of C ratio j .On the other hand, a larger standard deviation indicates more diversity across the environments for X j .Finally, we formulate a consistency mask based on a predefined threshold C thresh :
C mask j = 1 if C ratio j ≥ C thresh 0 otherwise (5)
The weights are updated only for the feature that has a nonzero mask and remains unchanged otherwise as per the following equation:
w t+1 j = w t j − η µ grad j • C mask j for j ∈ {1, 2}(6)
Considering our motivating example, where X 1 is causal and expected to show more consistency across environments, C mask 1 is expected to be 1.Conversely, X 2 is spurious with respect to the target, expected to show inconsistency across environments, and C mask 2 is expected to be 0. Therefore, the weight for X 1 is mostly updated throughout the training steps while the weight for X 2 is not.The model thus focuses on the features that show consistency for learning the predictors of the target.This implementation strategy ensures to emphasis on reliable, invariant features while minimizing the impact of unreliable features by keeping their weights unchanged (or keeping the changes to a minimum).As a result, the contributions of the spurious features remain constant in the context of the model updates.In the next section, we extend the CGLearn method to a nonlinear setting using multilayer perceptron (MLP) as an instance.</p>
<p>Nonlinear Implementation</p>
<p>For the nonlinear implementation of CGLearn using a multilayer perceptron (MLP), we focus on the gradients in the first hidden layer (h 1 ), where feature contributions can be distinctly identified.By controlling the contribution of spurious features at the first hidden layer, we ensure they do not influence the final output.The process involves calculating the L 2 -norm of the gradients for each feature in each environment, followed by determining the consistency ratio and mask to impose the consistency constraint.∥∇L ei jh1 ∥ 2 denotes the L 2 -norm of the gradients of the j-th feature X j in the i-th environment e i at the first hidden layer h 1 .We compute the mean and standard deviation of the L 2 -norm of the gradients across all environments as follows:
µ grad j = 1 m m i=1 ∥∇L ei jh1 ∥ 2 (7) σ grad j = 1 m m i=1 ∥∇L ei jh1 ∥ 2 − µ grad j 2(8)
We then calculate the consistency ratio, C ratio j and the consistency mask, C mask j for feature X j by following Eq. 4 and 5 respectively.All the weights that belong to a particular feature, X j in the first hidden layer h 1 , are updated by following a similar strategy to Eq. 6.This updating strategy that depends on the consistency ratio, ensures that only the features that show consistency across the environments are considered to be updated.Otherwise, the weights remain unchanged, effectively treating them as constants similar to the linear implementation.For weights corresponding to the rest of the model other than the first hidden layer are updated as similar to ERM.Fig. 2 illustrates a simple demonstration of the nonlinear MLP implementation of CGLearn.In this figure, X 1 and X 2 represent causal and spurious features, respectively, in accordance with our earlier motivating example.The gradient consistency is checked in the first hidden layer (h 1 ), and weights are updated only if the consistency ratio exceeds the threshold, ensuring that features that show invariance across environments are utilized.</p>
<p>In both implementations, the goal is to ensure that the model relies on features that show invariance across different environments.This leads to more robust and generalizable models by reducing dependency on spurious correlations.</p>
<p>Experiments and Results</p>
<p>We have considered three different major scenarios to assess the predictivity, robustness, and generalization capabilities of CGLearn.The first two scenarios are the ones where we considered linearly generated dataset-based experiments and in the last experimental case we have used the nonlinear implementation of CGLearn using multilayer perceptron (MLP) and applied it to different real world regression and classification tasks.</p>
<p>For all evaluations, we reported the mean and standard deviation of the performance metrics considered.For statistical significance tests, we used a t-test with α = 0.05 as the significance level.</p>
<p>Linear Multiple Environments</p>
<p>To evaluate the performance of our proposed CGLearn method, we generated synthetic linear datasets inspired by the approach used in the Invariant Risk Minimization (IRM) framework (Arjovsky et al. 2019).Our goal was to create diverse environments to test the robustness of our model under varying conditions.We generated eight different experimental setups based on three key factors.Each setup included datasets with one target variable Y and ten feature variables X 1 to X 10 .Features X 1 to X 5 acted as causal parents of Y , while X 6 to X 10 were influenced by Y (non-causal).First, we distinguished between scrambled (S) and unscrambled (U) observations by applying an orthogonal transformation matrix S for scrambled data and using the identity matrix I for unscrambled data.This scrambling ensures that the features are not directly aligned with their original scales, making the learning task more challenging.Second, we designed fully-observed (F) scenarios where hidden confounders did not directly affect the features (i.e., no hidden confounder effects on features), and partially-observed (P) scenarios where hidden confounders influenced the features with Gaussian noise.Third, we incorporated two types of noise for the target variable Y : homoskedastic (O) noise, where the noise variance remained constant across different environments, and heteroskedastic (E) noise, where the noise variance varied depending on the environment, increasing with higher values of e.This distinction captures different real-world scenarios where noise may or may not depend on external factors.For each of these eight configurations (combinations of S/U, F/P, and O/E), we generated datasets corresponding to three distinct environments defined by the values e ∈ {0.2, 2, 5}.Each dataset consisted of 1000 samples.To ensure consistency with the IRM methodology and experimental setup, we used e = 5 as the validation environment and determined the optimal consistency threshold (C thresh ) for our CGLearn method using the performance based on this validation data.We selected the threshold C thresh from the candidate values {0.25, 1, 4, 16, 64} based on validation performance.This threshold is critical for identifying the invariant and most reliable features across different environments.For more details on the data generation process, we refer readers to the IRM paper (Arjovsky et al. 2019).</p>
<p>We compared the performance of CGLearn with Empirical Risk Minimization (ERM), Invariant Causal Prediction (ICP) (Peters, Bühlmann, and Meinshausen 2016), and IRM (Arjovsky et al. 2019).We considered 50 random trials and reported the results in Fig. 3.In most cases, our proposed method CGLearn achieves the lowest mean squared error (MSE), demonstrating superior performance across various test cases to distinguish the causal and noncausal factors of the target by exploiting invariance across environments.IRM performs better than ERM but does not match the accuracy of CGLearn.ERM shows the highest errors in most cases, as it fails to differentiate between causal and noncausal features, relying on spurious correlations.Interestingly, ICP performs well in noncausal scenarios but poorly in causal ones.This observation aligns with the findings from the IRM study (Arjovsky et al. 2019), which noted that ICP's conservative nature leads it to reject most covariates as direct causes, resulting in high causal errors.</p>
<p>Linear Single Environment</p>
<p>To evaluate the performance of our proposed CGLearn method in scenarios with only one environment, we generated synthetic linear datasets without relying on multiple environments as in previous experiments.For each of the eight cases, we used a single setting with e = 2.The data generation process was similar to the previous section, with each dataset consisting of 1000 samples and ten feature variables, X 1 to X 10 .The first five features (X 1 to X 5 ) acted as causal parents of the target variable Y , while the remaining five features (X 6 to X 10 ) were influenced by Y .Given the single environment setup, we could not apply IRM and ICP methods, as they require multiple environments to distinguish between causal and noncausal factors.Therefore, we compared our results solely with Empirical Risk Minimization (ERM).</p>
<p>In the case of CGLearn, we created multiple batches, with b = {3, 5} representing the number of batches created from the dataset.The last batch was used as the validation batch to determine the optimal consistency threshold parameter (C thresh ).We selected the threshold C thresh from the candidate values {0.25, 1, 4, 16, 64} based on validation performance.We imposed gradient consistency across different batches to learn consistent and reliable factors of the target.</p>
<p>Table 1 shows the results of experiments in the single environment setup.Considering the causal error across all eight cases, CGLearn consistently achieves significantly lower mean squared errors (MSE) compared to ERM.For the noncausal error, CGLearn also outperforms ERM in most cases, suggesting the superiority of the proposed approach.Even in the absence of multiple environments, the optimization strategy based on gradient consistency across different batches enables CGLearn to achieve better predictive power than standard ERM.</p>
<p>Nonlinear Multiple Environments</p>
<p>For the nonlinear experimental setups, we considered two types of supervised learning tasks: regression and classification, both on real-world datasets.This approach allows us to evaluate the performance and robustness of our proposed CGLearn method in different real-world contexts.Recent work has highlighted limitations in the original Invariant Risk Minimization (IRM) framework, particularly in nonlinear settings where deep models tend to overfit (Rosenfeld, Ravikumar, and Risteski 2021).To address this, we included Bayesian Invariant Risk Minimization (BIRM) as a baseline, which has been shown to alleviate overfitting issues by incorporating Bayesian inference and thereby improving generalization in nonlinear scenarios (Lin et al. 2022).</p>
<p>Regression Tasks.In the nonlinear implementation of CGLearn, we used a multilayer perceptron (MLP) to evaluate its performance on real-world regression tasks, comparing it with other baselines.For the regression tasks, we used the Boston Housing dataset (Harrison and Rubinfeld 1978) and the Yacht Hydrodynamics dataset (Gerritsma, Onnink, and Versluis 2013).The Boston Housing dataset consists of 506 instances and 13 continuous attributes.It concerns housing values in suburbs of Boston, with the task being to predict the median value of owner-occupied homes (MEDV) based on attributes such as per capita crime rate (CRIM), proportion of residential land zoned for large lots (ZN), average number of rooms per dwelling, and etc.The Yacht Hydrodynamics dataset consists of 308 instances and 6 attributes.The task is to predict the residuary resistance per unit weight of displacement of a yacht based on various hull geometry coefficients and the Froude number, such as the longitudinal position of the center of buoyancy, prismatic coefficient, and beam-draught ratio.</p>
<p>Since real-world datasets do not naturally come with different environments, we followed a similar approach to the study by Ge et al. (2022).We used the K-Means (Lloyd 1982) clustering algorithm to generate diverse environments and determined the optimal number of environments (between 3 to 10) using the Silhouette (Rousseeuw 1987) method.For each dataset, we created all possible test cases where each environment was considered as the test environment once, and the rest were used as training environments.We averaged the results over all possible test cases and repeated the process for 10 random trials.We evaluated the models based on RMSE, with the results shown in Table 2.For the Boston Housing dataset, we found the optimal number of environments was 7, while for the Yacht Hydrodynamics dataset, it was 5. From Table 2, we observe that all four methods perform better on the training environments than the test environments, as expected.However, CGLearn shows significantly lower error in the testing or unseen environments compared to the other methods, demonstrating that imposing gradient consistency leads to less dependence on spurious features and thus better generalization.</p>
<p>Classification Tasks.For the classification tasks, we evaluated the performance on two real-world classification datasets: the Wine Quality dataset for red and white wines from the UCI repository (Cortez et al. 2009).The Wine Quality dataset for red wine has 1599 instances and 11 attributes, while the dataset for white wine has 4898 instances and 11 attributes.The goal is to model wine quality based on physicochemical tests, such as fixed acidity, volatile acidity, citric acid, residual sugar, pH, and etc.Similar to the regression tasks, we used K-means clustering to generate diverse environments and determined the optimal number of environments using the Silhouette method, finding 4 as the optimal number of environments for both classification datasets.We then generated all possible test cases where each environment was considered the test environment once, and the rest were used as training environments (as we did with the regression tasks).We averaged the performance over all possible test cases and conducted the process for 10 random trials.We used accuracy and F1-score as evaluation metrics, with the results shown in Table 3.As expected, all methods performed better in training environments compared to test environments.However, we found that CGLearn achieved higher accuracy and F1-scores, which are desirable, and the superior performance was statistically significant for the F1score on the Wine Quality Red dataset.It also had significantly better accuracy on the Wine Quality White dataset.Similar to the regression tasks, CGLearn demonstrated better predictive power and generalization over ERM, IRM, and BIRM for the classification tasks.</p>
<p>Limitations of CGLearn with Invariant Spurious Features.We evaluated CGLearn on the Colored MNIST dataset, a synthetic binary classification task derived from MNIST (LeCun et al. 1995) and proposed in the IRM study (Arjovsky et al. 2019).This dataset introduces color as a spurious feature that strongly correlates with the label in the training environments but has the correlation reversed in the test environment.We applied the nonlinear implementation of CGLearn and compared it with the results of ERM and IRM as reported in the IRM study (Arjovsky et al. 2019).Over 10 trials, ERM achieved a training accuracy of 87.4 ± 0.2 and a test accuracy of 17.1 ± 0.6, while IRM achieved a training accuracy of 70.8 ± 0.9 and a test accuracy of 66.9 ± 2.5.In our experimental study, CGLearn achieved a training accuracy of 93.1 ± 0.8 and a test accuracy of 29.1 ± 0.8.While CGLearn slightly outperformed ERM in the test environment, it still struggled to generalize.This limitation arises because CGLearn imposes gradient consistency on the training environments to distinguish invariant features from spurious ones.However, in the Colored MNIST setup, the spurious feature (color) is consistent across both training environments, leading CGLearn to erroneously treat it as an invariant feature.Consequently, CGLearn relies on color and performs poorly in the test environment.</p>
<p>Conclusions</p>
<p>In this study, we presented CGLearn, a novel approach for developing robust and predictive machine learning models by leveraging gradient consistency across multiple environments.By focusing on the agreement of gradients, CGLearn effectively identifies and utilizes invariant features, leading to superior generalization and reduced reliance on spurious correlations.Our extensive experiments on both synthetic and real-world datasets, including regression and classification tasks, demonstrated that CGLearn outperforms traditional ERM and state-of-the-art invariant learners like ICP, IRM, and BIRM, achieving lower errors and better generalization in diverse scenarios.Notably, even in the absence of predefined environments, we demonstrated that CGLearn can be effectively applied to different subsamples of data, leading to better predictive models than regular ERM.This flexibility enhances the applicability of CGLearn in a wide range of real-world scenarios where many state-of-the-art methods require diverse and defined environments for OOD generalization.Despite its strengths, CGLearn has limitations, particularly in scenarios where spurious features are invariant across environments, as observed in the Colored MNIST experiments.Such cases violate our assumption as generally we expect and observe causal features to be stable and invariant in nature whereas spurious features do not (Wood-ward 2005;Wang et al. 2022).CGLearn erroneously considers these invariant but spurious features as reliable, impacting its generalization performance.Addressing this limitation and adapting CGLearn to better handle such cases is a promising direction for future research.</p>
<p>Overall, CGLearn provides a significant step forward in the field of robust machine learning by effectively harnessing causal invariance.Our work opens new avenues for developing models that are not only highly predictive but also resilient to distribution shifts, paving the way for more reliable applications in real-world settings.</p>
<p>Figure 1 :
1
Figure 1: Illustration of three environments generated by intervening on the variable e, which takes distinct values e = 0.2, e = 2, and e = 5 in environments e 1 , e 2 , and e 3 , respectively.In each environment, X 1 acts as a causal factor for the target variable Y , while X 2 is a spurious (non-causal) factor with respect to Y .This figure exemplifies how different interventions on e create distinct environments.</p>
<p>Figure 3 :
3
Figure 3: Performance comparison of CGLearn, ICP, and ERM across various linear multiple environment setups.Each subplot represents different configurations of the data, showing the mean squared error (MSE) for causal and noncausal variables over 50 trials.</p>
<p>Table 1 :
1
Performance evaluation of CGLearn and ERM in linear single environmental setups.The table shows the Mean Squared Errors (MSE) for causal and noncausal variables across 50 trials for each configuration.Bold values indicate statistical significance.
Causal Error (MSE)Noncausal Error (MSE)CGLearnERMCGLearnERMFOU1.28 ± 0.40 1.57 ± 0.13 0.61 ± 0.19 0.54 ± 0.05FOS1.40 ± 0.43 1.61 ± 0.10 0.53 ± 0.17 0.52 ± 0.06FEU0.13 ± 0.05 0.20 ± 0.04 7.22 ± 2.15 8.28 ± 0.28FES0.16 ± 0.06 0.20 ± 0.04 7.47 ± 2.23 8.36 ± 0.30POU0.28 ± 0.11 0.37 ± 0.08 0.51 ± 0.18 0.48 ± 0.11POS0.34 ± 0.13 0.39 ± 0.07 0.46 ± 0.17 0.48 ± 0.10PEU0.24 ± 0.10 0.32 ± 0.07 5.11 ± 1.57 5.83 ± 0.43PES0.26 ± 0.10 0.31 ± 0.06 5.21 ± 1.58 5.81 ± 0.36</p>
<p>Table 2 :
2
Performance comparison in nonlinear experimental setups for regression tasks.The table shows the RMSE for training and test environments across 10 trials.In test cases, we mark the statistically significant values in bold.
To im-</p>
<p>Table 3 :
3
Performance comparison in nonlinear setups for classification tasks.The table shows accuracy and F1-score for training and test environments across 10 trials.The statistically significant values are in bold for the test cases.WQ Red and WQ White represent the Wine Quality Red and Wine Quality White datasets respectively.prove CGLearn's generalization, future work should focus on adapting the method to account for the varying nature of spurious features, even when they appear consistent across training environments.</p>
<p>AcknowledgmentsThis research was supported by the Army Research Office under Grant W911NF-22-1-0035 and by the National Science Foundation under grant no.CBET 2218841.The views expressed are those of the authors and do not necessarily reflect the official policies of the Army Research Office or the U.S. Government.The U.S. Government retains the right to reproduce and distribute reprints for governmental purposes.
On the completeness of causal discovery in the presence of latent confounding with tiered background knowledge. B Andrews, P Spirtes, G F Cooper, International Conference on Artificial Intelligence and Statistics. PMLR2020</p>
<p>Invariant risk minimization. M Arjovsky, L Bottou, I Gulrajani, D Lopez-Paz, arXiv:1907.028932019arXiv preprint</p>
<p>Invariance embedded physics-infused deep neural network-based sub-grid scale models for turbulent flows. R Bose, A M Roy, Engineering Applications of Artificial Intelligence. 128107483</p>
<p>Optimal structure identification with greedy search. D M Chickering, Journal of Machine Learning Research. 32002. Nov</p>
<p>Invariant Molecular Representations for Heterogeneous Catalysis. J Chowdhury, C Fricke, O Bamidele, M Bello, W Yang, A Heyden, G Terejanu, Journal of Chemical Information and Modeling. 6422024</p>
<p>Evaluation of Induced Expert Knowledge in Causal Structure Learning by NOTEARS. J Chowdhury, R Rashid, G Terejanu, Proceedings of the 12th International Conference on Pattern Recognition Applications and Methods -ICPRAM. the 12th International Conference on Pattern Recognition Applications and Methods -ICPRAMINSTICC, SciTePress2023</p>
<p>Learning high-dimensional directed acyclic graphs with latent and selection variables. J Chowdhury, G Terejanu, D Maathuis, M H Kalisch, M Richardson, T S , 2023 International Conference on Machine Learning and Applications (ICMLA). 2023. 2012IEEE. Colombo,</p>
<p>P Cortez, A Cerdeira, F Almeida, T Matos, J Reis, 10.24432/C56S3TWine Quality. UCI Machine Learning Repository. 2009</p>
<p>Y Ge, S Ö Arik, J Yoon, A Xu, L Itti, T Pfister, arXiv:2206.06469Invariant Structure Learning for Better Generalization and Causal Explainability. 2022arXiv preprint</p>
<p>Causal modeling of twitter activity during covid-19. O Gencoglu, M Gruber, Computation. 84852020</p>
<p>J Gerritsma, R Onnink, A Versluis, 10.24432/C5XG7RYacht Hydrodynamics. UCI Machine Learning Repository. 2013</p>
<p>Hedonic prices and the demand for clean air. D Harrison, D L Rubinfeld, UCI Machine Learning Repository. 1978</p>
<p>Towards non-iid image classification: A dataset and baselines. Y He, Z Shen, P Cui, Pattern Recognition. 1101073832021</p>
<p>Generalized score functions for causal discovery. B Huang, K Zhang, Y Lin, B Schölkopf, C Glymour, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining2018</p>
<p>G.-Q Jiang, J Liu, Z Ding, L Guo, W Lin, arXiv:2309.13681Accelerating Large Batch Training via Gradient Signal to Noise Ratio (GSNR). 2023arXiv preprint</p>
<p>Unsuitability of NOTEARS for causal graph discovery when dealing with dimensional quantities. M Kaiser, M Sipos, M Koyama, S Yamaguchi, S Lachapelle, P Brouillard, T Deleu, S Lacoste-Julien, arXiv:1906.02226Gradient-based neural dag learning. 2022. 2020. 201954arXiv preprintOut-of-distribution generalization with maximal invariant predictor</p>
<p>Learning algorithms for classification: A comparison on handwritten digit recognition. Y Lecun, L D Jackel, L Bottou, C Cortes, J S Denker, H Drucker, I Guyon, U A Muller, E Sackinger, P Simard, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. Y Lin, H Dong, H Wang, T Zhang, the IEEE/CVF Conference on Computer Vision and Pattern Recognition1995261Neural networks: the statistical mechanics perspective</p>
<p>Knowledge enhanced event causality identification with mention masking generalizations. J Liu, Y Chen, J Zhao, Proceedings of the twenty-ninth international conference on international joint conferences on artificial intelligence. the twenty-ninth international conference on international joint conferences on artificial intelligence2021</p>
<p>Understanding why neural networks generalize well through gsnr of parameters. J Liu, G Jiang, Y Bai, T Chen, H Wang, arXiv:2001.07384IEEE transactions on information theory. 2822020. 1982arXiv preprintLeast squares quantization in PCM</p>
<p>On the impact of spurious correlation for out-of-distribution detection. Y Ming, H Yin, Y Li, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202236</p>
<p>Learning invariant representations of molecules for atomization energy prediction. G Montavon, K Hansen, S Fazli, M Rupp, F Biegler, A Ziehe, A Tkatchenko, A Lilienfeld, K.-R Müller, Advances in neural information processing systems. 201225</p>
<p>On the role of sparsity and dag constraints for learning linear dags. I Ng, A Ghassami, K Zhang, Advances in Neural Information Processing Systems. 202033</p>
<p>Masked gradient-based causal structure learning. I Ng, S Zhu, Z Fang, H Li, Z Chen, J Wang, W Sussex, S Lorch, L Schölkopf, B Krause, A , arXiv:2406.11601Proceedings of the 2022 SIAM International Conference on Data Mining (SDM). the 2022 SIAM International Conference on Data Mining (SDM)2022. 2024arXiv preprintStandardizing Structural Causal Models</p>
<p>Causal inference by using invariant prediction: identification and intervals. R T O'donnell, A E Nicholson, B Han, K B Korb, M J Alam, L R Hope, Springer, G Parascandolo, A Neitz, A Orvieto, L Gresele, B Schölkopf, J Peters, P Bühlmann, N Meinshausen, arXiv:2009.00329AI 2006: Advances in Artificial Intelligence: 19th Australian Joint Conference on Artificial Intelligence. Hobart, AustraliaCambridge university press2006. December 4-8, 2006. 2020. 2009. 201619arXiv preprintProceedings</p>
<p>Fishr: Invariant gradient variances for out-of-distribution generalization. A Rame, C Dancette, M Cord, International Conference on Machine Learning. PMLR2022</p>
<p>A million variables and more: the fast greedy equivalence search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images. J Ramsey, M Glymour, R Sanchez-Romero, C Glymour, International Journal of Data Science and Analytics. 32017</p>
<p>Beware of the simulated dag! causal discovery benchmarks may be easy to game. A Reisach, C Seiler, S Weichwald, Advances in Neural Information Processing Systems. 342021</p>
<p>A scale-invariant sorting criterion to find a causal order in additive noise models. A Reisach, M Tami, C Seiler, A Chambaz, S Weichwald, Advances in Neural Information Processing Systems. 202436</p>
<p>The Risks of Invariant Risk Minimization. E Rosenfeld, P K Ravikumar, A Risteski, International Conference on Learning Representations. 2021</p>
<p>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. P J Rousseeuw, Journal of computational and applied mathematics. 201987</p>
<p>An investigation of why overparameterization exacerbates spurious correlations. S Sagawa, A Raghunathan, P W Koh, P Liang, International Conference on Machine Learning. PMLR2020</p>
<p>A step towards the applicability of algorithms based on invariant causal learning on observational data. B G Santillan, arXiv:2304.022862023arXiv preprint</p>
<p>Shin, D. 2021. The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI. Y Shi, J Seely, P H Torr, N Siddharth, A Hannun, N Usunier, G Synnaeve, arXiv:2104.09937International journal of human-computer studies. 1461025512021arXiv preprintGradient matching for domain generalization</p>
<p>Causation, prediction, and search. P Spirtes, C Glymour, R Scheines, 2001MIT press</p>
<p>Unbiased look at dataset bias. A Torralba, A A Efros, CVPR 2011. IEEE2011</p>
<p>Generalizing to unseen domains: A survey on domain generalization. J Wang, C Lan, C Liu, Y Ouyang, T Qin, W Lu, Y Chen, W Zeng, S Y Philip, IEEE transactions on knowledge and data engineering. 3582022</p>
<p>Multiscale rotation-invariant convolutional neural networks for lung texture classification. Q Wang, Y Zheng, G Yang, W Jin, X Chen, Y Yin, IEEE journal of biomedical and health informatics. 2212017</p>
<p>DAGs with No Fears: A closer look at continuous optimization for learning Bayesian networks. T Wang, R Sridhar, D Yang, X Wang, D Wei, T Gao, Y Yu, arXiv:2110.07736Advances in Neural Information Processing Systems. 2021. 202033arXiv preprintIdentifying and mitigating spurious correlations for improving robustness in nlp models</p>
<p>Dags with no tears: Continuous optimization for structure learning. J Woodward, Y Yu, J Chen, T Gao, M Yu, Proceedings of the twenty-first international conference on Machine learning. X Zheng, B Aragam, P K Ravikumar, E Xing, the twenty-first international conference on Machine learningOxford university press2005. 2019. 2004. 201811431Advances in neural information processing systems</p>
<p>Learning sparse nonparametric dags. X Zheng, C Dan, B Aragam, P Ravikumar, E Xing, International Conference on Artificial Intelligence and Statistics. Pmlr2020</p>            </div>
        </div>

    </div>
</body>
</html>