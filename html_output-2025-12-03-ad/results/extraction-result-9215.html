<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9215 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9215</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9215</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-269982782</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.14755v3.pdf" target="_blank">Large language models can be zero-shot anomaly detectors for time series?</a></p>
                <p><strong>Paper Abstract:</strong> Recent studies have shown the ability of large language models to perform a variety of tasks, including time series forecasting. The flexible nature of these models allows them to be used for many applications. In this paper, we present a novel study of large language models used for the challenging task of time series anomaly detection. This problem entails two aspects novel for LLMs: the need for the model to identify part of the input sequence (or multiple parts) as anomalous; and the need for it to work with time series data rather than the traditional text input. We introduce sigllm, a framework for time series anomaly detection using large language models. Our framework includes a time-series-to-text conversion module, as well as end-to-end pipelines that prompt language models to perform time series anomaly detection. We investigate two paradigms for testing the abilities of large language models to perform the detection task. First, we present a prompt-based detection method that directly asks a language model to indicate which elements of the input are anomalies. Second, we leverage the forecasting capability of a large language model to guide the anomaly detection process. We evaluated our framework on 11 datasets spanning various sources and 10 pipelines. We show that the forecasting method significantly outperformed the prompting method in all 11 datasets with respect to the F1 score. Moreover, while large language models are capable of finding anomalies, state-of-the-art deep learning models are still superior in performance, achieving results 30% better than large language models.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9215.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9215.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SIGLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SIGLLM (Signals to Language Models) framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that converts univariate time series into text and applies large language models in zero-shot to detect anomalies via two pipelines (PROMPTER and DETECTOR); includes reversible scaling, quantization, rolling-window segmentation, and tokenization tailored per LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-7B-Instruct-v0.2; GPT-3.5-turbo-instruct (used within SIGLLM pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only transformer (pretrained LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Mistral: 7B; GPT-3.5: proprietary size not disclosed</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>univariate time series (converted to textual numerical lists/tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>heterogeneous: satellite telemetry (NASA SMAP, MSL), production system traffic (Yahoo S5 A1-A4), NAB datasets (Art, AWS, AdEx, Traf, Tweets), and other public time series benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>point anomalies and interval (collective) anomalies (varied lengths)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>A timeseries-to-text conversion module (scaling, quantization, digit/token formatting, rolling windows) feeds LLMs in zero-shot; two downstream paradigms implemented: PROMPTER (direct prompting to list anomalies) and DETECTOR (LLM zero-shot forecasting and residual-based anomaly scoring).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Classical statistical: ARIMA, Moving Average (MAvg), Matrix Profile; Deep learning: AER (Auto-encoder with Regression), LSTM DT, LSTM AE, VAE, TadGAN; Transformer-based detector: Anomaly Transformer; commercial: MS Azure anomaly detector</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 score (time-series-aware F1 that counts partial and full interval matching)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Across 492 signals and 2,349 anomalies: average F1 for SIGLLM DETECTOR = 0.525 ± 0.167; PROMPTER Mistral F1 = 0.223 ± 0.104; PROMPTER GPT F1 = 0.133 ± 0.076 (detailed per-dataset in paper Tables 4-5).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>SIGLLM (DETECTOR) outperforms simple moving average baseline (MAvg) on average (+14.6% F1) and outperforms Anomaly Transformer on 7/11 datasets, but falls short of state-of-the-art deep learning (AER) by ~30% (AER mean F1 = 0.753 vs DETECTOR mean F1 = 0.525).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>LLM context-window limits require rolling-window segmentation (inefficient and costly) and can impair capture of long-range trends; performance sensitive to tokenization/format choices (spacing between digits, scaling); zero-shot forecasting can miss non-stationary trend components when window/context is insufficient; costs and latency higher than many dedicated DL models; prompt engineering brittle (GPT repetitive prompt error on identical-value windows); difficulties expanding to multivariate signals.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Converting numeric time series into tailored textual tokenization (scaling + per-digit spacing for GPT, scaling + no-space for Mistral) materially affects LLM performance; LLMs' zero-shot forecasting capability can be repurposed for anomaly detection via residuals (DETECTOR) and outperforms direct anomaly-list prompting (PROMPTER) by large margin; aggregated forecast percentiles (5th/95th), median/mean reconstructions and choice of residual scoring (absolute vs squared) and smoothing significantly affect detection performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models can be zero-shot anomaly detectors for time series?', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9215.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9215.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PROMPTER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PROMPTER pipeline (direct prompting anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A zero-shot prompt-engineering pipeline that feeds a textualized time-series window to an LLM and asks it to list anomalous elements directly; outputs are sampled and aggregated across samples and overlapping windows with α/β filtering thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-7B-Instruct-v0.2; GPT-3.5-turbo-instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only transformer (pretrained LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Mistral: 7B; GPT-3.5: proprietary (size not disclosed)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>textualized numeric lists representing univariate time series windows (tokenized digits/values)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>same heterogeneous benchmark set (NASA SMAP & MSL, Yahoo S5 A1-A4, NAB sub-datasets including Tweets, AdEx, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>point anomalies and short anomalous ranges (LLM outputs point-wise anomalous indices/values)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Construct prompt (role/system + instruction) concatenated with a quantized/scaled window; sample k outputs (k=10) from LLM; collect indices/values the model declared anomalous; an index is labeled anomalous if it appears in ≥α fraction of samples; indices merged across overlapping windows and kept if present in ≥β fraction of windows. Hyperparameters α and β tuned (Mistral best α=0.4, β=0.9; GPT best α=0.2, β=0.9).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against MAvg, ARIMA, Anomaly Transformer, AER and other classic/DL baselines (see SIGLLM description)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 (time-series-specific F1 allowing partial interval credit)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>PROMPTER (Mistral) average Precision = 0.219 ± 0.108, Recall = 0.311 ± 0.213, F1 = 0.223 ± 0.104; PROMPTER (GPT) average Precision = 0.162 ± 0.133, Recall = 0.245 ± 0.191, F1 = 0.133 ± 0.076.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>PROMPTER outperforms simple baselines in selected cases but is substantially worse than DETECTOR and deep-learning SOTA (AER); PROMPTER had low precision and many false positives (average precision 0.219 for Mistral).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High false positive rate and many false alarms; outputs can be inconsistent across LLMs (GPT can output indices but may exceed sequence length; Mistral often outputs values not indices); prompt brittleness (model digression or producing code/explanations if prompt not tightly constrained); repetitive prompt errors with repeated values in GPT (causing many windows to be skipped); aggregation hyperparameters required to mitigate noise.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Direct asking of an LLM to list anomalies is fragile: while it can detect locally extreme values well, it tends to over-report anomalies and misses anomalies that require broader context; filtering via sampling frequency across multiple outputs (α) and across overlapping windows (β) can reduce noise but does not fully resolve false positives; role-based chat templates and constraints (e.g., forcing numeric-only outputs) are necessary for usable outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models can be zero-shot anomaly detectors for time series?', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9215.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9215.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DETECTOR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DETECTOR pipeline (forecasting-based anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A zero-shot forecasting approach: LLMs predict next-horizon values for each window; reconstructed forecasted time series are compared to observed values via residuals (absolute or squared), smoothed and thresholded to detect anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-7B-Instruct-v0.2; small-sample experiments with GPT-3.5-turbo-instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only transformer (pretrained LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Mistral: 7B; GPT-3.5: proprietary</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>univariate time series converted to textual token sequences; overlapping rolling windows used for forecasts</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>same benchmark mixture (NASA SMAP/MSL, Yahoo S5, NAB sub-datasets: Art, AWS, AdEx, Traf, Tweets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>point anomalies and anomalous intervals (detected via unusually large forecast residuals)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>For each window (size w=140 typically), prompt LLM to forecast h=5 future quantized values; sample n outputs per window (n=10) to obtain a distribution per-time-point; aggregate forecasts across overlapping windows (median/mean/percentile) to reconstruct X_hat; compute pointwise residual e_t = |x_t - x_hat_t| or (x_t - x_hat_t)^2, apply exponential moving average smoothing and sliding-window threshold (mean + 4*std) to mark anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to ARIMA, MAvg, Matrix Profile, Anomaly Transformer, AER, LSTM DT, LSTM AE, VAE, TadGAN, MS Azure</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 (time-series-aware F1)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>DETECTOR overall Precision = 0.613 ± 0.184, Recall = 0.514 ± 0.211, F1 = 0.525 ± 0.167 (averaged across datasets). Best reconstruction/scoring varied per dataset; squared-error with smoothing on median forecast often performed best on average.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>DETECTOR outperforms simple Moving Average baseline (+14.6% F1 overall) and outperforms Anomaly Transformer on 7/11 datasets, but underperforms leading deep learning model AER (~30% lower F1). DETECTOR matched or exceeded ARIMA in 4/11 datasets and exceeded MAvg in 6/11 datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Forecasts can fail to capture non-stationary trends if window/context length is insufficient (sensitivity to window size and step); forecasting approach is computationally and monetarily expensive compared to some baselines (DETECTOR average cost per signal in small sample ~$4.3 vs PROMPTER ~$1.69); LLM context window limits force rolling windows which add overhead; forecast uncertainty aggregation choices (median/mean/percentiles) and residual function selection affect detection and require per-dataset tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Repurposing LLM zero-shot forecasting to anomaly detection is effective: residual-based detection (DETECTOR) substantially outperforms direct prompting (PROMPTER). Aggregating multiple sampled forecasts (median, percentiles) and using smoothing + sliding-window local thresholds (mean + 4σ) enables robust detection. Percentile-based reconstructions (5th/95th) sometimes highlight anomalies better than mean/median reconstructions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models can be zero-shot anomaly detectors for time series?', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large language models are zero-shot time series forecasters. <em>(Rating: 2)</em></li>
                <li>Promptcast: A new promptbased learning paradigm for time series forecasting. <em>(Rating: 2)</em></li>
                <li>Forecastpfn: Synthetically-trained zeroshot forecasting. <em>(Rating: 2)</em></li>
                <li>Lag-Llama: Towards foundation models for time series forecasting. <em>(Rating: 2)</em></li>
                <li>Anomaly Transformer: Time series anomaly detection with association discrepancy. <em>(Rating: 2)</em></li>
                <li>AER: Auto-encoder with regression for time series anomaly detection. <em>(Rating: 2)</em></li>
                <li>Time series anomaly detection using generative adversarial networks. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9215",
    "paper_id": "paper-269982782",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "SIGLLM",
            "name_full": "SIGLLM (Signals to Language Models) framework",
            "brief_description": "A pipeline that converts univariate time series into text and applies large language models in zero-shot to detect anomalies via two pipelines (PROMPTER and DETECTOR); includes reversible scaling, quantization, rolling-window segmentation, and tokenization tailored per LLM.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-7B-Instruct-v0.2; GPT-3.5-turbo-instruct (used within SIGLLM pipelines)",
            "model_type": "decoder-only transformer (pretrained LLMs)",
            "model_size": "Mistral: 7B; GPT-3.5: proprietary size not disclosed",
            "data_type": "univariate time series (converted to textual numerical lists/tokens)",
            "data_domain": "heterogeneous: satellite telemetry (NASA SMAP, MSL), production system traffic (Yahoo S5 A1-A4), NAB datasets (Art, AWS, AdEx, Traf, Tweets), and other public time series benchmarks",
            "anomaly_type": "point anomalies and interval (collective) anomalies (varied lengths)",
            "method_description": "A timeseries-to-text conversion module (scaling, quantization, digit/token formatting, rolling windows) feeds LLMs in zero-shot; two downstream paradigms implemented: PROMPTER (direct prompting to list anomalies) and DETECTOR (LLM zero-shot forecasting and residual-based anomaly scoring).",
            "baseline_methods": "Classical statistical: ARIMA, Moving Average (MAvg), Matrix Profile; Deep learning: AER (Auto-encoder with Regression), LSTM DT, LSTM AE, VAE, TadGAN; Transformer-based detector: Anomaly Transformer; commercial: MS Azure anomaly detector",
            "performance_metrics": "Precision, Recall, F1 score (time-series-aware F1 that counts partial and full interval matching)",
            "performance_results": "Across 492 signals and 2,349 anomalies: average F1 for SIGLLM DETECTOR = 0.525 ± 0.167; PROMPTER Mistral F1 = 0.223 ± 0.104; PROMPTER GPT F1 = 0.133 ± 0.076 (detailed per-dataset in paper Tables 4-5).",
            "comparison_to_baseline": "SIGLLM (DETECTOR) outperforms simple moving average baseline (MAvg) on average (+14.6% F1) and outperforms Anomaly Transformer on 7/11 datasets, but falls short of state-of-the-art deep learning (AER) by ~30% (AER mean F1 = 0.753 vs DETECTOR mean F1 = 0.525).",
            "limitations_or_failure_cases": "LLM context-window limits require rolling-window segmentation (inefficient and costly) and can impair capture of long-range trends; performance sensitive to tokenization/format choices (spacing between digits, scaling); zero-shot forecasting can miss non-stationary trend components when window/context is insufficient; costs and latency higher than many dedicated DL models; prompt engineering brittle (GPT repetitive prompt error on identical-value windows); difficulties expanding to multivariate signals.",
            "unique_insights": "Converting numeric time series into tailored textual tokenization (scaling + per-digit spacing for GPT, scaling + no-space for Mistral) materially affects LLM performance; LLMs' zero-shot forecasting capability can be repurposed for anomaly detection via residuals (DETECTOR) and outperforms direct anomaly-list prompting (PROMPTER) by large margin; aggregated forecast percentiles (5th/95th), median/mean reconstructions and choice of residual scoring (absolute vs squared) and smoothing significantly affect detection performance.",
            "uuid": "e9215.0",
            "source_info": {
                "paper_title": "Large language models can be zero-shot anomaly detectors for time series?",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "PROMPTER",
            "name_full": "PROMPTER pipeline (direct prompting anomaly detection)",
            "brief_description": "A zero-shot prompt-engineering pipeline that feeds a textualized time-series window to an LLM and asks it to list anomalous elements directly; outputs are sampled and aggregated across samples and overlapping windows with α/β filtering thresholds.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-7B-Instruct-v0.2; GPT-3.5-turbo-instruct",
            "model_type": "decoder-only transformer (pretrained LLMs)",
            "model_size": "Mistral: 7B; GPT-3.5: proprietary (size not disclosed)",
            "data_type": "textualized numeric lists representing univariate time series windows (tokenized digits/values)",
            "data_domain": "same heterogeneous benchmark set (NASA SMAP & MSL, Yahoo S5 A1-A4, NAB sub-datasets including Tweets, AdEx, etc.)",
            "anomaly_type": "point anomalies and short anomalous ranges (LLM outputs point-wise anomalous indices/values)",
            "method_description": "Construct prompt (role/system + instruction) concatenated with a quantized/scaled window; sample k outputs (k=10) from LLM; collect indices/values the model declared anomalous; an index is labeled anomalous if it appears in ≥α fraction of samples; indices merged across overlapping windows and kept if present in ≥β fraction of windows. Hyperparameters α and β tuned (Mistral best α=0.4, β=0.9; GPT best α=0.2, β=0.9).",
            "baseline_methods": "Compared against MAvg, ARIMA, Anomaly Transformer, AER and other classic/DL baselines (see SIGLLM description)",
            "performance_metrics": "Precision, Recall, F1 (time-series-specific F1 allowing partial interval credit)",
            "performance_results": "PROMPTER (Mistral) average Precision = 0.219 ± 0.108, Recall = 0.311 ± 0.213, F1 = 0.223 ± 0.104; PROMPTER (GPT) average Precision = 0.162 ± 0.133, Recall = 0.245 ± 0.191, F1 = 0.133 ± 0.076.",
            "comparison_to_baseline": "PROMPTER outperforms simple baselines in selected cases but is substantially worse than DETECTOR and deep-learning SOTA (AER); PROMPTER had low precision and many false positives (average precision 0.219 for Mistral).",
            "limitations_or_failure_cases": "High false positive rate and many false alarms; outputs can be inconsistent across LLMs (GPT can output indices but may exceed sequence length; Mistral often outputs values not indices); prompt brittleness (model digression or producing code/explanations if prompt not tightly constrained); repetitive prompt errors with repeated values in GPT (causing many windows to be skipped); aggregation hyperparameters required to mitigate noise.",
            "unique_insights": "Direct asking of an LLM to list anomalies is fragile: while it can detect locally extreme values well, it tends to over-report anomalies and misses anomalies that require broader context; filtering via sampling frequency across multiple outputs (α) and across overlapping windows (β) can reduce noise but does not fully resolve false positives; role-based chat templates and constraints (e.g., forcing numeric-only outputs) are necessary for usable outputs.",
            "uuid": "e9215.1",
            "source_info": {
                "paper_title": "Large language models can be zero-shot anomaly detectors for time series?",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "DETECTOR",
            "name_full": "DETECTOR pipeline (forecasting-based anomaly detection)",
            "brief_description": "A zero-shot forecasting approach: LLMs predict next-horizon values for each window; reconstructed forecasted time series are compared to observed values via residuals (absolute or squared), smoothed and thresholded to detect anomalies.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-7B-Instruct-v0.2; small-sample experiments with GPT-3.5-turbo-instruct",
            "model_type": "decoder-only transformer (pretrained LLMs)",
            "model_size": "Mistral: 7B; GPT-3.5: proprietary",
            "data_type": "univariate time series converted to textual token sequences; overlapping rolling windows used for forecasts",
            "data_domain": "same benchmark mixture (NASA SMAP/MSL, Yahoo S5, NAB sub-datasets: Art, AWS, AdEx, Traf, Tweets)",
            "anomaly_type": "point anomalies and anomalous intervals (detected via unusually large forecast residuals)",
            "method_description": "For each window (size w=140 typically), prompt LLM to forecast h=5 future quantized values; sample n outputs per window (n=10) to obtain a distribution per-time-point; aggregate forecasts across overlapping windows (median/mean/percentile) to reconstruct X_hat; compute pointwise residual e_t = |x_t - x_hat_t| or (x_t - x_hat_t)^2, apply exponential moving average smoothing and sliding-window threshold (mean + 4*std) to mark anomalies.",
            "baseline_methods": "Compared to ARIMA, MAvg, Matrix Profile, Anomaly Transformer, AER, LSTM DT, LSTM AE, VAE, TadGAN, MS Azure",
            "performance_metrics": "Precision, Recall, F1 (time-series-aware F1)",
            "performance_results": "DETECTOR overall Precision = 0.613 ± 0.184, Recall = 0.514 ± 0.211, F1 = 0.525 ± 0.167 (averaged across datasets). Best reconstruction/scoring varied per dataset; squared-error with smoothing on median forecast often performed best on average.",
            "comparison_to_baseline": "DETECTOR outperforms simple Moving Average baseline (+14.6% F1 overall) and outperforms Anomaly Transformer on 7/11 datasets, but underperforms leading deep learning model AER (~30% lower F1). DETECTOR matched or exceeded ARIMA in 4/11 datasets and exceeded MAvg in 6/11 datasets.",
            "limitations_or_failure_cases": "Forecasts can fail to capture non-stationary trends if window/context length is insufficient (sensitivity to window size and step); forecasting approach is computationally and monetarily expensive compared to some baselines (DETECTOR average cost per signal in small sample ~$4.3 vs PROMPTER ~$1.69); LLM context window limits force rolling windows which add overhead; forecast uncertainty aggregation choices (median/mean/percentiles) and residual function selection affect detection and require per-dataset tuning.",
            "unique_insights": "Repurposing LLM zero-shot forecasting to anomaly detection is effective: residual-based detection (DETECTOR) substantially outperforms direct prompting (PROMPTER). Aggregating multiple sampled forecasts (median, percentiles) and using smoothing + sliding-window local thresholds (mean + 4σ) enables robust detection. Percentile-based reconstructions (5th/95th) sometimes highlight anomalies better than mean/median reconstructions.",
            "uuid": "e9215.2",
            "source_info": {
                "paper_title": "Large language models can be zero-shot anomaly detectors for time series?",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large language models are zero-shot time series forecasters.",
            "rating": 2,
            "sanitized_title": "large_language_models_are_zeroshot_time_series_forecasters"
        },
        {
            "paper_title": "Promptcast: A new promptbased learning paradigm for time series forecasting.",
            "rating": 2,
            "sanitized_title": "promptcast_a_new_promptbased_learning_paradigm_for_time_series_forecasting"
        },
        {
            "paper_title": "Forecastpfn: Synthetically-trained zeroshot forecasting.",
            "rating": 2,
            "sanitized_title": "forecastpfn_syntheticallytrained_zeroshot_forecasting"
        },
        {
            "paper_title": "Lag-Llama: Towards foundation models for time series forecasting.",
            "rating": 2,
            "sanitized_title": "lagllama_towards_foundation_models_for_time_series_forecasting"
        },
        {
            "paper_title": "Anomaly Transformer: Time series anomaly detection with association discrepancy.",
            "rating": 2,
            "sanitized_title": "anomaly_transformer_time_series_anomaly_detection_with_association_discrepancy"
        },
        {
            "paper_title": "AER: Auto-encoder with regression for time series anomaly detection.",
            "rating": 2,
            "sanitized_title": "aer_autoencoder_with_regression_for_time_series_anomaly_detection"
        },
        {
            "paper_title": "Time series anomaly detection using generative adversarial networks.",
            "rating": 1,
            "sanitized_title": "time_series_anomaly_detection_using_generative_adversarial_networks"
        }
    ],
    "cost": 0.012035249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large language models can be zero-shot anomaly detectors for time series?
31 Oct 2024</p>
<p>Sarah Alnegheimish 
IRD ESPACE-DEV</p>
<p>Linh Nguyen linhnk@mit.edu 
IRD ESPACE-DEV</p>
<p>Laure Berti-Equille 
IRD ESPACE-DEV</p>
<p>Kalyan Veeramachaneni kalyanv@mit.edu 
IRD ESPACE-DEV</p>
<p>Large language models can be zero-shot anomaly detectors for time series?
31 Oct 2024978F6DCD8CEA460256724F3C91064A06arXiv:2405.14755v3[cs.LG]
Recent studies have shown the ability of large language models to perform a variety of tasks, including time series forecasting.The flexible nature of these models allows them to be used for many applications.In this paper, we present a novel study of large language models used for the challenging task of time series anomaly detection.This problem entails two aspects novel for LLMs: the need for the model to identify part of the input sequence (or multiple parts) as anomalous; and the need for it to work with time series data rather than the traditional text input.We introduce SIGLLM, a framework for time series anomaly detection using large language models.Our framework includes a timeseries-to-text conversion module, as well as end-toend pipelines that prompt language models to perform time series anomaly detection.We investigate two paradigms for testing the abilities of large language models to perform the detection task.First, we present a prompt-based detection method that directly asks a language model to indicate which elements of the input are anomalies.Second, we leverage the forecasting capability of a large language model to guide the anomaly detection process.We evaluated our framework on 11 datasets spanning various sources and 10 pipelines.We show that the forecasting method significantly outperformed the prompting method in all 11 datasets with respect to the F1 score.Moreover, while large language models are capable of finding anomalies, state-of-the-art deep learning models are still superior in performance, achieving results 30% better than large language models.</p>
<p>Introduction</p>
<p>Large language models (LLMs) have demonstrated an outstanding ability to learn natural language tasks implicitly, whether performing reading comprehension, text summarization, translation, or related tasks.Radford et al. [2019]; Brown et al. [2020]; Sanh et al. [2022]; Chowdhery et al. [2023]; Wei et al. [2022].Moreover, LLMs have shown tremendous promise for formal language generation, including code generation and synthesis Xu et al. [2022a]; Austin et al. [2021]; Chen et al. [2021], and in production beyond textual output, such as generating images and videos from natural language descriptions Saharia et al. [2022]; Koh et al. [2023].Testing these models on new tasks and data modalities allows us to push the boundaries of LLMs and discover their value.In this paper, we present a thorough study of LLMs used for the challenging task of anomaly detection from time series data, asking the question Can LLMs become anomaly detectors for time series data?Here, LLMs are exposed to a new data type -time series -and are tasked with a detection task -different from the classification tasks in which they are known to excel at Howard and Ruder [2018].</p>
<p>Recently, Gruver et al. [2023] posited that large language models have an inherent auto-regressive feature which allows them to be effective forecasters.In the study, the authors fed a string representation of a time series sequence to a pretrained LLM.The LLM then generated the next expected values, treating time series forecasting as a next-token prediction task.A follow-up question ari QWERT]śes: Does LLMs' auto-regressive nature allow them to take on more complex tasks, such as anomaly detection?State-of-the-art time series anomaly detection models using deep learning typically include a forecasting model as one of the steps in their process Hundman et al. [2018].</p>
<p>Time series anomaly detection is a regular part of day-today industry operations.Identifying unusual patterns can be a cumbersome and difficult task, especially when massive amounts of signal must be analyzed.If LLMs are genuine anomaly detectors, and can be employed directly in zeroshot (without any additional training), they could serve as off-the-shelf anomaly detectors for users, lifting a considerable amount of this burden.Considering that training deep learning models is time-consuming, skipping this phase could make anomaly detection more efficent overall.</p>
<p>In this paper, we present SIGLLM, a framework for using LLMs to detect anomalies in time series data, with current interaction support for models hosted by OpenAI 1 and Hug-gingFace 2 .Our framework includes a signal-to-text representation component to convert time series data into LLMready input.Moreover, we present two distinct approaches to investigating our main question.First, PROMPTER is a simple and direct prompting method, which elicits LLMs to identify the parts of a sequence it thinks are anomalous.Second, DETECTOR leverages LLMs' ability to forecast time series to find anomalies, by using the residual between the original signal and the forecasted one.</p>
<p>Our findings, captured in Figure 1(left), show that LLMs improve on a simple moving average baseline.Moreover, they outperform transformer-based models such as Anomaly Transformer Xu et al. [2022b].However, there is still a gap between classic and deep learning approaches and LLMs.Furthermore, between our two approaches, DETECTOR is superior to PROMPTER, with an improvement of 135% in F1 Score, as the latter suffers from false positives.We highlight the potential of the DETECTOR approach in Figure 1(right), which showcases an example of an LLM forecast.We can clearly see that the LLM forecast is substantially different from the original signal; this difference is attributed to the presence of anomalies.</p>
<p>We summarize our contributions as follows:</p>
<p>• Propose a new application for LLMs-anomaly detection-and study their efficacy and efficiency for this task.We formalize a new task to present to LLMs; namely, time series anomaly detection in zero-shot.</p>
<p>• Present the SIGLLM framework with a time-seriesto-text representation module and two novel methodologies for solving this task.We present SIGLLM with a module to convert time series data into languagemodel-ready input through a series of reversible transformations.Moreover, we propose two distinct approaches for solving the problem: the PROMPTER pipeline and the DETECTOR pipeline.As of this writing, our framework integrates propriety models such as GPT by OpenAI and open models provided on the Hug-gingFace transformers package.</p>
<p>• Provide a comprehensive and thorough evaluation of LLM performance on this task.We conduct our experiments on two prominent LLM models -GPT-3.5-turboand MISTRAL-7B-Instruct-v0.2 -and 11 datasets.We 1 https://platform.openai.com/docs/models 2 https://huggingface.co/models show that LLMs are able to find anomalies with an average F1 score of 0.525.Moreover, we compare SIGLLM methods to 10 other existing methods including state-ofthe-art models such as AER Wong et al. [2022].</p>
<p>• Publish an open source software.Our code and datasets are publicly available on github: https://github.com/sintel-dev/sigllm.</p>
<p>Background and Related Work</p>
<p>Anomaly Detection Pipelines.Unsupervised machine learning-based anomaly detection pipelines generally follow the same sequence of steps, which roughly consist of pre-processing, modeling, and post-processing abstractions as presented in Figure 2 Alnegheimish et al. [2022].Preprocessing operations include scaling the time series into a specific range, while post-processing includes computing discrepancies between two sequences.A wide variety of models can be trained to learn the features of input data, including Long-Short-Term-Memory models (LSTMs) Hundman et al. [2018], AutoEncoders (AE) Malhotra et al. [2016], Variational AutoEncoders (VAE) Park et al. [2018], Generative Adversarial Networks (GANs) Geiger et al. [2020], and Transformers Xu et al. [2022b]; Tuli et al. [2022].These models perform well on existing benchmarks such as Alnegheimish et al. [2024], surpassing the performance of statistical approaches such as ARIMA Box and Pierce [1970]; Pena et al. [2013].Transformers for Time Series.Transformers can be used directly to reconstruct time series Tuli et al. [2022].Moreover, the attention mechanism can be leveraged to find anomalous sequences Xu et al. [2022b].Recently, more work has emerged adopting transformer-based models for forecasting purposes by pretraining large transformer models on a large corpus of time series data.FORECASTPFN Dooley et al. [2023] pre-trains a basic encoder-decoder transformer with one multi-head attention layer and two feedforward layers on a synthetically generated time series dataset.Similarly, TIMEGPT was pretrained on a large collection of publicly available time series datasets.LAG-LLAMA Rasul et al. [2023] is a decoder-only LLAMA-2 model pretrained on a large corpus of real time series data from diverse domains.Moreover, CHRONOS Ansari et al. [2024] adopts a T5 architecture, and parses time series data into text to pretrain their model.Most of these models were developed with the objective of creating a time series foundation model for time series forecasting.</p>
<p>LLMs for Time Series.The past several months have seen considerable efforts toward LLM utilization for time series data.Given the parallels between predicting the next word in a sentence and predicting the next value in a time series, most of these efforts have focused on time series forecasting.One notable effort is LLMTIME where Gruver et al. [2023] employ GPT Brown et al. [2020], and LLAMA-2 Touvron et al. [2023] models to forecast time series data.PROMPT- CAST Xue and Salim [2023] is a related work that translates a forecasting problem into a prompt, transforming forecasting into a question-answering task.Our Work.In this paper, we work strictly with LLMs that have been pre-trained on text, particularly a proprietary model using GPT-3.5 Brown et al. [2020] and an open source model using MISTRAL Jiang et al. [2023].Our main objective is to determine whether LLMs have the ability to directly uncover anomalies in time series data.Referring back to Figure 2, our methodology focuses on Step 2 onwards -primarily the inference phase.To our knowledge, there is no other work that utilizes large language models as zero-shot anomaly detectors for time series data.We explore two avenues for accomplishing this task: (a) Through the paradigm of prompt engineering; (b) By leveraging LLMs' ability to forecast time series in zero-shot without any additional data or fine-tuning.</p>
<p>Time Series Representation</p>
<p>Time series data can take many different forms.In this paper, we define a univariate time series as X = (x 1 , x 2 , . . ., x T ), where x t ∈ Z ≥0 is the value at time step t, and T is the length of the series.To make a time series LLM-ready, we transform the univariate time series X into a sequence of values that is tokenized.We follow a sequence of reversible steps, beginning with scaling, quantization, and processing the time series into segments using rolling windows, and ending with tokenizing each window.We detail these steps below.Scaling.Time series data includes values of varying numerical magnitudes, and may include both positive and negative values.To standardize the representation and optimize computational efficiency, we subtract the minimum value from the time series x st = x t − min(x 1 , x 2 , . . ., x T ), resulting in a new time series X s = (x s1 , x s2 , . . ., x s T ), where x st ∈ R ≥0 .In other words, we introduced a mapping function: E : R → R ≥0 .This eliminates the need to handle negative values separately.</p>
<p>Other scaling methods, such as min-max scaling, can be utilized to achieve the same goal.However, reducing the set of possible values to a smaller range (e.g.[0, 1]), may cause a loss of information in the quantization step.On the other hand, increasing the range will mean there are more digits to tokenize.With our approach, we simply shift the range of the signal values, which allows us to reduce the number of individual digits that need to be tokenized while maintaining the original gaps between pairs of entries.Moreover, by projecting the values into a non-negative range, we eliminate the need for sign indicator "-/+" and save an additional token.Quantization.Unlike the finite set of vocabulary words used to train LLMs (32k vocab tokens for MISTRAL)3 , the set of scaled time series values x st is infinite, and cannot be processed by language models.Therefore, time series that are to be used with LLMs are generally quantized Ansari et al.</p>
<p>[2024]; Gruver et al. [2023].We use the rounding method, as proposed in in Gruver et al. [2023].Because in some cases the number of decimal digits are redundant given a fixed precision, we round each value up to a predetermined number of decimals, and subsequently scale to an integer format to avoid wasting tokens on the decimal point.Hence, the input time series becomes X q = (x q1 , x q2 , . . ., x q T ), where x qt ∈ Z ≥0 .Below is an example of this operation : 0.2437, 0.3087, 0.002, 0.462 → "244,309,2,462" Overall, we use 2 mapping functions: the scaling function noted E : R → R ≥0 and the quantization function noted Q : R ≥0 → Z ≥0 .Because both mapping functions are reversible up to a certain number of precision digits, we can always reconstruct the input time series:
E −1 Q −1 (x qt ) ≈ x t
Rolling windows.Because there is an upper limit on the context length input to LLMs (e.g., MISTRAL has an upper limit of 32k tokens and GPT-3.5-turbo has a limit of 16k tokens), and there are constraints on GPU memory, a rolling windows technique is employed to manage input data that exceeds these thresholds.This method involves segmenting each time series into rolling windows characterized by predetermined lengths and step sizes; i.e., a processed time series X q is segmented and turned into a set { x i q1...w } N i=1 , where w is the window size and N is the number of windows.For a cleaner notation, we refer to the set as { x i 1...w } N i=1 .We drop q in the notation from this point on, as all the input is now quantized.Tokenization.Different tokenization schemes vary in how they treat numerical values.Several open-source LLMs, such as LLAMA-2 Touvron et al. [2023] and MISTRAL Jiang et al. [2023], utilize the SentencePiece Byte-Pair Encoding tokenizer Touvron et al. [2023], which segments numbers into individual digits.However, the GPT tokenizer tends to segment numbers into chunks that may not correspond directly with the individual digits Liu and Low [2023].For instance, the number 234595678 is segmented into chunks [234,595,678] and assigned token IDs [11727, 22754, 17458].Empirical evidence suggests that this segmentation impedes the LLM's ability to learn patterns in time series data Gruver et al. [2023].To make sure GPT tokenizes each digit separately, we adopt the approach introduced by Gruver et al. [2023], which inserts spaces between the digits in a number.The remaining rows indicate whether scaling and inserting space between digits has occurred during the conversion from signal to text.The gray intervals highlight the anomalies detected under these conditions; thus, we would like to maximize the overlap between the green and gray intervals.Overall we find that "scaling + space" is the configuration that yields a better output for GPT; and "scaling + no space" is better for MISTRAL.Continuing with the running example:</p>
<p>"244,309,2,462" → "2 4 4 , 3 0 9 , 2 , 4 6 2"</p>
<p>Where each digit is now encoded separately.Figure 3 shows how different preprocessing steps affect the output of the model.Overall, we find that scaling reduces the number of tokenized digits, and yields better results than not scaling.Moreover, GPT performs better with added space between digits, while MISTRAL does not.These results accord with the forecasting representation presented in Gruver et al. [2023].</p>
<p>SIGLLM: Detecting Anomalies in Signals using Large Language Models</p>
<p>Given a univariate time series X = (x 1 , x 2 , . . ., x T ), and assuming there exists a set of anomalies of varied length
A = {(t s , t e ) i | 1 ≤ t s &lt; t e ≤ T } m i=1
that is unknown a priori, our goal is to find a set of m anomalous time segments, where t s and t e represent the start and end time points of an anomalous interval.We introduce two fundamentally different methods that can be used for anomaly detection with LLMs: PROMPTER and DETECTOR, as visualized in Fig- ure 4.</p>
<p>PROMPTER: Finding Anomalies through Prompting</p>
<p>As depicted in Figure 4, this pipeline involves querying the LLMs directly for time series anomalies through a text prompt (as shown below) concatenated with the processed time series window
u i 1...k := prompt⊕(x i 1...w ),
where k is the total length of the input after concatenation.LLMs will output the next token u k+1 sampled from an autoregressive distribution conditioned on the previous tokens p θ (u k+1 |u 1...k ).</p>
<p>Following a series of experiments, as shown in Table 1, we iterated over trial #5 and arrived at the following prompt for our study:</p>
<p>"You are an exceptionally intelligent assistant that detects anomalies in time series data by listing all the anomalies.Below is a sequence, please return the anomalies in that sequence.Do not say anything like 'the anomalous indices in the sequence are', just return the numbers.Sequence: {the input sequence (x 1...w )}."</p>
<p>Under this prompt, the LLM generates a list of values it delineates as point-wise anomalies.It is noteworthy that the GPT-3.5-turbomodel is capable of directly outputting anomalous indices using the prompt presented in Table 1, while MISTRAL lacks this ability, as shown in trial #5.To maintain consistency across our experiments, we conducted experiments on both models using the same prompt mentioned above.</p>
<p>As explained in Section III.A, we adopt the rolling windows method, segmenting the time series into rolling windows before inputting it into the LLMs.For each window, we generate 10 samples from the output probability distribution.For each sample containing values deemed anomalous by LLMs, we collect all indices of the window corresponding to those values.Then, the 10 lists of indices are merged together: if an index appears in at least α percent of the total number of samples, it is considered an anomaly.Finally, the lists of detected anomalies from each window are combined to get the final prediction using a similar criterion: an index is considered an anomaly if it appears in at least β percent of the total number of overlapping windows, which are estimated by dividing the window size by the step size.Here, α and β are hyperparameters, which can be tuned to improve performance.</p>
<p>DETECTOR: Finding Anomalies through Forecasting</p>
<p>As depicted in Figure 2, the first step in a typical ML pipeline involves training an ML model on a collection of time series.</p>
<p>From Gruver et al. [2023], pretrained LLMs are capable of forecasting time series, allowing us to jump straight to the inference phase.Pre-processing.As detailed in Section 3, our first step involves transforming a raw input into a textual representation, and creating samples ready for the LLM from the rolling window sequences { x i 1...w } N i=1 .Forecasting.For each given window x i 1...w , we aim to predict the next values (x i w+1...w+h ) where h is the forecast horizon.For ease of notation, the predicted sequence for a window i is noted as x i h , and the lack of i indication means it is applied for all windows.This can be achieved through the next token conditional probability distribution noted p θ (x h | x 1...w and x ∈ Z ≥0 ).With this approach, we give the model the input window (x 1...w ), and sample multiple sequences from the distribution to estimate xh ≈ E −1 (G −1 (x h )).This yields multiple overlapping sequences { xi 1...h } N i=1 at each point in time when h &gt; 1. Post-processing.For each time point t, we now have multiple forecasted values xt in different windows when the horizon is larger than 1, concretely {(x i+h t )}.We take the median from the collection as the final predicted value for xt .Furthermore, to increase the reliability of the prediction, we take n samples from the distribution for each window i.Therefore, each x t has n samples.To map this back to a univariate time series, we explore the results by taking the mean, median, 5 th -percentile, and 95 th -percentile as values.For the purpose of anomaly detection, an extreme forecast value could indicate a precursor to an anomaly; therefore, acute values can be informative (see Section 5.1).Now, we have reconstructed the time series as X = (x 1 , x2 , . . ., xT ).</p>
<p>We next compute the discrepancy between X and X.A large discrepancy indicates the presence of an anomaly.We denote this discrepancy as an error signal e by computing point-wise residuals, given their simplicity and ease of interpretation.We explore the usage of absolute difference suggested by Hundman et al. [2018] e t = |x t − xt |.Moreover, we explore how other functions, such as squared difference e t = (x t − xt ) 2 will help reveal the location of anomalies.More complex functions that capture the difference between Table 1: Examples of prompts used in PROMPTER with their respective observed output.{x1..w} is a placeholder of the actual signal values in the given window.</p>
<p>Trial Prompt</p>
<p>Observed Output 1 {x 1..w }.Find the anomalies of the time series above.</p>
<p>(1) generating code with generic stack overflow code for anomaly detection in python with numpy's convolve 4 or sklearn's IsolationForest 5 .</p>
<p>(2) could not find anomalies (3) produced a vague answer about common approaches to finding anomalies 2 Find the range of indices that are anomalous in this series {x 1..w } or (1) producing a list of indices Given this series {x 1..w }.Find the range of indices that are anomalous</p>
<p>(2) generating code similar to trial #1 (3) could not find anomalies (4) produced a vague answer about common approaches to finding anomalies (5) asked 'do you have any criteria or specific method in mind' (6) confirmed that anomalies are values deviating significantly from the mean.</p>
<p>After confirming, the model digressed from the topic 3 Find the anomalous indices in this series {x ts−100..te+100 }.</p>
<p>(1) producing a list of indices where t s and t e is the index of where the anomalies starts and ends, respectively.(2) could not find anomalies 4</p>
<p>The anomaly indices in timeseries 1 = {x 1..w } 1 is:
{t 1..k } 1 (1) producing a list of indices The anomaly indices in timeseries 2 = {x 1..w } 2 is: {t 1..k } 2
(2) claimed anomalies of timeseries 3 had been given The anomaly indices in timeseries 3 = {x 1..w } 3 is:</p>
<p>(3) could not find anomalies (4) outputted 'Whoa, that's quite a lengthy time series!What can I help you with regarding this data' 5 You are a helpful assitant that performs time series anomaly detection.GPT-3.5-turbo:</p>
<p>(1) producing a list of indices The user will provide a sequence and you will give a list of indices that are</p>
<p>(2) occasionally, words like 'Index:' were included anomalous in the sequence.The sequence is represented by decimal strings</p>
<p>(3) sometimes, the output indices exceeded sequence length separated by commas.Please give a list of indices that are anomalous in the MISTRAL: following sequence without producing any additional text.Do not say anything</p>
<p>(1) produced a list of values.like 'the anomalous indices in the sequence are', just return the numbers.Sequence: {x 1..w } two signals, such as dynamic time warping Müller [2007] can be used.However, Geiger et al. [2020] shows that discrepancies found with point-wise errors are sufficient for this purpose.Moreover, we apply an exponentially weighted moving average to reduce the sensitivity of the detection algorithm Hundman et al. [2018].Error values that surpass the threshold are considered anomalous.We use a sliding window approach to compute the threshold to help reveal contextual anomalies that are abnormal compared to the local neighborhood.As such, we assign the window size and step size to T /3 and T /10 respectively.We set a static threshold for each sliding window as four standard deviations away from the mean.These hyperparameters were chosen based on preliminary empirical results that agree with previous settings in other approaches Hundman et al. [2018]; Geiger et al. [2020]; Wong et al. [2022].</p>
<p>Evaluation</p>
<p>In this section, we assess our framework and seek to answer the following research questions:</p>
<p>• RQ1 Are large language models effective anomaly detectors for univariate time series?</p>
<p>• RQ2 How does the SIGLLM framework compare to existing approaches?</p>
<p>• RQ3 What are the success and failure cases and why?Datasets.We examined SIGLLM on 11 datasets with known ground truth anomalies.These datasets were gathered from a wide range of sources, including a satellite telemetry signal corpus from NASA6 that includes two sub-datasets: SMAP and MSL; Yahoo S57 , which contains four sub-datasets: A1, which is based on real production traffic to Yahoo systems, and three others (A2, A3, and A4) which have been synthetically generated; and NAB8 , which includes multiple types of time series data from various application domains.We consider five sub-datasets: Art, AWS, AdEx, Traf, and Tweets.In total, these datasets contain 492 univariate time series and 2,349 anomalies.The properties of each dataset, including the number of signals and anomalies, the average signal length, and the average length of anomalies, are presented in Table 2.The table makes clear how properties differ between datasets; for instance, the NASA and NAB datasets contain anomalies that are longer than those in Yahoo S5, and the majority of anomalies in Yahoo S5's A3 &amp; A4 datasets are point anomalies.</p>
<p>Models.</p>
<p>We used Mistral-7B-Instruct-v0.2 for PROMPTER and DETECTOR.</p>
<p>Moreover, we used gpt-3.5-turbo-instructfor PROMPTER alone.Due to cost constraints, we explored the usage of GPT for DE-TECTOR on a 5% sample of all datasets, which produced similar results to using MISTRAL.We compared SIGLLM to state-of-the-art models in unsupervised time series anomaly detection.This includes a variety of models similar to the ones considered in Wong et al. [2022]; Alnegheimish et al.</p>
<p>[2022]:</p>
<p>• Classic statistical methods including ARIMA, Matrix Profiling (MP), and a simple Moving Average (MAvg).These models use a wide range of underlying detection methods, which increases our anomaly detection coverage overall.Metrics.We utilized anomaly detection-specific metrics for time series data Tatbul et al. [2018]; Alnegheimish et al. [2022].Namely, we looked at the F1 score, under which both partial and full anomaly detection are considered correct identification.Hyperparameters.For PROMPTER, GPU capacity means that the maximum input window length of SMAP and MSL is 500 values (for other datasets, it is 200 values).We chose a step size such that, on average, a value was contained in 5 overlapping windows (i.e, 100 steps for SMAP and MSL, and 40 for others).For DETECTOR, we set the window size to 140 and the step size to 1.With a rolling window strategy of step size 1, it is important to keep the windows as small as possible while still ensuring that they are large enough to make useful predictions, as more context tends to be useful for LLMs.Our preliminary results suggested that a window size of 140 was as performative as a window size of 200, and was better than a window size of 100.We set the horizon to 5. Computation.For GPT, we used GPT-3.5-turbodue to its superior performance on time series data (demonstrated by Gruver et al. [2023]) and its affordability.For MISTRAL, we used the publicly available model hosted by Hugging-Face 9 on an Intel i9-7920X 24 CPU core processor and 128GB RAM machine with 2 dedicated NVIDIA Titan RTX 24GB GPUs.For benchmarking, we use Intel Xeon processor of 10 CPU cores (9 GB RAM per core) and one NVIDIA Volta V100 GPU with 32 GB memory.</p>
<p>5.1 Are large language models effective anomaly detectors for univariate time series?Ablation Study PROMPTER.The PROMPTER approach originally produced an extremely high number of anomalies.We introduced the α and β hyperparameters to filter the end result.We performed an ablation study to test multiple combinations of α and β values on the F1 score.For some windows, the LLMs consistently outputted more than half of the window values as anomalous; thus, we discarded the predicted results of all windows containing all 10 samples, which was more than 50% of the windows.DETECTOR Since we sampled multiple instances from the probability distribution (namely 10 samples in our experiments), we obtained a possible range of values that could be assigned to each particular point in time.We studied a multiple aggregation function to recreate a one-dimensional signal.</p>
<p>Table 4 shows the detection F1 score when the signal is recreated from mean, median, 5 th -percentile, and 95 th -percentile values of the predicted distribution.Moreover, we consider different error scores under smoothing operation and without.</p>
<p>We can see that, on average, squared error with smoothing on the median signal produced the best score, even though it was not the best performer on any individual dataset.The best configuration proved to be different for almost every dataset, with squared error producing the best results on Yahoo S5, and absolute error on NAB.One interesting observation is that the signal reconstructed from the 5 th /95 thpercentile showcased higher potential in revealing the location of anomalies.In the following section, we aim to address where the LLMs succeeded at this problem and where they fell short.</p>
<p>How does the SIGLLM compare to existing approaches?</p>
<p>What are the success and failure cases and why?</p>
<p>Figures 6 and 7 illustrate example outputs for both the PROMPTER and DETECTOR methods, respectively.We focus on MISTRAL since it yielded better overall results than GPT, as depicted in Table 3. Success Cases.For both signals shown in Figure 7, DETEC-TOR correctly identified all the anomalies, with only one false alarm in the second signal.The PROMPTER approach is able to detect outliers and locally extreme values a lot more effectively than anomalies that are buried within the signal.For example, if the window is "244 , 309 , 2 , 462", both GPT and MISTRAL point to "2" as the observed anomaly.However, this problem becomes more ambiguous when the context is larger.As seen in Figure 6 on Twitter volume AMZN signal, PROMPTER identified some locally extreme values as anomalous.Oddly enough, it also missed some anomalies that were global outliers.Failure Cases.Even though DETECTOR correctly identified all anomalies in the example shown in Figure 7, the forecast itself struggled to capture the non-stationary aspects of the signal, particularly its trend.This is due to the sensitivity of LLMs to context length.A window size larger than 140 is needed to capture this property.While it did not impact the detection in this case, this may explain failure cases in other signals.</p>
<p>PROMPTER raised a large number of false alarms, with an average precision of 0.219.Using the filtering method described in Section 4.1 does not eliminate false positives.An alternative strategy could be to use log probabilities as a measure of confidence for filtering.We recommend exploring this avenue in future work.</p>
<p>Discussion</p>
<p>Prompting Challenges.Over a three-month experimental period, various prompts were employed, as laid out in Table 1.It is evident that both GPT and MISTRAL fail to produce the desired responses unless a chat template is applied that attributes roles to the user and the system.Furthermore, to ensure the exclusivity of numerical values in the generated responses, in addition to specifying in the prompt to "just return numbers," we adjusted the likelihood of non-numerical tokens appearing in the output generated by the LLMs.</p>
<p>Under the 'find indices' prompt, GPT may generate lists of indices; however, these indices frequently surpass the sequence length.Conversely, MISTRAL yields values instead of indices when utilizing the same prompt.Therefore, for our experiment, we altered the prompt to include "find values" rather than "find indices."</p>
<p>Unlike MISTRAL, GPT outputs a "repetitive prompt" error when presented with a series of identical values within a window.This happened particularly for NASA datasets (there are 23 signals in SMAP and 13 in MSL with this error, affecting up to 85% of the windows).In this experiment, we deemed such windows as having no detectable anomalies, obtaining a true positive of zero.Addressing Memorization.Large language models are trained on a vast amount of data.The training data for most models -for instance, those provided by OpenAI -is completely unknown to the general public, which makes evaluating these models a nuanced problem.Given that large language models, especially GPT models Chang et al., are notorious for memorizing training data Biderman et al. [2023], how do we ensure that there was no data and label leakage for the benchmark datasets used?We posit that our transformation of the time series data into its string representation is unique, essentially making the input time series different from its original form and reducing the chances of blatant memorization.Moreover, unlike with the forecasting task, the task of anomaly detection is not inherent to the training convention used, which is next token prediction.Practicality of Usage.The appeal of using LLMs for this task lies in their ability to be used in zero-shot, without necessitating any fine-tuning.However, this property is bottlenecked by the latency time.Figure 8 illustrates the average time it takes to use LLMs for each of the suggested approaches.It is unreasonable to wait half an hour to two hours for the model to produce a response, especially when deep learning models take less than an hour to train.Since these experiments were run in an offline setting, we can ex- pect that real-time deployment would be more sensible, especially since the context size is much smaller, eliminating the need for rolling windows.In other cases, a single window would be sufficient, which takes approximately 5 seconds to infer depending on the window size.In total, running PROMPTER experiments using the gpt-3.5-turbo-instructversion has cost us approximately $834.11 -an average of $1.69 per signal.For DE-TECTOR, we ran a small-scale experiment where we sampled 22 signals of the data, roughly 5%.The total reached $95.08 -an average of $4.3 per signal -making DETECTOR a more expensive method than PROMPTER.</p>
<p>Conclusion</p>
<p>In this paper, we present large language models with a new and challenging task: detecting anomalies in time series data with no prior learning.To this end, we propose two methods, PROMPTER and DETECTOR, covering the prompting and forecasting paradigms respectively.We demonstrate that LLMs can find anomalies through the forecasting paradigm (DETECTOR method) more accurately than they can through the PROMPTER method.We present SIGLLM, a framework for converting signals into text, enabling LLMs to work with time series data.A major weakness of LLMs is their limited context window size.In SIGLLM, we rely on rolling windows to chop the time series up into smaller segments.This is both inefficient and costly.Moreover, it seriously challenges the possibility of expanding the framework to work with multivariate time series.As LLMs rapidly advance, more models can handle larger context sizes; however, they do not yet have the capacity to handle time series data without segmentation.Even with their limited capability, LLMs are able to beat a well-known transformer method, and to approach the performance of classical methods when tested against 492 signals.They fall short of deep learning models by a factor of ×1.2.In anomaly detection, post-processing strategies are critical for revealing the locations of anomalies.In future work, we plan to investigate post-processing functionalities that can help PROMPTER filter false alarms.Similarly, we plan to conduct a thorough exploration of error functions that bring out anomalies for DETECTOR.Twitter_volume_AMZN from realTweets</p>
<p>Figure 1 :
1
Figure 1: (left) F1 Score performances of different model types, compared to a moving average baseline.Each category represents a collection of models that fall under that group.For classic models, we consider ARIMA and Matrix Profiling; for Deep Learning (DL), we utilize AER and LSTM DT; for transformer anomaly detection models, we look at Anomaly Transformer; lastly, for the commercial category, we compare to MS Azure.(right) Illustration of MISTRAL forecasts on E-2 signal from the SMAP dataset.The deviation between the signals can help identify anomalous regions.</p>
<p>Figure 3 :
3
Figure3: Visualizing the output of large language models (GPT and MISTRAL) under different variations of the transformation process.Each row depicts the exchange-2 cpm results signal from the AdEx dataset, where the x-axis shows the timestamp and the y-axis is the signal value.The first row indicates the ground truth anomalies present in the time series (highlighted in green).The remaining rows indicate whether scaling and inserting space between digits has occurred during the conversion from signal to text.The gray intervals highlight the anomalies detected under these conditions; thus, we would like to maximize the overlap between the green and gray intervals.Overall we find that "scaling + space" is the configuration that yields a better output for GPT; and "scaling + no space" is better for MISTRAL.</p>
<p>Figure 4 :
4
Figure4: Anomaly detection methods in the SIGLLM framework.(a) PROMPTER: a prompt engineering approach to elicit large language models to identify parts of the input which are anomalies.(b) DETECTOR: a forecasting approach to use large language models as forecasting methods.DETECTOR then finds discrepencies between the original and forecasted signal, which indicate the presence of anomalies.</p>
<p>Fig 5 shows detection F1 scores from different combinations of α and β values.We observed that on all datasets, for MISTRAL, α = 0.4 and β = 0.9 yielded the best F1 score; for GPT, α = 0.2 and β = 0.9 yielded the best F1 score as shown in Fig 5.</p>
<p>Figure 5 :
5
Figure 5: Optimizing the choice α and β values based on the average F1 scores on all datasets.</p>
<p>Figure 6 :
6
Figure 6:Examples of anomalies identified through PROMPTER.While the model was able to find anomalies, the number of false positives was high, and there were false negatives.</p>
<p>Figure 7 :
7
Figure 7: Examples of anomalies successfully identified by DE-TECTOR.Even though the model did not capture the trend present in synthetic 58, it still managed to find the anomalous intervals.</p>
<p>Figure 8 :
8
Figure 8: Recorded time for PROMPTER and DETECTOR.(left) On average, DETECTOR takes the longest to infer, almost double the time of PROMPTER.(right) Distribution of signal length and execution time.</p>
<p>Figure 2: General principle of how machine learning models find anomalies in an unsupervised setting.Step 1: Apply a sequence of preprocessing operations and train a machine learning model to learn the pattern of the data.This is the most time-consuming step; Step 2: Use the trained model to generate another time series; Step 3: Quantify the error between what the model expects and the original time series value; Step 4: Use this discrepancy to extract anomalies.
Training1Pre-processingModeling...10ML Model...Inference2original signal3Post-processing4ML Modelsignal generatedanomaly error</p>
<p>Table 2 :
2
Dataset Summary: 492 signals and 2349 anomalies.
Dataset# Sub-datasets # Signals # Anomalies Avg. LengthNASA2801038686 ± 5376Yahoo S5436721521561 ± 140NAB545946088 ± 3150Total114922349• Deep learning models currently considered state-of-the-art, including LSTM DT which is a forecasting-based model, LSTM AE, VAE, and TadGAN which arereconstruction-based models, and AER which is a hybridbetween forecasting and reconstruction.• AnomalyTransformer (AT), a transformer archi-tecture model for anomaly detection.• MS Azure, an anomaly detection service.</p>
<p>Table 3 :
3
Summary of Precision, Recall, and F1 Score
PrecisionRecallF1 ScorePROMPTER MISTRAL 0.219 ± 0.108 0.311 ± 0.213 0.223 ± 0.104PROMPTER GPT0.162 ± 0.133 0.245 ± 0.191 0.133 ± 0.076DETECTOR0.613 ± 0.184 0.514 ± 0.211 0.525 ± 0.167</p>
<p>Comparing DETECTOR to AT, which is a transformer-based method, we see DETECTOR outperforms AT in 7 out of the 11 datasets.However, this observation is only relevant to DETECTOR.LLM-based methods can perform surprisingly well.Our methods achieved an F1 score 14.6% higher than that of MAvg, and only 10.9% lower than that of ARIMA which is a reasonable model.Moreover, the DETECTOR pipeline alone surpasses MAvg performance in 6 out of 11 datasets, and ARIMA in 4 out of 11 dataset.We can best see the potential of DETECTOR in the Tweets dataset, where the gap between the LLM's result and the highest result (from MAvg) is minimal, at only 1.8%.AER, the current best deep learning model, is 30% better than LLM-based approaches.Deep learning methods still perform better than LLM-based methods by 18% on average.Looking more closely at DETECTOR shows that it does not perform as well as deep learning models, achieving a 30% lower score than that of the highest performing model (AER) and a 5% lower score than the that of least performative model (VAE).Moreover, LLMs do not hold the highest score for any dataset.It is clear that there is a significant gap here, and an opportunity for improvement.
Table 5 highlights the F1 score obtained for each of the 11datasets.LLM-based methods can outperform transformer-basedmethods by 12.5%.</p>
<p>Table 4 :
4
F1 Score of all variations of DETECTOR
NASAYahoo S5NABVariationMSL SMAPA1A2A3A4ArtAWS AdEx Traf Tweetsµ ± σmean0.277 0.384 0.537 0.387 0.000 0.000 0.400 0.329 0.640 0.444 0.586 0.362 ± 0.199with smoothingmedian 0.269 0.384 0.538 0.387 0.000 0.000 0.400 0.312 0.696 0.480 0.593 0.369 ± 0.210 5% 0.294 0.400 0.542 0.387 0.000 0.000 0.400 0.308 0.727 0.417 0.615 0.372 ± 0.214AE95%0.254 0.396 0.532 0.387 0.004 0.005 0.400 0.289 0.696 0.348 0.655 0.361 ± 0.214mean0.412 0.350 0.563 0.762 0.060 0.129 0.235 0.282 0.625 0.368 0.325 0.374 ± 0.200w/o smoothingmedian 0.412 0.337 0.572 0.762 0.060 0.127 0.235 0.286 0.625 0.359 0.333 0.373 ± 0.201 5% 0.429 0.353 0.564 0.759 0.040 0.123 0.235 0.284 0.621 0.400 0.350 0.378 ± 0.20395%0.406 0.337 0.608 0.765 0.114 0.167 0.235 0.288 0.600 0.387 0.342 0.386 ± 0.190mean0.316 0.414 0.551 0.673 0.004 0.016 0.364 0.344 0.643 0.424 0.719 0.406 ± 0.228with smoothingmedian 0.316 0.414 0.560 0.671 0.008 0.016 0.364 0.352 0.667 0.412 0.730 0.410 ± 0.232 5% 0.333 0.400 0.552 0.662 0.000 0.014 0.364 0.362 0.621 0.400 0.730 0.403 ± 0.227SE95%0.306 0.431 0.577 0.688 0.023 0.064 0.364 0.318 0.593 0.345 0.762 0.406 ± 0.225mean0.344 0.257 0.567 0.828 0.324 0.315 0.333 0.279 0.541 0.280 0.220 0.390 ± 0.174w/o smoothingmedian 0.344 0.247 0.583 0.824 0.323 0.315 0.333 0.281 0.541 0.259 0.220 0.388 ± 0.176 5% 0.358 0.241 0.563 0.828 0.294 0.290 0.333 0.279 0.556 0.286 0.220 0.386 ± 0.17895%0.390 0.238 0.615 0.796 0.376 0.363 0.235 0.287 0.588 0.293 0.246 0.402 ± 0.176Table 5: Benchmark Summary Results depicting F1 Score.NASAYahoo S5NABPipelineMSL SMAPA1A2A3A4ArtAWS AdEx Traf Tweetsµ ± σAER0.587 0.819 0.799 0.987 0.892 0.709 0.714 0.741 0.690 0.703 0.638 0.753 ± 0.109LSTM DT0.471 0.726 0.728 0.985 0.744 0.646 0.400 0.468 0.786 0.585 0.603 0.649 ± 0.161ARIMA0.525 0.411 0.728 0.856 0.797 0.686 0.308 0.382 0.727 0.467 0.514 0.582 ± 0.176MP0.474 0.423 0.507 0.897 0.793 0.825 0.571 0.440 0.692 0.305 0.343 0.570 ± 0.193TadGAN0.560 0.605 0.578 0.817 0.416 0.340 0.500 0.623 0.818 0.452 0.554 0.569 ± 0.142LSTM AE0.545 0.662 0.595 0.867 0.466 0.239 0.667 0.741 0.500 0.500 0.475 0.569 ± 0.158VAE0.494 0.613 0.592 0.803 0.438 0.230 0.667 0.689 0.583 0.483 0.533 0.557 ± 0.143AT0.400 0.266 0.571 0.565 0.760 0.576 0.414 0.430 0.500 0.371 0.287 0.467 ± 0.138MAvg0.171 0.092 0.713 0.356 0.647 0.615 0.222 0.408 0.880 0.157 0.776 0.458 ± 0.266MS Azure0.051 0.019 0.280 0.653 0.702 0.344 0.056 0.112 0.163 0.117 0.176 0.243 ± 0.225PROMPTER MISTRAL 0.160 0.154 0.194 0.235 0.338 0.336 0.370 0.268 0.000 0.135 0.257 0.223 ± 0.104PROMPTER GPT0.049 0.110 0.143 0.078 0.157 0.195 0.154 0.194 0.133 0.133 0.197 0.133 ± 0.076DETECTOR0.429 0.431 0.615 0.828 0.376 0.363 0.400 0.362 0.727 0.480 0.762 0.525 ± 0.167
The exact vocabulary size for GPT-3.5-turbo has not been released by OpenAI.
https://numpy.org/doc/stable/reference/generated/numpy. convolve.html
https://scikit-learn.org/stable/modules/generated/sklearn. ensemble.IsolationForest.html
https://github.com/khundman/telemanom
https://webscope.sandbox.yahoo.com/catalog.php?datatype= s&amp;did=70
https://github.com/numenta/NAB
After running the models on the full datasets, we computed the precision, recall, and F1 scores, shown in Table 3. Overall, MISTRAL achieved better results than GPT for the PROMPTER method, with a 2× improvement in F1 score. In addition, DETECTOR performed better overall than PROMPTER. We investigate each approach below. 9 https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
AcknowledgmentsOur research is supported by SES S.A., Iberdrola and Scot-tishPower Renewables, and Hyundai Motor Company.Change LogUpdated the acknowledgment section.Removed the previous version which had acknowledgements to the folks who had helped create the IJCAI template.
Sintel: A machine learning framework to extract insights from signals. Sarah Alnegheimish, Proceedings of the 2022 International Conference on Management of Data, SIGMOD '22. the 2022 International Conference on Management of Data, SIGMOD '22New York, NY, USAAssociation for Computing Machinery2022</p>
<p>Making the end-user a priority in benchmarking: Orionbench for unsupervised time series anomaly detection. Sarah Alnegheimish, 2024</p>
<p>Abdul Fatir, Ansari , arXiv:2403.07815Learning the language of time series. 2024arXiv preprint</p>
<p>Program synthesis with large language models. Jacob Austin, 2021</p>
<p>Emergent and predictable memorization in large language models. Stella Biderman, Advances in Neural Information Processing Systems. 202336</p>
<p>Distribution of residual autocorrelations in autoregressive-integrated moving average time series models. E P George, David A Box, Pierce, Journal of the American statistical Association. 653321970</p>
<p>Language models are few-shot learners. Tom Brown, Advances in Neural Information Processing Systems. Curran Associates, Inc202033</p>
<p>Speak, memory: An archaeology of books known to ChatGPT/GPT-4. Kent Chang, EMNLP 2023. </p>
<p>Evaluating large language models trained on code. Mark Chen, 2021</p>
<p>Palm: Scaling language modeling with pathways. Aakanksha Chowdhery, Journal of Machine Learning Research. 242402023</p>
<p>Forecastpfn: Synthetically-trained zeroshot forecasting. Samuel Dooley, Advances in Neural Information Processing Systems. Curran Associates, Inc202336</p>
<p>Time series anomaly detection using generative adversarial networks. Alexander Geiger, 2020 IEEE International Conference on Big Data (Big Data). IEEE2020</p>
<p>Large language models are zero-shot time series forecasters. Nate Gruver, Advances in Neural Information Processing Systems. 202336</p>
<p>Universal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational LinguisticsJuly 20181</p>
<p>Detecting spacecraft anomalies using LSTMs and nonparametric dynamic thresholding. Kyle Hundman, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining2018</p>
<p>. Albert Q Jiang, Mistral 7b, 2023</p>
<p>Generating images with multimodal language models. Jing Yu, Koh , Advances in Neural Information Processing Systems. Curran Associates, Inc202336</p>
<p>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks. Tiedong Liu, Bryan Kian, Hsiang Low, 2023</p>
<p>Meinard Müller. Dynamic time warping. Information retrieval for music and motion. Pankaj Malhotra, arXiv:1607.001482016. 2007arXiv preprintLSTM-based encoder-decoder for multi-sensor anomaly detection</p>
<p>A multimodal anomaly detector for robot-assisted feeding using an LSTM-based variational autoencoder. Daehyung Park, IEEE Robotics and Automation Letters. 332018</p>
<p>Anomaly detection using forecasting methods ARIMA and HWDS. H M Eduardo, Pena, 2013 32nd International Conference of the Chilean Computer Science Society (sccc). IEEE2013</p>
<p>Language models are unsupervised multitask learners. Alec Radford, OpenAI blog. 1892019</p>
<p>Lag-Llama: Towards foundation models for time series forecasting. Kashif Rasul, arXiv:2310.082782023arXiv preprint</p>
<p>Photorealistic text-to-image diffusion models with deep language understanding. Chitwan Saharia, Advances in Neural Information Processing Systems. Curran Associates, Inc202235</p>
<p>Multitask prompted training enables zeroshot task generalization. Victor Sanh, International Conference on Learning Representations. 2022</p>
<p>Precision and recall for time series. Nesime Tatbul, Advances in Neural Information Processing Systems. Curran Associates, Inc2018</p>
<p>Llama 2: Open foundation and finetuned chat models. Hugo Touvron, 2023</p>
<p>Tranad: deep transformer networks for anomaly detection in multivariate time series data. Shreshth Tuli, Proc. VLDB Endow. VLDB Endowfeb 202215</p>
<p>Emergent abilities of large language models. Jason Wei, Transactions on Machine Learning Research. 2022Survey Certification</p>
<p>AER: Auto-encoder with regression for time series anomaly detection. Lawrence Wong, 2022 IEEE International Conference on Big Data (Big Data). IEEE2022</p>
<p>A systematic evaluation of large language models of code. F Frank, Xu, Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming. the 6th ACM SIGPLAN International Symposium on Machine Programming2022</p>
<p>Anomaly Transformer: Time series anomaly detection with association discrepancy. Jiehui Xu, International Conference on Learning Representations. 2022</p>
<p>Promptcast: A new promptbased learning paradigm for time series forecasting. Hao Xue, Flora D Salim, 2023</p>            </div>
        </div>

    </div>
</body>
</html>