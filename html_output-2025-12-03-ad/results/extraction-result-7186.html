<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7186 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7186</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7186</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-135.html">extraction-schema-135</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <p><strong>Paper ID:</strong> paper-d299a6b26e9ee23d0337a1d1a896fc1c847f5a46</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d299a6b26e9ee23d0337a1d1a896fc1c847f5a46" target="_blank">InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This paper proposes InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment, and proposes a structured format verbalizer to unify all graph data into a universal code-like format.</p>
                <p><strong>Paper Abstract:</strong> Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders. Furthermore, a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks. Finally, we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment, the target of which is to enhance the output's reliability of the model. Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than 13\% and 38\%, respectively.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7186.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7186.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Code-format / Structured Format Verbalizer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured Format Verbalizer (code-like graph serialization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A code-like, structured textual serialization that lists graph entities and edges as programmatic variables (e.g., entity_list/node_list and triple_list/edge_list), with optional property assignments (e.g., Node.prop = value) to represent node attributes; used as the canonical input/output text format for instruction tuning of LLMs in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Structured format verbalizer (code-like graph language)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Encodes a graph into a code-like sequence where nodes/entities are serialized as a list variable (node_list or entity_list) and edges/triples as another list variable (edge_list or triple_list). Optional textual properties are encoded via object-like assignments (e.g., User1.review = "The film is nice."). The whole graph is presented as a contiguous textual code block that an LLM can both parse and generate.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential; token-based; code-like; (intended to be lossless in preserving explicit node and edge lists)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Edge-list / entity-list serialization (no traversal specified): nodes are listed, then triples/edges are listed as tuple entries; properties serialized as object-like attribute assignments. (The paper maps G -> C via M(G) where M is this verbalizer.)</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Multiple (instruction corpus compiled from 29 graph tasks including WebNLG, GenWiki, Wikipedia/Wikidata, PathQSP, NLGraph, UIE, Wikidata, FB15K-237, ConceptNet, Cora, Citeseer, Pubmed, ArXiv, Products, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Graph instruction tuning for graph reasoning and graph generation (graph structure modeling, graph language modeling/captioning, graph generation modeling, evaluated across many downstream tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>InstructGraph-INS (LLaMA2-7B-HF backbone instruction-tuned), InstructGraph-PRE (preference-aligned variant); compared with LLaMA2, Vicuna, GPT-3.5, GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Backbone primarily LLaMA2-7B-HF fine-tuned with parameter-efficient LoRA (rank=32) for instruction tuning (max length 2048); comparisons include larger and closed models (GPT-3.5, GPT-4) and other open 7B/13B variants (LLaMA2, Vicuna). InstructGraph-PRE further applies DPO-style preference alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Various task-specific metrics reported across tasks: overall average accuracy/score (%), task metrics such as ACC, BLEU, EM, Hits@1, F1, and perplexity-based preference accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Representative outcomes reported: InstructGraph-INS average over graph instruction tasks = 79.84% (Table 2) vs GPT-4 66.76% and LLaMA2 41.65%; specific task examples comparing code-format to template (Table 7): PathQSP (code-format 68.64% vs template 58.20 on GPT-4 prompts), WebNLG (code-format 99.29% vs template 96.13 on GPT-4 prompts), LLaMA2 PathQSP (code-format 42.70% vs template 20.36). Preference alignment: InstructGraph-PRE average preference accuracy = 82.02% vs InstructGraph-INS 72.32% and LLaMA2 55.88% (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Using the code-like representation enabled direct reuse of the standard causal language modeling objective for instruction tuning, improved downstream graph reasoning and generation accuracy (substantial gains across many tasks), and produced outputs that are easier to parse back into graph structures compared to natural-language templates; allowed parameter-efficient tuning (LoRA) to be effective.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Paper does not report canonical ordering or a deterministic canonicalization procedure (ordering may vary); average token cost per graph not reported (potential verbosity for large/complex graphs); InstructGraph still underperforms very large models (GPT-3.5/GPT-4) on some tasks that rely on broad memorized knowledge (e.g., Degree Computing, WebNLG, GenWiki, WikiTQ, Citeseer). Manual instruction templates were designed per dataset (i.e., dataset-specific instruction design required).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to heuristic natural-language graph descriptions (templates) and embedding-fusion or GNN-injection approaches, the code-format preserves explicit nodes/triples and is easier for LLMs to parse/emit (empirically better in the paper). Compared to graph embeddings or injecting GNN features, code-format avoids embedding-induced information loss and does not require external graph encoders; compared to templates, code-format yields higher graph generation capability (templates sometimes failed to support generation).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7186.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7186.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heuristic Template / Natural-language Graph Description</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heuristic natural-language graph description (template-based verbalizer, e.g., InstructGLM-style templates)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A natural-language textual verbalization that describes graph structure in sentence form using handcrafted templates (e.g., describing paths as 'e1 is connected with e3 within two hops through e2, and featured relations r1 and r2'); used as a baseline graph-to-text representation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Natural language is all a graph needs.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Template-based natural-language graph description</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Encodes graph structure into human-readable sentences via manually designed templates that describe relations and paths in natural language rather than a code-like serialized list; typically requires many templates to cover different graph constructs and tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential; natural-language (lossy for exact reconstruction in many cases); template-driven</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Heuristic template rendering of graph features (e.g., path-based descriptions), not a strict list/tuple serialization; often describes paths or relations in prose rather than raw triples.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Used as a baseline on the same evaluation tasks (PathQSP, WebNLG, CoRA, UIE) in comparisons (Table 7); related to datasets used in Ye et al. 2023 and other benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Prompting LLMs for graph understanding and generation using natural-language templates (graph-to-text for reasoning and captioning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Baseline prompts applied to LLaMA2 and GPT-4 in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not a model per se; evaluated as an input prompt/verbalization applied to LLaMA2 and GPT-4 to assess how natural-language templates compare to code-format serialization.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Same task metrics as code-format baselines (ACC, BLEU, EM, F1, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported baseline template scores (Table 7): GPT-4 PathQSP template 58.20% vs code-format 68.64%; GPT-4 WebNLG template 96.13% vs code-format 99.29%; LLaMA2 PathQSP template 20.36% vs code-format 42.70%; Template often produced 0.00% on some generation tasks (UIE) for LLaMA2 where code-format achieved non-zero results.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Template-based verbalization can enable LLMs to consume graph information without model fine-tuning, but requires many manual templates and was found less effective for graph generation and for enabling deterministic graph reconstruction in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires a large number of manual templates to cover diverse graph phenomena; tends to be less suitable for generating code-like graph outputs that can be straightforwardly parsed back into structured graphs; in experiments templates sometimes failed to support graph generation for some LLMs (e.g., LLaMA2 produced 0% on UIE with templates).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Paper reports that code-like structured verbalizer outperforms template-based natural language descriptions across evaluated tasks, offering better generation fidelity and easier parsing back into graphs; template methods can be effective for some captioning tasks on very large models (GPT-4) but are overall weaker and more labor-intensive to design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Natural language is all a graph needs. <em>(Rating: 2)</em></li>
                <li>GraphLLM: Boosting graph reasoning ability of large language model <em>(Rating: 2)</em></li>
                <li>Graphtext: Graph reasoning in text space <em>(Rating: 2)</em></li>
                <li>GenWiki: A dataset of 1.3 million content-sharing text and graphs for unsupervised graph-to-text generation <em>(Rating: 1)</em></li>
                <li>WebNLG: Creating training corpora for NLG micro-planners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7186",
    "paper_id": "paper-d299a6b26e9ee23d0337a1d1a896fc1c847f5a46",
    "extraction_schema_id": "extraction-schema-135",
    "extracted_data": [
        {
            "name_short": "Code-format / Structured Format Verbalizer",
            "name_full": "Structured Format Verbalizer (code-like graph serialization)",
            "brief_description": "A code-like, structured textual serialization that lists graph entities and edges as programmatic variables (e.g., entity_list/node_list and triple_list/edge_list), with optional property assignments (e.g., Node.prop = value) to represent node attributes; used as the canonical input/output text format for instruction tuning of LLMs in this work.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Structured format verbalizer (code-like graph language)",
            "representation_description": "Encodes a graph into a code-like sequence where nodes/entities are serialized as a list variable (node_list or entity_list) and edges/triples as another list variable (edge_list or triple_list). Optional textual properties are encoded via object-like assignments (e.g., User1.review = \"The film is nice.\"). The whole graph is presented as a contiguous textual code block that an LLM can both parse and generate.",
            "representation_type": "sequential; token-based; code-like; (intended to be lossless in preserving explicit node and edge lists)",
            "encoding_method": "Edge-list / entity-list serialization (no traversal specified): nodes are listed, then triples/edges are listed as tuple entries; properties serialized as object-like attribute assignments. (The paper maps G -&gt; C via M(G) where M is this verbalizer.)",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "Multiple (instruction corpus compiled from 29 graph tasks including WebNLG, GenWiki, Wikipedia/Wikidata, PathQSP, NLGraph, UIE, Wikidata, FB15K-237, ConceptNet, Cora, Citeseer, Pubmed, ArXiv, Products, etc.)",
            "task_name": "Graph instruction tuning for graph reasoning and graph generation (graph structure modeling, graph language modeling/captioning, graph generation modeling, evaluated across many downstream tasks)",
            "model_name": "InstructGraph-INS (LLaMA2-7B-HF backbone instruction-tuned), InstructGraph-PRE (preference-aligned variant); compared with LLaMA2, Vicuna, GPT-3.5, GPT-4",
            "model_description": "Backbone primarily LLaMA2-7B-HF fine-tuned with parameter-efficient LoRA (rank=32) for instruction tuning (max length 2048); comparisons include larger and closed models (GPT-3.5, GPT-4) and other open 7B/13B variants (LLaMA2, Vicuna). InstructGraph-PRE further applies DPO-style preference alignment.",
            "performance_metric": "Various task-specific metrics reported across tasks: overall average accuracy/score (%), task metrics such as ACC, BLEU, EM, Hits@1, F1, and perplexity-based preference accuracy.",
            "performance_value": "Representative outcomes reported: InstructGraph-INS average over graph instruction tasks = 79.84% (Table 2) vs GPT-4 66.76% and LLaMA2 41.65%; specific task examples comparing code-format to template (Table 7): PathQSP (code-format 68.64% vs template 58.20 on GPT-4 prompts), WebNLG (code-format 99.29% vs template 96.13 on GPT-4 prompts), LLaMA2 PathQSP (code-format 42.70% vs template 20.36). Preference alignment: InstructGraph-PRE average preference accuracy = 82.02% vs InstructGraph-INS 72.32% and LLaMA2 55.88% (Table 3).",
            "impact_on_training": "Using the code-like representation enabled direct reuse of the standard causal language modeling objective for instruction tuning, improved downstream graph reasoning and generation accuracy (substantial gains across many tasks), and produced outputs that are easier to parse back into graph structures compared to natural-language templates; allowed parameter-efficient tuning (LoRA) to be effective.",
            "limitations": "Paper does not report canonical ordering or a deterministic canonicalization procedure (ordering may vary); average token cost per graph not reported (potential verbosity for large/complex graphs); InstructGraph still underperforms very large models (GPT-3.5/GPT-4) on some tasks that rely on broad memorized knowledge (e.g., Degree Computing, WebNLG, GenWiki, WikiTQ, Citeseer). Manual instruction templates were designed per dataset (i.e., dataset-specific instruction design required).",
            "comparison_with_other": "Compared to heuristic natural-language graph descriptions (templates) and embedding-fusion or GNN-injection approaches, the code-format preserves explicit nodes/triples and is easier for LLMs to parse/emit (empirically better in the paper). Compared to graph embeddings or injecting GNN features, code-format avoids embedding-induced information loss and does not require external graph encoders; compared to templates, code-format yields higher graph generation capability (templates sometimes failed to support generation).",
            "uuid": "e7186.0",
            "source_info": {
                "paper_title": "InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Heuristic Template / Natural-language Graph Description",
            "name_full": "Heuristic natural-language graph description (template-based verbalizer, e.g., InstructGLM-style templates)",
            "brief_description": "A natural-language textual verbalization that describes graph structure in sentence form using handcrafted templates (e.g., describing paths as 'e1 is connected with e3 within two hops through e2, and featured relations r1 and r2'); used as a baseline graph-to-text representation.",
            "citation_title": "Natural language is all a graph needs.",
            "mention_or_use": "use",
            "representation_name": "Template-based natural-language graph description",
            "representation_description": "Encodes graph structure into human-readable sentences via manually designed templates that describe relations and paths in natural language rather than a code-like serialized list; typically requires many templates to cover different graph constructs and tasks.",
            "representation_type": "sequential; natural-language (lossy for exact reconstruction in many cases); template-driven",
            "encoding_method": "Heuristic template rendering of graph features (e.g., path-based descriptions), not a strict list/tuple serialization; often describes paths or relations in prose rather than raw triples.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "Used as a baseline on the same evaluation tasks (PathQSP, WebNLG, CoRA, UIE) in comparisons (Table 7); related to datasets used in Ye et al. 2023 and other benchmarks.",
            "task_name": "Prompting LLMs for graph understanding and generation using natural-language templates (graph-to-text for reasoning and captioning)",
            "model_name": "Baseline prompts applied to LLaMA2 and GPT-4 in experiments",
            "model_description": "Not a model per se; evaluated as an input prompt/verbalization applied to LLaMA2 and GPT-4 to assess how natural-language templates compare to code-format serialization.",
            "performance_metric": "Same task metrics as code-format baselines (ACC, BLEU, EM, F1, etc.)",
            "performance_value": "Reported baseline template scores (Table 7): GPT-4 PathQSP template 58.20% vs code-format 68.64%; GPT-4 WebNLG template 96.13% vs code-format 99.29%; LLaMA2 PathQSP template 20.36% vs code-format 42.70%; Template often produced 0.00% on some generation tasks (UIE) for LLaMA2 where code-format achieved non-zero results.",
            "impact_on_training": "Template-based verbalization can enable LLMs to consume graph information without model fine-tuning, but requires many manual templates and was found less effective for graph generation and for enabling deterministic graph reconstruction in the experiments.",
            "limitations": "Requires a large number of manual templates to cover diverse graph phenomena; tends to be less suitable for generating code-like graph outputs that can be straightforwardly parsed back into structured graphs; in experiments templates sometimes failed to support graph generation for some LLMs (e.g., LLaMA2 produced 0% on UIE with templates).",
            "comparison_with_other": "Paper reports that code-like structured verbalizer outperforms template-based natural language descriptions across evaluated tasks, offering better generation fidelity and easier parsing back into graphs; template methods can be effective for some captioning tasks on very large models (GPT-4) but are overall weaker and more labor-intensive to design.",
            "uuid": "e7186.1",
            "source_info": {
                "paper_title": "InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Natural language is all a graph needs.",
            "rating": 2
        },
        {
            "paper_title": "GraphLLM: Boosting graph reasoning ability of large language model",
            "rating": 2
        },
        {
            "paper_title": "Graphtext: Graph reasoning in text space",
            "rating": 2
        },
        {
            "paper_title": "GenWiki: A dataset of 1.3 million content-sharing text and graphs for unsupervised graph-to-text generation",
            "rating": 1
        },
        {
            "paper_title": "WebNLG: Creating training corpora for NLG micro-planners",
            "rating": 1
        }
    ],
    "cost": 0.015071,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment</h1>
<p>Jianing Wang ${ }^{1,2 *}$, Junda $\mathbf{W u}^{2}$, Yupeng Hou ${ }^{2}$, Yao Liu ${ }^{1 \dagger}$, Ming Gao ${ }^{1}$, Julian McAuley ${ }^{2}$<br>${ }^{1}$ East China Normal University, Shanghai, China<br>${ }^{2}$ University of California San Diego, La Jolla, USA<br>lygwjn@gmail.com, {juw069, yphou}@ucsd.edu<br>liuyao@cc.ecnu.edu.cn, mgao@dase.ecnu.edu.cn, jmcauley@ucsd.edu</p>
<h4>Abstract</h4>
<p>Do current large language models (LLMs) better solve graph reasoning and generation tasks with parameter updates? In this paper, we propose InstructGraph, a framework that empowers LLMs with the abilities of graph reasoning and generation by instruction tuning and preference alignment. Specifically, we first propose a structured format verbalizer to unify all graph data into a universal code-like format, which can simply represent the graph without any external graph-specific encoders. Furthermore, a graph instruction tuning stage is introduced to guide LLMs in solving graph reasoning and generation tasks. Finally, we identify potential hallucination problems in graph tasks and sample negative instances for preference alignment, the target of which is to enhance the output's reliability of the model. Extensive experiments across multiple graph-centric tasks exhibit that InstructGraph can achieve the best performance and outperform GPT-4 and LLaMA2 by more than $13 \%$ and $38 \%$, respectively ${ }^{1}$.</p>
<h2>1 Introduction</h2>
<p>Currently, large language models (LLMs) have succeeded in reasoning on textual data (Brown et al., 2020; OpenAI, 2023a; Touvron et al., 2023b; Zhao et al., 2023c). However, there also exists rich information in graph data, that is difficult to represent using plain text (Jin et al., 2023), such as knowledge graphs (Schneider et al., 2022), symbolic graphs (Saba, 2023), social networks (Wang et al., 2023d), and implicit mind graphs (Besta et al., 2023).</p>
<p>To endow LLMs with the ability to solve graph tasks, a series of works focus on designing the interface (e.g., prompt engineering) of LLMs on graph</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>data to make them understand the semantics without parameter optimization (Ye et al., 2023; Han et al., 2023; Zhang et al., 2023b; Zhang, 2023; Kim et al., 2023; Jiang et al., 2023; Wang et al., 2023b; Luo et al., 2023), or injecting the graph embeddings into the partial parameters of LLMs through graph neural networks (GNNs) (Zhang et al., 2022; Chai et al., 2023; Tang et al., 2023; Perozzi et al., 2024). Despite significant progress, we explore these two challenges: 1) There still exists a semantic gap between graph and text, which may impede the LLM in graph reasoning and generation. 2) LLMs tend to generate hallucinations which may be caused by fabricated erroneous inputs or lack of pertinent knowledge. It can be viewed as the graph hallucination problem.</p>
<p>To overcome these challenges, we present a framework named InstructGraph that boosts LLMs by instruction tuning and preference alignment. A straightforward approach to solve the first challenge is to use a graph description (Ye et al., 2023) or graph embeddings (Chai et al., 2023), However, these methods require a large number of manual templates to describe the graph. Representing a large or complex graph via embeddings may cause information loss. In addition, the responses generated by the LLM with these methods are difficult to parse into actual graphs (Jin et al., 2023; Zhao et al., 2023c). Current investigations have demonstrated that LLMs have a great ability for code understanding and generation (Gao et al., 2023; Ma et al., 2023; Wong et al., 2023; Yang et al., 2024). Inspired by them, we can unify graph data into a code-like universal format to enhance the LLM's understanding and generation performance on graph tasks. As shown in Figure 1, each graph can be converted into a code with basic variables, such as node_list (or entity_list), edge_list (or triple_list) and optional properties. To this end, a graph instruction tuning stage is introduced to train the LLM on these</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Four groups of graph-centric reasoning and generation tasks.</p>
<p>formulated data.</p>
<p>In addition, previous works have found that LLMs generate responses with hallucination when following the instructions, typically referring to fabricated erroneous inputs or lack of intrinsic knowledge (Dziri et al., 2022; Zhang et al., 2023a; Ji et al., 2023). For example, the LLM may derive a wrong answer when being questioned on a graph that lacks key information, or the LLM may generate a graph with incorrect facts, conflicting, or missing information. However, how to reduce this effect in graph reasoning and generation is still under-explored. Hence, we introduce the graph preference alignment to alleviate the hallucination problem in the LLM's reasoning and generation. Specifically, we follow the direct preference optimization (DPO) algorithm (Rafailov et al., 2023) to optimize the LLM to make better preferences. To automatically sample the negative instances in DPO, we explore various scenarios, such as <em>unfactual graph</em>, <em>conflict graph</em> and <em>missing graph</em>, , to simulate the graph hallucination problem.</p>
<p>To evaluate the effectiveness of our framework, we perform extensive experiments on multiple graph reasoning and generation tasks. Results reveal that the proposed InstructGraph achieves the best performance on both graph-centric instruction and preference tasks and outperforms the GPT-4 (OpenAI, 2023b) and LLaMA2 (Touvron et al., 2023b) by more than 13% and 38%, respectively.</p>
<h2>2 Methodology</h2>
<p>The skeleton is shown in Figure 2, which can be decomposed into three modules, i.e., graph input engineering, graph instruction tuning, and graph preference aligning.</p>
<h3>2.1 Notation</h3>
<p>Suppose that there are <em>M</em> graph tasks <strong>D</strong> = {<strong>D</strong><sub>1</sub>, . . . <strong>D</strong><sub>M</sub>}, and the corresponding dataset of each task can be denoted as <strong>D</strong><sup>j</sup> = {(<strong>I</strong><sub><em>i</em></sub>, <strong>G</strong><sub><em>i</em></sub>, <strong>P</strong><sub><em>i</em></sub>, <strong>A</strong><sub><em>i</em></sub>)}<sub><em>N</em><sub><em>j</em></sub></sub>, where <em>N</em><sub><em>j</em></sub> denotes the number of examples of <strong>D</strong><sup>j</sup>, <strong>I</strong><sub><em>i</em></sub> is the corresponding instruction <sup>2</sup>, <strong>G</strong><sub><em>i</em></sub> = (<strong>E</strong><sub><em>i</em></sub>, <strong>R</strong><sub><em>i</em></sub>, <strong>T</strong><sub><em>i</em></sub>, <strong>S</strong><sub><em>i</em></sub>) is the graph with one node (entity) set <strong>E</strong><sub><em>i</em></sub>, one optional relation set <strong>R</strong><sub><em>i</em></sub>, one edge (triple) set <strong>T</strong><sub><em>i</em></sub>, and one optional textual property set <strong>S</strong><sub><em>i</em></sub>, <strong>P</strong><sub><em>i</em></sub> is the optional passage, and <strong>A</strong><sub><em>i</em></sub> is the final answer <sup>3</sup>.</p>
<h3>2.2 Graph Input Engineering</h3>
<p>The first challenge is how to align the graph to the text to meet the sequence interface of LLMs, previ-</p>
<p><sup>2</sup>We manually design the instruction for each dataset.</p>
<p><sup>3</sup>Especially, the answer <strong>A</strong><sub><em>i</em></sub> can be not only an independent text but also one of <strong>G</strong><sub><em>i</em></sub> and <strong>P</strong><sub><em>i</em></sub>, depending on the task paradigm.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The InstructGraph framework. 1) We first collect multiple graph tasks, and unify them into a code-like format, along with task-specific textual data to form a graph instruction corpus. 2) Then, we perform graph instruction tuning to improve the ability of an LLM to solve graph reasoning and generation tasks. 3) Finally, we investigate multiple graph hallucination scenarios and optimize the LLM by preference alignment.</p>
<p>ous works solved this issue by using graph description (Ye et al., 2023) or embedding fusion (Chai et al., 2023), which may make the generated responses difficult to parse into actual graphs.</p>
<p>Inspired by current LLMs that can simultaneously understand and generate code, we introduce a <em>structured format verbalizing</em> strategy to transform the graph into a simple code-like format. Formally, given one task graph $$G_i \in D_j$$, we denote $$M(\cdot)$$ as the structured format verbalizer, and the original graph can be mapped into a sequence as $$C_i = M(G_i)$$. For the fundamental format, all nodes (or entities) are listed as a sequence with variable node_list (or entity_list), while all edges (or triples) are listed as a sequence with variable edge_list (or triple_list). For graphs that contain side information, we can simulate the object-oriented language to express the node (or entity). Take the graph in Figure 1 as an example, the review text "The film is nice." of the node "User1" can be expressed by "User1.review=The film is nice.", where ".review" can be replaced as the property name in the graph. Therefore, we can unify all graphs into a unified format to align with textual data.</p>
<h3>2.3 Graph Instruction Tuning</h3>
<p>As shown in Figure 1, we first define four different groups of graph-centric instruction tasks to bolster the ability of LLMs on the graph, including graph structure modeling, graph language modeling, graph generation modeling, and graph thought modeling. The first two groups are focused on graph reasoning, the third group is typical graph generation, and the last group aims at both graph reasoning and generation <sup>4</sup>. After graph input engineering, we can directly reuse the standard causal language modeling (CLM) objective to continually tune the LLM on such groups. Formally, given one task dataset $$D_j = { (L_i, G_i, P_i, A_i) }_{ i=1 N_f}^{ N_f}$$, the LLM can be optimized by <em>maximum likelihood</em> with:</p>
<p>$$\mathcal{L}(D_j) = -\sum_{i=1}^{N_f} \log \pi_\theta (Y_i = \mathcal{A}_i | \mathcal{X}_i), \tag{1}$$</p>
<p>where $$\pi_\theta$$ denotes the LLM with trainable parameters $$\theta$$, $$Y_i$$ is the model output, $$X_i$$ and $$A_i$$ respectively represent the input sequence and reference</p>
<p><sup>4</sup>We only choose the first three groups of tasks for instruction tuning. The tasks from graph thought modeling are only used for the evaluation.</p>
<table>
<thead>
<tr>
<th>Task Groups</th>
<th>Task Clusters</th>
<th>Task Definition</th>
<th>Task Input</th>
<th>Task Output</th>
</tr>
</thead>
<tbody>
<tr>
<td>Graph Structure Modeling</td>
<td>Connection Detection, Cycle Detection, Hamilton Path, Bipartite Matching, Shortest Path, Degree Computing</td>
<td>The tasks in this group aim to make LLMs better understand some basic graph structures. The input only contains nodes, directed or un-directed edges, and optional weights.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>\right]$}, \mathcal{C}_{i</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td>Graph Language Modeling</td>
<td>Graph Caption Generation</td>
<td>The task aims to generate a caption passage $\mathcal{P}<em i="i">{i}$ to describe the graph $\mathcal{G}</em>$.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>\right]$}, \mathcal{C}_{i</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{P}</em>$</td>
</tr>
<tr>
<td></td>
<td>Graph Question Answering</td>
<td>The task aims to reason on the whole graph $\mathcal{G}<em i="i">{i}$ and find an entity as the final answer $\mathcal{A}</em>$.} \in \mathcal{E}_{i</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>}, \mathcal{C<em i="i">{i}, \mathcal{P}</em>\right]$</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td></td>
<td>Graph Node Classification</td>
<td>The task aims to classify the target node into predefined classes based on $\mathcal{G}_{i}$.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>}, \mathcal{C<em i="i">{i}, \mathcal{P}</em>\right]$</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td></td>
<td>Graph Link Prediction</td>
<td>The task aims to predict the relation between two given nodes based on $\mathcal{G}_{i}$.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>}, \mathcal{C<em i="i">{i}, \mathcal{P}</em>\right]$</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td></td>
<td>Graph Relevance Inspection</td>
<td>The task aims to detect whether the graph $\mathcal{G}<em i="i">{i}$ is relevant to the passage $\mathcal{P}</em> \in{$ relevant, irrelevant $}$.}$, we have $\mathcal{A}_{i</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>}, \mathcal{C<em i="i">{i}, \mathcal{P}</em>\right]$</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td></td>
<td>Graph Collaboration Filtering</td>
<td>The task aims to predict whether the target user prefers the target item based on the whole graph $\mathcal{G}<em i="i">{i}$, the answer $\mathcal{A}</em>$ can be set as a score.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>}, \mathcal{C<em i="i">{i}, \mathcal{P}</em>\right]$</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{A}</em>$</td>
</tr>
<tr>
<td>Graph Generation Modeling</td>
<td>Knowledge Graph Generation</td>
<td>The task aims to given a passage $\mathcal{P}<em i="i">{i}$ that describes a piece of factual or commonsense information, the task aims to extract entities and relations from $\mathcal{P}</em>$.}$ to generate a graph $\mathcal{G}_{i</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>\right]$}, \mathcal{P}_{i</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{C}</em>$</td>
</tr>
<tr>
<td></td>
<td>Structure Graph Generation</td>
<td>The task aims to generate a graph to meet the structure information described in the passage $\mathcal{P}_{i}$.</td>
<td>$\mathcal{X}<em i="i">{i}=\left[\mathcal{I}</em>\right]$}, \mathcal{P}_{i</td>
<td>$\mathcal{Y}<em i="i">{i}=\mathcal{C}</em>$</td>
</tr>
<tr>
<td>Graph Thought Modeling</td>
<td>Arithmetic Symbolic Robotic Logic</td>
<td>The task aims to solve the general reasoning task in three think steps: 1) first find the question subject, 2) then generate a thought graph $\mathcal{G}<em i="i">{i}$ to express the rationale and 3) finally output the result $\mathcal{A}</em>$ based on the graph.</td>
<td>$\mathcal{X}<em i="i">{i}=\mathcal{I}</em>$</td>
<td>$\mathcal{Y}<em i="i">{i}=\left[\mathcal{C}</em>\right]$}, \mathcal{A}_{i</td>
</tr>
</tbody>
</table>
<p>Table 1: The overview of all groups of tasks.
label, which depends on the specific task definition. Table 1 lists all groups of tasks and corresponding clusters to show the task definition, model input, and output. Therefore, we can obtain an instructionbased graph LLM and named InstructGraph-INS.</p>
<h3>2.4 Graph Preference Alignment</h3>
<p>Recently, the NLP community has witnessed a significant decrease in hallucination through preference optimization (Ouyang et al., 2022; Zhao et al., 2023e; Rafailov et al., 2023; MacGlashan et al., 2017). Following this, we propose graph preference alignment to alleviate the hallucination of LLMs on the graph. As depicted in Figure 2, we intuitively design four typical hallucination circumstances for graph reasoning and generation and perform negative sampling for each graph task.</p>
<p>Hallucinations in Graph Reasoning Typically, the instruction-version LLM may be a strong instruction follower, yet, sometimes fall into hallucinations because of the erroneous input or lack of knowledge: 1) correct graph but wrong answer
means the LLM makes a wrong prediction even though the input is legal, 2) unfactual graph but wrong answer means the wrong answer caused by a graph with unfaithful semantics to external knowledge, 3) conflict graph but wrong answer means there exists conflict information in the input graph, and 4) missing graph but wrong answer means that the input graph is missing some crucial information related to the answer.</p>
<p>To simulate the first circumstance, we can randomly choose a result from other examples to form a negative output $\mathcal{Y}<em i="i">{i}^{-}$. For the rest, we can randomly replace, add, or remove some nodes (entities) or edges (triples) in the graph and construct a new input with the original instruction and passage. Therefore, the original answer can be viewed as the negative $\mathcal{Y}</em>$defined as "Sorry, the input graph contains wrong information, so the question is unanswerable directly.".}^{-}$and the positive $\mathcal{Y}_{i}^{+</p>
<p>Hallucination in Graph Generation Graph generation is harder than reasoning because the LLM needs to output a complete and accurate code-like</p>
<p>format sequence. The following are three kinds of wrong-generated graphs: unfactual graph, conflict graph and missing graph. We can directly construct a wrong graph as the final output $\mathcal{Y}<em i="i">{i}^{-}$by performing replace, add, and remove operators, which are similar to the graph reasoning. The original graph is denoted as positive $\mathcal{Y}</em>$.}^{+}$. Additionally, in cases where an incorrect answer is due to a faulty input, we may substitute the original input with an unrelated one from the dataset that doesn't affect the answer graph. The original answer graph is then considered as the negative output $\mathcal{Y}_{i}^{-</p>
<p>We next use the DPO algorithm to reduce hallucination. Specifically, given one instruction example $\left(\mathcal{X}<em i="i">{i}, \mathcal{Y}</em>}^{+}\right)$and a corresponding negative $\left(\mathcal{X<em i="i">{i}, \mathcal{Y}</em>\right)$, we can define the preference model under the Bradley-Terry }^{-<em>Bradley and Terry (1952)</em> as:</p>
<p>$$
\begin{aligned}
p_{\theta}\left(\mathcal{Y}<em i="i">{i}^{+}&gt;\mathcal{Y}</em>}^{-} \mid \mathcal{X<em i="i">{i}\right)= &amp; \frac{1}{1+\exp \left{r\left(\mathcal{Y}</em>}^{+}, \mathcal{Y<em i="i">{i}^{-}, \mathcal{X}</em> \
r\left(\mathcal{Y}}\right)\right}<em i="i">{i}^{+}, \mathcal{Y}</em>}^{-}, \mathcal{X<em _theta="\theta">{i}\right)= &amp; -\beta \log \frac{\pi</em>}\left(\mathcal{Y<em i="i">{i}^{+} \mid \mathcal{X}</em>}\right)}{\pi_{\operatorname{ref}}\left(\mathcal{Y<em i="i">{i}^{+} \mid \mathcal{X}</em> \
&amp; +\beta \log \frac{\pi_{\theta}\left(\mathcal{Y}}\right)<em i="i">{i}^{-} \mid \mathcal{X}</em>}\right)}{\pi_{\operatorname{ref}}\left(\mathcal{Y<em i="i">{i}^{-} \mid \mathcal{X}</em>
\end{aligned}
$$}\right)</p>
<p>where $\beta$ is the balance factor, $p_{\theta}$ denotes the preference model, $\pi_{\theta}$ and $\pi_{\operatorname{ref}}$ respectively denotes the policy and reference model, which can be initialized from instruction-version LLM. Thus, we can optimize the LLM by maximum likelihood with:</p>
<p>$$
\begin{aligned}
&amp; \mathcal{J}\left(\pi_{\theta}, \pi_{\operatorname{ref}}\right)=-\mathbb{E}<em i="i">{\left(\mathcal{X}</em>}, \mathcal{Y<em i="i">{i}^{+}, \mathcal{Y}</em> \
&amp; {\left[\log \sigma\left(\beta \log \frac{\pi_{\theta}\left(\mathcal{Y}}^{-}\right) \sim \mathcal{D}<em i="i">{i}^{+} \mid \mathcal{X}</em>}\right)}{\pi_{\operatorname{ref}}\left(\mathcal{Y<em i="i">{i}^{+} \mid \mathcal{X}</em>}\right)}-\beta \log \frac{\pi_{\theta}\left(\mathcal{Y<em i="i">{i}^{-} \mid \mathcal{X}</em>}\right)}{\pi_{\operatorname{ref}}\left(\mathcal{Y<em i="i">{i}^{-} \mid \mathcal{X}</em>
\end{aligned}
$$}\right)}\right)\right]</p>
<p>We denote the policy $\pi_{\theta}$ as InstructGraph-PRE.</p>
<h2>3 Experiments</h2>
<p>In this section, we perform extensive experiments to evaluate the effectiveness of InstructGraph over graph tasks and general NLP tasks.</p>
<h3>3.1 Implementation Settings</h3>
<p>We construct about 1.6 M examples for graph instruction tuning and 100 K examples for graph preference alignment. In default, we choose LLaMA2-7B-HF <em>Touvron et al. (2023b)</em> from HuggingFace as the backbone. The maximum length is set as 2048. The optimizer is AdamW. The learning rate is set to $5 e-5$ with a decay rate of 0.1 in the graph instruction tuning stage and will be changed to $5 e-7$ in the graph preference alignment stage.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>To accelerate the training ${ }^{6}$, we utilize FSDP <em>Zhao et al. (2023d)</em> with CPU Offloading <em>Tsog et al. (2021)</em>, FlashAttention <em>Dao et al. (2022)</em>, and BFloat16 techniques, and utilize LoRA <em>Hu et al. (2022)</em> to perform parameter-efficient learning with $\operatorname{rank}=32$ and $\operatorname{lor} a _\alpha=128$.</p>
<h3>3.2 Main Results on Graph Instruction Tasks</h3>
<p>In this section, we exhaustively evaluate the InstructGraph-INS on multiple graph reasoning and generation tasks in zero-shot settings. We use a code-like format to unify all graphs and construct an instruction tuning test set. Data statistics are shown in Table 10, and the details are shown in Appendix A.1. To make a comparison with a similar scale LLM, we choose the widely-used LLaMA27B and Vicuna-7B as the open-source baseline. In pursuit of investigating the performance level of InstructGraph in the era of AGI, we also choose GPT-3.5 (turbo) <em>Ouyang et al. (2022)</em> and GPT-4 <em>OpenAI (2023b)</em> as strong baselines ${ }^{7}$.</p>
<p>Table 2 showcases the main results of graph reasoning and generation, we thus draw the following conclusions: 1) InstructGraph-INS achieves the best overall results $79.84 \%$ and outperforms GPT-4 by $13.08 \%$. 2) Compared with the same scale LLMs, our framework performs the best on all graph tasks, which shows that further instruction tuning over well-designed graph tasks can better improve the reasoning and generation ability. 3) For the tasks Degree Computing, WebNLG, GenWiki, WikiTQ, and Citseer, InstructGraph-INS underperforms GPT-3.5 and GPT-4. Since the LLMs with large-scale parameters have stored more similar knowledge. Despite this, InstructGraph-INS still exhibits approximately $10 \%$ better performance on other reasoning tasks.</p>
<p>Additionally, we also expect to delve into whether InstructGraph-INS achieves the improvement on graph generation tasks, We choose two external manners to evaluate the results: 1) $N E R$ denotes named entity recognition, and 2) $R E$ denotes relation extraction. As shown in Figure 3, we visualize the comparison performances on three graph generation tasks, where Wikidata and UIE belong to knowledge graph construction and $N L$ Graph focus on structure graph generation. We observe that: 1) InstructGraph-INS can bring significant improvement for LLaMA2 and Vicuna, in-</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th>Clusters</th>
<th>Tasks</th>
<th>Metrics</th>
<th>GPT-3.5</th>
<th>GPT-4</th>
<th>LLaMA2</th>
<th>Vicuna</th>
<th>InstructGraph-INS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Structure</td>
<td>Conn. Dect.</td>
<td>ACC</td>
<td>81.45</td>
<td>80.47</td>
<td>54.01</td>
<td>54.85</td>
<td>83.54</td>
</tr>
<tr>
<td></td>
<td>Cycle Dect.</td>
<td>ACC</td>
<td>59.02</td>
<td>61.44</td>
<td>50.79</td>
<td>52.88</td>
<td>91.10</td>
</tr>
<tr>
<td></td>
<td>Hami. Path</td>
<td>ACC</td>
<td>21.03</td>
<td>29.10</td>
<td>1.23</td>
<td>1.23</td>
<td>34.80</td>
</tr>
<tr>
<td></td>
<td>Bipt. Match</td>
<td>ACC</td>
<td>50.23</td>
<td>66.11</td>
<td>0.00</td>
<td>0.00</td>
<td>76.36</td>
</tr>
<tr>
<td></td>
<td>Shrt. Path</td>
<td>ACC</td>
<td>38.99</td>
<td>49.03</td>
<td>0.00</td>
<td>0.00</td>
<td>66.29</td>
</tr>
<tr>
<td></td>
<td>Degree Comp.</td>
<td>ACC</td>
<td>41.18</td>
<td>70.59</td>
<td>18.13</td>
<td>19.57</td>
<td>65.65</td>
</tr>
<tr>
<td>Caption</td>
<td>Wikipedia</td>
<td>BLEU</td>
<td>91.99</td>
<td>93.85</td>
<td>77.15</td>
<td>82.94</td>
<td>95.81</td>
</tr>
<tr>
<td></td>
<td>WebNLG</td>
<td>BLEU</td>
<td>99.51</td>
<td>99.29</td>
<td>88.67</td>
<td>89.33</td>
<td>97.35</td>
</tr>
<tr>
<td></td>
<td>GenWiki</td>
<td>BLEU</td>
<td>98.60</td>
<td>98.65</td>
<td>79.72</td>
<td>87.67</td>
<td>97.71</td>
</tr>
<tr>
<td></td>
<td>EventNA</td>
<td>BLEU</td>
<td>62.66</td>
<td>61.75</td>
<td>53.39</td>
<td>75.52</td>
<td>81.64</td>
</tr>
<tr>
<td></td>
<td>Xalign</td>
<td>BLEU</td>
<td>86.77</td>
<td>88.59</td>
<td>84.05</td>
<td>86.05</td>
<td>93.08</td>
</tr>
<tr>
<td>Graph QA</td>
<td>PathQSP</td>
<td>EM</td>
<td>52.54</td>
<td>68.64</td>
<td>42.70</td>
<td>31.90</td>
<td>86.40</td>
</tr>
<tr>
<td></td>
<td>GrailQA</td>
<td>EM</td>
<td>43.92</td>
<td>60.17</td>
<td>15.83</td>
<td>17.95</td>
<td>81.30</td>
</tr>
<tr>
<td></td>
<td>WebQSP</td>
<td>EM</td>
<td>53.73</td>
<td>61.57</td>
<td>40.07</td>
<td>26.42</td>
<td>73.30</td>
</tr>
<tr>
<td></td>
<td>WikiTQ</td>
<td>EM</td>
<td>49.02</td>
<td>60.78</td>
<td>29.94</td>
<td>35.76</td>
<td>47.82</td>
</tr>
<tr>
<td>Node CLS</td>
<td>Cora</td>
<td>EM</td>
<td>74.51</td>
<td>64.17</td>
<td>83.04</td>
<td>84.08</td>
<td>89.33</td>
</tr>
<tr>
<td></td>
<td>Citeseer</td>
<td>EM</td>
<td>70.39</td>
<td>74.94</td>
<td>68.24</td>
<td>67.94</td>
<td>71.65</td>
</tr>
<tr>
<td></td>
<td>Pubmed</td>
<td>EM</td>
<td>74.63</td>
<td>77.16</td>
<td>79.78</td>
<td>80.18</td>
<td>81.09</td>
</tr>
<tr>
<td></td>
<td>Arxiv</td>
<td>EM</td>
<td>70.59</td>
<td>74.51</td>
<td>45.50</td>
<td>57.75</td>
<td>81.50</td>
</tr>
<tr>
<td></td>
<td>Products</td>
<td>EM</td>
<td>68.82</td>
<td>84.16</td>
<td>29.34</td>
<td>79.50</td>
<td>95.20</td>
</tr>
<tr>
<td>Link Pred.</td>
<td>Wikidata</td>
<td>Hits@1</td>
<td>43.73</td>
<td>62.94</td>
<td>10.75</td>
<td>10.38</td>
<td>96.52</td>
</tr>
<tr>
<td></td>
<td>FB15K-237</td>
<td>Hits@1</td>
<td>60.34</td>
<td>66.88</td>
<td>0.00</td>
<td>0.00</td>
<td>98.91</td>
</tr>
<tr>
<td></td>
<td>ConceptNet</td>
<td>Hits@1</td>
<td>31.33</td>
<td>38.30</td>
<td>8.30</td>
<td>8.19</td>
<td>59.86</td>
</tr>
<tr>
<td>Relevance</td>
<td>Wikipedia</td>
<td>ACC</td>
<td>94.40</td>
<td>100</td>
<td>69.27</td>
<td>68.12</td>
<td>100</td>
</tr>
<tr>
<td>RecSys</td>
<td>Amazon</td>
<td>Hits@1</td>
<td>27.09</td>
<td>59.77</td>
<td>44.40</td>
<td>16.40</td>
<td>78.80</td>
</tr>
<tr>
<td>IE</td>
<td>Wikipedia</td>
<td>F1</td>
<td>50.97</td>
<td>46.89</td>
<td>40.76</td>
<td>38.84</td>
<td>83.56</td>
</tr>
<tr>
<td></td>
<td>UIE</td>
<td>F1</td>
<td>24.41</td>
<td>26.22</td>
<td>20.21</td>
<td>26.11</td>
<td>76.82</td>
</tr>
<tr>
<td></td>
<td>InstructKGC</td>
<td>F1</td>
<td>21.44</td>
<td>21.86</td>
<td>19.26</td>
<td>16.6</td>
<td>38.98</td>
</tr>
<tr>
<td>Graph Gen.</td>
<td>NLGraph</td>
<td>F1</td>
<td>80.86</td>
<td>88.17</td>
<td>3.64</td>
<td>42.21</td>
<td>91.05</td>
</tr>
<tr>
<td>Avg.</td>
<td></td>
<td></td>
<td>59.45</td>
<td>66.76</td>
<td>41.65</td>
<td>46.06</td>
<td>79.84</td>
</tr>
</tbody>
</table>
<p>Table 2: Main results (%) over multiple graph instruction tuning tasks under zero-shot settings. The number highlighted in bold denotes the best performance.
dicating the graph generation ability encompasses NER and RE. 2) We also integrate all baselines with the 2-shot exemplars, the results illustrate that the performance of InstructGraph-INS is consistently the highest. 3) RE is more challenging to NER because it involves understanding the semantics of generated nodes (entities) and making decisions on their relation or weight. Despite this, the improvement of RE is larger than NER, which signifies that graph-specific optimization can better empower the LLM in constructing triples.</p>
<h3>3.3 Main Results on Graph Preference Tasks</h3>
<p>We next explore whether InstructGraph can reduce the graph hallucination problem. We sample a few tasks from the corresponding cluster to build a hal-
lucination testing set, including structure, caption, graph question answering, and node classification. The data statistics are shown in Table 10, and the details are shown in Appendix A.2. Specifically, each example consists of a correct answer and a wrong answer, we calculate the LLMs perplexity (PPL) on these answers and choose the option with the lowest PPL score as the preference results. Therefore, the accuracy metric can reflect the performance of hallucination mitigation.</p>
<p>As shown in Table 3, we choose LLaMA2, Vicuna, and two variants of InstructGraph to make a comparison. InstructGraph-INS outperforms LLaMA2 and Vicuna by $16.44 \%$ and $15.46 \%$, respectively, demonstrating that our framework with only graph instruction tuning can solve the pref-</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Performance (%) comparison with LLaMA2, Vicuna, GPT-3.5, and GPT-4 towards the overall graph, named entity recognition (NER), and relation extraction (RE) on graph generation tasks.</p>
<table>
<thead>
<tr>
<th>Methods (7B)</th>
<th>Is Align</th>
<th>Structure</th>
<th>Caption</th>
<th>Graph QA</th>
<th>Nodel CLS</th>
<th>IE</th>
<th>Avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>LLaMA2</td>
<td></td>
<td>38.64</td>
<td>57.96</td>
<td>70.70</td>
<td>74.68</td>
<td>37.40</td>
<td>55.88</td>
</tr>
<tr>
<td>Vicuna</td>
<td></td>
<td>39.12</td>
<td>62.37</td>
<td>64.38</td>
<td>77.63</td>
<td>40.8</td>
<td>56.86</td>
</tr>
<tr>
<td>InstructGraph-INS</td>
<td></td>
<td>50.32</td>
<td>81.15</td>
<td>77.85</td>
<td>83.16</td>
<td>69.14</td>
<td>72.32</td>
</tr>
<tr>
<td>InstructGraph-PRE</td>
<td></td>
<td>57.80</td>
<td>87.44</td>
<td>84.44</td>
<td>88.98</td>
<td>91.44</td>
<td>82.02</td>
</tr>
</tbody>
</table>
<p>Table 3: Main results (%) over multiple graph preference tasks under zero-shot settings.</p>
<p>erence tasks better. This indicates that injecting task-related knowledge into the LLM's intrinsic parameter can be one of the significant factors for hallucination reduction. Furthermore, InstructGraph-PRE significantly enhances the instruction version model by about 10%, demonstrating that well-designed preference optimization can hit the upper boundary and endow the LLM with the ability to alleviate the pitfalls of hallucination.</p>
<p>We also delve into whether the preference optimization on the graph data hinders the effectiveness in the general domains. To reach this goal, we choose three external preference and hallucination tasks. 1) HaluEval (Li et al., 2023a) 8 focuses on hallucination evaluation in dialogue, general understanding, question answering, and text summarization (abstract). 2) TruthfulQA (Lin et al., 2022) 9 aims to test the factuality of LLMs on knowledge-intensive tasks. We choose MC1 as the test. 3) Anthropic-HH (Bai et al., 2022) 10 has released the evaluation set for both harmless and helpful perspective. For these tasks, we do not perform task-specific fine-tuning to show the zero-shot performance. Results in Table 4 showcase that our framework occasionally outperforms the sample scale baselines on some tasks, which meets our desiderata.</p>
<h3>3.4 Effectiveness of Thought Planning</h3>
<p>Recall the graph instruction tuning, we are eager for the LLM to solve the thought planning tasks, including arithmetic, symbolic, robotic, and logic. We design two few-shot scenarios: 1) <em>Chain-of-Thought (CoT)</em> directly sampling few-shot exemplars with manually annotated sequence rationales to form a prompt. 2) <em>Graph Thought Modeling (GTM)</em> decomposes the sequence rationale into</p>
<p>^{8}https://github.com/RUCAIBox/HaluEval.</p>
<p>^{9}https://github.com/sylinrl/TruthfulQA.</p>
<p>^{10}https://github.com/anthropics/hh-rlhf.</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th>Is Align</th>
<th>HaluEval</th>
<th></th>
<th></th>
<th></th>
<th>Anthropic-HH</th>
<th></th>
<th>TruthfulQA</th>
<th>Avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Dialogue</td>
<td>General</td>
<td>QA</td>
<td>Abstract</td>
<td>Harmless</td>
<td>Helpful</td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPT-3.5</td>
<td></td>
<td>72.40</td>
<td>79.44</td>
<td>62.59</td>
<td>58.53</td>
<td>-</td>
<td>-</td>
<td>47.50</td>
<td>-</td>
</tr>
<tr>
<td>GPT-4</td>
<td></td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>59.80</td>
<td>-</td>
</tr>
<tr>
<td>LLaMA2-7B</td>
<td></td>
<td>43.99</td>
<td>20.46</td>
<td>49.60</td>
<td>49.55</td>
<td>54.28</td>
<td>60.49</td>
<td>33.29</td>
<td>44.52</td>
</tr>
<tr>
<td>Vicuna-7B</td>
<td></td>
<td>46.35</td>
<td>19.48</td>
<td>60.34</td>
<td>45.62</td>
<td>55.70</td>
<td>58.71</td>
<td>30.10</td>
<td>45.19</td>
</tr>
<tr>
<td>InstructGraph-INS</td>
<td></td>
<td>44.88</td>
<td>21.35</td>
<td>52.90</td>
<td>51.10</td>
<td>56.33</td>
<td>59.10</td>
<td>35.35</td>
<td>45.86</td>
</tr>
<tr>
<td>InstructGraph-PRE</td>
<td></td>
<td>47.03</td>
<td>21.61</td>
<td>52.88</td>
<td>51.39</td>
<td>58.40</td>
<td>60.12</td>
<td>35.77</td>
<td>46.74</td>
</tr>
</tbody>
</table>
<p>Table 4: Main results (\%) over multiple universal NLP preference tasks under zero-shot settings.</p>
<table>
<thead>
<tr>
<th>Methods (7B)</th>
<th>Arithmetic</th>
<th></th>
<th></th>
<th>Symbolic</th>
<th></th>
<th>Robotic</th>
<th></th>
<th>Logic</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>GSM8K</td>
<td>SVAMP</td>
<td>AQuA</td>
<td>Letter</td>
<td>Coin</td>
<td>Termes</td>
<td>Floortile</td>
<td>ProofWriter</td>
<td>FOLIO</td>
</tr>
<tr>
<td></td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
<td>(4-shot)</td>
</tr>
<tr>
<td>LLaMA2 w/. CoT</td>
<td>11.89</td>
<td>23.30</td>
<td>18.60</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>30.64</td>
<td>32.40</td>
</tr>
<tr>
<td>Vicuna w/. CoT</td>
<td>14.33</td>
<td>24.19</td>
<td>17.80</td>
<td>1.50</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>28.77</td>
<td>33.15</td>
</tr>
<tr>
<td>InstructGraph-INS w/. CoT</td>
<td>17.52</td>
<td>28.80</td>
<td>22.33</td>
<td>8.70</td>
<td>6.20</td>
<td>30.00</td>
<td>50.00</td>
<td>55.80</td>
<td>41.68</td>
</tr>
<tr>
<td>LLaMA2 w/. GTM</td>
<td>14.38</td>
<td>23.10</td>
<td>20.13</td>
<td>2.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>33.19</td>
<td>34.80</td>
</tr>
<tr>
<td>Vicuna w/. GTM</td>
<td>15.10</td>
<td>24.84</td>
<td>19.60</td>
<td>1.50</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>31.50</td>
<td>36.19</td>
</tr>
<tr>
<td>InstructGraph-INS w/. GTM</td>
<td>19.46</td>
<td>27.10</td>
<td>23.80</td>
<td>7.40</td>
<td>9.40</td>
<td>30.00</td>
<td>50.00</td>
<td>52.77</td>
<td>43.06</td>
</tr>
</tbody>
</table>
<p>Table 5: Results (\%) on thought planning tasks in few-shot scenarios.
three stages, i.e., finding topic entities or keywords, building a graph to express the thought, and outputting the final answer. The comparison results are depicted in Table 5, and we can observe that InstructGraph-INS achieves the best performance when elicited by CoT and GTM prompts. In addition, GTM sometimes performs below expectations in the tasks of SVAMP, Letter, and ProofWriter. We believe that these tasks are difficult to express using an explicit graph to convey the thinking process.</p>
<h3>3.5 Performance on General NLP Tasks</h3>
<p>We next evaluate the performance of InstructGraph on the general NLP tasks. We choose Big-Bench-Hard (BBH) <em>Suzgun et al. (2023)</em> and Massive Multitask Language Understanding (MMLU) <em>Hendrycks et al. (2021)</em> benchmarks with few-shot exemplars to perform reasoning. As shown in Table 6, even though these tasks do not belong to graph domains, we can still obtain competitive results compared with other same-scale open-source LLMs.</p>
<h2>4 Analysis</h2>
<h3>4.1 Parameter-Efficient Learning Study</h3>
<p>To accelerate the training speed and reduce memory usage under the limitation of sources, we leverage parameter-efficient learning (PEL) techniques to equip the original LLM with only a few trainable parameters. To study the choice of differ-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: center;">BBH <br> (3-shot)</th>
<th style="text-align: center;">MMLU <br> (5-shot)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GPT-3.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">70.00</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">86.40</td>
</tr>
<tr>
<td style="text-align: left;">MPT-7B</td>
<td style="text-align: center;">31.00</td>
<td style="text-align: center;">26.80</td>
</tr>
<tr>
<td style="text-align: left;">Falcon-7B</td>
<td style="text-align: center;">28.00</td>
<td style="text-align: center;">26.20</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA-7B</td>
<td style="text-align: center;">30.30</td>
<td style="text-align: center;">35.10</td>
</tr>
<tr>
<td style="text-align: left;">LLaMA2-7B</td>
<td style="text-align: center;">32.58</td>
<td style="text-align: center;">45.65</td>
</tr>
<tr>
<td style="text-align: left;">Vicuna-7B</td>
<td style="text-align: center;">31.54</td>
<td style="text-align: center;">50.34</td>
</tr>
<tr>
<td style="text-align: left;">InstructGraph-INS</td>
<td style="text-align: center;">$\mathbf{3 3 . 0 6}$</td>
<td style="text-align: center;">$\mathbf{5 1 . 6 2}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Results (\%) over multiple general NLP tasks under few-shot in-context learning settings.
ent PEL methods, we compare LoRA with other PEL methods, such as Prefix-tuning <em>Li and Liang (2021)</em> ${ }^{11}$, and Adapter <em>Houlsby et al. (2019)</em>. For each method, we choose six different scales and perform graph instruction tuning over 10\% training data. The balance between trainable parameters and averaged results is visualized in Figure 4. We can see that LoRA can achieve the best performance and is similar to full fine-tuning regardless of the scale of trainable parameters.</p>
<h3>4.2 Effectiveness of Code Format Graph</h3>
<p>In this part, we evaluate the use of the structured format verbalizer when aligning the graph structure to the textual LLM. We choose four classic</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Results (%) of balance between trainable parameters and performances over graph tasks.</p>
<table>
<thead>
<tr>
<th>Methods</th>
<th>PathQSP</th>
<th>WebNLG</th>
<th>CoRA</th>
<th>UIE</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Template</td>
<td>58.20</td>
<td>96.13</td>
<td>58.58</td>
<td>0.00</td>
</tr>
<tr>
<td>Code Format</td>
<td>68.64</td>
<td>99.29</td>
<td>64.17</td>
<td>26.22</td>
</tr>
<tr>
<td>LLaMA2</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Template</td>
<td>20.36</td>
<td>59.15</td>
<td>27.44</td>
<td>0.00</td>
</tr>
<tr>
<td>Code Format</td>
<td>42.70</td>
<td>88.67</td>
<td>83.04</td>
<td>20.21</td>
</tr>
</tbody>
</table>
<p>Table 7: Results (%) comparison with different prompt engineering during the inference.</p>
<p>Graph reasoning and generation tasks, i.e., PathQSP, WebNLG, CoRA, and UIE. To compare with the structured format verbalizer, we directly choose the heuristic template introduced by InstructGLM (Ye et al., 2023) to describe each path in the graph. For example, the path "(e1, r1, e2), (e2, r2, e3)" can be formulated as "e1 is connected with e3 within the tow hops through e2, and featured relations r1 and r2". We use this template to prompt GPT-4 and LLaMA2 to show the performance. The results in Table 7 demonstrate that our structured format verbalizer outperforms traditional templates in all tasks. Especially, the LLM with traditional templates cannot support graph generation, while the structured format verbalizer can reach this goal.</p>
<h3>4.3 Ablation Study</h3>
<p>In this section, we focus on the ablation study to show how much each component contributes to performance. We choose three clusters for the test, i.e., Graph QA, Node CLS, and IE. For the graph instruction testing, we validate the effectiveness of each modeling task, and the test set is from the instruction corpus. For the graph preference testing, we evaluate three hallucination sampling strategies, including <em>unfactual graph</em>, <em>conflict graph</em>, and <em>miss-</em></p>
<table>
<thead>
<tr>
<th>Baselines</th>
<th>Graph QA</th>
<th>Node CLS</th>
<th>IE</th>
</tr>
</thead>
<tbody>
<tr>
<td>Graph Instruction Testing</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>InstructGraph-INS</td>
<td>72.21</td>
<td>83.75</td>
<td>66.45</td>
</tr>
<tr>
<td>w/. only GSM</td>
<td>71.89</td>
<td>83.04</td>
<td>63.77</td>
</tr>
<tr>
<td>w/. only GLM</td>
<td>69.32</td>
<td>78.40</td>
<td>66.13</td>
</tr>
<tr>
<td>w/. only GGM</td>
<td>72.09</td>
<td>83.66</td>
<td>39.10</td>
</tr>
<tr>
<td>w/. only GTM</td>
<td>69.30</td>
<td>81.90</td>
<td>66.33</td>
</tr>
<tr>
<td>Graph Preference Testing</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>InstructGraph-PRE</td>
<td>84.44</td>
<td>88.98</td>
<td>91.44</td>
</tr>
<tr>
<td>w/o. only unfactual</td>
<td>82.10</td>
<td>84.52</td>
<td>84.33</td>
</tr>
<tr>
<td>w/o. only conflict</td>
<td>83.70</td>
<td>85.17</td>
<td>81.11</td>
</tr>
<tr>
<td>w/o. only missing</td>
<td>79.35</td>
<td>83.55</td>
<td>78.40</td>
</tr>
<tr>
<td>w/o. ALL</td>
<td>77.85</td>
<td>83.16</td>
<td>69.14</td>
</tr>
</tbody>
</table>
<p>Table 8: Average performance (%) of all tasks in each cluster when comparing different ablation versions. GSM, GLM, GGM, and GTM denote graph structure modeling, graph language modeling, graph generation modeling, and graph thought modeling, respectively. w/o. ALL equals to InstructGraph-INS.</p>
<p><em>ing graph</em>, the test set is from the preference corpus.</p>
<p>As shown in Table 8, the results illustrate that the performance drops when removing one of these components. For the instruction tuning testing, we can observe that graph language modeling plays a significant role in Graph QA and Node CLS clusters, while graph generation modeling is beneficial to the performance of IE. For the preference testing, we can see that the performance of w/o. <em>missing graph</em> drops significantly, indicating that the major factor of hallucination is the lack of key information in the input graph or generated graph.</p>
<h3>4.4 Effectiveness of Different Backbones</h3>
<p>To investigate whether the proposed InstructGraph can consistently improve the graph reasoning and generation ability with different LLMs, we select LLaMA2-7B, LLaMA2-13B, Vicuna-7B, and Vicuna-13B as the start checkpoints. To make the experiment efficient, we randomly chose 10% training data to perform graph instruction tuning and make a comparison with the corresponding vanilla LLMs. Results in Figure 5 show that InstructGraph can consistently achieve substantial improvement for arbitrary backbones and scales. Additionally, we observe that Vicuna has better performance than LLaMA2 initially. However, after graph instruction tuning, this trend is reversed. Upon further analysis, we find that both LLaMA2 and Vicuna were re-optimized based on LLaMA (Touvron et al., 2023a). Vicuna's optimization involves using supervised fine-tuning (SFT) to inject domain knowledge with massive conver-</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Effectiveness (\%) of InstructGraph towards different scales and backbones.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Instruction (Graph Caption)</th>
<th style="text-align: center;">LLaMA2 Output</th>
<th style="text-align: center;">InstructGraph Output</th>
<th style="text-align: center;">Reference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">You are a good graph reasoner. Give you a graph language that describes a graph structure and node information. You need to understand the graph and the task definition and answer the question. ' $\mathrm{n}^{\text {acc }}$ nGraph[names='wikipedia-knowledge-graph'] ' $n$ entity_list = ['clows beetle', 'enspilotus cribrum', 'america', 'the family', 'species', 'histeridae']; $\backslash n$ triple_list = [('enspilotus cribrum' -&gt; 'species'</td>
<td style="text-align: center;">(relations='taxon rank'], ('the family' -&gt; 'america'</td>
<td style="text-align: center;">(relations='country')]; $\backslash n \backslash n^{\text {acc }}$ ) $\backslash n$ Task definition: given a knowledge graph with all entities and structure triples representing factual and commonsense knowledge. Please leverage this graph to generate an encyclopedia passage. Note that do not list all knowledge in a running account. $\backslash n$ Q: Please generate an encyclopedia passage for the knowledge graph. $\backslash n$ A:</td>
<td style="text-align: center;">The relation between Euspilotus cribrum and species is 'taxon rank', and the family country is America. [Human Evaluation]: This answer directly states each fact triple from the given graph separately. It is accurate but not natural and satisfied as a whole.</td>
</tr>
<tr>
<td style="text-align: center;">Instruction (Graph Generation)</td>
<td style="text-align: center;">LLaMA2 Output</td>
<td style="text-align: center;">InstructGraph Output</td>
<td style="text-align: center;">Reference</td>
</tr>
<tr>
<td style="text-align: center;">You are a good graph generator. You need to understand the task definition and generate a graph language to answer the question. $\backslash n$ Task definition: given a passage, extract some corresponding structure factual triples from the passage to form a knowledge graph, and generate a graph language to describe the graph. Note that: 1) the graph is a directed graph and the name is 'knowledge-graph'. 2) The entities must be mentioned in the passage. 3) The candidate relation type must be one of 'publication date', 'country of origin', 'publisher', 'performer'. 4) The generated graph language should be a code-like structure, and the skeleton format can be expressed as the following: $\backslash n$ ${ }^{\text {acc }}$ n Graph[names='knowledge-graph'] $\backslash \backslash n$ entity_list = ['xxx', $\cdots$ ]; $\backslash n$ triple_list = [('xxx' -&gt; 'xxx'</td>
<td style="text-align: center;">(relation='xxx'), $\cdots$ ]; $\backslash n$ $\backslash \backslash n^{\text {acc }} n$ Passage: '"Bluesman' is the 12th original album of Tak Matsumoto, the guitarist of the Japanese music group B'z. It was released by VERMILLION RECORDS on September 2, 2020." $\backslash n$ Q: Given you a passage, please generate a corresponding knowledge graph. $\backslash n$ A:</td>
<td style="text-align: center;">Graph[names='knowledgegraph'] $\backslash \backslash n$ entity_list = ['Bluesman', 'Tak Matsumoto', 'B'z $\backslash \backslash \backslash n$ triple_list = [('Bluesman' $-&gt;$ 'Tak Matsumoto) [relation='performer'], $\backslash n$ ('Bluesman' -&gt; 'B'z') [relation='performer'], $\backslash n$ (Tak Matsumoto' -&gt; 'B'z) [relation='performer'], $\backslash n$ ('Tak Matsumoto' -&gt; 'VERMILLION RECORDS') [relation='publisher']]; [Human Evaluation]: This answer sometimes contains wrong triples or missing some entities.</td>
<td style="text-align: center;">Graph[names='knowledgegraph] $\backslash \backslash n$ entity_list = [Bluesman, Tak Matsumoto, B'z, VERMILLION RECORDS, September 2, 2020]; $\backslash n$ triple_list = [(Bluesman-&gt; September 2, 2020) [relation=publication date], (Bluesman-&gt; Tak Matsumoto) [relation='performer], (Bluesman&lt;) VERMILLION RECORDS] [relation=publisher], [Bluesman-&gt; Japan] [relation='country of origin]]; $\backslash n$ ] [Human Evaluation]: This answer looks satisfying.</td>
</tr>
</tbody>
</table>
<p>Table 9: Human evaluation for the generation of LLaMA2 and InstructGraph.
sation data into LLaMA. Meanwhile, LLaMA2 focuses on refactoring the model architecture and pre-training strategy to improve the model's versatility. Thus, Vicuna may have a better ability to understand instructions than LLaMA2. Despite this, LLaMA2 can be the better starting checkpoint for boosting LLMs on graph reasoning and generation tasks with parameter updates.</p>
<h3>4.5 Human Evaluation</h3>
<p>We end this section with a case study to demonstrate the performance of LLMs when solving graph reasoning and generation tasks. We choose LLaMA2 (7B) to make a comparison and respectively choose one example from graph caption gen-
eration and knowledge graph generation. For the answer, we perform a human evaluation to estimate the effectiveness of InstructGraph. As shown in Table 9, InstructGraph can outperform all the baselines. Specifically, compared with LLaMA2, InstructGraph can generate more natural and readable captions to describe factual information. For the graph generation, InstructGraph can provide accurate entities and triples.</p>
<h2>5 Related Work</h2>
<h3>5.1 LLMs for Graph Learning</h3>
<p>A series of works have studied how to leverage LLMs to solve graph-centric tasks (Jin et al., 2023),</p>
<p>which can be decomposed into the following categories: 1) Prompt engineering. A series of works aims to design the interface to elicit the LLM to better understand and reason on the graph (Ye et al., 2023; Han et al., 2023; Zhang et al., 2023b; Zhang, 2023; Kim et al., 2023; Wang et al., 2023b; Luo et al., 2023; Wang et al., 2023a; Guo et al., 2023; Zhao et al., 2023b). 2) Boosting LLMs with trainable GNNs. This kind of method focuses on enhancing the LLMs with trainable GNNs which can capture the arbitrary scale of the graph (Zhang et al., 2022; Chai et al., 2023; Tang et al., 2023; Zhao et al., 2023a; Tian et al., 2023; Qin et al., 2023). 3) Instruction tuning over graph data. Similar to ours, Xu et al. (2023); Jiang et al. (2023); Fang et al. (2023); Zeng et al. (2023) directly collect some graph or symbol data to form an instruction corpus, and then continually pre-train the LLM. Different from them, our InstructGraph further empowers the LLM by graph instruction tuning with the code-like universal format and well-designed hallucination alleviation strategy by preference alignment.</p>
<h3>5.2 Hallucination in LLMs</h3>
<p>Recent works have studied that hallucination may degrade the performance of LLMs when performing instruction-follow inference. LLMs usually generate seemingly plausible answers, which is called hallucination (Ji et al., 2023; Zhang et al., 2023a). The phenomenon of hallucination encompasses fabricating erroneous user input, unfaithful for previously generated context, and unfactual for external knowledge and commonsense. To estimate hallucination, Kryscinski et al. (2020); Li et al. (2023a); Tam et al. (2023); Min et al. (2023) leverage external tools or neural networks (e.g., BERTNLI, GPT-4) to score the faithfulness and factuality of the model output. Recently, many works focus on suppressing this problem by retrievalaugmented generation (RAG) (Lewis et al., 2020), contrastive learning (Sun et al., 2023), contradictory evaluation (Mndler et al., 2023), and decoding strategies (Lee et al., 2022; Shi et al., 2023; Li et al., 2023b). Different from them, we aim to solve the hallucination problem on graph tasks with preference alignment.</p>
<h2>6 Conclusion</h2>
<p>This paper proposes a novel InstructGraph framework that empowers the LLM with the capacity to solve graph reasoning and generation tasks. To
bridge the gap between graph data and textual language models, we introduce a structured format verbalizer to transform each graph into a code-like format and continually tune the LLM based on the instruction dataset, which is collected from 29 graph tasks. In addition, we also introduce a graph preference alignment stage to further mitigate the hallucination problem when reasoning on or generating a graph. Extensive experiments illustrate that InstructGraph can unleash the LLMs' power of graph reasoning and generation, and substantially achieve the best performance. In our future work, we aim to further improve the performance of our framework on both graph-centric and universal NLP tasks, and scale it to other LLMs.</p>
<h2>References</h2>
<p>Tushar Abhishek, Shivprasad Sagare, Bhavyajeet Singh, Anubhav Sharma, Manish Gupta, and Vasudeva Varma. 2022. Xalign: Cross-lingual fact-to-text alignment and generation for low-resource languages. In Companion of The Web Conference 2022, Virtual Event / Lyon, France, April 25 - 29, 2022, pages 171-175. ACM.</p>
<p>Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom B. Brown, Jack Clark, Sam McCandlish, Chris Olah, Benjamin Mann, and Jared Kaplan. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. CoRR, abs/2204.05862.</p>
<p>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1533-1544. ACL.</p>
<p>Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2023. Graph of thoughts: Solving elaborate problems with large language models. CoRR, abs/2308.09687.</p>
<p>Kurt D. Bollacker, Colin Evans, Praveen K. Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the ACM SIGMOD International Conference on Management of</p>
<p>Data, SIGMOD 2008, Vancouver, BC, Canada, June 10-12, 2008, pages 1247-1250. ACM.</p>
<p>Ralph Allan Bradley and Milton E Terry. 1952. Rank analysis of incomplete block designs: I. the method of paired comparisons. Biometrika, 39(3/4):324345.</p>
<p>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.</p>
<p>Ziwei Chai, Tianjie Zhang, Liang Wu, Kaiqiao Han, Xiaohai Hu, Xuanwen Huang, and Yang Yang. 2023. Graphllm: Boosting graph reasoning ability of large language model. CoRR, abs/2310.05845.</p>
<p>Anthony Colas, Ali Sadeghian, Yue Wang, and Daisy Zhe Wang. 2021. Eventnarrative: A largescale event-centric dataset for knowledge graph-totext generation. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual.</p>
<p>Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher R. 2022. Flashattention: Fast and memory-efficient exact attention with io-awareness. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022.</p>
<p>Nouha Dziri, Sivan Milton, Mo Yu, Osmar R. Zaane, and Siva Reddy. 2022. On the origin of hallucinations in conversational models: Is it the datasets or the models? In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022, pages 5271-5285. Association for Computational Linguistics.</p>
<p>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. 2023. Mol-instructions: A large-scale biomolecular instruction dataset for large language models. CoRR, abs/2306.08018.</p>
<p>Shuzheng Gao, Xin-Cheng Wen, Cuiyun Gao, Wenxuan Wang, Hongyu Zhang, and Michael R. Lyu. 2023. What makes good in-context demonstrations for code intelligence tasks with llms? In 38th IEEE/ACM</p>
<p>International Conference on Automated Software Engineering, ASE 2023, Luxembourg, September 11-15, 2023, pages 761-773. IEEE.</p>
<p>Claire Gardent, Anastasia Shimorina, Shashi Narayan, and Laura Perez-Beltrachini. 2017. Creating training corpora for NLG micro-planners. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 179-188. Association for Computational Linguistics.
C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. 1998. Citeseer: An automatic citation indexing system. In Proceedings of the 3rd ACM International Conference on Digital Libraries, June 23-26, 1998, Pittsburgh, PA, USA, pages 89-98. ACM.</p>
<p>Yu Gu, Sue Kase, Michelle Vanni, Brian M. Sadler, Percy Liang, Xifeng Yan, and Yu Su. 2021. Beyond I.I.D.: three levels of generalization for question answering on knowledge bases. In WWW '21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, pages 3477-3488. ACM / IW3C2.</p>
<p>Honghao Gui, Jintian Zhang, Hongbin Ye, and Ningyu Zhang. 2023. Instructie: A chinese instructionbased information extraction dataset. CoRR, abs/2305.11527.</p>
<p>Jiayan Guo, Lun Du, and Hengyu Liu. 2023. Gpt4graph: Can large language models understand graph structured data ? an empirical evaluation and benchmarking. CoRR, abs/2305.15066.</p>
<p>Jiuzhou Han, Nigel Collier, Wray L. Buntine, and Ehsan Shareghi. 2023. Pive: Prompting with iterative verification improving graph-based generative capability of llms. CoRR, abs/2305.12392.</p>
<p>Ruining He and Julian J. McAuley. 2016. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016, pages 507-517. ACM.</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021. Measuring massive multitask language understanding. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.</p>
<p>Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 2790-2799. PMLR.</p>
<p>Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. Lora: Low-rank adaptation of large language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net.</p>
<p>Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets for machine learning on graphs. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.</p>
<p>Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination in natural language generation. ACM Comput. Surv., 55(12):248:1-248:38.</p>
<p>Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Xin Zhao, and Ji-Rong Wen. 2023. Structgpt: A general framework for large language model to reason over structured data. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 9237-9251. Association for Computational Linguistics.</p>
<p>Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng Ji, and Jiawei Han. 2023. Large language models on graphs: A comprehensive survey. CoRR, abs/2312.02783.</p>
<p>Zhijing Jin, Qipeng Guo, Xipeng Qiu, and Zheng Zhang. 2020. Genwiki: A dataset of 1.3 million contentsharing text and graphs for unsupervised graph-totext generation. In Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020, pages 2398-2409. International Committee on Computational Linguistics.</p>
<p>Jiho Kim, Yeonsu Kwon, Yohan Jo, and Edward Choi. 2023. KG-GPT: A general framework for reasoning on knowledge graphs using large language models. In Findings of the Association for Computational Linguistics: EMNLP 2023, Singapore, December 6-10, 2023, pages 9410-9421. Association for Computational Linguistics.</p>
<p>Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and Richard Socher. 2020. Evaluating the factual consistency of abstractive text summarization. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 93329346. Association for Computational Linguistics.</p>
<p>Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale Fung, Mohammad Shoeybi, and Bryan Catanzaro. 2022. Factuality enhanced language models for open-ended text generation. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022,</p>
<p>NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022.</p>
<p>Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kttler, Mike Lewis, Wen-tau Yih, Tim Rocktschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.</p>
<p>Junyi Li, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2023a. Halueval: A large-scale hallucination evaluation benchmark for large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 6449-6464. Association for Computational Linguistics.</p>
<p>Kenneth Li, Oam Patel, Fernanda B. Vigas, Hanspeter Pfister, and Martin Wattenberg. 2023b. Inference-time intervention: Eliciting truthful answers from a language model. CoRR, abs/2306.03341.</p>
<p>Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021, pages 45824597. Association for Computational Linguistics.</p>
<p>Stephanie Lin, Jacob Hilton, and Owain Evans. 2022. Truthfulqa: Measuring how models mimic human falsehoods. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 3214-3252. Association for Computational Linguistics.</p>
<p>Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. 2023. Reasoning on graphs: Faithful and interpretable large language model reasoning. CoRR, abs/2310.01061.</p>
<p>Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu Jiang, Changjian Wang, and Shanshan Li. 2023. At which training stage does code data help llms reasoning? CoRR, abs/2309.16298.</p>
<p>James MacGlashan, Mark K. Ho, Robert Tyler Loftin, Bei Peng, Guan Wang, David L. Roberts, Matthew E. Taylor, and Michael L. Littman. 2017. Interactive learning from policy-dependent human feedback. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 2285-2294. PMLR.</p>
<p>Andrew McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. 2000. Automating the construction</p>
<p>of internet portals with machine learning. Inf. Retr., 3(2):127-163.</p>
<p>Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. Factscore: Fine-grained atomic evaluation of factual precision in long form text generation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 12076-12100. Association for Computational Linguistics.</p>
<p>Niels Mndler, Jingxuan He, Slobodan Jenko, and Martin T. Vechev. 2023. Self-contradictory hallucinations of large language models: Evaluation, detection and mitigation. CoRR, abs/2305.15852.</p>
<p>OpenAI. 2023a. GPT-4 technical report. CoRR, abs/2303.08774.</p>
<p>OpenAI. 2023b. GPT-4 technical report. CoRR, abs/2303.08774.</p>
<p>Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. In Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022.</p>
<p>Panupong Pasupat and Percy Liang. 2015. Compositional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long Papers, pages 14701480. The Association for Computer Linguistics.</p>
<p>Bryan Perozzi, Bahare Fatemi, Dustin Zelle, Anton Tsitsulin, Mehran Kazemi, Rami Al-Rfou, and Jonathan Halcrow. 2024. Let your graph do the talking: Encoding structured data for llms. arXiv preprint arXiv:2402.05862.</p>
<p>Yijian Qin, Xin Wang, Ziwei Zhang, and Wenwu Zhu. 2023. Disentangled representation learning with large language models for text-attributed graphs. CoRR, abs/2310.18152.</p>
<p>Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly a reward model. CoRR, abs/2305.18290.</p>
<p>Walid S. Saba. 2023. Stochastic llms do not understand language: Towards symbolic, explainable and ontologically based llms. In Conceptual Modeling - 42nd International Conference, ER 2023, Lisbon, Portugal, November 6-9, 2023, Proceedings, volume 14320 of Lecture Notes in Computer Science, pages 3-19. Springer.</p>
<p>Phillip Schneider, Tim Schopf, Juraj Vladika, Mikhail Galkin, Elena Simperl, and Florian Matthes. 2022. A decade of knowledge graphs in natural language processing: A survey. CoRR, abs/2210.00105.</p>
<p>Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI Mag., 29(3):93-106.</p>
<p>Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke Zettlemoyer, and Scott Wen-tau Yih. 2023. Trusting your evidence: Hallucinate less with context-aware decoding. CoRR, abs/2305.14739.</p>
<p>Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA, pages 4444-4451. AAAI Press.</p>
<p>Weiwei Sun, Zhengliang Shi, Shen Gao, Pengjie Ren, Maarten de Rijke, and Zhaochun Ren. 2023. Contrastive learning reduces hallucination in conversations. In Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence, IAAI 2023, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023, Washington, DC, USA, February 7-14, 2023, pages 1361813626. AAAI Press.</p>
<p>Mirac Suzgun, Nathan Scales, Nathanael Schrli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed Chi, Denny Zhou, and Jason Wei. 2023. Challenging big-bench tasks and whether chain-of-thought can solve them. In Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 13003-13051. Association for Computational Linguistics.</p>
<p>Derek Tam, Anisha Mascarenhas, Shiyue Zhang, Sarah Kwan, Mohit Bansal, and Colin Raffel. 2023. Evaluating the factual consistency of large language models through news summarization. In Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023, pages 52205255. Association for Computational Linguistics.</p>
<p>Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, and Chao Huang. 2023. Graphgpt: Graph instruction tuning for large language models. CoRR, abs/2310.13023.</p>
<p>Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang, Nitesh V. Chawla, and Panpan Xu. 2023. Graph neural prompting with large language models. CoRR, abs/2309.15427.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, Faisal Azhar, Aurlien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurlien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023b. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288.</p>
<p>Nandinbaatar Tsog, Saad Mubeen, Fredrik Bruhn, Moris Behnam, and Mikael Sjdin. 2021. Offloading accelerator-intensive workloads in CPU-GPU heterogeneous processors. In 26th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2021, Vasteras, Sweden, September 7-10, 2021, pages 1-8. IEEE.</p>
<p>Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, and Yulia Tsvetkov. 2023a. Can language models solve graph problems in natural language? CoRR, abs/2305.10037.</p>
<p>Jianing Wang, Wenkang Huang, Minghui Qiu, Qiuhui Shi, Hongbin Wang, Xiang Li, and Ming Gao. 2022. Knowledge prompting in pre-trained language model for natural language understanding. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 3164-3177. Association for Computational Linguistics.</p>
<p>Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, and Ming Gao. 2023b. Boosting language models reasoning with chain-of-knowledge prompting. CoRR, abs/2306.06427.</p>
<p>Xiao Wang, Weikang Zhou, Can Zu, Han Xia, Tianze Chen, Yuansen Zhang, Rui Zheng, Junjie Ye, Qi Zhang, Tao Gui, Jihua Kang, Jingsheng Yang, Siyuan Li, and Chunsai Du. 2023c. Instructuie: Multi-task instruction tuning for unified information extraction. CoRR, abs/2304.08085.</p>
<p>Xiaolei Wang, Xinyu Tang, Xin Zhao, Jingyuan Wang, and Ji-Rong Wen. 2023d. Rethinking the evaluation for conversational recommendation in the era of large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 10052-10065. Association for Computational Linguistics.</p>
<p>Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. 2021. KEPLER: A unified model for knowledge embedding and pre-trained language representation. Trans. Assoc. Comput. Linguistics, 9:176-194.</p>
<p>Man-Fai Wong, Shangxin Guo, Ching Nam Hang, SiuWai Ho, and Chee-Wei Tan. 2023. Natural language generation and understanding of big code for ai-assisted programming: A review. Entropy, 25(6):888.</p>
<p>Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, and Jun Liu. 2023. Symbol-llm: Towards foundational symbolcentric interface for large language models. CoRR, abs/2311.09278.</p>
<p>Ke Yang, Jiateng Liu, John Wu, Chaoqi Yang, Yi R. Fung, Sha Li, Zixuan Huang, Xu Cao, Xingyao Wang, Yiquan Wang, Heng Ji, and Chengxiang Zhai. 2024. If LLM is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents. CoRR, abs/2401.00812.</p>
<p>Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, and Yongfeng Zhang. 2023. Natural language is all a graph needs. CoRR, abs/2308.07134.</p>
<p>Zheni Zeng, Bangchen Yin, Shipeng Wang, Jiarui Liu, Cheng Yang, Haishen Yao, Xingzhi Sun, Maosong Sun, Guotong Xie, and Zhiyuan Liu. 2023. Interactive molecular discovery with natural language. CoRR, abs/2306.11976.</p>
<p>Jiawei Zhang. 2023. Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt. CoRR, abs/2304.11116.</p>
<p>Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D. Manning, and Jure Leskovec. 2022. Greaselm: Graph reasoning enhanced language models. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net.</p>
<p>Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei</p>
<p>Bi, Freda Shi, and Shuming Shi. 2023a. Siren's song in the AI ocean: A survey on hallucination in large language models. CoRR, abs/2309.01219.</p>
<p>Zeyang Zhang, Xin Wang, Ziwei Zhang, Haoyang Li, Yijian Qin, Simin Wu, and Wenwu Zhu. 2023b. Llm4dyg: Can large language models solve problems on dynamic graphs? CoRR, abs/2310.17110.</p>
<p>Haiteng Zhao, Shengchao Liu, Chang Ma, Hannan Xu, Jie Fu, Zhi-Hong Deng, Lingpeng Kong, and Qi Liu. 2023a. GIMLET: A unified graph-text model for instruction-based molecule zero-shot learning. CoRR, abs/2306.13089.</p>
<p>Jianan Zhao, Le Zhuo, Yikang Shen, Meng Qu, Kai Liu, Michael M. Bronstein, Zhaocheng Zhu, and Jian Tang. 2023b. Graphtext: Graph reasoning in text space. CoRR, abs/2310.01089.</p>
<p>Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023c. A survey of large language models. CoRR, abs/2303.18223.</p>
<p>Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, Alban Desmaison, Can Balioglu, Pritam Damania, Bernard Nguyen, Geeta Chauhan, Yuchen Hao, Ajit Mathews, and Shen Li. 2023d. Pytorch FSDP: experiences on scaling fully sharded data parallel. Proc. VLDB Endow., 16(12):3848-3860.</p>
<p>Zhiyuan Zhao, Bin Wang, Linke Ouyang, Xiaoyi Dong, Jiaqi Wang, and Conghui He. 2023e. Beyond hallucinations: Enhancing lvlms through hallucination-aware direct preference optimization. CoRR, abs/2311.16839.</p>
<p>Mantong Zhou, Minlie Huang, and Xiaoyan Zhu. 2018. An interpretable reasoning network for multi-relation question answering. In Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August 20-26, 2018, pages 2010-2022. Association for Computational Linguistics.</p>
<h2>A Details of the InstructGraph Corpus</h2>
<p>In this section, we provide some details of the corpus construction including both instruction and preference perspective.</p>
<h2>A. 1 Instruction Tuning Dataset</h2>
<p>To merge all graph-oriented reasoning and generation tasks, we collect and construct 29 tasks to form instruction data. We do not construct training sets for graph thought modeling.</p>
<p>Graph Structure Modeling Graph structure modeling aims to urge the LLM to understand the structure of a graph along with the corresponding task-specific instruction. To reach this aim, we collect structure dataset NLGraph (Wang et al., 2023a). The original dataset consists of 8 different tasks, such as Connectivity Detection, Cycle Detection, Topological Sorting, Shortest Path Computing, Maximum Flow Computing, Bipartite Graph Matching, Hamilton Path Detection and GNN Embedding. Yet, the authors Wang et al. (2023a) mentioned that the current LLMs are hard to perform on more complex graph reasoning, such as Topological Sorting, Maximum Flow Computing, and GNN Embedding, so we remove them. In addition, we also random sample some graphs of NLGraph, and construct a Degree Computing task.</p>
<ul>
<li>Connectivity Detection: detect whether there exists a path between two nodes in the graph. This task is a binary classification and the answer should be 'The answer is yes' or 'The answer is no'.</li>
<li>Cycle Detection: determine if there is a cycle in this graph. This task is a binary classification and the answer should be 'Yes' or 'No'.</li>
<li>Topological Sorting: determine if there is a path that visits every node exactly once in this graph. This task is a binary classification and the answer should be 'Yes' or 'No'.</li>
<li>Bipartite Graph Matching: detect whether there exists an edge between two given nodes in a bipartite graph. This task is a binary classification and the answer should be 'Yes' or 'No'.</li>
<li>Shortest Path Computing: find the shortest path between two nodes in the graph, and calculate the sum of the weights in the shortest path. The answer is a sequence of the path with a value.</li>
<li>Graph Degree Computing: calculate the degree of the target node in the graph. The answer is an integer value.</li>
</ul>
<p>Graph Language Modeling Graph language modeling aims to teach the LLM to understand both the structure and semantics knowledge of the graph and answer the question. We decompose this</p>
<table>
<thead>
<tr>
<th>Clusters</th>
<th>Tasks</th>
<th>Source</th>
<th>Sampling</th>
<th>Instruction Dataset</th>
<th></th>
<th>Preference Dataset</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td>#Train</td>
<td>#Test</td>
<td>#Train</td>
<td>#Test</td>
</tr>
<tr>
<td>Structure</td>
<td>Conn. Dect.</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>3,737</td>
<td>237</td>
<td>2,227</td>
<td>463</td>
</tr>
<tr>
<td></td>
<td>Cycle Dect.</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>2,877</td>
<td>191</td>
<td>863</td>
<td>191</td>
</tr>
<tr>
<td></td>
<td>Hami. Path</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>1,315</td>
<td>55</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Bipt. Match</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>1,755</td>
<td>71</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Shrt. Path</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>1,580</td>
<td>64</td>
<td>948</td>
<td>128</td>
</tr>
<tr>
<td></td>
<td>Degree Comp.</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Up</td>
<td>2,435</td>
<td>230</td>
<td>1,429</td>
<td>445</td>
</tr>
<tr>
<td>Caption</td>
<td>Wikipedia</td>
<td><em>Wang et al. (2022)</em></td>
<td>Down</td>
<td>516,585</td>
<td>1,979</td>
<td>15,208</td>
<td>4,785</td>
</tr>
<tr>
<td></td>
<td>WebNLG</td>
<td><em>Gardent et al. (2017)</em></td>
<td>100%</td>
<td>12,237</td>
<td>2,000</td>
<td>6,040</td>
<td>2,616</td>
</tr>
<tr>
<td></td>
<td>GenWiki</td>
<td><em>Jin et al. (2020)</em></td>
<td>100%</td>
<td>99,997</td>
<td>1,000</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>EventNA</td>
<td><em>Colas et al. (2021)</em></td>
<td>100%</td>
<td>58,733</td>
<td>1,952</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Xalign</td>
<td><em>Abhishek et al. (2022)</em></td>
<td>100%</td>
<td>30,000</td>
<td>470</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Graph QA</td>
<td>PathQSP</td>
<td><em>Zhou et al. (2018)</em></td>
<td>Down</td>
<td>30,530</td>
<td>1,000</td>
<td>27477</td>
<td>3,000</td>
</tr>
<tr>
<td></td>
<td>GrailQA</td>
<td><em>Gu et al. (2021)</em></td>
<td>Down</td>
<td>13,797</td>
<td>1,421</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>WebQSP</td>
<td><em>Berant et al. (2013)</em></td>
<td>Down</td>
<td>13,152</td>
<td>1,465</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>WikiTQ</td>
<td><em>Pasupat and Liang (2015)</em></td>
<td>Down</td>
<td>2,780</td>
<td>688</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Node CLS</td>
<td>Cora</td>
<td><em>McCallum et al. (2000)</em></td>
<td>Down</td>
<td>548</td>
<td>961</td>
<td>166</td>
<td>965</td>
</tr>
<tr>
<td></td>
<td>Citeseer</td>
<td><em>Giles et al. (1998)</em></td>
<td>Down</td>
<td>943</td>
<td>995</td>
<td>284</td>
<td>990</td>
</tr>
<tr>
<td></td>
<td>Pubmed</td>
<td><em>Sen et al. (2008)</em></td>
<td>Down</td>
<td>9,736</td>
<td>1,756</td>
<td>2,988</td>
<td>1,789</td>
</tr>
<tr>
<td></td>
<td>Arxiv</td>
<td><em>Hu et al. (2020)</em></td>
<td>Down</td>
<td>9,710</td>
<td>400</td>
<td>2,705</td>
<td>325</td>
</tr>
<tr>
<td></td>
<td>Products</td>
<td><em>Hu et al. (2020)</em></td>
<td>Down</td>
<td>19,975</td>
<td>1,688</td>
<td>5,995</td>
<td>1,719</td>
</tr>
<tr>
<td>Link Pred.</td>
<td>Wikidata</td>
<td><em>Wang et al. (2022)</em></td>
<td>Down</td>
<td>49,320</td>
<td>3,190</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>FB15K-237</td>
<td><em>Bollacker et al. (2008)</em></td>
<td>Down</td>
<td>2,988</td>
<td>92</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>ConceptNet</td>
<td><em>Speer et al. (2017)</em></td>
<td>Down</td>
<td>21,240</td>
<td>598</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Relevance</td>
<td>Wikipedia</td>
<td><em>Wang et al. (2022)</em></td>
<td>Down</td>
<td>39,672</td>
<td>1,991</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>RecSys</td>
<td>Amazon</td>
<td><em>He and McAuley (2016)</em></td>
<td>Down</td>
<td>2,424</td>
<td>250</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>IE</td>
<td>Wikipedia</td>
<td><em>Wang et al. (2022)</em></td>
<td>Down</td>
<td>73,101</td>
<td>1,814</td>
<td>19,490</td>
<td>1,589</td>
</tr>
<tr>
<td></td>
<td>UIE</td>
<td><em>Wang et al. (2023c)</em></td>
<td>100%</td>
<td>285,877</td>
<td>3,000</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>InstructKGC</td>
<td><em>Gui et al. (2023)</em></td>
<td>Down</td>
<td>31,605</td>
<td>994</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Graph Gen.</td>
<td>NLGraph</td>
<td><em>Wang et al. (2023a)</em></td>
<td>Down</td>
<td>3,056</td>
<td>407</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>The total number of the corpus</td>
<td></td>
<td></td>
<td></td>
<td>1,341,885</td>
<td>30,959</td>
<td>85,820</td>
<td>19,005</td>
</tr>
</tbody>
</table>
<p>Table 10: The data statistics of each graph task for graph instruction tuning and preference alignment.
group into 6 kinds of tasks, including graph caption generation, graph question answering, graph node classification, graph link prediction, graph relevance inspection, and graph collaboration filtering.</p>
<ul>
<li>Graph caption generation: generate an encyclopedia passage when given a knowledge graph with all entities and structure triples representing factual and commonsense knowledge. We directly choose the datasets from WebNLG <em>Gardent et al. (2017)</em>, GenWiki <em>Jin et al. (2020)</em>, EventNarrative <em>Colas et al. (2021)</em>, XAlign <em>Abhishek et al. (2022)</em>. In addition, we also follow <em>Wang et al. (2022)</em> to collect the Wikipedia corpus and corresponding wikidata knowledge graph to build the caption task. Specifically, we use the AC automatic machine algorithm to recognize all entities in the passage and construct a 2-hop sub-graph based on the topic entity.</li>
<li>Graph question answering: find an entity and a reasoning path in the graph to answer the question. We directly collect the corpus from PathQuestions <em>Zhou et al. (2018)</em>, GrailQA <em>Gu et al. (2021)</em>, WebQuestions <em>Berant et al. (2013)</em>, WikiTableQuestions <em>Pasupat and Liang (2015)</em>. Especially, the WikiTableQuestions is a table understanding task that answers a question based on the table. To make our framework support this kind of task, we perform preprocessing that transforms each row line of the table into a single graph, where the table head is the relation name and each cell is the entity.</li>
<li>Graph node classification: classify the target node based on the corresponding graph. We directly choose from Cora <em>McCallum et al. (2000)</em>, Citeseer <em>Giles et al. (1998)</em>, Pubmed <em>Sen et al. (2008)</em>, OGBN-ArXiv, and OGBN-Products <em>Hu et al. (2020)</em>. Because</li>
</ul>
<table>
<thead>
<tr>
<th>Task Name</th>
<th>Hallucination Type</th>
<th>Positive Answer</th>
<th>Negative Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Conn. Dect. Cycle Detect. Shrt. Path Degree Comp.</td>
<td>Correct graph but wrong answer</td>
<td><The original answer></td>
<td><Randomly sampled from other examples></td>
</tr>
<tr>
<td></td>
<td>Unfactual graph but wrong answer</td>
<td>Sorry, the graph contains some wrong knowledge in the follow: <list all unfactual triples>. So the question is unanswerable, you had better provide a correct graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td></td>
<td>Conflict graph but wrong answer</td>
<td>Sorry, the graph contains some conflict edges in the follow: <list all conflict triples>. So the question is unanswerable, you had better provide a correct graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td></td>
<td>Missing graph but wrong answer</td>
<td>Sorry, the graph does not exist node node name. So the question is unanswerable, you had better provide a correct graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td>Caption</td>
<td>Correct graph but wrong answer</td>
<td><The original answer></td>
<td><Randomly sampled from other examples></td>
</tr>
<tr>
<td></td>
<td>Unfactual graph but wrong answer</td>
<td>Sorry, the graph contains some wrong knowledge in the follow: <list all unfactual triples>. based on the corrected graph, the answer can be <The original answer>.</td>
<td><The original answer></td>
</tr>
<tr>
<td></td>
<td>Conflict graph but wrong answer</td>
<td>Sorry, the graph contains some conflict edges in the follow: <list all conflict triples>. So the question is unanswerable, you had better provide a correct graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td>Graph QA</td>
<td>Correct graph but wrong answer</td>
<td><The original answer></td>
<td><Randomly sampled from other examples></td>
</tr>
<tr>
<td></td>
<td>Unfactual graph but wrong answer</td>
<td>Sorry, the graph contains some wrong knowledge in the follow: <list all unfactual triples>. based on the corrected graph, the answer can be <The original answer>.</td>
<td><The original answer></td>
</tr>
<tr>
<td></td>
<td>Conflict graph but wrong answer</td>
<td>Sorry, the graph contains some conflict edges in the follow: <list all conflict triples>. So the question is unanswerable, you had better provide a correct graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td></td>
<td>Missing graph but wrong answer</td>
<td>Based on the world knowledge, the correct answer to the question is <The original answer>, but the answer does not exist in the graph.</td>
<td><The original answer></td>
</tr>
<tr>
<td>Node CLS</td>
<td>Correct graph but wrong answer</td>
<td><The original answer></td>
<td><Randomly sampled from other examples></td>
</tr>
<tr>
<td>IE</td>
<td>Wrong input but wrong graph</td>
<td><The original graph></td>
<td><Randomly sampled from other examples></td>
</tr>
<tr>
<td></td>
<td>Correct input but unfaithful graph</td>
<td><The original graph></td>
<td><Randomly edit entities in the original graph></td>
</tr>
<tr>
<td></td>
<td>Correct input but unfactual graph</td>
<td><Randomly edit edges in the original graph></td>
<td><The original graph></td>
</tr>
<tr>
<td></td>
<td>Correct input but missing or redundant information in graph</td>
<td><Randomly remove or add edges in the original graph></td>
<td><The original graph></td>
</tr>
</tbody>
</table>
<p>Table 11: The positive and negative answer of each example for preference alignment.
the graph in these tasks is too big, we only sample a 2-hop sub-graph of centering each target node. We also perform down-sampling for each task.</p>
<ul>
<li>Graph link prediction: classify the edge (relation) between two given nodes (entities) based on the graph. We choose three main knowledge graph, such as Wikidata (Wang et al., 2021), Freebase (Bollacker et al., 2008), ConceptNet (Speer et al., 2017). Specifically, we random sample a subset of triples, and then extract and merge two 2-hop sub-graphs that center with two entities, respectively.</li>
<li>Graph relevance inspection: inspect whether the caption is relevant to the graph. The task is a binary classification with two categories, i.e., "relevant" and "irrelevant". We directly use the same corpus from wikipedia (Wang et al., 2022) in graph caption generation task. For the negative sampling of each graph, we directly choose other captions.</li>
<li>Graph Collaboration Filtering: predict the score that the user node prefers to the target item node based on the collaboration graph. We choose the widely used Amazon (He and</li>
</ul>
<p>McAuley, 2016) as the corpus. Because the Amazon dataset does not provide any graph data, we thus perform a preprocessing stage to construct a collaboration graph. Specifically, we calculate the Jaccard similarity between each pair of users based on their preference items and then recall the top-10 similarity users for each user to form a graph. Hence, we can inject this graph into the LLM to let it know how to recommend some items based on all potential users.</p>
<p>Graph Generation Modeling This group aims to guide the LLM to generate a graph in a codelike format. We consider two challenging graph generation domains, including, knowledge graph generation and structure graph generation.</p>
<ul>
<li>
<p>Knowledge graph generation: similar to information extraction which aims to extract entities and relations when given one passage. We directly choose the corpus from unified information extraction (UIE) (Wang et al., 2023c; Gui et al., 2023), which consists of 21 used named entity recognition (NER) tasks, 10 used relation extraction (RE), and 4 used event extraction (EE).</p>
</li>
<li>
<p>Structure graph generation: generate a structure graph based on the description. For example, when given a graph description is "Please generate a full-connection un-directed graph with four nodes ranging from 0 to 3.", the expected codelike format graph is "Graph[name='structuregraph']node_list=[0, 1, 2, 3]; edge_list=[(0 $&lt;-&gt;1),(0&lt;-&gt;2),(0&lt;-&gt;3),(1&lt;-&gt;2),(1&lt;-&gt;$ 3), (2 &lt;-&gt; 3)];". We can directly reuse the corpus from NLGraph (Wang et al., 2023a) and sample a subset to build this task.</p>
</li>
</ul>
<h1>A. 2 Preference Alignment Dataset</h1>
<p>We have selected a partial dataset from the graph instruction tuning dataset for preference alignment. This dataset includes Connection Detection, Cycle Detection, Shortest Path Computing, Degree Computing, Graph Caption with Wikipedia and WebNLG, Graph QA with PathQSP, Node CLS with Cora, Citeseer, Pubmed, Arxiv, and Products, and IE with Wikipedia.</p>
<p>For each task, we design positive and negative answers to support preference alignment. Details are shown in Table 11.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{11}$ Prefix-Embedd: only tune the input embeddings layer; Prefix-Layer: tune each transformer layer.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{6}$ The implementation is referred to https://github. com/facebookresearch/llama-recipes.
${ }^{7}$ https://platform.openai.com/.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>