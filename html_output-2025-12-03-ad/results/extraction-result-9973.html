<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9973 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9973</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9973</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-170.html">extraction-schema-170</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <p><strong>Paper ID:</strong> paper-278635941</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.09848v1.pdf" target="_blank">Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection</a></p>
                <p><strong>Paper Abstract:</strong> Imaging and genomic data offer distinct and rich features, and their integration can unveil new insights into the complex landscape of diseases. In this study, we present a novel approach utilizing radiogenomic data including structural MRI images and gene expression data, for Alzheimer's disease detection. Our framework introduces a novel heterogeneous bipartite graph representation learning featuring two distinct node types: genes and images. The network can effectively classify Alzheimer's disease (AD) into three distinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN) classes, utilizing a small dataset. Additionally, it identified which genes play a significant role in each of these classification groups. We evaluate the performance of our approach using metrics including classification accuracy, recall, precision, and F1 score. The proposed technique holds potential for extending to radiogenomic-based classification to other diseases.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9973.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9973.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Protein aggregates</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Abnormal protein aggregates in brain (amyloid/tau implied)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Paper describes accumulation of abnormal protein aggregates in the brain as a central pathological hallmark of Alzheimer's disease that leads to progressive neuronal loss and cognitive decline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>molecular / proteinopathy</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>Accumulation of abnormal protein aggregates in the brain (paper states this generally; amyloid-beta and tau pathology are implied though not explicitly named in the main text).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>The paper states this accumulation as the primary characterization of AD in the Introduction, consistent with the canonical description of AD pathology; the statement is used as background rather than as new experimental evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>No direct refuting experimental evidence is presented in the paper. The paper does not discuss failed amyloid-targeting trials or other challenges to the protein-aggregation hypothesis.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>biological hallmark, detectable via imaging/biomarkers</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>Indirect detection via PET imaging (molecular imaging of protein aggregates) and CSF/plasma biomarkers (not detailed experimentally in this paper, but mentioned among modalities in related work comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>No direct sensitivity/specificity numbers for imaging/CSF of protein aggregates provided in this paper; referenced multimodal studies in Table report high accuracies when PET/CSF are combined with other modalities (e.g., MRI+PET+SNP reported accuracy 96.1% in a referenced work), but those numbers are taken from cited studies and not produced here.</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>background statement; referenced imaging/biomarker studies (reviewed by citation list)</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>Not specified for the general statement in this paper (background).</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Paper does not discuss controversies about the protein-aggregation hypothesis, but does emphasize that imaging signs of downstream effects (e.g., atrophy) are not disease-specific.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9973.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9973.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>APOE / PSEN1 / PSEN2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>APOE (Apolipoprotein E), PSEN1 (Presenilin 1), PSEN2 (Presenilin 2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Three well-known genetic drivers associated with Alzheimer's disease used in this study as genomics features (gene expression) for radiogenomic classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>genetic</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>Genetic association: APOE and presenilin genes (PSEN1, PSEN2) are treated as driver genes linked to AD risk/pathogenesis; these genes' expression values were used as genomics features in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>Paper selects these three genes because of their 'well-known association' with AD and uses their expression in experiments; integrating these gene expression features with MRI improved classification performance (see model performance with three genes + MRI). The Introduction and Methods explicitly state that these genes were chosen for known association with AD.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>The paper does not present direct counter-evidence refuting causality of these genes. Limitations include that only three genes were used and no causal inference analyses were performed.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>genetic / gene-expression biomarker</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>Gene expression values for APOE (dimension 52x1), PSEN1 (52x4), PSEN2 (52x4) were normalized and used as node features in a bipartite graph model together with MRI-derived features.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>When integrated with MRI in the paper's model (BGRL), the combination of APOE, PSEN1, PSEN2 with imaging produced the best reported classification results: AD vs CN accuracy 92%, F1 93%, recall 100%, precision 87.5% (reported for the integrated model using learned edge weights). The paper does not report standalone sensitivity/specificity for gene-only classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>computational classification study using ADNI-derived gene expression and MRI features (case-control classification).</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>52 samples total (equal numbers representing CN, MCI, AD) drawn from ADNI2 and ADNIGO; gene feature dimensions reported in Methods; samples with missing genomics were excluded.</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Limited gene set (three genes) — not a genome-wide analysis; small sample size (52) limits generalizability; no external validation cohort reported; gene expression used rather than genotype/SNP arrays in the experiments; paper does not address population diversity or replication.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9973.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9973.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structural MRI / hippocampal atrophy</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural magnetic resonance imaging (sMRI) and hippocampal volume loss</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Structural MRI is used to assess brain atrophy (including hippocampal volume) as a non-invasive diagnostic tool for AD, but the paper emphasizes specificity limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>neuroanatomical biomarker (imaging-derived change)</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>Brain atrophy, including degradation of hippocampal volume, is described as a hallmark imaging finding associated with AD, though it may be non-specific and arise in other disorders.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>MRI is widely used and the paper cites many imaging studies; in the present work MRI-derived features (3D autoencoder latent features) are a primary input modality and contribute to high classification performance when combined with genomics. Table entries from cited studies report MRI-alone results (e.g., MRI 88.4% accuracy in a referenced comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>Paper explicitly notes that brain atrophy (including hippocampal volume loss) is not disease-specific and can result from Parkinson's disease, Huntington's disease, cardiac arrest, alcohol dependence, and other conditions — cited literature examples are provided. Thus hippocampal atrophy alone is insufficient to establish AD diagnosis.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>neuroimaging (structural MRI)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>sMRI measures global and regional brain volumes and atrophy patterns; in this paper 3D MRI scans (preprocessed to 64 slices) were passed through a 3D denoising autoencoder to extract latent imaging features used for classification.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>Referenced MRI-only performance (from Table) includes example accuracies such as 88.4% (cited work) for AD vs CN; within this paper the integrated MRI+genes model outperforms MRI alone (integrated accuracy 92% vs MRI-alone benchmarks shown in Table). The paper does not consistently report sensitivity/specificity for MRI-alone in their own experiments; recall/precision values are provided for the integrated model.</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>imaging-based machine-learning classification (this paper uses ADNI images and cites other MRI studies).</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>In this study: 52 ADNI subjects (ADNI2 and ADNIGO) with preprocessed 3D MRI (170×256×256 reduced to 64 slices); referenced studies use various ADNI cohorts (not all population details provided in-paper).</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Main limitation emphasized: structural MRI measures of atrophy are not specific to AD and can result from other neurological and non-neurological conditions; imaging can be expensive, time-consuming, and less accessible for some patients; repeated scans may be required for accurate detection. The present study's small sample size and potential lack of generalizability also limit claims about MRI utility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9973.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9973.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PET / CSF multimodal biomarkers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Positron Emission Tomography (PET) and cerebrospinal fluid (CSF) biomarkers (mentioned via multimodal comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Paper references PET imaging and CSF biomarkers as modalities that, when combined with MRI and genomics, have produced high classification performance in prior studies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>diagnostic biomarkers (molecular imaging / fluid biomarkers)</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>PET can image functional or molecular processes (e.g., metabolic change or protein aggregates) and CSF biomarkers measure molecules (e.g., amyloid-beta, tau) reflective of AD pathology; these modalities are discussed as complementary to MRI and genomics.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>Referenced studies in Table show high reported accuracies when PET and CSF are included (e.g., MRI+PET+SNP accuracy 96.1% in a cited work; MRI+PET+CSF+SNP reported accuracy 94.8%). Those results are from external cited works summarized in the comparison table.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>The paper does not provide counter-evidence against PET/CSF biomarkers; however it notes that multi-modal integration is often superior to single modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>molecular imaging (PET) and fluid biomarker (CSF)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>PET provides imaging of brain function or molecular targets; CSF analysis measures concentrations of disease-related proteins; both are discussed as parts of multimodal pipelines in prior literature (cited in Table).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>Performance numbers are taken from cited studies summarized in Table (e.g., combined-modality pipelines achieving accuracies in the mid-90s), but the present paper does not generate new PET/CSF-specific sensitivity/specificity values.</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>referenced multimodal machine-learning studies (comparative table entries summarizing prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>Not detailed within this paper for the referenced PET/CSF studies (they are summarized from the literature).</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Paper does not analyze PET/CSF limitations in detail here, but includes them in the set of modalities that can improve classification when combined; practical limitations (cost, invasiveness for CSF lumbar puncture) are indirectly implied by the paper's discussion of expense and accessibility for imaging modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9973.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9973.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Radiogenomic BGRL (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Radiogenomic Bipartite Graph Representation Learning (BGRL) for Alzheimer's detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors' novel heterogeneous bipartite graph neural network that fuses structural MRI-derived features and gene expression (APOE, PSEN1, PSEN2) via dynamically learned inter-modality edge weights to classify AD, MCI, and CN.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>method / diagnostic algorithm (multimodal computational detection)</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>Not a cause; this is a detection algorithm that models relationships between imaging and gene-expression nodes (genes and images) using a bipartite graph with learned dynamic edge weights.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>N/A (method). Evidence for method effectiveness is provided by experiments on ADNI-derived data: integrating MRI with APOE/PSEN1/PSEN2 gene expression and using learned dynamic edge weights produced improved classification metrics compared to ablated variants.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>N/A (method). Ablation experiments show that removing dynamic weight learning or omitting genes reduces performance, indicating dependencies and limitations of the approach.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>computational multimodal classifier (radiogenomic; graph neural network)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>3D denoising autoencoder extracts latent MRI features which, together with normalized gene-expression features for three genes, are assembled into a bipartite graph (genes <-> images). A heterogeneous GNN learns a dynamic adjacency (edge weights) from a Gaussian prior and uses aggregated node embeddings for downstream classification into AD / MCI / CN.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>Reported best results (AD vs CN) for the integrated model with learned edge weights: accuracy 92%, F1-score 93%, recall 100%, precision 87.5% (paper also reports ~91% accuracy and F1~92.3% for MCI vs AD in places). Ablation: for AD vs CN, 'with learned weights' achieved 83.33% accuracy in one ablation comparison (16% better than without), while the fully integrated reported best-case accuracy was 92%—the paper presents multiple performance summaries (main reported best-case numbers are 92% accuracy, F1 93%).</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>computational machine-learning classification study using ADNI imaging and gene-expression data (case-control classification; ablation experiments included).</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>52 subjects from ADNI2 and ADNIGO (equal numbers of CN, MCI, AD) used in the main experiments; additional classification tasks used sample sizes of 115, 52, and 78 in separate experiments (paper states these numbers without full per-task breakdown); 80/20 train-test splits used.</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Major limitations reported or implied: small dataset (52 subjects) and exclusion of samples with missing genomics; limited genomics (only three genes); potential for overfitting (long training epochs, small N); variability in reported numbers across tables/ablation (inconsistencies in reported accuracy for 'with weights' across sections); lack of external validation cohort; no full sensitivity/specificity estimates beyond recall/precision for some comparisons; no longitudinal / early preclinical-stage detection claims are validated here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9973.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9973.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of proposed causes of Alzheimer's disease, supporting or refuting evidence for each cause, methods for detecting Alzheimer's disease (including biomarkers, imaging, cognitive tests, etc.), and the effectiveness of these detection methods (such as sensitivity, specificity, and stage of detection). Also extract any controversies, limitations, or counter-evidence related to causes or detection methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Genomics + Imaging integration</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Radiogenomic integration of imaging and genomics features (general modality)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper emphasizes that combining imaging (MRI) and genomics (gene expression or SNPs) improves predictive performance for AD detection compared to single-modality approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>cause_type</strong></td>
                            <td>diagnostic strategy / multimodal biomarker</td>
                        </tr>
                        <tr>
                            <td><strong>cause_description</strong></td>
                            <td>Integration of imaging-derived features with genomics (gene expression, SNPs) as complementary data sources for AD detection and progression prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_cause</strong></td>
                            <td>Authors cite prior studies and provide experiments showing that their multimodal bipartite approach outperforms single-modality baselines; explicit claim: incorporating imaging and genomic features leads to superior model performance compared to relying solely on either imaging or genomics data (cited literature and demonstrated in their experiments). The ablation study shows that removing dynamic edge weights or omitting genes reduces accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_cause</strong></td>
                            <td>No direct refuting evidence in this paper; however the paper notes practical constraints (imaging expense/accessibility) that motivate inclusion of genomics as a potentially cost-effective supplement.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_type</strong></td>
                            <td>multimodal biomarker / computational fusion</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method_description</strong></td>
                            <td>Fusion implemented either in prior work via concatenation/fusion layers or, in this paper, via a bipartite graph with dynamic adjacency learning; genomics modalities referenced include gene expression and SNPs from the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_performance</strong></td>
                            <td>This paper reports that multimodal fusion (MRI + APOE/PSEN1/PSEN2 via BGRL) achieves top classification metrics for AD vs CN (accuracy 92%, F1 93%, recall 100%, precision 87.5%). The literature summarized in Table shows other multimodal combinations achieving very high accuracies (e.g., MRI+PET+SNP 96.1%, MRI+PET+CSF+SNP 94.8%), indicating multimodal advantage across studies.</td>
                        </tr>
                        <tr>
                            <td><strong>study_type</strong></td>
                            <td>comparative machine-learning studies; this paper provides an experimental demonstration using ADNI data and references multiple prior multimodal works.</td>
                        </tr>
                        <tr>
                            <td><strong>study_population</strong></td>
                            <td>This paper: ADNI-derived samples (52 main subjects for experiments) and other experiments with sample counts reported (115, 52, 78) depending on the task; referenced studies use various ADNI cohorts (not fully detailed here).</td>
                        </tr>
                        <tr>
                            <td><strong>controversies_or_limitations</strong></td>
                            <td>Limitations include that multimodal benefit depends on modality quality and availability (e.g., PET/CSF costly or invasive), small sample sizes limit confidence in generalizability, and naive fusion (concatenation) used in many prior works may ignore modality interactions (motivation for the bipartite graph approach). The paper does not evaluate long-term predictive validity or robustness across diverse populations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>App, psen1, and psen2 mutations in early-onset alzheimer disease: A genetic screening study of familial and sporadic cases. <em>(Rating: 2)</em></li>
                <li>Brain imaging in alzheimer disease. <em>(Rating: 2)</em></li>
                <li>Imaging techniques in alzheimer's disease: a review of applications in early diagnosis and longitudinal monitoring. <em>(Rating: 2)</em></li>
                <li>Integrative analysis of multi-dimensional imaging genomics data for alzheimer's disease prediction. <em>(Rating: 2)</em></li>
                <li>Radiomics analysis of magnetic resonance imaging facilitates the identification of preclinical alzheimer's disease: an exploratory study. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9973",
    "paper_id": "paper-278635941",
    "extraction_schema_id": "extraction-schema-170",
    "extracted_data": [
        {
            "name_short": "Protein aggregates",
            "name_full": "Abnormal protein aggregates in brain (amyloid/tau implied)",
            "brief_description": "Paper describes accumulation of abnormal protein aggregates in the brain as a central pathological hallmark of Alzheimer's disease that leads to progressive neuronal loss and cognitive decline.",
            "citation_title": "",
            "mention_or_use": "mention",
            "cause_type": "molecular / proteinopathy",
            "cause_description": "Accumulation of abnormal protein aggregates in the brain (paper states this generally; amyloid-beta and tau pathology are implied though not explicitly named in the main text).",
            "evidence_for_cause": "The paper states this accumulation as the primary characterization of AD in the Introduction, consistent with the canonical description of AD pathology; the statement is used as background rather than as new experimental evidence.",
            "evidence_against_cause": "No direct refuting experimental evidence is presented in the paper. The paper does not discuss failed amyloid-targeting trials or other challenges to the protein-aggregation hypothesis.",
            "detection_method_type": "biological hallmark, detectable via imaging/biomarkers",
            "detection_method_description": "Indirect detection via PET imaging (molecular imaging of protein aggregates) and CSF/plasma biomarkers (not detailed experimentally in this paper, but mentioned among modalities in related work comparisons).",
            "detection_performance": "No direct sensitivity/specificity numbers for imaging/CSF of protein aggregates provided in this paper; referenced multimodal studies in Table report high accuracies when PET/CSF are combined with other modalities (e.g., MRI+PET+SNP reported accuracy 96.1% in a referenced work), but those numbers are taken from cited studies and not produced here.",
            "study_type": "background statement; referenced imaging/biomarker studies (reviewed by citation list)",
            "study_population": "Not specified for the general statement in this paper (background).",
            "controversies_or_limitations": "Paper does not discuss controversies about the protein-aggregation hypothesis, but does emphasize that imaging signs of downstream effects (e.g., atrophy) are not disease-specific.",
            "uuid": "e9973.0",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "APOE / PSEN1 / PSEN2",
            "name_full": "APOE (Apolipoprotein E), PSEN1 (Presenilin 1), PSEN2 (Presenilin 2)",
            "brief_description": "Three well-known genetic drivers associated with Alzheimer's disease used in this study as genomics features (gene expression) for radiogenomic classification.",
            "citation_title": "",
            "mention_or_use": "use",
            "cause_type": "genetic",
            "cause_description": "Genetic association: APOE and presenilin genes (PSEN1, PSEN2) are treated as driver genes linked to AD risk/pathogenesis; these genes' expression values were used as genomics features in the model.",
            "evidence_for_cause": "Paper selects these three genes because of their 'well-known association' with AD and uses their expression in experiments; integrating these gene expression features with MRI improved classification performance (see model performance with three genes + MRI). The Introduction and Methods explicitly state that these genes were chosen for known association with AD.",
            "evidence_against_cause": "The paper does not present direct counter-evidence refuting causality of these genes. Limitations include that only three genes were used and no causal inference analyses were performed.",
            "detection_method_type": "genetic / gene-expression biomarker",
            "detection_method_description": "Gene expression values for APOE (dimension 52x1), PSEN1 (52x4), PSEN2 (52x4) were normalized and used as node features in a bipartite graph model together with MRI-derived features.",
            "detection_performance": "When integrated with MRI in the paper's model (BGRL), the combination of APOE, PSEN1, PSEN2 with imaging produced the best reported classification results: AD vs CN accuracy 92%, F1 93%, recall 100%, precision 87.5% (reported for the integrated model using learned edge weights). The paper does not report standalone sensitivity/specificity for gene-only classifiers.",
            "study_type": "computational classification study using ADNI-derived gene expression and MRI features (case-control classification).",
            "study_population": "52 samples total (equal numbers representing CN, MCI, AD) drawn from ADNI2 and ADNIGO; gene feature dimensions reported in Methods; samples with missing genomics were excluded.",
            "controversies_or_limitations": "Limited gene set (three genes) — not a genome-wide analysis; small sample size (52) limits generalizability; no external validation cohort reported; gene expression used rather than genotype/SNP arrays in the experiments; paper does not address population diversity or replication.",
            "uuid": "e9973.1",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Structural MRI / hippocampal atrophy",
            "name_full": "Structural magnetic resonance imaging (sMRI) and hippocampal volume loss",
            "brief_description": "Structural MRI is used to assess brain atrophy (including hippocampal volume) as a non-invasive diagnostic tool for AD, but the paper emphasizes specificity limitations.",
            "citation_title": "",
            "mention_or_use": "use",
            "cause_type": "neuroanatomical biomarker (imaging-derived change)",
            "cause_description": "Brain atrophy, including degradation of hippocampal volume, is described as a hallmark imaging finding associated with AD, though it may be non-specific and arise in other disorders.",
            "evidence_for_cause": "MRI is widely used and the paper cites many imaging studies; in the present work MRI-derived features (3D autoencoder latent features) are a primary input modality and contribute to high classification performance when combined with genomics. Table entries from cited studies report MRI-alone results (e.g., MRI 88.4% accuracy in a referenced comparison).",
            "evidence_against_cause": "Paper explicitly notes that brain atrophy (including hippocampal volume loss) is not disease-specific and can result from Parkinson's disease, Huntington's disease, cardiac arrest, alcohol dependence, and other conditions — cited literature examples are provided. Thus hippocampal atrophy alone is insufficient to establish AD diagnosis.",
            "detection_method_type": "neuroimaging (structural MRI)",
            "detection_method_description": "sMRI measures global and regional brain volumes and atrophy patterns; in this paper 3D MRI scans (preprocessed to 64 slices) were passed through a 3D denoising autoencoder to extract latent imaging features used for classification.",
            "detection_performance": "Referenced MRI-only performance (from Table) includes example accuracies such as 88.4% (cited work) for AD vs CN; within this paper the integrated MRI+genes model outperforms MRI alone (integrated accuracy 92% vs MRI-alone benchmarks shown in Table). The paper does not consistently report sensitivity/specificity for MRI-alone in their own experiments; recall/precision values are provided for the integrated model.",
            "study_type": "imaging-based machine-learning classification (this paper uses ADNI images and cites other MRI studies).",
            "study_population": "In this study: 52 ADNI subjects (ADNI2 and ADNIGO) with preprocessed 3D MRI (170×256×256 reduced to 64 slices); referenced studies use various ADNI cohorts (not all population details provided in-paper).",
            "controversies_or_limitations": "Main limitation emphasized: structural MRI measures of atrophy are not specific to AD and can result from other neurological and non-neurological conditions; imaging can be expensive, time-consuming, and less accessible for some patients; repeated scans may be required for accurate detection. The present study's small sample size and potential lack of generalizability also limit claims about MRI utility.",
            "uuid": "e9973.2",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "PET / CSF multimodal biomarkers",
            "name_full": "Positron Emission Tomography (PET) and cerebrospinal fluid (CSF) biomarkers (mentioned via multimodal comparisons)",
            "brief_description": "Paper references PET imaging and CSF biomarkers as modalities that, when combined with MRI and genomics, have produced high classification performance in prior studies.",
            "citation_title": "",
            "mention_or_use": "mention",
            "cause_type": "diagnostic biomarkers (molecular imaging / fluid biomarkers)",
            "cause_description": "PET can image functional or molecular processes (e.g., metabolic change or protein aggregates) and CSF biomarkers measure molecules (e.g., amyloid-beta, tau) reflective of AD pathology; these modalities are discussed as complementary to MRI and genomics.",
            "evidence_for_cause": "Referenced studies in Table show high reported accuracies when PET and CSF are included (e.g., MRI+PET+SNP accuracy 96.1% in a cited work; MRI+PET+CSF+SNP reported accuracy 94.8%). Those results are from external cited works summarized in the comparison table.",
            "evidence_against_cause": "The paper does not provide counter-evidence against PET/CSF biomarkers; however it notes that multi-modal integration is often superior to single modalities.",
            "detection_method_type": "molecular imaging (PET) and fluid biomarker (CSF)",
            "detection_method_description": "PET provides imaging of brain function or molecular targets; CSF analysis measures concentrations of disease-related proteins; both are discussed as parts of multimodal pipelines in prior literature (cited in Table).",
            "detection_performance": "Performance numbers are taken from cited studies summarized in Table (e.g., combined-modality pipelines achieving accuracies in the mid-90s), but the present paper does not generate new PET/CSF-specific sensitivity/specificity values.",
            "study_type": "referenced multimodal machine-learning studies (comparative table entries summarizing prior work).",
            "study_population": "Not detailed within this paper for the referenced PET/CSF studies (they are summarized from the literature).",
            "controversies_or_limitations": "Paper does not analyze PET/CSF limitations in detail here, but includes them in the set of modalities that can improve classification when combined; practical limitations (cost, invasiveness for CSF lumbar puncture) are indirectly implied by the paper's discussion of expense and accessibility for imaging modalities.",
            "uuid": "e9973.3",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Radiogenomic BGRL (this work)",
            "name_full": "Radiogenomic Bipartite Graph Representation Learning (BGRL) for Alzheimer's detection",
            "brief_description": "The authors' novel heterogeneous bipartite graph neural network that fuses structural MRI-derived features and gene expression (APOE, PSEN1, PSEN2) via dynamically learned inter-modality edge weights to classify AD, MCI, and CN.",
            "citation_title": "here",
            "mention_or_use": "use",
            "cause_type": "method / diagnostic algorithm (multimodal computational detection)",
            "cause_description": "Not a cause; this is a detection algorithm that models relationships between imaging and gene-expression nodes (genes and images) using a bipartite graph with learned dynamic edge weights.",
            "evidence_for_cause": "N/A (method). Evidence for method effectiveness is provided by experiments on ADNI-derived data: integrating MRI with APOE/PSEN1/PSEN2 gene expression and using learned dynamic edge weights produced improved classification metrics compared to ablated variants.",
            "evidence_against_cause": "N/A (method). Ablation experiments show that removing dynamic weight learning or omitting genes reduces performance, indicating dependencies and limitations of the approach.",
            "detection_method_type": "computational multimodal classifier (radiogenomic; graph neural network)",
            "detection_method_description": "3D denoising autoencoder extracts latent MRI features which, together with normalized gene-expression features for three genes, are assembled into a bipartite graph (genes &lt;-&gt; images). A heterogeneous GNN learns a dynamic adjacency (edge weights) from a Gaussian prior and uses aggregated node embeddings for downstream classification into AD / MCI / CN.",
            "detection_performance": "Reported best results (AD vs CN) for the integrated model with learned edge weights: accuracy 92%, F1-score 93%, recall 100%, precision 87.5% (paper also reports ~91% accuracy and F1~92.3% for MCI vs AD in places). Ablation: for AD vs CN, 'with learned weights' achieved 83.33% accuracy in one ablation comparison (16% better than without), while the fully integrated reported best-case accuracy was 92%—the paper presents multiple performance summaries (main reported best-case numbers are 92% accuracy, F1 93%).",
            "study_type": "computational machine-learning classification study using ADNI imaging and gene-expression data (case-control classification; ablation experiments included).",
            "study_population": "52 subjects from ADNI2 and ADNIGO (equal numbers of CN, MCI, AD) used in the main experiments; additional classification tasks used sample sizes of 115, 52, and 78 in separate experiments (paper states these numbers without full per-task breakdown); 80/20 train-test splits used.",
            "controversies_or_limitations": "Major limitations reported or implied: small dataset (52 subjects) and exclusion of samples with missing genomics; limited genomics (only three genes); potential for overfitting (long training epochs, small N); variability in reported numbers across tables/ablation (inconsistencies in reported accuracy for 'with weights' across sections); lack of external validation cohort; no full sensitivity/specificity estimates beyond recall/precision for some comparisons; no longitudinal / early preclinical-stage detection claims are validated here.",
            "uuid": "e9973.4",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Genomics + Imaging integration",
            "name_full": "Radiogenomic integration of imaging and genomics features (general modality)",
            "brief_description": "The paper emphasizes that combining imaging (MRI) and genomics (gene expression or SNPs) improves predictive performance for AD detection compared to single-modality approaches.",
            "citation_title": "",
            "mention_or_use": "use",
            "cause_type": "diagnostic strategy / multimodal biomarker",
            "cause_description": "Integration of imaging-derived features with genomics (gene expression, SNPs) as complementary data sources for AD detection and progression prediction.",
            "evidence_for_cause": "Authors cite prior studies and provide experiments showing that their multimodal bipartite approach outperforms single-modality baselines; explicit claim: incorporating imaging and genomic features leads to superior model performance compared to relying solely on either imaging or genomics data (cited literature and demonstrated in their experiments). The ablation study shows that removing dynamic edge weights or omitting genes reduces accuracy.",
            "evidence_against_cause": "No direct refuting evidence in this paper; however the paper notes practical constraints (imaging expense/accessibility) that motivate inclusion of genomics as a potentially cost-effective supplement.",
            "detection_method_type": "multimodal biomarker / computational fusion",
            "detection_method_description": "Fusion implemented either in prior work via concatenation/fusion layers or, in this paper, via a bipartite graph with dynamic adjacency learning; genomics modalities referenced include gene expression and SNPs from the literature.",
            "detection_performance": "This paper reports that multimodal fusion (MRI + APOE/PSEN1/PSEN2 via BGRL) achieves top classification metrics for AD vs CN (accuracy 92%, F1 93%, recall 100%, precision 87.5%). The literature summarized in Table shows other multimodal combinations achieving very high accuracies (e.g., MRI+PET+SNP 96.1%, MRI+PET+CSF+SNP 94.8%), indicating multimodal advantage across studies.",
            "study_type": "comparative machine-learning studies; this paper provides an experimental demonstration using ADNI data and references multiple prior multimodal works.",
            "study_population": "This paper: ADNI-derived samples (52 main subjects for experiments) and other experiments with sample counts reported (115, 52, 78) depending on the task; referenced studies use various ADNI cohorts (not fully detailed here).",
            "controversies_or_limitations": "Limitations include that multimodal benefit depends on modality quality and availability (e.g., PET/CSF costly or invasive), small sample sizes limit confidence in generalizability, and naive fusion (concatenation) used in many prior works may ignore modality interactions (motivation for the bipartite graph approach). The paper does not evaluate long-term predictive validity or robustness across diverse populations.",
            "uuid": "e9973.5",
            "source_info": {
                "paper_title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "App, psen1, and psen2 mutations in early-onset alzheimer disease: A genetic screening study of familial and sporadic cases.",
            "rating": 2,
            "sanitized_title": "app_psen1_and_psen2_mutations_in_earlyonset_alzheimer_disease_a_genetic_screening_study_of_familial_and_sporadic_cases"
        },
        {
            "paper_title": "Brain imaging in alzheimer disease.",
            "rating": 2,
            "sanitized_title": "brain_imaging_in_alzheimer_disease"
        },
        {
            "paper_title": "Imaging techniques in alzheimer's disease: a review of applications in early diagnosis and longitudinal monitoring.",
            "rating": 2,
            "sanitized_title": "imaging_techniques_in_alzheimers_disease_a_review_of_applications_in_early_diagnosis_and_longitudinal_monitoring"
        },
        {
            "paper_title": "Integrative analysis of multi-dimensional imaging genomics data for alzheimer's disease prediction.",
            "rating": 2,
            "sanitized_title": "integrative_analysis_of_multidimensional_imaging_genomics_data_for_alzheimers_disease_prediction"
        },
        {
            "paper_title": "Radiomics analysis of magnetic resonance imaging facilitates the identification of preclinical alzheimer's disease: an exploratory study.",
            "rating": 2,
            "sanitized_title": "radiomics_analysis_of_magnetic_resonance_imaging_facilitates_the_identification_of_preclinical_alzheimers_disease_an_exploratory_study"
        }
    ],
    "cost": 0.014911499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection
14 May 2025</p>
<p>Aditya Raj 
Department of Electrical and Computer Engineering
Ohio State University
43210ColumbusOHUSA</p>
<p>Golrokh Mirzaei mirzaei.4@osu.edu 
Department of Computer Science and Engineering
Ohio State University
43210ColumbusOHUSA</p>
<p>Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection
14 May 202505C4FD3A3FCBA978BB360C79D6783ECCarXiv:2505.09848v1[cs.LG]imaging genomicsgraph representation learningAlzheimer
Imaging and genomic data offer distinct and rich features, and their integration can unveil new insights into the complex landscape of diseases.In this study, we present a novel approach utilizing radiogenomic data including structural MRI images and gene expression data, for Alzheimer's disease detection.Our framework introduces a novel heterogeneous bipartite graph representation learning featuring two distinct node types: genes and images.The network can effectively classify Alzheimer's disease (AD) into three distinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN) classes, utilizing a small dataset.Additionally, it identified which genes play a significant role in each of these classification groups.We evaluate the performance of our approach using metrics including classification accuracy, recall, precision, and F1 score.The proposed technique holds potential for extending to radiogenomic-based classification to other diseases.</p>
<p>Introduction</p>
<p>Alzheimer's disease (AD) is one of the most prevalent neurodegenerative conditions that progressively impairs cognitive function and overall functionality in individuals.It primarily targets the aging population and is characterized by the accumulation of abnormal protein aggregates in the brain, which leads to the gradual destruction of nerve cells and neural connections.Consequently, those afflicted with Alzheimer's often experience memory loss, difficulties in thinking, problem-solving, and language skills, as well as changes in behavior and personality.</p>
<p>Currently, imaging is one of the common techniques used to assess Alzheimer's disease.Neuroimaging methods, such as MRI and PET scans, offer detailed insights into the brain's structure and function.The benefits of utilizing imaging data as a non-invasive diagnostic tool are significant; however, there are also some limitations associated with this approach.Imaging techniques can be expensive and, on their own, may not provide conclusive results.Additionally, accessibility can be an issue for some individuals, and the process can be time-consuming, often requiring multiple scans for accurate pathology detection.Furthermore, when it comes to structural MRI (sMRI)-based Alzheimer's detection, brain atrophy is not disease-specific and can result from various other conditions [8,22].For example, the degradation of hippocampus volume, considered a vital biomarker for Alzheimer's, has also been associated with several other neurodegenerative disorders, including Parkinson's disease [3], Huntington's disease [20], and even non-neurological conditions like cardiac arrest [5] and alcohol dependence [1].Therefore, it becomes essential to develop diagnostic tools that incorporate more than just imaging data.Mirzaei et al. provided comprehensive surveys of different imaging and machine learning techniques for AD detection [14] [15].</p>
<p>Studies has demonstrated that incorporating imaging and genomic features leads to superior model performance compared to relying solely on either imaging or genomics data in disease detection [11,21].Genomics can offer supplementary information and often serves as a cost-effective alternative in various cases compared to repeated imaging scans.Thus, the integration of genomics and imaging features holds the promise of designing diagnostic tools that are not only costefficient but also capable of providing conclusive assessments.Imaging genomics has recently received attention in AD detection [4], AD biomarker prediction [27], and the progression analysis of Mild Cognitive Impairment (MCIs) to AD [7].</p>
<p>Majority of current radiogenomic studies integrate imaging features and genomics using standard concatenation in a form of matrix or fusion layer [12] [6].However, this approach may disregard the inherent complexities and interactions within the data.Other studies have focused on using one type of modality, either genomics or imaging for AD detection.For instance, Mirzaei [13] and Kavitha et al. [9] utilized MRI imaging, while Nativio et al. [16] solely focused on genomics.</p>
<p>In this study, we propose a bipartite graph representation learning (BGRL) for AD detection using radiogenomic data, which includes structural MRI images and gene expression data for three AD driver genes (PSEN1, PSEN2, and APOE).These genes are chosen for their well-known association with Alzheimer's disease.The bipartite graph is constructed based on two sets of nodes: images and genes.We assume that there are no edges between the nodes within the same modality.Subsequently, a dynamic adjacency matrix is learned through training, which establishes the connections between nodes (image and genes).We introduce a novel aggregation function for learning weights, derived from a randomly sampled prior.The proposed framework is evaluated using performance metrics, including accuracy, F1 score, recall, and precision.</p>
<p>Methods</p>
<p>Given a multimodal dataset consisting pairs of MRI images and gene expression data for three driver genes associated with AD (PSEN1, PSEN2, and APOE), our method learns the structural information of the graph for the downstream classification task.As shown in Fig. 1, the overall framework consists of three parts: 1) 3D autoEncoder denoising for feature extraction, 2) Bipartite graph construction by fusion of imaging and genomics data, and 3) Radiogenomic graph structure learning and classification.In the subsequent sections, we will introduce each part of our proposed framework in detail.</p>
<p>3D Denoising Autoencoder for Feature Extraction</p>
<p>We utilize a 3D denoising autoencoder to extract features from MRI data.The autoencoder consists of an encoder function f e and a decoder function f d .Gaussian noise µ ∼ N (0, 1) is added to the normalized feature vector x, resulting in a noisy input x ′ = x + µ, which is then used as input to the encoder model.Subsequently, the output of the encoder, denoted as f e (x ′ ), is utilized to extract latent features via a fully connected network.Additionally, f e (x ′ ) is passed as input to the decoder function to produce the output f d (f e (x ′ )).To evaluate the quality of the reconstruction, a mean square error is computed between f d (f e (x ′ )) and x, as shown in Eqn.1.
Loss = ||f d (f e (x ′ )) − x|| 2(1)
The reconstruction loss measures how well the decoder can generate a reconstructed input from the encoded features.The 3D denoising autoencoder consists of three layers of 3D convolutional networks followed by batch normalization, Recitified Linear Unit (Relu) activation function, and 3D max pooling.The latent features extracted from the encoder's output are used for the fusion with genomics.The detailed architecture of the 3D convolution-based autoencoder is provided in Supplementary Table 1.</p>
<p>Radiogenomic Bipartite Graph Construction</p>
<p>A bipartite graph G = (U, V, E) is represented by two sets of different domains U (genes) and V (Images), and a set of edges E ⊂ U × V .Bipartite graphs contain only inter-domain edges between genes and images.Each sample represents</p>
<p>Bipartite Graph Neural Network</p>
<p>A graph neural network (GNN) consists of three fundamental steps: message passing, aggregating, and updating [28].Consider a given graph G = (V, E), where V represents the set of nodes, and X ∈ R d×|V | represents the node features, where d is dimension of each node feature, and |V | is the total number of nodes in the graph.Let's assume the node embedding denoted as h k u at step k, where u ∈ {V }.According to the Update function, the node embedding is updated based on its neighborhood, represented as N (u), as [24]:
h (k+1) u = Update (k) (h (k) u , m(k)N (u) )(2)
where h
(k+1) u
represents the updated node embedding at step k + 1 and is calculated by applying the Update function to the previous embedding h  N (u) .The aggregation process involves collecting information from neighboring nodes (such as node v).We define these two functions with weights w self and w neigh as the following.where σ represent a non linearity.Finally, the message passing in GNN can be expressed as:
Update(h u , m Nu ) = σ(W self (h u ) + W neigh (m Nu ))(3)h (k+1) u = σ(W (k) self (h (k) u ) + W (k) neigh ( v∈N (u) h (k) v ) + b)(4)
where b denotes the bias term.In the proposed approach, the goal is to learn a dynamic adjacency matrix that establishes connections between different types of nodes based on their respective node features.During training, the weights associated with each edge are dynamically updated.The primary objective is to identify the optimal edge weights, denoted as w (1,4) , w (2,4) , and w (3,4) , while classifying the subgraphs extracted from the bipartite graph into AD, MCI, or CN groups.We introduce an aggregation function for learning weights associated with each type of edge, which is derived from a randomly sampled prior.This approach stands in contrast to the graph attention network (GAT) ( [23]), where the attention parameters are implicitly learned through a neural network using concatenated node feature embeddings as input.In our formulation, we have four types of nodes as i, j, k and l; and four types of edges: i → l, j → l and k → l.Further, let |V i |,|V j |, |V k | and |V l | represent the number of neighboring nodes around each type of node.The node features for each type are represented as
X i ∈ R di×|Vi| , X j ∈ R dj ×|Vj | , X k ∈ R d k ×|V k | and X l ∈ R d l ×|V l | .
We initialize a prior α sampled from a random Gaussian distribution with a mean of 0 and a standard variation of 1.This prior remains consistent for all types of nodes.Subsequently, we compute a higher dimensional representation z for each type of edge using the formula z = ϕα, where, ϕ represents a differentiable learnable function, in this case a fully connected neural network layer.Following this, we calculate the edge weights, denoted by e.For instance, the edge weights e i,l is computed as e i,l = σ(x i .z.x T l ), where σ is non-linearity(Relu).We then compute the node embedding, represented as h, for each node using the formula h = V x, where V is a neural network with learnable parameters.Finally, we employ the aggregation function to compute the updated embedding for each node, as:
h n+1 p = σ( q∈N (p) e n p,q h n q )(5)
where n denotes the iteration, p is the node for which we wish to compute the node embedding and q represents the nodes in the neighborhood of p.</p>
<p>The framework of the proposed heterogeneous graph neural network is shown in Fig. 3, where f i denotes the features associated with each node, and t j represents the higher dimensional feature representation for each type of edge in the graph.The core component of the network includes a matrix multiplication block, which takes as input the feature vectors and t j , resulting in the computation of edge weights w j associated with each edge.The calculated weights in junction with the feature embeddings, are subsequently supplied as input to the aggregation block.The output of this aggregation block serves as the input to the prediction block, which generates the final classification score.Throughout this process, the loss is computed and back-propagated through the neural network blocks.Finally, we compute the averaged weight parameters for positive and negative samples per feature dimension in the test set to identify which gene contributes more significantly to the final graph classification score.Eqn.6 outlines the formula employed to compute the average weights for both classes separately.In this equation, p can take values {0, 1, 2} representing the three genes, d p represents the features dimension of the p th node, and N corresponds to the total number of subgraphs.
w avg (p,4) = 1 d p N k=1 w k p,4(6)</p>
<p>Experiments and Results</p>
<p>Datasets.All image and genomics data are publicly available.We collected MRI images and genomic data for three AD driver genes [10], namely APOE (Apolipoprotein E), PSEN1 (Presenilin 1), and PSEN2 (Presenilin 2) from the Alzheimer's Disease Neuroimaging Initiative (ADNI) https : //adni.loni.usc.edu/.</p>
<p>A total of 52 samples, with an equal number of subjects representing three classes (CN, MCI, and AD), were collected from ADNI2 and ADNIGO datasets.Each 3D MRI image had dimension of 170 × 256 × 256 and underwent preprocessing using a histogram-based ranking method [18].This preprocessing step reduced the number of slices per sample in the 3D MRI to 64 slices.These processed samples served as input for the denoising autoencoder for feature extraction.The final imaging features had dimension of 52 × 512.The gene expression data dimensions were as follows: 52 × 1 for AP OE, 52 × 4 for P SEN 1, and 52 × 4 for P SEN 2. The genomics features were normalized using the min-max normalization.Samples with missing corresponding genomics data were excluded from the dataset.</p>
<p>Implementation Details.The denoising autoencoder feature extraction was trained for total of 100 epochs using Adam optimizer with a learning rate of 9e − 4. Additionally, a cosine annealing learning rate scheduler was employed.The bipartite GNN training was conducted over 800 epochs with the Adam optimizer and learning rate of 9e − 3.Both the autoencoder and GNN models were trained using the mean square error loss function.Experiments were performed using all three genes for learning, as well as all possible permutations involving two genes.This allowed us to thoroughly investigate the effects of different gene combinations on our model's performance.We conducted binary classification experiments distinguishing between MCI vs. CN, MCI vs. AD, CN vs AD, and a three-way classification task involving MCI, AD, and CN.The feature dimensions of the genes and imaging data remained consistent across these classification tasks.The total number of samples used for training were 115, 52, and 78 for three additional classification tasks.In all cases, a standard 80-20 train-test split was employed.</p>
<p>Results.In Table 1, our approach shows improved prediction accuracy by integrating the MRI image and the genomics data for the three genes.Our method outperforms state-of-the-art-models in all AD vs CN, AD vs MCI, CN vs MCI by integrating both image and genomics modality.Additionally, the the performance metrics for binary classification (MCI vs AD, MCI vs NC, AD vs NC) and 3-level classification (NC vs MCI vs AD) tasks using accoracy, F1-score, recall, precision is provided in Supplementary Table 2.The highest accuracy of 92% and F1-score of 93% is achieved for the classification of AD vs CN using the proposed weight learning.The model also achieved slightly less results for MCI and AD classification (accuracy of 91% and F1 score of 92.3%).Additionally, Supplementary Table 3 shows the averaged weights learned over test data.The computation of edge weights is carried out using the formula outlined in Eqn.6.</p>
<p>Ablation Study</p>
<p>We verified the model efficiency by evaluating the effect of graph structure learning.Specifically, we trained the model with and without dynamic edge weights, as shown in  2. Performance of the proposed model for the AD vs. CN classification task on the test set, comparing results with and without dynamic weight learning using all three genes for training provided the most robust performance across all metrics.With learned weights, this set achieved an accuracy of 83.33%, surpassing the performance without weights by 16%.Nevertheless, the performance of the two genes and the image remains inferior to the accuracy achieved with all three genes and image combined.In fact, the integrated performance attained an accuracy of 92%, F1 score of 93%, recall of 100%, and precision of 87.5% when incorporating all three genes and the image, surpassing the performance achieved by omitting any individual modality.</p>
<p>Conclusion</p>
<p>In this study, we proposed a novel multimodal bipartite graph representation learning to exploit the complementary relationship of genomics and MRI images for Alzheimer's disease detection.Specifically, we introduced a fusion model (gene expression and structural MRI) using a bipartite graph in which the edges are leaned dynamically through the training of a graph neural network.Addition-ally, we identified the importance of the edges by introducing averaged weight over the edges.Experimental results demonstrate the superior performance of the proposed approach compared to the state-of-the-art methods.</p>
<p>Fig. 1 .
1
Fig. 1.The proposed framework of bipartite graph representation learning with imaging genomics data.</p>
<p>Fig. 2 .
2
Fig. 2. The bipartite graph construction for imaging-genomics fusion in AD detection.(A) graph containing all samples in the study.(B) Subgraph representing one sample.</p>
<p>Fig. 3 .
3
Fig. 3.The heterogeneous bipartite GNN model with dynamic edge weight learning.</p>
<p>Table 2 .
2
It can be observed that the model achieves an accuracy of 92%, utilizing the learned edge weights, which represents a 17% improvement compared to the scenario without using weights.Additionally, we assessed the effect of the integrated model by retaining two genes and imaaging while removing one gene.The classification results based on two gene permutations, with and without dynamic weight learning, are shown in Supplementary Table4.Among the gene permutations, the combination of {P SEN 1, P SEN 2, M RI}
Classification Task :AD vs. CN %AD vs. MCI % CN vs. MCI %Method ModalityAcc F1BAAcc F1BAAcc F1BAMRI88.4 88.32 88.5 ---71.6 60.41 65.5[17] SSRSNP (135 genes) 76 MRI + SNP 91.1 91.17 91.2 -75.66 76.2 -----66.2 58.73 61.75 74.9 67.14 70.1MRI + PET + SNP96.1 96.08 96.1 ---80.3 76.89 77.7SNP (189 genes) 62--64--66--[26] SMMLMRI MRI + SNP86 87----67 69----69 70----MRI + PET + CSF + SNP94.8 94.74 94.75 69.1 69.24 69.25 75.6 74.87 74.9[25]DSCCA MRI + CSF + Plasma PMA92.12 -83.38 ---70.33 -67.72 ---75.26 -53.51 ---SNP85.3 47.6 69.6 88.7 35.3 64.9 59.1 71.9 49.8[12]MRI MRI + SNP92.2 68.1 79 94.1 76.4 83.6 91.8 48.7 70.9 61.7 71.2 56.8 88.4 26.4 59.5 63.2 71.5 59.7[2]CERF + SVMfMRI + SNP87-----80--[19]RL + reg.GE (3 genes)70.31 707063.80 61.75 62.30 58.33 57.77 57.87[18] LRCN MRI71.28 68.4 69------Ours BGRL MRI + GE929393.75 9192.3 92.85 7878.26 82.14</p>
<p>Table 1 .
1
Comparison with existing works for the task of AD vs. CN, AD vs.MCI and CN vs.MCI binary classification using ADNI dataset
Experiment with all four nodes : Imaging + Genes (APOE, PSEN1, PSEN2)Learning weightsF1 scoreRecall Precision AccuracyMacro AverageWeighted Averagew/o60% 100% 42%75%70%72%w93% 100% 87.5% 92%91%91%Table
Acknowledgment.The results of this study are based on the data collected from the public ADNI dataset https : //adni.loni.usc.edu/.
Hippocampal volume in patients with alcohol dependence. Ingrid Agartz, Reza Momenan, Michael J Robert R Rawlings, Daniel W Kerich, Hommer, Archives of general psychiatry. 5641999</p>
<p>Multimodal data analysis of alzheimer's disease based on clustering evolutionary random forest. Xia-An Bi, Xi Hu, Hao Wu, Yang Wang, IEEE Journal of Biomedical and Health Informatics. 24102020</p>
<p>Parkinson's disease is associated with hippocampal atrophy. Richard Camicioli, Anthony Milar Moore, Elizabeth Kinney, Kathryn Corbridge, Jeffrey A Glassberg, Kaye, Movement disorders. 1872003</p>
<p>Deep radiomic analysis of mri related to alzheimer's disease. Ahmad Chaddad, Christian Desrosiers, Tamim Niazi, Ieee Access. 62018</p>
<p>Hippocampal damage in the human brain after cardiac arrest. Masayuki Fujioka, Kenji Nishio, Seiji Miyamoto, Ken-Ichiro Hiramatsu, Toshisuke Sakaki, Kazuo Okuchi, Toshiaki Taoka, Susumu Fujioka, Cerebrovascular diseases. 1012000</p>
<p>Goo-Rak Known, and the Alzheimer's Disease Neuroimaging Initiative. Prediction and classification of alzheimer's disease based on combined features from apolipoprotein-e genotype, cerebrospinal fluid, mr, and fdg-pet imaging biomarkers. Yabraj Gupta, Ramesh Kumar Lama, Frontiers in Computational Neuroscience. IEEE201913</p>
<p>Kuangyu Shi, and for the Alzheimer's Disease Neuroimaging Initiative. Using radiomics-based modelling to predict individual progression from mild cognitive impairment to alzheimer's disease. Jiehui Jiang, Min Wang, Ian Alberts, Xiaoming Sun, Taoran Li, Axel Rominger, Chuantao Zuo, Ying Han, European journal of nuclear medicine and molecular imaging. 4972022</p>
<p>Brain imaging in alzheimer disease. Nick C Keith A Johnson, Reisa A Fox, William E Sperling, Klunk, Cold Spring Harbor perspectives in medicine. 2462132012</p>
<p>Early-stage alzheimer's disease prediction using machine learning models. Kavitha, Vinodhini Mani, Srividhya, Ibrahim Osamah, Carlos Khalaf, Tavera Andres, Romero, Frontiers in Public Health. 2022</p>
<p>App, psen1, and psen2 mutations in early-onset alzheimer disease: A genetic screening study of familial and sporadic cases. Helen-Marie Lanoiselee, Gael Nicolas, David Wallon, Anne Rovelet-Lecrux, Morgane Lacour, PLOS Medicine. 20174</p>
<p>Radiomics analysis of magnetic resonance imaging facilitates the identification of preclinical alzheimer's disease: an exploratory study. Tao-Ran Li, Yue Wu, Juan-Juan Jiang, Hua Lin, Chun-Lei Han, Jie-Hui Jiang, Ying Han, Frontiers in Cell and Developmental Biology. 86057342020</p>
<p>Integrating different data modalities for the classification of alzheimer's disease stages. Lucia Maddalena, Ilaria Granata, Maurizio Giordano, Mario Manzo, Mario Rosario Guarracino, SN Computer Science. 432492023</p>
<p>Ensembles of convolutional neural network pipelines for diagnosis of alzheimer's disease. Golrokh Mirzaei, IEEE 2021 55th Asilomar Conference on Signals, Systems, and Computers. IEEE2021</p>
<p>Imaging and machine learning techniques for diagnosis of alzheimer's disease. Golrokh Mirzaei, Anahita Adeli, Hojjat Adeli, Reviews in the Neurosciences. 201627</p>
<p>Machine learning techniques for diagnosis of alzheimer disease, mild cognitive disorder, and other types of dementia. Golrokh Mirzaei, Hojjat Adeli, Biomedical Signal Processing and Control. Elsevier202272</p>
<p>An integrated multi-omics approach identifies epigenetic alterations associated with alzheimer's disease. Raffaella Nativio, Yemin Lan, Greg Donahue, Nature Genetics. 2020</p>
<p>Structured sparse kernel learning for imaging genetics based alzheimer's disease diagnosis. Jailin Peng, Le An, Xiaofeng Zhu, Yan Jin, Dinggang Shen, Medical Image Computing and Computer-Assisted Intervention-MICCAI 2016: 19th International Conference. Athens, GreeceSpringerOctober 17-21, 2016. 2016Proceedings, Part II 19</p>
<p>End to end trained long term recurrent convolutional network for subject-level alzheimer detection. Aditya Raj, Golrokh Mirzaei, 2022 56th Asilomar Conference on Signals, Systems, and Computers. IEEE2022</p>
<p>Multi-armed bandit approach for multi-omics integration. Aditya Raj, Golrokh Mirzaei, 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2022</p>
<p>Evidence for more widespread cerebral pathology in early hd: an mri-based morphometric analysis. Herminia D Rosas, Koroshetz, Yi Chen, Skeuse, Vangel, Cudkowicz, Caplan, Marek, Seidman, Makris, Neurology. 60102003</p>
<p>Radiomics approach in the neurodegenerative brain. Christian Salvatore, Isabella Castiglioni, Antonio Cerasa, Aging Clinical and Experimental Research. 332021</p>
<p>Imaging techniques in alzheimer's disease: a review of applications in early diagnosis and longitudinal monitoring. Elizabeth Cm De Wieke M Van Oostveen, Lange, International journal of molecular sciences. 22421102021</p>
<p>Graph attention networks. Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, arXiv:1710.109032017arXiv preprint</p>
<p>Graph neural networks. Lingfei Wu, Peng Cui, Jian Pei, Liang Zhao, Le Song, 2022Springer</p>
<p>Identification of discriminative imaging proteomics associations in alzheimer's disease via a novel sparse correlation model. Jingwen Yan, Shannon L Risacher, Kwangsik Nho, Andrew J Saykin, L I Shen, PSB. World Scientific2017</p>
<p>Dinggang Shen, and Alzheimer's Disease Neuroimaging Initiative. Integrative analysis of multi-dimensional imaging genomics data for alzheimer's disease prediction. Ziming Zhang, Heng Huang, Frontiers in aging neuroscience. 62602014</p>
<p>Chuantao Zuo, and Alzheimer's Disease Neuroimaging Initiative. Dual-model radiomic biomarkers predict development of mild cognitive impairment progression to alzheimer's disease. Hucheng Zhou, Jiehui Jiang, Jiaying Lu, Min Wang, Huiwei Zhang, Frontiers in neuroscience. 1210452019</p>
<p>Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun, Graph neural networks: A review of methods and applications. AI open. 20201</p>            </div>
        </div>

    </div>
</body>
</html>