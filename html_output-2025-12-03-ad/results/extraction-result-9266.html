<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9266 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9266</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9266</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-270702371</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.16308v1.pdf" target="_blank">Anomaly Detection of Tabular Data Using LLMs</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zero-shot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective data-generating processes to simulate synthetic batch-level anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9266.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9266.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proprietary, large pre-trained transformer language model by OpenAI used in this work as a zero-shot batch-level anomaly detector on tabular data via text serialization and prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (serialized per-feature one-dimensional lists); synthetic continuous and categorical batches; ODDS tabular datasets</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>ODDS benchmark (various tabular domains), synthetic Gaussian and categorical mixtures</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density region anomalies (contamination with wide distributions); unlabeled anomalies in batches</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot text-prompting: per-feature serialization of scalar values into sentences ("Data i is x_i."), prompt "Abnormal data differ from the majority. Which data are abnormal?", system message "Only answer data indices." Aggregate per-feature responses by counting how many features flagged each row to form anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against transductive learning baselines (ECOD) and KNN on ODDS benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC (area under ROC curve)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported qualitatively: GPT-4 achieves on-par performance with state-of-the-art transductive methods (ECOD) on the ODDS benchmark (no per-dataset numeric AUROC table printed in the main text).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Similar / on-par with ECOD (state-of-the-art transductive method) in zero-shot batch-level anomaly detection on ODDS according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>General LLM limitations apply (context window limits requiring subsampling rows/columns); instruction-following variability across LLMs; numerical precision / arithmetic limitations for LLMs noted but GPT-4 works well zero-shot in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>GPT-4, without task-specific fine-tuning, can act as a strong zero-shot batch-level anomaly detector that identifies low-density regions in tabular batches when data are serialized and simple prompts/system messages are used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9266.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 3.5 (GPT-3.5-turbo family)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proprietary, large transformer LLM by OpenAI evaluated as a zero-shot batch-level anomaly detector using the paper's serialization and prompting approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo-1106 API used)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (serialized per-feature lists); ODDS benchmark; synthetic batches</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>ODDS benchmark and synthetic continuous/categorical batches</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density anomalies in batches</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot prompting with serialized per-feature text and instruction/system messages; same aggregation-by-counts across features to compute anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to ECOD, KNN; also compared to fine-tuned LLMs (Mistral-AD) in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported qualitatively: GPT-3.5 performs worse than fine-tuned Mistral-AD; specific AUROC numbers not shown in main text. Fine-tuned Mistral-AD is reported to outperform GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Worse than best-performing GPT-4; inferior to some fine-tuned open models (Mistral-AD) in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same practical limitations as GPT-4 regarding context window and numerical reasoning; performance inferior to GPT-4 zero-shot and to some fine-tuned models.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates that not all powerful LLMs are equally strong zero-shot anomaly detectors; fine-tuned open models can exceed GPT-3.5 in this task.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9266.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2 (vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 (meta open model, evaluated off-the-shelf)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source large transformer LLM (70B parameter version and other sizes referenced) which, without alignment, makes factual errors on batch-level anomaly detection when used with the paper's prompting/serialization approach.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2 (70B evaluated; 7B also referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained open LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B (vanilla failing case described); 7B also referenced</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (serialized per-feature lists), synthetic batches, ODDS benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>ODDS benchmark and synthetic continuous/categorical batches</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot prompting/serialization identical to other LLMs: per-feature sentences + anomalydetection prompt + system message to restrict format, aggregate per-feature outputs by counting index occurrences.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to fine-tuned versions (Llama2-AD), GPT models, and transductive baselines (KNN, ECOD)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Vanilla Llama-2 (70B) shows failure cases: factual errors (missed anomalies, false positives), inconsistent index-value pairing; quantitative AUROC not cited, but fine-tuning greatly improves performance (Llama2-AD showed average +8.9 AUROC increase over vanilla Llama2 across ODDS datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Vanilla Llama-2 performs worse than fine-tuned Llama2-AD and GPT-4; fine-tuning closes the gap and improves substantially.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Observed factual errors: missing anomalies, false positives, incorrect index-value pairing, outputting indices beyond batch length, listing all rows as abnormal, and producing redundant text that complicates parsing. Instruction-following capability varies.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Large model scale alone (70B) does not guarantee good performance on this numeric tabular AD task without alignment/fine-tuning; alignment via supervised synthetic fine-tuning significantly alleviates these failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9266.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-AD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2 fine-tuned for Anomaly Detection (LoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B Llama-2 model fine-tuned via LoRA on a synthetic supervised anomaly-detection dataset to align it to the batch-level tabular anomaly detection task introduced in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2-AD (Llama-2 7B base + LoRA fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained LLM, LoRA parameter-efficient fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (base model size reported for fine-tuned variant)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (per-feature serialized lists); synthetic continuous (Gaussian mixture) and discrete (categorical mixture) batches for training; ODDS benchmark for evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Synthetic continuous and categorical batches (training/validation) and ODDS benchmark datasets (evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density region anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>End-to-end supervised fine-tuning using synthetic labeled batches: serialize batches into text prompts and train the model to output ground-truth index-format responses; LoRA used to update low-rank adapters while freezing base weights; inference uses same serialization + prompt and aggregation-by-counts.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to vanilla Llama-2, GPT-3.5, GPT-4, and transductive baselines (KNN, ECOD)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Fine-tuning yields substantial improvements: reported average AUROC increase of ~8.9 points over vanilla Llama-2 across ODDS datasets; the fine-tuned 7B Llama-2-AD can detect anomalies in cases where the 70B vanilla Llama-2 failed (qualitative examples shown).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Llama2-AD substantially outperforms unaligned (vanilla) Llama-2; reduces factual indexing errors and substantially increases AUROC; still compared against GPT-4 which is a strong zero-shot performer.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on quality and coverage of synthetic training distributions; may still be limited by context window size and token limits when many rows/columns are present; generalization beyond simulated anomalies depends on synthetic data diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>An end-to-end supervised alignment with synthetic batches and LoRA fine-tuning effectively teaches an LLM what the expected output format/decision is, overcoming numerical reasoning/instruction-following failures without teaching intermediate arithmetic steps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9266.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral (vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral (open transformer LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source transformer LLM evaluated in its vanilla form for zero-shot batch-level anomaly detection using the paper's serialization and prompt scheme.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral (vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (serialized per-feature lists); synthetic batches; ODDS benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>ODDS benchmark and synthetic Gaussian/categorical mixtures</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot prompting with per-feature serialization and instruction/system messages; outputs parsed and aggregated per-feature to form anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to Mistral-AD (fine-tuned), GPT-3.5, GPT-4, KNN, ECOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Vanilla Mistral improved substantially after fine-tuning; average AUROC increase of ~6.7 points when converted to Mistral-AD. Exact vanilla AUROC numbers not listed in-text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Vanilla Mistral is weaker than Mistral-AD and GPT-4; fine-tuning yields notable gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Similar instruction-following variability and redundant output problems as other open models; needs fine-tuning to be reliable for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Open models like Mistral benefit substantially from synthetic supervised alignment; fine-tuning enables them to capture low-density regions and produce parseable, accurate anomaly index outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9266.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral-AD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral fine-tuned for Anomaly Detection (LoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B Mistral model fine-tuned using LoRA on the paper's synthetic dataset to align it to the batch-level tabular anomaly detection task; used to demonstrate detection of low-density regions in contaminated distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-AD (Mistral 7B + LoRA fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (pretrained LLM, LoRA fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular numerical data (serialized per-feature lists); synthetic continuous and categorical batches for training; ODDS benchmark for evaluation; contaminated synthetic 1-D distribution for qualitative density capture experiment</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Synthetic Gaussian mixtures with uniform contamination (1D experiments), ODDS benchmark (real datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / low-density region anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Supervised fine-tuning end-to-end on synthetic labeled batches using LoRA; inference via the same serialization + prompt + aggregation-by-counts; used to collect predicted anomalies across many sampled batches and estimate anomaly density (kernel density estimation) demonstrating identification of low-density regions.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to vanilla Mistral, GPT-3.5, GPT-4, KNN, ECOD</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC (quantitative on ODDS), qualitative density estimation (kernel density estimation over predicted anomaly samples)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Fine-tuning increased average AUROC by ~6.7 points over vanilla Mistral; qualitative experiment: using Mistral-AD on a contaminated 1-D mixture (p(x)=0.45N(-25,2.5^2)+0.45N(25,2.5^2)+0.1Unif(-100,100)), collecting anomalies from 500 batches of 50 points, kernel density estimate of predicted anomalies captured three low-density regions (matching contamination modes). Fine-tuned Mistral-AD outperforms GPT-3.5 in experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Mistral-AD substantially outperforms vanilla Mistral; outperforms GPT-3.5 in reported comparisons; GPT-4 still a strong zero-shot competitor.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Dependence on synthetic training distribution design and coverage; sensitivity to prompt formatting and output parsing; context window limits requiring subsampling when evaluating large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Fine-tuned Mistral-AD can be used not only for per-batch detection but also to empirically recover low-density regions of a global contaminated distribution by aggregating batch-level detections and applying density estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9266.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Serialization / Text formulation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Per-feature Data Serialization and Prompting (text formulation for batch-level AD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method introduced in this paper that converts batch-level tabular anomaly detection into a text-to-text task by serializing each feature's one-dimensional values into natural-language sentences and prompting an LLM to output anomalous row indices.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>n/a (method applied to LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>data / prompt engineering procedure</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data serialized as per-feature 1D lists of scalars (floats approximated to two decimals) and categorical lists</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>General tabular domains (ODDS benchmark and synthetic datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / rows from anomalous distributions</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Assume feature independence; for each feature k, serialize N scalars as sentences 'Data 1 is x_1,k. Data 2 is x_2,k. ...' append prompt 'Abnormal data differ from the majority. Which data are abnormal?' plus system message 'Only answer data indices.' Parse LLM responses per-feature and aggregate counts across features to obtain per-row anomaly scores (s_i = number of features that flagged row i).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>N/A (this is the core method applied to LLMs; compared experimentally to vector input / alternative encodings where vector input degraded performance)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC (when used in full pipeline), density-recovery via kernel density estimation for aggregated anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Enables GPT-4 to be a strong zero-shot detector on ODDS; vector encoding (feeding data as a vector) degraded performance compared to per-feature serialization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Per-feature serialization outperformed vector-style encoding (paper reports performance degradation when using vector input).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Assumes independence across features (paper uses per-feature detection then aggregates); some real datasets may have important cross-feature dependencies lost with this scheme; context/window token limits force subsampling (e.g., 150 rows x 10 columns in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Converting numerical tabular detection to a text-to-text format by serializing per-feature scalars is sufficient for LLMs (particularly GPT-4) to detect low-density anomalies; enforcing a simple system message to restrict output format simplifies parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9266.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9266.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>End-to-end fine-tune (synthetic + LoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>End-to-end supervised fine-tuning with synthetic anomaly batches using LoRA adapters</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fine-tuning strategy introduced in the paper where synthetic labeled batches (continuous Gaussian mixtures and discrete categorical mixtures with random contamination ratios) are used to train LLMs end-to-end (directly on expected output answers) via LoRA parameter-efficient updates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>n/a (fine-tuning method applied to open LLMs like Llama-2 and Mistral)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>training / alignment procedure (supervised LoRA fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>synthetic tabular batches: continuous (narrow Gaussian normal + wide Gaussian anomalies) and discrete (mixture of categorical distributions)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Synthetic training data (2,500 batches per data type used for simulation; training set of 5000 batches and validation of 400 for fine-tuning), applied to ODDS benchmark for evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers / contaminated batch anomalies (contamination ratio Ï€ < 0.2 randomized)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Simulate labeled batches where ground-truth responses are either 'All rows are normal.' or 'Data a1, a2, ... are abnormal.' Train LLMs to map serialized input X to ground-truth response Y by maximizing conditional log-likelihood over tokens; use LoRA (low-rank adapters) so base weights are frozen and only adapters are learned; after training adapters can be merged.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared fine-tuned LLMs (Llama2-AD, Mistral-AD) vs their vanilla counterparts and proprietary GPT models as zero-shot baselines; also compared to transductive methods (ECOD, KNN) on ODDS.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC for ODDS; qualitative density-capture experiments (kernel density estimation) for synthetic contaminated distributions</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Fine-tuning produced large gains: Llama-2 improved by ~8.9 AUROC points on average; Mistral improved by ~6.7 AUROC points; trained models could detect all anomalies in qualitative toy examples where vanilla models failed. Training dataset: 5000 batches (2500 continuous / 2500 discrete), validation 400 batches; Llama-2 fine-tuned for 5 epochs, Mistral for 2 epochs, learning rate 1e-3.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>End-to-end synthetic fine-tuning reliably closes performance gaps vs vanilla open models and can surpass some zero-shot closed models in certain comparisons (e.g., Mistral-AD > GPT-3.5); overall GPT-4 remained a strong zero-shot performer.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Quality of alignment depends on realistic coverage of synthetic data generating processes; chain-of-thought style supervision was avoided because arithmetic reasoning is brittle in LLMs; still subject to context window/token limits at inference and parsing issues if model does not follow output format.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Teaching 'what to expect' via supervised end-to-end outputs (instead of teaching intermediate arithmetic steps) is an effective alignment strategy for LLMs on tabular anomaly detection; LoRA enables parameter-efficient fine-tuning using synthetic batches to correct factual/output-format errors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ODDS library <em>(Rating: 2)</em></li>
                <li>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions <em>(Rating: 2)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9266",
    "paper_id": "paper-270702371",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A proprietary, large pre-trained transformer language model by OpenAI used in this work as a zero-shot batch-level anomaly detector on tabular data via text serialization and prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_type": "transformer (pretrained LLM)",
            "model_size": null,
            "data_type": "tabular numerical data (serialized per-feature one-dimensional lists); synthetic continuous and categorical batches; ODDS tabular datasets",
            "data_domain": "ODDS benchmark (various tabular domains), synthetic Gaussian and categorical mixtures",
            "anomaly_type": "outliers / low-density region anomalies (contamination with wide distributions); unlabeled anomalies in batches",
            "method_description": "Zero-shot text-prompting: per-feature serialization of scalar values into sentences (\"Data i is x_i.\"), prompt \"Abnormal data differ from the majority. Which data are abnormal?\", system message \"Only answer data indices.\" Aggregate per-feature responses by counting how many features flagged each row to form anomaly scores.",
            "baseline_methods": "Compared against transductive learning baselines (ECOD) and KNN on ODDS benchmark",
            "performance_metrics": "AUROC (area under ROC curve)",
            "performance_results": "Reported qualitatively: GPT-4 achieves on-par performance with state-of-the-art transductive methods (ECOD) on the ODDS benchmark (no per-dataset numeric AUROC table printed in the main text).",
            "comparison_to_baseline": "Similar / on-par with ECOD (state-of-the-art transductive method) in zero-shot batch-level anomaly detection on ODDS according to the paper.",
            "limitations_or_failure_cases": "General LLM limitations apply (context window limits requiring subsampling rows/columns); instruction-following variability across LLMs; numerical precision / arithmetic limitations for LLMs noted but GPT-4 works well zero-shot in experiments.",
            "unique_insights": "GPT-4, without task-specific fine-tuning, can act as a strong zero-shot batch-level anomaly detector that identifies low-density regions in tabular batches when data are serialized and simple prompts/system messages are used.",
            "uuid": "e9266.0",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "Generative Pre-trained Transformer 3.5 (GPT-3.5-turbo family)",
            "brief_description": "A proprietary, large transformer LLM by OpenAI evaluated as a zero-shot batch-level anomaly detector using the paper's serialization and prompting approach.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo-1106 API used)",
            "model_type": "transformer (pretrained LLM)",
            "model_size": null,
            "data_type": "tabular numerical data (serialized per-feature lists); ODDS benchmark; synthetic batches",
            "data_domain": "ODDS benchmark and synthetic continuous/categorical batches",
            "anomaly_type": "outliers / low-density anomalies in batches",
            "method_description": "Zero-shot prompting with serialized per-feature text and instruction/system messages; same aggregation-by-counts across features to compute anomaly scores.",
            "baseline_methods": "Compared to ECOD, KNN; also compared to fine-tuned LLMs (Mistral-AD) in experiments",
            "performance_metrics": "AUROC",
            "performance_results": "Reported qualitatively: GPT-3.5 performs worse than fine-tuned Mistral-AD; specific AUROC numbers not shown in main text. Fine-tuned Mistral-AD is reported to outperform GPT-3.5.",
            "comparison_to_baseline": "Worse than best-performing GPT-4; inferior to some fine-tuned open models (Mistral-AD) in experiments.",
            "limitations_or_failure_cases": "Same practical limitations as GPT-4 regarding context window and numerical reasoning; performance inferior to GPT-4 zero-shot and to some fine-tuned models.",
            "unique_insights": "Demonstrates that not all powerful LLMs are equally strong zero-shot anomaly detectors; fine-tuned open models can exceed GPT-3.5 in this task.",
            "uuid": "e9266.1",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama-2 (vanilla)",
            "name_full": "Llama 2 (meta open model, evaluated off-the-shelf)",
            "brief_description": "An open-source large transformer LLM (70B parameter version and other sizes referenced) which, without alignment, makes factual errors on batch-level anomaly detection when used with the paper's prompting/serialization approach.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama-2 (70B evaluated; 7B also referenced)",
            "model_type": "transformer (pretrained open LLM)",
            "model_size": "70B (vanilla failing case described); 7B also referenced",
            "data_type": "tabular numerical data (serialized per-feature lists), synthetic batches, ODDS benchmark",
            "data_domain": "ODDS benchmark and synthetic continuous/categorical batches",
            "anomaly_type": "outliers / low-density anomalies",
            "method_description": "Zero-shot prompting/serialization identical to other LLMs: per-feature sentences + anomalydetection prompt + system message to restrict format, aggregate per-feature outputs by counting index occurrences.",
            "baseline_methods": "Compared to fine-tuned versions (Llama2-AD), GPT models, and transductive baselines (KNN, ECOD)",
            "performance_metrics": "AUROC",
            "performance_results": "Vanilla Llama-2 (70B) shows failure cases: factual errors (missed anomalies, false positives), inconsistent index-value pairing; quantitative AUROC not cited, but fine-tuning greatly improves performance (Llama2-AD showed average +8.9 AUROC increase over vanilla Llama2 across ODDS datasets).",
            "comparison_to_baseline": "Vanilla Llama-2 performs worse than fine-tuned Llama2-AD and GPT-4; fine-tuning closes the gap and improves substantially.",
            "limitations_or_failure_cases": "Observed factual errors: missing anomalies, false positives, incorrect index-value pairing, outputting indices beyond batch length, listing all rows as abnormal, and producing redundant text that complicates parsing. Instruction-following capability varies.",
            "unique_insights": "Large model scale alone (70B) does not guarantee good performance on this numeric tabular AD task without alignment/fine-tuning; alignment via supervised synthetic fine-tuning significantly alleviates these failure modes.",
            "uuid": "e9266.2",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama2-AD",
            "name_full": "Llama-2 fine-tuned for Anomaly Detection (LoRA)",
            "brief_description": "A 7B Llama-2 model fine-tuned via LoRA on a synthetic supervised anomaly-detection dataset to align it to the batch-level tabular anomaly detection task introduced in this paper.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama2-AD (Llama-2 7B base + LoRA fine-tuning)",
            "model_type": "transformer (pretrained LLM, LoRA parameter-efficient fine-tuning)",
            "model_size": "7B (base model size reported for fine-tuned variant)",
            "data_type": "tabular numerical data (per-feature serialized lists); synthetic continuous (Gaussian mixture) and discrete (categorical mixture) batches for training; ODDS benchmark for evaluation",
            "data_domain": "Synthetic continuous and categorical batches (training/validation) and ODDS benchmark datasets (evaluation)",
            "anomaly_type": "outliers / low-density region anomalies",
            "method_description": "End-to-end supervised fine-tuning using synthetic labeled batches: serialize batches into text prompts and train the model to output ground-truth index-format responses; LoRA used to update low-rank adapters while freezing base weights; inference uses same serialization + prompt and aggregation-by-counts.",
            "baseline_methods": "Compared to vanilla Llama-2, GPT-3.5, GPT-4, and transductive baselines (KNN, ECOD)",
            "performance_metrics": "AUROC",
            "performance_results": "Fine-tuning yields substantial improvements: reported average AUROC increase of ~8.9 points over vanilla Llama-2 across ODDS datasets; the fine-tuned 7B Llama-2-AD can detect anomalies in cases where the 70B vanilla Llama-2 failed (qualitative examples shown).",
            "comparison_to_baseline": "Llama2-AD substantially outperforms unaligned (vanilla) Llama-2; reduces factual indexing errors and substantially increases AUROC; still compared against GPT-4 which is a strong zero-shot performer.",
            "limitations_or_failure_cases": "Relies on quality and coverage of synthetic training distributions; may still be limited by context window size and token limits when many rows/columns are present; generalization beyond simulated anomalies depends on synthetic data diversity.",
            "unique_insights": "An end-to-end supervised alignment with synthetic batches and LoRA fine-tuning effectively teaches an LLM what the expected output format/decision is, overcoming numerical reasoning/instruction-following failures without teaching intermediate arithmetic steps.",
            "uuid": "e9266.3",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mistral (vanilla)",
            "name_full": "Mistral (open transformer LLM)",
            "brief_description": "An open-source transformer LLM evaluated in its vanilla form for zero-shot batch-level anomaly detection using the paper's serialization and prompt scheme.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mistral (vanilla)",
            "model_type": "transformer (pretrained LLM)",
            "model_size": "7B (used in experiments)",
            "data_type": "tabular numerical data (serialized per-feature lists); synthetic batches; ODDS benchmark",
            "data_domain": "ODDS benchmark and synthetic Gaussian/categorical mixtures",
            "anomaly_type": "outliers / low-density anomalies",
            "method_description": "Zero-shot prompting with per-feature serialization and instruction/system messages; outputs parsed and aggregated per-feature to form anomaly scores.",
            "baseline_methods": "Compared to Mistral-AD (fine-tuned), GPT-3.5, GPT-4, KNN, ECOD",
            "performance_metrics": "AUROC",
            "performance_results": "Vanilla Mistral improved substantially after fine-tuning; average AUROC increase of ~6.7 points when converted to Mistral-AD. Exact vanilla AUROC numbers not listed in-text.",
            "comparison_to_baseline": "Vanilla Mistral is weaker than Mistral-AD and GPT-4; fine-tuning yields notable gains.",
            "limitations_or_failure_cases": "Similar instruction-following variability and redundant output problems as other open models; needs fine-tuning to be reliable for this task.",
            "unique_insights": "Open models like Mistral benefit substantially from synthetic supervised alignment; fine-tuning enables them to capture low-density regions and produce parseable, accurate anomaly index outputs.",
            "uuid": "e9266.4",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mistral-AD",
            "name_full": "Mistral fine-tuned for Anomaly Detection (LoRA)",
            "brief_description": "A 7B Mistral model fine-tuned using LoRA on the paper's synthetic dataset to align it to the batch-level tabular anomaly detection task; used to demonstrate detection of low-density regions in contaminated distributions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-AD (Mistral 7B + LoRA fine-tuning)",
            "model_type": "transformer (pretrained LLM, LoRA fine-tuning)",
            "model_size": "7B",
            "data_type": "tabular numerical data (serialized per-feature lists); synthetic continuous and categorical batches for training; ODDS benchmark for evaluation; contaminated synthetic 1-D distribution for qualitative density capture experiment",
            "data_domain": "Synthetic Gaussian mixtures with uniform contamination (1D experiments), ODDS benchmark (real datasets)",
            "anomaly_type": "outliers / low-density region anomalies",
            "method_description": "Supervised fine-tuning end-to-end on synthetic labeled batches using LoRA; inference via the same serialization + prompt + aggregation-by-counts; used to collect predicted anomalies across many sampled batches and estimate anomaly density (kernel density estimation) demonstrating identification of low-density regions.",
            "baseline_methods": "Compared to vanilla Mistral, GPT-3.5, GPT-4, KNN, ECOD",
            "performance_metrics": "AUROC (quantitative on ODDS), qualitative density estimation (kernel density estimation over predicted anomaly samples)",
            "performance_results": "Fine-tuning increased average AUROC by ~6.7 points over vanilla Mistral; qualitative experiment: using Mistral-AD on a contaminated 1-D mixture (p(x)=0.45N(-25,2.5^2)+0.45N(25,2.5^2)+0.1Unif(-100,100)), collecting anomalies from 500 batches of 50 points, kernel density estimate of predicted anomalies captured three low-density regions (matching contamination modes). Fine-tuned Mistral-AD outperforms GPT-3.5 in experiments reported.",
            "comparison_to_baseline": "Mistral-AD substantially outperforms vanilla Mistral; outperforms GPT-3.5 in reported comparisons; GPT-4 still a strong zero-shot competitor.",
            "limitations_or_failure_cases": "Dependence on synthetic training distribution design and coverage; sensitivity to prompt formatting and output parsing; context window limits requiring subsampling when evaluating large datasets.",
            "unique_insights": "Fine-tuned Mistral-AD can be used not only for per-batch detection but also to empirically recover low-density regions of a global contaminated distribution by aggregating batch-level detections and applying density estimation.",
            "uuid": "e9266.5",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Serialization / Text formulation",
            "name_full": "Per-feature Data Serialization and Prompting (text formulation for batch-level AD)",
            "brief_description": "A method introduced in this paper that converts batch-level tabular anomaly detection into a text-to-text task by serializing each feature's one-dimensional values into natural-language sentences and prompting an LLM to output anomalous row indices.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "n/a (method applied to LLMs)",
            "model_type": "data / prompt engineering procedure",
            "model_size": null,
            "data_type": "tabular data serialized as per-feature 1D lists of scalars (floats approximated to two decimals) and categorical lists",
            "data_domain": "General tabular domains (ODDS benchmark and synthetic datasets)",
            "anomaly_type": "outliers / rows from anomalous distributions",
            "method_description": "Assume feature independence; for each feature k, serialize N scalars as sentences 'Data 1 is x_1,k. Data 2 is x_2,k. ...' append prompt 'Abnormal data differ from the majority. Which data are abnormal?' plus system message 'Only answer data indices.' Parse LLM responses per-feature and aggregate counts across features to obtain per-row anomaly scores (s_i = number of features that flagged row i).",
            "baseline_methods": "N/A (this is the core method applied to LLMs; compared experimentally to vector input / alternative encodings where vector input degraded performance)",
            "performance_metrics": "AUROC (when used in full pipeline), density-recovery via kernel density estimation for aggregated anomalies",
            "performance_results": "Enables GPT-4 to be a strong zero-shot detector on ODDS; vector encoding (feeding data as a vector) degraded performance compared to per-feature serialization.",
            "comparison_to_baseline": "Per-feature serialization outperformed vector-style encoding (paper reports performance degradation when using vector input).",
            "limitations_or_failure_cases": "Assumes independence across features (paper uses per-feature detection then aggregates); some real datasets may have important cross-feature dependencies lost with this scheme; context/window token limits force subsampling (e.g., 150 rows x 10 columns in experiments).",
            "unique_insights": "Converting numerical tabular detection to a text-to-text format by serializing per-feature scalars is sufficient for LLMs (particularly GPT-4) to detect low-density anomalies; enforcing a simple system message to restrict output format simplifies parsing.",
            "uuid": "e9266.6",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "End-to-end fine-tune (synthetic + LoRA)",
            "name_full": "End-to-end supervised fine-tuning with synthetic anomaly batches using LoRA adapters",
            "brief_description": "A fine-tuning strategy introduced in the paper where synthetic labeled batches (continuous Gaussian mixtures and discrete categorical mixtures with random contamination ratios) are used to train LLMs end-to-end (directly on expected output answers) via LoRA parameter-efficient updates.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "n/a (fine-tuning method applied to open LLMs like Llama-2 and Mistral)",
            "model_type": "training / alignment procedure (supervised LoRA fine-tuning)",
            "model_size": null,
            "data_type": "synthetic tabular batches: continuous (narrow Gaussian normal + wide Gaussian anomalies) and discrete (mixture of categorical distributions)",
            "data_domain": "Synthetic training data (2,500 batches per data type used for simulation; training set of 5000 batches and validation of 400 for fine-tuning), applied to ODDS benchmark for evaluation",
            "anomaly_type": "outliers / contaminated batch anomalies (contamination ratio Ï€ &lt; 0.2 randomized)",
            "method_description": "Simulate labeled batches where ground-truth responses are either 'All rows are normal.' or 'Data a1, a2, ... are abnormal.' Train LLMs to map serialized input X to ground-truth response Y by maximizing conditional log-likelihood over tokens; use LoRA (low-rank adapters) so base weights are frozen and only adapters are learned; after training adapters can be merged.",
            "baseline_methods": "Compared fine-tuned LLMs (Llama2-AD, Mistral-AD) vs their vanilla counterparts and proprietary GPT models as zero-shot baselines; also compared to transductive methods (ECOD, KNN) on ODDS.",
            "performance_metrics": "AUROC for ODDS; qualitative density-capture experiments (kernel density estimation) for synthetic contaminated distributions",
            "performance_results": "Fine-tuning produced large gains: Llama-2 improved by ~8.9 AUROC points on average; Mistral improved by ~6.7 AUROC points; trained models could detect all anomalies in qualitative toy examples where vanilla models failed. Training dataset: 5000 batches (2500 continuous / 2500 discrete), validation 400 batches; Llama-2 fine-tuned for 5 epochs, Mistral for 2 epochs, learning rate 1e-3.",
            "comparison_to_baseline": "End-to-end synthetic fine-tuning reliably closes performance gaps vs vanilla open models and can surpass some zero-shot closed models in certain comparisons (e.g., Mistral-AD &gt; GPT-3.5); overall GPT-4 remained a strong zero-shot performer.",
            "limitations_or_failure_cases": "Quality of alignment depends on realistic coverage of synthetic data generating processes; chain-of-thought style supervision was avoided because arithmetic reasoning is brittle in LLMs; still subject to context window/token limits at inference and parsing issues if model does not follow output format.",
            "unique_insights": "Teaching 'what to expect' via supervised end-to-end outputs (instead of teaching intermediate arithmetic steps) is an effective alignment strategy for LLMs on tabular anomaly detection; LoRA enables parameter-efficient fine-tuning using synthetic batches to correct factual/output-format errors.",
            "uuid": "e9266.7",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ODDS library",
            "rating": 2,
            "sanitized_title": "odds_library"
        },
        {
            "paper_title": "Ecod: Unsupervised outlier detection using empirical cumulative distribution functions",
            "rating": 2,
            "sanitized_title": "ecod_unsupervised_outlier_detection_using_empirical_cumulative_distribution_functions"
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 1,
            "sanitized_title": "training_language_models_to_follow_instructions_with_human_feedback"
        }
    ],
    "cost": 0.0160445,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Anomaly Detection of Tabular Data Using LLMs</p>
<p>Aodong Li aodongl1@uci.edu 
Yunhan Zhao 
Chen Qiu 
Marius Kloft 
Padhraic Smyth 
Maja Rudolph 
Stephan Mandt 
U C Irvine 
Bosch Center 
Rptu Kaiserslautern-Landau 
Anomaly Detection of Tabular Data Using LLMs
4DA8310044E110A62A7DA286FBC264EE
Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning.In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zeroshot batch-level anomaly detectors.That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions.For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective datagenerating processes to simulate synthetic batchlevel anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies.Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</p>
<p>Introduction</p>
<p>Large language models (LLMs), which employ transformerbased architectures and billions of learnable parameters, can process and generate text that exhibits human-level realism.LLMs have enabled groundbreaking real-world applications that were hardly possible a few years ago, such as chatbots e.g.,(ChatGPT) and code generation e.g., GitHub Copilot [Roziere et al., 2023].</p>
<p>This paper studies the application of LLMs to anomaly detection (AD)-one of the fundamental problems in machine learning occurring in many applications [Ruff et al., 2021].AD concerns the detection of irregular instances-so-called anomalies-in data.There exist several settings of AD [Qiu et al., 2022;Li et al., 2023;Li et al., 2024]; we consider the setting of zero-shot batch-level AD [Li et al., 2024], illustrated in Fig. 1, where we want to find an anomalous instance x i âˆˆ R K in a batch of data X = {x 1 , . . ., x N } âŠ‚ R K .This setting finds applications in many domains, from fraud detection and intrusion detection to medical anomaly detection and industrial damage detection.</p>
<p>Zero-shot batch-level AD utilizes batch information to adapt to distribution shifts and can exploit modern hardware like GPUs for parallel computation [Li et al., 2024].Numerous shallow methods have been developed for this setting under the name of unsupervised anomaly discovery1 [Ramaswamy et al., 2000;Breunig et al., 2000;Liu et al., 2008;Li et al., 2022].On the other hand, LLMs have high promise for this setting.Their input and output format-natural language text-leads to simpler usage for practitioners.LLMs require no expertise in selecting anomaly detection models and setting hyperparameters.Moreover, they have the potential to understand task background information and customize task needs.For example, when we know some pattern is rare but normal, we can inform LLMs to exclude that pattern from detected anomalies.</p>
<p>Another motivation for studying zero-shot batch-level AD arises from the data-wrangling task.[Narayan et al., 2022] demonstrated employing LLMs to detect and correct errors in attribute-value pairs for tabular data, assuming that LLMs understand the attribute meanings and values as humans do.Unfortunately, in many real-world applications, especially in specialized domains where i) LLMs have relatively less information and ii) data are preprocessed into numerical values, LLMs cannot reliably detect errors.Therefore, we study the problem of using LLMs to detect errors in a given data batch where errors are present as outliers.</p>
<p>Using LLMs for zero-shot batch-level AD is challenging.First, the data consists of numerical tables, while LLMs expect text as input.Second, detecting anomalies in tables requires sophisticated computation with numerical data, such as estimating and thresholding densities.It remains unclear 1) whether LLMs can perform these tasks and 2) how to effectively prompt LLMs for AD.Third, LLMs have varying capabilities in mathematical reasoning and text understanding.How to align LLMs unprepared for this AD problem must be addressed.</p>
<p>The contributions of this paper are as follows, addressing the aforementioned challenges:</p>
<p>â€¢ We propose a serialization method (illustrated in Fig. 1)</p>
<p>that converts batch-level anomaly detection from a numerical task to a text-based task.The method comes along without hyperparameter tuning.â€¢ We empirically evaluate our approach on both synthetic and real-world data using GPT, Llama2, and Mistral.The experiments demonstrate that GPT-3.5 and GPT-4 can effectively detect anomalies in batches.â€¢ We develop a strategy for fine-tuning anomaly detectors by synthesizing normal and anomalous data, thereby training the LLM to detect anomalies accurately.â€¢ Experiments on the ODDS benchmark [Rayana, 2016] demonstrate that our simple method using the original GPT-4 performs on par with the state-of-the-art transductive learning-based methods.The fine-tuned Mistral-based detector outperforms GPT-3.5, highlighting the effectiveness of our fine-tuning strategy.</p>
<p>As follows, we discuss related works in Sec. 2, then present our method of applying and fine-tuning LLMs to detect anomalies in Sec. 3. We conduct experiments in Sec. 4 and conclude with Sec. 5.</p>
<p>Related Work</p>
<p>Anomaly detection with LLMs.[Gu et al., 2024] uses indistribution paired images and texts to jointly train a language model and a vision encoder to describe in natural language text the found anomalies in an image.[Elhafsi et al., 2023] relies on LLMs' environment understanding and reasoning ability to monitor semantic anomalies in autonomous driving systems.[Park, 2024] employs LLMs as agents to validate and interpret financial anomalies.[Su et al., 2024] surveyed the work in time series anomaly detection.Unlike the above work, we tackle zero-shot batch-level anomaly detection for tabular data.Zero-shot batch-level anomaly detection.Batch-level anomaly detection or unsupervised anomaly discovery has been studied for a long time [Chandola et al., 2009].While numerous transductive learning-based methods have been proposed, they are shallow methods and require hyperparameter settings for each data batch [Tax and Duin, 2004;Xu et al., 2010;Zhou and Paffenroth, 2017;Ramaswamy et al., 2000;Li et al., 2022].In deep anomaly detection, zero-shot batch-level anomaly detection utilizes batch normalization layers to automatically adapt to each data batch [Li et al., 2024].In this work, we apply LLMs as zero-shot batch-level anomaly detectors to accomplish this task across datasets solely based on their gained knowledge through pretraining.</p>
<p>Zero-shot learning in LLMs.LLMs have shown unprecedented zero-shot ability in many downstream NLP tasks [Chang et al., 2023].Many recent works start to leverage such zero-shot ability of LLMs to other tasks, such as arithmetic reasoning [Lewkowycz et al., 2022;Imani et al., 2023] and time series forecasting [Gruver et al., 2024].LLMs have also been applied to data wrangling for error detection [Narayan et al., 2022;Vos et al., 2022].To our knowledge, we are the first to explore and benchmark LLMs on tabular anomaly detection tasks and propose effective approaches that enhance the ability of LLMs on this task.</p>
<p>Method</p>
<p>This section will first present the problem setup, then introduce our text-based method for batch-level anomaly detection using large language models (LLMs), and finally propose an end-to-end fine-tuning strategy for LLMs to be better aligned to anomaly detection.</p>
<p>Problem Setup</p>
<p>We consider a batch of possibly contaminated data D := {x i âˆˆ R K } N i=1 (a numerical table) in the presence of unlabeled anomalies.We assume the number of anomalies is far less than normal data, i.e., the normal data takes the majority in the batch.We stress that the data batch can contain no anomalies.LLMs can tell when the batch is contaminated or not.The aim is to identify which data points in the batch are abnormal.</p>
<p>Text Formulation of Batch-level Anomaly Detection</p>
<p>We assume each feature dimension is independent, and we detect anomalies for each feature separately2 .The detection results of each feature dimension will then be aggregated to form the final results.</p>
<p>Data Serialization.We designed a template to serialize data into text because LLMs only accept text input.Assuming independent features, we can detect anomalies on one feature dimension at a time.Then, the data to be serialized will be one-dimensional float scalars.Denote the single-feature data by {x i âˆˆ R} N i=1 .We use the template serialize the ith data point. 3The data index i is necessary to disambiguate repetitive data values.We approximate the data value up to two decimal places in the serialization.Each serialized data point is then concatenated as input to the LLMs.We use T in := +{T in I } N i=1 to denote the concatenation operation where + represents concatenating each element in a set.Prompt Engineering.Besides the data input, we need to inform the LLMs of the anomaly detection task.We use a description text C :="Abnormal data are different from the majority.Which data are abnormal?"to characterize anomalies and ask questions.The serialized data input and task description together formulate the input to the LLMs, i.e., X := +{T in , C}. Fig. 1 presents a serialization example with five synthetic data.
T in i :="Data i is x i ." to
With the input X, LLMs can respond to the anomaly detection request.The response will include anomalous data indices (the numeric data indices) by design.In most cases, LLMs tend to generate diverse responses with long reasoning.We further regularize the output format by delivering another system message-"Only answer data indices."-tothe LLMs to have easy-to-parse responses. 4lgorithm 1 LLM for batch-level anomaly detection
Require: LLM, D := {x i âˆˆ R K } N i=1
Initialize anomaly score for each row
s i = 0, i = 1, . . . , N for each column k in D do Set serialization T in = "Data 1 is x 1,k . Data 2 is x 2,k . ... Data N is x N,k ."
Set prompt C = "Abnormal data differ from the majority.Which data are abnormal?"</p>
<p>Get response Å¶k = LLM(T in + C) Update anomaly scores for all data points
s i = s i + 1[i âˆˆ Å¶k ].
end for return anomaly scores s i , i = 1, . . ., N</p>
<p>Anomaly detection as a text-to-text task.One can get anomaly predictions for each feature dimension with the pro-posed data serialization methods and the prompts.We now introduce a simple method for aggregating the responses of all feature dimensions and constructing anomaly scores for each data point.</p>
<p>We propose to set the anomaly score of the ith data to be the number of occurrences of data index i in all responses.That is, suppose the response to the kth feature dimension is Å¶k , then
s i = K k=1 1[i âˆˆ Å¶k ].
The anomaly scores are useful for performance evaluation and characterizing the degree of abnormality.The full procedure is presented in Alg. 1.</p>
<p>Prediction extraction from output.Automatically parsing the LLM output and extracting the predicted anomalies facilitate model evaluations and improve the response-to-detection speed.To get the predictions, we instruct the model to output only anomalous data indices by sending a system message-"Only answer data indices" However, research shows that the capability of following instructions by LLMs differs to some extent [Ouyang et al., 2022;Zhou et al., 2023].In our experiments, we observed that the fine-tuned LLMs (e.g., Mistral-AD and Llama-AD used in the experiments) can faithfully follow the same output format used during the fine-tuning stage.GPT-3.5 and GPT-4 also follow the instructions well and output succinct answers containing predicted data identifiers.So, we can extract the predictions automatically for these models.See Supp.B.1 for script details.</p>
<p>The other models in our experiments, Llama-2 and Mistral, oftentimes output redundant information besides predictions even though they are instructed to only output predictions.Redundant information makes it hard to pinpoint the predictions without human involvement, complicating the parsing process.To completely suppress redundant information, we manually modify the output token probabilities at each generation step and require the generation to follow a specific pattern.We use regular expressions to specify the desired model output patterns with the Outlines library [Willard and Louf, 2023]5 .We found that grammar-correct formats with complete sentences are essential for generating high-quality predictions.So the regular expression in use is ((Data [0-9]+(, [0-9]+) * are abnormal.)|(Alldata are normal.))which allows the model to predict abnormal data or to abstain from predictions if all data seemingly comes from the same datagenerating process.Extracting integers from the formatted output can be accomplished by the same automatic procedure</p>
<p>End-to-end Finetune Strategy</p>
<p>Unfortunately, not all LLMs are prepared to detect anomalies.Fig. 2 shows a failing case with an open-sourced LLM-Llama-2 (70 billion-parameter version).Llama-2 makes factual errors: it only discovers two outliers and misses another two; it wrongly labels one normal data as abnormal.Our experiments also observed that Llama-2 may pair incorrect indices and values, generate indices beyond the batch length, or list every data as abnormal.These phenomena signify the misalignment of Llama-2 or other LLMs in detecting anomalies.</p>
<p>Synthetic dataset.To align LLMs in batch-level anomaly detection, we simulate a synthetic dataset with ground truth labels for LLMs to learn.The dataset contains continuous and discrete data types, covering real-world data types.Discrete data is a mixture of normal and abnormal Categorical distributions.Continuous data is a Gaussian mixture where normal data is a narrow Gaussian while anomalies are from a wide Gaussian.All the model parameters are randomly selected from a pre-defined interval.The contamination ratio Ï€ for both data types is also random but ensured to be smaller than 0.2.The data generating processes are listed in Algs. 2 and 3 in Supp. A. The corresponding graphical models are shown in Fig. 3.We simulate 2,500 batches for each data type.When a data batch is normal, its ground-truth response is "All rows are normal."6For other batches that contain anomalies, we use the ground truth answers Y ="Data a 1 , a 2 ,... and a A are abnormal."where {a i : y ai = 1} A i=1 are the anomaly indices.Simulated synthetic data is serialized in our proposed text formulation.Synthetic data examples are in Supp. A.</p>
<p>End-to-end fine-tune.We align LLMs to the anomaly detection task through fine-tuning.The most common finetuning strategy is Chain-of-Thought [Wei et al., 2022].However, applying Chain-of-Thoughts to reason about anomalies is hard.Challenges arise from the complications of the AD task.For example, suppose we construct the chain of thoughts using the two-standard deviation range method7 .This method is a rough criterion and cannot cover all discrete and multimodal continuous data cases.In addition, asking LLMs to calculate the sample mean and sample standard deviation is another arithmetic challenge for LLMs.</p>
<p>Instead, we propose to teach LLMs in an end-to-end fashion-not focusing on "how to solve" but on "what to expect."We directly present the answer to the model and ask LLMs to learn to predict that given answer without caring about the intermediate steps.Therefore, we fine-tune LLMs on the synthetic dataset {(X b , Y b )} B b=1 in a supervised manner.Fig. 2 shows the efficacy of our fine-tuning method on a toy data batch.After aligning Llama2 (7 billion-parameter version) -Llama2-AD -detects all anomalies.</p>
<p>We apply low-rank adaptation (LoRA [Hu et al., 2022]), a parameter-efficient fine-tuning method to align LLMs.LoRA appends an additional low-rank weight matrix to each original weight matrix.The low-rank matrix can be parameterized efficiently through matrix factorization.The original weights are kept fixed during fine-tuning, and newly added low-rank matrices are updated.After fine-tuning, the low-rank weight matrices can be absorbed into the original weight matrix to fix the model size.</p>
<p>We fine-tune the LLMs by maximizing the conditional loglikelihood
B b=1 log p(Y b |X b ; Î¸ LoRA , Î¸ LLM ) of our simulated synthetic dataset {(X b , Y b )} B
b=1 with respect to the learnable Î¸ LoRA while keeping LLM's original parameter Î¸ LLM fixed.The conditional log-likelihood can be further factorized over the tokens
{y b i } L b i=1 of each response Y b in an auto-regressive fashion: B b=1 L b i=1 log p(y b i |y b &lt;i , X b ; Î¸ LoRA , Î¸ LLM ).
After optimization, Î¸ LoRA can be integrated into Î¸ LLM by an element-wise addition, which keeps the model size constant.More details are in [Hu et al., 2022].</p>
<p>Experiments</p>
<p>This section shows experimental results on the ODDS anomaly detection benchmark.One surprising result is that our simple prompt engineering method with the original GPT-4 performs similarly to the state-of-the-art anomaly detection method.Our alignment method using synthetic data on Llama2 and Mistral demonstrates significant improvements over their primitive counterparts.</p>
<p>We first introduce the global experimental setups and then the implementation details of our proposed methods.Finally, we present the results.</p>
<p>Experiment Setup</p>
<p>We follow the widely adopted ODDS tabular data benchmark [Rayana, 2016] to evaluate LLMs batch-level anomaly detection performance.Some LLMs have input token limits due to the context window size and GPU memory constraint.Therefore, we randomly sub-sample 150 rows and use the first 10 columns for each dataset to perform the evaluation.We extensively study various LLMs to support our findings.</p>
<p>Table 1: AUROC results of batch-level anomaly detection on the ODDS benchmark.Different LLMs are evaluated.Specifically, we show the performance of two LLMs (Llama2, Mistral) before and after finetuning.Proprietary LLMs (GPT-3.5 and GPT-4) are also compared.Additional state-of-the-art transductive learning-based approaches, i.e., KNN and ECOD, are listed for comparisons.Note that KNN and ECOD are not zero-shot batch-level methods.</p>
<p>Proposed Methods</p>
<p>Baselines GPT-3.5 GPT-</p>
<p>Implementation Details</p>
<p>We run all experiments three times with different random seeds.All our experiments except GPT-3.5 and GPT-4 are performed using an A6000 GPU with PyTorch.Llama-2 and Mistral can fit into the GPU memory.The temperature and where the contamination ratio is 0.1, resulting in p(x) in blue.We sample 500 independent batches from p(x) and ask the LLM to predict anomalies using our proposed method for each batch.We collect all the predicted anomalies and estimate the density by a kernel density estimator, shown by pa(x) in orange.pa(x) successfully captures three low-density regions of p(x), demonstrating the LLM's ability to detect anomalies.More details are in Supp.B. illustrate LLM's low-density region detection ability, we simulate a synthetic data distribution contaminated by anomalies.We use a two-component Gaussian mixture as the normal data distribution.We contaminate this normal data distribution with a wide uniform distribution representing abnormal data distribution.The final distribution is shown by p(x) in blue in Fig. 4. We sample data batches from this contaminated data distribution and apply our fine-tuned Mistral-AD (see below) to predict anomalies.We collect the predicted anomalies from all batches and use the kernel density estimator to fit a density pa (x) on them.Llama2-AD, Mistral vs. Mistral-AD), both models show significant improvements: on average, 8.9 and 6.7 AUROC increases, respectively, showing the efficacy of our fine-tuning strategy.</p>
<p>Conclusion</p>
<p>We consider using large language models (LLMs) to detect anomalies for numerical data wrangling.We address this problem through batch-level anomaly detection.We developed a text formulation for LLMs to accomplish this task.</p>
<p>We found LLMs are capable to identify low-density regions in a batch of data.Surprisingly, GPT-4 is a strong zeroshot batch-level anomaly detectors that have comparable performance with state-of-the-art transductive learning methods.For LLMs that are not well aligned to this task, we designed and simulated a synthetic dataset to fine-tune the LLMs in an "end-to-end" fashion.Experiments demonstrate the significance of our findings and the efficacy of our proposed finetune strategy.</p>
<p>Figure 1 :
1
Figure 1: The illustration of batch-level anomaly detection with LLMs.We serialize the data batch into text and apply our proposed prompts as the input to LLMs.LLMs then respond by answering the indices of abnormal data based on LLMs' knowledge.The system message "Only answer data indices" regularizes LLM responses and ensures responses are easy to parse.</p>
<p>Figure 2 :
2
Figure 2: Illustration of Llama2 for batch-level anomaly detection before and after our fine-tuning strategy.With the same input prompt, Llama2-70b (70-billion parameter version) makes factual mistakes-two false negatives (missing 5 and 10) and one false positive (incorrect 14).These results are obtained from https://www.llama2.ai.On the contrary, our fine-tuned 7-billion parameter (10x smaller than Llama2-70b) Llama2-AD succeeds in discovering all anomalies.</p>
<p>Figure 3 :
3
Figure 3: Graphical models of the synthetic data generating processes.(Left) We use a binary Gaussian mixture (i.e., K = 2) to generate a batch of continuous data of size N .One Gaussian corresponds to normal data, and another corresponds to abnormal data.(Right) A multinomial mixture model (K = 2) for discrete data where one multinomial is for normal and one for abnormal data.Ï€ controls the anomaly ratio.Specifics of the random variables in the models are in Supp.A</p>
<p>Figure 4 :
4
Figure4: LLMs can detect low-density regions in a contaminated data distribution.We use our Mistral-AD fine-tuned based on Mistral as the demonstrating LLM.Normal data distribution is represented by two Gaussian distributions located at -25 and 25 respectively.The contaminated data distribution is formed by combining the normal distributions and a wide uniform distribution spanned over interval[âˆ’100, 100], where the contamination ratio is 0.1, resulting in p(x) in blue.We sample 500 independent batches from p(x) and ask the LLM to predict anomalies using our proposed method for each batch.We collect all the predicted anomalies and estimate the density by a kernel density estimator, shown by pa(x) in orange.pa(x) successfully captures three low-density regions of p(x), demonstrating the LLM's ability to detect anomalies.More details are in Supp.B.</p>
<p>Fig. 4
4
shows pa (x) captures the three low-density regions in p(x), separated by two peak Gaussian distributions, demonstrating LLM's low-density region detection ability.Quantitative results.The results of OODS benchmark are shown in Tab. 1.The results summarize two salient conclusions: (i) Sophisticated LLMs are state-of-the-art zero-shot batch-level anomaly detectors.Comparing GPT-4 against ECOD, state-of-the-art method on ODDS benchmark, GPT-4 shows on-par performance without extra fine-tuning, indicating the huge potential of LLMs in the anomaly detection task.(ii) Proposed end-to-end fine-tuning strategy significantly boost the performance.Checking the performance of the same LLM before and after fine-tuning (Llama2 vs.</p>
<p>Using "zero-shot batch-level" stresses that our proposed method is a deep learning-based method rather than a shallow method.
We also tried to relax this independence assumption and input the data as a vector. However, the performance degrades. The reason could be that LLMs cannot distinguish a vector from a set of scalars. For the latter, the order between elements is unimportant.
Experimental performance is not sensitive to data names. We also named data by "Row" instead of "Data" as if in a table where columns correspond to features or data dimensions and rows index data points. The experimental performance is similar.
Use "Only answer row numbers" when data are named "Row."
https://outlines-dev.github.io/outlines/
We facilitate optimization convergence by designing highprobability response formats and using complete, grammarconsistent sentences.
The two-standard deviation range refers to the interval[âˆ’2Ïƒ, 2Ïƒ]  where Ïƒ is the standard deviation. Any data points located outside this range are considered abnormal.
Specifically, we use api of gpt-3.5-turbo-1106 and gpt-4-1106preview.
A Synthetic DatasetA.1 Data Generating Processes Data generating processes of synthetic discrete and continuous data are presented in Alg. 2 and Alg. 3, respectively.Discrete data is a mixture of normal and abnormal Categorical distributions.Continuous data is the clutter setup where normal data is sampled from a narrow Gaussian distribution while anomalies are from another wide Gaussian distribution.In practice, we generate the discrete data by setting the hyperparameters N l = 20, N h = 100, Ï€ l = 0.01, Ï€ h = 0.2, M l = 1, M h = 4, Î± = 20.For continuous data generation, we choose N l = 20, N h = 100, Ï€ l = 0.01, Ï€ h = 0.2, Âµ l = âˆ’100, Âµ h = 100, Ïƒ l n = 0.5, Ïƒ h n = 5.For both data types, the contamination ratio Ï€ is smaller than 0.2.Algorithm 2 Generate discrete datap n âˆ¼ Dir({Î±} Mn ) 5: p a âˆ¼ Dir({Î±} Ma ) 6: for i = 1, . . ., N do 7:x i âˆ¼ {(1 âˆ’ Ï€)p n , Ï€p a } 8: end for 9: return {x i }, i = 1, . . ., N Algorithm 3 Generate continuous data5: Ïƒ a = 10Ïƒ n 6: for i = 1, . . ., N do 7:xA.2 Data ExamplesB Implementation DetailsB.1 Prediction Extraction ProcedureThe automatic procedure for extracting model predictions in all experiments is the following code snippet in Python.def parse_generation_results(ans, max_num=149): response_ret = [] if ans.endswith("."):ans = ans.rstrip(".")ans = ans.rsplit(":-&gt;",1)[-1] if ":" in and: ans = ans.replace(":"," ") ans = ans.replace(",","") ans = ans.split()if "no" in ans or "No" in ans or "None" in and:return [] for r in and: if r.isnumeric() and "." not in r and int(r)&lt;= max_num: response_ret.append(int(r))return response_retB.2 Qualitative StudyIn Fig.4, we use p(x) = 0.45N (âˆ’25, 2.5 2 ) + 0.45N (25, 2.5 2 ) + 0.1Unif(âˆ’100, 100).pa (x) is estimated by a kernel density estimator with 5.0-bandwidth Gaussian kernels.The predicted anomalies are collected from 500 independent batch predictions, where each batch contains 50 data points sampled from p(x).B.3 Quantitative StudyImplementation details.The output from LLMs are naturally diverse and less controllable.A system prompt: "Only answer row numbers." is passed to all LLMs to easier parse the responses for evaluation.We manually filter unreasonable predictions of LLMs.Specifically, (i) we ignore predictions that beyond provided data samples; (ii) we choose the semantic consistent one if the output contains multiple answers.We repeat all experiments 3 times with different random seeds.All our experiments are implemented with Py-Torch using A6000 GPU.For Llama-2 and Mistral, the temperature and top p generation hyperparameters are set as 0.75 and 0.9, respectively.For GPT-3.5 and GPT-4, we use the default hypereparameter settings.We fine-tune all models using LoRA parameter-efficient fine-tuning strategy[Hu et al., 2022].We finetune Llama-2 for five epochs and Mistral for two epochs with the same learning rate 1e-3.All optimizations are convergent.
On the other hand, for GPT-3.5 and GPT-4, we use their default hyperparameter settings and perform the experiments through their API. We fine-tune Llama-2-7B and Mistral-7B using LoRA parameter-efficient fine-tuning strategy [Hu et al., 2022] on our synthetic datasets. We generate training and validation sets separately. The training set involves 5000 data batches (2500 continuous data batches and 2500 discrete data batches), while the validation set contains 400 data batches (200 for continuous and 200 for discrete data). top p generation hyperparameters are set as 0.75 and 0.9 for Llama-2 and Mistral, respectively. The resulting models are named Llama2-AD and Mistral-AD</p>
<p>Semantic anomaly detection with large language models. Breunig, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of dataEdward Schmerling, Issa AD Nesnas, and Marco Pavone2000. 2000. 2009. 2009. 2023. 2023. 202341Autonomous Robots</p>
<p>Anomalygpt: Detecting industrial anomalies using large visionlanguage models. Gruver, mathprompter:The 61st Annual Meeting Of The Association For Computational Linguistics. ICLR2024. 2024. 2024. 1932-1940, 2024. 2022. 2022. 202336Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. Jiang, arXiv:2310.068252008 eighth ieee international conference on data mining. Avanika Narayan, Ines Chami, Laurel Orr, Christopher RÃ©, Alex RayIEEE2023. 2023. 2022. 2022. 2022. 2022. 2023. 19882-19910. PMLR, 2023. 2024. 2024. 2008. 2008. 2022. 2022. 202235arXiv preprintProceedings of the VLDB Endowment. Ouyang et al., 2022. et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems</p>
<p>Enhancing anomaly detection in financial markets with an llm-based multi-agent framework. Taejin Park, ; Park, Qiu, arXiv:2403.19735Proceedings of the 2000 ACM SIGMOD international conference on Management of data. Sridhar Ramaswamy, Rajeev Rastogi, Kyuseok Shim, the 2000 ACM SIGMOD international conference on Management of dataPMLR2024. 2024. 2022. 2022. 2000arXiv preprintInternational conference on machine learning</p>
<p>A unifying review of deep and shallow anomaly detection. Rayana ; Roziere, arXiv:2308.12950Shebuti Rayana. ODDS library. 2016. 2016. 2023. 2023. 2021109arXiv preprintCode llama: Open foundation models for code</p>
<p>Large language models for forecasting and anomaly detection: A systematic literature review. Su, arXiv:2402.10350arXiv:2307.09702Advances in Neural Information Processing Systems. Wei, 2024. 2024. 2004. 2004. 2023. 2023. 2022. 2022. 202354arXiv preprintNeurIPS 2022 First Table Representation Workshop. Willard and Louf, 2023] Brandon T Willard and RÃ©mi Louf. Efficient guided generation for llms</p>
<p>Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep autoencoders. Xu, Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data mining2010. 2010. 2017. 201723Advances in neural information processing systems</p>
<p>Instruction-following evaluation for large language models. Zhou, arXiv:2311.079112023. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>