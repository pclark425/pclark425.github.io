<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2009 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2009</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2009</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-48.html">extraction-schema-48</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <p><strong>Paper ID:</strong> paper-280137859</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2507.07207v2.pdf" target="_blank">Scaling can lead to compositional generalization</a></p>
                <p><strong>Paper Abstract:</strong> Can neural networks systematically capture discrete, compositional task structure despite their continuous, distributed nature? The impressive capabilities of large-scale neural networks suggest that the answer to this question is yes. However, even for the most capable models, there are still frequent failure cases that raise doubts about their compositionality. Here, we seek to understand what it takes for a standard neural network to generalize over tasks that share compositional structure. We find that simply scaling data and model size leads to compositional generalization. We show that this holds across different task encodings as long as the training distribution sufficiently covers the task space. In line with this finding, we prove that standard multilayer perceptrons can approximate a general class of compositional task families to arbitrary precision using only a linear number of neurons with respect to the number of task modules. Finally, we uncover that if networks successfully compositionally generalize, the constituents of a task can be linearly decoded from their hidden activations. We show that this metric correlates with failures of text-to-image generation models to compose known concepts.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2009.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2009.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hyperteacher-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hyperteacher compositional task family evaluated with ReLU multilayer perceptrons</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised regression experiments where tasks are generated by a linear hypernetwork (summing K of M modules to produce single-hidden-layer ReLU teacher networks) and solved by standard ReLU MLPs fed concatenated input and task encoding; used to study compositional generalization as data and model size scale.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ReLU MLP (fully connected multilayer perceptron)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Standard feedforward MLP with ReLU nonlinearities that takes concatenated input x and task encoding φ(z,r); typical instantiation uses 4 hidden layers of 1024 neurons (other depths/sizes explored).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>standard MLP (no explicit modularity), concatenated task encoding input; uses ReLU nonlinearities</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>functional regression / synthetic task family</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Hyperteacher compositional task family</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Each task f_z is a single-hidden-layer ReLU network whose hidden weights are formed by summing K out of M module weight matrices (a linear hypernetwork); tasks are sampled from an exponentially-large family O(M choose K). The student model receives inputs x and a task encoding φ(z,r) and must predict f_z(x). Compositionality arises from combining modules to form tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>function composition via selection/summation of modules (K-of-M composition)</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>held-out tasks (novel combinations of known modules); fraction of distinct tasks held-out varied to test generalization</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>standard supervised learning sampling tasks from p_train(z) and data from p(x); experiments vary number of distinct training tasks (coverage) and model capacity</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Measured with R^2 on held-out tasks; compositional generalization operationalized (in plots) as R^2 > 0.95. Performance improves (R^2 increases) as number of distinct training tasks and model size increase; required number of training tasks grows sub-exponentially with total task count.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Compared different task encodings (identity, orthogonal projection, language, few-shot example-based, invertible NN, interval shuffle) as well as different training support constructions (Random, Balanced, Non-compositional, Disconnected, Popular/Unpopular modules). Also compared to transformer architecture (see separate entry).</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td>MLP vs transformer: both can achieve compositional generalization under sufficient scale, but transformers require fewer distinct training tasks to reach the R^2 > 0.95 threshold (i.e., better data efficiency). Deeper/wider MLPs perform better given sufficient data.</td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td>Increasing number of training tasks (data scale) and increasing model size (more layers and hidden units) consistently improve compositional generalization; empirical curves show monotonic improvement and a sub-exponential required-training-tasks scaling. No explicit parameter counts reported.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Standard ReLU MLPs can compositionally generalize on the hyperteacher family if (i) the training distribution sufficiently covers the task space (compositional and connected support) and (ii) data and model size are scaled; compositional generalization can be achieved with a sub-exponential number of training tasks and larger models. Task constituents become linearly decodable from hidden activations when compositional generalization succeeds.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td>Failures occur when the training support is deficient: if some module never appears (non-compositional support), if support is disconnected, or if some modules are extremely underrepresented (unpopular modules), compositional generalization degrades. Identity availability of z at input is not sufficient if representations are lost in hidden layers.</td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Sufficient coverage of task space (compositional + connected support), sufficiently large number of distinct training tasks (scaling), and sufficient model capacity; information-preserving task encodings (not necessary to be linear) support generalization when model size is adequate.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2009.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2009.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hyperteacher-Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Decoder-only transformer on hyperteacher compositional tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Decoder-only transformer trained to autoregressively predict labels given a sequence containing task constituents followed by task inputs; evaluated for compositional generalization on same hyperteacher family to compare architecture and data-efficiency effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Decoder-only Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Causally-masked decoder-only transformer with 4 layers, 4 attention heads, model dimension 256 and feedforward dimension 1024; separate projection matrices for task constituents, inputs and outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>self-attention mechanism, autoregressive decoding, standard transformer feedforward blocks</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>functional regression / synthetic task family</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Hyperteacher compositional task family (same as MLP experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Transformer receives sequence with task constituents followed by input tokens and predicts the corresponding output label for that input/task pair; held-out-task evaluation tests compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>function composition via selection of modules (K-of-M)</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>held-out tasks (novel combinations); varying number of training tasks</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>standard supervised training from scratch on sampled tasks; varied number of distinct tasks to measure data-efficiency</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Transformer achieves compositional generalization as data scale grows; empirically requires fewer distinct training tasks than MLP to reach the same compositional generalization threshold (R^2 > 0.95). Exact numeric performance curves shown in paper figures but no absolute numeric tables provided.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Compared directly to MLPs (same hyperteacher tasks) showing transformers are more data-efficient; also comparisons across task encodings and model sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td>Transformer outperforms MLP in data efficiency: needs fewer distinct training tasks to reach R^2 > 0.95; both architectures can compositionally generalize under sufficient scale.</td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td>Transformer compositional generalization improves with more training tasks and model capacity, but the transformer curve is shifted toward requiring fewer tasks compared to MLP (i.e., better scaling with data).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Transformers can compositionally generalize on the hyperteacher family and do so with greater data efficiency than MLPs; scaling still helps. This supports that standard architectures with attention prefer low-algorithmic-complexity solutions at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Sufficient training coverage of tasks (compositional & connected support) and sufficient model capacity/data; transformer architecture shows better data efficiency compared to plain MLP.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2009.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2009.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deep-Hyperteacher</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hyperteacher with deep target networks (multi-layer teacher networks) evaluated with MLP students</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Variant of hyperteacher where each task network (teacher) has multiple hidden layers; used to test whether increased target-network difficulty changes the emergence of compositional generalization under scaling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ReLU MLP (student)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same standard MLP student architectures as main experiments; student trained to predict outputs of deeper hyperteacher tasks (teachers with 3 hidden layers in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>standard MLP student; teacher networks are deeper (3 hidden layers) but generated via linear hypernetwork composition</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>synthetic functional regression with deeper target networks</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Deep hyperteacher compositional task family</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Similar K-of-M module composition but target tasks are deeper (e.g., 3 hidden layers), increasing task difficulty and nonlinearity while retaining compositional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>function composition via module-summed weights; deeper internal composition due to multi-layer teacher networks</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>held-out tasks (novel module combinations)</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>standard supervised learning with varied number of distinct training tasks and model sizes</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Scaling number of training tasks still leads to compositional generalization even with deeper teacher networks, though tasks are noticeably more difficult and require more data/model capacity; exact metrics shown in Figure 11 but numeric tables not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Compared to single-layer hyperteacher experiments; deeper teacher networks increase data requirements but scaling trend remains (data + model size produce compositional generalization).</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td>Deeper hyperteacher tasks require more training tasks / larger students to reach the same compositional generalization threshold; but compositional generalization still emerges with scale.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Increasing task difficulty by making teacher networks deeper does not abolish the emergence of compositional generalization: scaling training tasks and student model size still yields compositional generalization, albeit with higher data/model requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Same as base hyperteacher: sufficient training support coverage and larger model/data scale enable generalization even for deeper tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2009.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2009.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Compositional-Preference-MLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Compositional preference task family evaluated with MLPs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Reproduction of main findings on a different compositional benchmark (preference/grid-world policies) where tasks are optimal policies induced by compositional reward functions; used to verify generality of scaling effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ReLU MLP (student)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>MLP with two hidden layers (for this task family) trained to predict actions/policies given inputs and task encodings; task encodings include linear and nonlinear variants.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>standard MLP (no explicit modularity); tested multiple task encodings incl. invertible NN and interval shuffle</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>reinforcement-policy / grid-world compositional preferences</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Compositional preference task family</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks correspond to optimal policies in a grid world where reward functions are compositional (K-of-M preferences combined into a task); the student learns to map states and task encoding to actions. Compositionality arises from combining preference modules.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>composition of reward modules into policies (K-of-M combination)</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>held-out tasks (novel combinations of preferences); varying fraction held-out and module counts M,K</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>standard supervised learning (cross-entropy loss), varying number of distinct training tasks and model capacity; task encodings both linear and nonlinear tested</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Scaling data and model size leads to compositional generalization on this family as well (plots show R^2-like metrics and classification accuracy improvements); Table 2 reports linear decodability (R^2) of task constituents from hidden activations for several encodings. Exact numeric values provided in Table 2 (paper) for M=16,K=3 (not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Compared multiple task encodings (Identity, Orthogonal, Language, Invertible NN, Interval shuffle) and varying model sizes; also examined effects of different training support constructions (balanced, non-compositional, disconnected, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td>Increasing model depth/width and increasing number of training tasks improves compositional generalization; nonlinear task encodings require more model capacity but still allow generalization when scaled.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Findings from hyperteacher replicate: data + model scaling yields compositional generalization across task encodings; linear decodability of task constituents from hidden activations correlates with successful compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td>Non-compositional or disconnected training supports and underrepresentation of modules harm compositional generalization; nonlinear encodings shift where constituents become linearly decodable (later layer).</td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Sufficient training support coverage (compositional & connected), enough distinct training tasks, and sufficient model capacity; invertible/nonlinear encodings are fine if models are large enough to 'linearize' them internally.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2009.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2009.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ImageGen-Decodability</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Text-to-image diffusion models: relation between linear decodability of constituents and image composition success</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical evaluation across several diffusion-based text-to-image models testing whether linear decodability of composed image constituents from hidden activations correlates with the success rate of generated image compositions judged by a vision-language model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Diffusion-based text-to-image models (FLUX.1-dev, SD XL base 1.0, SD 3.0 medium, SD 3.5 medium)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>State-of-the-art diffusion image generation models; architectures differ (some transformer-based), run multi-step denoising inference; hidden activations collected at specified time steps and layers and concatenated for decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>diffusion sampling process, some use transformer blocks and cross-attention to text encodings, model-specific bottleneck blocks</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>visual composition / text-to-image generation</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Image composition task families (multiple synthetic benchmarks defined in Appendix)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Large set of compositional prompts that require composing multiple concepts (objects, attributes, positions, nesting) into a single coherent image; compositions are combinatorial over sets of modules (e.g., animals, colors, styles).</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td>varies by task family (examples include 2-3 components; nested containment examples with three levels); exact depths vary across 27 task families described in Appendix C.7</td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>novel combinations of known visual concepts (objects + attributes + spatial/nesting relations)</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>All possible combinations prompted at generation time; success judged per combination (no explicit train/test split because models are pre-trained), but analysis correlates decodability of constituents in model activations with judged success rates</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>Models are large pretrained diffusion models (off-the-shelf); no fine-tuning on synthetic families reported; the paper probes hidden activations during inference to train linear decoders (logistic regression) to predict constituents.</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Generation success rate measured by a VLM judge (Gemini 2.0 Flash) per task family; average success rates per model and task family plotted (Figure 12). Linear decodability measured by F1 of logistic classifiers predicting constituents from hidden activations; clear positive correlation reported between decodability and generation success across models (R^2 and p-values reported in figure titles). Exact numeric values for each model/task appear in appendix figures/tables but are not enumerated in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td>Paper shows relative task difficulty similar across models (Figure 12) and that performance deteriorates as number of concepts to compose grows, but exact per-depth percentages not tabulated in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Compared across four open-weight image-generation models (FLUX.1-dev, SD XL base 1.0, SD 3.0 medium, SD 3.5 medium); used same tasks and evaluation pipeline. Also compared layers/time steps for decoding (varied where hidden activations probed).</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td>Different diffusion models exhibit different absolute success rates, but relative task difficulty patterns are consistent; models with higher constituent decodability show higher composition success rates.</td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Linear decodability of task/image constituents from hidden activations correlates with a model's ability to systematically compose known concepts into novel scenes; models that form more linearly-decodable constituent representations tend to generate correct compositions more often.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td>Image generation models systematically fail on some combinatorial compositions as the number/complexity of concepts increases; such failures correlate with poor linear decodability of constituents in the generation model's hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Models that internally represent constituents in a linearly-decodable way (across chosen probe layers/time steps) are more successful at composing concepts into images; success is measured without additional fine-tuning, i.e., emerges from pretraining representations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Discovering modular solutions that generalize compositionally <em>(Rating: 2)</em></li>
                <li>When can transformers compositionally generalize in-context? <em>(Rating: 2)</em></li>
                <li>Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task <em>(Rating: 2)</em></li>
                <li>Does CLIP Bind Concepts? Probing Compositionality in Large Image Models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2009",
    "paper_id": "paper-280137859",
    "extraction_schema_id": "extraction-schema-48",
    "extracted_data": [
        {
            "name_short": "Hyperteacher-MLP",
            "name_full": "Hyperteacher compositional task family evaluated with ReLU multilayer perceptrons",
            "brief_description": "Supervised regression experiments where tasks are generated by a linear hypernetwork (summing K of M modules to produce single-hidden-layer ReLU teacher networks) and solved by standard ReLU MLPs fed concatenated input and task encoding; used to study compositional generalization as data and model size scale.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ReLU MLP (fully connected multilayer perceptron)",
            "model_description": "Standard feedforward MLP with ReLU nonlinearities that takes concatenated input x and task encoding φ(z,r); typical instantiation uses 4 hidden layers of 1024 neurons (other depths/sizes explored).",
            "model_size": null,
            "is_pretrained": false,
            "architectural_features": "standard MLP (no explicit modularity), concatenated task encoding input; uses ReLU nonlinearities",
            "task_domain": "functional regression / synthetic task family",
            "task_name": "Hyperteacher compositional task family",
            "task_description": "Each task f_z is a single-hidden-layer ReLU network whose hidden weights are formed by summing K out of M module weight matrices (a linear hypernetwork); tasks are sampled from an exponentially-large family O(M choose K). The student model receives inputs x and a task encoding φ(z,r) and must predict f_z(x). Compositionality arises from combining modules to form tasks.",
            "compositional_depth": null,
            "composition_type": "function composition via selection/summation of modules (K-of-M composition)",
            "split_type": "held-out tasks (novel combinations of known modules); fraction of distinct tasks held-out varied to test generalization",
            "training_strategy": "standard supervised learning sampling tasks from p_train(z) and data from p(x); experiments vary number of distinct training tasks (coverage) and model capacity",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Measured with R^2 on held-out tasks; compositional generalization operationalized (in plots) as R^2 &gt; 0.95. Performance improves (R^2 increases) as number of distinct training tasks and model size increase; required number of training tasks grows sub-exponentially with total task count.",
            "generalization_gap": null,
            "performance_by_depth": null,
            "performance_by_composition_type": null,
            "has_baseline_comparison": true,
            "baseline_comparisons": "Compared different task encodings (identity, orthogonal projection, language, few-shot example-based, invertible NN, interval shuffle) as well as different training support constructions (Random, Balanced, Non-compositional, Disconnected, Popular/Unpopular modules). Also compared to transformer architecture (see separate entry).",
            "architectural_comparison": "MLP vs transformer: both can achieve compositional generalization under sufficient scale, but transformers require fewer distinct training tasks to reach the R^2 &gt; 0.95 threshold (i.e., better data efficiency). Deeper/wider MLPs perform better given sufficient data.",
            "scale_effects": "Increasing number of training tasks (data scale) and increasing model size (more layers and hidden units) consistently improve compositional generalization; empirical curves show monotonic improvement and a sub-exponential required-training-tasks scaling. No explicit parameter counts reported.",
            "transfer_results": null,
            "key_findings": "Standard ReLU MLPs can compositionally generalize on the hyperteacher family if (i) the training distribution sufficiently covers the task space (compositional and connected support) and (ii) data and model size are scaled; compositional generalization can be achieved with a sub-exponential number of training tasks and larger models. Task constituents become linearly decodable from hidden activations when compositional generalization succeeds.",
            "failure_analysis": "Failures occur when the training support is deficient: if some module never appears (non-compositional support), if support is disconnected, or if some modules are extremely underrepresented (unpopular modules), compositional generalization degrades. Identity availability of z at input is not sufficient if representations are lost in hidden layers.",
            "success_conditions": "Sufficient coverage of task space (compositional + connected support), sufficiently large number of distinct training tasks (scaling), and sufficient model capacity; information-preserving task encodings (not necessary to be linear) support generalization when model size is adequate.",
            "uuid": "e2009.0"
        },
        {
            "name_short": "Hyperteacher-Transformer",
            "name_full": "Decoder-only transformer on hyperteacher compositional tasks",
            "brief_description": "Decoder-only transformer trained to autoregressively predict labels given a sequence containing task constituents followed by task inputs; evaluated for compositional generalization on same hyperteacher family to compare architecture and data-efficiency effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Decoder-only Transformer",
            "model_description": "Causally-masked decoder-only transformer with 4 layers, 4 attention heads, model dimension 256 and feedforward dimension 1024; separate projection matrices for task constituents, inputs and outputs.",
            "model_size": null,
            "is_pretrained": false,
            "architectural_features": "self-attention mechanism, autoregressive decoding, standard transformer feedforward blocks",
            "task_domain": "functional regression / synthetic task family",
            "task_name": "Hyperteacher compositional task family (same as MLP experiments)",
            "task_description": "Transformer receives sequence with task constituents followed by input tokens and predicts the corresponding output label for that input/task pair; held-out-task evaluation tests compositional generalization.",
            "compositional_depth": null,
            "composition_type": "function composition via selection of modules (K-of-M)",
            "split_type": "held-out tasks (novel combinations); varying number of training tasks",
            "training_strategy": "standard supervised training from scratch on sampled tasks; varied number of distinct tasks to measure data-efficiency",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Transformer achieves compositional generalization as data scale grows; empirically requires fewer distinct training tasks than MLP to reach the same compositional generalization threshold (R^2 &gt; 0.95). Exact numeric performance curves shown in paper figures but no absolute numeric tables provided.",
            "generalization_gap": null,
            "performance_by_depth": null,
            "performance_by_composition_type": null,
            "has_baseline_comparison": true,
            "baseline_comparisons": "Compared directly to MLPs (same hyperteacher tasks) showing transformers are more data-efficient; also comparisons across task encodings and model sizes.",
            "architectural_comparison": "Transformer outperforms MLP in data efficiency: needs fewer distinct training tasks to reach R^2 &gt; 0.95; both architectures can compositionally generalize under sufficient scale.",
            "scale_effects": "Transformer compositional generalization improves with more training tasks and model capacity, but the transformer curve is shifted toward requiring fewer tasks compared to MLP (i.e., better scaling with data).",
            "transfer_results": null,
            "key_findings": "Transformers can compositionally generalize on the hyperteacher family and do so with greater data efficiency than MLPs; scaling still helps. This supports that standard architectures with attention prefer low-algorithmic-complexity solutions at scale.",
            "failure_analysis": null,
            "success_conditions": "Sufficient training coverage of tasks (compositional & connected support) and sufficient model capacity/data; transformer architecture shows better data efficiency compared to plain MLP.",
            "uuid": "e2009.1"
        },
        {
            "name_short": "Deep-Hyperteacher",
            "name_full": "Hyperteacher with deep target networks (multi-layer teacher networks) evaluated with MLP students",
            "brief_description": "Variant of hyperteacher where each task network (teacher) has multiple hidden layers; used to test whether increased target-network difficulty changes the emergence of compositional generalization under scaling.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ReLU MLP (student)",
            "model_description": "Same standard MLP student architectures as main experiments; student trained to predict outputs of deeper hyperteacher tasks (teachers with 3 hidden layers in experiments).",
            "model_size": null,
            "is_pretrained": false,
            "architectural_features": "standard MLP student; teacher networks are deeper (3 hidden layers) but generated via linear hypernetwork composition",
            "task_domain": "synthetic functional regression with deeper target networks",
            "task_name": "Deep hyperteacher compositional task family",
            "task_description": "Similar K-of-M module composition but target tasks are deeper (e.g., 3 hidden layers), increasing task difficulty and nonlinearity while retaining compositional structure.",
            "compositional_depth": null,
            "composition_type": "function composition via module-summed weights; deeper internal composition due to multi-layer teacher networks",
            "split_type": "held-out tasks (novel module combinations)",
            "training_strategy": "standard supervised learning with varied number of distinct training tasks and model sizes",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Scaling number of training tasks still leads to compositional generalization even with deeper teacher networks, though tasks are noticeably more difficult and require more data/model capacity; exact metrics shown in Figure 11 but numeric tables not provided.",
            "generalization_gap": null,
            "performance_by_depth": null,
            "performance_by_composition_type": null,
            "has_baseline_comparison": true,
            "baseline_comparisons": "Compared to single-layer hyperteacher experiments; deeper teacher networks increase data requirements but scaling trend remains (data + model size produce compositional generalization).",
            "architectural_comparison": null,
            "scale_effects": "Deeper hyperteacher tasks require more training tasks / larger students to reach the same compositional generalization threshold; but compositional generalization still emerges with scale.",
            "transfer_results": null,
            "key_findings": "Increasing task difficulty by making teacher networks deeper does not abolish the emergence of compositional generalization: scaling training tasks and student model size still yields compositional generalization, albeit with higher data/model requirements.",
            "failure_analysis": null,
            "success_conditions": "Same as base hyperteacher: sufficient training support coverage and larger model/data scale enable generalization even for deeper tasks.",
            "uuid": "e2009.2"
        },
        {
            "name_short": "Compositional-Preference-MLP",
            "name_full": "Compositional preference task family evaluated with MLPs",
            "brief_description": "Reproduction of main findings on a different compositional benchmark (preference/grid-world policies) where tasks are optimal policies induced by compositional reward functions; used to verify generality of scaling effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ReLU MLP (student)",
            "model_description": "MLP with two hidden layers (for this task family) trained to predict actions/policies given inputs and task encodings; task encodings include linear and nonlinear variants.",
            "model_size": null,
            "is_pretrained": false,
            "architectural_features": "standard MLP (no explicit modularity); tested multiple task encodings incl. invertible NN and interval shuffle",
            "task_domain": "reinforcement-policy / grid-world compositional preferences",
            "task_name": "Compositional preference task family",
            "task_description": "Tasks correspond to optimal policies in a grid world where reward functions are compositional (K-of-M preferences combined into a task); the student learns to map states and task encoding to actions. Compositionality arises from combining preference modules.",
            "compositional_depth": null,
            "composition_type": "composition of reward modules into policies (K-of-M combination)",
            "split_type": "held-out tasks (novel combinations of preferences); varying fraction held-out and module counts M,K",
            "training_strategy": "standard supervised learning (cross-entropy loss), varying number of distinct training tasks and model capacity; task encodings both linear and nonlinear tested",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Scaling data and model size leads to compositional generalization on this family as well (plots show R^2-like metrics and classification accuracy improvements); Table 2 reports linear decodability (R^2) of task constituents from hidden activations for several encodings. Exact numeric values provided in Table 2 (paper) for M=16,K=3 (not reproduced here).",
            "generalization_gap": null,
            "performance_by_depth": null,
            "performance_by_composition_type": null,
            "has_baseline_comparison": true,
            "baseline_comparisons": "Compared multiple task encodings (Identity, Orthogonal, Language, Invertible NN, Interval shuffle) and varying model sizes; also examined effects of different training support constructions (balanced, non-compositional, disconnected, etc.).",
            "architectural_comparison": null,
            "scale_effects": "Increasing model depth/width and increasing number of training tasks improves compositional generalization; nonlinear task encodings require more model capacity but still allow generalization when scaled.",
            "transfer_results": null,
            "key_findings": "Findings from hyperteacher replicate: data + model scaling yields compositional generalization across task encodings; linear decodability of task constituents from hidden activations correlates with successful compositional generalization.",
            "failure_analysis": "Non-compositional or disconnected training supports and underrepresentation of modules harm compositional generalization; nonlinear encodings shift where constituents become linearly decodable (later layer).",
            "success_conditions": "Sufficient training support coverage (compositional & connected), enough distinct training tasks, and sufficient model capacity; invertible/nonlinear encodings are fine if models are large enough to 'linearize' them internally.",
            "uuid": "e2009.3"
        },
        {
            "name_short": "ImageGen-Decodability",
            "name_full": "Text-to-image diffusion models: relation between linear decodability of constituents and image composition success",
            "brief_description": "Empirical evaluation across several diffusion-based text-to-image models testing whether linear decodability of composed image constituents from hidden activations correlates with the success rate of generated image compositions judged by a vision-language model.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Diffusion-based text-to-image models (FLUX.1-dev, SD XL base 1.0, SD 3.0 medium, SD 3.5 medium)",
            "model_description": "State-of-the-art diffusion image generation models; architectures differ (some transformer-based), run multi-step denoising inference; hidden activations collected at specified time steps and layers and concatenated for decoding.",
            "model_size": null,
            "is_pretrained": true,
            "architectural_features": "diffusion sampling process, some use transformer blocks and cross-attention to text encodings, model-specific bottleneck blocks",
            "task_domain": "visual composition / text-to-image generation",
            "task_name": "Image composition task families (multiple synthetic benchmarks defined in Appendix)",
            "task_description": "Large set of compositional prompts that require composing multiple concepts (objects, attributes, positions, nesting) into a single coherent image; compositions are combinatorial over sets of modules (e.g., animals, colors, styles).",
            "compositional_depth": "varies by task family (examples include 2-3 components; nested containment examples with three levels); exact depths vary across 27 task families described in Appendix C.7",
            "composition_type": "novel combinations of known visual concepts (objects + attributes + spatial/nesting relations)",
            "split_type": "All possible combinations prompted at generation time; success judged per combination (no explicit train/test split because models are pre-trained), but analysis correlates decodability of constituents in model activations with judged success rates",
            "training_strategy": "Models are large pretrained diffusion models (off-the-shelf); no fine-tuning on synthetic families reported; the paper probes hidden activations during inference to train linear decoders (logistic regression) to predict constituents.",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Generation success rate measured by a VLM judge (Gemini 2.0 Flash) per task family; average success rates per model and task family plotted (Figure 12). Linear decodability measured by F1 of logistic classifiers predicting constituents from hidden activations; clear positive correlation reported between decodability and generation success across models (R^2 and p-values reported in figure titles). Exact numeric values for each model/task appear in appendix figures/tables but are not enumerated in main text.",
            "generalization_gap": null,
            "performance_by_depth": "Paper shows relative task difficulty similar across models (Figure 12) and that performance deteriorates as number of concepts to compose grows, but exact per-depth percentages not tabulated in the main text.",
            "performance_by_composition_type": null,
            "has_baseline_comparison": true,
            "baseline_comparisons": "Compared across four open-weight image-generation models (FLUX.1-dev, SD XL base 1.0, SD 3.0 medium, SD 3.5 medium); used same tasks and evaluation pipeline. Also compared layers/time steps for decoding (varied where hidden activations probed).",
            "architectural_comparison": "Different diffusion models exhibit different absolute success rates, but relative task difficulty patterns are consistent; models with higher constituent decodability show higher composition success rates.",
            "scale_effects": null,
            "transfer_results": null,
            "key_findings": "Linear decodability of task/image constituents from hidden activations correlates with a model's ability to systematically compose known concepts into novel scenes; models that form more linearly-decodable constituent representations tend to generate correct compositions more often.",
            "failure_analysis": "Image generation models systematically fail on some combinatorial compositions as the number/complexity of concepts increases; such failures correlate with poor linear decodability of constituents in the generation model's hidden states.",
            "success_conditions": "Models that internally represent constituents in a linearly-decodable way (across chosen probe layers/time steps) are more successful at composing concepts into images; success is measured without additional fine-tuning, i.e., emerges from pretraining representations.",
            "uuid": "e2009.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Discovering modular solutions that generalize compositionally",
            "rating": 2
        },
        {
            "paper_title": "When can transformers compositionally generalize in-context?",
            "rating": 2
        },
        {
            "paper_title": "Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task",
            "rating": 2
        },
        {
            "paper_title": "Does CLIP Bind Concepts? Probing Compositionality in Large Image Models",
            "rating": 1
        }
    ],
    "cost": 0.0177305,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Scaling can lead to compositional generalization
23 Oct 2025</p>
<p>Florian Redhardt 
Yassir Akram 
Simon Schug sschug@princeton.edu </p>
<p>ETH Zurich</p>
<p>ETH Zurich</p>
<p>Princeton University</p>
<p>Scaling can lead to compositional generalization
23 Oct 20253F35C10524AD2E4756FE41084201059AarXiv:2507.07207v2[cs.LG]
Can neural networks systematically capture discrete, compositional task structure despite their continuous, distributed nature?The impressive capabilities of largescale neural networks suggest that the answer to this question is yes.However, even for the most capable models, there are still frequent failure cases that raise doubts about their compositionality.Here, we seek to understand what it takes for a standard neural network to generalize over tasks that share compositional structure.We find that simply scaling data and model size leads to compositional generalization.We show that this holds across different task encodings as long as the training distribution sufficiently covers the task space.In line with this finding, we prove that standard multilayer perceptrons can approximate a general class of compositional task families to arbitrary precision using only a linear number of neurons with respect to the number of task modules.Finally, we uncover that if networks successfully compositionally generalize, the constituents of a task can be linearly decoded from their hidden activations.We show that this metric correlates with failures of text-to-image generation models to compose known concepts.</p>
<p>Introduction</p>
<p>The ability to understand and produce novel combinations from familiar constituents is a key faculty of intelligence.It has been debated for decades whether neural networks are ever able to truly achieve such compositional generalization [1].Regardless of these theoretical considerations, scaling neural networks continues to result in increasingly capable models [2][3][4].Naturally, as models are scaled up, their capacity to memorize grows, and it is perhaps unsurprising that as a result of training on ever larger datasets their ability to recall more information grows too [5].However, the nature of compositionality is an exponential growth and ultimately any attempt to exhaustively capture this breadth by scaling the training data will be confronted with physical constraints.</p>
<p>Many works therefore advocate that neural network architectures should be explicitly endowed with compositional structure [e.g., [6][7][8][9] to allow making infinite use of their finite means [10,11].Capturing the underlying compositional procedure of the data is a more efficient pathway to generalize.In particular, the algorithmic complexity of this generalizing solution is much smaller than the complexity of the memorizing solution [12].But does this mean that architectures need to explicitly factorize according to the data's underlying compositional mechanisms [9]?For instance, monolithic networks have been shown to discover modular subnetworks which may enable compositionality without specialized symbolic mechanisms [13].Maybe simply scaling the data and size of neural networks is then enough to achieve compositionality.Here, we attempt to answer this question: Do neural networks compositionally generalize at scale?Scaling can lead to compositional generalization.We consider compositional task families that compose K out of M modules into tasks, each of which is modeled as a function.This gives rise to an exponential number of O(M K ) tasks.We train standard feedforward networks on a subset of tasks and evaluate compositional generalization on held-out tasks.We find that scaling the size of the model and the data leads to compositional generalization.</p>
<p>Our main contributions are as follows</p>
<p>• We demonstrate that standard multilayer perceptrons compositionally generalize on a variety of tasks as data and model size are scaled across task encodings if the training distribution sufficiently covers the task space.</p>
<p>• We prove that multilayer perceptrons can approximate a general class of compositional task families to arbitrary precision using only a linear number of neurons with respect to the number of task modules.</p>
<p>• We show that task constituents can be (linearly) decoded from the hidden activations of models that compositionally generalize, and demonstrate that this metric correlates with failures of image generation models to compose known concepts.</p>
<p>Compositionality and compositional generalization</p>
<p>We begin by formalizing compositionality and compositional generalization with the goal of capturing a variety of compositional data types including visual scenes, abstract reasoning and behavior policies.</p>
<p>Compositional task family</p>
<p>Specifically, we will consider compositional task families that specify a generative procedure over tasks with shared compositional structure.In a similar vein to [14], our definition uses algorithmic complexity theory, in particular the notion of Kolmogorov complexity, see [15] for a formal treatment.This definition is a modified version of the definition introduced by [16]. 1efinition 2.1 (Compositional task family).A compositional task family is a tuple T = (C, p : z → p(z), p : x → p(x)), where:</p>
<p>• The task constituent space is a set Z ⊆ {z ∈ [0, 1] M : 1 ≤ ∥z∥ 0 ≤ K ≤ M } with corresponding task distribution p(z).K is the number of task components and M is the number of task modules.• A task is a function f z : X → Y that labels data points x ∼ p(x).</p>
<p>• The composition operator is a mapping C : Z → (X → Y ) that takes as input task constituents z ∈ Z and maps them to a task, C(z) := f z for which the following conditions hold: (i) C(z) ̸ = C(z ′ ) for all z ̸ = z ′ with z, z ′ ∈ Z, i.e.C is injective.</p>
<p>(ii) The length of the shortest program that implements C as a function of K grows subexponentially in K.</p>
<p>In the discrete case, where Z ⊆ {z ∈ {0, 1} M : 1 ≤ ∥z∥ 0 ≤ K ≤ M } is restricted to the set of binary, K-hot vectors, Definition 2.1 essentially states that a compositional task family compactly captures exponentially many tasks.Condition (i) ensures that all task components functionally enter the composition, while condition (ii) excludes the case where compositions are purely contextsensitive, ensuring that there is shared structure between tasks.For a more detailed discussion of this definition, please refer to [16].</p>
<p>The notion of a task is used in a general sense here and allows to capture different types of compositional data.For instance, a task could refer to a visual scene, where modules are the set of possible objects and the composition operator renders a selection of such objects into a scene.Similarly, a task could refer to a behavior policy, where modules consist of different reward functions, a subset of which is combined by the composition operator to induce an optimal policy.</p>
<p>Task encoding</p>
<p>Before we can continue to define compositional generalization using Definition 2.1, we must first specify how to present the model with information about its current task, as captured by the task constituents z.In practice, such a task description might not be the task constituents themselves, but rather some encoding thereof.For example, a task could be described through a natural language instruction or by presenting example data points (x i , f z (x i )) i .To model this aspect, we define the task encoder as the mapping φ : (Z, N) → Z ′ that maps task constituents z ∈ Z and a random seed r ∈ N to a task encoding.Throughout the paper, we mostly focus on settings where the task is unambiguously specified, i.e.where the task encoding φ is information-preserving and therefore injective.</p>
<p>Compositional generalization</p>
<p>With Definition 2.1 at hand, we can now formalize compositional generalization for a model that learns to perform tasks from a compositional task family, given a task encoding φ.This definition is a slightly modified version of the definition presented in [16].</p>
<p>Definition 2.2 (Compositional generalization)</p>
<p>. A model parameterized by θ is said to compositionally generalize with respect to the compositional task family T = (Z, C, p(z), p(x)) if there exists a discrete training distribution z → p train (z) with finite support such that the number of points in the support grows sub-exponentially in K and it holds that
θ * ∈ arg min θ E z∼p train (z) E x∼p(x) [l(θ, x, z)] ⇒ θ * ∈ arg min θ E z∼p(z) E x∼p(x) [l(θ, x, z)] ,
where l(θ, x, z) = l (f z (x), g θ (x, φ(z)) is a loss function that measures the discrepancy between model predictions and the outputs of a task f z (x) for a given datum x and task encoding φ(z).</p>
<p>Note, that we are not considering fixed-size datasets but are sampling directly from the data distribution which reflects the nowadays common single-epoch training regime of large-scale foundation models [e.g., 3].</p>
<p>Hyperteachers: A general class of compositional task families</p>
<p>For the purpose of this study, it will be useful to instantiate a concrete but nevertheless general class of compositional task families according to Definition 2.1.Given that neural networks are flexible function approximators and thus able to cover a wide range of behaviors, we parameterize both the composition operator as well as the task functions using neural networks.The resulting system, a composable neural network that generates another neural network, can be interpreted as a hypernetwork [17].Indeed, hypernetworks have previously been used to study compositional generalization [18].</p>
<p>Following [18], we consider a linear hypernetwork that sums K out of M possible weight matrices to parameterize a single hidden layer task network.We define the task constituent space to be Z ⊆ {z ∈ {0.5, 0.6, . . ., 1.0} M : 1 ≤ ∥z∥ 0 ≤ K ≤ M } and the composition operator as  where we have M sets of neural network parameters {Θ m ∈ R I×H } M m=1 with I input neurons and H hidden neurons, Ω ∈ R H×O is a shared readout projection with O output neurons and we sample x ∈ R I from the uniform distribution p(x) = U[−1, 1] I .Each module Θ m also has an associated bias vector which we omit here for conciseness.The resulting task functions, f z : R I → R O , are thus single hidden layer ReLU networks.
C(z) = x → Ω ReLU   k:z k ̸ =0 z k Θ k x   ,(1)</p>
<p>Scaling can lead to compositional generalization</p>
<p>In the following, we will investigate if and under what circumstances standard multilayer perceptrons compositionally generalize.We will show that simply scaling the number of tasks in the training distribution as well as scaling model size leads to compositional generalization.The results presented in this section focus on various parameterizations of the hyperteacher compositional task family presented in Section 2.4.We reproduce all findings of this section on the compositional preference task family introduced by [18].This task family requires learning optimal policies in a grid world with compositional reward functions.We present the corresponding results in Appendix B.1 in Figures 7, 8, 9 and Table 2.For additional experimental details, please refer to Appendix C.</p>
<p>While there exist various architectures specialized for compositionality, here we are interested in understanding if a standard fully connected neural network, a multilayer perceptron, can compositionally generalize.Fully connected layers are common building blocks of virtually all standard architectures, including transformers or recurrent neural networks.Specifically, we consider a multilayer perceptron with ReLU nonlinearities that accepts the concatenation of x and φ(z, r) as input.</p>
<p>ReLU MLP x φ(z, r) y</p>
<p>In order to measure a model's ability to compositionally generalize, we will hold out tasks from training and evaluate the model's performance on these tasks.</p>
<p>Scaling the number of compositional tasks leads to compositional generalization</p>
<p>To investigate the main question of how scale affects compositional generalization, we will vary both data and model size.The former can be accomplished along two different dimensions: We can vary the total number of tasks in the compositional task family by changing both the number of modules M and the number of components K, and we can vary the fraction of distinct tasks that are held-out from training.Since the number of possible tasks grows exponentially, O(M K ), the compositional task families we consider can easily contain a very large number of distinct tasks.</p>
<p>The top-left of Figure 2 shows that as we scale the number of tasks, compositional generalization improves.Notably, the required number of training tasks to achieve compositional generalization grows more slowly than the total number of tasks as shown on the top-right of Figure 2.This implies that compositional generalization with a sub-exponential number of tasks, as in Definition 2.2, is indeed achievable at scale.In Appendix B, we further demonstrate that this scaling relationship is even more favorable for transformers and similarly holds for the compositional preference task family as well as a hyperteacher with a deep target network.</p>
<p>In addition to scaling the data, we would like to understand how scaling model size affects compositional generalization.Shown at the bottom of Figure 2, we vary both the number of hidden layers and the size of the hidden layers for various possible task encodings φ(z, r) (more details on the task encodings will follow in Section 3.3).We find that, given sufficient data, increasing model size consistently improves compositional generalization.This is noteworthy, given that increasing model size in principle increases the capacity to memorize training tasks without capturing the underlying compositional structure required for compositional generalization.As we will argue in the following however, these results can be interpreted as evidence that deep neural networks tend to prefer solutions of low algorithmic complexity [19].</p>
<p>Complexity of generalizing solution dominates memorizing solution asymptotically</p>
<p>Memorizing all tasks of a compositional task family by definition requires exponential network capacity.Intuitively, a solution that captures the underlying compositional structure and thus generalizes should be more efficient.A priori, it is however not clear whether such a solution exists for a finite-sized, multilayer perceptron.As we have argued before, hyperteachers can be regarded as a general class of compositional task families.It is therefore instructive to consider whether a finite-sized multilayer perceptron can implement any hyperteacher without having to memorize the exponential number of possible tasks.The following theorem answers this question in the affirmative.</p>
<p>Theorem 3.1.Let Θ m ∈ R I×H be a sequence of uniformly bounded matrices.Then, for any M ∈ N, ε &gt; 0, and on any compact input set, X × Z with Z = {z : ∥z∥ 1 ≤ 1}, there exists a ReLU multilayer perceptron that approximates a hyperteacher to within ε error in the ∥ • ∥ ∞ norm using
O 1 √ ε + M neurons.
The corresponding constructive proof is presented in Appendix A.2 along with an extension to hyperteachers with multiple layers.Theorem 3.1 notably states that the number of neurons required for the generalizing solution scales linearly in the number of modules M .Consistent with our experimental findings, this means that as M grows, the simplicity of the fully generalizing solution will increasingly dominate the naive memorizing solution.</p>
<p>Compositional generalization emerges across task encodings</p>
<p>We now turn to the question, to what extent the way in which the task is specified to the model matters for its ability to compositionally generalize.Specifically, one might suspect that certain ways of encoding a task are better suited to leveraging compositional structure than others.For instance, [20] argue that language in particular encodes task structure in a way that is beneficial for learning compositional representations.To study this question in the context of our setup, we experiment with different task encodings φ(z, r) illustrated in Figure 3.</p>
<p>Generally, we find that all task encodings lead to compositional generalization, including nonlinear encodings, although some require more model capacity as shown at the bottom of Figure 2  .Specifically, we observe no benefit of directly using the identity task encoding φ(z, r) = z, over a random but fixed orthogonal projection φ(z, r) = Qz where Q ∈ R M ×M is an orthogonal matrix.In the same way, encoding each task through a language instruction poses no issues.The latter is consistent with the observation that the task constituents can be linearly decoded from such instructions.Interestingly, even nonlinear encodings such as specifying the task through examples (denoted fewshot), via an invertible neural network or from the highly nonlinear interval shuffle function (see Algorithm 1 in the appendix for a definition) lead to compositional generalization if the model size is sufficiently large.One possible explanation for these findings is that regardless of the task encoding, the model internally infers the task constituents up to a linear transformation after which Theorem 3.1 guarantees that a generalizing solution that scales linearly in the number of modules M exists.</p>
<p>To verify this hypothesis, we train a linear decoder to predict the task constituents based on the hidden activations of the model solving the task.We report the ability of this task decoder to predict the task constituents on the held-out compositional generalization tasks in Table 1.Indeed, we find that also for nonlinear task encodings the task constituents can be linearly decoded from the hidden activations providing evidence that the models internally linearize the task constituents to achieve compositional generalization.We will expand on this finding in Section 4.</p>
<p>The support of the training distribution needs to sufficiently cover the task space</p>
<p>In principle, it is easy to come up with degenerate training distributions that make compositional generalization impossible.For instance, if a module is consistently absent from all training tasks, the model has no opportunity to learn this module and will generally fail to generalize to tasks that contain this module.In this sense, the support of the training distribution p train (z) needs to sufficiently cover the full constituent space for compositional generalization to succeed.In this section we investigate how various conditions over the training support affect compositional generalization.</p>
<p>Prior work has studied how the training distribution affects compositional generalization [e.g., 18,21,22].Following [21] we refer to the condition of having non-zero support for each module in the training distribution as compositional support .For the class of hyperteacher task families, the additional condition of connected support needs to be satisfied, which states that no subset of modules should appear solely in isolation from the rest.[18] show that in a teacher-student setting where both the teacher and the student are hypernetworks, this condition is required to guarantee compositional generalization.We can extend this result to the more general case of any kind of student, including the ReLU multilayer perceptron.The proof follows immediately by constructing examples of multiple different hyperteachers that have an identical training distribution if the training support is not connected.Please refer to Appendix A.1 for more details.</p>
<p>Figure 4 illustrates the different types of training support we consider here as well as their effect on compositional generalization in the hyperteacher.For a more detailed description for how each training support is constructed, please refer to Appendix C.3.Our findings empirically confirm that violating compositional and connected support interferes with compositional generalization.Interestingly, having a small set of popular modules who appear more frequently poses no issue for achieving compositional generalization.The converse of having a small set of unpopular modules that are rarely encountered however does lead to a noticeable drop.These findings are consistent with prior work that find that module imbalance hampers compositional generalization [23,24].However, our experiments further suggest that such failures are due to underrepresentation of certain modules and not simply due to an asymmetry in module popularity.Intuitively, if a module is seen only a constant number of times during training, it can be memorized with constant capacity.</p>
<p>4 Task constituents are linearly decodable in models that compositionally generalize Section 3.3 has revealed that in cases where compositional generalization succeeds, the task constituents can be linearly decoded from the hidden activations.This prompts the question whether models that succeed to compositionally generalize typically form an internal linear representation of the task constituents.Generally speaking, we can show that for any model that compositionally generalizes to most tasks, the task constituents must be decodable.</p>
<p>Theorem 4.1 (Decodability under compositional generalization).For any δ &gt; 0, assume we have a student g that predicts labels f z (x) = y given a task encoding φ(z, r) and inputs x.Then there exists a decoder map ϕ that decodes φ(z, r) to z with probability at least 1 − √ δ, if:  We provide the proof in Appendix A. 3.In practice, we observe an even stronger version of this statement, namely that the task constituents are linearly decodable from the hidden activations in multilayer perceptrons that successfully compositionally generalize.
(i) P z,x [g(φ(z, r), x) = C(z)(x)] &gt; 1 − δ (ii) For each z ̸ = z ′ , P x [C(z)(x) = C(z ′ )(x)] &lt; 1 − 2 √ δ 0.6 0.</p>
<p>Compositional generalization correlates with linear decodability of task constituents</p>
<p>To further illuminate the connection between the observed linear decodability of the task constituents and compositional generalization, we attempt to decode the task constituents in models that (partially) fail to fully compositionally generalize.Figure 5 shows a remarkably clear correlation between decodability and compositional generalization across different data scales (top) and model sizes and task encodings (bottom).Particularly interesting is the case where the unmodified task constituents are provided to the model, i.e.where the task encoding is the identity.In this case, the task constituents are of course trivially linearly decodable from the input.However, training the decoder on the hidden activations of deeper layers, this information is lost in networks that do not compositionally generalize.In line with previous research, this implies that having access to a disentangled task representation is by itself not sufficient to achieve compositional generalization [25,26].</p>
<p>Task constituents can be linearly decoded when image composition succeeds</p>
<p>Finally, can we leverage the decodability of task constituents to gain insights into the successes and failures of image generation models at composing scenes from text prompts? 2 Image generation models have come a long way, displaying impressive abilities in creating novel compositions of known concepts [24].Nevertheless, there are still systematic failure cases [27,28].Can such failures be related to the ability to infer the task constituents from the model's hidden activations?</p>
<p>To answer this question, we construct a large number of compositional tasks that require composing several concepts.Two examples are shown in the top-left of Figure 6.For an extensive list of all the tasks we consider, as well as more details on the task construction, see Appendix C.7.Using these tasks, we evaluate the ability of several diffusion-based image generation models to systematically generate image compositions [29,30].We use a vision-language model to label whether a given generation was successful and train a linear decoder to decode the task constituents based on the We observe a clear correlation between the average task constituent decodability and the average generation success rate across models, with the relative task difficulty being similar across models, as shown in Figure 12 of the Appendix.This provides evidence that models which succeed at systematically composing known concepts into scenes form an internal representation of the task constituents.</p>
<p>Related work</p>
<p>The study of compositional generalization in neural networks has a long and rich history, with early critiques highlighting the challenges of connectionist models to exhibit systematicity and compositionality [e.g., 1, 31-33] and numerous work that in response explored mechanisms for representing and processing structured information using distributed representations [e.g., 34,35].In recent years, theoretical progress has been made in showing that compositional generalization can provably be achieved with neural networks in specific settings [18,22,[36][37][38][39].This typically requires constraining the model architecture and the data generating process.Consistent with our results, the statistics of the training data play a crucial rule in enabling compositional generalization [18,21,22,39].</p>
<p>We aim to complement this work by showing how scaling generic neural networks can lead to compositional generalization in the absence of stronger architectural constraints.This is motivated by the finding that scaling neural networks can break the curse of dimensionality [40], and consistently results in improvements in model performance [2,41] with new capabilities emerging as models are scaled up [3,4,42].Compositional abilities in particular have therefore seemingly moved within grasp in practice [43][44][45][46][47][48].However, even at larger scales, models often display a compositional generalization gap which does not close as scale increases [49][50][51][52][53][54][55][56][57], despite standard transformers showing compositionality in controlled settings [58][59][60].</p>
<p>Image generation models in particular have made impressive leaps in their ability to create novel image compositions [29,30,61,62].Compositional abilities have been shown to emerge in such diffusion-based models on synthetic tasks in an order determined by the underlying data processes and with performance showing sudden emergence due to multiplicative dependencies [24,63].Consistent with our finding that the task constituents are linearly decodable in models that successfully compositionally generalize, [64] find that diffusion image generation models learn factorized representations on a number of synthetic tasks.However, as the number of concepts that need to be composed grows, the performance of image generation models starts to deteriorate, showing the limits of their productivity to arbitrarily complex compositions [27,28].</p>
<p>Discussion</p>
<p>We have shown that simply scaling standard multilayer perceptrons can lead to compositional generalization challenging the position that stronger architectural priors are necessary to endow neural networks with compositionality [6][7][8][9].That being said, architectural priors do matter when it comes to data efficiency, as highlighted by the improved scaling of transformers over multilayer perceptrons (see Appendix B).Our findings also emphasize that the particular structure of the training data plays a critical role, demonstrating that not any type of scaling will lead to compositional generalization.</p>
<p>Interestingly, we find that when the training distribution is appropriately chosen, a wide range of task encodings support compositional generalization, including language but crucially also nonlinear task encodings such as specifying each task through examples.Prior work posits that language compositionally structures neural representations and thereby aids rapid adaptation to novel compositional tasks [20].Our results indicate that in fact any information-preserving mapping of the underlying task constituents suffices to achieve compositional generalization.This might help explain why animals that do not use sophisticated languages can compositionally generalize [e.g., 65].Surprisingly, regardless of whether task encodings are linear or nonlinear, we consistently find that the degree to which a model compositionally generalizes is related to the task constituents being linearly decodable from its hidden activations.In particular, we show that this metric correlates with the success rate of image generation models at composing novel scenes from known constituents.This finding suggests that, even though nonlinear representations would in principle be possible, successful compositional generalization in neural networks depends on linear representations of compositional structure.</p>
<p>Limitations While Theorem3.1 reveals the existence of a solution that enables compositional generalization without requiring an exponential number of neurons, identifying the theoretical conditions under which one can show that this solution is guaranteed to be discovered by stochastic gradient descent is an open question.Prior results indicate that deep neural networks trained with stochastic gradient descent often display a preference towards simple solutions [19,[66][67][68].In the context of compositional generalization, the complexity of the memorizing solution is by definition exponential in the number of modules which might help explain why empirically we observe the discovery of the generalizing solution which in contrast scales linearly in the number of modules.</p>
<p>We have focused on settings, where the task is fully specified through the task encoding.In practice, a task specification might be ambiguous or incomplete, requiring models to handle uncertainty and infer the task at hand.The strong in-context learning abilities of transformers that might allow extracting localized, and even cross-modal task vectors could play an important role in this context [69][70][71].</p>
<p>More generally, scaling the data in a way that precisely controls the coverage of the training distribution requires an understanding of the true generative process underlying the compositional data.For this reason, our scaling experiments rely on synthetic data generation that gives us the required experimental control.On real-world data, the underlying generative process is mostly unknown and accordingly identifying training distributions that can support compositional generalization remains an open question.</p>
<p>Broader impacts This paper conducts foundational research aiming to illuminate under what circumstances neural networks compositionally generalize.While we foresee no immediate negative societal impact, we hope that it may improve our understanding of this widely deployed technology.</p>
<p>A Proofs</p>
<p>A.1 Connected support</p>
<p>We briefly state the definition of connected support as introduced by [18] using our notation.</p>
<p>Definition A.1 (Connected support).Let T = (C, p : z → p(z), p : x → p(x)) be a compositional task family, and let z → p train (z) be a distribution over Z with discrete support supp(p train ) ⊆ Z.We say that supp(p train ) is connected if the graph G = (V, E) is connected, where V = {z ∈ Z | p train (z) &gt; 0} is the set of vertices and
E = {(z, z ′ ) ∈ V × V | ∃i ∈ {1, 2, . . . , M } such that z i = z ′
i } is the set of edges.In other words, two training task constituents are connected by an edge if and only if they share at least one element at the same position.Section A.3 of [18] provides an example that demonstrates how a student hypernetwork can perfectly fit the training distribution of a different teacher hypernetwork if the task support is compositional but disconnected.This implies that there exist two distinct hyperteachers that have the same training distribution.In such cases, any student, including the multilayer perceptron considered here, is not guaranteed to generalize even when perfectly fitting the training tasks.To avoid those cases, connected support is generally required for the hyperteacher.</p>
<p>A.2 Proof of Theorem 3.1</p>
<p>In the following, we will show that a multilayer perceptron can approximate a hyperteacher using a linear number of neurons in the number of task modules.We first state the result for the single layer hyperteacher we primarily consider in the main text, before extending the result to hyperteachers with multiple layers.</p>
<p>A.2.1 Single layer hyperteacher</p>
<p>Let us recall the definition of the hyperteacher in Equation 1 with M modules, I input neurons, H hidden neurons and O output neurons,
(x, z) → Ω ReLU M m=1 I i=1 Θ m,i z m x i ,
where {Θ m ∈ R I×H } M m=1 are the modules, Ω ∈ R H×O is a readout projection and z ∈ [0, 1] M are the task constituents.We are restating Theorem 3.1 here for convenience.Theorem 3.1.Let Θ m ∈ R I×H be a sequence of uniformly bounded matrices.Then, for any M ∈ N, ε &gt; 0, and on any compact input set, X × Z with Z = {z : ∥z∥ 1 ≤ 1}, there exists a ReLU multilayer perceptron that approximates a hyperteacher to within ε error in the ∥ • ∥ ∞ norm using
O 1 √ ε + M neurons.
Proof.We will prove the statement, by providing an explicit construction of a ReLU multilayer perceptron that approximates a hyperteacher.The construction relies on two key lemmas: in Lemma A.2, we show that the square function can be approximated in a ReLU multilayer perceptron, which we use in Lemma A.3 to show how the multiplication of two numbers can be approximated.Based on these building blocks, we then provide the construction of the full hyperteacher approximation.</p>
<p>Lemma A.2.For any ε &gt; 0, there exists a ReLU multilayer perceptron that approximates
square := [0, 1] → R x → x 2
to within ε error in the ∥ • ∥ ∞ norm using O(1/ε 2 ) neurons.</p>
<p>Proof.Let us first consider how any function f can be approximated by a piecewise linear function L matching f on x i := i n for i ∈ {0, 1, . . ., n}, where n is a fixed integer.We define
L : x → f (0) + i f (x i+1 ) − f (x i ) x i+1 − x i ReLU(x − x i ) − f (x i ) − f (x i−1 ) x i − x i−1 ReLU(x − x i−1 )
where
f (x0)−f (x−1) x0−x−1
is set to 0 by convention.</p>
<p>It can easily be verified that L is linear on any interval [x i , x i+1 ] for i ∈ {0, 1, . . ., n}, and coincides with f on i n , i ∈ {0, 1, . . ., n} .We now want to bound ∥f − L∥ ∞ .While more general results can be shown for f ∈ C 2 , for f = square we can derive our result in the following simple way: for any x on any interval [x i , x i+1 ],
L(x) = f (x i+1 ) − f (x i ) x i+1 − x i (x − x i ) + f (x i ) so |L(x) − f (x)| = x 2 i+1 − x 2 i x i+1 − x i (x − x i ) + x 2 i − x 2 = (x − x i )(x i+1 − x) ≤ ε for n ≥ 1/ √ ε
An immediate corollary is that this result holds on any fixed bounded set.We now show how to multiply two numbers using a ReLU multilayer perceptron:</p>
<p>Lemma A.3.For any ε &gt; 0, there exists a ReLU multilayer perceptron that approximates
multiply := [0, 1] 2 → R (x, y) → xy to within ε error in the ∥ • ∥ ∞ norm using O(1/ε 2 ) neurons.
Proof.Using the polarization identity xy = (x+y) 2 −(x−y) 2</p>
<p>4</p>
<p>, we can approximate multiply(x, y) with a ReLU multilayer perceptron as follows:</p>
<p>(x, y) → (x + y, x − y) → ((x + y) 2 , (x − y) 2 ) → xy Again, this result holds on any fixed bounded set.</p>
<p>We can now state a construction for a multilayer perceptron that approximates the preactivation of the hyperteacher, namely (x, z) → M m=1 I i=1 Θ m,i z m x i using a linear number of neurons in the number of task modules.</p>
<p>Lemma A.4.Let Θ m ∈ R I×H be a sequence of uniformly bounded matrices.Then, for any M ∈ N, ε &gt; 0, and on any compact input set, X × Z with Z = {z : ∥z∥ 1 ≤ 1}, there exists a ReLU multilayer perceptron that approximates (x, z) →
M m=1 I i=1 Θ m,i z m x i to within ε error in the ∥ • ∥ ∞ norm using O 1 √ ε + M neurons.
Proof.We construct our multilayer perceptron layer by layer, tracking the number of neurons required for each layer and the error it incurs in the approximation:</p>
<p>• The first layer copies the input x and computes (x, z) → ( M m=1 z m Θ m,i,h ) i,h for each i ∈ {1, . . ., I} and h ∈ {1, . . ., O}, canceling the ReLUs by adjusting the biases accordingly given that the input is bounded.This requires O(M ) neurons.</p>
<p>• Using Lemma A.3 with error ε I , the next three layers multiply M m=1 z m Θ m,i,h by x i for each i ∈ {1, . . ., I} and h ∈ {1, . . ., O}, using O(1/ √ ε) neurons.</p>
<p>• The next layer sums over i for each h ∈ {1, . . ., O}, again canceling the ReLU nonlinearity by adjusting the biases.This requires M neurons and incurs a final error of at most ε since each output neuron sums the error coming from I neurons.</p>
<p>In total, this construction uses
O(M ) + O 1 √ ε + O(M ) = O 1 √ ε + M neurons.
Since ReLU is a contracting function, the output error after applying the ReLU activation is also ε.Finally, we can straightforwardly apply the output projection Ω using a constant number of neurons, scaling the error by a constant.</p>
<p>A.2.2 Multilayer hyperteacher</p>
<p>We now consider a multilayer hyperteacher, where a linear hypernetwork configures a multilayer perceptron with L layers, H l neurons for layer l, H 0 = I input neurons and H L = O output neurons.</p>
<p>In this case, we have C(z) := Ωh L , a sequence of hidden layers,
h l+1 = ReLU M m=1 z m Θ l,m =:W l (z) h l ,
with input h 0 = x, a sequence of modules for each layer, Θ l,m ∈ R H l ×H l+1 l=1,...,L m=1,...,M</p>
<p>, and output
projection Ω ∈ R H L−1 ×O .
Theorem A.5.Let Θ l,m ∈ R H l ×H l+1 be a sequence of uniformly bounded matrices.Then, for any M ∈ N, ε &gt; 0, fixed L and on any compact input set, X × Z with Z = {z : ∥z∥ 1 ≤ 1}, there exists a ReLU multilayer perceptron that approximates an L-layer hyperteacher to within
ε error in the ∥ • ∥ ∞ norm using O 1 √ ε + M neurons.
Proof.First, observe that we can copy the task constituents z to each layer using M neurons per layer.Because of this, we will assume that we have access to the task constituents at each layer.The proof then follows a similar approach to the proof of the single layer case of Theorem 3.1 but we must now consider how the error propagates through each layer.For the sake of simplicity, we will ignore the readout projection (i.e.assume Ω = I), since this part of the proof is identical.</p>
<p>We prove by induction on the number of layers L that we can approximate h L to within ε error in the ∥ • ∥ ∞ norm with O 1 √ ε + M neurons.The base case for L = 0 holds by definition, i.e. h 0 = x.Now, assume the result holds for an L-layer hyperteacher.Let ε &gt; 0 and X , Z be compact sets with Z = {z : ∥z∥ 1 ≤ 1}.By the induction hypothesis, let ĥL be a multilayer perceptron that approximates h L on the compact set X × Z, up to error ε in the ∥ • ∥ ∞ norm.By Lemma A.4, let g be a multilayer perceptron that approximates (x, z) → M m=1 z m Θ L+1,m x on Bε ×Z, where Bε is the closed ε-ball around ĥL (X ×Z).Since the image of a compact set formed by a continuous map is compact and the closed epsilon ball around a compact set in a finite-dimensional space is compact, Bε is also a compact set.</p>
<p>Let us now show that (x, z) → ReLU g( ĥL (x, z), z) approximates h L+1 on X × Z up to error O(ε).We define ∆ L := ĥL (x, z) − h L for L layers.Then, for L + 1 layers it holds that,
∥∆ L+1 ∥ ∞ = ∥ReLU(g(h L + ∆ L , z)) − h L+1 ∥ ∞ = ∥g(h L + ∆ L , z) − W L (z)h L ∥ ∞ (since ReLU is contracting) = ∥g(h L + ∆ L , z) − W L (z)(h L + ∆ L ) + W L (z)∆ L ∥ ∞ ≤ ∥g(h L + ∆ L , z) − W L (z)(h L + ∆ L )∥ ∞ + ∥W L (z)∥ ∞→∞ ∥∆ L ∥ ∞ = ε + O(ε) = O(ε),
where ∥ • ∥ ∞→∞ is the operator norm induced by the ∥ • ∥ ∞ norm.The final error can be reduced to be at most ε by adjusting the number of neurons by a constant factor.Proof.Let X, Z, R be independent random variables sampled according to their respective distributions.We define the event made of the set of pairs of task constituents z and seeds r such that the accuracy is higher than 1 − √ δ:
A := E [1{g(φ(Z, R), X) = C(Z)(X)}|Z, R] ≥ 1 − √ δ = (z, r) ∈ Z × N | P[g(φ(z, r), X) = C(z)(X)] ≥ 1 − √ δ
where the expectation is taken over X.By Markov's inequality, and the first assumption, this set can't be too small.Indeed,
P[¬A] &lt; E [1{g(φ(Z, R), X) ̸ = C(Z)(X)}] √ δ by Markov's inequality &lt; √ δ by</p>
<p>the first assumption</p>
<p>We now show that for all (z, r),
(z ′ , r ′ ) ∈ A ⊂ Z × N φ(z, r) = φ(z ′ , r ′ ) =⇒ z = z ′ . Indeed, let (z, r), (z ′ , r ′ ) ∈ A ⊂ Z × N, with ẑ := φ(z, r) = φ(z ′ , r ′ ).
We have, by definition of A,
P[g(ẑ, X) = C(z)(X)] ≥ 1 − √ δ P[g(ẑ, X) = C(z ′ )(X)] ≥ 1 − √ δ
so by union-bound, it holds
P[C(z)(X) = C(z ′ )(X)] ≥ 1 − 2 √ δ
which is only possible if z = z ′ given the second assumption.</p>
<p>We now define ϕ :
   Z ′ → Z ẑ → z for any (z, r) ∈ φ −1 (ẑ) if ẑ ∈ φ(A) ẑ → 0 otherwise
ϕ is uniquely defined because of the previous property.</p>
<p>We have
P[ϕ(φ(Z, R)) = Z] ≥ P[(Z, R) ∈ A] ≥ 1 − √ δ
which proves our statement.</p>
<p>B Additional results</p>
<p>B.1 Compositional generalization on the preference grid</p>
<p>The findings in Section 3 and Section 4.1 focus on the hyperteacher task family.In the following, we show that all findings can be reproduced on the compositional preference family introduced by [18].</p>
<p>In Figure 7 we show, that scaling data and model size leads to compositional generalization on the compositional preference task family.This holds for various linear and nonlinear task encodings as further shown in Table 2. Note, that we are not able to evaluate the fewshot task encoding of the main text since the resulting input dimension is prohibitively large.Figure 8 shows that noncompositional and disconnected task support as well as rarely encountering a few modules interferes with compositional generalization.And finally, Figure 9 demonstrates that also on the compositional preference task family, compositional generalization and linear decodability of the task constituents from the hidden activations of the model are correlated.</p>
<p>Table 2: Compositional generalization emerges across task encodings.Comparison of the decodability of the task constituents from the hidden activations (Task decoder) and compositional generalization performance for linear and nonlinear task encodings on the compositional preference task family with M = 16, K = 3.For the linear Identity, Orthogonal and Language task encoding, we report the decodability of task constituents from the first layer whereas for the nonlinear Invertible NN (with 2 layers) and Interval shuffle encodings we report it for the second layer.As opposed to linear task encodings, for nonlinear task encodings the decodability of task constituents is higher in the second layer compared to the first layer suggesting that the first layer is used to linearize the task constituents.We additionally show the linear decodability of the task constituents directly from the task encoding itself (Input decoder), which allows to distinguish linear from nonlinear task encodings.± SEM over three seeds.</p>
<p>B.2 Scaling data leads to compositional generalization in transformers</p>
<p>In addition to using multilayer perceptrons as done in the main text, we investigate whether the widely used transformer architecture similarly achieves compositional generalization through scale.For this purpose, we train a decoder-only transformer that takes a sequence consisting of the task constituents followed by the task inputs as input and predicts the corresponding labels.Given that the transformer contains multilayer perceptrons in the feedforward blocks, we expect it to be similarly capable of compositional generalization at scale.The top of Figure 10 confirms this, showing that scaling data similarly leads to compositional generalization in transformers.Compared to the multilayer perceptron, the transformer requires less    distinct training tasks to achieve compositional generalization, as can be observed at the bottom of Figure 10.</p>
<p>B.3 Scaling data leads to compositional generalization in a deep hyperteacher</p>
<p>In the main text, we focus on a hyperteacher with a task network with a single hidden layer.A natural question is how increasing the difficulty of the hyperteacher by equipping the task network with multiple hidden layers affects our results.For this purpose, we reproduce the data scaling plot shown in Figure 2 of Section 3 for a hyperteacher with three hidden layers, each with 16 hidden neurons.Figure 11 demonstrates that while this makes the task noticeably more difficult, it reproduces our finding that scaling data leads to compositional generalization.</p>
<p>B.4 Difficulty of image composition task family</p>
<p>To complement Figure 6 of the main text, Figure 12 shows the task difficulty as well as the average linear decodability of the task constituents from the hidden activations for all the image composition task families and text-to-image generation models we consider.</p>
<p>C Experimental details C.1 Task families</p>
<p>We create the hyperteacher task family described in Section 2.4 with I = 16 input neurons, H = 16 hidden neurons and O = 16 output neurons to create a family of compositional regression tasks to be learned by a student.We sample teacher modules from a truncated normal distribution with zero mean and standard deviation √ 3</p>
<p>I .Each teacher module also has a bias term that is sampled from the uniform distribution over the interval [0, 0.5].We sample the fixed readout matrix shared by all tasks from a truncated normal distribution with zero mean and standard deviation √ 3</p>
<p>H .These values have been picked as to ensure that the hyperteacher creates tasks of sufficient diversity and difficulty.</p>
<p>For the definition of the compositional preference task family, please refer to [18].Following the notation of the hyperteacher, we denote the number of possible preferences as M and the maximum number of preferences combined into a task as K. [18] uses M = 8 number of possible preferences throughout.We increase the difficulty of the tasks by increasing the number of preference features to M = 16 in Figure 7 bottom, Figure 8 and Figure 9 and to M = 32 in Figure 7 top.</p>
<p>C.2 Task encoding</p>
<p>We employ the invertible neural network introduced by [72] with 5 layers (3 for the compositional preference task family) that consists of a series of bijective transformations, to obtain a nonlinear but information-preserving encoding of the task constituents.In addition, we use the Interval Shift function defined in Algorithm 1 as another example of a nonlinear but bijective task encoding.We investigate the effect of various procedures to construct the training task support on compositional generalization, which we describe in the following.For this purpose, consider the graph G = (V, E) where V = {z ∈ Z | p train (z) &gt; 0} is the set of vertices and
E = {(z, z ′ ) ∈ V × V | ∃i ∈ {1, 2, . . . , K} such that z i = z ′ i } is the set of edges.
• Random: Samples a random subset of vertices until a graph that is both compositional and connected is found.</p>
<p>• Balanced: Similar to Random, but ensures that each module appears with equal frequency in the training distribution using a greedy search over vertices.</p>
<p>• Non-compositional: Holds out all tasks that contain one random but fixed module.</p>
<p>• Disconnected: Divides modules into two disjoint subsets and only uses vertices that use modules from either subset but do not contain modules from both subsets.</p>
<p>• Popular modules: Defines a set of P popular modules and only includes vertices that contain at least one popular module.P is determined such that the fraction of held-out tasks can be satisfied as specified.If it cannot be exactly satisfied, one module that is not in the set of popular modules receives additional vertices.Additionally ensures that the resulting set is compositional and connected.</p>
<p>• Unpopular modules: Defines a set of U unpopular modules and includes all vertices that do not contain any unpopular module.For each unpopular module, one vertex that includes the unpopular module and otherwise only not unpopular modules is added.U is determined such that the fraction of held-out tasks can be satisfied as specified.If it cannot be exactly satisfied, one unpopular module receives additional vertices.Additionally ensures that the resulting set is compositional and connected.</p>
<p>C.4 Task constituent decoding</p>
<p>On the hyperteacher and compositional preference task family, we fit a linear decoder using ridge regression to predict the task constituents given the hidden activations of a particular layer of the multilayer perceptron solving the task.For this purpose, we train on pairs of hidden activations and ground truth task constituents from the training distribution, p train (z), and evaluate the performance of the decoder on held-out tasks, reporting the coefficient of determination (R 2 score).Throughout, we employ a regularizer of λ = 1.0 for the ridge regression.</p>
<p>C.5 Architecture</p>
<p>Unless specified otherwise, we use a multilayer perceptron with four hidden layers with 1024 hidden neurons each for the hyperteacher and with two hidden layers for the compositional preference task family.</p>
<p>The transformer in Section B is causally masked and consists of 4 layers with 4 attention heads, a model dimension of 256, a feedforward dimension of 1024 and separate projection matrices for the task constituents, inputs and the output.</p>
<p>C.6 Hyperparameters</p>
<p>Throughout our experiments, we use the AdamW optimizer [73] with a batch size of 128.On the hyperteacher task family, we use a mean-squared error loss, on the compositional preference task family, we use a cross-entropy loss.We performed an initial grid search over the learning rate and weight decay to find a common set of hyperparameters for all experiments on the hyperteacher task family and a common set of hyperparameters for all experiments on the compositional preference tasks respectively.We report the search grid in Table 3. Experimental setup In the following, we describe the experimental setup illustrated in Figure 6.</p>
<p>For each image composition task family listed below, we prompt each model on all possible image combinations to generate an image using 40 inference steps.During this process, we collect their hidden activations to be used by the image constituent decoder (see below).We then prompt a VLM to judge whether the image constituents have been correctly combined into a coherent image by asking it to readout the image constituents given the image and the full set of possible constituents.We count an image generation as successful if the image constituents generated by the VLM exhaustively match the ground truth constituents.Here, we report results using Gemini 2.0 Flash [77] as the judge.</p>
<p>Image constituent decoder We train standard logistic regression classifiers to predict image constituents given the hidden activations of the text-to-image generation models and report their F1 scores on held-out image compositions.Not all layers of the respective models contain this information and we need to carefully choose layers depending on the model architecture.In particular, the image constituents can trivially be linearly decoded from early layers of the model that encode the text prompt, as well as any layers that are directly connected to the text encoding either via residual connections or via cross-attention.For this reason, we select layers that require the model to explicitly learn to pass information about image constituents to.In the transformer-based models FLUX.1-dev,SD 3.5 medium and SD 3.0 medium, we probe the hidden activation of the penultimate transformer block's MLP.SD XL base 1.0 contains a bottleneck block, so we probe the hidden activations at the final layer of the bottleneck.Since the models we are considering are diffusion models that run inference over several time steps, we must specify at what time during the inference process to collect the hidden activations.In our experiments, we run 30 inference steps and collect hidden activations at time steps 9, 15, 21, and 30, as well as the average hidden activation over all time steps.We concatenate all hidden activations for a given model and image and use them as the input to the linear decoder.</p>
<p>Image composition task families</p>
<p>We create a variety of image composition task families that each consist of a combinatorial space of objects and attributes that need to be combined into a coherent image.Specifically, each task has the following structure with a corresponding prompt template:</p>
<p>• task_name: Prompt template specifying how to compose {component1} and {component2}.</p>
<p>-component1: module1, module2, ... -component2: module1, module2, ... We list all the tasks in the following: -food_top: burger, pizza, salad, Sushi, taco, donut, Ice cream, pancake, Spaghetti, sandwich -food_middle: burger, pizza, salad, sushi, taco, donut, ice cream, pancake, spaghetti, sandwich -food_bottom: burger, pizza, salad, sushi, taco, donut, ice cream, pancake, spaghetti, sandwich</p>
<p>• stacked_animals: {animal_top} on top of {animal_middle} on top of {animal_bottom} -animal_top: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_middle: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_bottom: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger</p>
<p>• animals_chasing_chain: {animal1} chasing {animal2} chasing {animal3} -animal1: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal2: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal3: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger</p>
<p>• nested_containment: A {container1} containing a {container2} containing a {object} -container1: transparent cube, glass jar, wooden box, metal safe, woven basket, leather bag, ceramic pot, copper kettle, crystal sphere, rubber ball -container2: small treasure chest, porcelain teacup, silk pouch, stone bowl, paper envelope, cardboard tube, tin can, shell, gold locket, velvet case -object: diamond, living butterfly, ticking clock, miniature planet, flickering flame, drop of mercury, hologram, glowing ember, snowflake, single cell organism • impossible_materials: A {object} made entirely of {material} sitting on a {surface} -object: chair, bicycle, bookshelf, piano, computer, refrigerator, watch, umbrella, camera, guitar -material: liquid water, fire, smoke, mirrors, ice, tree bark, glass noodles, gelatin, paper, soap bubbles -surface: clouds, ocean waves, melting ice, sand dunes, moss, broken glass, spiderwebs, lily pads, autumn leaves, foam • three_animals_three_fixed_styles: A {animal_pixel} in pixel art, a {animal_oil} in oil painting, and a {animal_cartoon} in cartoon style -animal_pixel: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_oil: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_cartoon: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger</p>
<p>• three_animals_three_fixed_descriptors: A {animal_furry} with fur, a {animal_scaly} with scales, and a {animal_feathered} with feathers -animal_furry: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_scaly: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_feathered: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger</p>
<p>• animals_long: An image with {one {animal}} 1,2,3 -animals: giraffe, lion, elephant, crocodile, bear, snake, eagle, cow, zebra, tiger, rhino, hippo, wolf, fox, deer, monkey, panda, koala, kangaroo, penguin • objects_three_colours: An image with {one {object}} 1,2,3  -objects: red cube, green cube, blue cube, blue sphere, orange sphere, red sphere, green cylinder, purple cylinder, yellow cylinder, yellow cone, blue cone, green cone, purple pyramid, red pyramid, orange pyramid, orange cuboid, yellow cuboid, blue cuboid • fruits_veggies_long: An image with {one {fruit_veggie}} 1,2,3  -fruits_veggies: apple, banana, orange, grape, strawberry, watermelon, pineapple, mango, blueberry, peach, lemon, cherry, carrot, broccoli, tomato, cucumber, potato, onion, pepper, lettuce • animals_vegetables_shapes: An image with {one {element}} 1,2,3  -animals_vegetables_shapes: lion, elephant, giraffe, tiger, bear, zebra, monkey, carrot, broccoli, potato, tomato, cucumber, onion, pepper, cube, sphere, cylinder, cone, pyramid, triangular prism</p>
<p>D Additional details D.1 Compute resources</p>
<p>We used a Linux workstation with two Nvidia RTX 3090 GPUs with 24GB of memory each for development and conducted hyperparameter searches and experiments on an internal Slurm cluster using Nvidia RTX 4090 GPUs and Nvidia A100 GPUs.</p>
<p>A single run of a hyperteacher experiment takes 4-10 minutes on a RTX 4090 depending on model size, a single run of a compositional preference experiment takes 50-100 minutes.In total, reproducing all experiments reported for the hyperteacher task family with around 1000 distinct runs takes about 7 GPU days and reproducing all corresponding experiments for the compositional preference task family takes about 70 GPU days.</p>
<p>Generating the images for one of the image composition task families takes 8 GPU hours on an A100 for the Flux.1-devmodel and 4 GPU hours on an RTX 4090 for each of the SD models.Running all 27 tasks for all models takes a total of 23 GPU days.</p>
<p>D.2 Software and libraries</p>
<p>For the results obtained in this paper we built on free and open-source software.We implemented our experiments in Python using JAX [</p>
<p>Figure 1 :
1
Figure1: Scaling can lead to compositional generalization.We consider compositional task families that compose K out of M modules into tasks, each of which is modeled as a function.This gives rise to an exponential number of O(M K ) tasks.We train standard feedforward networks on a subset of tasks and evaluate compositional generalization on held-out tasks.We find that scaling the size of the model and the data leads to compositional generalization.</p>
<p>Figure 2 :
2
Figure2: Scaling data and model size leads to compositional generalization.Top-left Scaling the number of training tasks by increasing the number of modules, task components or decreasing the fraction of tasks held-out from training leads to compositional generalization on the hyperteacher task family.Top-right The number of training tasks required to achieve compositional generalization, here defined as a R 2 &gt; 0.95, scales sub-exponentially as the number of total tasks in the task family grows.Bottom Scaling model size by increasing the number of hidden neurons and the number of hidden layers leads to compositional generalization on the hyperteacher across different task encodings.Error bars denote SEM over three seeds.</p>
<p>Figure 4 :
4
Figure 4: The support of the training distribution needs to sufficiently cover the task space.: Left Illustration of the different types of task support for the special case of a compositional task family with two components.Turquoise tiles denote module combinations that are part of the training distribution, red tiles are reserved for evaluation.Right Compositional generalization as a function of the different types of task support on the hyperteacher for M = 16 and K = 3.</p>
<p>Figure 5 :
5
Figure 5: Compositional generalization correlates with linear decodability of task constituents.Top Relationship between linear decodability of the task constituents and compositional generalization across hyperteachers with M = 8 modules and varying K. Bottom Relationship between linear decodability of the task constituents and compositional generalization across different task encodings for varying model sizes on the hyperteacher with M = 16, K = 3. Error bars denote SEM over three seeds.Top/Bottom We report the R 2 and corresponding p-value for an ordinary least square estimator in the facet titles.</p>
<p>animals_with_food_eyes_and_clothesFigure 6 :
6
Figure6: Task constituents can be linearly decoded when image composition succeeds.Top Example tasks to test compositionality of image generation models as well as an overview of the pipeline used to decode task constituents and judge model outputs.Bottom Relationship between average constituent decodability and image generation success rate across image composition task families for four different image generation models.We report the R 2 and corresponding p-value for an ordinary least square estimator in the facet titles.model's hidden activations.The full pipeline is shown in the top-right of Figure6.Please refer to Appendix C.7 for further details.The results of this analysis are shown at the bottom of Figure6.We observe a clear correlation between the average task constituent decodability and the average generation success rate across models, with the relative task difficulty being similar across models, as shown in Figure12of the Appendix.This provides evidence that models which succeed at systematically composing known concepts into scenes form an internal representation of the task constituents.</p>
<p>Finally</p>
<p>, let us bound the number of neurons required for the full construction.We used O(M ) neurons for copying z to each layer, O 1 √ ε + M neurons for the construction of ĥL , and O 1 √ ε + M neurons for the construction of g, which sums up to O 1 √ ε + M neurons.A.3 Proof of Theorem 4.1</p>
<p>Figure 7 :Figure 8 :
78
Figure 7: Scaling data and model size leads to compositional generalization.Top Scaling the number of training tasks by increasing the number of modules, task components or decreasing the fraction of tasks held-out from training leads to compositional generalization on the compositional preference task family.Bottom Scaling model size by increasing the number of hidden neurons or the number of hidden layers leads to compositional generalization on the compositional preference task family across different task encodings.Error bars denote SEM over three seeds.</p>
<p>Figure 9 :
9
Figure 9: Compositional generalization correlates with linear decodability of task constituents.Top Relationship between linear decodability of the task constituents and compositional generalization across instantiations of the compositional preference task family with M = 8 preferences and varying K. Bottom Relationship between linear decodability of the task constituents and compositional generalization across different task encodings for varying model sizes on the compositional preference task family with M = 16, K = 3. Error bars denote SEM over three seeds.Top/Bottom We report the R 2 and corresponding p-value for an ordinary least square estimator in the facet titles.</p>
<p>Figure 10 :
10
Figure 10: Scaling data leads to compositional generalization in transformers.Top Scaling the number of training tasks by increasing the number of modules, task components or decreasing the fraction of tasks held-out from training leads to compositional generalization in transformers on the hyperteacher task family.Bottom Transformers require less training tasks to achieve compositional generalization (R 2 &gt; 0.95) compared to multilayer perceptrons (MLP).</p>
<p>Figure 11 :
11
Figure 11: Scaling data leads to compositional generalization on a deep hyperteacher.Scaling the number of training tasks by increasing the number of modules, task components or decreasing the fraction of tasks held-out from training leads to compositional generalization on the hyperteacher task family with a deep task network with three hidden layers.</p>
<p>Figure 12 :
12
Figure 12: Image composition task difficulties sorted by linear decodability of task constituents.Left Average image generation success for each image composition task family for different text-toimage generation models.Left Average linear decodability of constituents from hidden activations for each image composition task family for different text-to-image generation models.</p>
<p>Algorithm 1 Shift 1 :▷
11
Interval Number of intervals: N 2: function φ(z, r) Preserve relative position within new interval 8: end function C.3 Training task support</p>
<p>Table 1 :
1
and Table 1 (also see Table 2 in the appendix for corresponding results on the compositional preference task Compositional generalization emerges across task encodings.
Identity</p>
<p>Table 3 :
3
Hyperparameters for experiments on the hyperteacher task family and compositional preference task family.Lists of values denote parameters explored via grid search with a bold number indicating the value found to perform best and used throughout the experiments.Compositional text-to-image generation Models We compare four open-weight text-to-image generation models: FLUX.1-dev [29, FLUX.1 dev Non-Commercial License], SD XL base 1.0 [74, Open RAIL++-M License], SD 3.0 medium [75, Stability AI Community License] SD 3.5 medium [76, Stability AI Community License].
ParameterHyperteacherCompositional preferenceslearning_rate [0.001, 0.003, 0.0001, 0.0003] [0.001, 0.003, 0.0001, 0.0003]weight_decay[0.003, 0.001, 0.0003][0.003, 0.001, 0.0003]C.7</p>
<p>• animals_with_colours: A {colour} {animal} -animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -colour: red, blue, green, yellow, orange, purple, pink, brown, black, white • animals_with_style: A {animal} illustrated in {style} style A sad {animal_happy}, a happy {animal_sad}, and an angry {animal_angry} -animal_happy: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_sad: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_angry: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger • animals_with_clothes: {animal} wearing {clothing} -animal: cat, dog, bear, lion, elephant, giraffe, monkey, zebra, tiger, panda -clothing: hat, pair of sunglasses, scarf, bowtie, jacket, crown, tie, cape, sweater, necklace • animals_with_clothes_and_food: {animal} wearing {clothing} eating {food} -animal: cat, dog, bear, lion, elephant, giraffe, monkey, zebra, tiger, panda -clothing: hat, pair of sunglasses, scarf, bowtie, jacket, crown, tie, cape, pair of pants, pair of boots -food: pizza, banana, ice cream, cake, hamburger, apple, watermelon, donut, sandwich, salad • animals_with_food_eyes_and_clothes: A {animal} with {food} as eyes wearing {clothing} -animal: cat, bear, lion, elephant, giraffe, monkey, zebra, panda, wolf, rabbit -food: strawberries, oranges, burgers, watermelons, donuts, cookies, cupcakes, pizza, lemons, tomatoes -clothing: crown, cowboy hat, scarf, cape, hawaiian shirt, leather jacket, pair of pants, tuxedo, raincoat, sunglasses • stacked_foods: {food_top} on top of {food_middle} on top of {food_bottom}
-animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-style: watercolor, pixel art, oil painting, sketch, cartoon, origami, stained glass, pop art, charcoal,clay sculpture• animals_with_locations: A {animal} in the {location}-animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-location: top left, top center, top right, middle left, center, middle right, bottom left, bottomcenter, bottom right• animals_with_descriptor: A {descriptor} {animal}-animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-descriptor: furry, scaly, feathered, leathery, smooth, wrinkled, young, old, three-legged, spottedfourteen,fifteen, sixteen, seventeen, eighteen, nineteen, twenty-object: tomatoes, onions, oranges, wolves, bears, apples, bananas, carrots, cucumbers, strawber-ries, lemons, cherries, grapes, peaches, pears, foxes, rabbits, cats, dogs, sheep• nested_containment_animals: A {animal_outer} containing a {animal_middle} containing an{animal_inner}-animal_outer: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-animal_middle: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-animal_inner: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger• three_animals_three_materials: {animal_fire} made of fire, {animal_ice} made of ice, and{animal_wood} made of wood-animal_fire: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-animal_ice: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger-animal_wood: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger
• animals_with_adjectives: A image of a {adjective} {animal} -adjective: happy, sad, angry, sleepy, curious, playful, scared, proud, surprised, bored -animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger • fruits_with_verbs: A {fruit} is {verb} -fruit: apple, banana, orange, grape, strawberry, watermelon, pineapple, mango, blueberry, peach -verb: dancing, flying, bouncing, sleeping, swimming, rolling, climbing, stretching, spinning, hiding• counting_animals: An image with exactly {number} {animal} -number: one, two, three, four, five, six, seven, eight, nine, ten -animal: lions, elephants, giraffes, crocodiles, bears, snakes, eagles, cows, zebras, tigers• animals_with_verbs: A {animal} is {verb} -animal: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -verb: eating, sleeping, running, jumping, flying, swimming, climbing, dancing, playing, hiding• counting_objects: An image with exactly {number} {object} -number: one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen,• three_animals_three_verbs: {animal_singing} singing, {animal_eating} eating, and {ani-mal_sleeping} sleeping -animal_singing: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_eating: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger -animal_sleeping: lion, elephant, giraffe, crocodile, bear, snake, eagle, cow, zebra, tiger• three_animals_three_adjectives:</p>
<p>78, Apache License 2.0], Flax [79, Apache License 2.0], the Deepmind Jax Ecosystem [80, Apache License 2.0], PyTorch [BSD-style license 81], LLM [82, Apache License 2.0] and Scikit-learn [83, BSD 3-Clause License].We utilized WandB [84, MIT license] to monitor the progress and results of experiments, and Plotly [85, MIT license] for generating the plots.We use uv for Python project dependency management [86, MIT License].</p>
<p>For the sake of simplicity, we are stating the definition slightly informally. For the asymptotic behavior over K used in condition (ii) to be defined, we are technically considering a family of compositional task families.
Code for image composition experiments available at https://github.com/florian-toll/ compgen-vision
Acknowledgments We would like to thank Seijin Kobayashi, Angelika Steger, Jack Brady and Brenden Lake for vital discussions and fruitful feedback.Simon Schug was supported by a Postdoc.Mobility grant (P500PT_225369) from the Swiss National Science Foundation.Appendix Table of Contents
Connectionism and cognitive architecture: A critical analysis. Jerry A Fodor, Zenon W Pylyshyn, 10.1016/0010-0277(88)90031-5Cognition. 281-2March 1988</p>
<p>Scaling Laws for Neural Language Models. Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, arXiv:2001.08361January 2020</p>
<p>Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS '20. the 34th International Conference on Neural Information Processing Systems, NIPS '20Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford; Red Hook, NY, USACurran Associates IncDecember 2020Ilya Sutskever, and Dario Amodei</p>
<p>Emergent Abilities of Large Language Models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus, Transactions on Machine Learning Research. 2835-88562022</p>
<p>Exploring the Limits of Weakly Supervised Pretraining. Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, Laurens Van Der Maaten, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)September 2018</p>
<p>Breaking Neural Network Scaling Laws with Modularity. Akhilan Boopathy, Sunshine Jiang, William Yue, Jaedong Hwang, Abhiram Iyer, Ila R Fiete, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. Relational inductive biases, deep learning, and graph networks. Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, arXiv:1806.01261October 2018cs, stat</p>
<p>Systematicity in a Recurrent Neural Network by Factorizing Syntax andSemantics. Jacob Russin, Randall C O'reilly, Jason Jo, Yoshua Bengio, Proceedings of the Annual Meeting of the Cognitive Science Society. the Annual Meeting of the Cognitive Science Society202042</p>
<p>Compositional Generative Modeling: A Single Model is Not All You Need. Yilun Du, Leslie Pack, Kaelbling , Forty-first International Conference on Machine Learning. 2024</p>
<p>On language': On the diversity of human language construction and its influence on the mental development of the human species. Wilhelm Von, Humboldt Humboldt, 1836Cambridge University Press</p>
<p>Aspects of the Theory of Syntax. Number 11. Noam Chomsky, 1965MIT press</p>
<p>Understanding Simplicity Bias towards Compositional Mappings via Learning Dynamics. Yi Ren, Danica J Sutherland, NeurIPS 2024 Workshop on Compositional Learning: Perspectives, Methods, and Paths Forward. 2024</p>
<p>Break It Down: Evidence for Structural Compositionality in Neural Networks. Michael Lepori, Thomas Serre, Ellie Pavlick, Advances in Neural Information Processing Systems. A Oh, T Naumann, A Globerson, K Saenko, M Hardt, S Levine, Curran Associates, Inc202336</p>
<p>A Complexity-Based Theory of Compositionality. Eric Elmoznino, Thomas Jiralerspong, Yoshua Bengio, Guillaume Lajoie, arXiv:2410.14817February 2025</p>
<p>An Introduction to Kolmogorov Complexity and Its Applications. Ming Li, Paul Vitányi, 10.1007/978-3-030-11298-12019SpringerChamTexts in Computer Science. 4th ed. 2019 edition</p>
<p>Meta-Learning &amp; Compositional Generalization in Neural Networks. Simon Schug, 2025ETH ZurichDoctoral Thesis</p>
<p>David Ha, Andrew M Dai, V Quoc, Le, Hypernetworks, International Conference on Learning Representations. 2017</p>
<p>Discovering modular solutions that generalize compositionally. Simon Schug, Seijin Kobayashi, Yassir Akram, Maciej Wolczyk, Alexandra Maria Proca, Razvan Johannes Von Oswald, Joao Pascanu, Angelika Sacramento, Steger, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Deep Learning is Not So Mysterious or Different. Andrew Gordon, Wilson , arXiv:2503.02113March 2025</p>
<p>Natural language instructions induce compositional generalization in networks of neurons. Reidar Riveland, Alexandre Pouget, 10.1038/s41593-024-01607-5Nature Neuroscience. 1546- 1726March 2024Nature Publishing Group</p>
<p>Compositional Generalization from First Principles. Thaddäus Wiedemer, Prasanna Mayilvahanan, Matthias Bethge, Wieland Brendel, November 2023</p>
<p>When does compositional structure yield compositional generalization? A kernel theory. Samuel Lippl, Kim Stachenfeld, October 2024</p>
<p>Attribute-Centric Compositional Text-to-Image Generation. Yuren Cong, Martin Renqiang Min, Li Erran Li, Bodo Rosenhahn, Michael Ying, Yang , arXiv:2301.01413January 2023</p>
<p>Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task. Maya Okawa, S Ekdeep, Robert Lubana, Hidenori Dick, Tanaka, Advances in Neural Information Processing Systems. A Oh, T Naumann, A Globerson, K Saenko, M Hardt, S Levine, Curran Associates, Inc202336</p>
<p>Lost in Latent Space: Examining failures of disentangled models at combinatorial generalisation. Milton Montero, Jeffrey Bowers, Rui Ponte Costa, Casimir Ludwig, Gaurav Malhotra, Advances in Neural Information Processing Systems. S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, A Oh, Curran Associates, Inc202235</p>
<p>When can transformers compositionally generalize in-context?. Seijin Kobayashi, Simon Schug, Yassir Akram, Florian Redhardt, Razvan Johannes Von Oswald, Guillaume Pascanu, João Lajoie, Sacramento, arXiv:2407.12275July 2024</p>
<p>Does CLIP Bind Concepts? Probing Compositionality in Large Image Models. Martha Lewis, Nihal Nayak, Peilin Yu, Jack Merullo, Qinan Yu, Stephen Bach, Ellie Pavlick, Findings of the Association for Computational Linguistics: EACL 2024. Yvette Graham, Matthew Purver, St. Julian's, MaltaAssociation for Computational LinguisticsMarch 2024</p>
<p>ConceptMix: A Compositional Image Generation Benchmark with Controllable Difficulty. Xindi Wu, Dingli Yu, Yangsibo Huang, Olga Russakovsky, Sanjeev Arora, November 2024</p>
<p>Black Forest Labs. black-forest-labs/FLUX.1-dev • Hugging Face. April 2025</p>
<p>Scaling Rectified Flow Transformers for High-Resolution Image Synthesis. Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, arXiv:2403.03206March 2024Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Robin Rombach</p>
<p>Constituency and the Language of Thought. Paul Smolensky, Connectionism, Meaning in Mind: Fodor and His Critics. M Barry, Georges Loewer, Rey, Blackwell1991</p>
<p>. Hadley Robert, Systematicity in connectionist language learning. Mind &amp; Language. 931994Wiley Online Library</p>
<p>Connectionism and the problem of systematicity. Steven Phillips, 1995University of QueenslandPhD Thesis</p>
<p>Tensor product variable binding and the representation of symbolic structures in connectionist systems. Paul Smolensky, 10.1016/0004-3702(90)90007-MArtificial Intelligence. 0004- 3702461November 1990</p>
<p>Neural Module Networks. Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)June 2016</p>
<p>On The Specialization of Neural Modules. Devon Jarvis, Richard Klein, Benjamin Rosman, Andrew M Saxe, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Provable Compositional Generalization for Object-Centric Learning. Thaddäus Wiedemer, Jack Brady, Alexander Panfilov, Attila Juhos, Matthias Bethge, Wieland Brendel, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Why Do Animals Need Shaping? A Theory of Task Composition and Curriculum Learning. Jin Hwa Lee, Stefano Sarao Mannelli, Andrew M Saxe, Proceedings of the 41st International Conference on Machine Learning. Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, Felix Berkenkamp, the 41st International Conference on Machine LearningPMLRJuly 2024235</p>
<p>Interaction Asymmetry: A General Principle for Learning Composable Abstractions. Jack Brady, Julius Von Kügelgen, Sebastien Lachapelle, Simon Buchholz, Thomas Kipf, Wieland Brendel, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. Francesco Cagnetta, Leonardo Petrini, Umberto M Tomasini, Alessandro Favero, Matthieu Wyart, 10.1103/PhysRevX.14.031001Physical Review X. 14331001July 2024American Physical Society</p>
<p>Training compute-optimal large language models. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego De Las, Lisa Anne Casas, Johannes Hendricks, Aidan Welbl, Tom Clark, Eric Hennigan, Katie Noland, George Millican, Bogdan Van Den Driessche, Aurelia Damoc, Simon Guy, Karen Osindero, Erich Simonyan, Oriol Elsen, Jack W Vinyals, Laurent Rae, Sifre, Proceedings of the 36th International Conference on Neural Information Processing Systems, NIPS '22. the 36th International Conference on Neural Information Processing Systems, NIPS '22Red Hook, NY, USACurran Associates IncNovember 2022</p>
<p>. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ambrose Slone, Ameet Rahane, Anantharaman S Iyer, Anders Johan Andreassen, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew M Dai, Andrew La, Andrew Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakaş, B Ryan Roberts, Bao Sheng Loe, Barret Zoph, Bart\lomiej Bojanowski, Batuhan Özyurt, Behnam Hedayatnia, Behnam Neyshabur, Benjamin Inden, Benno Stein, Berk Ekmekci, Bill Yuchen Lin, Blake Howald, Bryan Orinion, Cameron Diao, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar Ferri, Chandan Singh, Charles Rathkopf, Chenlin Meng, Chitta Baral, Chiyu Wu, Chris Callison-Burch, Christopher Waites, Christian Voigt, Christopher D Manning, Christopher Potts, Cindy Ramirez, Clara E Rivera, Clemencia Siro, Colin Raffel, Courtney Ashcraft, Cristina Garbacea, Damien Sileo, Dan Garrette, Dan Hendrycks, Dan Kilman, Dan Roth, C Daniel Freeman, Daniel Khashabi, Daniel Levy, Daniel Moseguí González, Danielle Perszyk, Danny Hernandez, Danqi Chen, Daphne Ippolito, Dar Gilboa, David Dohan, David Drakard, David Jurgens, Debajyoti Datta, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Derek Tam, Dieuwke Hupkes, Diganta Misra, Dilyar Buzan, Dimitri Coelho Mollo, Diyi Yang, Dong-Ho Lee, Dylan Schrader, Ekaterina Shutova, Ekin Dogus Cubuk, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Ellie Pavlick, Emanuele Rodolà, Emma Lam, Eric Chu, Eric Tang, Erkut Erdem, Ernie Chang, Ethan A Chi, Ethan Dyer, Ethan Jerzak, Ethan Kim, Eunice Engefu Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fatemeh Siar, Fernando Martínez-Plumed, Francesca Happé, Francois Chollet, Frieda Rong, Gaurav Mishra, Genta Indra Winata, Gerard De Melo, Germán Kruszewski, Giambattista Parascandolo, Giorgio Mariani, Gloria Xinyue Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Guy Gur-Ari, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hannaneh Hajishirzi, Harsh Mehta, Hayden Bogar, Henry Francis, Anthony Shevlin, Hinrich Schuetze, Hiromu Yakura, Hongming Zhang, Hugh Mee Wong, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, Jacob Hilton, Jaehoon Lee, Jaime Fernández Fisac, James B Simon, James Koppel, James Zheng, James Zou, Jan Kocon, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jascha Sohl-Dickstein, Jason Phang, Jason Wei, Jason Yosinski, Jekaterina Novikova, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesse Engel, Jesujoba Alabi, Jiacheng Xu, Jiaming Song, Jillian Tang, Joan Waweru, John Burden, John Miller, John U Balis, Jonathan Batchelder, Jonathan Berant, Jörg Frohberg, Jos Rozen, Jose Hernandez-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua B Tenenbaum, Joshua S Rule, Joyce Chua, Kamil Kanclerz, Karen Livescu, Karl Krauth, Karthik Gopalakrishnan, Katerina Ignatyeva, Katja Markert, Kaustubh Dhole, Kevin Gimpel, Kevin Omondi, Kory Wallace Mathewson, Kristen Chiafullo, Ksenia Shkaruta, Kumar Shridhar, Kyle Mcdonell, Kyle Richardson, Laria Reynolds, Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin, Lidia Contreras-Ochando, Louis-Philippe Morency, Luca Moschella, Lucas Lam, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros-Colón, Luke Metz, Lütfi Kerem Senel, Maarten Bosma, Maarten Sap, Maartje Ter Hoeve, Maheen Farooqi, Manaal Faruqui, Mantas Mazeika, Marco Baturan, Marco Marelli, Marco Maru, Maria Jose Ramirez-Quintana, Marie Tolkiehn, Mario Giulianelli, Martha Lewis, Martin Potthast, Matthew L Leavitt, Matthias Hagen, Mátyás Schubert, Medina Orduna Baitemirova, Melody Arnaud, Melvin Mcelrath, Michael Andrew Yee, Michael Cohen, Michael Gu, Michael Ivanitskiy, Michael Starritt, Michael Strube, Michal Swedrowski, Michele Bevilacqua, Michihiro Yasunaga, Mihir Kale, Mike Cain, Mimee Xu, Mirac Suzgun, Mitch Walker, Mo Tiwari, Mohit Bansal, Moin Aminnaseri, Mor Geva, Mozhdeh Gheini, Mukund Varma, T , Nanyun Peng, Nathan Andrew Chi, Nayeon Lee, Neta Gur-, Ari Krakover, ; Niveditha, S Iyer, Noah Constant, Noah Fiedel, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi ; Rylan, Sahib Yang, Saif M Singh, Sajant Mohammad, Sam Anand, Sam Dillavou, Sam Shleifer, Samuel Wiseman, Gruetter, R Samuel, Samuel Bowman, Sanghyun Stern Schoenholz, Sanjeev Han, Sarah A Kwatra, Sarik Rous, Sayan Ghazarian, Sean Ghosh, Sebastian Casey, Sebastian Bischoff, Sebastian Gehrmann, Sepideh Schuster, Shadi Sadeghi, Sharon Hamdan, Shashank Zhou, Sherry Srivastava, Shikhar Shi, Shima Singh, Asaadi, Shane Shixiang, Shubh Gu, Shubham Pachchigar, Shyam Toshniwal, Upadhyay, Shammie Shyamolima, Siamak Debnath, Simon Shakeri, Simone Thormeyer, Siva Melzi, Reddy, Priscilla Sneha, Soo-Hwan Makini, Spencer Lee, Sriharsha Torene, Stanislas Hatwar, Stefan Dehaene, Stefano Divic, Stella Ermon, Stephanie Biderman, Stephen Lin, Steven Prasad, Stuart Piantadosi, Summer Shieber, Svetlana Misherghi, Swaroop Kiritchenko, Tal Mishra, Tal Linzen, Tao Schuster, Tao Li, Tariq Yu, Tatsunori Ali, Hashimoto ; Xinran, Xinyi Zhao, Xudong Wu, Yadollah Shen, Yair Yaghoobzadeh, Yasaman Lakretz, Yejin Bahri, Yichi Choi, Yiding Yang, Yifu Hao, Yonatan Chen, Yu Belinkov, Yufang Hou, Yuntao Hou, Zachary Bai, Zhuoye Seid, Zijian Zhao, Zijie J Wang, Zirui Wang, Ziyi Wang, Wu, Transactions on Machine Learning Research. Trishala Neeraj, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Vera Demberg, Victoria Nyamai2835-88562023Vinay Venkatesh RamaseshNitish Shirish Keskar</p>
<p>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, Ed H Chi, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Compositional generalization in semantic parsing with pretrained transformers. A Emin Orhan, arXiv:2109.15101December 2022</p>
<p>Compositional Generalization in Semantic Parsing: Pre-training vs. Specialized Architectures. Daniel Furrer, Nathan Marc Van Zee, Nathanael Scales, Schärli, arXiv:2007.08970September 2021</p>
<p>The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers. Róbert Csordás, Kazuki Irie, Juergen Schmidhuber, 10.18653/v1/2021.emnlp-main.49Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational Linguistics2021Online and Punta Cana</p>
<p>Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing. Linlu Qiu, Peter Shaw, Panupong Pasupat, Tianze Shi, Jonathan Herzig, Emily Pitler, Fei Sha, Kristina Toutanova, 10.18653/v1/2022.emnlp-main.624Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Yoav Goldberg, Zornitsa Kozareva, Yue Zhang, the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>The Impact of Depth on Compositional Generalization in Transformer Language Models. Jackson Petty, Sjoerd Steenkiste, Ishita Dasgupta, Fei Sha, Dan Garrette, Tal Linzen, 10.18653/v1/2024.naacl-long.402Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. Kevin Duh, Helena Gomez, Steven Bethard, the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMexico City, MexicoAssociation for Computational LinguisticsJune 20241</p>
<p>Faith and Fate: Limits of Transformers on Compositionality. Nouha Dziri, Ximing Lu, Melanie Sclar, Lorraine Xiang, Liwei Li, Bill Yuchen Jiang, Peter Lin, Chandra West, Bhagavatula, Le Ronan, Jena D Bras, Soumya Hwang, Sean Sanyal, Xiang Welleck, Allyson Ren, Zaid Ettinger, Yejin Harchaoui, Choi, arXiv:2305.18654June 2023</p>
<p>Measuring and Narrowing the Compositionality Gap in Language Models. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, Mike Lewis, arXiv:2210.03350May 2023</p>
<p>Not All LLM Reasoners Are Created Equal. Arian Hosseini, Alessandro Sordoni, Daniel Kenji Toyama, Aaron Courville, Rishabh Agarwal, The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24. 2024</p>
<p>Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability. Zhuoyan Xu, Zhenmei Shi, Yingyu Liang, ICLR 2024 Workshop on Mathematical and Empirical Understanding of Foundation Models. 2024</p>
<p>GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models. Keivan Seyed Iman Mirzadeh, Hooman Alizadeh, Shahrokhi, The Thirteenth International Conference on Learning Representations. 2025Oncel Tuzel, Samy Bengio, and Mehrdad Farajtabar</p>
<p>Grokking of Implicit Reasoning in Transformers: A Mechanistic Journey to the Edge of Generalization. Boshi Wang, Xiang Yue, Yu Su, Huan Sun, Advances in Neural Information Processing Systems. A Globerson, L Mackey, D Belgrave, A Fan, U Paquet, J Tomczak, C Zhang, Curran Associates, Inc202437</p>
<p>Do Large Language Models Latently Perform Multi-Hop Reasoning?. Sohee Yang, Elena Gribovskaya, Nora Kassner, Mor Geva, Sebastian Riedel, 10.18653/v1/2024.acl-long.550Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. Lun-Wei Ku, Andre Martins, Vivek Srikumar, the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, ThailandAssociation for Computational LinguisticsAugust 20241</p>
<p>The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A. Lukas Berglund, Meg Tong, Maximilian Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans, The Twelfth International Conference on Learning Representations. 2024</p>
<p>How Do Language Models Compose Functions?. Apoorv Khandelwal, Ellie Pavlick, arXiv:2510.01685October 2025</p>
<p>Human-like systematic generalization through a meta-learning neural network. M Brenden, Marco Lake, Baroni, 10.1038/s41586-023-06668-3Nature. 1476- 46876237985November 2023Nature Publishing Group</p>
<p>Attention as a Hypernetwork. Simon Schug, Seijin Kobayashi, Yassir Akram, Joao Sacramento, Razvan Pascanu, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Analyzing the Inner Workings of Transformers in Compositional Generalization. Ryoma Kumon, Hitomi Yanaka, Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. Luis Chiruzzo, Alan Ritter, Lu Wang, the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language TechnologiesAlbuquerque, New MexicoAssociation for Computational LinguisticsApril 20251</p>
<p>Yufei Guo, and others. Improving image generation with better captions. James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Computer Science. 2382023</p>
<p>Jason Imagen-Team-Google, Jakob Baldridge, Mukul Bauer, Nicole Bhutani, Andrew Brichtova, Lluis Bunner, Kelvin Castrejon, Yichang Chan, Sander Chen, Yuqing Dieleman, Zach Du, Hongliang Eaton-Rosen, Fei, Yilin Nando De Freitas, Evgeny Gao, Sergio Gómez Gladchenko, Mandy Colmenarejo, Alex Guo, Will Haig, Hexiang Hawkins, Huilian Hu, Tobenna Huang, Christos Peter Igwe, Siavash Kaplanis, Yelin Khodadadeh, Ksenia Kim, Karol Konyushkova, Eric Langner, Rory Lau, Shixin Lawton, Soňa Luo, Henna Mokrá, Yasumasa Nandwani, Aäron Onoe, Zarana Van Den Oord, Jordi Parekh, Hang Pont-Tuset, Rui Qi, Deepak Qian, Poorva Ramachandran, Abdullah Rane, Ali Rashwan, Robert Razavi, Hansa Riachi, Srivatsan Srinivasan, Robin Srinivasan, Benigno Strudel, Oliver Uria, Su Wang, Austin Wang, Chris Waters, Auriel Wolff, Zhisheng Wright, Hao Xiao, Keyang Xiong, Xu, Junlin Marc Van Zee, Katie Zhang, Wenlei Zhang, Konrad Zhou, Ola Zolna, Canfer Aboubakar, Oscar Akbulut, Isabela Akerlund, Nina Albuquerque, Marco Anderson, Lora Andreetto, Ben Aroyo, David Bariach, Sherry Barker, Dana Ben, Courtney Berman, Irina Biles, Pankil Blok, Jenny Botadra, Karla Brennan, John Brown, Rudy Buckley, Elie Bunel, Christina Bursztein, Ben Butterfield, Viral Caine, Norman Carpenter, Ming-Wei Casagrande, Solomon Chang, Shamik Chang, Tony Chaudhuri, John Chen, Dmitry Choi, Nathan Churbanau, Matan Clement, Forrester Cohen, Mikhail Cole, Vincent Dektiarev, Praneet Du, Tom Dutta, Ndidi Eccles, Ashley Elue, Shlomi Feden, Frankie Fruchter, Roopal Garcia, Weina Garg, Ahmed Ge, Bryant Ghazy, Andrew Gipson, Dawid Goodman, Sven Górny, Khyatti Gowal, Yoni Gupta, Yena Halpern, Susan Han, Jamie Hao, Jonathan Hayes, Amir Heek, Ed Hertz, Emiel Hirst, Tingbo Hoogeboom, Heidi Hou, Mohamed Howard, Dirichi Ibrahim, Joana Ike-Njoku, Vlad Iljazi, William Ionescu, Reena Isaac, Gemma Jana, Donovon Jennings, Xuhui Jenson, Kerry Jia, Xiaoen Jones, Ivana Ju, Christos Kajic, Burcu Kaplanis, Jacob Karagol Ayan, Suraj Kelly, Christina Kothawade, Ira Kouridi, Jolanda Ktena, Dana Kumakaw, Dmitry Kurniawan, Lily Lagun, Jason Lavitas, Tao Lee, Marco Li, Maggie Liang, Yuchi Li-Calis, Javier Liu, Matthieu Lopez Alberca, Peggy Kim Lorrain, Kristian Lu, Yukun Lum, Chase Ma, John Malik, Thomas Mellor, Inbar Mensink, Tom Mosseri, Aida Murray, Paul Nematzadeh, Signe Nicholas, João Nørly, Guillermo Gabriel Oliveira, Michela Ortiz-Jimenez, Tom Le Paganini, Roni Paine, Alicia Paiss, Anne Parrish, Vikas Peckham, Igor Peswani, Tobias Petrovski, Alex Pfaff, Ryan Pirozhenko, Utsav Poplin, Yuan Prabhu, Matthew Qi, Rahtz ; Luyu, Miaosen Wang, Simon Wang, Stanley Wang, Qifei Wang, Yuxiao Wang, Ágoston Wang, Olivia Weisz, Chenxia Wiles, Xingyu Federico Wu, Andrew Xu, Jianbo Xue, Luo Yang, Mete Yu, Ali Yurtoglu, Han Zand, Jiageng Zhang, Catherine Zhang, Adilet Zhao, Miao Zhaxybay, Shengqi Zhou, Zhenkai Zhu, Dawn Zhu, Mahyar Bloxwich, Luis C Bordbar, Eli Cobo, Shengyang Collins, Tulsee Dai, Doshi, arXiv:2408.07009Andeep Toor, Cristian Udrescu, Aayush Upadhyay. Cyrus Rashtchian, Charvi Rastogi, Amit Raul, Ali Razavi, Sylvestre-Alvise, Susanna Rebuffi, Felix Ricco, Dirk Riedel, Pankaj Robinson, Bill Rohatgi, Sarah Rosgen, Moonkyung Rumbley, Anthony Ryu, Tim Salgado, Sahil Salimans, Florian Singla, Candice Schroff, Tanmay Schumann, Eleni Shah, Gregory Shaw, Brendan Shaw, Kaushik Shillingford, Dennis Shivakumar, Zach Shtatnov, Evgeny Singer, Valerii Sluzhaev, Thibault Sokolov, Florian Sottiaux, Brad Stimberg, David Stone, Yu-Chuan Stutz, Eric Su, Shuai Tabellion, David Tang, Kurt Tao, Gregory Thomas, Thornton, Cristina Vasconcelos, Alex Vasiloff, Andrey Voynov, Amanda Walker,; Tom Hume; Helen King, Jack Krawczyk, Yeqing LiKoray KavukcuogluDecember 2024Anca Dragan, Douglas Eck, Demis Hassabis, Sissie Hsiao. Kathy Meier-Hellstern, Andras Orban, Yury Pinsky, Amar Subramanya, Oriol Vinyals, Ting Yu, and Yori Zwols. Imagen 3</p>
<p>Swing-by Dynamics in Concept Learning and Compositional Generalization. Yongyi Yang, Core Francisco Park, Ekdeep Singh Lubana, Maya Okawa, Wei Hu, Hidenori Tanaka, arXiv:2410.08309March 2025</p>
<p>How Diffusion Models Learn to Factorize and Compose. Qiyao Liang, Ziming Liu, Mitchell Ostrow, Ila Fiete, Advances in Neural Information Processing Systems. A Globerson, L Mackey, D Belgrave, A Fan, U Paquet, J Tomczak, C Zhang, Curran Associates, Inc202437</p>
<p>Neural representation of action symbols in primate frontal cortex. Lucas Y Tian, U Kedar, Adam G Garzón, Rouse, A G Mark, Marc H Eldridge, Xiao-Jing Schieber, Joshua B Wang, Winrich A Tenenbaum, Freiwald, 10.1101/2025.03.03.641276March 2025</p>
<p>How do infinite width bounded norm networks look in function space?. Pedro Savarese, Itay Evron, Daniel Soudry, Nathan Srebro, Proceedings of the Thirty-Second Conference on Learning Theory. the Thirty-Second Conference on Learning TheoryPMLRJune 2019</p>
<p>Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss. Lénaïc Chizat, Francis Bach, Proceedings of Thirty Third Conference on Learning Theory. Thirty Third Conference on Learning TheoryPMLRJuly 2020</p>
<p>Gradient flow dynamics of shallow ReLU networks for square loss and orthogonal inputs. Etienne Boursier, Loucas Pillaud-Vivien, Nicolas Flammarion, Advances in Neural Information Processing Systems. 20105-20118, December 202235</p>
<p>In-Context Learning Creates Task Vectors. Roee Hendel, Mor Geva, Amir Globerson, 10.18653/v1/2023.findings-emnlp.624Findings of the Association for Computational Linguistics: EMNLP 2023. Houda Bouamor, Juan Pino, Kalika Bali, SingaporeAssociation for Computational LinguisticsDecember 2023</p>
<p>Vision-Language Models Create Cross-Modal Task Representations. Grace Luo, Trevor Darrell, Amir Bar, arXiv:2410.22330May 2025</p>
<p>Task Vectors in In-Context Learning: Emergence, Formation, and Benefit. Liu Yang, Ziqian Lin, Kangwook Lee, Dimitris Papailiopoulos, Robert Nowak, arXiv:2501.09240January 2025</p>
<p>Density estimation using Real NVP. Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio, February 2017</p>
<p>Decoupled Weight Decay Regularization. Ilya Loshchilov, Frank Hutter, arXiv:1711.05101January 2019cs, math</p>
<p>stabilityai/stable-diffusion-xl-base-1.0 • Hugging Face. A I Stability, January 2025</p>
<p>stabilityai/stable-diffusion-3-medium • Hugging Face. A I Stability, January 2025</p>
<p>stabilityai/stable-diffusion-3.5-medium • Hugging Face. A I Stability, January 2025</p>
<p>. Google Deepmind, Gemini, 2.0 Flash, 2025</p>
<p>JAX: composable transformations of Python+NumPy programs. James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake Vanderplas, Skye Wanderman-Milne, Qiao Zhang, 2018</p>
<p>Jonathan Heek, Anselm Levskaya, Avital Oliver, Marvin Ritter, Bertrand Rondepierre, Andreas Steiner, Marc Van Zee, Flax: A neural network library and ecosystem for JAX. 2023</p>
<p>. Igor Babuschkin, Kate Baumli, Alison Bell, Surya Bhupatiraju, Jake Bruce, Peter Buchlovsky, David Budden, Trevor Cai, Aidan Clark, Ivo Danihelka, Antoine Dedieu, Claudio Fantacci, Jonathan Godwin, Chris Jones, Ross Hemsley, Tom Hennigan, Matteo Hessel, Shaobo Hou, Steven Kapturowski, Thomas Keck, Iurii Kemaev, Michael King, Markus Kunesch, Lena Martens, Hamza Merzic, Vladimir Mikulik, Tamara Norman, George Papamakarios, John Quan, Roman Ring, Francisco Ruiz, Alvaro Sanchez, Rosalia Schneider, Eren Sezener, Stephen Spencer, Srivatsan Srinivasan, Wojciech Stokowiec, Luyu Wang, Guangyao Zhou, Fabio Viola, The DeepMind JAX Ecosystem. 2020</p>
<p>PyTorch: an imperative style, high-performance deep learning library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary Devito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, Soumith Chintala, Advances in Neural Information Processing Systems. 2019</p>
<p>llm: CLI utility and Python library for interacting with Large Language Models from organizations like OpenAI, Anthropic and Gemini plus local models installed on your own machine. Simon Willison, 2023</p>
<p>Scikit-learn: Machine Learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, E Duchesnay, Journal of Machine Learning Research. 122011</p>
<p>Experiment Tracking with Weights and Biases. Lukas Biewald, 2020</p>
<p>Collaborative data science. 2015Plotly Technologies Inc</p>
<p>uv: An extremely fast Python package and project manager, written in Rust. Charlie Marsh, 2024</p>            </div>
        </div>

    </div>
</body>
</html>