<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2439 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2439</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2439</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-258141273</p>
                <p><strong>Paper Title:</strong> Probe microscopy is all you need</p>
                <p><strong>Paper Abstract:</strong> We pose that microscopy offers an ideal real-world experimental environment for the development and deployment of active Bayesian and reinforcement learning methods. Indeed, the tremendous progress achieved by machine learning (ML) and artificial intelligence over the last decade has been largely achieved via the utilization of static data sets, from the paradigmatic MNIST to the bespoke corpora of text and image data used to train large models such as GPT3, DALL·E and others. However, it is now recognized that continuous, minute improvements to state-of-the-art do not necessarily translate to advances in real-world applications. We argue that a promising pathway for the development of ML methods is via the route of domain-specific deployable algorithms in areas such as electron and scanning probe microscopy and chemical imaging. This will benefit both fundamental physical studies and serve as a test bed for more complex autonomous systems such as robotics and manufacturing. Favorable environment characteristics of scanning and electron microscopy include low risk, extensive availability of domain-specific priors and rewards, relatively small effects of exogenous variables, and often the presence of both upstream first principles as well as downstream learnable physical models for both statics and dynamics. Recent developments in programmable interfaces, edge computing, and access to application programming interfaces (APIs) facilitating microscope control, all render the deployment of ML codes on operational microscopes straightforward. We discuss these considerations and hope that these arguments will lead to create novel set of development targets for the ML community by accelerating both real world ML applications and scientific progress.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2439.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2439.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>On-the-fly DKL active sampling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>On-the-fly Active Learning via Deep Kernel Learning (DKL) for Measurement Selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active learning system implemented by the authors' group that fits a probabilistic structure–property surrogate using deep kernel learning during an experiment and selects the next measurement locations expected to host a targeted physical behavior, minimizing the number of measurements required.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>On-the-fly Deep Kernel Learning Active Sampler</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A closed-loop experimental system in which (1) hyperspectral or pointwise measurements (spectra) are collected at candidate spatial locations, (2) a deep-kernel Gaussian process surrogate (deep kernel learning) is trained/updated online to predict the property of interest and quantify predictive uncertainty, and (3) the surrogate is queried to select the next probe locations to measure that are expected to host the desired behavior. The system is designed to operate during live microscopy experiments to guide spatial sampling and discovery with minimal measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials characterization and discovery in scanning probe and electron microscopy (structure–property mapping, e.g., ferroelectric domain properties and leakage measurements).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequential allocation of point measurements: at each iteration the DKL surrogate predicts locations most likely to exhibit the target property and (implicitly) uses the model's uncertainty to guide selection; the next measurement is chosen to maximize expected discovery of high-value local functionalities according to the surrogate's outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not explicitly specified in the paper for this system; practical constraints discussed qualitatively (experiment wall-clock time per measurement vs model retraining latency).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not explicitly specified; selection described as 'expected to host the physical behavior of interest' (i.e., model-predicted utility) rather than a stated mutual-information or expected-improvement acquisition function.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Implicit exploitation via selection of locations with high predicted property values; any explicit exploration mechanism (e.g., uncertainty-weighted acquisition) is not spelled out in the paper, though the surrogate provides uncertainty estimates that could be used for exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity-promoting mechanism is described; diversity may arise indirectly through surrogate uncertainty and spatial constraints in selection.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Measurement time / number of measurements (experimental budget) and practical experimental latency (probe-scan time).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy sequential selection under an implicit measurement budget — the method aims to reach discovery objectives with as few measurements as possible by prioritizing high-utility locations predicted by the surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Implicit: identification of locations with maximized target physical behavior (e.g., spectral signatures or scalarized property maxima); no explicit novelty or breakthrough-scoring metric is defined in the description.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>The paper describes the approach qualitatively and references experimental demonstrations (see cited experimental works) but does not provide numerical performance metrics within this perspective article.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Implicit baselines discussed conceptually: uniform/grid scanning and passive pre-trained models; specific quantitative baselines are provided in the cited experimental papers rather than in this perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified here; the method is claimed to reduce measurement burden relative to dense raster scans as demonstrated in cited experimental work (references provided), but numerical comparisons are left to the primary experimental publications.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not quantified in this paper; described qualitatively as achieving the identification of structure–property relationships 'with as few measurements as possible.'</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper discusses qualitatively that tradeoffs exist between measurement time, model retraining/computation latency, and experiment throughput, and highlights the need to choose what to measure given these constraints, but provides no formal tradeoff curves.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation-level insight: active on-the-fly surrogate modeling (e.g., DKL) is effective for allocating limited measurement budget to regions most likely to yield the property of interest; explicit formal optimal-allocation rules are not derived in this perspective.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2439.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Augmented GP BO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-augmented Gaussian Process Bayesian Optimization and Active Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of Bayesian optimization / active learning methods that augment Gaussian process surrogates with physical priors or models to guide experiment selection more effectively than black-box BO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Physics-Augmented Gaussian Process Bayesian Optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Gaussian process regression is augmented with physics-derived terms or kernels (or informed priors) to bias the surrogate toward plausible physical behaviors; standard BO acquisition functions (e.g., expected improvement, upper confidence bound) are applied to this physics-aware surrogate to select next experiments, improving sample efficiency by incorporating domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science active learning and optimization (e.g., discovery of materials with target properties through microscopy-guided experiments and simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Use of a physics-informed GP surrogate to prioritize experiments that maximize an acquisition function (e.g., expected improvement or uncertainty-aware criteria), thereby focusing limited experimental resources on the most informative or highest-potential candidates as judged by both data and physics priors.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Not rigidly specified in the perspective, but typical metrics are experiment count and wall-clock time for surrogate updates and acquisition optimization; the referenced work emphasizes sample-efficiency (fewer experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Described conceptually as acquisition-function-driven (expected improvement / uncertainty reduction) on a physics-informed posterior; information-aware criteria are central to the BO framework.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Standard BO tradeoff via acquisition functions (e.g., expected improvement or UCB) applied to the physics-augmented posterior; the physics prior reduces pathological exploration and focuses search in physically plausible subspaces.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No separate diversity-promoting mechanism described beyond the inherent exploration term in BO acquisition functions; physics priors can encourage exploration in physically relevant regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experiment budget or desire for sample-efficiency (minimize number of costly measurements).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>BO naturally optimizes acquisition under a limited number of sequential experiments by maximizing expected gain per experiment; physics augmentation further increases utility per experiment by constraining plausible regions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Operationalized via target objective function values (e.g., property maxima) and sample efficiency (finding high-performing samples within few trials); novelty can be captured indirectly via the surrogate's predictive posterior if novelty metrics are included.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not numerically reported in this perspective; the referenced augmentation approach is argued to increase efficiency and discovery rate relative to vanilla BO in cited works.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Unaugmented Gaussian process Bayesian optimization and naive search strategies (grid, random sampling).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative claim that physics-augmented BO outperforms black-box BO in sample efficiency; specific quantitative gains are reported in the cited primary research.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not reported numerically here; stated as improved sample-efficiency and discovery performance when physics priors are included.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights the tradeoff between model bias (physics priors) and flexibility: stronger priors reduce required data but risk mis-specification; recommends augmented GP to gain efficiency while retaining probabilistic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Insight: incorporate physical priors into probabilistic surrogates to allocate experimental resources more effectively — i.e., design acquisition functions on physics-aware posteriors to improve discovery under constrained budgets.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2439.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ensemble-iterative training</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ensemble Learning with Iterative Training for Uncertainty Quantification and Automated Experiments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble-based ML pipeline that iteratively retrains models and uses ensemble uncertainty estimates to guide automated microscopy experiments and quantify model confidence for atom-resolved tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ensemble Iterative Training for UQ and Experimentation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A workflow that (1) trains an ensemble of deep models on atom-resolved imaging data, (2) uses the ensemble spread as an uncertainty estimate to flag low-confidence regions or novel features, and (3) iteratively requests additional targeted measurements or retraining to improve performance and guide automated experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Atom-resolved microscopy (STEM/STM) analysis, defect detection, and automated experiment steering.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate additional measurements and annotation/retraining effort to regions of high ensemble uncertainty; use uncertainty to prioritize instrument time and human labeling resources for model improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Training cost (GPU hours) for ensemble members and the number of additional targeted measurements requested; not specified as a single metric in the perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Ensemble predictive variance / uncertainty is used as a proxy for expected information from new measurements; explicit mutual-information objectives are not stated but ensemble uncertainty serves as the acquisition cue.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration via sampling regions with high ensemble uncertainty (to reduce model epistemic uncertainty); exploitation via selecting regions where ensembles predict high-value structures when confident.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity arises from ensemble disagreement; no separate diversity regularizer for hypothesis diversity is described beyond sampling diverse uncertain regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Measurement budget (microscope time) and human labeling / compute resources for retraining ensembles.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Iterative loop that requests the minimal set of additional measurements needed to reduce uncertainty where it matters, thereby prioritizing scarce experimental time and annotation resources.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Detection of novel/low-confidence features flagged by ensemble disagreement (proxy for potential novel discoveries); no formal novelty scoring function is defined in the perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not numerically reported in this perspective summary; primary cited work contains experiments demonstrating improved uncertainty quantification and automated experiment performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Single-model training without ensemble-based UQ, passive data collection strategies (dense raster scans).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative statement that ensemble iterative training improves robustness and uncertainty quantification vs single-model approaches; quantitative comparisons are in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not specified numerically here; conceptual gains include fewer redundant measurements and more targeted retraining cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes computational cost of ensembles (more training compute) vs gains from reduced experimental measurements and better-guided experiments; recommends balancing ensemble size vs measurement savings.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: use predictive uncertainty (ensemble spread) to allocate experimental and annotation resources adaptively, focusing costly experiments where they yield maximal reduction in model uncertainty or maximal discovery potential.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2439.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP + compressed sensing scan</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Optimization with Compressive Sensing for Fast Scanning Probe Microscopy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method combining non-rectangular scanning trajectories, compressive sensing, and Gaussian process optimization to dramatically reduce imaging time while retaining critical spatial information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GP-guided Compressive Scanning</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>System composes optimized non-raster probe trajectories (e.g., spiral or sparse patterns) informed by Gaussian process models, and reconstructs full images via compressive sensing/GP interpolation, thereby allocating sampling (time) budget to maximize information recovery per unit measurement time.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>High-throughput / fast scanning probe microscopy imaging where imaging time is the primary constrained resource.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate probe dwell time to selected spatial points determined by GP acquisition that maximize expected reduction in reconstruction error (information) under a fixed scan-time budget; use compressive reconstruction to infer unsampled locations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Imaging throughput (Hz), number of sampled points per image, and reconstruction CPU/GPU time; paper frames cost primarily as experimental (scan) time savings.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicitly minimizes expected reconstruction error; GP predictive variance and acquisition heuristics target points with high expected reduction in uncertainty or high expected information content.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploit structure in the signal by sampling where GP predicts high variance or feature-rich regions (exploration) and fill in background via compressive reconstruction (exploitation of smoothness/priors).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity in sampled spatial locations is achieved by GP acquisition across the scan area and by compressive sampling patterns; no explicit hypothesis-diversity objective is used beyond spatial coverage and uncertainty targeting.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed scan-time or probe time per image (throughput constraint).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Design non-rectangular scan trajectories and select a sparse subset of pixels to measure that maximize expected information under the scan-time budget; reconstruct full images from sparse data.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Improved ability to detect spatially localized features (e.g., defects, domain walls) within dramatically reduced acquisition time; no single novelty metric is specified beyond reconstruction fidelity and detection of features.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Referenced demonstrations claim significant speedups (orders of magnitude faster for some modalities) in acquisition while preserving feature detectability; specific numerical gains are presented in primary experimental papers.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Standard raster (dense grid) scans and purely compressive/random sampling without GP guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative and experimental claims of large throughput gains versus raster scanning; exact numbers are provided in the cited experimental studies.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Paper describes 'significant speedups' (e.g., image acquisition frequency improvements) though specific percentages/times are provided in the primary citations.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Discussion highlights tradeoff between reconstruction accuracy and scan-time savings, and computational cost for reconstruction vs experimental time saved.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation to co-optimize sampling trajectories, acquisition selection (via GP), and reconstruction priors to achieve optimal information per unit scan time under hardware constraints.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2439.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-in-the-loop active learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-in-the-loop Active Learning and Simulation Allocation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conceptual framework to combine in-situ experiments with on-the-fly simulations (DFT, MD, phase-field) to prioritize experimental actions and decide which simulated computations to run given computational and experimental latency constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Theory-in-the-loop Active Discovery Framework</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An integrated framework where experimental observations trigger targeted simulations (from fast semi-empirical methods to expensive DFT/quantum calculations) that inform surrogate models and acquisition decisions; the framework must manage simulator selection, fidelity trade-offs, and latency to keep feedback relevant to live experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Microscopy-guided materials discovery, linking atomic-scale imaging with simulations for assessing stability, electronic properties, and candidate prioritization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Decide which simulation(s) to run on which region/patch of the sample by weighing expected information from a simulation (helping rank/interpret experimental observations) against simulation cost (compute hours and wall-clock latency) and experiment timescale; prioritize fast/approximate simulations for rapid feedback and reserve expensive high-fidelity simulations for high-value candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Discussed qualitatively: wall-clock simulation time, CPU/GPU/core-hours, and time-to-solution relative to experiment cadence (e.g., seconds for some analyses vs hours for DFT).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not specified as a single metric; proposed to use simulation-derived predictive improvements or decrease in experimental uncertainty as the decision criterion for allocating simulation resources.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Allocate cheap simulations broadly to explore candidate hypotheses (exploration) and invest expensive simulations in promising or ambiguous cases where high-fidelity results would materially change experimental decisions (exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Conceptual suggestion to sample diverse candidate patches for simulation to avoid over-committing to a single hypothesis, but no concrete diversity algorithm is specified.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Compute resource budget (CPU/GPU hours), wall-clock latency relative to experiment, and user-specified accuracy/cost constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Multi-fidelity simulation scheduling: choose simulation fidelity based on available compute, expected information value, and experiment turnaround requirements; recommend patch-based simulations rather than full-system high-cost runs to reduce cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not formalized; simulations are used to assess 'interestingness' or potential utility (e.g., predicted electronic properties) to prioritize follow-up experiments that could yield breakthroughs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>No quantitative metrics reported in this perspective; the discussion emphasizes practical latency and fidelity considerations rather than concrete numerical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Naive strategies such as only experimental measurement without simulation guidance, or uniformly running the highest-fidelity simulations everywhere.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified; argued qualitatively that mixed-fidelity, targeted simulations improve decision quality and reduce wasted high-cost computation compared to naive strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not quantified here; conceptual gain is reduced high-fidelity compute usage and improved experimental targeting when simulations are used judiciously.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Explicitly discusses the cost vs fidelity vs latency tradeoff: high-fidelity simulations are expensive and slow (hours) vs experiment rates (sub-second to seconds), motivating the need to choose what and when to simulate.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Principle: prioritize fast, lower-fidelity simulations to inform live decisions and reserve expensive, high-fidelity simulations for a small set of high-value candidates; perform simulations on small patches of interest rather than whole-system simulations to meet experimental timeliness.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2439.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Digital twins / in-silico emulators</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Digital Twins and In-silico Emulation for De-risking Automated Microscopy Experiments</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of digital twin models (data-driven or physics-informed emulators of microscope + sample) to emulate instrument operation and test automated agents offline, reducing risk to hardware and guiding resource allocation between virtual and physical experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Microscope Digital Twin / In-silico Emulation</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A software model that emulates microscope behavior and sample responses (via experiment-derived datasets or physics-based simulators) enabling automated algorithms to be tested and tuned offline; used for safety verification, policy pretraining, and selecting which actions to attempt on the real instrument.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Automated / autonomous microscopy, instrument control, and development of active learning / reinforcement learning policies.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Shift initial exploratory and risky experiments into the digital twin to test policies and parameter regimes; only commit to physical experiments when simulations indicate a high expected utility or when physical validation is necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Simulator runtime and fidelity-related compute cost (wall-clock and CPU/GPU hours); trade-off between fidelity (and cost) vs usefulness for policy development.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not explicitly defined; digital twin usefulness measured by its ability to reduce risk and improve policy performance when deployed on hardware (proxy metrics), and by enabling additional virtual experiments at low hardware cost.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration is primarily shifted into the virtual twin to avoid instrument risk; exploitation is done on the physical instrument after virtual validation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Digital twin enables broad virtual exploration of diverse hypotheses without physical cost; no explicit diversity regularizer described beyond enabling more backups of experiments virtually.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Instrument risk/cost (hardware wear, probe damage) and compute cost for simulation runs.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Use digital twin to lower hardware risk and prioritize limited physical experiments for high-value validated actions; balance compute vs hardware wear by choosing what to emulate vs execute.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not formalized; digital twin judged by its contribution to safer, faster development of policies that lead to discoveries on the physical instrument.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not provided in this perspective; the twin is presented qualitatively as a de-risking and pretraining tool.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Direct on-instrument policy learning and testing without virtual emulation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified here; paper argues that digital twins reduce hardware risk and improve development efficiency compared to purely on-instrument exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not numerically specified; conceptual gains include fewer instrument crashes and faster algorithm iteration cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Discusses compute cost vs hardware risk tradeoff: investing compute in digital twin exploration can reduce costly instrument downtime and damage.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendation to use digital twins to perform broad, risky exploration virtually and reserve real instrument time for validated, high-utility experiments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2439.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2439.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Experimental active learning (ferroelectrics)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Experimental Discovery of Structure–Property Relationships in Ferroelectric Materials via Active Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An experimental demonstration (cited by the perspective) where active learning guided microscopy experiments discover structure–property relationships in ferroelectric films efficiently by adaptively selecting measurements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Experimental discovery of structure-property relationships in ferroelectric materials via active learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Active Learning Experimental Discovery Pipeline (Ferroelectric case)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An end-to-end experimental pipeline that couples automated scanning probe measurements, online analysis, and an active learning policy (e.g., surrogate model-driven sampling) to identify locations and structural correlates associated with desired electrical/functional responses in ferroelectric thin films.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials discovery and characterization — specifically ferroelectric domain structure–function mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Adaptive allocation of measurement locations informed by an online surrogate to prioritize sampling where the surrogate predicts high potential for the functional behavior of interest or where uncertainty is informative for model improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Primarily experimental time (number of measurements, scan time) and latency of online model updates; computational cost of surrogate updates not explicitly quantified in the perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not specified in the perspective summary; the cited experimental work uses surrogate-driven acquisition to improve discovery efficiency (surrogate uncertainty is implied as part of acquisition decisions).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Adaptive selection targeting both predicted high-functionality regions (exploitation) and regions that reduce surrogate uncertainty (exploration) as needed to efficiently reveal structure–property relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism is described in the perspective summary; practical experiments likely balance spatial coverage and informativeness.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental time / number of probe interactions (measurement budget).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Active selection to maximize discovery per measurement; the pipeline is explicitly framed to minimize the number of measurements to discover relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Discovery operationalized as identification of statistically significant and actionable structure–property links (e.g., local geometrical descriptors correlated with higher local T_c or functional response); exact metric definitions are in the cited experimental publication.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>The perspective does not reproduce numerical metrics; the experimental paper demonstrates efficient discovery and reduced measurement counts relative to baseline scanning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Dense raster scanning and passive pre-trained analysis; likely random sampling baselines in the cited experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not numerically given here; the perspective reports that active learning enabled experimental discovery with fewer measurements relative to conventional approaches (details in the primary experimental article).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Not specified numerically in this perspective; described qualitatively as fewer measurements required to uncover structure–property relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper frames the tradeoff between measurement budget and fidelity of discovered relationships and advocates active learning to make better use of limited experimental budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Empirical recommendation: actively allocate measurements to candidate locations predicted to be informative by an online surrogate to maximize discovery under constrained experimental resources.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Experimental discovery of structure-property relationships in ferroelectric materials via active learning <em>(Rating: 2)</em></li>
                <li>Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process <em>(Rating: 2)</em></li>
                <li>Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy <em>(Rating: 2)</em></li>
                <li>Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization <em>(Rating: 2)</em></li>
                <li>Bayesian learning of adatom interactions from atomically resolved imaging data <em>(Rating: 1)</em></li>
                <li>Automated and autonomous experiment in electron and scanning probe microscopy <em>(Rating: 2)</em></li>
                <li>Probing electron beam induced transformations on a single-defect level via automated scanning transmission electron microscopy <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2439",
    "paper_id": "paper-258141273",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "On-the-fly DKL active sampling",
            "name_full": "On-the-fly Active Learning via Deep Kernel Learning (DKL) for Measurement Selection",
            "brief_description": "An active learning system implemented by the authors' group that fits a probabilistic structure–property surrogate using deep kernel learning during an experiment and selects the next measurement locations expected to host a targeted physical behavior, minimizing the number of measurements required.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "On-the-fly Deep Kernel Learning Active Sampler",
            "system_description": "A closed-loop experimental system in which (1) hyperspectral or pointwise measurements (spectra) are collected at candidate spatial locations, (2) a deep-kernel Gaussian process surrogate (deep kernel learning) is trained/updated online to predict the property of interest and quantify predictive uncertainty, and (3) the surrogate is queried to select the next probe locations to measure that are expected to host the desired behavior. The system is designed to operate during live microscopy experiments to guide spatial sampling and discovery with minimal measurements.",
            "application_domain": "Materials characterization and discovery in scanning probe and electron microscopy (structure–property mapping, e.g., ferroelectric domain properties and leakage measurements).",
            "resource_allocation_strategy": "Sequential allocation of point measurements: at each iteration the DKL surrogate predicts locations most likely to exhibit the target property and (implicitly) uses the model's uncertainty to guide selection; the next measurement is chosen to maximize expected discovery of high-value local functionalities according to the surrogate's outputs.",
            "computational_cost_metric": "Not explicitly specified in the paper for this system; practical constraints discussed qualitatively (experiment wall-clock time per measurement vs model retraining latency).",
            "information_gain_metric": "Not explicitly specified; selection described as 'expected to host the physical behavior of interest' (i.e., model-predicted utility) rather than a stated mutual-information or expected-improvement acquisition function.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Implicit exploitation via selection of locations with high predicted property values; any explicit exploration mechanism (e.g., uncertainty-weighted acquisition) is not spelled out in the paper, though the surrogate provides uncertainty estimates that could be used for exploration.",
            "diversity_mechanism": "No explicit diversity-promoting mechanism is described; diversity may arise indirectly through surrogate uncertainty and spatial constraints in selection.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Measurement time / number of measurements (experimental budget) and practical experimental latency (probe-scan time).",
            "budget_constraint_handling": "Greedy sequential selection under an implicit measurement budget — the method aims to reach discovery objectives with as few measurements as possible by prioritizing high-utility locations predicted by the surrogate.",
            "breakthrough_discovery_metric": "Implicit: identification of locations with maximized target physical behavior (e.g., spectral signatures or scalarized property maxima); no explicit novelty or breakthrough-scoring metric is defined in the description.",
            "performance_metrics": "The paper describes the approach qualitatively and references experimental demonstrations (see cited experimental works) but does not provide numerical performance metrics within this perspective article.",
            "comparison_baseline": "Implicit baselines discussed conceptually: uniform/grid scanning and passive pre-trained models; specific quantitative baselines are provided in the cited experimental papers rather than in this perspective.",
            "performance_vs_baseline": "Not quantified here; the method is claimed to reduce measurement burden relative to dense raster scans as demonstrated in cited experimental work (references provided), but numerical comparisons are left to the primary experimental publications.",
            "efficiency_gain": "Not quantified in this paper; described qualitatively as achieving the identification of structure–property relationships 'with as few measurements as possible.'",
            "tradeoff_analysis": "The paper discusses qualitatively that tradeoffs exist between measurement time, model retraining/computation latency, and experiment throughput, and highlights the need to choose what to measure given these constraints, but provides no formal tradeoff curves.",
            "optimal_allocation_findings": "Recommendation-level insight: active on-the-fly surrogate modeling (e.g., DKL) is effective for allocating limited measurement budget to regions most likely to yield the property of interest; explicit formal optimal-allocation rules are not derived in this perspective.",
            "uuid": "e2439.0"
        },
        {
            "name_short": "Augmented GP BO",
            "name_full": "Physics-augmented Gaussian Process Bayesian Optimization and Active Learning",
            "brief_description": "A class of Bayesian optimization / active learning methods that augment Gaussian process surrogates with physical priors or models to guide experiment selection more effectively than black-box BO.",
            "citation_title": "Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process",
            "mention_or_use": "mention",
            "system_name": "Physics-Augmented Gaussian Process Bayesian Optimizer",
            "system_description": "Gaussian process regression is augmented with physics-derived terms or kernels (or informed priors) to bias the surrogate toward plausible physical behaviors; standard BO acquisition functions (e.g., expected improvement, upper confidence bound) are applied to this physics-aware surrogate to select next experiments, improving sample efficiency by incorporating domain knowledge.",
            "application_domain": "Materials science active learning and optimization (e.g., discovery of materials with target properties through microscopy-guided experiments and simulations).",
            "resource_allocation_strategy": "Use of a physics-informed GP surrogate to prioritize experiments that maximize an acquisition function (e.g., expected improvement or uncertainty-aware criteria), thereby focusing limited experimental resources on the most informative or highest-potential candidates as judged by both data and physics priors.",
            "computational_cost_metric": "Not rigidly specified in the perspective, but typical metrics are experiment count and wall-clock time for surrogate updates and acquisition optimization; the referenced work emphasizes sample-efficiency (fewer experiments).",
            "information_gain_metric": "Described conceptually as acquisition-function-driven (expected improvement / uncertainty reduction) on a physics-informed posterior; information-aware criteria are central to the BO framework.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Standard BO tradeoff via acquisition functions (e.g., expected improvement or UCB) applied to the physics-augmented posterior; the physics prior reduces pathological exploration and focuses search in physically plausible subspaces.",
            "diversity_mechanism": "No separate diversity-promoting mechanism described beyond the inherent exploration term in BO acquisition functions; physics priors can encourage exploration in physically relevant regions.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Fixed experiment budget or desire for sample-efficiency (minimize number of costly measurements).",
            "budget_constraint_handling": "BO naturally optimizes acquisition under a limited number of sequential experiments by maximizing expected gain per experiment; physics augmentation further increases utility per experiment by constraining plausible regions.",
            "breakthrough_discovery_metric": "Operationalized via target objective function values (e.g., property maxima) and sample efficiency (finding high-performing samples within few trials); novelty can be captured indirectly via the surrogate's predictive posterior if novelty metrics are included.",
            "performance_metrics": "Not numerically reported in this perspective; the referenced augmentation approach is argued to increase efficiency and discovery rate relative to vanilla BO in cited works.",
            "comparison_baseline": "Unaugmented Gaussian process Bayesian optimization and naive search strategies (grid, random sampling).",
            "performance_vs_baseline": "Qualitative claim that physics-augmented BO outperforms black-box BO in sample efficiency; specific quantitative gains are reported in the cited primary research.",
            "efficiency_gain": "Not reported numerically here; stated as improved sample-efficiency and discovery performance when physics priors are included.",
            "tradeoff_analysis": "Paper highlights the tradeoff between model bias (physics priors) and flexibility: stronger priors reduce required data but risk mis-specification; recommends augmented GP to gain efficiency while retaining probabilistic uncertainty.",
            "optimal_allocation_findings": "Insight: incorporate physical priors into probabilistic surrogates to allocate experimental resources more effectively — i.e., design acquisition functions on physics-aware posteriors to improve discovery under constrained budgets.",
            "uuid": "e2439.1"
        },
        {
            "name_short": "Ensemble-iterative training",
            "name_full": "Ensemble Learning with Iterative Training for Uncertainty Quantification and Automated Experiments",
            "brief_description": "An ensemble-based ML pipeline that iteratively retrains models and uses ensemble uncertainty estimates to guide automated microscopy experiments and quantify model confidence for atom-resolved tasks.",
            "citation_title": "Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy",
            "mention_or_use": "mention",
            "system_name": "Ensemble Iterative Training for UQ and Experimentation",
            "system_description": "A workflow that (1) trains an ensemble of deep models on atom-resolved imaging data, (2) uses the ensemble spread as an uncertainty estimate to flag low-confidence regions or novel features, and (3) iteratively requests additional targeted measurements or retraining to improve performance and guide automated experiments.",
            "application_domain": "Atom-resolved microscopy (STEM/STM) analysis, defect detection, and automated experiment steering.",
            "resource_allocation_strategy": "Allocate additional measurements and annotation/retraining effort to regions of high ensemble uncertainty; use uncertainty to prioritize instrument time and human labeling resources for model improvement.",
            "computational_cost_metric": "Training cost (GPU hours) for ensemble members and the number of additional targeted measurements requested; not specified as a single metric in the perspective.",
            "information_gain_metric": "Ensemble predictive variance / uncertainty is used as a proxy for expected information from new measurements; explicit mutual-information objectives are not stated but ensemble uncertainty serves as the acquisition cue.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration via sampling regions with high ensemble uncertainty (to reduce model epistemic uncertainty); exploitation via selecting regions where ensembles predict high-value structures when confident.",
            "diversity_mechanism": "Diversity arises from ensemble disagreement; no separate diversity regularizer for hypothesis diversity is described beyond sampling diverse uncertain regions.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Measurement budget (microscope time) and human labeling / compute resources for retraining ensembles.",
            "budget_constraint_handling": "Iterative loop that requests the minimal set of additional measurements needed to reduce uncertainty where it matters, thereby prioritizing scarce experimental time and annotation resources.",
            "breakthrough_discovery_metric": "Detection of novel/low-confidence features flagged by ensemble disagreement (proxy for potential novel discoveries); no formal novelty scoring function is defined in the perspective.",
            "performance_metrics": "Not numerically reported in this perspective summary; primary cited work contains experiments demonstrating improved uncertainty quantification and automated experiment performance.",
            "comparison_baseline": "Single-model training without ensemble-based UQ, passive data collection strategies (dense raster scans).",
            "performance_vs_baseline": "Qualitative statement that ensemble iterative training improves robustness and uncertainty quantification vs single-model approaches; quantitative comparisons are in the cited work.",
            "efficiency_gain": "Not specified numerically here; conceptual gains include fewer redundant measurements and more targeted retraining cycles.",
            "tradeoff_analysis": "Paper notes computational cost of ensembles (more training compute) vs gains from reduced experimental measurements and better-guided experiments; recommends balancing ensemble size vs measurement savings.",
            "optimal_allocation_findings": "Principle: use predictive uncertainty (ensemble spread) to allocate experimental and annotation resources adaptively, focusing costly experiments where they yield maximal reduction in model uncertainty or maximal discovery potential.",
            "uuid": "e2439.2"
        },
        {
            "name_short": "GP + compressed sensing scan",
            "name_full": "Gaussian Process Optimization with Compressive Sensing for Fast Scanning Probe Microscopy",
            "brief_description": "A method combining non-rectangular scanning trajectories, compressive sensing, and Gaussian process optimization to dramatically reduce imaging time while retaining critical spatial information.",
            "citation_title": "Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization",
            "mention_or_use": "mention",
            "system_name": "GP-guided Compressive Scanning",
            "system_description": "System composes optimized non-raster probe trajectories (e.g., spiral or sparse patterns) informed by Gaussian process models, and reconstructs full images via compressive sensing/GP interpolation, thereby allocating sampling (time) budget to maximize information recovery per unit measurement time.",
            "application_domain": "High-throughput / fast scanning probe microscopy imaging where imaging time is the primary constrained resource.",
            "resource_allocation_strategy": "Allocate probe dwell time to selected spatial points determined by GP acquisition that maximize expected reduction in reconstruction error (information) under a fixed scan-time budget; use compressive reconstruction to infer unsampled locations.",
            "computational_cost_metric": "Imaging throughput (Hz), number of sampled points per image, and reconstruction CPU/GPU time; paper frames cost primarily as experimental (scan) time savings.",
            "information_gain_metric": "Implicitly minimizes expected reconstruction error; GP predictive variance and acquisition heuristics target points with high expected reduction in uncertainty or high expected information content.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploit structure in the signal by sampling where GP predicts high variance or feature-rich regions (exploration) and fill in background via compressive reconstruction (exploitation of smoothness/priors).",
            "diversity_mechanism": "Diversity in sampled spatial locations is achieved by GP acquisition across the scan area and by compressive sampling patterns; no explicit hypothesis-diversity objective is used beyond spatial coverage and uncertainty targeting.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Fixed scan-time or probe time per image (throughput constraint).",
            "budget_constraint_handling": "Design non-rectangular scan trajectories and select a sparse subset of pixels to measure that maximize expected information under the scan-time budget; reconstruct full images from sparse data.",
            "breakthrough_discovery_metric": "Improved ability to detect spatially localized features (e.g., defects, domain walls) within dramatically reduced acquisition time; no single novelty metric is specified beyond reconstruction fidelity and detection of features.",
            "performance_metrics": "Referenced demonstrations claim significant speedups (orders of magnitude faster for some modalities) in acquisition while preserving feature detectability; specific numerical gains are presented in primary experimental papers.",
            "comparison_baseline": "Standard raster (dense grid) scans and purely compressive/random sampling without GP guidance.",
            "performance_vs_baseline": "Qualitative and experimental claims of large throughput gains versus raster scanning; exact numbers are provided in the cited experimental studies.",
            "efficiency_gain": "Paper describes 'significant speedups' (e.g., image acquisition frequency improvements) though specific percentages/times are provided in the primary citations.",
            "tradeoff_analysis": "Discussion highlights tradeoff between reconstruction accuracy and scan-time savings, and computational cost for reconstruction vs experimental time saved.",
            "optimal_allocation_findings": "Recommendation to co-optimize sampling trajectories, acquisition selection (via GP), and reconstruction priors to achieve optimal information per unit scan time under hardware constraints.",
            "uuid": "e2439.3"
        },
        {
            "name_short": "Theory-in-the-loop active learning",
            "name_full": "Theory-in-the-loop Active Learning and Simulation Allocation",
            "brief_description": "A conceptual framework to combine in-situ experiments with on-the-fly simulations (DFT, MD, phase-field) to prioritize experimental actions and decide which simulated computations to run given computational and experimental latency constraints.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Theory-in-the-loop Active Discovery Framework",
            "system_description": "An integrated framework where experimental observations trigger targeted simulations (from fast semi-empirical methods to expensive DFT/quantum calculations) that inform surrogate models and acquisition decisions; the framework must manage simulator selection, fidelity trade-offs, and latency to keep feedback relevant to live experiments.",
            "application_domain": "Microscopy-guided materials discovery, linking atomic-scale imaging with simulations for assessing stability, electronic properties, and candidate prioritization.",
            "resource_allocation_strategy": "Decide which simulation(s) to run on which region/patch of the sample by weighing expected information from a simulation (helping rank/interpret experimental observations) against simulation cost (compute hours and wall-clock latency) and experiment timescale; prioritize fast/approximate simulations for rapid feedback and reserve expensive high-fidelity simulations for high-value candidates.",
            "computational_cost_metric": "Discussed qualitatively: wall-clock simulation time, CPU/GPU/core-hours, and time-to-solution relative to experiment cadence (e.g., seconds for some analyses vs hours for DFT).",
            "information_gain_metric": "Not specified as a single metric; proposed to use simulation-derived predictive improvements or decrease in experimental uncertainty as the decision criterion for allocating simulation resources.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Allocate cheap simulations broadly to explore candidate hypotheses (exploration) and invest expensive simulations in promising or ambiguous cases where high-fidelity results would materially change experimental decisions (exploitation).",
            "diversity_mechanism": "Conceptual suggestion to sample diverse candidate patches for simulation to avoid over-committing to a single hypothesis, but no concrete diversity algorithm is specified.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Compute resource budget (CPU/GPU hours), wall-clock latency relative to experiment, and user-specified accuracy/cost constraints.",
            "budget_constraint_handling": "Multi-fidelity simulation scheduling: choose simulation fidelity based on available compute, expected information value, and experiment turnaround requirements; recommend patch-based simulations rather than full-system high-cost runs to reduce cost.",
            "breakthrough_discovery_metric": "Not formalized; simulations are used to assess 'interestingness' or potential utility (e.g., predicted electronic properties) to prioritize follow-up experiments that could yield breakthroughs.",
            "performance_metrics": "No quantitative metrics reported in this perspective; the discussion emphasizes practical latency and fidelity considerations rather than concrete numerical performance.",
            "comparison_baseline": "Naive strategies such as only experimental measurement without simulation guidance, or uniformly running the highest-fidelity simulations everywhere.",
            "performance_vs_baseline": "Not quantified; argued qualitatively that mixed-fidelity, targeted simulations improve decision quality and reduce wasted high-cost computation compared to naive strategies.",
            "efficiency_gain": "Not quantified here; conceptual gain is reduced high-fidelity compute usage and improved experimental targeting when simulations are used judiciously.",
            "tradeoff_analysis": "Explicitly discusses the cost vs fidelity vs latency tradeoff: high-fidelity simulations are expensive and slow (hours) vs experiment rates (sub-second to seconds), motivating the need to choose what and when to simulate.",
            "optimal_allocation_findings": "Principle: prioritize fast, lower-fidelity simulations to inform live decisions and reserve expensive, high-fidelity simulations for a small set of high-value candidates; perform simulations on small patches of interest rather than whole-system simulations to meet experimental timeliness.",
            "uuid": "e2439.4"
        },
        {
            "name_short": "Digital twins / in-silico emulators",
            "name_full": "Digital Twins and In-silico Emulation for De-risking Automated Microscopy Experiments",
            "brief_description": "Use of digital twin models (data-driven or physics-informed emulators of microscope + sample) to emulate instrument operation and test automated agents offline, reducing risk to hardware and guiding resource allocation between virtual and physical experiments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Microscope Digital Twin / In-silico Emulation",
            "system_description": "A software model that emulates microscope behavior and sample responses (via experiment-derived datasets or physics-based simulators) enabling automated algorithms to be tested and tuned offline; used for safety verification, policy pretraining, and selecting which actions to attempt on the real instrument.",
            "application_domain": "Automated / autonomous microscopy, instrument control, and development of active learning / reinforcement learning policies.",
            "resource_allocation_strategy": "Shift initial exploratory and risky experiments into the digital twin to test policies and parameter regimes; only commit to physical experiments when simulations indicate a high expected utility or when physical validation is necessary.",
            "computational_cost_metric": "Simulator runtime and fidelity-related compute cost (wall-clock and CPU/GPU hours); trade-off between fidelity (and cost) vs usefulness for policy development.",
            "information_gain_metric": "Not explicitly defined; digital twin usefulness measured by its ability to reduce risk and improve policy performance when deployed on hardware (proxy metrics), and by enabling additional virtual experiments at low hardware cost.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Exploration is primarily shifted into the virtual twin to avoid instrument risk; exploitation is done on the physical instrument after virtual validation.",
            "diversity_mechanism": "Digital twin enables broad virtual exploration of diverse hypotheses without physical cost; no explicit diversity regularizer described beyond enabling more backups of experiments virtually.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Instrument risk/cost (hardware wear, probe damage) and compute cost for simulation runs.",
            "budget_constraint_handling": "Use digital twin to lower hardware risk and prioritize limited physical experiments for high-value validated actions; balance compute vs hardware wear by choosing what to emulate vs execute.",
            "breakthrough_discovery_metric": "Not formalized; digital twin judged by its contribution to safer, faster development of policies that lead to discoveries on the physical instrument.",
            "performance_metrics": "Not provided in this perspective; the twin is presented qualitatively as a de-risking and pretraining tool.",
            "comparison_baseline": "Direct on-instrument policy learning and testing without virtual emulation.",
            "performance_vs_baseline": "Not quantified here; paper argues that digital twins reduce hardware risk and improve development efficiency compared to purely on-instrument exploration.",
            "efficiency_gain": "Not numerically specified; conceptual gains include fewer instrument crashes and faster algorithm iteration cycles.",
            "tradeoff_analysis": "Discusses compute cost vs hardware risk tradeoff: investing compute in digital twin exploration can reduce costly instrument downtime and damage.",
            "optimal_allocation_findings": "Recommendation to use digital twins to perform broad, risky exploration virtually and reserve real instrument time for validated, high-utility experiments.",
            "uuid": "e2439.5"
        },
        {
            "name_short": "Experimental active learning (ferroelectrics)",
            "name_full": "Experimental Discovery of Structure–Property Relationships in Ferroelectric Materials via Active Learning",
            "brief_description": "An experimental demonstration (cited by the perspective) where active learning guided microscopy experiments discover structure–property relationships in ferroelectric films efficiently by adaptively selecting measurements.",
            "citation_title": "Experimental discovery of structure-property relationships in ferroelectric materials via active learning",
            "mention_or_use": "mention",
            "system_name": "Active Learning Experimental Discovery Pipeline (Ferroelectric case)",
            "system_description": "An end-to-end experimental pipeline that couples automated scanning probe measurements, online analysis, and an active learning policy (e.g., surrogate model-driven sampling) to identify locations and structural correlates associated with desired electrical/functional responses in ferroelectric thin films.",
            "application_domain": "Materials discovery and characterization — specifically ferroelectric domain structure–function mapping.",
            "resource_allocation_strategy": "Adaptive allocation of measurement locations informed by an online surrogate to prioritize sampling where the surrogate predicts high potential for the functional behavior of interest or where uncertainty is informative for model improvement.",
            "computational_cost_metric": "Primarily experimental time (number of measurements, scan time) and latency of online model updates; computational cost of surrogate updates not explicitly quantified in the perspective.",
            "information_gain_metric": "Not specified in the perspective summary; the cited experimental work uses surrogate-driven acquisition to improve discovery efficiency (surrogate uncertainty is implied as part of acquisition decisions).",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Adaptive selection targeting both predicted high-functionality regions (exploitation) and regions that reduce surrogate uncertainty (exploration) as needed to efficiently reveal structure–property relationships.",
            "diversity_mechanism": "No explicit diversity mechanism is described in the perspective summary; practical experiments likely balance spatial coverage and informativeness.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Fixed experimental time / number of probe interactions (measurement budget).",
            "budget_constraint_handling": "Active selection to maximize discovery per measurement; the pipeline is explicitly framed to minimize the number of measurements to discover relationships.",
            "breakthrough_discovery_metric": "Discovery operationalized as identification of statistically significant and actionable structure–property links (e.g., local geometrical descriptors correlated with higher local T_c or functional response); exact metric definitions are in the cited experimental publication.",
            "performance_metrics": "The perspective does not reproduce numerical metrics; the experimental paper demonstrates efficient discovery and reduced measurement counts relative to baseline scanning.",
            "comparison_baseline": "Dense raster scanning and passive pre-trained analysis; likely random sampling baselines in the cited experiment.",
            "performance_vs_baseline": "Not numerically given here; the perspective reports that active learning enabled experimental discovery with fewer measurements relative to conventional approaches (details in the primary experimental article).",
            "efficiency_gain": "Not specified numerically in this perspective; described qualitatively as fewer measurements required to uncover structure–property relationships.",
            "tradeoff_analysis": "Paper frames the tradeoff between measurement budget and fidelity of discovered relationships and advocates active learning to make better use of limited experimental budgets.",
            "optimal_allocation_findings": "Empirical recommendation: actively allocate measurements to candidate locations predicted to be informative by an online surrogate to maximize discovery under constrained experimental resources.",
            "uuid": "e2439.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Experimental discovery of structure-property relationships in ferroelectric materials via active learning",
            "rating": 2,
            "sanitized_title": "experimental_discovery_of_structureproperty_relationships_in_ferroelectric_materials_via_active_learning"
        },
        {
            "paper_title": "Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process",
            "rating": 2,
            "sanitized_title": "physics_makes_the_difference_bayesian_optimization_and_active_learning_via_augmented_gaussian_process"
        },
        {
            "paper_title": "Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy",
            "rating": 2,
            "sanitized_title": "ensemble_learningiterative_training_machine_learning_for_uncertainty_quantification_and_automated_experiment_in_atomresolved_microscopy"
        },
        {
            "paper_title": "Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization",
            "rating": 2,
            "sanitized_title": "fast_scanning_probe_microscopy_via_machine_learning_nonrectangular_scans_with_compressed_sensing_and_gaussian_process_optimization"
        },
        {
            "paper_title": "Bayesian learning of adatom interactions from atomically resolved imaging data",
            "rating": 1,
            "sanitized_title": "bayesian_learning_of_adatom_interactions_from_atomically_resolved_imaging_data"
        },
        {
            "paper_title": "Automated and autonomous experiment in electron and scanning probe microscopy",
            "rating": 2,
            "sanitized_title": "automated_and_autonomous_experiment_in_electron_and_scanning_probe_microscopy"
        },
        {
            "paper_title": "Probing electron beam induced transformations on a single-defect level via automated scanning transmission electron microscopy",
            "rating": 1,
            "sanitized_title": "probing_electron_beam_induced_transformations_on_a_singledefect_level_via_automated_scanning_transmission_electron_microscopy"
        }
    ],
    "cost": 0.026352249999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Probe microscopy is all you need *
2023</p>
<p>Sergei V Kalinin sergei2@utk.edu 
Department of Materials Science and Engineering
University of Tennessee
37996KnoxvilleTNUnited States of America</p>
<p>Rama Vasudevan vasudevanrk@ornl.gov 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p>Yongtao Liu 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p> 
Ayana Ghosh 
Computational Sciences and Engineering Division
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p> 
Kevin Roccapriore 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p>Maxim Ziatdinov ziatdinovma@ornl.gov 
Center for Nanophase Materials Sciences
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p>Computational Sciences and Engineering Division
Oak Ridge National Laboratory
37831Oak RidgeTNUnited States of America</p>
<p>Probe microscopy is all you need *</p>
<p>Mach. Learn.: Sci. Technol
423001202310.1088/2632-2153/acccd5OPEN ACCESS RECEIVED 29 October 2022 REVISED 26 January 2023 ACCEPTED FOR PUBLICATION 13 April 2023 PUBLISHEDOriginal content from this work may be used under the terms of the Creative Commons Attribution 4.0 licence. Any further distribution of this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI. PERSPECTIVE Authors to whom any correspondence should be addressed. * Notice: This manuscript has been authored by UT-Battelle, LLC, under Contract No. DE-AC0500OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for public-ation, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for the United States Govern-ment purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/downloads/doe-public-access-plan).machine learningmicroscopyactive learningBayesianreinforcement learning
We pose that microscopy offers an ideal real-world experimental environment for the development and deployment of active Bayesian and reinforcement learning methods. Indeed, the tremendous progress achieved by machine learning (ML) and artificial intelligence over the last decade has been largely achieved via the utilization of static data sets, from the paradigmatic MNIST to the bespoke corpora of text and image data used to train large models such as GPT3, DALL·E and others. However, it is now recognized that continuous, minute improvements to state-of-the-art do not necessarily translate to advances in real-world applications. We argue that a promising pathway for the development of ML methods is via the route of domain-specific deployable algorithms in areas such as electron and scanning probe microscopy and chemical imaging. This will benefit both fundamental physical studies and serve as a test bed for more complex autonomous systems such as robotics and manufacturing. Favorable environment characteristics of scanning and electron microscopy include low risk, extensive availability of domain-specific priors and rewards, relatively small effects of exogenous variables, and often the presence of both upstream first principles as well as downstream learnable physical models for both statics and dynamics. Recent developments in programmable interfaces, edge computing, and access to application programming interfaces (APIs) facilitating microscope control, all render the deployment of ML codes on operational microscopes straightforward. We discuss these considerations and hope that these arguments will lead to create novel set of development targets for the ML community by accelerating both real world ML applications and scientific progress.The last decade has seen the meteoric growth of methods and applications of deep learning (DL). Starting with the seminal paper by Heravi et al [1] that introduced DL for image recognition tasks trained with the ImageNet database by Deng [2], the field has developed almost exponentially, as evidenced by both numbers of papers, as well as recognition of the field in everyday society. The early overviews[3,4]have laid the landscape for the applications of DL in a variety of areas, from medicine to computer vision to robotics. Over the last 2-3 years, we have witnessed an accelerating trend of adoption of DL in more experimental sciences, including chemical synthesis [5], materials science and condensed matter physics[6,7], as well as multiple modalities of chemical and physical imaging [8].Mach. Learn.: Sci. Technol. 4 (2023) 023001S V Kalinin et alThe rapid development in DL architectures for classical neural network architectures resulted in new models including different forms of convolutional networks [9], introduction of graph networks (e.g. crystal graph convolutions) [10], and transformers[11], by now ubiquitous for natural language and increasingly, vision applications. It has also stimulated the development of generative models such as variational autoencoders (VAEs)[12][13][14], and generative adversarial networks (GANs)[15]and their variants that enable a broad range of generative and style transfer applications[16][17][18][19]. Finally, advancements in deep reinforcement learning gave rise to such examples as muZero[20], AlphaZero[20,21], OpenAI5 [22], and real-world applications such as in control over a robotic hand [23], as well as navigation of stratospheric balloons[24].It is important to note that this progress has been based on multiple algorithmic and technical developments over the preceding decades. Neural networks were developed as an idea by McCulloch and  Pitts in 1943 [25]. Advances in computing would facilitate the invention of the first neural network in-silico, termed the ADALINE network[26], which was used to filter audio signals. Multi-layer neural networks, studied first by Rosenblatt [27], were explored in the 1970s [28], but they were not significantly utilized until the backpropagation method was developed in 1986 by Rumelhart [29] to enable efficient training. Reinforcement learning has been known for similarly long periods of time, going back to the works of Widrow in the late 60s[30], with other pioneering work by Sutton[31]. The q-learning algorithm was developed in 1989 by Watkins[32]. The long short-term memory network was introduced by Schmithuber in 1997[33], and recurrent neural networks were studied for a decade before that seminal work. However, it is only over the last decade that the confluence of available computation capabilities[34]and large data sets, emerging in the context of internet searches, social media, and open knowledge projects, that these methods became practically useful across multiple domains and applications.In parallel with the development of algorithmic tools, the community has developed a range of static data sets, mainly driven by the need to define and benchmark the machine learning (ML) methods. In classical image analysis these include the paradigmatic MNIST hand written digits[35], and multiple CIFAR data sets[36]. Similar data sets have been developed in domain areas, including theoretical quantum science, e.g. with the NTangled dataset[37], several examples in climate science[38][39][40], as well as in materials science, for example the SuperMat dataset for superconducting materials[41], or that of multi-principal element alloys[42]. Note that there is also a large number of datasets of simulated data in materials science, many of which are discussed in recent reviews[43].Much progress over this last decade has been fueled by the availability of these well-established datasets enabling benchmarking. While remaining a topic of considerable controversy, it is being argued currently that developing of the large 'foundation' models such as GPT and DALLE may be almost exhausted[44]. Indeed, these models clearly show outstanding performance for in-distribution tasks. However, they very often fail to generalize or yield a well-defined answer for a specific question (as anyone who played with DALLE or Craiyon have discovered). Unsurprisingly, the first applications of DALLE in science is cover art. Complementing these, somewhat less visible are problems of extreme training in costs that make these models available only to large research organizations (and very often trained models are proprietary). For example, the compute time for GPT-3 was 3650 petaflop-days[45], which is about 34 d of continuous use of 1024 T A100 graphic processing units (GPUs). The energy for this training is about 190 000 kWh, which is about what 19 US homes use on average in an entire year [46]. Similarly, emerging is the issue of data exhaustion, i.e. models can be trained with full Wikipedia only once. Complementary to it are by now multiple cautionary stories where DL models trained on static data sets are limited, and fail to generalize. Multiple examples of this problem abound, for example in self-driving cars, radiology and biological imaging [47-52]. It was the experience of the authors of this opinion piece that deep convolutional neural networks (DCNNs) trained on theoretical (i.e. simulated) data requires tuning for specific microscope settings [53], but will fail to generalize for a different set of microscope parameters. While solutions based on more complex contrastive losses such as Siamese networks [54] and Barlow twins [55], ensembling [56], and invariant risk minimization [57] are being continuously developed, this problem is far from resolved.A number of the leading scientists now argue that artificial intelligence (AI) needs to move away from ever-increasing dataset and network sizes, to essentially 'do more with less [58] by using small data sets and physical priors. Similar arguments have been made in the physical science field[59,60], typically in cognizance of rich systems of prior knowledge and inferential biases and extremely small experimental budgets. This convergence between ML and physical fields is, in our opinion, a significant aspect of the last three years.Traditionally, it is believed that ML methods emerge at the interface between classical computer science and established applications such as robotics, automated vehicles, and computer vision, are developed within these domains, and then become accepted in domain communities. However, for the domain experts it is
 Figure 1
. A comparison of real-world images and microscopy images shows the similarity of real world and microscopy world. The real-world image of night sky is generated by Craiyon (www.craiyon.com/). The conductive spot image and the morphology image of Hf0.5Zr0.5O2 are Reprinted from [61], with the permission of AIP Publishing. immediately clear that adoption of the problems and challenges in the ML community often follows an 'inverse' logic, with inherently complex and high-risk problems accruing most of the attention and investment, whereas relatively simple and well-defined problems are ignored or explored only in the domain context. At the same time, many domain problems offer highly simplified toy problems for ML. For example, in figure 1 and table 1, we establish the similarity between the challenges in the context of AI for self-driving vehicles and modern microscopies.</p>
<p>In this opinion, we argue that a promising new venue for the development of active learning methods capable of operating in real world situations are electron and scanning probe microscopy (SPM), both for intrinsic discovery value, and as simplified models for more complex systems. These methods are relatively low risk (compared to automated driving), are usually fairly closed systems minimizing but not excluding exogenous effects (unlike e.g. stock-market), come with a multitude of domain specific reward functions, allow for multiple levels at which prior knowledge can be incorporated, rely on systems with well-defined but often unknown or partially known physical models, and allow for interventional and counterfactual studies. Most importantly, over the last few years, Python application programming interfaces (APIs) and remote operation has become broadly available, allowing for the direct (via edge computing) and remote deployment of the codes on operational machines and their digital twins. Below, we expound on these considerations and (following a well-established ML meme) argue that electron and SPM is what the ML community needs (for now).</p>
<p>What are electron and SPM</p>
<p>When writing this opinion, we feel it is prudent to briefly introduce scanning transmission electron microscopy (STEM) and SPM to an ML community. STEM is an imaging technique based on the electron beam, as illustrated in figure 2(a) [62]. The beam is emitted by the electron gun and subsequently focused and monochromated via a bespoke collection of electron lenses. Effectively the beam is compressed to sub-atomic width and formed by electrons with a very narrow energy distribution. The STEM sample is a very thin membrane, typically below 50 nm thickness, i.e. ∼1000 atoms. These samples can be fabricated via a variety of methods ranging from the native formation via crushing or delamination to highly sophisticated techniques such as focused ion beam milling. Generally, the infrastructure for this sample fabrication is by now well established, and is available in academic, national labs, and industrial centers, and we will not expand further on it here.</p>
<p>Upon transmission through the sample, the electrons are collected via bright field (direct transmission) and dark field (electrons that were partially deflected) detectors. The signal intensity thus provides the information on the density of the solid. Perhaps the simplest analogy for STEM image formation mechanisms is shining the flashlight onto the construct and observing the shadows that transmitted light makes on the wall. Despite apparent simplicity, STEM allow direct visualization of atomic structures, with often spectacular images of atomic structures of metals, oxides, and semiconductors being available. In certain cases, the STEM images can be quantified, providing direct information on atomic spacing and bond length [63]-via direct images! In addition to imaging, STEM allows a number of other interesting possibilities. The energy distribution of transmitted electrons can be measured (much like optical spectra) in a technique called electron energy loss spectroscopy (EELS). These EELS spectra can also be localized on the level of single atoms [65] and provide information on chemical and orbital states of individual atoms, energy excitations and quasiparticles, etc. The STEM is highly relevant to applications such as quantum computing (beam induced photon emission, quasiparticles and other excitations). Most intriguingly, the electron beam can be used for atomic assembly [66,67], to remove or move single atoms [68,69] and assemble atomic structures [67,70]. For the time being, with few exceptions [71] the atomic manipulation was enabled with purely human operator control.</p>
<p>The second type of microscopy we discuss here is the SPM. SPM is based on the interaction of the sharp mechanical probe, or tip, with the surface. In force-based SPMs, the probe is fabricated on the end of a silicon cantilever and the interaction between the probe and the surface leads to the deflection of the cantilever (figure 3). This deflection is then detected via either an interferometer or a laser beam deflection system [73]. Despite simplicity, the sensitivity of this method is such that the forces on the level of interatomic ones can be detected, hence the name atomic force microscopy [74]. The simplest but apt analogy to SPM is touching the surface with the finger (with eyes closed).</p>
<p>Depending on the specific configuration and operation mode, force-based SPMs can be made sensitive to a broad range of forces including magnetic, electric, and Van-der-Waals, allowing visualization of phenomena such as magnetic domains [75,76], electronic and ionic transport [77][78][79], mechanical properties of the surface [80], ferroelectric domains [81], and many others. SPM can be implemented on active devices, exploring phenomena induced by lateral stimuli [78,79,82,83]. The SPM tip can be further used to manipulate matter, from local nanooxidation and lithography [84] and writing ferroelectric domains [85] to mechanical manipulation, moving particle and nanowires around [86][87][88]. In fact, multiple versions of haptic interfaces for SPM have been developed over time providing a human interface to the nanoworld [89][90][91].</p>
<p>A special (and first invented) class of SPMs is scanning tunneling microscopy (STM) [92][93][94]. STM uses simple metallic probe and detects the tunneling current between the probe and conductive surface. While generally requiring a ultra-high vacuum environment for operation, STM is capable of visualizing surfaces on the atomic level and manipulating matter atom by atom. In fact, the letters 'I' , 'B' , and 'M' written in xenon atoms on the copper surface by Don Eigler at IBM [95] was the initial demonstration of atomic manipulation, and gave impetus to the nanotechnology revolution. Now, manipulation of phosphorus atoms on silicon surfaces is broadly considered as one of the possible pathways to solid-state qubits [96,97] for quantum computing. Principle of STEM as both a multimodal imaging tool and atomic manipulation tool. Schematic representation of electron path (a) as it interacts with a specimen and produces a variety of signals that may be detected, most standard of which is the annular dark field (ADF) signal. A magnetic prism (not shown) is typically at the end of the path that separates electrons based on energy lost (EELS) which is yet another signal. Examples of typical STEM imaging (b) where nanoparticles (left) down to single atoms in graphene (right) can be observed. Quantitative imaging example (c) by comparing ideal atom location with actual position, revealing slight displacements on the order of picometers of each cation (middle, blue dots) then visualized as a quiver plot (right) with implications in ferroelectric polarization and strain. Collection of electron energy loss spectrum (EELS) at each probe position in, for example, a chain of plasmonic nanoparticles (d) results in 3D data cube of which certain spectral components can be visualized as different spatially-resolved energy signals, represented here as different colors. In certain conditions, the electron beam can strongly interact with matter to the point of removing atoms from of the atomic lattice entirely (e) which allows to sculpt matter with atomic precision. Manipulation of matter at the atomic scale with single-atom specificity requires identification and classification of each atom followed by accurate positioning of electron beam onto desired sites, where (f) shows the formation of single vacancy lines (SVLs) in MoS2 by specifically knocking out single sulfur atoms in a designated pattern. Scale bars are (b) 20 nm (left) and 2 nm (right), (c) 1 nm, (d) 10   Overview of the scanning probe microscopy (SPM) operation, which includes force-SPM and scanning tunneling microscopy (STM), (a) schematic of the force-SPM setup, (b) force-SPM topography image, reprinted from [61], with the permission of AIP Publishing, (c) force-SPM resonance frequency image, adapted with permission from [72]. (d) Schematic of STM setup, (e), (f) STM images of atomic defects in graphene (e) and molecular self-assembly (f).</p>
<p>Common for both SPM and STEM is the basic principle of a mechanical (SPM, STM) or electron beam probe that can be scanned across the material surface and detect the local state (imaging mode), perform more detailed measurements (spectroscopy), or modify the material state. We note here that this is often a differentiating factor from standard optical microscopy, where the amount of functional property information that can be acquired is not as broad and ability to perturb the sample is generally limited (except via external means). The probe parameters and trajectory can be controlled by the microscope electronics. In this manner, we consider these to be systems that allow a limited set of operations and controls on the local level and provide a convenient model system for deployment of ML, active learning and reinforcement learning algorithms. Below, we discuss these considerations further.</p>
<p>Why microscopy for ML</p>
<p>Electron and SPM are, by now, well-established fields with broad applications within physics, chemistry, and materials science. Below, we discuss aspects of these field that, in our opinion, makes them ideal model systems for active learning methods and hence the ML community. In all cases, we introduce domain-specific considerations and illustrate the connection to the ML.</p>
<p>Language and control</p>
<p>The vast majority of STEM and SPM studies have been performed with commercial tools, often representing black box systems with fairly narrow user interfaces and (for STEMs) service contracts. While customizable controllers have been available (e.g. Nanonis) they used to represent a small part of the field. Correspondingly, deployment of custom developed spectroscopies and ML tools required teams comprising microscopy, physics, and electrical engineering expertise and have been the exception rather than the rule [98][99][100][101].</p>
<p>The situation started to change rapidly over the last several years, when a number of microscope manufacturers started to introduce Python programmable interfaces for commercial tools. A partial list includes SWIFT for NION microscopes [102], PyJEM for JEOL systems [103] and even more open source efforts in optical microscopy that are significantly hardware agnostic, such as pycroManager [104]. For SPM, this includes Python interfaces e.g. the NanoSurf atomic force microscopes [105], and home-grown efforts at multiple research centers worldwide [106,107] for control of low-level microscopy functions on a range of instruments, all via python commands [108]. Correspondingly, the operator has significant programmable control over the microscope operation, and thus correspondingly, access to data streams. This makes it significantly easier to deploy ML codes on these data streams to affect microscope operations, thus greatly lowering the activation barrier for deployment.</p>
<p>It should be noted that one of the advantages of the ability to control the probe position externally is that it enables implanting fast scanning approaches, such as those using spiral scans or compressive sensing techniques, thus enabling significant speedups in image acquisition (on the order of ∼1-2 Hz in SPM for example, and faster for electron microscopy) [109][110][111].</p>
<p>Additionally, the ability to 'script' entire experiments and run them on multiple instruments is a significant shift not only for the types of experiments that are then possible (due to automation), but also in that it changes the user paradigm to one of remote operation, in tune with the recently developed 'cloud labs' for chemical synthesis [112,113]. This parallels the deployment of online quantum computers that allow users to run their own codes by simply uploading them. Remotely operated and automated microscopy instruments offer the same tantalizing possibility, to test not only new experimental workflows, but to benchmark ML algorithms across a range of microscopy platforms.</p>
<p>The last decade has also seen significant developments in terms of data models and associated infrastructure for the microscopy community. Although there exist many formats, on almost all occasions typically there exist ways to convert between multiple formats and read data and associated meta-data into python, regardless of which instrument the data was acquired on. For SPM, virtually every vendor produces their own data format, but programs such as WsXM [114] and Gwyddion [115] have long been capable of reading of data from a wide variety of SPM formats. Tools such as pySPM [116] and Pycroscopy SciFiReaders [117] have significant collections of 'translators' , which build on community tools to convert data into standardized data models, such as the spectral imaging dataset [118]. Regardless of the choice of final format, the codebase exists to convert most existing datasets to a common one for generating curated ML datasets.</p>
<p>A similar situation exists in the electron microscopy, with translators existing for virtually all of the commonly used microscopes, with packages such as HyperSpy [119] and openNCEM [120] providing the necessary bridges to ensure interoperability. In contrast with most scanning probe work, it is interesting to note that the idea of parallel computation and workflows is more established within the TEM community through efforts such as LiberTEM [121], primarily due to the nature of the reconstruction algorithms that are compute intensive. Note however, that this is changing rapidly within SPM in the past two years, and workflow solutions more specific to SPM can be expected to follow suit in due course.</p>
<p>Finally, we note that a significant portion of development on microscopy platforms occurs at scientific user facilities, in both the United States and across other centers around the globe [122]. This dynamic ensures continuous development that is not limited to groups led by individual principal investigators (PIs) at universities, and furthermore, encourages a more broad-based effort, given the needs of the user center are to ensure new techniques and analysis methods are available to the user community with minimal barriers. However, it is still incumbent on the whole microscopy community to engage more deeply with data sharing and curation [100]. Overall, we are not yet at the stage when the codes from GitHub can be deployed to run on selected microscope as a 'physical RL gym' from the ML side. However, from the domain side it is already possible to run specific code as a plug-in to the microscope.</p>
<p>Risk</p>
<p>One significant consideration in real world applications of ML is that of risk. Perhaps the most recognized case for it is autonomous driving, where each accident is instantly popularized. However, this is also well recognized in areas such as ML fairness and explainability, with the algorithm trained on historical data often making predictions and recommendations inconsistent with current social norms [123].</p>
<p>Comparatively, for microscopy the risk is relatively small. It is well understood that scientific research is prone to errors, and knowledge emerges as the result of multiple trial and error cycles, often including community feedback. Given this established paradigm, any results derived from the automated workflows will be verified by conventional methods for an extended time, and the impact of potentially incorrect findings can be expected to be comparable to that derived during normal research processes.</p>
<p>The second component is the risk to the instrument. While crashed kernels in the notebook can be restarted, the crash in a microscope often necessitates the change of the probe. For ambient SPMs this is of the order of ten minutes and process can be automated. For UHV systems it can be several days (and hence STM community is highly conservative). Beyond the probe, the damage for the mechanical parts of the systems may be considerable. Practically however, these risks can (and are) heavily mitigated by constraints in allowable operations. Following on the concepts and ideas from the operation of cloud compute infrastructure and automated labs, the allowed actions in automated microscopy can be chosen to be within safety tolerances to ensure equipment safety. Similarly, de risking is possible via the introduction of the digital twins, meaning the in-silico models of the microscope that either emulate operation via ground-truth data, or allow modeling of the mechanical and electronic equivalent of the microscopes [124].</p>
<p>Note that the advantage of the microscope as a model system for active learning is the low risk combined with the large variability of microscope and sample environments, ideal for developing ML solutions stable with respect to large out of distribution (OOD) effects. Once developed, these can be potentially transferred to higher-risk problems, e.g. robotics or autonomous drones.</p>
<p>Exogenous variables and causal models</p>
<p>A very important consideration for any real-world ML algorithm is the number and character of exogenous variables, i.e. external (to the system) stochastic parameters. For example, the success of AlphaGo [21,125] or any other reinforcement learning algorithm for computer games is predicated on known rules and lack of external variables (e.g. the number of squares on the board will never change). In other words, while the game contains the element of randomness, the general rules are constant, and the algorithm builds the approximations via the Q-tables or continuous policies.</p>
<p>Comparatively, the self-driving car or stock-trading algorithm has to deal with influences outside of the system-from pedestrians coming from around the corner to political events. Correspondingly, long-term prediction or even models of the environment for long time are difficult to construct. Clearly, the absence of exogenous variables is an oversimplification of the real-world applications (the world is not a chess game), while too many limits how far we can predict (it is not a fully random process either).</p>
<p>From this perspective, microscopy offers an intriguing range of possibilities from almost deterministic to highly stochastic systems and from full to partial knowledge of the system, all in the presence of strong physical priors. For example, STEM imaging of bulk materials visualizes the atomic columns averaged over the beam direction. Imaging with focal and tilt series, while more complex, provide information on the structural variability in the beam direction [126][127][128][129][130]. Atomically resolved images of 2D materials such as graphene allow all static atoms to be visualized in the image plane, but the observed phenomena may also be affected by the presence of (invisible) moving atoms that can participate in chemical reactions and atomic reconfigurations. At the same time, at this length scale the objects that we observe in the microscope can only be atoms, and atoms have a well-defined geometry. Correspondingly, ML analysis of such data allows for very strong inferential biases.</p>
<p>For SPM microscopy these considerations are more complex and can be less well defined depending on the specific material system. For example, UHV STM relies on atomically clean surfaces to minimize unwanted noises and chemical contamination (i.e. each stray atom will be seen as a 'mound' on surface). Techniques such piezoresponse force microscopy [131] allow almost complete decoupling of information on different aspects of materials functionality, e.g. topography, elastic properties, and ferroelectric domain structures. At the same time, magnetic force microscopy [76] will be sensitive to both magnetic and electric interactions, whereas phase imaging mixes all interactions including magnetic, electrostatic, adhesion, and elastic into one information channel. Yet, compared to largely uncontrollable interactions in the real world, microscopy offers an opportunity to explore correlative and causal links in technologically relevant systems under (mostly) controlled environments, starting from relatively simple systems with largely known physics (e.g. one-element-based 2D materials) and progressing towards more complex systems demonstrating yet-to-be understood physical behaviors (e.g. cuprate superconductors).</p>
<p>For example, SPM and spectroscopy allow collecting data on both atomic positions and physical behaviors of interest (encoded in spectra) over the same sample region [132,133]. The local atomic distortions and classical and quantum phenomena are assumed to be correlated and their relationship is considered to be parsimonious, that is, ultimately explained by a small number of (latent) mechanisms. A conventional approach to the analysis of such data is to apply a blind unmixing to the hyperspectral data and do a linear correlation analysis of the abundance maps of the derived sources with structural descriptors at each unit cell [134]. It would be interesting instead to utilize deep latent variable models trained in end-to-end fashion (with structural images as input and spectroscopic curves, full or scalarized, as outputs) to disentangle different physical mechanisms and establish how changes in specific geometric features influence a property of interest (for example, local T c ). Furthermore, in complex systems with competing interactions and chemical disorder, it will be critical to distinguish between correlative and casual links, offering a playground for a newly emerging class of casual representation learning techniques.</p>
<p>Interventions and counterfactuals</p>
<p>Electron and scanning probe microscopies are often perceived as a purely observational areas, much like astronomy. However, familiarity with the field suggest that this is generally not the case-both probes and beams can modify the surface, but these behaviors are often perceived as deleterious. For example, while a high energy electron beam can easily modify the sample, this is traditionally perceived as beam damage. In fact, much of the evolution of modern STEMs, first towards high voltages and then towards low voltage aberration corrected machines was driven by the need to balance resolution and beam damage. Similarly, in SPM the damage to the surface and especially the probe is generally unwanted.</p>
<p>However, for many materials classes the evolution of both SPM and electron microscopy techniques has facilitated control over the modifications inflicted on the sample. Atomic manipulation in STM [95] and STEM [68,70,135] is one example of this. Here, we create atomic configurations that are absent in the original material, and explore their functionality via imaging and spectroscopy ( figure 4(b)). Similarly, in piezoresponse force microscopy we can create new domain structures and explore their polarization dynamics [81,136].</p>
<p>From a ML perspective, this opens a pathway for exploring interventional and counterfactual questions implemented on an experimental platform. For example, a system of plasmonic nanoparticles contains multiple local geometries that can be extracted from the experimental data and correlated with the associated plasmonic spectra using im2spec [137,138] or parallel VAE approaches [139,140]. These methods allow us to predict the plasmonic properties for the extant geometries. However, the electron beam can be used to modify the system in a broad variety of scenarios, including those that remain in distribution compared to original data (e.g. remove the particle and create a hole similar to the ones that already exist), or create geometries that were not present in the original data sets (e.g. hole within the particle). We note here that the ability to repeatedly modify and probe the system should also enable a playground for 'concept learning' for automated agents. Combined with the reasonably well-understood physics of these systems, this opens a very broad set of opportunities to implement causal active learning methods and explore interventional and counterfactual strategies.</p>
<p>Prior knowledge and active learning</p>
<p>Most ML methods are correlative and generally take only limited advantage of the prior knowledge, typically implicitly in the form of output or the loss function. As such, they capture the structure of the target distribution, but generally impose no limitations on the properties of the object. However, physical sciences take a very different approach where past knowledge plays the preponderant role, and the experiment is often formulated to falsify the specific hypothesis formulated based on prior domain specific and general knowledge.</p>
<p>Recently, significant progress has been achieved in developing physics-informed neural networks [141]. In these, the network structure can be such that outputs directly satisfy certain invariances or equations of motion. Alternatively, the known factors of variability such as rotations, translations, or shear can be incorporated as defined latent variables in architectures such as VAEs [142][143][144].</p>
<p>From the perspective of physics-informed ML, STEM and SPM offer a broad range of opportunities both on the instrument and materials side. From the instrument perspective, the SPM cantilever oscillations closely follow Euler beam equations, providing a strong inferential bias. In electron microscopy, the image formation mechanisms are complex, but the physics of the multiple scattering can be naturally incorporated into the neural network structure. An even broader range of opportunities emerge on the materials side, where materials systems chosen for detailed study usually come with known composition, preparation history, and hence well-defined physical priors in structure and range of possible phenomena.</p>
<p>The important aspect for ML applications is that the experimental setup in SPM is often selected to narrow down the scope of relevant knowledge. For example, when exploring ferroelectric domains [145], the relevant information with a good degree of approximation is the domain structure tied to the corresponding free energy functional and the preparation method. At the same time, a second level of parameters with be the surface preparation and surface chemistry conditions [146][147][148]. Often the potential contributions of certain level of description can be estimated from straightforward physics-based estimates, with the remaining variables contributing to exogenous factors with some known level of significance.</p>
<p>Physical models</p>
<p>The characteristic aspect of many physical systems is the simplicity of the laws that govern their behavior, as exemplified by the fundamental gravitational laws, Maxwell equations, or quantum mechanics. This local simplicity however gives rise to very complex behaviors of real systems, from real material properties to the emergent behaviors in systems with collective interactions [149]. The important aspects of these laws is that generally they are expected to be universal, e.g. the force fields between two carbon atoms do not depend on where in the universe these atoms are. Correspondingly, it can be argued the high-resolution imaging studies can be aimed at discovery and identification of these laws.</p>
<p>The significant progress toward these applications of ML has been accomplished in astronomy. It has been demonstrated by Lemos et al that the symbolic laws of gravitation can be derived from observations of planetary motion [150]. Similarly, Udrescu and Tegmark have demonstrated that equation of motions can be derived from video data [151].</p>
<p>From this perspective, microscopy data opens virtually unlimited opportunities to explore physical models. Provided only the position of atoms, it is possible to extract a number material properties. For example, built-in polarization fields and ferroelectric domains can be identified by-i.e. the electron beam in the STEM is sensitive enough to resolve picometer displacements that have origins in polarization [153]. Figure 5(a) demonstrates how the determined atomic coordinates in a ferroelectric superlattice are used to compute polarization fields-simply, the deviation of a cation (bright atom) from its ideal lattice position gives the polarization vector at that site. Similarly, it is known that strain can in turn have an impact on electronic properties [154], but it turns out only a small fraction of atoms deviate from their nominal lattice location, for example, at the interface of a core-shell nanoparticle. Hence, we can begin to understand the underlying reason why a material exhibits a certain response-it may be intimately tied to a very localized strain or built-in polarization field.</p>
<p>Another subtle feature that can be detected via atomic coordinates is the presence of defects, which can exist in the form of vacancies, impurity atoms, or practically anything that is not part of the pristine crystal. Many times, these can be extremely difficult for the human operator to notice (especially in the case of a single atomic defect) during experimental operation, therefore a rapid means for detecting and classifying atomic coordinates is of critical importance. In figure 5(b), a single layer of graphene is shown, where the atomic coordinates given by a trained deep ensemble neural network [152,155] are shown. Graph analysis is performed given the coordinates, from which vacancy defect structures like a Stone-Wales [156] (or, 5-7 ring) defect strongly stand out. As a separate example, in figure 5(c), HAADF-STEM image of MoS 2 is shown also with its detected coordinates shown, where completely different defect structures can be identified and clustered based on, for instance, nearest neighbor distances or relative intensities. In the systems where the electron beam can create atomic defects, each image contains information on the position of multiple atoms in the system in the quasi-equilibrium state. The possible configurations are ultimately determined by the force fields between the atoms. Hence, observations of the atomic configurations allow (in principle) probabilistic reconstruction of the force fields between the atoms.</p>
<p>Similar insight can be derived from mesoscale SPM images. For example, it is the formation of domains that makes of ferroelectrics important for applications in sensors, actuators, capacitors, gates, and information technology devices [145,[158][159][160][161]. Therefore, exploring the mechanisms of the ferroelectric domain and domain wall dynamics has been a long-standing problem [162][163][164][165]. A ferroelectric domain is an area of aligned spontaneous electric polarization, usually an area in nanoscale or microscale levels. Piezoresponse force microscopy has emerged as a powerful tool for the visualization of ferroelectric domains and explore associated physical mechanisms. Domain walls-boundaries between domains with different polarization orientations-with the discontinuity of polarization often present complicated properties due to the presence of defects, disorder, and complex histories. In addition, owing to the polar nature of ferroelectric materials, the bound charge may result in charged walls, leading to strong coupling between domain wall and semiconducting properties [166,167]. Therefore, domain wall behavior and switching mechanisms at the nanoscale level, including wall motion, domain nucleation, and pinning, root a broad spectrum of properties and applications of ferroelectric materials. Shown in figure 6 is an example of a ferroelectric domain and its dynamics imaged by piezoresponse force microscopy. The raw phase and amplitude are extracted from a video that indicates continuous domain evolution under applied bias. Here the domain walls can be identified by a Canny filter or DCNN model, as shown in figures 6(c) and (d), which indicated segmented ferroelectric walls and ferroelastic walls, respectively. Then, the identified domain wall videos allow the exploration of relevant mechanisms by ML analysis. Indeed, in our earlier study, using rotationally invariant autoencoders we discovered factors affecting the ferroelectric wall dynamics [168].</p>
<p>Theory-in-the-loop</p>
<p>For atomic systems, one can run simulations and obtain result while the experiment is still running. For example, as shown in figure 7, we can observe existing structure or assemble a structure in the STEM environment on the atomic level, but we cannot really measure its electronic/magnetic properties (since it requires probing states at the Fermi level). So, we can use theory to get an idea of how 'interesting' or 'useful' these structures are and to help identify the next step (e.g. what shall we passivate our vacancies with to make sure they remain stable, etc).</p>
<p>Using DL surrogate models, one can in principle allow these behaviors in real-time, opening a connection to physical DL models. Physical models constructed using first-principles theory to quantum Monte Carlo and finite-element methods, spanning over quantum-mechanical to continuum scales, carry a multitude of information on structural, thermodynamic, and electronic properties of materials. Hence, introducing knowledge gathered from theoretical simulations can guide DL models to become more physics(science)-informed. Such understandings from simulations also help in decision-making process by underpinning causal hypothesis-driven [169,170] mechanisms. The elaborative nature of theoretical models assists in establishing structure-property relations for which structured causal networks work well to answer associational interventional and counterfactual questions. Policies to draw inferences on effects of specific variables on functionalities of interest in a simulated environment can eventually be translated into active discovery frameworks for automated experiments. It is possible to even design active learning strategies that draw prior information [171] based on theoretical models for exploring both existing as well as unknown chemical spaces.</p>
<p>Be it the DL models, or causal networks or physics-informed optimization schemes for active learning or all combined, there are certain challenges to bringing 'theory-in-the-loop' applicable to all of frameworks. Although significant progress has been achieved over the years in high-performance computing, stark differences in time-, length scale and latency still exist between running an experiment versus performing one simulation representing the same scenario. For example, density-functional theory (DFT) and molecular dynamics simulations can optimally generate system sizes of Å to nanometer scales. The length of time required to perform one such simulation that is up to a few microseconds long can be multiple CPU hours, whereas STEM images are typically available at a fraction of a second. Semi-empirical methods such as density functional based tight binding and the extended tight binding method, enable simulations of large systems and relatively long timescales at a reasonable accuracy. These are considerably faster for typical DFT ab initio [172], but still takes a few hours to converge. Defining regions of interest in an automated fashion followed by performing simulations on those 'patches' is a suitable alternative to draw inferences on a partial or entire system [173]. These can be achieved by multiple means, such as finding optimized fit-to-experiment structures via forward modeling and scalable data analyses.</p>
<p>As a result of these considerations, the typical question of 'what to simulate' depends heavily on the available constraints-computational resources, the accuracy required for the particular task (which can be very minimal for explorative work, or may need to be very accurate to match closely with experimental observables), and the specific functionalities explored. For instance, a person investigating ferroelectric domain dynamics would likely want to simulate the domain evolution under applied fields via phase-field models, and in real-time, adapt the phae-field model parameters to both the boundary conditions (surface polarization structure observed, and electrical and elastic boundary conditions of the sample) to produce large set of simulations that can guide the operator in what possible meta-stable states could be observed, and potentially how to reach them. We note that this is possible in mesoscale systems where the partial differential equations (PDE) is given, and relatively well-understood, but in e.g. atomic cases the situation is more complicated and may need a mix of models across length/time scales.</p>
<p>Overall, frameworks bringing microscopic experiment and theory together in real time require capability for rapid exploration of features, analyses of images, quantification of associated uncertainties and most importantly, simulations performed in reasonable (comparable to experiment run time) timescale to establish an active feedback loop for guiding the next set of experiments.</p>
<p>Rewards</p>
<p>A key but often overlooked aspect of an automated experiment is the reward. Interestingly, on the domain side, it is often understood implicitly and incorporated both in the type of research and experiment planning. Basic science is associated with exploration, e.g. the discovery of new behaviors or finding generalized descriptions of the observed behaviors. Applied science targets exploitation, e.g. optimizing a specific aspect of materials functionality. However, even basic science has the exploration limited to a specific region of knowledge space, or constrained to a strong hypothesis, to make the scientific process tractable. The reward in this case is refining or falsifying the hypothesis. The combination of these elements gives rise to the current paradigm of hypothesis-driven science, allowing for serendipitous discovery.</p>
<p>Comparatively, the reward in ML is usually much more well-defined. For example, in computer games, it is a win. In automated driving it is to get from location A to location B in the least amount of time, with minimal use of fuel, and avoiding accidents and road rule-breaking. Hence, while multiple types of rewards, including external prescribed rewards, curiosity, or empowerment in reinforcement learning, and strategies to balance multiple rewards in multi-objective optimization, have been developed, the reward structure is usually straightforward and is derived externally or from simple information-theoretical criteria.</p>
<p>Microscopy experiments are associated with a much larger range of possible rewards, defined locally within the experimental context or more broadly with respect to the chosen project or experimental workflow. For example, for instrumentation and technique development, the reward is often the increase of spatial and energy resolution [174] or minimization of the beam damage. Of course, time is also a reward, in the sense that increased throughput of imaging is also desirable from an efficiency standpoint. In fact, for the microscopy community, this is often the primary factor driving the development of the microscope over the technological cycle, or tuning the existing system during the experiment. At the same time, this reward is of less interest for domain communities, that aim to explore specific materials or quantify specific aspects of materials behaviors.</p>
<p>Implicitly, the reward structure drives the experiment led by a human operator, and the reward structure and time budget control the experiment planning. Correspondingly, microscopy offers an extensive playground for planning multi-level workflows, with resolution and stability optimization as a lower-level goal and the discovery and experiment planning as a higher-level goal. The former task is defined within a well-defined parameter space, for example the tuning of the scanning probe or electron microscope. At the same time, domain specific tasks offer an interesting scientific and sociological challenge. Can these models and workflows be made machine interpretable? Similarly, given these domain specific rewards, can ML algorithms discover new strategies for tuning the microscope to achieve them?</p>
<p>Current state of ML in microscopy</p>
<p>The first applications of modern DL techniques to scanning probe [175] and scanning transmission electron [53] microscopy were demonstrated in 2017 for the off-line data analysis. Since then, there has been a growing interest in using deep and ML to automate routine analysis of microscopy data (such as atom/defect/particle finding) [8,155,[176][177][178][179], learning symmetries [180], and to extract physically meaningful latent parameters explaining high-dimensional observations [138,143,144,157,[181][182][183]. More recently, the pre-trained DL models were used to identify on-the-fly objects of interests, such as domain walls and atomic defects, in automated experiments in scanning probe and electron microscopy.</p>
<p>However, a significant and well-known limitation of DL models pre-trained on static datasets is that they often fail to generalize OOD, demonstrating poor performance (or even outright failure) when applied to data from outside the domain of training examples. The examples of OOD data in microscopy are images acquired under different acquisition parameters, presence of contaminants on the surface, sample damage due to e-beam irradiation, or change in the probe state due to unexpected interaction with a sample surface. While a combination of ensemble learning and iterative re-training partially addresses this issue for atom-resolved data [155], it does not solve the problem entirely. Furthermore, the approach based on pre-trained DL models assumes that we always know what structures are 'interesting' , while in many cases this is exactly what we want to discover.</p>
<p>One way to overcome the above limitations is to replace model(s) pre-trained on a static dataset with a model actively interacting with a data generation process. Recently, our group have used an active learning approach for learning a probabilistic structure-property relationship on-the-fly and using this 'knowledge' to sample next measurement locations [184,185]. This approach is based on the idea that we often know what physical behavior (functionality) we are interested in and that it is encoded in spectra, and we want to identify (local) structural features where this behavior is maximized. We also want to achieve this with as few measurements as possible. The structure-property relationship of interest is then approximated at each step via a deep kernel learning model [186], which is used to sample the next measurement locations expected to host the physical behavior of interest.</p>
<p>Way forward</p>
<p>The considerations in sections 2 and 3 suggest that there is a tremendous opportunity for research and development at the interface between ML and microscopy. While the potential benefits for the microscopy community per se are by now well realized and explored in multiple publications and opinion pieces [187][188][189], the opportunities for ML community in microscopy domain are much less realized. Below, we summarize the classical components for the developments of an ML ecosystem, but aim to highlight the potential benefits and outcomes from ML side.</p>
<p>Data repositories: useful but limited</p>
<p>The initial success of ML research was based on (and is continuously measured against) the static datasets, the proverbial big data. While the definitions of big data evolved with time, it is now generally understood that it will refer to the data sets that is sufficient to sample the distribution from which the data is drawn, for example allow training of a generative model. Similar to many other fields, initial effort in microscopy was also dedicated towards the development of supervised models [53,175]. By analogy with other fields, it has been proposed that large-scale data repositories can be universally useful. Some attempts to create these in microscopy have been made [190,191].</p>
<p>We argue that this may not be the case, at least not in the direct form. While training examples are definitely useful, they cannot represent all the ways the microscope can work. Even in STEM, the microscope variability can be very significant between different experiments, and the phenomena such as beam distortion due to the incomplete correction can be mixed with (as an example), the atomic column shape distortion due to octahedra tilts in the beam direction [192,193]. For the simplest example, all ideal crystalline materials with the same lattice will look the same under a microscope (down to lattice parameter). In SPM, the variability of the possible objects is even larger and magnetic domains, ferroelectric domains, polar regions in nanomaterials, or grains in polycrystalline materials can give rise to very similar contrasts.</p>
<p>While at the first glance counterintuitive, we argue that this is simple because the imaging methods are convolution of material and detection system. For the latter, detection system can have variabilities and modalities that far exceed that of the material variability (all crystalline materials look the same under the microscope). Comparatively, all vision tasks are predominantly based on human eye, or compared to the human eye baseline (e.g. in medical imaging analysis is verified via human labeled data sets/experts). Correspondingly, the value of the bespoke image databases can be minimal unless images are augmented by the detailed metadata on microscope parameters and sample composition and history.</p>
<p>At the same time, microscopy creates unique opportunities for the development of novel ML methods. For example, the image plus microscope metadata pairs offers ideal model systems for the invariant risk minimization problems due to the presence of strong inferential biases. In other words, unlike many other computer vision problems, it is well known that the answer exists and is unique. This further opens the pathway for developing ML methods that allows for problem-specific augmentation (variability of the imaging system), encapsulate and aim to discover data generation process, etc.</p>
<p>Hyper language: tuning and manipulations</p>
<p>On a fundamental level, every microscopy experiment consists of a carefully orchestrated sequence of tasks, often with inner and outer optimization loops, and decision making at particular steps. This appears obvious when stated but is in fact so ingrained in the standard microscope operator's daily routine that it is rarely formulated in explicit form. However, in order to enable fully autonomous microscopes, we need to develop a language that can represent every low-level task that a microscope system can perform. This can be thought of as the microscopy equivalent of the recently developed 'XDL' programming language for chemical synthesis, which is a Turing-complete language that is in principle able to represent all types of chemical reactions [194]. Naturally, the low-level microscopy functions would be operations such as moving the stage and/or tip to a certain location, scanning along a trajectory, enabling and disabling feedback systems, measuring along different channels, changing local and global excitation parameters, and so forth, and there would additionally be 'decision blocks' for where decisions would be made about the next course of action (either by a human or algorithm).</p>
<p>As an example, consider a simply SPM experiment of measuring the roughness of a sample. The basic steps would be to initiate the tapping mode operation (including the tuning steps), scan regions of a particular size that are free from large debris and move the scan window after each scan to collect more images and thus statistics. Then the tip should be withdrawn, and the images analyzed with a standard topographic analysis to determine the average sample roughness. This could easily be represented as a sequence of function calls in a script, but it could also be represented by an even more compact representation akin to that of molecules-such as the SELFIES representation introduced by Aspuru-Guzik group [195,196]. Then, performing an experiment and generating new experiments becomes an exercise in generating new such 'microscope SELFIES' .</p>
<p>Beyond human workflows</p>
<p>An interesting and very weakly explored concept in the context of automated experiment is the development of beyond-human workflows. Indeed, currently most of the effort in automated experiment relies on classical human based workflows, implemented via robotic agents. An alternative is combined human and robotics operators orchestrated by central agent.</p>
<p>At the same time, recent advances in reinforcement learning have demonstrated that for closed systems with known rules but complex emergent strategies (e.g. Alpha Go), AI is capable of formulating the strategies beyond human. Interestingly, this leads to the inverse developments when exposure to the AI agents improves human learning. Until now, these developments have been limited to fully closed system, albeit recent progress with large models such as DALLE make in the art field suggest that the situation is likely to change.</p>
<p>Similar developments, albeit with a certain time delay, are now proceeding in the field of automated labs. To date, the vast majority of automated or hybrid labs utilize the human made workflows derived from human experts or via literature mining [197][198][199][200][201]. In many cases, ML is used to optimize specific steps such as yield of specific product via optimization in low-dimensional continuous parameter space and implemented via continuous flow reactors, microfluidic systems, or pipetting robots [202]. However, proponents such as Symes et al [203] now explore pathways for full chemistry design with 3D printing of components. That said, exploration of the chemical space of e.g. small molecules is an exceptionally complex problem due to its immense size and non-differentiability [204]. For the experimental world, this often limits discovery space to the molecules that can be synthesized from a limited set of precursors and reactions.</p>
<p>Comparatively, microscopy offers a large, but still much smaller realm for exploration. Systems such as atomic manipulation by electron beam or STM probe or ferroelectric domain manipulation by Piezoresponse Force Microscopy (PFM) offer the richness of unknown physical behaviors, a multitude of possible metastable states, and a variety of ways to reach them. However, these systems come with a finite range of possible actions and actions that are fully available within the specific system. As such, this can be an ideal toy system for exploring ML creation of workflows starting from optimization of human based ones but evolving to discover new ones, via empowerment learning or other techniques. Interestingly, even deep kernel learning discovery of the plasmonic EELS signals already presents beyond human workflow.</p>
<p>Learning physics</p>
<p>Generally, a physics-based solution, in circumstance where the physics is computable and understood, is much preferable to a purely data-driven approach, due to efficiency of learning. In most cases, the physics-models may have zero, one or a few parameters to be estimated. As an example, consider that that the standard 'cartpole' reinforcement learning environment, where the aim is to move the cart left or right to balance a pole in the center of the cart without it tipping over, is solvable using deep reinforcement learning techniques, which can take 100s of episodes, or, it can be solved in 5 lines of code without any RL, given knowledge of Newtonian mechanics. Of course, in a real scientific problem, we may have to infer the underlying model from noisy measurements of the system, often sparsely in space and/or time.</p>
<p>Notably, the ML community is developing methods that can attempt to recover the underlying equations that generate the observations measured, through techniques such as symbolic regression. These are exemplified by the approach of the 'AI Feynman' proposed by Wu and Tegmark [205][206][207], amongst others [208,209]. In general, the applications of these techniques to microscopy are still very limited. For instance, it would be instructive to learn the force-fields from an atomically resolved STEM video of an amorphous material being crystallized by the electron beam, or of directly determining the energy of barriers for dopants imaged moving through a 3D lattice. Although much simpler in the static case [210], the extension to a fully dynamic system naturally tends to lead towards the need for large volumes of data, and careful tuning of thermodynamic variables to efficiently determine the likelihood of proposed models describing the dynamics.</p>
<p>Causal processes, interventions, and counterfactuals</p>
<p>Traditional causal discovery approaches assume that the observations are structured into elementary units representing random variables connected by a causal graph. In some cases, we may treat different modalities in multimodal SPM as such units. Practically, an image in each observational channel is split into patches at selected coordinates, followed by an established post-processing analysis to form appropriate structural and functional descriptors associated with such units. Then, one can deploy causal discovery models for finding causal links between various structural and functional parameters.</p>
<p>At the same time, in many experiments, the observations cannot be directly mapped onto a causal graph, and one must first uncover ('learn') in an unsupervised manner low-dimensional, high-level causal variables from high-dimensional, low-level observational data to allow for causal discovery. The emerging field of causal representation learning [211] aims at addressing this problem through an extension of the deep latent variables (correlative) models. The goal of deep latent variable models, such as (variational) autoencoder ((V)AE), is to explain high-dimensional observations by a small number of unobserved (latent) variables [212]. Recently, VAEs were used to uncover physical order parameters in lattice models and dynamic atomically resolved imaging data [182]. However, the latent variables in those VAE setups did not support intervention and reasoning. Recently, an approach based on self-supervised learning with data augmentation has been proposed to overcome this limitation of traditional deep latent variable models. In this approach, data augmentation acts as a counterfactual under a hypothetical intervention, allowing to separate content from style. We argue that in microscopy, one could replace data augmentations by changing various imaging parameters during the experiment to disentangle the real physical variables and use them for further causal discovery.</p>
<p>Future</p>
<p>Finally, we aim to summarize what these developments can bring to the classical physics, chemistry, and materials science fields, including both the extant ones, as well as new areas that may emerge based on these developments. While the list below is undoubtedly partial and new applications can be expected to be ideated and implemented, it nonetheless suggests an extremely broad potential for emerging science at the interface between ML and microscopy.</p>
<p>Learn physics</p>
<p>Traditional physics describes the structure of crystalline materials as ordering of building blocks (elementary unit cells) in a periodic lattice. These descriptors are conveniently matched to the information that can be obtained from scattering methods, and in turn allows exploring materials structure in the Fourier domain. However, many important materials such as highly defective solids, structural, spin, and cluster glasses, and ferroelectric relaxors do not have periodic structures [213,214]. While their structures can be visualized via electron microscopy, it is not clear what information can be derived from the knowledge of the atomic positions. Similar opportunities arise in the context of the electron microscopy of the extended defects and multiphase materials, STM of materials with complex topological and electronic orders, and even conventional SPM of ferroelectric and ferromagnetic domains and materials microstructures. The microscopy images are often spectacular, contain information on the specific aspects of materials structures and functionality, but extracting this information is non-trivial.</p>
<p>One approach to use these data is to train the generative statistical models such as VAEs and GANs, that can provide multiple examples of the microstructure from a smaller number of observations. However, such models typically extrapolate very poorly, meaning that the data acquired for specific set of conditions will not generalize to a different one. At the same time, the structural complexity of many materials strongly depends on temperature. For example, in materials undergoing order-disorder phase transition, correlation length (and hence the size of structural descriptor) diverges in the vicinity of phase transitions.</p>
<p>Comparatively, the complexity of observed structures and functionalities of solids emerges from relatively simple interactions. For atomic distributions in solid solutions and certain magnetic systems, these can be the variants of an Ising Hamiltonian, representing the interactions in the system via pairwise exchange integrals. For structurally amorphous systems, the system can be described via force fields acting between the atoms. Note that the modeling of the systems behavior from known force fields or Hamiltonians is the foundational part of computational physics. However, relevant materials parameters are usually derived ad hoc, or fit from a large body of macroscopic observations. Hence, the obvious challenge for the ML in physics is probabilistic learning of the atomic interactions on the level of lattice models, force fields from the observational data, or phase field free energies. These physical generative models can provide insight into the fundamental physics and chemistry of materials.</p>
<p>New chemistry</p>
<p>Synthetic organic chemistry is a cornerstone of fields ranging from drug and catalyst design to polymers. Applications of ML in chemical synthesis to understand the relationships between molecule structure and biological functionality, predict the synthesizability, and predict possible synthetic pathways from available components is one of the most rapidly developing scientific directions [218,219], via graph networks [5,220], etc. The rapid emergence of cloud laboratories provides a real-world implementation for in-silico developments. However, by its very nature chemical space is extremely high-dimensional, and exploring even specific classes of compounds often requires access to large number of initial compounds and ligands.</p>
<p>The emergence of imaging methods allows us to merge chemistry and characterization. The first definitive example of this synergy is the overlap between CryoEM and biology, where local structural information on biomolecules is now being used to design biological targets, etc. Electron microscopy methods can provide similar insights into the chemistry of solids. For example, STEM data can be used derive a library of possible defects in solids [176]. We can also extend this to explore whether we can chemically modify them and build reaction schemes on top of it as a pathway towards better catalysts, etc.</p>
<p>Nanophotonics and quantum optics</p>
<p>The wavelength of light, about half a micron, fundamentally limits its use in non-biological nanotechnology-hence the primary adoption of electrical signals to this day. Currently, using extreme ultraviolet exposure methods, the semiconductor industry has pushed the limits of creating nanoelectronic devices down to the 3∼nm node length, but such devices all rely on the use of electrons or holes for computations and information transfer, which inefficiently generate heat and is relatively slow. On the other hand, light propagates at the ultimate speed (of light!) and because photons do not have a rest mass, it does not lose energy to Joule heating. However, it cannot be easily confined to volumes smaller than the diffraction limit, or about 250 nm.</p>
<p>Plasmonics offers a tempting route to bridge the macro and nano scales with light by exploiting a quasiparticle known as the plasmon, which is light coupled to a collective electron wave at the interface of (usually) a metal and insulator, either propagating across an interface or localized to a small volume. The former is known as a surface plasmon polariton (SPP), while the latter is known as a localized surface plasmon resonance (LSPR). Intriguingly, a strong enhancement of the light can occur when it is coupled to the surface plasmon [221], making for a useful attribute. An idea for information transfer is that an incoming light source on the order of millimeters in size is focused down by ordinary means close to the diffraction limit and then partially transformed into a propagating wave (SPP) that is tens of nanometers in size, therefore the nature of the plasmon acts as a bridge between these two different length scales. Other applications take advantage of the LSPR in order to ensure extremely localized (and enhanced) light or heat sources. For example, in some cancer treatments, small nanoparticles may be placed in the body and then illuminated by a light source (to which the human body is transparent), which in turn excite LSPRs in the nanoparticles that act as tiny, localized heat sources to attack cancerous cells [222].</p>
<p>In terms of quantum optics, controlling the location, energy, and spatial extent of an emitter is of utmost importance, particularly in the rapidly developing field of quantum computing. Plasmonic nanoparticles can act as localized emitters that can in turn excite, for instance, a dye molecule which itself may be a single photon emitter. Alternatively, and perhaps of more utility, point defects in 2D materials like boron nitride [223] can also act as quantum emitters, and the electron beam can potentially be used to both create and probe such single defects.</p>
<p>The STEM then offers a unique and well-suited platform for nanophotonics [224]. From the point of view of measuring the light-matter interaction's energy dependence in space at the nanometer scale, STEM-EELS is the only currently available tool to spatially resolve the energy dependence of plasmon modes. A perfect corollary to the nano and atomic scale measurement capability is the ability of the STEM to geometrically sculpt or chemically modify a two-or three-dimensional solid such that it suits a specific plasmonic need, which can then be measured in STEM-EELS almost immediately.</p>
<p>However, realizing the full potential of STEM for nanophotonics and quantum optics requires solving the inverse design problem, i.e. what geometries and positioning/type of defects are necessary to induce the required functional responses. This space is ripe for exploration with ML methodologies [152], and one can envision both generative as well as reinforcement learning approaches to tackle this inverse problem, ideally incorporating simulations where necessary to reduce data requirements.</p>
<p>Atomic fabrication</p>
<p>Fabricating matter atom by atom has long remained the dream of scientific community. In his final note, Richard Feynman had famously written 'what I cannot create, I do not understand' [225]. It is clear that atomic fabrication [226][227][228][229] at scale is a pathway for quantum devices, new electronics, and serendipitous discoveries in multiple areas of science and technology.</p>
<p>Currently, both STM and STEM can be used to manipulate matter on the atomic scale, as have been demonstrated by multiple groups over time [67,230,231]. However, while the enabling instrumentation and the engineering controls are currently available, the operation of the microscopes is preponderantly enabled by human operator. This is a clear area where ML can make a tangible difference. For STM, the relevant tasks include tip conditioning and optimization, rapid sampling of surface electronic structure, investigating the electronic properties of individual atomic groups, physics discovery based on desired electronic signatures, and learning the rules of atomic manipulation towards specific functionalities and structures. Similar problems emerge in the STEM context, with added complexity of the higher stochasticity of the system.</p>
<p>Our vision</p>
<p>The last decade has seen the exponential growth of ML methods that by now have become an inseparable part of multiple scientific and applied domains. However, the emerging challenge in ML is a transition away from static data sets towards exploring active data generation processes and enabling autonomous systems, from automated cars to chemical design and synthesis. Each of these fields encounter problems related to the inability of classical ML to generalize and extrapolate. At the same time, many of these fields own specific physical interferential biases, are many hidden degrees of freedom, as well as exogenous variables.</p>
<p>We argue that microscopy platforms that operate in very simplified (compared to the macroscopic world) physical environments, and that are associated with strong physical biases and low risks, are ideal toy system for deployment of active learning algorithms, learning physics based digital twins, and many other applications. While these tools have traditionally been perceived to be highly specialized, over the last two decades microscopes have evolved to become significantly more user-friendly, with effective APIs and easy to use systems capable of visualizing matter from atomic to micron levels. Further, they are capable of a broad spectrum of actions, ranging from manipulation of nanoparticles and nanowires, to inducing local chemical reactions, and moving single atoms and making and breaking chemical bonds. From the domain perspective, the missing component is the algorithms that enabled controlled manipulation towards specific materials objectives. At the same time, from the ML perspective, these domains offer a challenging but bounded environment with characteristics ideal for development and deployment of active learning and reinforcement learning methods. In contrast to many other traditional environments (e.g. for robotics), these systems are associated with a reduced set of commands, low risk, and well understood physical biases and causal relationships, often with minimal exogenous effects. At some point, a Chat-GPT like system can be deployed at the edge to assist with operating a physical instrument such as a microscope. For example, it can be trained on a large dataset of instructions and common queries related to the operation of the instrument and measurement of different samples. This can allow the model to generate natural language responses to user queries and provide step-by-step instructions for operating the instrument for different type of samples/experiments. In addition, a ChatGPT-like system trained on scientific literature and relevant materials databases can dramatically accelerate the traditional hypothesis-experiment cycle by using AI to automatically generate hypotheses and integrate them into active learning models that 'drive' characterization experiments in microscopy. In other words, microscopy is all you need (to start).</p>
<p>Data availability statement</p>
<p>No new data were created or analyzed in this study.</p>
<p>Figure 2 .
2Figure 2. Principle of STEM as both a multimodal imaging tool and atomic manipulation tool. Schematic representation of electron path (a) as it interacts with a specimen and produces a variety of signals that may be detected, most standard of which is the annular dark field (ADF) signal. A magnetic prism (not shown) is typically at the end of the path that separates electrons based on energy lost (EELS) which is yet another signal. Examples of typical STEM imaging (b) where nanoparticles (left) down to single atoms in graphene (right) can be observed. Quantitative imaging example (c) by comparing ideal atom location with actual position, revealing slight displacements on the order of picometers of each cation (middle, blue dots) then visualized as a quiver plot (right) with implications in ferroelectric polarization and strain. Collection of electron energy loss spectrum (EELS) at each probe position in, for example, a chain of plasmonic nanoparticles (d) results in 3D data cube of which certain spectral components can be visualized as different spatially-resolved energy signals, represented here as different colors. In certain conditions, the electron beam can strongly interact with matter to the point of removing atoms from of the atomic lattice entirely (e) which allows to sculpt matter with atomic precision. Manipulation of matter at the atomic scale with single-atom specificity requires identification and classification of each atom followed by accurate positioning of electron beam onto desired sites, where (f) shows the formation of single vacancy lines (SVLs) in MoS2 by specifically knocking out single sulfur atoms in a designated pattern. Scale bars are (b) 20 nm (left) and 2 nm (right), (c) 1 nm, (d) 10 nm, (e) 5 nm, and (f) 1 nm ([64]. John Wiley &amp; Sons. © 2021 Wiley-VCH GmbH).</p>
<p>nm, (e) 5 nm, and (f) 1 nm ([64]. John Wiley &amp; Sons. © 2021 Wiley-VCH GmbH).</p>
<p>Figure 3 .
3Figure 3. Overview of the scanning probe microscopy (SPM) operation, which includes force-SPM and scanning tunneling microscopy (STM), (a) schematic of the force-SPM setup, (b) force-SPM topography image, reprinted from [61], with the permission of AIP Publishing, (c) force-SPM resonance frequency image, adapted with permission from [72]. (d) Schematic of STM setup, (e), (f) STM images of atomic defects in graphene (e) and molecular self-assembly (f).</p>
<p>Figure 4 .
4Electron beam sculpting of matter and its connection to its nanophotonic properties. Specific energetic features, represented by different colors, can be placed by the electron beam by sculpting nanoparticles into geometric shapes that support a desired nanophotonic property. Hyperspectral EELS image is acquired then decomposed into four dominant spectral components using non-negative matrix factorization (NMF) shown in (e), with corresponding abundance maps in (c). Scale bar in (a) 5 nm, (b) 10 nm, and (c) 20 nm.[64]. John Wiley &amp; Sons. © 2021 Wiley-VCH GmbH.</p>
<p>Figure 5 .
5Feature and property extraction with use of atomic coordinates. Polarization and strain fields may be calculated once atom columns are properly located and classified, for example a ferroelectric material shown in (a) has its cations (bright atoms, blue) distinguished from the rest of the lattice (dim atoms, red). The deviation of the cation from its ideal position yields a displacement vector which can be interpreted as a built-in polarization field. Atomic classification in other materials allows to identify subtle features at the single defect level, such as Stone-Wales defects or other topological ring defects in single layer graphene in (b), or sulfur vacancy lines in MoS2 in (c). Scale bar in (a) 2 nm, (b) and (c) both 1 nm. Reprinted with permission from[152]. Copyright (2022) American Chemical Society.</p>
<p>Figure 6 .
6DCNN and VAE investigation of ferroelectric domains in scanning probe microscopy. (a) Domains in a ferroelectric sample imaged by piezoresponse force microscopy, (b) ResHedNet converts the domain image to domain wall data. (c) VAE manifold2D representation shows that the ferroelectric domain walls pinning mechanism is related to ferroelastic domain walls distributions. (d) VAE manifold2D representation indicates the latent space is related to domain wall curvatures. [157] John Wiley &amp; Sons. © 2021 Wiley-VCH GmbH.</p>
<p>Figure 7 .
7(a) Force-SPM phase image shows domain structure in PbZr0.2Ti0.8O3. Reproduced from[215]. CC BY 4.0. (b) Force-SPM images of P3DT adsorbed on the surface of hBN. Reproduced from[216]. CC BY 4.0. (c) STEM image of disordered graphene, and force-distance curve. Reprinted with permission from[152]. Copyright (2022) American Chemical Society. (d) STEM of a MoS2doped with Re atoms, adapted with permission from[217] with a snapshot of the Ising model. Reprinted from[217], with the permission of AIP Publishing.</p>
<p>Table 1 .
1Microscopy is all you need (for now). Conduct actions (turns, navigation) Navigate to different parts of sample Navigate to different parts of sample Simulated drives for data collection Simulated images from scattering codesAutonomous driving 
Electron microscopy 
Scanning probe microscopy </p>
<p>Camera glitch 
Cosmic ray spark, electron gun 
change </p>
<p>Tip changes </p>
<p>Weird weather 
Unexpected surface contaminations 
Surface contamination 
Camera out of focus 
Microscope focus 
Setpoint setting/sample drift 
Optimize motor 
Tune the microscope 
Tune feedback 
Simulated images from phase-field 
models or density functional theory 
Collision 
E-beam induced sample damage 
Tip crashes into a surface 
N/A 
Modify material with electron beam 
Modify material with tip pressure or bias </p>
<p>AcknowledgmentsORCID iDsRama Vasudevan  https://orcid.org/0000-0003-4692-8579 Yongtao Liu  https://orcid.org/0000-0003-0152-1783 Ayana Ghosh  https://orcid.org/0000-0002-0432-3689 Maxim Ziatdinov  https://orcid.org/0000-0003-2570-4592
. E J Heravi, H Aghdam, D Puig, Ccia, Heravi E J, Aghdam H H and Puig D CCIA pp 163-8</p>
<p>ImageNet: a large-scale hierarchical image database 'CVPR09. J Deng, IEEE Computer SocietyMiami, Florida, USADeng J et al 2009 ImageNet: a large-scale hierarchical image database 'CVPR09' IEEE Computer Society (Miami, Florida, USA) pp 248-55</p>
<p>. Y Lecun, Y Bengio, G Hinton, 10.1038/nature14539Deep learning Nature. 521LeCun Y, Bengio Y and Hinton G 2015 Deep learning Nature 521 436-44</p>
<p>Deep learning in neural networks: an overview Neural Netw. J Schmidhuber, 10.1016/j.neunet.2014.09.00361Schmidhuber J 2015 Deep learning in neural networks: an overview Neural Netw. 61 85-117</p>
<p>Computer-assisted synthetic planning: the end of the beginning. S Szymkuc, E P Gajewska, T Klucznik, K Molga, P Dittwald, M Startek, M Bajczyk, B A Grzybowski, 10.1002/anie.201506101Angew. Chem., Int. Ed. 55Szymkuc S, Gajewska E P, Klucznik T, Molga K, Dittwald P, Startek M, Bajczyk M and Grzybowski B A 2016 Computer-assisted synthetic planning: the end of the beginning Angew. Chem., Int. Ed. 55 5904-37</p>
<p>Chemical robotics enabled exploration of stability in multicomponent lead halide perovskites via machine learning. K Higgins, S M Valleti, M Ziatdinov, S Kalinin, M Ahmadi, 10.1021/acsenergylett.0c01749ACS Energy Lett. 5Higgins K, Valleti S M, Ziatdinov M, Kalinin S V and Ahmadi M 2020 Chemical robotics enabled exploration of stability in multicomponent lead halide perovskites via machine learning ACS Energy Lett. 5 3426-36</p>
<p>K Higgins, M Ziatdinov, S Kalinin, M Ahmadi, arXiv:2106.03312High-throughput study of antisolvents on the stability of multicomponent metal halide perovskites through robotics-based synthesis and machine learning approaches. Higgins K, Ziatdinov M, Kalinin S V and Ahmadi M 2021 High-throughput study of antisolvents on the stability of multicomponent metal halide perovskites through robotics-based synthesis and machine learning approaches (arXiv:2106.03312)</p>
<p>Automated searching and identification of self-organized nanostructures. O M Gordon, J E A Hodgkinson, S M Farley, E Hunsicker, P J Moriarty, 10.1021/acs.nanolett.0c03213Nano Lett. 20Gordon O M, Hodgkinson J E A, Farley S M, Hunsicker E L and Moriarty P J 2020 Automated searching and identification of self-organized nanostructures Nano Lett. 20 7688-93</p>
<p>A Krizhevsky, I Sutskever, G E Hinton, ImageNet classification with deep convolutional neural networks Advances in Neural Information Processing Systems (NIPS 2012. 25Krizhevsky A, Sutskever I and Hinton G E 2012 ImageNet classification with deep convolutional neural networks Advances in Neural Information Processing Systems (NIPS 2012) vol 25</p>
<p>Molecular graph convolutions: moving beyond fingerprints. S Kearnes, K Mccloskey, M Berndl, V Pande, P Riley, 10.1007/s10822-016-9938-8J. Comput. Aided Mol. Des. 30Kearnes S, McCloskey K, Berndl M, Pande V and Riley P 2016 Molecular graph convolutions: moving beyond fingerprints J. Comput. Aided Mol. Des. 30 595-608</p>
<p>Attention is all you need Advances in neural information processing systems. A Vaswani, 30Vaswani A et al 2017 Attention is all you need Advances in neural information processing systems vol 30</p>
<p>D P Kingma, M Welling, arXiv:1312.6114Auto-encoding variational bayes. Kingma D P and Welling M 2013 Auto-encoding variational bayes (arXiv:1312.6114)</p>
<p>An introduction to variational autoencoders Found. D P Kingma, M Welling, 10.1561/2200000056Trends Mach. Learn. 12Kingma D P and Welling M 2019 An introduction to variational autoencoders Found. Trends Mach. Learn. 12 307-92</p>
<p>Variational autoencoders for new physics mining at the large hadron collider. O Cerri, T Q Nguyen, M Pierini, M Spiropulu, J R Vlimant, 10.1007/jhep05(2019)036J. High Energy Phys. 0536Cerri O, Nguyen T Q, Pierini M, Spiropulu M and Vlimant J R 2019 Variational autoencoders for new physics mining at the large hadron collider J. High Energy Phys. JHEP05(2019)036 36</p>
<p>. I Goodfellow, Generative adversarial nets. 27Goodfellow I et al 2014 Generative adversarial nets vol 27</p>
<p>Altered functional properties of the codling moth. Y V Bobkov, W Walker, Iii, A M Cattaneo, 10.1038/s41598-021-83024-3Orco mutagenized in the intracellular loop-3 Sci. Rep. 11Bobkov Y V, Walker W B III and Cattaneo A M 2021 Altered functional properties of the codling moth Orco mutagenized in the intracellular loop-3 Sci. Rep. 11 1-16</p>
<p>Lensless imaging of pollen grains at three-wavelengths using deep learning. Grant-Jacob J A Praeger, M Loxham, M Eason, R Mills, B , 10.1088/2515-7620/aba6d1Environ. Res. Commun. 275005Grant-Jacob J A, Praeger M, Loxham M, Eason R W and Mills B 2020 Lensless imaging of pollen grains at three-wavelengths using deep learning Environ. Res. Commun. 2 075005</p>
<p>Deep learning approach for Fourier ptychography microscopy. T Nguyen, Y Xue, Y Li, L Tian, G Nehmetallah, 10.1364/OE.26.026470Opt. Express. 26Nguyen T, Xue Y, Li Y, Tian L and Nehmetallah G 2018 Deep learning approach for Fourier ptychography microscopy Opt. Express 26 26470-84</p>
<p>Evaluation and development of deep neural networks for image super-resolution in optical microscopy. C Qiao, D Li, Y Guo, C Liu, T Jiang, Q Dai, D Li, 10.1038/s41592-020-01048-5Nat. Methods. 18Qiao C, Li D, Guo Y, Liu C, Jiang T, Dai Q and Li D 2021 Evaluation and development of deep neural networks for image super-resolution in optical microscopy Nat. Methods 18 194-202</p>
<p>Mastering Atari, Go, chess and shogi by planning with a learned model. J Schrittwieser, 10.1038/s41586-020-03051-4Nature. 588604Schrittwieser J et al 2020 Mastering Atari, Go, chess and shogi by planning with a learned model Nature 588 604</p>
<p>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. D Silver, 10.1126/science.aar6404Science. 3621140Silver D et al 2018 A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play Science 362 1140</p>
<p>C Berner, arXiv:1912.06680Dota 2 with large scale deep reinforcement learning. Berner C et al 2019 Dota 2 with large scale deep reinforcement learning (arXiv:1912.06680)</p>
<p>Learning dexterous in-hand manipulation. O Andrychowicz, 10.1177/0278364919887447Int. J. Rob. Res. 39Andrychowicz O M et al 2020 Learning dexterous in-hand manipulation Int. J. Rob. Res. 39 3-20</p>
<p>Autonomous navigation of stratospheric balloons using reinforcement learning. M G Bellemare, S Candido, P S Castro, J Gong, M C Machado, S Moitra, S Ponda, Z Wang, 10.1038/s41586-020-2939-8Nature. 588Bellemare M G, Candido S, Castro P S, Gong J, Machado M C, Moitra S, Ponda S S and Wang Z 2020 Autonomous navigation of stratospheric balloons using reinforcement learning Nature 588 77-82</p>
<p>A logical calculus of the ideas immanent in nervous activity. W S Mcculloch, W Pitts, 10.1007/BF02478259Bull. Math. Biophys. 5McCulloch W S and Pitts W 1943 A logical calculus of the ideas immanent in nervous activity Bull. Math. Biophys. 5 115-33</p>
<p>30 Years of adaptive neural networks: perceptron. Madaline, and backpropagation Proc. B Widrow, M A Lehr, 10.1109/5.58323IEEE. 78Widrow B and Lehr M A 1990 30 Years of adaptive neural networks: perceptron. Madaline, and backpropagation Proc. IEEE 78 1415-42</p>
<p>F Rosenblatt, Principles of Neurodynamics. Perceptrons and the Theory of Brain Mechanisms. Buffalo, NYCornell Aeronautical Lab IncRosenblatt F 1961 Principles of Neurodynamics. Perceptrons and the Theory of Brain Mechanisms (Buffalo, NY: Cornell Aeronautical Lab Inc)</p>
<p>Artificial nose and data analysis using multi layer perceptron WIT Trans. M Santos, T Ludermir, F Santos, C P De Melo, J Gomes, Inf. Commun. Technol. 22Santos M, Ludermir T, Santos F, de Melo C P and Gomes J 1970 Artificial nose and data analysis using multi layer perceptron WIT Trans. Inf. Commun. Technol. 22</p>
<p>Learning representations by back-propagating errors. D E Rumelhart, G Hinton, R J Williams, 10.1038/323533a0Nature. 323Rumelhart D E, Hinton G E and Williams R J 1986 Learning representations by back-propagating errors Nature 323 533-6</p>
<p>Punish/reward: learning with a critic in adaptive threshold systems. B Widrow, N Gupta, S Maitra, IEEE Trans. Syst. Man Cybern. 3Widrow B, Gupta N K and Maitra S 1973 Punish/reward: learning with a critic in adaptive threshold systems IEEE Trans. Syst. Man Cybern. 3 455-65</p>
<p>R S Sutton, A G Barto, Reinforcement Learning: An Introduction. Cambridge, MAMIT PressSutton R S and Barto A G 2018 Reinforcement Learning: An Introduction (Cambridge, MA: MIT Press)</p>
<p>. C J C Watkins, H1989, Watkins C J C H1989 Learning from delayed rewards</p>
<p>Long short-term memory Neural Comput. S Hochreiter, J Schmidhuber, 10.1162/neco.1997.9.8.17359Hochreiter S and Schmidhuber J 1997 Long short-term memory Neural Comput. 9 1735-80</p>
<p>Evolution of the graphics processing unit (GPU). W J Dally, S Keckler, D B Kirk, 10.1109/MM.2021.3113475IEEE Micro. 41Dally W J, Keckler S W and Kirk D B 2021 Evolution of the graphics processing unit (GPU) IEEE Micro 41 42-51</p>
<p>. L Deng, Deng L 2012</p>
<p>Learning multiple layers of features from tiny images. A Krizhevsky, G Hinton, Krizhevsky A and Hinton G 2009 Learning multiple layers of features from tiny images</p>
<p>L Schatzki, A Arrasmith, P Coles, M Cerezo, arXiv:2109.03400Entangled datasets for quantum machine learning. Schatzki L, Arrasmith A, Coles P J and Cerezo M 2021 Entangled datasets for quantum machine learning (arXiv:2109.03400)</p>
<p>M Prabhat, AGU fall meeting abstracts. Prabhat M et al 2017 AGU fall meeting abstracts IN13E-01</p>
<p>HadUK-Grid-a new UK dataset of gridded climate observations Geosci. D Hollis, M Mccarthy, M Kendon, T Legg, I Simpson, 10.1002/gdj3.78Data J. 6Hollis D, McCarthy M, Kendon M, Legg T and Simpson I 2019 HadUK-Grid-a new UK dataset of gridded climate observations Geosci. Data J. 6 151-9</p>
<p>Extremeweather: a large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events. E Racah, Advances in Neural Information Processing Systems. 30Racah E et al 2017 Extremeweather: a large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events Advances in Neural Information Processing Systems vol 30</p>
<p>SuperMat: construction of a linked annotated dataset from superconductors-related publications Sci. L Foppiano, 10.1080/27660400.2021.1918396Adv. Mater. 1TechnolFoppiano L et al 2021 SuperMat: construction of a linked annotated dataset from superconductors-related publications Sci. Technol. Adv. Mater. 1 34-44</p>
<p>Expanded dataset of mechanical properties and observed phases of multi-principal element alloys. C K H Borg, C Frey, J Moh, T M Pollock, S Gorsse, D B Miracle, O N Senkov, Meredig B Saal, J E , 10.1038/s41597-020-00768-9Sci. Data. 7Borg C K H, Frey C, Moh J, Pollock T M, Gorsse S, Miracle D B, Senkov O N, Meredig B and Saal J E 2020 Expanded dataset of mechanical properties and observed phases of multi-principal element alloys Sci. Data 7 1-6</p>
<p>Recent advances and applications of deep learning methods in materials science npj. K Choudhary, 10.1038/s41524-022-00734-6Comput. Mater. 8Choudhary K et al 2022 Recent advances and applications of deep learning methods in materials science npj Comput. Mater. 8 1-26</p>
<p>Rebooting AI: Building Artificial Intelligence We Can Trust (Vintage). G Marcus, E Davis, Marcus G and Davis E 2019 Rebooting AI: Building Artificial Intelligence We Can Trust (Vintage)</p>
<p>Language models are few-shot learners. T Brown, Adv. Neural Inf. Process. Syst. 33Brown T et al 2020 Language models are few-shot learners Adv. Neural Inf. Process. Syst. 33 1877-901</p>
<p>. K Quach, Quach K 2020</p>
<p>D Amodei, arXiv:1606.06565Concrete problems in AI safety. Amodei D et al 2016 Concrete problems in AI safety (arXiv:1606.06565)</p>
<p>A Nguyen, J Yosinski, J Clune, Deep neural networks are easily fooled: high confidence predictions for unrecognizable images Proc. IEEE conference on Conf. on Computer Vision and Pattern Recognition pp. Nguyen A, Yosinski J and Clune J 2015 Deep neural networks are easily fooled: high confidence predictions for unrecognizable images Proc. IEEE conference on Conf. on Computer Vision and Pattern Recognition pp 427-36</p>
<p>I Gulrajani, D Lopez-Paz, arXiv:2007.01434search of lost domain generalization. Gulrajani I and Lopez-Paz D 2020 In search of lost domain generalization (arXiv:2007.01434)</p>
<p>Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study. J R Zech, M A Badgeley, M Liu, A B Costa, J Titano, E K Oermann, 10.1371/journal.pmed.1002683PLoS Med. 151002683Zech J R, Badgeley M A, Liu M, Costa A B, Titano J J and Oermann E K 2018 Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study PLoS Med. 15 e1002683</p>
<p>Understanding the failure modes of out-of-distribution generalization. V Nagarajan, A Andreassen, B Neyshabur, arXiv:2010.15775Nagarajan V, Andreassen A and Neyshabur B 2020 Understanding the failure modes of out-of-distribution generalization (arXiv:2010.15775)</p>
<p>S Beery, Perona Van Horn G And, Recognition in terra incognita Proc. European Conf. on Computer Vision (ECCV). Beery S, Van Horn G and Perona P 2018 Recognition in terra incognita Proc. European Conf. on Computer Vision (ECCV) pp 456-73</p>
<p>Deep learning of atomically resolved scanning transmission electron microscopy images: chemical identification and tracking local transformations. M Ziatdinov, O Dyck, A Maksov, X Li, X Sang, K Xiao, R R Unocic, R Vasudevan, Jesse S Kalinin, S V , 10.1021/acsnano.7b07504ACS Nano. 11Ziatdinov M, Dyck O, Maksov A, Li X, Sang X, Xiao K, Unocic R R, Vasudevan R, Jesse S and Kalinin S V 2017 Deep learning of atomically resolved scanning transmission electron microscopy images: chemical identification and tracking local transformations ACS Nano 11 12742-52</p>
<p>Learning a similarity metric discriminatively, with application to face verification. S Chopra, R Hadsell, Y Lecun, 10.1109/CVPR.2005.202IEEE Computer Society Conf. on Computer Vision and Pattern Recognition (CVPR'05). 531Chopra S, Hadsell R and LeCun Y 2005 Learning a similarity metric discriminatively, with application to face verification 2005 IEEE Computer Society Conf. on Computer Vision and Pattern Recognition (CVPR'05) vol 531 pp 539-46</p>
<p>Barlow twins: self-supervised learning via redundancy reduction Int. J Zbontar, L Jing, I Misra, Y Lecun, S Deny, Conf. on Machine Learning pp. Zbontar J, Jing L, Misra I, LeCun Y and Deny S 2021 Barlow twins: self-supervised learning via redundancy reduction Int. Conf. on Machine Learning pp 12310-20</p>
<p>B Lakshminarayanan, A Pritzel, C Blundell, Proc. 31st Int. Conf. on Neural Information Processing Syst. 31st Int. Conf. on Neural Information essing SystLong Beach, CACurran Associates IncLakshminarayanan B, Pritzel A and Blundell C 2017 Proc. 31st Int. Conf. on Neural Information Processing Syst. (Long Beach, CA: Curran Associates Inc.) pp 6405-16</p>
<p>M Arjovsky, L Bottou, Gulrajani I Lopez-Paz, D , arXiv:1907.02893Invariant risk minimization. Arjovsky M, Bottou L, Gulrajani I and Lopez-Paz D 2019 Invariant risk minimization (arXiv:1907.02893)</p>
<p>A path towards autonomous machine intelligence version 0. Y Lecun, 10.1016/j.neunet.2022.03.0379LeCun Y 2022 A path towards autonomous machine intelligence version 0.9. 2 (Accessed 27 June 2022) (https://doi.org/ 10.1016/j.neunet.2022.03.037)</p>
<p>Off-the-shelf deep learning is not enough, and requires parsimony. R K Vasudevan, M Ziatdinov, L Vlcek, S V Kalinin, 10.1038/s41524-020-00487-0Bayesianity, and causality npj Comput. Mater. 76Vasudevan R K, Ziatdinov M, Vlcek L and Kalinin S V 2021 Off-the-shelf deep learning is not enough, and requires parsimony, Bayesianity, and causality npj Comput. Mater. 7 6</p>
<p>Why big data and compute are not necessarily the path to big materials science. N Fujinuma, B Decost, J Hattrick-Simpers, S E Lofland, 10.1038/s43246-022-00283-xCommun. Mater. 3Fujinuma N, DeCost B, Hattrick-Simpers J and Lofland S E 2022 Why big data and compute are not necessarily the path to big materials science Commun. Mater. 3 1-9</p>
<p>Exploring leakage in dielectric films via automated experiments in scanning probe microscopy. Y Liu, S S Fields, T Mimura, K P Kelley, S Trolier-Mckinstry, J Ihlefeld, S V Kalinin, 10.1063/5.0079217Appl. Phys. Lett. 120182903Liu Y, Fields S S, Mimura T, Kelley K P, Trolier-mckinstry S, Ihlefeld J F and Kalinin S V 2022 Exploring leakage in dielectric films via automated experiments in scanning probe microscopy Appl. Phys. Lett. 120 182903</p>
<p>. S J Pennycook, P D Nellist, SpringerNew YorkPennycook S J and Nellist P D 2011 (New York: Springer)</p>
<p>. A B Yankovich, B Berkels, W Dahmen, P Binev, S I Sanchez, S A Bradley, A Li, I Szlufarska, P M Voyles, Yankovich A B, Berkels B, Dahmen W, Binev P, Sanchez S I, Bradley S A, Li A, Szlufarska I and Voyles P M 2014</p>
<p>Picometre-precision analysis of scanning transmission electron microscopy images of platinum nanocatalysts. 10.1038/ncomms5155Nat. Commun. 54155Picometre-precision analysis of scanning transmission electron microscopy images of platinum nanocatalysts Nat. Commun. 5 4155</p>
<p>Sculpting the plasmonic responses of nanoparticles by directed electron beam irradiation. K M Roccapriore, S-H Cho, A R Lupini, D Milliron, S V Kalinin, 10.1002/smll.202105099Small. 182105099Roccapriore K M, Cho S-H, Lupini A R, Milliron D J and Kalinin S V 2022 Sculpting the plasmonic responses of nanoparticles by directed electron beam irradiation Small 18 2105099</p>
<p>Spectroscopic imaging of single atoms within a bulk solid. M Varela, 10.1103/PhysRevLett.92.095502Phys. Rev. Lett. 9295502Varela M et al 2004 Spectroscopic imaging of single atoms within a bulk solid Phys. Rev. Lett. 92 095502</p>
<p>. S V Kalinin, A Borisevich, Jesse S , 10.1038/539485aNature. 539Kalinin S V, Borisevich A and Jesse S 2016 Fire up the atom forge Nature 539 485-7</p>
<p>Atom-by-atom fabrication with electron beams. O Dyck, M Ziatdinov, D B Lingerfelt, R R Unocic, B M Hudak, A R Lupini, Jesse S Kalinin, S V , 10.1038/s41578-019-0118-zNat. Rev. Mater. 4Dyck O, Ziatdinov M, Lingerfelt D B, Unocic R R, Hudak B M, Lupini A R, Jesse S and Kalinin S V 2019 Atom-by-atom fabrication with electron beams Nat. Rev. Mater. 4 497-507</p>
<p>Placing single atoms in graphene with a scanning transmission electron microscope. O Dyck, S Kim, S Kalinin, Jesse S , 10.1063/1.4998599Appl. Phys. Lett. 111113104Dyck O, Kim S, Kalinin S V and Jesse S 2017 Placing single atoms in graphene with a scanning transmission electron microscope Appl. Phys. Lett. 111 113104</p>
<p>Towards atomically precise manipulation of 2D nanostructures in the electron microscope 2D Mater. T Susi, D Kepaptsoglou, Y-C Lin, Q M Ramasse, J C Meyer, K Suenaga, J Kotakoski, 10.1088/2053-1583/aa878f442004Susi T, Kepaptsoglou D, Lin Y-C, Ramasse Q M, Meyer J C, Suenaga K and Kotakoski J 2017 Towards atomically precise manipulation of 2D nanostructures in the electron microscope 2D Mater. 4 042004</p>
<p>. O Dyck, S Kim, E Jimenez-Izal, A N Alexandrova, S Kalinin, Jesse S , 10.1002/smll.201801771Small. 141801771Dyck O, Kim S, Jimenez-Izal E, Alexandrova A N, Kalinin S V and Jesse S 2018 Building structures atom by atom via electron beam manipulation Small 14 1801771</p>
<p>Direct atomic fabrication and dopant positioning in Si using electron beams with active real-time image-based feedback. S Jesse, 10.1088/1361-6528/aabb79Nanotechnology. 29255303Jesse S et al 2018 Direct atomic fabrication and dopant positioning in Si using electron beams with active real-time image-based feedback Nanotechnology 29 255303</p>
<p>Band excitation in scanning probe microscopy: sines of change. Jesse S Kalinin, S V , 10.1088/0022-3727/44/46/464006J. Phys. D: Appl. Phys. 44464006Jesse S and Kalinin S V 2011 Band excitation in scanning probe microscopy: sines of change J. Phys. D: Appl. Phys. 44 464006</p>
<p>Force measurements with the atomic force microscope: technique, interpretation and applications Surf. H Butt, Cappella B Kappl, 10.1016/j.surfrep.2005.08.003Sci. Rep. 59Butt H, Cappella B and Kappl. M 2005 Force measurements with the atomic force microscope: technique, interpretation and applications Surf. Sci. Rep. 59 1-152</p>
<p>. G Binnig, C Quate, C Gerber, 10.1103/PhysRevLett.56.930ATOMIC FORCE MICROSCOPE Phys. Rev. Lett. 56Binnig G, Quate C F and Gerber C 1986 ATOMIC FORCE MICROSCOPE Phys. Rev. Lett. 56 930-3</p>
<p>Frequency-modulation detection using high-q cantilevers for enhanced force microscope sensitivity. T R Albrecht, P Grutter, D Horne, D Rugar, 10.1063/1.347347J. Appl. Phys. 69Albrecht T R, Grutter P, Horne D and Rugar D 1991 Frequency-modulation detection using high-q cantilevers for enhanced force microscope sensitivity J. Appl. Phys. 69 668-73</p>
<p>Magnetic dissipation force microscopy. P Grutter, Y Liu, P Leblanc, U Durig, 10.1063/1.119519Appl. Phys. Lett. 71Grutter P, Liu Y, LeBlanc P and Durig U 1997 Magnetic dissipation force microscopy Appl. Phys. Lett. 71 279-81</p>
<p>Magnetic-field measurements of current-carrying devices by force-sensitive magnetic-force microscopy with potential correction. T Alvarez, S Kalinin, D A Bonnell, 10.1063/1.1345818Appl. Phys. Lett. 78Alvarez T, Kalinin S V and Bonnell D A 2001 Magnetic-field measurements of current-carrying devices by force-sensitive magnetic-force microscopy with potential correction Appl. Phys. Lett. 78 1005-7</p>
<p>Kelvin probe force microscopy for characterization of semiconductor devices and processes. M Tanimoto, 10.1116/1.589136J. Vac. Sci. Technol. B. 14Tanimoto M 1996 Kelvin probe force microscopy for characterization of semiconductor devices and processes J. Vac. Sci. Technol. B 14 1547-51</p>
<p>Space-and time-resolved mapping of ionic dynamic and electroresistive phenomena in lateral devices. E Strelcov, Jesse S Huang, Y-L Teng, Y-C Kravchenko, I I Chu, Y-H Kalinin, S V , 10.1021/nn4017873ACS Nano. 7Strelcov E, Jesse S, Huang Y-L, Teng Y-C, Kravchenko I I, Chu Y-H and Kalinin S V 2013 Space-and time-resolved mapping of ionic dynamic and electroresistive phenomena in lateral devices ACS Nano 7 6806-15</p>
<p>Acoustic microscopy by atomic-force microscopy. U Rabe, W Arnold, 10.1063/1.111869Appl. Phys. Lett. 64Rabe U and Arnold W 1994 Acoustic microscopy by atomic-force microscopy Appl. Phys. Lett. 64 1493-5</p>
<p>Electromechanical imaging and spectroscopy of ferroelectric and piezoelectric materials: state of the art and prospects for the future. N Balke, I Bdikin, S Kalinin, A L Kholkin, 10.1111/j.1551-2916.2009.03240.xJ. Am. Ceram. Soc. 92Balke N, Bdikin I, Kalinin S V and Kholkin A L 2009 Electromechanical imaging and spectroscopy of ferroelectric and piezoelectric materials: state of the art and prospects for the future J. Am. Ceram. Soc. 92 1629-47</p>
<p>High velocity, low-voltage collective in-plane switching in (100) BaTiO3 thin films. T Raeder, 10.1002/advs.202201530Adv. Sci. 92201530Raeder T M et al High velocity, low-voltage collective in-plane switching in (100) BaTiO3 thin films Adv. Sci. 9 2201530</p>
<p>. J Shin, V Meunier, A Baddorf, S V Kalinin, 10.1063/1.1812372Nonlinear transport imaging by scanning impedance microscopy Appl. Phys. Lett. 85Shin J, Meunier V, Baddorf A P and Kalinin S V 2004 Nonlinear transport imaging by scanning impedance microscopy Appl. Phys. Lett. 85 4240-2</p>
<p>Nano-chemistry and scanning probe nanolithographies. R Garcia, R Martinez, J Martinez, 10.1039/b501599pChem. Soc. Rev. 35Garcia R, Martinez R V and Martinez J 2006 Nano-chemistry and scanning probe nanolithographies Chem. Soc. Rev. 35 29-38</p>
<p>Quantitative analysis of the bit size dependence on the pulse width and pulse voltage in ferroelectric memory devices using atomic force microscopy. J Woo, S Hong, N Setter, H Shin, J-U Jeon, Y Pak, K No, 10.1116/1.1364697J. Vac. Sci. Technol. B. 19Woo J, Hong S, Setter N, Shin H, Jeon J-U, Pak Y E and No K 2001 Quantitative analysis of the bit size dependence on the pulse width and pulse voltage in ferroelectric memory devices using atomic force microscopy J. Vac. Sci. Technol. B 19 818-24</p>
<p>. A Requicha, IEEE Int. Conf. Robotics and Automation. IEEERequicha A A G et al 1998 IEEE Int. Conf. Robotics and Automation (IEEE) pp 3368-74</p>
<p>A Requicha, 10.1109/jproc.2003.818333NEMS, and nanoassembly Proc. IEEE. 91Requicha A A G 2003 Nanorobots, NEMS, and nanoassembly Proc. IEEE 91 1922-33</p>
<p>Robotic nanomanipulation with a scanning probe microscope in a networked computing environment. C Baur, 10.1116/1.589404J. Vac. Sci. Technol. B. 15Baur C et al 1997 Robotic nanomanipulation with a scanning probe microscope in a networked computing environment J. Vac. Sci. Technol. B 15 1577-80</p>
<p>Development of nanomanipulator using a high-speed atomic force microscope coupled with a haptic device. F Iwata, Y Ohashi, I Ishisaki, L Picco, T Ushiki, 10.1016/j.ultramic.2013.06.014Ultramicroscopy. 133Iwata F, Ohashi Y, Ishisaki I, Picco L M and Ushiki T 2013 Development of nanomanipulator using a high-speed atomic force microscope coupled with a haptic device Ultramicroscopy 133 88-94</p>
<p>Investigation and modification of molecular structures with the nanoManipulator. M Guthold, 10.1016/s1093-3263(99)00030-3J. Mol. Graph. 17Guthold M et al 1999 Investigation and modification of molecular structures with the nanoManipulator J. Mol. Graph. 17 187-97</p>
<p>Nanomanipulation experiments exploring frictional and mechanical properties of carbon nanotubes Microsc. M R Falvo, G Clary, A Helser, S Paulson, R M Taylor, Chi V Brooks, F P Washburn, S Superfine, R , 10.1017/s1431927698980485Falvo M R, Clary G, Helser A, Paulson S, Taylor R M, Chi V, Brooks F P, Washburn S and Superfine R 1998 Nanomanipulation experiments exploring frictional and mechanical properties of carbon nanotubes Microsc. Microanal. 4 504-12</p>
<p>. G Binnig, H Rohrer, Scanning tunneling microscopy Helv. Phys. Acta. 55Binnig G and Rohrer H 1982 Scanning tunneling microscopy Helv. Phys. Acta 55 726-35</p>
<p>7X7 reconstruction on SI(111) resolved in real space. G Binnig, H Rohrer, C Gerber, E Weibel, 10.1103/PhysRevLett.50.120Phys. Rev. Lett. 50Binnig G, Rohrer H, Gerber C and Weibel E 1983 7X7 reconstruction on SI(111) resolved in real space Phys. Rev. Lett. 50 120-3</p>
<p>Scanning tunneling microscopy-from birth to adolescence. G Binnig, H Rohrer, 10.1103/RevModPhys.59.615Rev. Mod. Phys. 59Binnig G and Rohrer H 1987 Scanning tunneling microscopy-from birth to adolescence Rev. Mod. Phys. 59 615-25</p>
<p>Positioning single atoms with a scanning tunnelling microscope. D M Eigler, E K Schweizer, 10.1038/344524a0Nature. 344Eigler D M and Schweizer E K 1990 Positioning single atoms with a scanning tunnelling microscope Nature 344 524-6</p>
<p>Atomically precise placement of single dopants in Si. S R Schofield, N J Curson, M Y Simmons, F J Rueß, Hallam T , Oberbeck L Clark, R G , 10.1103/PhysRevLett.91.136104Phys. Rev. Lett. 91136104Schofield S R, Curson N J, Simmons M Y, Rueß F J, Hallam T, Oberbeck L and Clark R G 2003 Atomically precise placement of single dopants in Si Phys. Rev. Lett. 91 136104</p>
<p>A two-qubit gate between phosphorus donor electrons in silicon. Y He, S K Gorman, D Keith, L Kranz, J Keizer, M Y Simmons, 10.1038/s41586-019-1381-2Nature. 571He Y, Gorman S K, Keith D, Kranz L, Keizer J G and Simmons M Y 2019 A two-qubit gate between phosphorus donor electrons in silicon Nature 571 371-5</p>
<p>Big, deep, and smart data in scanning probe microscopy. S Kalinin, 10.1021/acsnano.6b04212ACS Nano. 10Kalinin S V et al 2016 Big, deep, and smart data in scanning probe microscopy ACS Nano 10 9068-86</p>
<p>Big-deep-smart data in imaging for guiding materials design. S V Kalinin, B Sumpter, Archibald R K , 10.1038/nmat4395Nat. Mater. 14973Kalinin S V, Sumpter B G and Archibald R K 2015 Big-deep-smart data in imaging for guiding materials design Nat. Mater. 14 973</p>
<p>Towards data-driven next-generation transmission electron microscopy. S Spurgeon, 10.1038/s41563-020-00833-zNat. Mater. 20Spurgeon S R et al 2021 Towards data-driven next-generation transmission electron microscopy Nat. Mater. 20 274-9</p>
<p>Application of a long short-term memory for deconvoluting conductance contributions at charged ferroelectric domain walls npj. T Holstad, 10.1038/s41524-020-00426-zComput. Mater. 6Holstad T S et al 2020 Application of a long short-term memory for deconvoluting conductance contributions at charged ferroelectric domain walls npj Comput. Mater. 6 1-7</p>
<p>Nion swift: open source image processing software for instrument control, data acquisition, organization, visualization, and analysis using Python Microsc. Microanal. C Meyer, N Dellby, J A Hachtel, T Lovejoy, A Mittelberger, O Krivanek, 10.1017/S143192761900134X25Meyer C, Dellby N, Hachtel J A, Lovejoy T, Mittelberger A and Krivanek O 2019 Nion swift: open source image processing software for instrument control, data acquisition, organization, visualization, and analysis using Python Microsc. Microanal. 25 122-3</p>
<p>. Pyjem, PyJEM (available at: https://github.com/PyJEM/PyJEM)</p>
<p>Pycro-manager: open-source software for customized and reproducible microscope control. H Pinkard, 10.1038/s41592-021-01087-6Nat. Methods. 18Pinkard H et al 2021 Pycro-manager: open-source software for customized and reproducible microscope control Nat. Methods 18 226-8</p>
<p>Large field-induced strains in a lead-free piezoelectric material. J Zhang, 10.1038/nnano.2010.265Nat. Nanotechnol. 6Zhang J X et al 2011 Large field-induced strains in a lead-free piezoelectric material Nat. Nanotechnol. 6 97-101</p>
<p>Adaptive probe trajectory scanning probe microscopy for multiresolution measurements of interface geometry. O S Ovchinnikov, Jesse S Kalinin, S V , 10.1088/0957-4484/20/25/255701Nanotechnology. 20255701Ovchinnikov O S, Jesse S and Kalinin S V 2009 Adaptive probe trajectory scanning probe microscopy for multiresolution measurements of interface geometry Nanotechnology 20 255701</p>
<p>Full data acquisition in Kelvin probe force microscopy: mapping dynamic electric phenomena in real space. L Collins, A Belianinov, S Somnath, N Balke, S Kalinin, Jesse S , 10.1038/srep30557Sci. Rep. 630557Collins L, Belianinov A, Somnath S, Balke N, Kalinin S V and Jesse S 2016 Full data acquisition in Kelvin probe force microscopy: mapping dynamic electric phenomena in real space Sci. Rep. 6 30557</p>
<p>R Vasudevan, Gordon Research Conf. on Computational Materials Science and Engineering. Vasudevan R K 2022 2022 Gordon Research Conf. on Computational Materials Science and Engineering</p>
<p>T R Meyer, D Ziegler, C Brune, A Chen, R Farnham, N Huynh, J-M Chang, A Bertozzi, P D Ashby, 10.1016/j.ultramic.2013.10.014Height drift correction in non-raster atomic force microscopy Ultramicroscopy. 137Meyer T R, Ziegler D, Brune C, Chen A, Farnham R, Huynh N, Chang J-M, Bertozzi A L and Ashby P D 2014 Height drift correction in non-raster atomic force microscopy Ultramicroscopy 137 48-54</p>
<p>Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization. K P Kelley, M Ziatdinov, L Collins, M A Susner, R K Vasudevan, N Balke, S Kalinin, Jesse S , 10.1002/smll.202002878Small. 16Kelley K P, Ziatdinov M, Collins L, Susner M A, Vasudevan R K, Balke N, Kalinin S V and Jesse S 2020 Fast scanning probe microscopy via machine learning: non-rectangular scans with compressed sensing and Gaussian process optimization Small 16 2002878</p>
<p>Applying compressive sensing to TEM video: a substantial frame rate increase on any camera Adv. A Stevens, L Kovarik, P Abellan, X Yuan, Carin L Browning, N D , 10.1186/s40679-015-0009-3Struct. Chem. Imaging. 1Stevens A, Kovarik L, Abellan P, Yuan X, Carin L and Browning N D 2015 Applying compressive sensing to TEM video: a substantial frame rate increase on any camera Adv. Struct. Chem. Imaging 1 1-20</p>
<p>Role of 90 degrees domains in lead zirconate titanate thin films. C S Ganpule, V Nagarajan, H Li, A S Ogale, D E Steinhauer, S Aggarwal, Williams E , Ramesh R , De Wolf, P , 10.1063/1.126954Appl. Phys. Lett. 77Ganpule C S, Nagarajan V, Li H, Ogale A S, Steinhauer D E, Aggarwal S, Williams E, Ramesh R and De Wolf P 2000 Role of 90 degrees domains in lead zirconate titanate thin films Appl. Phys. Lett. 77 292-4</p>
<p>Cloud labs: where robots do the research. C Arnold, 10.1038/d41586-022-01618-xNat. Mater. 606Arnold C 2022 Cloud labs: where robots do the research Nat. Mater. 606 612-3</p>
<p>WSXM: a software for scanning probe microscopy and a tool for nanotechnology. I Horcas, R Fernández, J M Gómez-Rodríguez, J Colchero, J Gómez-Herrero, A M Baro, 10.1063/1.2432410Rev. Sci. Instrum. 7813705Horcas I, Fernández R, Gómez-Rodríguez J M, Colchero J, Gómez-Herrero J and Baro A M 2007 WSXM: a software for scanning probe microscopy and a tool for nanotechnology Rev. Sci. Instrum. 78 013705</p>
<p>Gwyddion: an open-source software for SPM data analysis Open Phys. D Nečas, P Klapetek, 10.2478/s11534-011-0096-210Nečas D and Klapetek P 2012 Gwyddion: an open-source software for SPM data analysis Open Phys. 10 181-8</p>
<p>Scholder, scholi/pySPM: pySPM v0. 216Version v0.2.16Scholder O 2018 scholi/pySPM: pySPM v0.2.16 (Version v0.2.16)</p>
<p>. Scifireaders, 118] sidpy 2022SciFiReaders [118] sidpy 2022</p>
<p>Electron microscopy (big and small) data analysis with the open source software package. F De La Peña, 10.1017/S1431927617001751HyperSpy Microsc. Microanal. 23de la Peña F et al 2017 Electron microscopy (big and small) data analysis with the open source software package HyperSpy Microsc. Microanal. 23 214-5</p>
<p>Robotic microscopy for everyone: the OpenFlexure microscope. J Collins, 10.1364/BOE.385729Biomed. Opt. Express. 11Collins J T et al 2020 Robotic microscopy for everyone: the OpenFlexure microscope Biomed. Opt. Express 11 2447-60</p>
<p>A survey on bias and fairness in machine learning ACM. N Mehrabi, F Morstatter, N Saxena, K Lerman, A Galstyan, 10.1145/3457607Comput. Surv. 54Mehrabi N, Morstatter F, Saxena N, Lerman K and Galstyan A 2021 A survey on bias and fairness in machine learning ACM Comput. Surv. 54 1-35</p>
<p>Invited Article: VEDA: a web-based virtual environment for dynamic atomic force microscopy. J Melcher, S Hu, A Raman, 10.1063/1.2938864Rev. Sci. Instrum. 7961301Melcher J, Hu S and Raman A 2008 Invited Article: VEDA: a web-based virtual environment for dynamic atomic force microscopy Rev. Sci. Instrum. 79 061301</p>
<p>Mastering the game of Go without human knowledge. D Silver, 10.1038/nature24270Nature. 550354Silver D et al 2017 Mastering the game of Go without human knowledge Nature 550 354</p>
<p>Three-dimensional imaging of localized surface plasmon resonances of metal nanoparticles. O Nicoletti, F De La Peña, R K Leary, D J Holland, C Ducati, P A Midgley, 10.1038/nature12469Nature. 502Nicoletti O, de la Peña F, Leary R K, Holland D J, Ducati C and Midgley P A 2013 Three-dimensional imaging of localized surface plasmon resonances of metal nanoparticles Nature 502 80-84</p>
<p>Three-dimensional coordinates of individual atoms in materials revealed by electron tomography. R Xu, 10.1038/nmat4426Nat. Mater. 14Xu R et al 2015 Three-dimensional coordinates of individual atoms in materials revealed by electron tomography Nat. Mater. 14 1099-103</p>
<p>Atomic electron tomography: 3D structures without crystals. J Miao, P Ercius, S J Billinge, 10.1126/science.aaf2157Science. 3532157Miao J, Ercius P and Billinge S J 2016 Atomic electron tomography: 3D structures without crystals Science 353 aaf2157</p>
<p>Depth sectioning combined with atom-counting in HAADF STEM to retrieve the 3D atomic structure Ultramicroscopy. M Alania, T Altantzis, De Backer, A Lobato, I Bals, S Van Aert, S , 10.1016/j.ultramic.2016.11.002177Alania M, Altantzis T, De Backer A, Lobato I, Bals S and Van Aert S 2017 Depth sectioning combined with atom-counting in HAADF STEM to retrieve the 3D atomic structure Ultramicroscopy 177 36-42</p>
<p>High-resolution detection of Au catalyst atoms in Si nanowires. J Allen, 10.1038/nnano.2008.5Nat. Nanotechnol. 3Allen J E et al 2008 High-resolution detection of Au catalyst atoms in Si nanowires Nat. Nanotechnol. 3 168-73</p>
<p>Piezoresponse force microscopy: a window into electromechanical behavior at the nanoscale MRS Bull. D A Bonnell, S V Kalinin, A Kholkin, A Gruverman, 10.1557/mrs2009.17634Bonnell D A, Kalinin S V, Kholkin A L and Gruverman A 2009 Piezoresponse force microscopy: a window into electromechanical behavior at the nanoscale MRS Bull. 34 648-57</p>
<p>. K Moler, 10.1038/nmat5018Imaging quantum materials Nat. Mater. 16Moler K A 2017 Imaging quantum materials Nat. Mater. 16 1049-52</p>
<p>Creating designer quantum states of matter atom-by-atom. A A Khajetoorians, D Wegner, A Otte, I Swart, 10.1038/s42254-019-0108-5Nat. Rev. Phys. 1Khajetoorians A A, Wegner D, Otte A F and Swart I 2019 Creating designer quantum states of matter atom-by-atom Nat. Rev. Phys. 1 703-15</p>
<p>Data mining graphene: correlative analysis of structure and electronic degrees of freedom in graphenic monolayers with defects. M Ziatdinov, S Fujii, M Kiguchi, T Enoki, Jesse S Kalinin, S V , 10.1088/0957-4484/27/49/495703Nanotechnology. 27495703Ziatdinov M, Fujii S, Kiguchi M, Enoki T, Jesse S and Kalinin S V 2016 Data mining graphene: correlative analysis of structure and electronic degrees of freedom in graphenic monolayers with defects Nanotechnology 27 495703</p>
<p>Manipulating low-dimensional materials down to the level of single atoms with electron irradiation. T Susi, J C Meyer, J Kotakoski, 10.1016/j.ultramic.2017.03.005Ultramicroscopy. 180Susi T, Meyer J C and Kotakoski J 2017 Manipulating low-dimensional materials down to the level of single atoms with electron irradiation Ultramicroscopy 180 163-72</p>
<p>Nanoscale ferroelectrics: processing, characterization and future trends. A Gruverman, A Kholkin, 10.1088/0034-4885/69/8/r04Rep. Prog. Phys. 69Gruverman A and Kholkin A 2006 Nanoscale ferroelectrics: processing, characterization and future trends Rep. Prog. Phys. 69 2443-74</p>
<p>. K M Roccapriore, M Ziatdinov, S H Cho, J Hachtel, S V Kalinin, 10.1002/smll.2021001812100181Roccapriore K M, Ziatdinov M, Cho S H, Hachtel J A and Kalinin S V 2021 Predictability of localized plasmonic responses in nanoparticle assemblies Small n/a 2100181</p>
<p>Toward decoding the relationship between domain structure and functionality in ferroelectrics via hidden latent variables. S V Kalinin, K Kelley, R Vasudevan, M Ziatdinov, 10.1021/acsami.0c15085ACS Appl. Mater. Interfaces. 13Kalinin S V, Kelley K, Vasudevan R K and Ziatdinov M 2021 Toward decoding the relationship between domain structure and functionality in ferroelectrics via hidden latent variables ACS Appl. Mater. Interfaces 13 1693-703</p>
<p>M Y Yaman, S V Kalinin, K N Guye, Ginger D Ziatdinov, M , arXiv:2208.03861Learning and predicting photonic responses of plasmonic nanoparticle assemblies via dual variational autoencoders. Yaman M Y, Kalinin S V, Guye K N, Ginger D and Ziatdinov M 2022 Learning and predicting photonic responses of plasmonic nanoparticle assemblies via dual variational autoencoders (arXiv:2208.03861)</p>
<p>M Ziatdinov, M Y Yaman, Y Liu, Ginger D Kalinin, S V , arXiv:2105.11475Semi-supervised learning of images with strong rotational disorder: assembling nanoparticle libraries. Ziatdinov M, Yaman M Y, Liu Y, Ginger D and Kalinin S V 2021 Semi-supervised learning of images with strong rotational disorder: assembling nanoparticle libraries (arXiv:2105.11475)</p>
<p>. G E Karniadakis, I G Kevrekidis, L Lu, P Perdikaris, Wang S , Yang L , 10.1038/s42254-021-00314-5Physics-informed machine learning Nat. Rev. Phys. 3Karniadakis G E, Kevrekidis I G, Lu L, Perdikaris P, Wang S and Yang L 2021 Physics-informed machine learning Nat. Rev. Phys. 3 422-40</p>
<p>Explicitly disentangling image content from translation and rotation with spatial-VAE. T Bepler, E Zhong, K Kelley, E Brignole, B Berger, 10.1038/s41598-019-51926-yAdvances in Neural Information Processing Systems. Bepler T, Zhong E, Kelley K, Brignole E and Berger B 2019 Explicitly disentangling image content from translation and rotation with spatial-VAE Advances in Neural Information Processing Systems pp 15409-19</p>
<p>. S V Kalinin, M P Oxley, M Valleti, J Zhang, R P Hermann, H Zheng, W Zhang, G Eres, R Vasudevan, M Ziatdinov, 10.1038/s41524-021-00621-6Deep Bayesian local crystallography npj Comput. Mater. 7181Kalinin S V, Oxley M P, Valleti M, Zhang J, Hermann R P, Zheng H, Zhang W, Eres G, Vasudevan R K and Ziatdinov M 2021 Deep Bayesian local crystallography npj Comput. Mater. 7 181</p>
<p>Disentangling ferroelectric domain wall geometries and pathways in dynamic piezoresponse force microscopy via unsupervised machine learning. S V Kalinin, J J Steffes, Y Liu, B D Huey, M Ziatdinov, 10.1088/1361-6528/ac2f5bNanotechnology. 3355707Kalinin S V, Steffes J J, Liu Y, Huey B D and Ziatdinov M 2021 Disentangling ferroelectric domain wall geometries and pathways in dynamic piezoresponse force microscopy via unsupervised machine learning Nanotechnology 33 055707</p>
<p>A K Tagantsev, L Cross, J Fousek, Domains in Ferroic Crystals and Thin Films. BerlinSpringerTagantsev A K, Cross L E and Fousek J 2010 Domains in Ferroic Crystals and Thin Films (Berlin: Springer)</p>
<p>Ferroionic states in ferroelectric thin films. A N Morozovska, E A Eliseev, N Morozovsky, S V Kalinin, 10.1103/PhysRevB.95.195413Phys. Rev. B. 95195413Morozovska A N, Eliseev E A, Morozovsky N V and Kalinin S V 2017 Ferroionic states in ferroelectric thin films Phys. Rev. B 95 195413</p>
<p>Equilibrium polarization of ultrathin PbTiO3 with surface compensation controlled by oxygen partial pressure. M J Highland, T T Fister, D D Fong, P H Fuoss, C Thompson, J A Eastman, S Streiffer, G B Stephenson, 10.1103/PhysRevLett.107.187602Phys. Rev. Lett. 107187602Highland M J, Fister T T, Fong D D, Fuoss P H, Thompson C, Eastman J A, Streiffer S K and Stephenson G B 2011 Equilibrium polarization of ultrathin PbTiO3 with surface compensation controlled by oxygen partial pressure Phys. Rev. Lett. 107 187602</p>
<p>Equilibrium and stability of polarization in ultrathin ferroelectric films with ionic surface compensation. G B Stephenson, M J Highland, 10.1103/PhysRevB.84.064107Phys. Rev. B. 8464107Stephenson G B and Highland M J 2011 Equilibrium and stability of polarization in ultrathin ferroelectric films with ionic surface compensation Phys. Rev. B 84 064107</p>
<p>. E Dagotto, 10.1126/science.1107559Complexity in strongly correlated electronic systems Science. 309Dagotto E 2005 Complexity in strongly correlated electronic systems Science 309 257-62</p>
<p>P Lemos, N Jeffrey, M Cranmer, S Ho, P Battaglia, arXiv:2202.02306Rediscovering orbital mechanics with machine learning. Lemos P, Jeffrey N, Cranmer M, Ho S and Battaglia P 2022 Rediscovering orbital mechanics with machine learning (arXiv:2202. 02306)</p>
<p>Symbolic regression: discovering physical laws from distorted video. S-M Udrescu, M Tegmark, 10.1103/PhysRevE.103.043307Phys. Rev. E. 10343307Udrescu S-M and Tegmark M 2021 Symbolic regression: discovering physical laws from distorted video Phys. Rev. E 103 043307</p>
<p>Probing electron beam induced transformations on a single-defect level via automated scanning transmission electron microscopy. K M Roccapriore, M G Boebinger, O Dyck, A Ghosh, S Unocic R R, Kalinin, M Ziatdinov, 10.1021/acsnano.2c07451ACS Nano. 16Roccapriore K M, Boebinger M G, Dyck O, Ghosh A, Unocic R R, Kalinin S V and Ziatdinov M 2022 Probing electron beam induced transformations on a single-defect level via automated scanning transmission electron microscopy ACS Nano 16 17116-27</p>
<p>Atomic-scale study of electric dipoles near charged and uncharged domain walls in ferroelectric films. C-L Jia, Mi S-B Urban, K Vrejoiu, I , Alexe , M Hesse, D , 10.1038/nmat2080Nat. Mater. 7Jia C-L, Mi S-B, Urban K, Vrejoiu I, Alexe M and Hesse D 2008 Atomic-scale study of electric dipoles near charged and uncharged domain walls in ferroelectric films Nat. Mater. 7 57-61</p>
<p>In situ strain tuning of the metal-insulator-transition of Ca2RuO4 in angle-resolved photoemission experiments. S Riccò, 10.1038/s41467-018-06945-0Nat. Commun. 94535Riccò S et al 2018 In situ strain tuning of the metal-insulator-transition of Ca2RuO4 in angle-resolved photoemission experiments Nat. Commun. 9 4535</p>
<p>Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy npj. A Ghosh, B G Sumpter, O Dyck, S Kalinin, M Ziatdinov, 10.1038/s41524-021-00569-7Comput. Mater. 7Ghosh A, Sumpter B G, Dyck O, Kalinin S V and Ziatdinov M 2021 Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom-resolved microscopy npj Comput. Mater. 7 1-8</p>
<p>Stone-Wales-type transformations in carbon nanostructures driven by electron irradiation. J Kotakoski, J C Meyer, S Kurasch, D Santos-Cottin, Kaiser U Krasheninnikov, A V , 10.1103/PhysRevB.83.245420Phys. Rev. B. 83245420Kotakoski J, Meyer J C, Kurasch S, Santos-Cottin D, Kaiser U and Krasheninnikov A V 2011 Stone-Wales-type transformations in carbon nanostructures driven by electron irradiation Phys. Rev. B 83 245420</p>
<p>Disentangling ferroelectric wall dynamics and identification of pinning mechanisms via deep learning. Y Liu, R Proksch, C Y Wong, Ziatdinov M Kalinin, S V , 10.1002/adma.202103680Adv. Mater. 332103680Liu Y, Proksch R, Wong C Y, Ziatdinov M and Kalinin S V 2021 Disentangling ferroelectric wall dynamics and identification of pinning mechanisms via deep learning Adv. Mater. 33 2103680</p>
<p>Nanoionics-based resistive switching memories. R Waser, M Aono, 10.1038/nmat2023Nat. Mater. 6Waser R and Aono M 2007 Nanoionics-based resistive switching memories Nat. Mater. 6 833-40</p>
<p>R Waser, Nanoelectronics and information technology nanoelectronics and information technology. Waser R 2012 Nanoelectronics and information technology nanoelectronics and information technology</p>
<p>Ferroelectric, dielectric and piezoelectric properties of ferroelectric thin films and ceramics Rep. D Damjanovic, 10.1088/0034-4885/61/9/002Prog. Phys. 61Damjanovic D 1998 Ferroelectric, dielectric and piezoelectric properties of ferroelectric thin films and ceramics Rep. Prog. Phys. 61 1267-324</p>
<p>Ferroelectric thin films: review of materials, properties, and applications. N Setter, 10.1063/1.2336999J. Appl. Phys. 10051606Setter N et al 2006 Ferroelectric thin films: review of materials, properties, and applications J. Appl. Phys. 100 051606</p>
<p>Contribution of the irreversible displacement of domain walls to the piezoelectric effect in barium titanate and lead zirconate titanate ceramics. D Damjanovic, M Demartin, 10.1088/0953-8984/9/23/018J. Phys.: Condens. Matter. 94943Damjanovic D and Demartin M 1997 Contribution of the irreversible displacement of domain walls to the piezoelectric effect in barium titanate and lead zirconate titanate ceramics J. Phys.: Condens. Matter 9 4943</p>
<p>An in situ diffraction study of domain wall motion contributions to the frequency dispersion of the piezoelectric coefficient in lead zirconate titanate. S B Seshadri, A D Prewitt, A J Studer, Damjanovic D Jones, J L , 10.1063/1.4789903Appl. Phys. Lett. 10242911Seshadri S B, Prewitt A D, Studer A J, Damjanovic D and Jones J L 2013 An in situ diffraction study of domain wall motion contributions to the frequency dispersion of the piezoelectric coefficient in lead zirconate titanate Appl. Phys. Lett. 102 042911</p>
<p>Domain wall motion and electromechanical strain in lead-free piezoelectrics: insight from the model system (1−x) Ba (Zr0. 2Ti0. 8) O3-x (Ba0. 7Ca0. 3) TiO3 using in situ high-energy x-ray diffraction during application of electric fields. G Tutuncu, B Li, K Bowman, J L Jones, 10.1063/1.4870934J. Appl. Phys. 115144104Tutuncu G, Li B, Bowman K and Jones J L 2014 Domain wall motion and electromechanical strain in lead-free piezoelectrics: insight from the model system (1−x) Ba (Zr0. 2Ti0. 8) O3-x (Ba0. 7Ca0. 3) TiO3 using in situ high-energy x-ray diffraction during application of electric fields J. Appl. Phys. 115 144104</p>
<p>Evaluation of domain wall motion in bipolar fatigued lead-zirconate-titanate: a study on reversible and irreversible contributions. J Glaum, T Granzow, J Rödel, 10.1063/1.3386461J. Appl. Phys. 107104119Glaum J, Granzow T and Rödel J 2010 Evaluation of domain wall motion in bipolar fatigued lead-zirconate-titanate: a study on reversible and irreversible contributions J. Appl. Phys. 107 104119</p>
<p>Dynamic conductivity of ferroelectric domain walls in BiFeO3 Nano Lett. P Maksymovych, J Seidel, Y H Chu, P Wu, A P Baddorf, L-Q Chen, S Kalinin, Ramesh R , 10.1021/nl104363x11Maksymovych P, Seidel J, Chu Y H, Wu P, Baddorf A P, Chen L-Q, Kalinin S V and Ramesh R 2011 Dynamic conductivity of ferroelectric domain walls in BiFeO3 Nano Lett. 11 1906-12</p>
<p>Domain-wall conduction in ferroelectric BiFeO3 controlled by accumulation of charged defects. T Rojac, 10.1038/nmat4799Nat. Mater. 16Rojac T et al 2017 Domain-wall conduction in ferroelectric BiFeO3 controlled by accumulation of charged defects Nat. Mater. 16 322-7</p>
<p>Disentangling ferroelectric domain wall geometries and pathways in dynamic piezoresponse force microscopy via unsupervised machine learning. S V Kalinin, J J Steffes, Y T Liu, B D Huey, M Ziatdinov, 10.1088/1361-6528/ac2f5bNanotechnology. 3311Kalinin S V, Steffes J J, Liu Y T, Huey B D and Ziatdinov M 2022 Disentangling ferroelectric domain wall geometries and pathways in dynamic piezoresponse force microscopy via unsupervised machine learning Nanotechnology 33 11</p>
<p>From atomically resolved imaging to generative and causal models. S V Kalinin, Rama Vasudevan, A G Ziatdinov, M , 10.1038/s41567-022-01666-0Nat. Phys. 18Kalinin S V, Rama Vasudevan A G and Ziatdinov M 2021 From atomically resolved imaging to generative and causal models Nat. Phys. 18 1152-60</p>
<p>Insights into cation ordering of double perovskite oxides from machine learning and causal relations. Ayana Ghosh, G P Trujillo, D P Shaikh, M Ghosh, S , 10.1021/acs.chemmater.2c00217Chem. Mater. 34Ayana Ghosh G P, Trujillo D P, Shaikh M and Ghosh S 2022 Insights into cation ordering of double perovskite oxides from machine learning and causal relations Chem. Mater. 34 7563-78</p>
<p>Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process. Maxim Ziatdinov, A Kalinin, S V , 10.1088/2632-2153/ac4baaMach. Learn.: Sci. Technol. 315022Maxim Ziatdinov A G and Kalinin S V 2021 Physics makes the difference: Bayesian optimization and active learning via augmented Gaussian process Mach. Learn.: Sci. Technol. 3 015022</p>
<p>DFTB+, a software package for efficient approximate density functional theory based atomistic simulations. B Hourahine, 10.1063/1.5143190J. Chem. Phys. 152124101Hourahine B et al 2020 DFTB+, a software package for efficient approximate density functional theory based atomistic simulations J. Chem. Phys. 152 124101</p>
<p>Bridging microscopy with molecular dynamics and quantum simulations: an AtomAI based pipeline npj. Ayana Ghosh, M Z Dyck, O Sumpter, B Kalinin, S V , 10.1038/s41524-022-00733-7Comput. Mater. 811Ayana Ghosh M Z, Dyck O, Sumpter B and Kalinin S V 2021 Bridging microscopy with molecular dynamics and quantum simulations: an AtomAI based pipeline npj Comput. Mater. 8 11</p>
<p>. C C M Mody, Instrumental Community. The MIT PressMody C C M 2011 Instrumental Community (Cambridge, MA: The MIT Press)</p>
<p>Learning surface molecular structures via machine vision npj. M Ziatdinov, A Maksov, S V Kalinin, 10.1038/s41524-017-0038-7Comput. Mater. 331Ziatdinov M, Maksov A and Kalinin S V 2017 Learning surface molecular structures via machine vision npj Comput. Mater. 3 31</p>
<p>Building and exploring libraries of atomic defects in graphene: scanning transmission electron and scanning tunneling microscopy study Sci. M Ziatdinov, O Dyck, X Li, B G Sumpter, Jesse S Vasudevan, R Kalinin, S V , 10.1126/sciadv.aaw8989Adv. 58989Ziatdinov M, Dyck O, Li X, Sumpter B G, Jesse S, Vasudevan R K and Kalinin S V 2019 Building and exploring libraries of atomic defects in graphene: scanning transmission electron and scanning tunneling microscopy study Sci. Adv. 5 eaaw8989</p>
<p>Deep learning analysis of defect and phase evolution during electron beam-induced transformations in WS2 npj. A Maksov, O Dyck, K Wang, K Xiao, D B Geohegan, B G Sumpter, R K Vasudevan, Jesse S Kalinin, S Ziatdinov, M , 10.1038/s41524-019-0152-9Comput. Mater. 5Maksov A, Dyck O, Wang K, Xiao K, Geohegan D B, Sumpter B G, Vasudevan R K, Jesse S, Kalinin S V and Ziatdinov M 2019 Deep learning analysis of defect and phase evolution during electron beam-induced transformations in WS2 npj Comput. Mater. 5 1-8</p>
<p>Scanning tunneling state recognition with multi-class neural network ensembles. O Gordon, D Hondt, P Knijff, L Freeney, S E Junqueira, F Moriarty, P Swart, I , 10.1063/1.5099590Rev. Sci. Instrum. 90103704Gordon O, D'Hondt P, Knijff L, Freeney S E, Junqueira F, Moriarty P and Swart I 2019 Scanning tunneling state recognition with multi-class neural network ensembles Rev. Sci. Instrum. 90 103704</p>
<p>Improving the segmentation of scanning probe microscope images using convolutional neural networks. S Farley, 10.1088/2632-2153/abc81cMach. Learn.: Sci. Technol. 215015Farley S et al 2020 Improving the segmentation of scanning probe microscope images using convolutional neural networks Mach. Learn.: Sci. Technol. 2 015015</p>
<p>Symmetry-aware recursive image similarity exploration for materials microscopy npj. T N M Nguyen, Y Guo, S Qin, K S Frew, R Xu, J C Agar, 10.1038/s41524-021-00637-yComput. Mater. 714Nguyen T N M, Guo Y, Qin S, Frew K S, Xu R and Agar J C 2021 Symmetry-aware recursive image similarity exploration for materials microscopy npj Comput. Mater. 7 14</p>
<p>Building ferroelectric from the bottom up: the machine learning analysis of the atomic-scale ferroelectric distortions. M Ziatdinov, C Nelson, R K Vasudevan, Chen D Kalinin, S V , 10.1063/1.5109520Appl. Phys. Lett. 11552902Ziatdinov M, Nelson C, Vasudevan R K, Chen D and Kalinin S V 2019 Building ferroelectric from the bottom up: the machine learning analysis of the atomic-scale ferroelectric distortions Appl. Phys. Lett. 115 052902</p>
<p>Exploring order parameters and dynamic processes in disordered systems via variational autoencoders Sci. S V Kalinin, O Dyck, Jesse S Ziatdinov, M , 10.1126/sciadv.abd5084Adv. 75084Kalinin S V, Dyck O, Jesse S and Ziatdinov M 2021 Exploring order parameters and dynamic processes in disordered systems via variational autoencoders Sci. Adv. 7 eabd5084</p>
<p>Probing atomic-scale symmetry breaking by rotationally invariant machine learning of multidimensional electron scattering npj Comput. M P Oxley, M Ziatdinov, O Dyck, A R Lupini, R Vasudevan, S V Kalinin, 10.1038/s41524-021-00527-3Mater765Oxley M P, Ziatdinov M, Dyck O, Lupini A R, Vasudevan R and Kalinin S V 2021 Probing atomic-scale symmetry breaking by rotationally invariant machine learning of multidimensional electron scattering npj Comput. Mater. 7 65</p>
<p>Experimental discovery of structure-property relationships in ferroelectric materials via active learning Nat. Y Liu, K P Kelley, R K Vasudevan, H Funakubo, M Ziatdinov, S V Kalinin, 10.1038/s42256-022-00460-0Mach. Intell. 4Liu Y, Kelley K P, Vasudevan R K, Funakubo H, Ziatdinov M A and Kalinin S V 2022 Experimental discovery of structure-property relationships in ferroelectric materials via active learning Nat. Mach. Intell. 4 341-50</p>
<p>K M Roccapriore, O Dyck, M P Oxley, Ziatdinov M Kalinin, S V , 10.1021/acsnano.1c111184D-STEM: exploring emergent physics and structural behaviors ACS Nano. 16Roccapriore K M, Dyck O, Oxley M P, Ziatdinov M and Kalinin S V 2022 Automated experiment in 4D-STEM: exploring emergent physics and structural behaviors ACS Nano 16 7605-14</p>
<p>. A G Wilson, Z Hu, R Salakhutdinov, E P Xing, 10.1016/0190-9622(91)70207-iArtificial intelligence and statistics. Wilson A G, Hu Z, Salakhutdinov R and Xing E P 2016 Artificial intelligence and statistics PMLR pp 370-8</p>
<p>S V Kalinin, M Ziatdinov, J Hinkle, Jesse S Ghosh, A Kelley, K P Lupini, A R Sumpter, B Vasudevan, R K , arXiv:2103.12165Automated and autonomous experiment in electron and scanning probe microscopy. Kalinin S V, Ziatdinov M, Hinkle J, Jesse S, Ghosh A, Kelley K P, Lupini A R, Sumpter B G and Vasudevan R K 2021 Automated and autonomous experiment in electron and scanning probe microscopy (arXiv:2103.12165)</p>
<p>Machine learning for active matter Nat. F Cichos, K Gustavsson, B Mehlig, G Volpe, 10.1038/s42256-020-0146-9Mach. Intell. 2Cichos F, Gustavsson K, Mehlig B and Volpe G 2020 Machine learning for active matter Nat. Mach. Intell. 2 94-103</p>
<p>Artificial-intelligence-driven scanning probe microscopy. A Krull, P Hirsch, C Rother, A Schiffrin, C Krull, 10.1038/s42005-020-0317-3Commun. Phys. 354Krull A, Hirsch P, Rother C, Schiffrin A and Krull C 2020 Artificial-intelligence-driven scanning probe microscopy Commun. Phys. 3 54</p>
<p>. J Ede, 10.1088/2632-2153/ab9c3cWarwick electron microscopy datasets Mach. Learn.: Sci. Technol. 145003Ede J M 2020 Warwick electron microscopy datasets Mach. Learn.: Sci. Technol. 1 045003</p>
<p>Infrastructure for analysis of large microscopy and microanalysis data sets Microsc. Microanal. J Wei, C Francis, D Morgan, K J Schmidt, A Scourtas, I Foster, B Blaiszik, P M Voyles, 10.1017/S143192762201153928Wei J, Francis C, Morgan D, Schmidt K J, Scourtas A, Foster I, Blaiszik B and Voyles P M 2022 Infrastructure for analysis of large microscopy and microanalysis data sets Microsc. Microanal. 28 3094-6</p>
<p>Mapping octahedral tilts and polarization across a domain wall in BiFeO(3) from Z-contrast scanning transmission electron microscopy image atomic column shape analysis. A Borisevich, 10.1021/nn1011539ACS Nano. 4Borisevich A et al 2010 Mapping octahedral tilts and polarization across a domain wall in BiFeO(3) from Z-contrast scanning transmission electron microscopy image atomic column shape analysis ACS Nano 4 6071-9</p>
<p>Towards 3D mapping of BO6 octahedron rotations at perovskite heterointerfaces, unit cell by unit cell. Q He, R Ishikawa, A R Lupini, L Qiao, E J Moon, O Ovchinnikov, S J May, M Biegalski, A Y Borisevich, 10.1021/acsnano.5b03232ACS Nano. 9He Q, Ishikawa R, Lupini A R, Qiao L, Moon E J, Ovchinnikov O, May S J, Biegalski M D and Borisevich A Y 2015 Towards 3D mapping of BO6 octahedron rotations at perovskite heterointerfaces, unit cell by unit cell ACS Nano 9 8412-9</p>
<p>Organic synthesis in a modular robotic system driven by a chemical programming language. S Steiner, 10.1126/science.aav2211Science. 3632211Steiner S et al 2019 Organic synthesis in a modular robotic system driven by a chemical programming language Science 363 eaav2211</p>
<p>A 2020 Self-referencing embedded strings (SELFIES): a 100% robust molecular string representation. M Krenn, F Häse, A Nigam, P Friederich, Aspuru-Guzik , 10.1088/2632-2153/aba947Mach. Learn.: Sci. Technol. 145024Krenn M, Häse F, Nigam A, Friederich P and Aspuru-Guzik A 2020 Self-referencing embedded strings (SELFIES): a 100% robust molecular string representation Mach. Learn.: Sci. Technol. 1 045024</p>
<p>Prediction of clinical diagnosis of Alzheimer's disease, vascular, mixed, and all-cause dementia by a polygenic risk score and APOE status in a community-based cohort prospectively followed over 17 years. H Stocker, L Perna, K Weigl, T Möllers, B Schöttker, H Thomsen, B Holleczek, D Rujescu, H Brenner, 10.1038/s41380-020-0764-yMol. Psychiatry. 26Stocker H, Perna L, Weigl K, Möllers T, Schöttker B, Thomsen H, Holleczek B, Rujescu D and Brenner H 2021 Prediction of clinical diagnosis of Alzheimer's disease, vascular, mixed, and all-cause dementia by a polygenic risk score and APOE status in a community-based cohort prospectively followed over 17 years Mol. Psychiatry 26 5812-22</p>
<p>Machine learning in computer-aided synthesis planning. C W Coley, W Green, K F Jensen, 10.1021/acs.accounts.8b00087Acc. Chem. Res. 51Coley C W, Green W H and Jensen K F 2018 Machine learning in computer-aided synthesis planning Acc. Chem. Res. 51 1281-9</p>
<p>Automated pipeline for superalloy data by text mining npj. W R Wang, X Jiang, S Tian, P Liu, D Dang, Y Su, T Lookman, J Xie, 10.1038/s41524-021-00687-2Comput. Mater. 812Wang W R, Jiang X, Tian S, Liu P, Dang D, Su Y, Lookman T and Xie J 2022 Automated pipeline for superalloy data by text mining npj Comput. Mater. 8 12</p>
<p>Data-driven materials research enabled by natural language processing and information extraction Appl. E A Olivetti, J M Cole, Kim E Kononova, O Ceder, G Han, T Y-J Hiszpanski, A M , 10.1063/5.0021106Phys. Rev. 719Olivetti E A, Cole J M, Kim E, Kononova O, Ceder G, Han T Y-J and Hiszpanski A M 2020 Data-driven materials research enabled by natural language processing and information extraction Appl. Phys. Rev. 7 19</p>
<p>Unsupervised word embeddings capture latent knowledge from materials science literature. V Tshitoyan, J Dagdelen, L Weston, A Dunn, Z Rong, O Kononova, K A Persson, G Ceder, A Jain, 10.1038/s41586-019-1335-8Nature. 57195Tshitoyan V, Dagdelen J, Weston L, Dunn A, Rong Z, Kononova O, Persson K A, Ceder G and Jain A 2019 Unsupervised word embeddings capture latent knowledge from materials science literature Nature 571 95</p>
<p>Semi-supervised machine-learning classification of materials synthesis procedures npj. H Y Huo, Z Rong, O Kononova, W Sun, T Botari, T He, V Tshitoyan, G Ceder, 10.1038/s41524-019-0204-1Comput. Mater. 57Huo H Y, Rong Z, Kononova O, Sun W, Botari T, He T, Tshitoyan V and Ceder G 2019 Semi-supervised machine-learning classification of materials synthesis procedures npj Comput. Mater. 5 7</p>
<p>Automated microfluidic platform for systematic studies of colloidal perovskite nanocrystals: towards continuous nano-manufacturing. R W Epps, K C Felton, C Coley, M Abolhasani, 10.1039/C7LC00884HLab Chip. 17Epps R W, Felton K C, Coley C W and Abolhasani M 2017 Automated microfluidic platform for systematic studies of colloidal perovskite nanocrystals: towards continuous nano-manufacturing Lab Chip 17 4040-7</p>
<p>Integrated 3D-printed reaction ware for chemical synthesis and analysis Nat. M D Symes, P J Kitson, Yan J Richmond, C J Cooper, G J T Bowman, R W Vilbrandt, T Cronin, L , 10.1038/nchem.1313Symes M D, Kitson P J, Yan J, Richmond C J, Cooper G J T, Bowman R W, Vilbrandt T and Cronin L 2012 Integrated 3D-printed reaction ware for chemical synthesis and analysis Nat. Chem. 4 349-54</p>
<p>Defining and exploring chemical spaces Trends Chem. C Coley, 10.1016/j.trechm.2020.11.0043Coley C W 2021 Defining and exploring chemical spaces Trends Chem. 3 133-45</p>
<p>Toward an artificial intelligence physicist for unsupervised learning. T L Wu, M Tegmark, 10.1103/PhysRevE.100.033311Phys. Rev. E. 10019Wu T L and Tegmark M 2019 Toward an artificial intelligence physicist for unsupervised learning Phys. Rev. E 100 19</p>
<p>A I 2020 A physics-inspired method for symbolic regression Sci. S-M Udrescu, Tegmark M , Feynman , 10.1126/sciadv.aay2631Adv. 62631Udrescu S-M, Tegmark M and Feynman: A I 2020 A physics-inspired method for symbolic regression Sci. Adv. 6 eaay2631</p>
<p>AI Feynman 2.0: pareto-optimal symbolic regression exploiting graph modularity. S-M Udrescu, Advances in Neural Information Processing Systems. 33Udrescu S-M et al 2020 AI Feynman 2.0: pareto-optimal symbolic regression exploiting graph modularity Advances in Neural Information Processing Systems vol 33 pp 4860-71</p>
<p>K Champion, B Lusch, J Kutz, S L Brunton, 10.1073/pnas.1906995116Data-driven discovery of coordinates and governing equations Proc. Natl Acad. Sci. 116Champion K, Lusch B, Kutz J N and Brunton S L 2019 Data-driven discovery of coordinates and governing equations Proc. Natl Acad. Sci. 116 22445-51</p>
<p>Discovering governing equations from data by sparse identification of nonlinear dynamical systems Proc. S L Brunton, J Proctor, J N Kutz, 10.1073/pnas.1517384113Natl Acad. Sci. 113Brunton S L, Proctor J L and Kutz J N 2016 Discovering governing equations from data by sparse identification of nonlinear dynamical systems Proc. Natl Acad. Sci. 113 3932-7</p>
<p>Bayesian learning of adatom interactions from atomically resolved imaging data. S M P Valleti, 10.1021/acsnano.0c10851ACS nano. 15Valleti S M P et al 2021 Bayesian learning of adatom interactions from atomically resolved imaging data ACS nano 15 9649-57</p>
<p>Toward causal representation learning Proc. B Schölkopf, F Locatello, S Bauer, N R Ke, N Kalchbrenner, A Goyal, Y Bengio, 10.1109/JPROC.2021.3058954IEEE. 109Schölkopf B, Locatello F, Bauer S, Ke N R, Kalchbrenner N, Goyal A and Bengio Y 2021 Toward causal representation learning Proc. IEEE 109 612-34</p>
<p>D P Kingma, M Welling, arXiv:1906.02691An introduction to variational autoencoders. Kingma D P and Welling M 2019 An introduction to variational autoencoders (arXiv:1906.02691)</p>
<p>. D A Keen, A L Goodwin, 10.1038/nature14453The crystallography of correlated disorder Nature. 521Keen D A and Goodwin A L 2015 The crystallography of correlated disorder Nature 521 303-9</p>
<p>Design of crystal-like aperiodic solids with selective disorder-phonon coupling. A R Overy, A B Cairns, M J Cliffe, A Simonov, M G Tucker, A L Goodwin, 10.1038/ncomms10445Nat. Commun. 710445Overy A R, Cairns A B, Cliffe M J, Simonov A, Tucker M G and Goodwin A L 2016 Design of crystal-like aperiodic solids with selective disorder-phonon coupling Nat. Commun. 7 10445</p>
<p>Kinetic control of tunable multi-state switching in ferroelectric thin films. M Kunitski, 10.1038/s41467-018-07882-8Nat. Commun. 10Kunitski M et al 2019 Kinetic control of tunable multi-state switching in ferroelectric thin films Nat. Commun. 10 1-10</p>
<p>Ultra-high resolution imaging of thin films and single strands of polythiophene using atomic force microscopy. V V Korolkov, A Summerfield, A Murphy, D B Amabilino, K Watanabe, T Taniguchi, P H Beton, 10.1038/s41467-019-09571-6Nat. Commun. 10Korolkov V V, Summerfield A, Murphy A, Amabilino D B, Watanabe K, Taniguchi T and Beton P H 2019 Ultra-high resolution imaging of thin films and single strands of polythiophene using atomic force microscopy Nat. Commun. 10 1-8</p>
<p>Investigating phase transitions from local crystallographic analysis based on statistical learning of atomic environments in 2D MoS2-ReS2 Appl. R Vasudevan, 10.1063/5.0012761Phys. Rev. 811409Vasudevan R K et al 2021 Investigating phase transitions from local crystallographic analysis based on statistical learning of atomic environments in 2D MoS2-ReS2 Appl. Phys. Rev. 8 011409</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, 10.1038/s41586-018-0337-2Nature. 559Butler K T, Davies D W, Cartwright H, Isayev O and Walsh A 2018 Machine learning for molecular and materials science Nature 559 547-55</p>
<p>. E Muratov, 10.1039/d0cs00098aChem. Soc. Rev. 49Muratov E N et al 2020 QSAR without borders Chem. Soc. Rev. 49 3525-64</p>
<p>Organic chemistry as a language and the implications of chemical linguistics for structural and retrosynthetic analyses. A Cadeddu, E K Wylie, J Jurczak, M Wampler-Doty, B A Grzybowski, 10.1002/anie.201403708Angew. Chem., Int. Ed. 53Cadeddu A, Wylie E K, Jurczak J, Wampler-Doty M and Grzybowski B A 2014 Organic chemistry as a language and the implications of chemical linguistics for structural and retrosynthetic analyses Angew. Chem., Int. Ed. 53 8108-12</p>
<p>Extraordinary optical transmission through sub-wavelength hole arrays. T W Ebbesen, H J Lezec, H Ghaemi, T Thio, P A Wolff, 10.1038/35570Nature. 391Ebbesen T W, Lezec H J, Ghaemi H, Thio T and Wolff P A 1998 Extraordinary optical transmission through sub-wavelength hole arrays Nature 391 667-9</p>
<p>Plasmonic photo-thermal therapy (PPTT) Alexandria. X Huang, M El-Sayed, 10.1016/j.ajme.2011.01.001J. Med. 47Huang X and El-Sayed M A 2011 Plasmonic photo-thermal therapy (PPTT) Alexandria J. Med. 47 1-9</p>
<p>Robust multicolor single photon emission from point defects in hexagonal boron nitride. T T Tran, C Elbadawi, D Totonjian, C J Lobo, G Grosso, H Moon, D R Englund, M J Ford, Aharonovich I Toth, M , 10.1021/acsnano.6b03602ACS Nano. 10Tran T T, Elbadawi C, Totonjian D, Lobo C J, Grosso G, Moon H, Englund D R, Ford M J, Aharonovich I and Toth M 2016 Robust multicolor single photon emission from point defects in hexagonal boron nitride ACS Nano 10 7331-8</p>
<p>Mapping plasmons at the nanometer scale in an electron microscope. M Kociak, O Stéphan, 10.1039/c3cs60478kChem. Soc. Rev. 43Kociak M and Stéphan O 2014 Mapping plasmons at the nanometer scale in an electron microscope Chem. Soc. Rev. 43 3865-83</p>
<p>What I cannot create, I do not understand. M Way, 10.1242/jcs.209791J. Cell. Sci. 130Way M 2017 What I cannot create, I do not understand J. Cell. Sci. 130 2941-2</p>
<p>Directing matter: toward atomic-scale 3D nanofabrication. S Jesse, A Y Borisevich, J D Fowlkes, A R Lupini, P D Rack, R R Unocic, B G Sumpter, S V Kalinin, A Belianinov, O S Ovchinnikova, 10.1021/acsnano.6b02489ACS Nano. 10Jesse S, Borisevich A Y, Fowlkes J D, Lupini A R, Rack P D, Unocic R R, Sumpter B G, Kalinin S V, Belianinov A and Ovchinnikova O S 2016 Directing matter: toward atomic-scale 3D nanofabrication ACS Nano 10 5600-18</p>
<p>. Gonzalez-Martinez I G, A Bachmatiuk, V Bezugly, J Kunstmann, T Gemming, Z Liu, Cuniberti G Rümmeli, M H , 10.1039/c6nr01941bGonzalez-Martinez I G, Bachmatiuk A, Bezugly V, Kunstmann J, Gemming T, Liu Z, Cuniberti G and Rümmeli M H 2016 Electron-beam induced synthesis of nanostructures: a review Nanoscale 8 11340-62</p>
<p>. M Fuechsle, J A Miwa, S Mahapatra, H Ryu, S Lee, O Warschkow, L C L Hollenberg, Klimeck G Simmons, M Y , 10.1038/nnano.2012.21Nat. Nanotechnol. 7Fuechsle M, Miwa J A, Mahapatra S, Ryu H, Lee S, Warschkow O, Hollenberg L C L, Klimeck G and Simmons M Y 2012 A single-atom transistor Nat. Nanotechnol. 7 242-6</p>
<p>There's plenty of room at the bottom. R Feynman, Caltech Eng. Sci. 23Feynman R P 1960 There's plenty of room at the bottom Caltech Eng. Sci. 23 22-36</p>
<p>2022 A quantum lab in a beam. S V Kalinin, Jesse S Lupini, A R , 10.1063/pt.3.5018Phys. Today. 75Kalinin S V, Jesse S and Lupini A R 2022 A quantum lab in a beam Phys. Today 75 30-36</p>
<p>Electron-beam manipulation of silicon dopants in graphene. M Tripathi, A Mittelberger, N A Pike, C Mangler, J C Meyer, M J Verstraete, Kotakoski J , Susi , 10.1021/acs.nanolett.8b02406Nano Lett. 18Tripathi M, Mittelberger A, Pike N A, Mangler C, Meyer J C, Verstraete M J, Kotakoski J and Susi T 2018 Electron-beam manipulation of silicon dopants in graphene Nano Lett. 18 5319-23</p>            </div>
        </div>

    </div>
</body>
</html>