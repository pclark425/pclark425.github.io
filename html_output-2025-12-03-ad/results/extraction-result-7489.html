<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7489 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7489</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7489</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-136.html">extraction-schema-136</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <p><strong>Paper ID:</strong> paper-7354a57261d27a281e56dc428b6ec146b9992afd</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/7354a57261d27a281e56dc428b6ec146b9992afd" target="_blank">Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> Novel experimental insights are presented into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations, and it is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.</p>
                <p><strong>Paper Abstract:</strong> While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7489.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7489.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrRec (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Sentence Recovery task evaluated with GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ScrRec measures the model's ability to reconstruct original sentences from character‑scrambled sentences; GPT‑4 achieves near‑perfect recovery rates across scramble types and rates reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source large autoregressive transformer-based LLM from OpenAI (chat/completion API variant GPT-4-0314 used in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Sentence Recovery (ScrRec; typoglycemia-style scrambled word recognition)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading / lexical recognition</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Given a sentence whose words have been character-scrambled under various schemes (random scramble, keep-first, keep-first-and-last), the model is asked to recover the original sentence; performance quantified by edit distance (ED) and Recovery Rate (RR = proportion of ED reduced).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Edit Distance (ED) and Recovery Rate (RR, percent ED reduction)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot: ED (20%,50%,100%,KF,KFL) = [1.69, 2.78, 5.47, 4.19, 2.53]; RR (20%,50%,100%,KF,KFL) = [93.76%, 95.89%, 95.94%, 95.99%, 96.66%]. (Few-shot 3-shot exemplars reported similar RR ~94.5–97.0%). Paper summary: GPT-4 reduces edit distance by ~95% even at 100% random scramble.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot; few-shot (3-shot) also evaluated for ScrRec</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as background on human recognition of scrambled words; no numeric human baseline reported in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>The paper frames ScrRec as analogous to typoglycemia and notes consistency with human letter-position importance, but it does not report numeric human baseline performance. GPT-4 maintains RR ≈95% across scramble types and rates; other LLMs degrade noticeably as scramble difficulty increases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7489.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrQA (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Question Answering (ScrQA) evaluated with GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ScrQA measures model QA accuracy when evidence/context sentences are character‑scrambled; GPT‑4 retains a large fraction of its original accuracy even with heavily scrambled evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source large autoregressive transformer-based LLM from OpenAI (GPT-4-0314 used).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Question Answering (ScrQA)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading comprehension / reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Answer multiple-choice or extractive questions using evidence/context in which words are character-scrambled under various schemes and rates; performance reported as accuracy and Relative Performance Gain (RPG) relative to original and substituted (randomized) evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (%) and Relative Performance Gain (RPG, normalized accuracy change)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA dataset): Accuracy (Ori, 20%, 50%, 100%, KF, KFL, Sub) = [97.69%, 97.40%, 96.82%, 93.35%, 93.35%, 95.66%, 62.14%]. RPG (normalized) = [100.0, 99.19, 97.56, 87.80, 87.80, 94.31, 0.0]. Paper notes GPT-4 maintains ~87.8% of its original performance at 100% random scramble.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as background; no empirical human QA baseline given in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Human baselines for ScrQA with scrambled evidence are not provided. GPT-4 substantially outperforms other evaluated LLMs on ScrQA as scramble difficulty and rate increase.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7489.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrRec (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Sentence Recovery task evaluated with GPT-3.5‑turbo</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT‑3.5‑turbo's ability to recover sentences from scrambled inputs is substantially lower than GPT‑4 and degrades with increasing scramble difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source OpenAI LLM (GPT-3.5-turbo-0301 version used), transformer-based chat/completion model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Sentence Recovery (ScrRec)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading / lexical recognition</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Recover original sentences from character-scrambled sentences; measured by ED and Recovery Rate (RR).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Edit Distance (ED) and Recovery Rate (RR)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [82.72%, 80.82%, 77.88%, 86.39%, 90.82%]; ED values reported in table. Performance drops as scramble difficulty increases; fewer than GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot (few-shot also evaluated elsewhere in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>No human numeric baseline provided. GPT‑3.5 shows moderate degradation with increased scramble rate compared to GPT‑4.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7489.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrQA (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Question Answering evaluated with GPT-3.5‑turbo</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT‑3.5‑turbo's accuracy on QA with scrambled evidence falls with scramble rate and type and is below GPT‑4's performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source transformer-based chat/completion model from OpenAI.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Question Answering (ScrQA)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading comprehension / reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Answer questions using scrambled context; accuracy and RPG report robustness relative to original context.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (%) and RPG</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [97.11%, 94.80%, 91.33%, 81.79%, 88.44%, 93.06%, 52.60%]. RPG = [100.0, 94.81, 87.01, 65.58, 80.52, 90.91, 0.0].</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>No human baseline presented. GPT‑3.5 loses a larger fraction of its original accuracy than GPT‑4 at high scramble rates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7489.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrRec (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Sentence Recovery task evaluated with text-davinci-003</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>text-davinci-003 shows substantially lower recovery rates than the top ChatGPT/GPT‑4 models and is more affected by heavy scrambling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-davinci-003</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI family GPT-3-based instruction-tuned model (text-davinci-003).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Sentence Recovery (ScrRec)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading / lexical recognition</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Recover original sentences from scrambled sentences; performance reported as ED and RR.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Edit Distance (ED) and Recovery Rate (RR)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [44.52%, 52.96%, 18.61%, 70.45%, 82.41%]; ED values also reported. Performance degrades strongly with heavy random scrambling.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>No human baseline; text-davinci-003 performs worse than GPT-3.5 and GPT-4 on these tasks according to reported RR/ED metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7489.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrQA (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Question Answering evaluated with text-davinci-003</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>text-davinci-003 accuracy on QA with scrambled evidence drops as scramble rate increases and is substantially lower than GPT‑4.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-davinci-003</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-3 family instruction-tuned model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Question Answering (ScrQA)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading comprehension / reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Answering questions using scrambled context; accuracy and RPG metrics evaluate robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (%) and RPG</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [93.93%, 91.62%, 87.28%, 77.46%, 84.10%, 88.15%, 54.91%]. RPG = [100.0, 94.07, 82.96, 57.78, 74.81, 85.19, 0.0].</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>Human baseline not provided. text-davinci-003 loses more accuracy at high scramble rates than GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7489.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrRec (Llama-2-70b)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Sentence Recovery task evaluated with Llama‑2‑70b</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama-2-70b (70B parameter open-source model) obtains moderate recovery rates on ScrRec but fails under extreme (100% random) scramble in zero-shot settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2-70b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source Llama 2 family decoder-only transformer model (70B parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Sentence Recovery (ScrRec)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading / lexical recognition</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Recover original sentences from character-scrambled inputs; evaluated by ED and RR.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Edit Distance (ED) and Recovery Rate (RR)</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [70.04%, 39.32%, <0, 42.45%, 71.34%]. (Few-shot improves some settings.)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot (few-shot also reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as human behavior references only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>At 100% random scrambling Llama-2-70b's RR becomes negative (worse than scrambled input) in zero-shot; finetuning on scrambled text (reported elsewhere in appendix for other Llama variants) can improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7489.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7489.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM performance on cognitive psychology tests and the corresponding human baseline results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ScrQA (Llama-2-70b)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scrambled Question Answering evaluated with Llama‑2‑70b</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama‑2‑70b's QA accuracy declines with scramble rate and performs substantially worse than GPT‑4 on heavily scrambled evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2-70b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source Llama 2 family decoder-only transformer model (70B parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>test_name</strong></td>
                            <td>Scrambled Question Answering (ScrQA)</td>
                        </tr>
                        <tr>
                            <td><strong>test_category</strong></td>
                            <td>reading comprehension / reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Answer multiple-choice questions using scrambled evidence; measured by accuracy and RPG.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Accuracy (%) and RPG</td>
                        </tr>
                        <tr>
                            <td><strong>human_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [88.44%, 86.13%, 80.35%, 67.92%, 75.43%, 80.64%, 57.23%]. RPG = [100.0, 92.59, 74.07, 34.26, 58.33, 75.00, 0.0].</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuned</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>human_data_source</strong></td>
                            <td>Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>notes</strong></td>
                            <td>No human baseline accuracy is reported; the paper notes that letter-position importance patterns for LLMs align qualitatively with human findings from cited cognitive studies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The significance of letter position in word recognition <em>(Rating: 2)</em></li>
                <li>Recognition time for letters and nonletters: effects of serial position, array size, and processing order <em>(Rating: 2)</em></li>
                <li>The importance of the first and last letter in words during sentence reading <em>(Rating: 2)</em></li>
                <li>Masked language modeling and the distributional hypothesis: Order word matters pre-training for little <em>(Rating: 1)</em></li>
                <li>UnNatural Language Inference <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7489",
    "paper_id": "paper-7354a57261d27a281e56dc428b6ec146b9992afd",
    "extraction_schema_id": "extraction-schema-136",
    "extracted_data": [
        {
            "name_short": "ScrRec (GPT-4)",
            "name_full": "Scrambled Sentence Recovery task evaluated with GPT-4",
            "brief_description": "ScrRec measures the model's ability to reconstruct original sentences from character‑scrambled sentences; GPT‑4 achieves near‑perfect recovery rates across scramble types and rates reported in the paper.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Closed-source large autoregressive transformer-based LLM from OpenAI (chat/completion API variant GPT-4-0314 used in experiments).",
            "model_size": null,
            "test_name": "Scrambled Sentence Recovery (ScrRec; typoglycemia-style scrambled word recognition)",
            "test_category": "reading / lexical recognition",
            "test_description": "Given a sentence whose words have been character-scrambled under various schemes (random scramble, keep-first, keep-first-and-last), the model is asked to recover the original sentence; performance quantified by edit distance (ED) and Recovery Rate (RR = proportion of ED reduced).",
            "evaluation_metric": "Edit Distance (ED) and Recovery Rate (RR, percent ED reduction)",
            "human_performance": null,
            "llm_performance": "Zero-shot: ED (20%,50%,100%,KF,KFL) = [1.69, 2.78, 5.47, 4.19, 2.53]; RR (20%,50%,100%,KF,KFL) = [93.76%, 95.89%, 95.94%, 95.99%, 96.66%]. (Few-shot 3-shot exemplars reported similar RR ~94.5–97.0%). Paper summary: GPT-4 reduces edit distance by ~95% even at 100% random scramble.",
            "prompting_method": "Zero-shot; few-shot (3-shot) also evaluated for ScrRec",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as background on human recognition of scrambled words; no numeric human baseline reported in this paper)",
            "statistical_significance": null,
            "notes": "The paper frames ScrRec as analogous to typoglycemia and notes consistency with human letter-position importance, but it does not report numeric human baseline performance. GPT-4 maintains RR ≈95% across scramble types and rates; other LLMs degrade noticeably as scramble difficulty increases.",
            "uuid": "e7489.0",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrQA (GPT-4)",
            "name_full": "Scrambled Question Answering (ScrQA) evaluated with GPT-4",
            "brief_description": "ScrQA measures model QA accuracy when evidence/context sentences are character‑scrambled; GPT‑4 retains a large fraction of its original accuracy even with heavily scrambled evidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Closed-source large autoregressive transformer-based LLM from OpenAI (GPT-4-0314 used).",
            "model_size": null,
            "test_name": "Scrambled Question Answering (ScrQA)",
            "test_category": "reading comprehension / reasoning",
            "test_description": "Answer multiple-choice or extractive questions using evidence/context in which words are character-scrambled under various schemes and rates; performance reported as accuracy and Relative Performance Gain (RPG) relative to original and substituted (randomized) evidence.",
            "evaluation_metric": "Accuracy (%) and Relative Performance Gain (RPG, normalized accuracy change)",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA dataset): Accuracy (Ori, 20%, 50%, 100%, KF, KFL, Sub) = [97.69%, 97.40%, 96.82%, 93.35%, 93.35%, 95.66%, 62.14%]. RPG (normalized) = [100.0, 99.19, 97.56, 87.80, 87.80, 94.31, 0.0]. Paper notes GPT-4 maintains ~87.8% of its original performance at 100% random scramble.",
            "prompting_method": "Zero-shot",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as background; no empirical human QA baseline given in this paper)",
            "statistical_significance": null,
            "notes": "Human baselines for ScrQA with scrambled evidence are not provided. GPT-4 substantially outperforms other evaluated LLMs on ScrQA as scramble difficulty and rate increase.",
            "uuid": "e7489.1",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrRec (GPT-3.5)",
            "name_full": "Scrambled Sentence Recovery task evaluated with GPT-3.5‑turbo",
            "brief_description": "GPT‑3.5‑turbo's ability to recover sentences from scrambled inputs is substantially lower than GPT‑4 and degrades with increasing scramble difficulty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo",
            "model_description": "Closed-source OpenAI LLM (GPT-3.5-turbo-0301 version used), transformer-based chat/completion model.",
            "model_size": null,
            "test_name": "Scrambled Sentence Recovery (ScrRec)",
            "test_category": "reading / lexical recognition",
            "test_description": "Recover original sentences from character-scrambled sentences; measured by ED and Recovery Rate (RR).",
            "evaluation_metric": "Edit Distance (ED) and Recovery Rate (RR)",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [82.72%, 80.82%, 77.88%, 86.39%, 90.82%]; ED values reported in table. Performance drops as scramble difficulty increases; fewer than GPT-4.",
            "prompting_method": "Zero-shot (few-shot also evaluated elsewhere in paper)",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)",
            "statistical_significance": null,
            "notes": "No human numeric baseline provided. GPT‑3.5 shows moderate degradation with increased scramble rate compared to GPT‑4.",
            "uuid": "e7489.2",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrQA (GPT-3.5)",
            "name_full": "Scrambled Question Answering evaluated with GPT-3.5‑turbo",
            "brief_description": "GPT‑3.5‑turbo's accuracy on QA with scrambled evidence falls with scramble rate and type and is below GPT‑4's performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo",
            "model_description": "Closed-source transformer-based chat/completion model from OpenAI.",
            "model_size": null,
            "test_name": "Scrambled Question Answering (ScrQA)",
            "test_category": "reading comprehension / reasoning",
            "test_description": "Answer questions using scrambled context; accuracy and RPG report robustness relative to original context.",
            "evaluation_metric": "Accuracy (%) and RPG",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [97.11%, 94.80%, 91.33%, 81.79%, 88.44%, 93.06%, 52.60%]. RPG = [100.0, 94.81, 87.01, 65.58, 80.52, 90.91, 0.0].",
            "prompting_method": "Zero-shot",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)",
            "statistical_significance": null,
            "notes": "No human baseline presented. GPT‑3.5 loses a larger fraction of its original accuracy than GPT‑4 at high scramble rates.",
            "uuid": "e7489.3",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrRec (text-davinci-003)",
            "name_full": "Scrambled Sentence Recovery task evaluated with text-davinci-003",
            "brief_description": "text-davinci-003 shows substantially lower recovery rates than the top ChatGPT/GPT‑4 models and is more affected by heavy scrambling.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "text-davinci-003",
            "model_description": "OpenAI family GPT-3-based instruction-tuned model (text-davinci-003).",
            "model_size": null,
            "test_name": "Scrambled Sentence Recovery (ScrRec)",
            "test_category": "reading / lexical recognition",
            "test_description": "Recover original sentences from scrambled sentences; performance reported as ED and RR.",
            "evaluation_metric": "Edit Distance (ED) and Recovery Rate (RR)",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [44.52%, 52.96%, 18.61%, 70.45%, 82.41%]; ED values also reported. Performance degrades strongly with heavy random scrambling.",
            "prompting_method": "Zero-shot",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)",
            "statistical_significance": null,
            "notes": "No human baseline; text-davinci-003 performs worse than GPT-3.5 and GPT-4 on these tasks according to reported RR/ED metrics.",
            "uuid": "e7489.4",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrQA (text-davinci-003)",
            "name_full": "Scrambled Question Answering evaluated with text-davinci-003",
            "brief_description": "text-davinci-003 accuracy on QA with scrambled evidence drops as scramble rate increases and is substantially lower than GPT‑4.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "text-davinci-003",
            "model_description": "OpenAI GPT-3 family instruction-tuned model.",
            "model_size": null,
            "test_name": "Scrambled Question Answering (ScrQA)",
            "test_category": "reading comprehension / reasoning",
            "test_description": "Answering questions using scrambled context; accuracy and RPG metrics evaluate robustness.",
            "evaluation_metric": "Accuracy (%) and RPG",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [93.93%, 91.62%, 87.28%, 77.46%, 84.10%, 88.15%, 54.91%]. RPG = [100.0, 94.07, 82.96, 57.78, 74.81, 85.19, 0.0].",
            "prompting_method": "Zero-shot",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)",
            "statistical_significance": null,
            "notes": "Human baseline not provided. text-davinci-003 loses more accuracy at high scramble rates than GPT-4.",
            "uuid": "e7489.5",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrRec (Llama-2-70b)",
            "name_full": "Scrambled Sentence Recovery task evaluated with Llama‑2‑70b",
            "brief_description": "Llama-2-70b (70B parameter open-source model) obtains moderate recovery rates on ScrRec but fails under extreme (100% random) scramble in zero-shot settings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama-2-70b",
            "model_description": "Open-source Llama 2 family decoder-only transformer model (70B parameters).",
            "model_size": "70B",
            "test_name": "Scrambled Sentence Recovery (ScrRec)",
            "test_category": "reading / lexical recognition",
            "test_description": "Recover original sentences from character-scrambled inputs; evaluated by ED and RR.",
            "evaluation_metric": "Edit Distance (ED) and Recovery Rate (RR)",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrRec): RR (20%,50%,100%,KF,KFL) = [70.04%, 39.32%, &lt;0, 42.45%, 71.34%]. (Few-shot improves some settings.)",
            "prompting_method": "Zero-shot (few-shot also reported in paper)",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited as human behavior references only)",
            "statistical_significance": null,
            "notes": "At 100% random scrambling Llama-2-70b's RR becomes negative (worse than scrambled input) in zero-shot; finetuning on scrambled text (reported elsewhere in appendix for other Llama variants) can improve performance.",
            "uuid": "e7489.6",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "ScrQA (Llama-2-70b)",
            "name_full": "Scrambled Question Answering evaluated with Llama‑2‑70b",
            "brief_description": "Llama‑2‑70b's QA accuracy declines with scramble rate and performs substantially worse than GPT‑4 on heavily scrambled evidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama-2-70b",
            "model_description": "Open-source Llama 2 family decoder-only transformer model (70B parameters).",
            "model_size": "70B",
            "test_name": "Scrambled Question Answering (ScrQA)",
            "test_category": "reading comprehension / reasoning",
            "test_description": "Answer multiple-choice questions using scrambled evidence; measured by accuracy and RPG.",
            "evaluation_metric": "Accuracy (%) and RPG",
            "human_performance": null,
            "llm_performance": "Zero-shot (RealtimeQA ScrQA): Accuracy (Ori,20%,50%,100%,KF,KFL,Sub) = [88.44%, 86.13%, 80.35%, 67.92%, 75.43%, 80.64%, 57.23%]. RPG = [100.0, 92.59, 74.07, 34.26, 58.33, 75.00, 0.0].",
            "prompting_method": "Zero-shot",
            "fine_tuned": false,
            "human_data_source": "Rawlinson (2007); Mason (1982); Johnson and Eisler (2012) (cited background only)",
            "statistical_significance": null,
            "notes": "No human baseline accuracy is reported; the paper notes that letter-position importance patterns for LLMs align qualitatively with human findings from cited cognitive studies.",
            "uuid": "e7489.7",
            "source_info": {
                "paper_title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The significance of letter position in word recognition",
            "rating": 2
        },
        {
            "paper_title": "Recognition time for letters and nonletters: effects of serial position, array size, and processing order",
            "rating": 2
        },
        {
            "paper_title": "The importance of the first and last letter in words during sentence reading",
            "rating": 2
        },
        {
            "paper_title": "Masked language modeling and the distributional hypothesis: Order word matters pre-training for little",
            "rating": 1
        },
        {
            "paper_title": "UnNatural Language Inference",
            "rating": 1
        }
    ],
    "cost": 0.01948825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text</h1>
<p>Qi Cao, Takeshi Kojima, Yutaka Matsuo, Yusuke Iwasawa<br>The University of Tokyo, Japan<br>{qi.cao,t.kojima,matsuo,iwasawa}@weblab.t.u-tokyo.ac.jp</p>
<h4>Abstract</h4>
<p>While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia ${ }^{1}$, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by $95 \%$, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text. ${ }^{2}$</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) demonstrate impressive proficiency across a range of tasks, with certain capabilities emerging as the models scale up in size-a phenomenon commonly known as emergent abilities. (Wei et al., 2022a). As LLMs</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: GPT-4 can recover original sentence from scrambled sentence (upper) and answer question based on scrambled context (lower), even if the tokenization drastically changes. The colors indicate the division of sub-words during the tokenization.
become more "intelligent", many new benchmarks have been proposed (Liang et al., 2022; Qin et al., 2023) to investigate the abilities of LLMs. Nonetheless, the internal mechanisms underlying the abilities of LLMs remain enigmatic.</p>
<p>Several studies investigate the behavior of LLMs given some input perturbations. For example, Sinha et al. (2021a,b); Abdou et al. (2022) investigate the influence of word-level permutations and discuss the phenomenon that models are insensitive to permutations of word order which corrupt the original syntax, in some downstream tasks (e.g., natural language inference). These results are particularly interesting because they challenge the common assumption of the inner workings of LLMs, i.e., LLMs understand human-like syntax to some extent and use it to understand sentences.</p>
<p>Going beyond the effect of word-level permutations, we investigate the ability of LLMs under</p>
<p>character-level permutations. LLMs are supposed to rely on the tokenizers to turn natural language into the form that LLMs can perceive. It would be counter-intuitive if LLMs could effectively handle text containing unnatural permutations that significantly alter tokenization. In other words, we propose the following research question: Deos the oredr of ltteers in wrods mttaer for LLMs? Note that the above sentence contains scrambled words, but humans can somehow recognize and understand such a sentence, as several cognitive studies have explored (Rawlinson, 2007; Mason, 1982; Johnson and Eisler, 2012). Analyzing the robustness of LLMs against such character-level permutations can shed light on their word comprehension capabilities and reveal differences between various LLMs and human understanding.</p>
<p>To this end, this paper first constructs Scrambled Bench, which converts existing benchmarks into a test suite to measure the ability of LLMs to handle scrambled text. We designed two types of tasks: (1) Scrambled Sentence Recovery, which tests the capability of LLMs to reconstruct original sentences from scrambled ones, and (2) Scrambled Question Answering, which measures how well LLMs can answer questions when some context is scrambled. Note that since the slight change in letter-order within a word drastically changes the tokenized output (see Figure 1), it is questionable whether LLMs can recognize the scrambled words in a sentence. Counter-intuitively, we show that most powerful LLMs are able to handle scrambled sentences to varying degrees, when we scramble words while keeping the first and last letters unchanged. More surprisingly, we found that only GPT-4 can almost flawlessly process inputs with unnatural errors, even under extreme conditions. That is, even when we scramble all letters in words, GPT-4 manages to handle such input - a significantly challenging task for other models and even humans. For instance, GPT-4 can reconstruct original sentences to near-perfect recovery rate in the extreme scenario, as in Figure 1.</p>
<h2>2 Related Works</h2>
<p>The most related works are the studies investigating the effects of word or sub-word level perturbations (Sinha et al., 2021a,b; Pham et al., 2021; Abdou et al., 2022) and the studies evaluating the robustness of LLMs (Wang et al., 2023; Zhu et al., 2023). To the best of our knowledge, no existing studies have investigated LLMs' ability to handle character-level permutations, particularly those of an extremely high level that drastically change tokenization. Our study aims to fill this gap. Table 2 in Appendix B categorizes the prior studies and demonstrates the position of our study.</p>
<p>For evaluations, we assess the ability to reconstruct the original text from its scrambled version and to answer questions using the scrambled text as a reference. It differs with typographical error correction (Shah and de Melo, 2020; Sun et al., 2022), as (i) we do not train models to correct errors, i.e., we measure the ability of LLMs, and (ii) we add much more severe noises than natural typographical errors. The word unscrambling task in BigBench (Srivastava et al., 2023) is similar to our recovery task. However, it is more akin to a wordplay puzzle rather than a task for comprehending scrambled text, since it includes only single common words and no context is given.</p>
<h2>3 Scrambled Bench</h2>
<p>We propose two tasks (as in Figure 1) to evaluate the capability of LLMs to handle scrambled text:
(1) Scrambled Sentence Recovery (ScrRec). In this task, we provide a sentence containing scrambled words to LLMs and then ask them to recover original sentence from it. This task can be utilized to directly measure the capability of LLMs to recognize and reconstruct the scrambled words in a sentence.
(2) Scrambled Question Answering (ScrQA). While ScrRec can directly measure the capability to comprehend and process scrambled text, it is an "unusual" task for LLMs. If a model does not perform well on the recovery task, there are two possible reasons: (i) having difficulty following the instructions and (ii) not being able to recover sentences. To distinguish them, we measure the ability to accomplish a standard task (i.e., QA) given scrambled context. Specifically, we scramble the context that contains essential information for answering questions and then assess the models based on the variations in their performances.</p>
<h3>3.1 Dataset Creation</h3>
<p>Data contamination is a significant concern when assessing LLMs, when the test data for downstream tasks has been inadvertently included in the training set. This issue is critical for our tasks, as the relia-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Experimental results using scrambled RealtimeQA dataset, including performance on ScrRec in a zero-shot setting (left) and a few-shot setting (middle) and performance on ScrQA in a zero-shot setting (right). The missing bars represent values less than zero.</p>
<p>Bility of the results could be compromised if some models simply memorized original content. To mitigate this, we primarily utilize a scrambled version of RealtimeQA <em>Kasai et al. (2022)</em> for evaluations in this study. RealtimeQA is a dynamic question answering dataset that weekly announces questions about recent news that are unlikely to be memorized by the current LLMs. Specifically, we collect the most recent data (2023/03/17–2023/08/04) from RealtimeQA (totally 419 samples) and process the evidence sentences to construct samples for ScrRec and ScrQA. Finally, 418 samples are selected for ScrRec (removing a duplicate sentence), and 346 samples are selected for ScrQA (manually eliminating 73 samples when the provided evidence does not provide sufficient information to answer the corresponding question).</p>
<p>Besides, we also introduce two additional datasets: DREAM <em>Sun et al. (2019)</em> and AQuA-RAT <em>Ling et al. (2017)</em>. DREAM is a dialog- and multiple-choice reading comprehension dataset. AQuA-RAT is a dataset of math word problems necessitating multi-step reasoning for their resolution. For DREAM dataset, we constructed the dataset by selecting 1025 samples with annotated categories from the development and test sets and then scrambling the dialogue part of each question. For AQuA-RAT dataset, we adopt the few-shot Chain of Thought (CoT) setting as in Wei et al. 2022b and evaluate LLMs with scrambled questions in samples and demonstrations.</p>
<p>For each dataset, we generate scrambled text with various scramble types and rates. <strong>(1) Randomly Scramble (RS)</strong>. For each sentence, we randomly select a certain rate (20%, 50%, 100% in our experiments) of words and randomly scramble all letters in each selected word (Arabic numerals are kept invariant). <strong>(2) Keep First (KF)</strong>. We keep the first letter in each word unchanged and randomly scramble the letters in other positions. <strong>(3) Keep First and Last (KFL)</strong>. We keep the first and last letter in each word unchanged and randomly scramble the letters in other positions. We use KF and KFL to investigate the effects of different scramble types in word recognition for LLMs.</p>
<h3>3.2 Metrics</h3>
<p>For ScrRec, the average Edit Distance (ED) <em>Levenshtein (1966)</em> between original sentences and recovered sentences is a natural metric to quantify the performance. Besides, we define Recovery Rate (RR) to measure the proportion of ED reduced in recovered sentences, which makes the performance comparison in different settings more straightforward as:</p>
<p>$$RR = \frac{\sum_{i}^{n} ED(ori_i, rec_i) - \sum_{i}^{n} ED(ori_i, scr_i)}{\sum_{i}^{n} ED(ori_i, scr_i) \tag{1}$$</p>
<p>where <em>ori<sub>i</sub></em>, <em>scr<sub>i</sub></em>, <em>rec<sub>i</sub></em> mean original sentence, scrambled sentence, and recovered sentence of sample <em>i</em>, respectively. If a model is capable of recovering scrambled text to some extent, its RR should range between 0 and 100%.</p>
<p>For ScrQA, accuracy is a natural metric to measure the performance. But varying capabilities of models on original questions make it hard to compare the performance among models. So, Relative Performance Gain (RPG) is defined to mitigate the differences and make evaluations focus on how well models are able to comprehend scrambled text in comparison to original text as:</p>
<p>$$RPG = \frac{Acc_{scr} - Acc_{sub}}{Acc_{ori} - Acc_{sub}} \tag{2}$$</p>
<p>where <em>Acc<sub>ori</sub></em>, <em>Acc<sub>scr</sub></em>, <em>Acc<sub>sub</sub></em> are defined as accuracy when using original evidences, scrambled evidences, substituted evidences (in which all letters</p>
<p><sup>3</sup>In the latter part of the paper, RS denotes 100% randomly scrambling, unless a different percentage is specified.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The effect of scramble rates on the performance on ScrRec (left) and ScrQA (right) using RealtimeQA dataset. The missing points represent values less than zero.</p>
<p>of words that can be scrambled have been substituted with random letters), respectively. <em>Accori</em>, <em>Accsub</em> are served as the higher bound and the lower bound of accuracy, respectively. Normally, RPG ranges between 0 and 100%.</p>
<h2>4 Experiments</h2>
<h3>Models and Settings</h3>
<p>In the experiments, we evaluate the most powerful closed-source LLMs, including text-davinci-003 (Brown et al., 2020), GPT-3.5-turbo and GPT-4 (OpenAI, 2023) and the open-source models from Falcon series (Penedo et al., 2023), Llama-2 series (Touvron et al., 2023), MPT series (Team, 2023), UL2 series (Tay et al., 2022), T5 series (Raffel et al., 2020; Chung et al., 2022; Xue et al., 2022). For the scrambled RealtimeQA dataset, we adopt a zero-shot setting and a few-shot setting with 3-shot exemplars from the wikiQA dataset (Yang et al., 2015) for ScrRec, while we only conduct experiments in a zero-shot setting for ScrQA (since the task is rather straightforward). For the scrambled DREAM dataset, the setting is also zero-shot ScrQA. For the scrambled AQuA dataset, we adopt a few-shot CoT setting with scrambled demonstrations (in the question part). Note that we are showcasing the results of the top five most proficient LLMs (i.e., GPT-4, GPT-3.5-turbo, text-davinci-003, Falcon-180b, Llama-2-70b) in this section, while full results can be found in Appendix D and examples of different tasks can be found in Appendix C.</p>
<h3>Results 1: Effect of different scramble types</h3>
<p>Figure 2 show the results on zero-shot ScrRec, few-shot ScrRec, and zero-shot ScrQA, with three scramble types: randomly scramble (RS), keep first (KF), and keep first and last (KFL). The results show the performance gaps between models are not large in KFL setup. However, except for GPT-4, performance significantly decreases as the difficulty of scramble types increases (KFL, KF, and RS in order). In contrast, the performance of GPT-4 remains constantly high regardless of the scramble types. On ScrRec, RR of GPT-4 is constantly above 95% for all setups. On ScrQA, GPT-4 consistently outperforms other models, maintaining a high level of accuracy even as the difficulty of scramble types increases.</p>
<h3>Results 2: Effect of different scramble rates</h3>
<p>Figure 3 (left) illustrates the relationship between the scramble rates (i.e., the percentages of randomly scrambled words in text) and the performance on ScrRec using scrambled RealtimeQA. As the scramble rates increases, RR decreases for text-davinci-003, Falcon-180b and Llama-2-70b. RR of GPT-3.5-turbo and GPT-4 does not change significantly. GPT-4 outperforms other models by a wide margin, with higher than 95% RR for most setups (except for 20% scramble rate).</p>
<p>Figure 3 (right) displays a plot of RPG versus scramble rates for different models on ScrQA using scrambled RealtimeQA. RPG of all models drops as scramble percentage increases. But GPT-4 maintains 87.8% of its original performance even with 100% scrambled evidences. The gap between the performance of different models becomes larger when the scramble rates increases. Table 3, Table 4 and Table 5 in Appendix D show full results on scrambled RealtimeQA, with additional evaluation metrics (ED for ScrRec and Acc for ScrQA).</p>
<h3>Results 3: Results of additional datasets</h3>
<p>We test the generality of the finding across datasets by two additional datasets for ScrQA. On scram-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Experimental results of ScrQA on scrambled DREAM dataset (zero-shot). Overall performance and performance on different categories of questions. The missing bars represent values less than or equal to zero.</p>
<table>
<thead>
<tr>
<th>Exemplars</th>
<th>Original</th>
<th>20%</th>
<th>50%</th>
<th>100%</th>
</tr>
</thead>
<tbody>
<tr>
<td>Question</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Original</td>
<td>66.93</td>
<td>52.76</td>
<td>46.85</td>
<td>70.87</td>
</tr>
<tr>
<td>20%</td>
<td>66.54</td>
<td>49.61</td>
<td>40.94</td>
<td>74.02</td>
</tr>
<tr>
<td>50%</td>
<td>67.72</td>
<td>40.94</td>
<td>40.94</td>
<td>65.75</td>
</tr>
<tr>
<td>100%</td>
<td>64.17</td>
<td>29.92</td>
<td>26.77</td>
<td>62.60</td>
</tr>
</tbody>
</table>
<p>Table 1: Experimental results of ScrQA on scrambled AQuA-RAT dataset in a few-shot CoT setting. LLMs are assessed in various scenarios by adjusting scramble rate of questions in examplars and the main question. (left: GPT-4; middle: GPT-3.5-turbo; right: text-davinci-003). Metric: Acc (\%).</p>
<p>bled DREAM dataset, we evaluate performance not only overall but also on different categories of questions using the annotations (in Figure 4). The performance disparities between GPT-4 and other models are more pronounced than those observed on RealtimeQA, possibly since DREAM requires higher-level comprehension of longer texts. The performance on arithmetic questions tends to be more susceptible to scrambled text compared to other categories, even for GPT-4. Table 1 demonstrates experimental results in a 4-shot CoT setting on scrambled AQuA-RAT dataset (we only assess the three closed-source models here because even original questions in AQuA-RAT are too challenging for most open-source models). We evaluate models with several different scenarios by changing scramble rates in both main question and questions in exemplars. The results show the influence of scrambled exemplars is relatively small. The performance of GPT-3.5-turbo and text-davinci-003 declines markedly as the scramble rate of the main questions reaches $100 \%$, whereas GPT-4 retains much of its initial performance. Table 6, Table 7 and Table 8 in Appendix D show full results on scrambled DREAM dataset.</p>
<p>We also conduct a deeper analysis, the details of which can be found in Appendix A.</p>
<h2>5 Conclusion</h2>
<p>In this study, we propose Scrambled Bench, a test suite to measure the ability of LLMs to handle scrambled text, including two tasks (i.e., scrambled sentence recovery and scrambled question answering) and construct scrambled datasets based on RealtimeQA, DREAM and AQuA-RAT. Despite the scrambled text drastically changes the tokenization, we demonstrate that most powerful LLMs are capable of processing scrambled text to varying degrees. However, most LLMs have difficulty handling text that is scrambled to an extreme degree (i.e., $100 \%$ randomly scrambling). Surprisingly, for both tasks, GPT-4 shows good results and outperforms other models by a large margin. For the scrambled sentence recovery task, GPT-4 can recover sentences by $95 \%$ edit distance reduction even in $100 \%$ randomly scrambling settings. For the scrambled question answering task, GPT-4 can maintain a very high proportion of its original accuracy using scrambled context.</p>
<h2>Limitations</h2>
<p>For LLMs, there are various ways to disrupt the tokenization of words (e.g., inserting letters, substituting letters). In this study, we only investigate the influence of scrambling the letter-order in words. Investigating the performance of LLMs to handle other situations would be an interesting topic.</p>
<p>In addition, we have conducted our experiments using only three datasets, RealtimeQA, DREAM and AQuA-RAT. Experiments on more diverse datasets could be another future work. Note that the two tasks can be applicable for diverse datasets, and it is easy to extend the analysis.</p>
<p>We investigate the capability of different LLMs to handle scrambled text in different settings. However, it is difficult to conclude the reason why some LLMs are capable of handling these tasks. Especially, the reason why GPT-4 can perform almost perfectly would be an interesting topic worth further investigation. We can not access the closedsource models directly and are aware of little information about them (even the exact parameter size of GPT-4). This makes investigating the reason difficult. One potential hypothesis is that this capability might stem from training methods, such as including denoising tasks or utilizing a huge corpus of text data with various errors. Another one is that this capability could emerges as LLMs scale. Validating the potential hypotheses could enhance our understanding of the inner workings of LLMs.</p>
<h2>References</h2>
<p>Mostafa Abdou, Vinit Ravishankar, Artur Kulmizev, and Anders Søgaard. 2022. Word order does matter and shuffled language models know it. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 6907-6919, Dublin, Ireland. Association for Computational Linguistics.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam</p>
<p>Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. 2022. Scaling instruction-finetuned language models.</p>
<p>Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. Qlora: Efficient finetuning of quantized llms. arXiv preprint arXiv:2305.14314.</p>
<p>Wikimedia Foundation. Wikimedia downloads.
Rebecca L Johnson and Morgan E Eisler. 2012. The importance of the first and last letter in words during sentence reading. Acta psychologica, 141(3):336351.</p>
<p>Jungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, and Kentaro Inui. 2022. Realtime qa: What's the answer right now? arXiv preprint arXiv:2207.13332.</p>
<p>Vladimir I Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Soviet physics doklady, 10(8):707-710.</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al. 2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110.</p>
<p>Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale generation: Learning to solve and explain algebraic word problems. ACL.</p>
<p>Mildred Mason. 1982. Recognition time for letters and nonletters: effects of serial position, array size, and processing order. Journal of Experimental Psychology: Human Perception and Performance, 8(5):724.</p>
<p>OpenAI. 2023. Gpt-4 technical report.
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only. arXiv preprint arXiv:2306.01116.</p>
<p>Thang Pham, Trung Bui, Long Mai, and Anh Nguyen. 2021. Out of order: How important is the sequential order of words in a sentence in natural language understanding tasks? In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 1145-1160, Online. Association for Computational Linguistics.</p>
<p>Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is chatgpt a general-purpose natural language processing task solver? arXiv preprint arXiv:2302.06476.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485-5551.</p>
<p>Graham Rawlinson. 2007. The significance of letter position in word recognition. IEEE Aerospace and Electronic Systems Magazine, 22(1):26-27.</p>
<p>Kshitij Shah and Gerard de Melo. 2020. Correcting the autocorrect: Context-aware typographical error correction via training data augmentation. In Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 6930-6936, Marseille, France. European Language Resources Association.</p>
<p>Koustuv Sinha, Robin Jia, Dieuwke Hupkes, Joelle Pineau, Adina Williams, and Douwe Kiela. 2021a. Masked language modeling and the distributional hypothesis: Order word matters pre-training for little. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2888-2913, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</p>
<p>Koustuv Sinha, Prasanna Parthasarathi, Joelle Pineau, and Adina Williams. 2021b. UnNatural Language Inference. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 7329-7346, Online. Association for Computational Linguistics.</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2023. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research.</p>
<p>Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, and Claire Cardie. 2019. DREAM: A challenge data set and models for dialogue-based reading comprehension. Transactions of the Association for Computational Linguistics, 7:217-231.</p>
<p>Rui Sun, Xiuyu Wu, and Yunfang Wu. 2022. An errorguided correction model for Chinese spelling error correction. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 38003810, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Steven Zheng, et al. 2022. Ul2: Unifying language learning paradigms. In The Eleventh International Conference on Learning Representations.</p>
<p>MosaicML NLP Team. 2023. Introducing mpt-30b: Raising the bar for open-source foundation models. Accessed: 2023-06-22.</p>
<p>Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. BERT rediscovers the classical NLP pipeline. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 45934601, Florence, Italy. Association for Computational Linguistics.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.</p>
<p>Jindong Wang, HU Xixu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Wei Ye, Haojun Huang, Xiubo Geng, et al. 2023. On the robustness of chatgpt: An adversarial and out-ofdistribution perspective. In ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. Emergent abilities of large language models. Transactions on Machine Learning Research. Survey Certification.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.</p>
<p>Linting Xue, Aditya Barua, Noah Constant, Rami AlRfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022. ByT5: Towards a token-free future with pre-trained byte-to-byte models. Transactions of the Association for Computational Linguistics, 10:291-306.</p>
<p>Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. Wikiqa: A challenge dataset for open-domain question answering. In Proceedings of the 2015 conference on empirical methods in natural language processing, pages 2013-2018.</p>
<p>Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023. Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. arXiv preprint arXiv:2306.04528.</p>
<p>A Analysis</p>
<h3>A.1 Relationship to Parameter Scale</h3>
<p>By scaling up their parameters, LLMs can significantly enhance their performance across a range of tasks and even acquire emergent abilities that were previously unattainable with smaller parameter sizes. [wei2022gpt4].</p>
<p>We investigate the relationship between the ability to handle scrambled text and parameter scale. Figure 5 displays the performance of LLMs in relation to their parameter sizes on 100% randomly scrambled text to illustrates the relationship (though the parameter sizes of GPT-4 and GPT-3.5-turbo are unknown). On ScrRec-RealtimeQA, only the three closed-source models can achieve a positive recovery rate in the zero-shot setting, while an additional open-source model, Falcon-180b, can achieve a positive recovery rate in the few-shot setting alongside the closed-source models. On ScrQA, performance improves with parameter scaling when using RealtimeQA dataset. However, even when parameters are scaled up to 180 billion, performance improvement on the DREAM dataset is limited due to its longer texts and more diverse questions, which present greater challenges. The top three models in all evaluations are the three closed-source models. Especially, GPT-4 significantly outperforms the others, although its parameter size is unknown.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Performance of LLMs in relation to their parameter sizes on four tasks, tested on 100% randomly scrambled text.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Illustrating letter importance by comparing performance of LLMs between four scramble types.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Performance of probe classifier using hidden states of each layer to predict answer on DREAM dataset in different scramble settings for three Llama-2 model with different parameter sizes.</p>
<h2>A. 2 Letter Importance</h2>
<p>In main experiments, we evaluate LLMs on three scrambled types (i.e., RS, KF and KFL). Nevertheless, the findings do not offer definitive conclusions regarding the varying importance of letter positions in word recognition, as the words to be scrambled vary for each type (e.g., in RS, all words with more than one letter are scrambled, while in KFL, only words with more than three letters are scrambled). To investigate the letter importance in word recognition for LLMs, we add three additional scramble types: (1) KR2, where we keep two letters in random positions unchanged; (2) KL\&amp;KR1, where we keep the last letter and one letter in another random position unchanged; and (3) KF\&amp;KR1, where we keep the first letter and one letter in another random position unchanged. Using these three scramble types, along with KFL, we can mitigate the differ-
ence of scrambled words, since same words with more than three letters are scrambled in all four types.</p>
<p>Figure 6 demonstrates the performance of the top five LLMs on four scramble types. The performance of each LLM typically follows an ascending order: KR2, KL\&amp;KR1, KF\&amp;KR1, KFL, with the exception of ScrQA-RealtimeQA. On ScrRec, the gaps between different scramble types are larger for less capable models. However, on ScrQA, the gaps are smaller, especially when using RealtimeQA. This might be the reason why the pattern does not hold on ScrQA-RealtimeQA, as the randomness has a greater impact on performance order when the gaps are smaller. The results imply that the first and last letters are important for LLMs to recognize words, with the first letter being more important than the last letter. This finding is consistent with</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Layer-wise accuracy differential: the difference of probe task performance between using hidden states from the current layer and the previous layer for Llama-2-70b in different settings.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Comparison of performance between three finetuned models (FT-RS, FT-KF&amp;Adj, FT-Ori) and original Llama-2-13b without finetuing (w/o FT) in four task settings. The missing bars represent values less than or equal to zero.</p>
<p>human behavior (Rawlinson, 2007; Mason, 1982; Johnson and Eisler, 2012).</p>
<h3>A.3 Probing Hidden States</h3>
<p>To better investigate the internal mechanistic of LLMs to process scrambled text, we design a probe task using the hidden states of Llama-2 models of different parameter sizes (7b, 13b and 70b) when inputting scrambled text (Tenney et al., 2019). In the experiment, we collect all data in DREAM dataset (including training, development and test sets), and process each sample with various scrambles types and rates used in main experiments. The hidden state of last token in each layer (since last token contains all information of each question) is extracted when inputting the question with dialogue in various scramble settings (Ori, RS-20%, RS-50%, RS-100%, KF, KFL, Sub). For each layer, we train a logistic regression model as a probing classifier using a mixture of hidden states from different settings in the training set to predict the answer. We evaluate the performance in different scramble settings separately by using a combination of the development set and test set.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Level</th>
<th style="text-align: center;">Example <br> (Original: How does the change affect tokenization?)</th>
<th style="text-align: center;">Natural errors</th>
<th style="text-align: center;">Change of tokenization</th>
<th style="text-align: center;">Severity</th>
<th style="text-align: center;">Studies</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">How the affect does tokenization change?</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Order</td>
<td style="text-align: center;">Low-High</td>
<td style="text-align: center;">Sinha et al. 2021a, <br> Sinha et al. 2021b, <br> Pham et al. 2021, <br> Abdou et al. 2022</td>
</tr>
<tr>
<td style="text-align: center;">Sub-word</td>
<td style="text-align: center;">How change token does affectization the?</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Order</td>
<td style="text-align: center;">Low-High</td>
<td style="text-align: center;">Abdou et al. 2022</td>
</tr>
<tr>
<td style="text-align: center;">Character</td>
<td style="text-align: center;">How does the chagne affect tokeniztion?</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Tokens</td>
<td style="text-align: center;">Low</td>
<td style="text-align: center;">Wang et al. 2023, Zhu et al. 2023</td>
</tr>
<tr>
<td style="text-align: center;">Character</td>
<td style="text-align: center;">wHo deso teh chenga afctfe aotznoenitki?</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Tokens</td>
<td style="text-align: center;">Middle-Extremely High</td>
<td style="text-align: center;">Ours</td>
</tr>
</tbody>
</table>
<p>Table 2: Categorizing the prior studies and demonstrating the position of this work.</p>
<p>Figure 7 displays the layer-wise prediction accuracy using hidden states from three models. With more layers and more parameters for comprehension, LLMs tend to better comprehend scrambled text with the help of unchanged surrounding context (as in RS-20\%, RS-50\%) and unchanged first and last letters (as in KF, KFL). However, even for Llama-2-70b, comprehending the text in RS-100\% is still too challenging. Figure 8 shows the layerwise accuracy differential on probe task for Llama-2-70b in different settings. Ori, RS-20\%, RS-50\%, KF, and KFL exhibit similar patterns in layer distribution, but with varying degrees of change. However, the pattern of RS-100\% is more similar to that of Sub. For example, both RS-100\% and Sub show almost no improvement in the 20th layer, unlike what is observed in other settings.</p>
<h2>A. 4 Training on Scrambled Text</h2>
<p>To initially investigate the potential reasons for this phenomenon, we aim is to examine the impact of training on scrambled text. In this experiment, we select Llama-2-13b model as a base model, then finetune it on scrambled text and evaluate finetuned models on scrambled bench. The 20220301.simple subset from wikipedia dataset (Foundation) is utilized to finetune the model on a language modelling task (irrelevant to our evaluation tasks). We finetune Llama-2-13b on scrambled dataset with two settings: (1) randomly scramble $30 \%$ words with more than two letters in $60 \%$ samples (FT-RS); (2) keep first letter unchanged and swap two adjacent letters in other positions for $30 \%$ words with more than two letters in $60 \%$ samples (FT-KF\&amp;Adj) to simulate natural typographical errors that are more likely to be found in real-world text. Additionally, we finetune a model using the original dataset (FTOri) to serve as a control for comparative analysis.</p>
<p>Figure 9 demonstrates the comparison of performance between three finetuned models and original Llama-2-13b without finetuing (w/o FT) on various datasets and scramble types. FT-Ori usually gets performance similar to w/o FT (except for ScrQARealtimeQA) which indicates that the original data is not likely to be beneficial for evaluation tasks. FT-RS shows significant improvement over w/o-FT baseline across all tasks, and it achieves positive RR in RS setting, which even surpasses the performance of Falcon-180b. FT-KF\&amp;Adj gets similar or marginally better performance than w/o FT on ScrQA. While, on ScrRec, it improve a lot over w/o FT baseline in KF and KFL, especially it can achieve comparable performance with FT-RS in KFL. It could be inferred that training on text with natural errors is likely to be advantageous for models in handling unnatural scrambled text, especially under KFL condition.</p>
<h2>B Summary of related work</h2>
<p>Table 2 categorizes the related work and demonstrates the position of our study.</p>
<h2>C Examples of different tasks (by GPT-4)</h2>
<h2>C. 1 Zero-shot ScrRec on RealtimeQA</h2>
<p>Input:
The following sentence contains words with scrambled letters. Please recover original sentence from it.
Scrambled sentence: A reGebr byba ulfaorm wsa titbudiserd ot soetsr epdstie a lclera eovr bslpioes ionmanantitco, grnoadicc ot eth ADF. heT pyomacn si noniacrggue rptsean ot ckhec yna poduc-</p>
<p>srt yhte evah ta mhoe nda cdisadr sehot taht aym eb ecaeftdf.
Recovered sentence:</p>
<h2>Output:</h2>
<p>A Gerber baby formula was distributed to stores despite a recall over possible contamination, according to the FDA. The company is encouraging parents to check any products they have at home and discard those that may be affected.</p>
<h2>C. 2 Few-shot ScrRec on RealtimeQA</h2>
<h2>Input:</h2>
<p>Scrambled Sentence: eTh camp continued to fnctinuo this ayw ilntu the rwa needd.
Recovered Sentence: The camp continued to function this way until the war ended.</p>
<p>Scrambled Sentence: It swa first developed ni the 1980s yb oAcrn Computers tdL ot erowp their pstodke nmecisah and subsequently supn off sa a separate paocnmy, now ARM Holdings.
Recovered Sentence: It was first developed in the 1980s by Acorn Computers Ltd to power their desktop machines and subsequently spun off as a separate company, now ARM Holdings.</p>
<p>Scrambled Sentence: According to the CIA kcbFotoa, the United States is one fo eethr iusecnort (het etrhos nebgi Liberia nda mBuar/Myanmar) that sha not adopted eth International System fo Utins (SI) rmtcei symset as iethr ffliicao system fo gswheit dna measures.
Recovered Sentence: According to the CIA Factbook, the United States is one of three countries (the others being Liberia and Burma/Myanmar) that has not adopted the International System of Units (SI) metric system as their official system of weights and measures.</p>
<p>Scrambled sentence: A reGebr byba ulfaorm wsa titbudiserd ot soetsr epdstie a lclera eovr bslpioes ionmanantitco, grnoadicc ot eth ADF. heT pyomacn si noniacrggue rptsean ot ckhec yna poducsrt yhte evah ta mhoe nda cdisadr sehot taht aym eb ecaeftdf.
Recovered sentence:</p>
<h2>Output:</h2>
<p>A Gerber baby formula was distributed to stores despite a recall over possible contamination, according to the FDA. The company is encouraging parents to check any products they have at home
and discard those that may be affected.</p>
<h2>C. 3 Zero-shot ScrQA on RealtimeQA</h2>
<p>Input:
Question: Which type of product was recently distributed to some US stores despite a recall notice? Choices: (A)Salad dressing (B)Baby formula (C)Ground beef (D)Whole milk</p>
<p>Evidence: A reGebr byba ulfaorm wsa titbudiserd ot soetsr epdstie a lclera eovr bslpioes ionmanantitco, grnoadicc ot eth ADF. heT pyomacn si noniacrggue rptsean ot ckhec yna poducsrt yhte evah ta mhoe nda cdisadr sehot taht aym eb ecaeftdf.
Answer: Based on the evidence, among A through D, the answer is
Output:
(B)Baby formula</p>
<h2>C. 4 Zero-shot ScrQA on DREAM</h2>
<p>Input:
Dialogue:
M: owH goln veah uyo eben ehctnaig ni iths edmdli colosh?
W: Fro ent esray. oT eb akfrn, I'm edirt fo higneact het mesa bokoextt rof os ongl hghuto I od jyneo gebin a aterceh. I'm idenoncisrg gntriy minseghot wne.
Question: What's the woman probably going to do?
Choices: (A)To teach a different textbook. (B)To change her job. (C)To learn a different textbook. Answer: Based on the dialogue, among A through C, the answer is
Output:
(B)To change her job.</p>
<h2>C. 5 Few-shot CoT ScrQA on AQuA-RAT</h2>
<p>(I)</p>
<h2>Input:</h2>
<p>Question: hJno nfodu ttah teh gaeerav fo 15 rnsbmue si 40 . fI 10 si edadd ot ceha umenbr enht teh naem fo het rbenmsu si?
Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
Answer: If 10 is added to each number, then the mean of the numbers also increases by 10 . So the new mean would be 50 . The answer is (A).</p>
<p>Question: fI a / b = 3/4 dan $8 \mathrm{a}+5 \mathrm{~b}=22$, htne nfid het evual fo a.
Choices: (A) $1 / 2$ (B) $3 / 2$ (C) $5 / 2$ (D) $4 / 2$ (E) $7 / 2$
Answer: If a / b = 3/4, then b = 4a / 3. So 8a +</p>
<p>$5(4 a / 3)=22$. This simplifies to $8 a+20 a / 3=22$, which means $44 a / 3=22$. So a is equal to $3 / 2$. The answer is (B).</p>
<p>Question: A nprseo si gtlanrvie ta $20 \mathrm{mk} / \mathrm{rh}$ nda hdrecae ihs ynedits ni 2.5 rh neth fdin eth dicatsen?
Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 km</p>
<p>Answer: The distance that the person traveled would have been $20 \mathrm{~km} / \mathrm{hr} * 2.5 \mathrm{hrs}=50 \mathrm{~km}$. The answer is (E).</p>
<p>Question: wHo aymn etosreyksk ear deeend ot peyt het nsrbmeu rfmo 1 ot 500 ?
Choices: (A) 1156 (B) 1392 (C) 1480 (D) 1562 (E) 1788</p>
<p>Answer: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. $9+90(2)+401(3)=1392$. The answer is (B).</p>
<p>Question: A ritna inunrgn ta a eepsd fo 100 mlesi/uhro, eakts 10 hurso ot cerah ist dneitiotsan. trefA ovgeirnc etarqru fo het cntsdaie, ti tstrsa grniina nda eth rniat ash ot eb dlseow ot seedp fo 75 liesm/uhor. Wtha si het otalt orjeyun iroatdnu? Choices: (A) 10 (B) 11.5 (C) 12.5 (D) 13.5 (E) 15 Answer:</p>
<h2>Output:</h2>
<p>The train covers a quarter of the distance at 100 miles/hour, so it travels for 2.5 hours (10 hours / 4) at this speed. The remaining distance is $3 / 4$ of the total distance, which takes the train 7.5 hours ( 10 hours - 2.5 hours) at 100 miles/hour. When the train slows down to 75 miles/hour, it takes 1.5 times longer to cover the same distance ( 100 miles/hour / 75 miles/hour = 1.33). So the train takes 11.25 hours ( 7.5 hours * 1.33) to cover the remaining distance at 75 miles/hour. The total journey duration is 13.75 hours ( 2.5 hours +11.25 hours). The answer is (D).</p>
<h2>(2)</h2>
<h2>Input:</h2>
<p>Question: John found that the average of 15 numbers is 40 . If 10 is added to each number then the mean of the numbers is?
Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64
Answer: If 10 is added to each number, then the mean of the numbers also increases by 10 . So the
new mean would be 50 . The answer is (A).
Question: If $a / b=3 / 4$ and $8 a+5 b=22$, then find the value of $a$.
Choices: (A) $1 / 2$ (B) $3 / 2$ (C) $5 / 2$ (D) $4 / 2$ (E) $7 / 2$
Answer: If $a / b=3 / 4$, then $b=4 a / 3$. So $8 a+$ $5(4 a / 3)=22$. This simplifies to $8 a+20 a / 3=22$, which means $44 a / 3=22$. So a is equal to $3 / 2$. The answer is $(B)$.</p>
<p>Question: A person is traveling at $20 \mathrm{~km} / \mathrm{hr}$ and reached his destiny in 2.5 hr then find the distance?
Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 km</p>
<p>Answer: The distance that the person traveled would have been $20 \mathrm{~km} / \mathrm{hr} * 2.5 \mathrm{hrs}=50 \mathrm{~km}$. The answer is (E).</p>
<p>Question: How many keystrokes are needed to type the numbers from 1 to 500 ?
Choices: (A) 1156 (B) 1392 (C) 1480 (D) 1562 (E) 1788</p>
<p>Answer: There are 9 one-digit numbers from 1 to 9. There are 90 two-digit numbers from 10 to 99. There are 401 three-digit numbers from 100 to 500. $9+90(2)+401(3)=1392$. The answer is (B).</p>
<p>Question: ieahMnc A psut otu a oy-oy ryeve 6 nsimtue. enicMah B pstu uto a oy-oy veeyr 9 nmusite. tAefr hwo aynm smtnuei lwil yeth hvea eurdpcod 10 oy-soy?
Choices: (A) 24 minutes (B) 32 minutes (C) 36 minutes (D) 64 minutes (E) 72 minutes
Answer:</p>
<h2>Output:</h2>
<p>First, let's rewrite the question with the words unscrambled: "Machine A puts out a yo-yo every 6 minutes. Machine B puts out a yo-yo every 9 minutes. After how many minutes will they have produced 10 yo-yos?"</p>
<p>To solve this problem, we can find the least common multiple (LCM) of 6 and 9 , which is 18 . This means that every 18 minutes, both machines will have produced a yo-yo at the same time. In 18 minutes, Machine A will have produced 3 yo-yos (18/6) and Machine B will have produced 2 yo-yos (18/9), for a total of 5 yo-yos. Since we need 10 yo-yos, we can multiply 18 minutes by 2 to get 36 minutes. The answer is (C) 36 minutes.</p>
<h1>D Full experimental results</h1>
<p>We conduct experiments using the most powerful closed-source LLMs, including text-davinci-003, GPT-3.5-turbo and GPT-4 and various open-source LLMs, including the models from Falcon series, Llama-2 series, MPT series, UL2 series, and T5 series. The open-source model covers diverse model architectures (decoder only and encoder-decoder), model size (from 7b to 180b), training objectives (e.g., with or without further finetuning) and tokenizers (e.g., tokenizer-free: ByT5-xxl).</p>
<p>For GPT-4, the version GPT-4-0314 is used. For GPT-3.5-turbo, the version GPT-3.5-turbo-0301 is used. For Falcon-180b and Falcon-180b-chat, the quantized method (Dettmers et al., 2023) is used to load the model and run the experiments. It probably affects their performance to some extent.</p>
<h3>D. 1 Full experimental results on scrambled RealtimeQA dataset</h3>
<p>Table 3 and Table 4 illustrate the full experimental results on ScrRec using the scrambled RealtimeQA dataset in both few-shot and zero-shot settings, respectively.</p>
<p>Table 5 illustrates the full experimental results on ScrQA using scrambled RealtimeQA dataset in a zero-shot setting.</p>
<h2>D. 2 Full experimental results on scrambled DREAM dataset</h2>
<p>Table 6 illustrate the full experimental results on ScrQA using scrambled DREAM dataset in a zeroshot setting.</p>
<p>Table 7 and Table 8 display the experimental results for various question categories, comparing the top five models using Acc and RPG as evaluation metrics.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">1.49</td>
<td style="text-align: center;">2.40</td>
<td style="text-align: center;">4.79</td>
<td style="text-align: center;">3.79</td>
<td style="text-align: center;">2.24</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">94.51</td>
<td style="text-align: center;">96.46</td>
<td style="text-align: center;">96.45</td>
<td style="text-align: center;">96.37</td>
<td style="text-align: center;">97.04</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">5.80</td>
<td style="text-align: center;">15.38</td>
<td style="text-align: center;">36.87</td>
<td style="text-align: center;">20.76</td>
<td style="text-align: center;">7.40</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">78.57</td>
<td style="text-align: center;">77.29</td>
<td style="text-align: center;">72.63</td>
<td style="text-align: center;">80.14</td>
<td style="text-align: center;">90.22</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">5.38</td>
<td style="text-align: center;">18.89</td>
<td style="text-align: center;">84.39</td>
<td style="text-align: center;">22.21</td>
<td style="text-align: center;">8.36</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">80.13</td>
<td style="text-align: center;">72.11</td>
<td style="text-align: center;">37.35</td>
<td style="text-align: center;">78.75</td>
<td style="text-align: center;">88.95</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">4.18</td>
<td style="text-align: center;">21.84</td>
<td style="text-align: center;">116.73</td>
<td style="text-align: center;">28.77</td>
<td style="text-align: center;">9.40</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">84.55</td>
<td style="text-align: center;">67.76</td>
<td style="text-align: center;">13.34</td>
<td style="text-align: center;">72.47</td>
<td style="text-align: center;">87.58</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b-chat</td>
<td style="text-align: center;">11.61</td>
<td style="text-align: center;">38.19</td>
<td style="text-align: center;">186.65</td>
<td style="text-align: center;">63.51</td>
<td style="text-align: center;">21.73</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">57.12</td>
<td style="text-align: center;">43.62</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">39.24</td>
<td style="text-align: center;">71.28</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b</td>
<td style="text-align: center;">17.27</td>
<td style="text-align: center;">69.86</td>
<td style="text-align: center;">185.26</td>
<td style="text-align: center;">119.00</td>
<td style="text-align: center;">66.03</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">36.18</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">12.71</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b-instruct</td>
<td style="text-align: center;">18.79</td>
<td style="text-align: center;">74.26</td>
<td style="text-align: center;">192.86</td>
<td style="text-align: center;">130.82</td>
<td style="text-align: center;">62.39</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30.56</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">17.53</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">7.85</td>
<td style="text-align: center;">37.30</td>
<td style="text-align: center;">169.85</td>
<td style="text-align: center;">56.25</td>
<td style="text-align: center;">18.99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">44.93</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">46.19</td>
<td style="text-align: center;">74.9</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b-chat</td>
<td style="text-align: center;">11.11</td>
<td style="text-align: center;">54.49</td>
<td style="text-align: center;">196.44</td>
<td style="text-align: center;">106.31</td>
<td style="text-align: center;">43.18</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">58.97</td>
<td style="text-align: center;">19.56</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">42.93</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b</td>
<td style="text-align: center;">14.18</td>
<td style="text-align: center;">59.13</td>
<td style="text-align: center;">192.67</td>
<td style="text-align: center;">103.50</td>
<td style="text-align: center;">42.67</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">47.62</td>
<td style="text-align: center;">12.71</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">0.99</td>
<td style="text-align: center;">43.59</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b-chat</td>
<td style="text-align: center;">20.75</td>
<td style="text-align: center;">73.04</td>
<td style="text-align: center;">201.50</td>
<td style="text-align: center;">119.52</td>
<td style="text-align: center;">56.03</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">23.35</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">25.93</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b</td>
<td style="text-align: center;">20.90</td>
<td style="text-align: center;">79.83</td>
<td style="text-align: center;">194.48</td>
<td style="text-align: center;">135.50</td>
<td style="text-align: center;">68.18</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">22.77</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">9.88</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b-chat</td>
<td style="text-align: center;">25.14</td>
<td style="text-align: center;">83.13</td>
<td style="text-align: center;">196.88</td>
<td style="text-align: center;">132.44</td>
<td style="text-align: center;">73.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">7.11</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">2.39</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b</td>
<td style="text-align: center;">14.36</td>
<td style="text-align: center;">54.81</td>
<td style="text-align: center;">181.43</td>
<td style="text-align: center;">90.92</td>
<td style="text-align: center;">36.14</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">46.96</td>
<td style="text-align: center;">19.08</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">13.02</td>
<td style="text-align: center;">52.23</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b-instruct</td>
<td style="text-align: center;">19.36</td>
<td style="text-align: center;">66.05</td>
<td style="text-align: center;">170.88</td>
<td style="text-align: center;">99.38</td>
<td style="text-align: center;">50.44</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">28.46</td>
<td style="text-align: center;">2.49</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">4.92</td>
<td style="text-align: center;">33.33</td>
</tr>
<tr>
<td style="text-align: center;">UL2</td>
<td style="text-align: center;">18.12</td>
<td style="text-align: center;">68.79</td>
<td style="text-align: center;">153.53</td>
<td style="text-align: center;">109.47</td>
<td style="text-align: center;">71.70</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">33.03</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">5.22</td>
</tr>
<tr>
<td style="text-align: center;">Flan-UL2</td>
<td style="text-align: center;">20.51</td>
<td style="text-align: center;">62.91</td>
<td style="text-align: center;">137.15</td>
<td style="text-align: center;">105.67</td>
<td style="text-align: center;">74.35</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">24.21</td>
<td style="text-align: center;">7.13</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">1.72</td>
</tr>
<tr>
<td style="text-align: center;">Flan-T5-xxl</td>
<td style="text-align: center;">16.60</td>
<td style="text-align: center;">59.34</td>
<td style="text-align: center;">136.41</td>
<td style="text-align: center;">105.44</td>
<td style="text-align: center;">73.97</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">38.68</td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">2.22</td>
</tr>
<tr>
<td style="text-align: center;">ByT5-xxl</td>
<td style="text-align: center;">79.27</td>
<td style="text-align: center;">104.28</td>
<td style="text-align: center;">160.17</td>
<td style="text-align: center;">123.97</td>
<td style="text-align: center;">102.50</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
</tbody>
</table>
<p>Table 3: The experimental results on few-shot ScrRec using RealtimeQA dataset (upper: ED; lower: RR).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">1.69</td>
<td style="text-align: center;">2.78</td>
<td style="text-align: center;">5.47</td>
<td style="text-align: center;">4.19</td>
<td style="text-align: center;">2.53</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">93.76</td>
<td style="text-align: center;">95.89</td>
<td style="text-align: center;">95.94</td>
<td style="text-align: center;">95.99</td>
<td style="text-align: center;">96.66</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">13.00</td>
<td style="text-align: center;">29.80</td>
<td style="text-align: center;">14.22</td>
<td style="text-align: center;">6.94</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">82.72</td>
<td style="text-align: center;">80.82</td>
<td style="text-align: center;">77.88</td>
<td style="text-align: center;">86.39</td>
<td style="text-align: center;">90.82</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">15.02</td>
<td style="text-align: center;">31.86</td>
<td style="text-align: center;">109.63</td>
<td style="text-align: center;">30.88</td>
<td style="text-align: center;">13.30</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">44.52</td>
<td style="text-align: center;">52.96</td>
<td style="text-align: center;">18.61</td>
<td style="text-align: center;">70.45</td>
<td style="text-align: center;">82.41</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">7.18</td>
<td style="text-align: center;">26.53</td>
<td style="text-align: center;">159.36</td>
<td style="text-align: center;">43.63</td>
<td style="text-align: center;">13.08</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">73.48</td>
<td style="text-align: center;">60.84</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">58.25</td>
<td style="text-align: center;">82.72</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b-chat</td>
<td style="text-align: center;">15.92</td>
<td style="text-align: center;">50.50</td>
<td style="text-align: center;">180.13</td>
<td style="text-align: center;">76.31</td>
<td style="text-align: center;">29.29</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">41.17</td>
<td style="text-align: center;">25.46</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">27.0</td>
<td style="text-align: center;">61.29</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b</td>
<td style="text-align: center;">20.59</td>
<td style="text-align: center;">66.33</td>
<td style="text-align: center;">177.33</td>
<td style="text-align: center;">92.45</td>
<td style="text-align: center;">39.04</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">23.94</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">11.56</td>
<td style="text-align: center;">48.39</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b-instruct</td>
<td style="text-align: center;">26.42</td>
<td style="text-align: center;">78.94</td>
<td style="text-align: center;">178.55</td>
<td style="text-align: center;">104.46</td>
<td style="text-align: center;">48.42</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2.4</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">36.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">8.11</td>
<td style="text-align: center;">41.10</td>
<td style="text-align: center;">180.82</td>
<td style="text-align: center;">60.16</td>
<td style="text-align: center;">21.68</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">70.04</td>
<td style="text-align: center;">39.32</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">42.45</td>
<td style="text-align: center;">71.34</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b-chat</td>
<td style="text-align: center;">12.65</td>
<td style="text-align: center;">60.23</td>
<td style="text-align: center;">181.30</td>
<td style="text-align: center;">118.13</td>
<td style="text-align: center;">51.73</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">53.26</td>
<td style="text-align: center;">11.08</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">31.62</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b</td>
<td style="text-align: center;">20.21</td>
<td style="text-align: center;">75.54</td>
<td style="text-align: center;">231.41</td>
<td style="text-align: center;">127.63</td>
<td style="text-align: center;">59.77</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">25.32</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">20.99</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b-chat</td>
<td style="text-align: center;">26.79</td>
<td style="text-align: center;">84.09</td>
<td style="text-align: center;">191.85</td>
<td style="text-align: center;">120.51</td>
<td style="text-align: center;">63.82</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.03</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">15.64</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b</td>
<td style="text-align: center;">29.81</td>
<td style="text-align: center;">106.38</td>
<td style="text-align: center;">192.05</td>
<td style="text-align: center;">165.56</td>
<td style="text-align: center;">88.65</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b-chat</td>
<td style="text-align: center;">48.92</td>
<td style="text-align: center;">123.66</td>
<td style="text-align: center;">202.16</td>
<td style="text-align: center;">167.49</td>
<td style="text-align: center;">112.03</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b</td>
<td style="text-align: center;">20.54</td>
<td style="text-align: center;">70.69</td>
<td style="text-align: center;">226.34</td>
<td style="text-align: center;">135.58</td>
<td style="text-align: center;">62.16</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">24.11</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">17.84</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b-instruct</td>
<td style="text-align: center;">36.01</td>
<td style="text-align: center;">84.98</td>
<td style="text-align: center;">233.60</td>
<td style="text-align: center;">132.77</td>
<td style="text-align: center;">76.60</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">UL2</td>
<td style="text-align: center;">72.39</td>
<td style="text-align: center;">139.14</td>
<td style="text-align: center;">205.86</td>
<td style="text-align: center;">188.57</td>
<td style="text-align: center;">163.67</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">Flan-UL2</td>
<td style="text-align: center;">33.10</td>
<td style="text-align: center;">71.76</td>
<td style="text-align: center;">136.94</td>
<td style="text-align: center;">106.48</td>
<td style="text-align: center;">78.55</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">Flan-T5-xxl</td>
<td style="text-align: center;">27.07</td>
<td style="text-align: center;">68.02</td>
<td style="text-align: center;">136.47</td>
<td style="text-align: center;">106.08</td>
<td style="text-align: center;">76.69</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
<tr>
<td style="text-align: center;">ByT5-xxl</td>
<td style="text-align: center;">85.83</td>
<td style="text-align: center;">111.53</td>
<td style="text-align: center;">155.27</td>
<td style="text-align: center;">136.99</td>
<td style="text-align: center;">117.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">$&lt;0$</td>
</tr>
</tbody>
</table>
<p>Table 4: The experimental results on zero-shot ScrRec using RealtimeQA dataset (upper: ED; lower: RR).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Ori</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
<th style="text-align: center;">Sub</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">97.69</td>
<td style="text-align: center;">97.40</td>
<td style="text-align: center;">96.82</td>
<td style="text-align: center;">93.35</td>
<td style="text-align: center;">93.35</td>
<td style="text-align: center;">95.66</td>
<td style="text-align: center;">62.14</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.19</td>
<td style="text-align: center;">97.56</td>
<td style="text-align: center;">87.80</td>
<td style="text-align: center;">87.80</td>
<td style="text-align: center;">94.31</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">97.11</td>
<td style="text-align: center;">94.80</td>
<td style="text-align: center;">91.33</td>
<td style="text-align: center;">81.79</td>
<td style="text-align: center;">88.44</td>
<td style="text-align: center;">93.06</td>
<td style="text-align: center;">52.60</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.81</td>
<td style="text-align: center;">87.01</td>
<td style="text-align: center;">65.58</td>
<td style="text-align: center;">80.52</td>
<td style="text-align: center;">90.91</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">93.93</td>
<td style="text-align: center;">91.62</td>
<td style="text-align: center;">87.28</td>
<td style="text-align: center;">77.46</td>
<td style="text-align: center;">84.10</td>
<td style="text-align: center;">88.15</td>
<td style="text-align: center;">54.91</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.07</td>
<td style="text-align: center;">82.96</td>
<td style="text-align: center;">57.78</td>
<td style="text-align: center;">74.81</td>
<td style="text-align: center;">85.19</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">84.68</td>
<td style="text-align: center;">82.37</td>
<td style="text-align: center;">78.61</td>
<td style="text-align: center;">65.03</td>
<td style="text-align: center;">70.52</td>
<td style="text-align: center;">74.28</td>
<td style="text-align: center;">57.23</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">91.58</td>
<td style="text-align: center;">77.89</td>
<td style="text-align: center;">28.42</td>
<td style="text-align: center;">48.42</td>
<td style="text-align: center;">62.11</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b-chat</td>
<td style="text-align: center;">75.43</td>
<td style="text-align: center;">72.54</td>
<td style="text-align: center;">71.39</td>
<td style="text-align: center;">58.09</td>
<td style="text-align: center;">63.87</td>
<td style="text-align: center;">67.34</td>
<td style="text-align: center;">54.62</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">86.11</td>
<td style="text-align: center;">80.56</td>
<td style="text-align: center;">16.67</td>
<td style="text-align: center;">44.44</td>
<td style="text-align: center;">61.11</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b</td>
<td style="text-align: center;">58.96</td>
<td style="text-align: center;">59.25</td>
<td style="text-align: center;">54.62</td>
<td style="text-align: center;">44.51</td>
<td style="text-align: center;">44.51</td>
<td style="text-align: center;">50.29</td>
<td style="text-align: center;">39.60</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">101.49</td>
<td style="text-align: center;">77.61</td>
<td style="text-align: center;">25.37</td>
<td style="text-align: center;">25.37</td>
<td style="text-align: center;">55.22</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b-instruct</td>
<td style="text-align: center;">65.90</td>
<td style="text-align: center;">63.87</td>
<td style="text-align: center;">61.27</td>
<td style="text-align: center;">48.55</td>
<td style="text-align: center;">53.47</td>
<td style="text-align: center;">60.69</td>
<td style="text-align: center;">46.82</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">89.39</td>
<td style="text-align: center;">75.76</td>
<td style="text-align: center;">9.09</td>
<td style="text-align: center;">34.85</td>
<td style="text-align: center;">72.73</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">88.44</td>
<td style="text-align: center;">86.13</td>
<td style="text-align: center;">80.35</td>
<td style="text-align: center;">67.92</td>
<td style="text-align: center;">75.43</td>
<td style="text-align: center;">80.64</td>
<td style="text-align: center;">57.23</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.59</td>
<td style="text-align: center;">74.07</td>
<td style="text-align: center;">34.26</td>
<td style="text-align: center;">58.33</td>
<td style="text-align: center;">75.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b-chat</td>
<td style="text-align: center;">96.24</td>
<td style="text-align: center;">92.49</td>
<td style="text-align: center;">83.82</td>
<td style="text-align: center;">64.74</td>
<td style="text-align: center;">75.43</td>
<td style="text-align: center;">82.66</td>
<td style="text-align: center;">54.91</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.91</td>
<td style="text-align: center;">69.93</td>
<td style="text-align: center;">23.78</td>
<td style="text-align: center;">49.65</td>
<td style="text-align: center;">67.13</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b</td>
<td style="text-align: center;">66.18</td>
<td style="text-align: center;">65.03</td>
<td style="text-align: center;">57.51</td>
<td style="text-align: center;">47.40</td>
<td style="text-align: center;">52.89</td>
<td style="text-align: center;">57.80</td>
<td style="text-align: center;">44.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.59</td>
<td style="text-align: center;">59.46</td>
<td style="text-align: center;">12.16</td>
<td style="text-align: center;">37.84</td>
<td style="text-align: center;">60.81</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b-chat</td>
<td style="text-align: center;">84.68</td>
<td style="text-align: center;">78.90</td>
<td style="text-align: center;">66.18</td>
<td style="text-align: center;">47.98</td>
<td style="text-align: center;">55.20</td>
<td style="text-align: center;">59.83</td>
<td style="text-align: center;">44.51</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">85.61</td>
<td style="text-align: center;">53.96</td>
<td style="text-align: center;">8.63</td>
<td style="text-align: center;">26.62</td>
<td style="text-align: center;">38.13</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b</td>
<td style="text-align: center;">47.40</td>
<td style="text-align: center;">45.09</td>
<td style="text-align: center;">42.77</td>
<td style="text-align: center;">38.73</td>
<td style="text-align: center;">40.75</td>
<td style="text-align: center;">43.64</td>
<td style="text-align: center;">39.31</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">71.43</td>
<td style="text-align: center;">42.86</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">17.86</td>
<td style="text-align: center;">53.57</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b-chat</td>
<td style="text-align: center;">82.08</td>
<td style="text-align: center;">75.14</td>
<td style="text-align: center;">64.16</td>
<td style="text-align: center;">45.09</td>
<td style="text-align: center;">52.31</td>
<td style="text-align: center;">56.94</td>
<td style="text-align: center;">43.93</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">81.82</td>
<td style="text-align: center;">53.03</td>
<td style="text-align: center;">3.03</td>
<td style="text-align: center;">21.97</td>
<td style="text-align: center;">34.09</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b</td>
<td style="text-align: center;">62.72</td>
<td style="text-align: center;">56.36</td>
<td style="text-align: center;">50.87</td>
<td style="text-align: center;">37.86</td>
<td style="text-align: center;">47.69</td>
<td style="text-align: center;">53.47</td>
<td style="text-align: center;">37.28</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">75.00</td>
<td style="text-align: center;">53.41</td>
<td style="text-align: center;">2.27</td>
<td style="text-align: center;">40.91</td>
<td style="text-align: center;">63.64</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b-instruct</td>
<td style="text-align: center;">65.03</td>
<td style="text-align: center;">66.76</td>
<td style="text-align: center;">58.67</td>
<td style="text-align: center;">47.11</td>
<td style="text-align: center;">54.62</td>
<td style="text-align: center;">61.27</td>
<td style="text-align: center;">39.88</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">106.90</td>
<td style="text-align: center;">74.71</td>
<td style="text-align: center;">28.74</td>
<td style="text-align: center;">58.62</td>
<td style="text-align: center;">85.06</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">UL2</td>
<td style="text-align: center;">87.57</td>
<td style="text-align: center;">84.68</td>
<td style="text-align: center;">76.30</td>
<td style="text-align: center;">45.95</td>
<td style="text-align: center;">60.69</td>
<td style="text-align: center;">71.10</td>
<td style="text-align: center;">38.44</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.12</td>
<td style="text-align: center;">77.06</td>
<td style="text-align: center;">15.29</td>
<td style="text-align: center;">45.29</td>
<td style="text-align: center;">66.47</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Flan-UL2</td>
<td style="text-align: center;">98.55</td>
<td style="text-align: center;">95.95</td>
<td style="text-align: center;">89.31</td>
<td style="text-align: center;">49.71</td>
<td style="text-align: center;">65.61</td>
<td style="text-align: center;">76.88</td>
<td style="text-align: center;">46.24</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">95.03</td>
<td style="text-align: center;">82.32</td>
<td style="text-align: center;">6.63</td>
<td style="text-align: center;">37.02</td>
<td style="text-align: center;">58.56</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Flan-T5-xxl</td>
<td style="text-align: center;">97.40</td>
<td style="text-align: center;">96.24</td>
<td style="text-align: center;">87.86</td>
<td style="text-align: center;">49.42</td>
<td style="text-align: center;">66.47</td>
<td style="text-align: center;">82.66</td>
<td style="text-align: center;">40.75</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.96</td>
<td style="text-align: center;">83.16</td>
<td style="text-align: center;">15.31</td>
<td style="text-align: center;">45.41</td>
<td style="text-align: center;">73.98</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">ByT5-xxl</td>
<td style="text-align: center;">73.12</td>
<td style="text-align: center;">57.23</td>
<td style="text-align: center;">46.24</td>
<td style="text-align: center;">26.30</td>
<td style="text-align: center;">35.84</td>
<td style="text-align: center;">41.91</td>
<td style="text-align: center;">25.14</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">66.87</td>
<td style="text-align: center;">43.98</td>
<td style="text-align: center;">2.41</td>
<td style="text-align: center;">22.29</td>
<td style="text-align: center;">34.94</td>
<td style="text-align: center;">0.0</td>
</tr>
</tbody>
</table>
<p>Table 5: The experimental results on zero-shot ScrQA using RealtimeQA dataset (upper: Acc; lower: RPG).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Ori</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
<th style="text-align: center;">Sub</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">96.68</td>
<td style="text-align: center;">96.29</td>
<td style="text-align: center;">94.43</td>
<td style="text-align: center;">87.40</td>
<td style="text-align: center;">93.65</td>
<td style="text-align: center;">96.39</td>
<td style="text-align: center;">46.48</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.22</td>
<td style="text-align: center;">95.53</td>
<td style="text-align: center;">81.52</td>
<td style="text-align: center;">93.97</td>
<td style="text-align: center;">99.42</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">92.48</td>
<td style="text-align: center;">87.30</td>
<td style="text-align: center;">77.83</td>
<td style="text-align: center;">45.61</td>
<td style="text-align: center;">71.78</td>
<td style="text-align: center;">83.89</td>
<td style="text-align: center;">26.07</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.21</td>
<td style="text-align: center;">77.94</td>
<td style="text-align: center;">29.41</td>
<td style="text-align: center;">68.82</td>
<td style="text-align: center;">87.06</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">92.29</td>
<td style="text-align: center;">89.45</td>
<td style="text-align: center;">80.27</td>
<td style="text-align: center;">52.44</td>
<td style="text-align: center;">76.66</td>
<td style="text-align: center;">87.50</td>
<td style="text-align: center;">43.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.15</td>
<td style="text-align: center;">75.20</td>
<td style="text-align: center;">17.74</td>
<td style="text-align: center;">67.74</td>
<td style="text-align: center;">90.12</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">93.65</td>
<td style="text-align: center;">89.65</td>
<td style="text-align: center;">82.23</td>
<td style="text-align: center;">55.37</td>
<td style="text-align: center;">75.39</td>
<td style="text-align: center;">84.47</td>
<td style="text-align: center;">51.17</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.57</td>
<td style="text-align: center;">73.10</td>
<td style="text-align: center;">9.89</td>
<td style="text-align: center;">57.01</td>
<td style="text-align: center;">78.39</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b-chat</td>
<td style="text-align: center;">92.68</td>
<td style="text-align: center;">89.16</td>
<td style="text-align: center;">78.32</td>
<td style="text-align: center;">49.90</td>
<td style="text-align: center;">70.51</td>
<td style="text-align: center;">80.76</td>
<td style="text-align: center;">45.31</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.58</td>
<td style="text-align: center;">69.69</td>
<td style="text-align: center;">9.69</td>
<td style="text-align: center;">53.20</td>
<td style="text-align: center;">74.85</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b</td>
<td style="text-align: center;">70.12</td>
<td style="text-align: center;">65.04</td>
<td style="text-align: center;">56.45</td>
<td style="text-align: center;">44.34</td>
<td style="text-align: center;">50.78</td>
<td style="text-align: center;">58.30</td>
<td style="text-align: center;">43.26</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">81.09</td>
<td style="text-align: center;">49.09</td>
<td style="text-align: center;">4.00</td>
<td style="text-align: center;">28.00</td>
<td style="text-align: center;">56.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-40b-instruct</td>
<td style="text-align: center;">75.20</td>
<td style="text-align: center;">67.48</td>
<td style="text-align: center;">58.59</td>
<td style="text-align: center;">43.65</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">60.06</td>
<td style="text-align: center;">42.87</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">76.13</td>
<td style="text-align: center;">48.64</td>
<td style="text-align: center;">2.42</td>
<td style="text-align: center;">22.05</td>
<td style="text-align: center;">53.17</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">93.26</td>
<td style="text-align: center;">89.75</td>
<td style="text-align: center;">80.96</td>
<td style="text-align: center;">54.30</td>
<td style="text-align: center;">73.34</td>
<td style="text-align: center;">84.38</td>
<td style="text-align: center;">47.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.26</td>
<td style="text-align: center;">72.90</td>
<td style="text-align: center;">14.19</td>
<td style="text-align: center;">56.13</td>
<td style="text-align: center;">80.43</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b-chat</td>
<td style="text-align: center;">91.11</td>
<td style="text-align: center;">85.74</td>
<td style="text-align: center;">75.10</td>
<td style="text-align: center;">48.24</td>
<td style="text-align: center;">59.67</td>
<td style="text-align: center;">74.02</td>
<td style="text-align: center;">45.12</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">88.32</td>
<td style="text-align: center;">65.18</td>
<td style="text-align: center;">6.79</td>
<td style="text-align: center;">31.63</td>
<td style="text-align: center;">62.85</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b</td>
<td style="text-align: center;">69.53</td>
<td style="text-align: center;">63.87</td>
<td style="text-align: center;">53.32</td>
<td style="text-align: center;">38.67</td>
<td style="text-align: center;">44.63</td>
<td style="text-align: center;">52.25</td>
<td style="text-align: center;">37.21</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">82.48</td>
<td style="text-align: center;">49.85</td>
<td style="text-align: center;">4.53</td>
<td style="text-align: center;">22.96</td>
<td style="text-align: center;">46.53</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-13b-chat</td>
<td style="text-align: center;">78.61</td>
<td style="text-align: center;">71.78</td>
<td style="text-align: center;">59.77</td>
<td style="text-align: center;">41.80</td>
<td style="text-align: center;">48.44</td>
<td style="text-align: center;">57.42</td>
<td style="text-align: center;">40.92</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">81.87</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">2.33</td>
<td style="text-align: center;">19.95</td>
<td style="text-align: center;">43.78</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b</td>
<td style="text-align: center;">60.55</td>
<td style="text-align: center;">55.08</td>
<td style="text-align: center;">47.46</td>
<td style="text-align: center;">37.60</td>
<td style="text-align: center;">43.07</td>
<td style="text-align: center;">46.39</td>
<td style="text-align: center;">37.30</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">76.47</td>
<td style="text-align: center;">43.70</td>
<td style="text-align: center;">1.26</td>
<td style="text-align: center;">24.79</td>
<td style="text-align: center;">39.08</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-7b-chat</td>
<td style="text-align: center;">73.63</td>
<td style="text-align: center;">64.45</td>
<td style="text-align: center;">56.25</td>
<td style="text-align: center;">40.04</td>
<td style="text-align: center;">45.41</td>
<td style="text-align: center;">53.81</td>
<td style="text-align: center;">39.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">72.83</td>
<td style="text-align: center;">48.55</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">16.47</td>
<td style="text-align: center;">41.33</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b</td>
<td style="text-align: center;">74.02</td>
<td style="text-align: center;">69.24</td>
<td style="text-align: center;">59.47</td>
<td style="text-align: center;">47.17</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">57.71</td>
<td style="text-align: center;">43.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">84.35</td>
<td style="text-align: center;">52.40</td>
<td style="text-align: center;">12.14</td>
<td style="text-align: center;">21.41</td>
<td style="text-align: center;">46.65</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">MPT-30b-instruct</td>
<td style="text-align: center;">83.50</td>
<td style="text-align: center;">75.68</td>
<td style="text-align: center;">65.43</td>
<td style="text-align: center;">44.82</td>
<td style="text-align: center;">54.30</td>
<td style="text-align: center;">60.64</td>
<td style="text-align: center;">41.41</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">81.44</td>
<td style="text-align: center;">57.08</td>
<td style="text-align: center;">8.12</td>
<td style="text-align: center;">30.63</td>
<td style="text-align: center;">45.71</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">UL2</td>
<td style="text-align: center;">43.36</td>
<td style="text-align: center;">39.36</td>
<td style="text-align: center;">29.88</td>
<td style="text-align: center;">14.55</td>
<td style="text-align: center;">17.38</td>
<td style="text-align: center;">25.20</td>
<td style="text-align: center;">12.79</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">86.90</td>
<td style="text-align: center;">55.91</td>
<td style="text-align: center;">5.75</td>
<td style="text-align: center;">15.02</td>
<td style="text-align: center;">40.58</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Flan-UL2</td>
<td style="text-align: center;">94.24</td>
<td style="text-align: center;">91.21</td>
<td style="text-align: center;">80.96</td>
<td style="text-align: center;">49.80</td>
<td style="text-align: center;">62.99</td>
<td style="text-align: center;">75.39</td>
<td style="text-align: center;">48.14</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">93.43</td>
<td style="text-align: center;">71.19</td>
<td style="text-align: center;">3.60</td>
<td style="text-align: center;">32.20</td>
<td style="text-align: center;">59.11</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Flan-T5-xxl</td>
<td style="text-align: center;">95.02</td>
<td style="text-align: center;">92.87</td>
<td style="text-align: center;">84.67</td>
<td style="text-align: center;">51.17</td>
<td style="text-align: center;">67.09</td>
<td style="text-align: center;">81.54</td>
<td style="text-align: center;">51.07</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">95.11</td>
<td style="text-align: center;">76.44</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">36.44</td>
<td style="text-align: center;">69.33</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">ByT5-xxl</td>
<td style="text-align: center;">43.16</td>
<td style="text-align: center;">40.23</td>
<td style="text-align: center;">36.23</td>
<td style="text-align: center;">31.93</td>
<td style="text-align: center;">33.50</td>
<td style="text-align: center;">36.62</td>
<td style="text-align: center;">31.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">74.14</td>
<td style="text-align: center;">38.79</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">14.66</td>
<td style="text-align: center;">42.24</td>
<td style="text-align: center;">0.0</td>
</tr>
</tbody>
</table>
<p>Table 6: The experimental results on zero-shot ScrQA using DREAM dataset (upper: Acc; lower: RPG).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Ori</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
<th style="text-align: center;">Sub</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">96.68</td>
<td style="text-align: center;">96.29</td>
<td style="text-align: center;">94.43</td>
<td style="text-align: center;">87.40</td>
<td style="text-align: center;">93.65</td>
<td style="text-align: center;">96.39</td>
<td style="text-align: center;">46.48</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">76.09</td>
<td style="text-align: center;">78.26</td>
<td style="text-align: center;">67.39</td>
<td style="text-align: center;">45.65</td>
<td style="text-align: center;">58.70</td>
<td style="text-align: center;">71.74</td>
<td style="text-align: center;">32.61</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">94.69</td>
<td style="text-align: center;">94.41</td>
<td style="text-align: center;">93.02</td>
<td style="text-align: center;">82.40</td>
<td style="text-align: center;">91.90</td>
<td style="text-align: center;">94.41</td>
<td style="text-align: center;">42.46</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">95.97</td>
<td style="text-align: center;">95.84</td>
<td style="text-align: center;">93.42</td>
<td style="text-align: center;">85.77</td>
<td style="text-align: center;">92.62</td>
<td style="text-align: center;">95.97</td>
<td style="text-align: center;">47.65</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">99.07</td>
<td style="text-align: center;">97.22</td>
<td style="text-align: center;">98.15</td>
<td style="text-align: center;">92.59</td>
<td style="text-align: center;">97.22</td>
<td style="text-align: center;">99.07</td>
<td style="text-align: center;">47.22</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">98.47</td>
<td style="text-align: center;">97.71</td>
<td style="text-align: center;">96.18</td>
<td style="text-align: center;">90.08</td>
<td style="text-align: center;">95.42</td>
<td style="text-align: center;">96.95</td>
<td style="text-align: center;">36.64</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">92.48</td>
<td style="text-align: center;">87.30</td>
<td style="text-align: center;">77.83</td>
<td style="text-align: center;">45.61</td>
<td style="text-align: center;">71.78</td>
<td style="text-align: center;">83.89</td>
<td style="text-align: center;">26.07</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">60.87</td>
<td style="text-align: center;">60.87</td>
<td style="text-align: center;">52.17</td>
<td style="text-align: center;">21.74</td>
<td style="text-align: center;">41.30</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">15.22</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">89.11</td>
<td style="text-align: center;">84.36</td>
<td style="text-align: center;">76.54</td>
<td style="text-align: center;">39.39</td>
<td style="text-align: center;">63.69</td>
<td style="text-align: center;">79.61</td>
<td style="text-align: center;">25.42</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">91.01</td>
<td style="text-align: center;">85.64</td>
<td style="text-align: center;">76.11</td>
<td style="text-align: center;">44.83</td>
<td style="text-align: center;">71.28</td>
<td style="text-align: center;">82.95</td>
<td style="text-align: center;">25.10</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">99.07</td>
<td style="text-align: center;">91.67</td>
<td style="text-align: center;">81.48</td>
<td style="text-align: center;">56.48</td>
<td style="text-align: center;">78.70</td>
<td style="text-align: center;">89.81</td>
<td style="text-align: center;">30.56</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">95.42</td>
<td style="text-align: center;">93.13</td>
<td style="text-align: center;">82.44</td>
<td style="text-align: center;">41.22</td>
<td style="text-align: center;">70.99</td>
<td style="text-align: center;">83.97</td>
<td style="text-align: center;">24.43</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">92.29</td>
<td style="text-align: center;">89.45</td>
<td style="text-align: center;">80.27</td>
<td style="text-align: center;">52.44</td>
<td style="text-align: center;">76.66</td>
<td style="text-align: center;">87.50</td>
<td style="text-align: center;">43.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">47.83</td>
<td style="text-align: center;">45.65</td>
<td style="text-align: center;">41.30</td>
<td style="text-align: center;">21.74</td>
<td style="text-align: center;">41.30</td>
<td style="text-align: center;">45.65</td>
<td style="text-align: center;">17.39</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">90.78</td>
<td style="text-align: center;">87.99</td>
<td style="text-align: center;">77.37</td>
<td style="text-align: center;">46.37</td>
<td style="text-align: center;">71.79</td>
<td style="text-align: center;">84.92</td>
<td style="text-align: center;">45.25</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">91.01</td>
<td style="text-align: center;">87.92</td>
<td style="text-align: center;">78.39</td>
<td style="text-align: center;">52.89</td>
<td style="text-align: center;">75.03</td>
<td style="text-align: center;">86.71</td>
<td style="text-align: center;">41.34</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">99.07</td>
<td style="text-align: center;">94.44</td>
<td style="text-align: center;">86.11</td>
<td style="text-align: center;">57.41</td>
<td style="text-align: center;">87.96</td>
<td style="text-align: center;">93.52</td>
<td style="text-align: center;">48.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">94.66</td>
<td style="text-align: center;">94.66</td>
<td style="text-align: center;">86.26</td>
<td style="text-align: center;">48.09</td>
<td style="text-align: center;">77.86</td>
<td style="text-align: center;">87.79</td>
<td style="text-align: center;">49.62</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">93.65</td>
<td style="text-align: center;">89.65</td>
<td style="text-align: center;">82.23</td>
<td style="text-align: center;">55.37</td>
<td style="text-align: center;">75.39</td>
<td style="text-align: center;">84.47</td>
<td style="text-align: center;">51.17</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">52.17</td>
<td style="text-align: center;">47.83</td>
<td style="text-align: center;">45.65</td>
<td style="text-align: center;">34.78</td>
<td style="text-align: center;">43.48</td>
<td style="text-align: center;">47.83</td>
<td style="text-align: center;">34.78</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">91.34</td>
<td style="text-align: center;">88.55</td>
<td style="text-align: center;">79.33</td>
<td style="text-align: center;">56.15</td>
<td style="text-align: center;">74.58</td>
<td style="text-align: center;">83.24</td>
<td style="text-align: center;">52.23</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">92.62</td>
<td style="text-align: center;">88.59</td>
<td style="text-align: center;">79.87</td>
<td style="text-align: center;">52.35</td>
<td style="text-align: center;">73.02</td>
<td style="text-align: center;">82.55</td>
<td style="text-align: center;">50.47</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">98.15</td>
<td style="text-align: center;">90.74</td>
<td style="text-align: center;">87.04</td>
<td style="text-align: center;">62.96</td>
<td style="text-align: center;">78.70</td>
<td style="text-align: center;">89.81</td>
<td style="text-align: center;">51.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">96.18</td>
<td style="text-align: center;">93.89</td>
<td style="text-align: center;">89.31</td>
<td style="text-align: center;">67.18</td>
<td style="text-align: center;">87.02</td>
<td style="text-align: center;">91.60</td>
<td style="text-align: center;">56.49</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">93.26</td>
<td style="text-align: center;">89.75</td>
<td style="text-align: center;">80.96</td>
<td style="text-align: center;">54.30</td>
<td style="text-align: center;">73.34</td>
<td style="text-align: center;">84.38</td>
<td style="text-align: center;">47.85</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">58.70</td>
<td style="text-align: center;">47.83</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">36.96</td>
<td style="text-align: center;">47.83</td>
<td style="text-align: center;">43.48</td>
<td style="text-align: center;">36.96</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">91.34</td>
<td style="text-align: center;">89.39</td>
<td style="text-align: center;">80.73</td>
<td style="text-align: center;">53.63</td>
<td style="text-align: center;">73.18</td>
<td style="text-align: center;">84.36</td>
<td style="text-align: center;">44.97</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">92.62</td>
<td style="text-align: center;">88.99</td>
<td style="text-align: center;">79.73</td>
<td style="text-align: center;">54.50</td>
<td style="text-align: center;">73.02</td>
<td style="text-align: center;">84.16</td>
<td style="text-align: center;">48.05</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">94.44</td>
<td style="text-align: center;">89.81</td>
<td style="text-align: center;">79.63</td>
<td style="text-align: center;">50.93</td>
<td style="text-align: center;">73.15</td>
<td style="text-align: center;">79.63</td>
<td style="text-align: center;">50.93</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">96.18</td>
<td style="text-align: center;">94.66</td>
<td style="text-align: center;">86.26</td>
<td style="text-align: center;">58.02</td>
<td style="text-align: center;">79.39</td>
<td style="text-align: center;">90.84</td>
<td style="text-align: center;">50.38</td>
</tr>
</tbody>
</table>
<p>Table 7: The experimental results of different categories on zero-shot ScrQA using DREAM dataset (Acc).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Ori</th>
<th style="text-align: center;">20\%</th>
<th style="text-align: center;">50\%</th>
<th style="text-align: center;">100\%</th>
<th style="text-align: center;">KF</th>
<th style="text-align: center;">KFL</th>
<th style="text-align: center;">Sub</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">GPT-4</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.22</td>
<td style="text-align: center;">95.53</td>
<td style="text-align: center;">81.52</td>
<td style="text-align: center;">93.97</td>
<td style="text-align: center;">99.42</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">105.00</td>
<td style="text-align: center;">80.00</td>
<td style="text-align: center;">30.00</td>
<td style="text-align: center;">60.00</td>
<td style="text-align: center;">90.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.47</td>
<td style="text-align: center;">96.79</td>
<td style="text-align: center;">76.47</td>
<td style="text-align: center;">94.65</td>
<td style="text-align: center;">99.47</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.72</td>
<td style="text-align: center;">94.72</td>
<td style="text-align: center;">78.89</td>
<td style="text-align: center;">93.06</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.43</td>
<td style="text-align: center;">98.21</td>
<td style="text-align: center;">87.50</td>
<td style="text-align: center;">96.43</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.77</td>
<td style="text-align: center;">96.30</td>
<td style="text-align: center;">86.42</td>
<td style="text-align: center;">95.06</td>
<td style="text-align: center;">97.53</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.21</td>
<td style="text-align: center;">77.94</td>
<td style="text-align: center;">29.41</td>
<td style="text-align: center;">68.82</td>
<td style="text-align: center;">87.06</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">80.95</td>
<td style="text-align: center;">14.29</td>
<td style="text-align: center;">57.14</td>
<td style="text-align: center;">76.19</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.54</td>
<td style="text-align: center;">80.26</td>
<td style="text-align: center;">21.93</td>
<td style="text-align: center;">60.09</td>
<td style="text-align: center;">85.09</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">91.85</td>
<td style="text-align: center;">77.39</td>
<td style="text-align: center;">29.94</td>
<td style="text-align: center;">70.06</td>
<td style="text-align: center;">87.78</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">89.19</td>
<td style="text-align: center;">74.32</td>
<td style="text-align: center;">37.84</td>
<td style="text-align: center;">70.27</td>
<td style="text-align: center;">86.49</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.77</td>
<td style="text-align: center;">81.72</td>
<td style="text-align: center;">23.66</td>
<td style="text-align: center;">65.59</td>
<td style="text-align: center;">83.87</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.15</td>
<td style="text-align: center;">75.20</td>
<td style="text-align: center;">17.74</td>
<td style="text-align: center;">67.74</td>
<td style="text-align: center;">90.12</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.86</td>
<td style="text-align: center;">78.57</td>
<td style="text-align: center;">14.29</td>
<td style="text-align: center;">78.57</td>
<td style="text-align: center;">92.86</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">93.87</td>
<td style="text-align: center;">70.55</td>
<td style="text-align: center;">2.45</td>
<td style="text-align: center;">58.28</td>
<td style="text-align: center;">87.12</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">93.78</td>
<td style="text-align: center;">74.59</td>
<td style="text-align: center;">23.24</td>
<td style="text-align: center;">67.84</td>
<td style="text-align: center;">91.35</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.91</td>
<td style="text-align: center;">74.55</td>
<td style="text-align: center;">18.18</td>
<td style="text-align: center;">78.18</td>
<td style="text-align: center;">89.09</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">81.36</td>
<td style="text-align: center;">$&lt;0$</td>
<td style="text-align: center;">62.71</td>
<td style="text-align: center;">84.75</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Falcon-180b</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.57</td>
<td style="text-align: center;">73.10</td>
<td style="text-align: center;">9.89</td>
<td style="text-align: center;">57.01</td>
<td style="text-align: center;">78.39</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">75.00</td>
<td style="text-align: center;">62.50</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">75.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.86</td>
<td style="text-align: center;">69.29</td>
<td style="text-align: center;">10.00</td>
<td style="text-align: center;">57.14</td>
<td style="text-align: center;">79.29</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.45</td>
<td style="text-align: center;">69.75</td>
<td style="text-align: center;">4.46</td>
<td style="text-align: center;">53.50</td>
<td style="text-align: center;">76.11</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">84.00</td>
<td style="text-align: center;">76.00</td>
<td style="text-align: center;">24.00</td>
<td style="text-align: center;">58.00</td>
<td style="text-align: center;">82.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.23</td>
<td style="text-align: center;">82.69</td>
<td style="text-align: center;">26.92</td>
<td style="text-align: center;">76.92</td>
<td style="text-align: center;">88.46</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama-2-70b</td>
<td style="text-align: center;">all</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.26</td>
<td style="text-align: center;">72.90</td>
<td style="text-align: center;">14.19</td>
<td style="text-align: center;">56.13</td>
<td style="text-align: center;">80.43</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">arithmetic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">60.00</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">50.00</td>
<td style="text-align: center;">30.00</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">commonsense</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">95.78</td>
<td style="text-align: center;">77.11</td>
<td style="text-align: center;">18.67</td>
<td style="text-align: center;">60.84</td>
<td style="text-align: center;">84.94</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">logic</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">91.87</td>
<td style="text-align: center;">71.08</td>
<td style="text-align: center;">14.46</td>
<td style="text-align: center;">56.02</td>
<td style="text-align: center;">81.02</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">matching</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">89.36</td>
<td style="text-align: center;">65.96</td>
<td style="text-align: center;">0.00</td>
<td style="text-align: center;">51.06</td>
<td style="text-align: center;">65.96</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">summary</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.67</td>
<td style="text-align: center;">78.33</td>
<td style="text-align: center;">16.67</td>
<td style="text-align: center;">63.33</td>
<td style="text-align: center;">88.33</td>
<td style="text-align: center;">0.0</td>
</tr>
</tbody>
</table>
<p>Table 8: The experimental results of different categories on zero-shot ScrQA using DREAM dataset (RPG).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ Typoglycemia is an internet meme without specific scientific backing. Nonetheless, people do exhibit the ability to recognize scrambled common words to some extent. Our focus is not on examining this ability of humans, we use the concept for illustrative purposes.
${ }^{2}$ Code will be available at https://github.com/ ccqq77/unnatural-error-correction.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>