<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7081 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7081</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7081</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-263829977</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.04560v1.pdf" target="_blank">Talk like a Graph: Encoding Graphs for Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Graphs are a powerful tool for representing and analyzing complex relationships in real-world applications such as social networks, recommender systems, and computational finance. Reasoning on graphs is essential for drawing inferences about the relationships between entities in a complex system, and to identify hidden patterns and trends. Despite the remarkable progress in automated reasoning with natural text, reasoning on graphs with large language models (LLMs) remains an understudied problem. In this work, we perform the first comprehensive study of encoding graph-structured data as text for consumption by LLMs. We show that LLM performance on graph reasoning tasks varies on three fundamental levels: (1) the graph encoding method, (2) the nature of the graph task itself, and (3) interestingly, the very structure of the graph considered. These novel results provide valuable insight on strategies for encoding graphs as text. Using these insights we illustrate how the correct choice of encoders can boost performance on graph reasoning tasks inside LLMs by 4.8% to 61.8%, depending on the task.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7081",
    "paper_id": "paper-263829977",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0048225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>TALK LIKE A GRAPH: ENCODING GRAPHS FOR LARGE LANGUAGE MODELS
6 Oct 2023</p>
<p>Bahare Fatemi baharef@google.com 
Jonathan Halcrow halcrow@google.com 
Bryan Perozzi bperozzi@google.com 
Robert James 
TALK LIKE A GRAPH: ENCODING GRAPHS FOR LARGE LANGUAGE MODELS
6 Oct 20239DA2190CF742580E4076C571998FDC8AarXiv:2310.04560v1[cs.LG]James and Robert wrote a paper together. … Jennifer and Linda wrote a paper together..
Graphs are a powerful tool for representing and analyzing complex relationships in real-world applications such as social networks, recommender systems, and computational finance.Reasoning on graphs is essential for drawing inferences about the relationships between entities in a complex system, and to identify hidden patterns and trends.Despite the remarkable progress in automated reasoning with natural text, reasoning on graphs with large language models (LLMs) remains an understudied problem.In this work, we perform the first comprehensive study of encoding graph-structured data as text for consumption by LLMs.We show that LLM performance on graph reasoning tasks varies on three fundamental levels:(1) the graph encoding method, (2) the nature of the graph task itself, and (3) interestingly, the very structure of the graph considered.These novel results provide valuable insight on strategies for encoding graphs as text.Using these insights we illustrate how the correct choice of encoders can boost performance on graph reasoning tasks inside LLMs by 4.8% to 61.8%, depending on the task.</p>
<p>INTRODUCTION</p>
<p>There has been remarkable recent progress in the research and applications of large language models (LLMs) (Vaswani et al., 2017;Devlin et al., 2018;Brown et al., 2020a;Ouyang et al., 2022).These generative models have captivated the artificial intelligence community and a plethora of models trained on a variety of tasks and modalities have recently been released (Zhao et al., 2023).All of these advancements have led to a growing consensus that LLMs are a pivotal advancement on the path to artificial general intelligence (AGI) (Bubeck et al., 2023).</p>
<p>However, despite all their successes, there are a number of limitations with the current methodology of design and implementation of LLMs.One of the most obvious limitations is their reliance on unstructured text, causing the models to sometimes miss obvious logical entailments or hallucinate incorrect conclusions (Zhang et al., 2023b).Another is that LLMs are fundamentally limited by when they were trained, and it can be difficult to incorporate 'fresh' information about the state of the world which has changed (Lewis et al., 2020).Graph-structured data is one of the most flexible ways to represent information and could be a promising solution to both challenges (Schneider et al., 2022;Pan et al., 2023).</p>
<p>Interestingly, despite this promise, the intersection of graphs and LLMs has been relatively understudied.For example, while much work has focused on LLMs and graph databases (or knowledge graphs (Guu et al., 2020;Lewis et al., 2020)) there has not been much study about general purpose use of graph-structured data.More recently, Wang et al. (2023) have sought to address this by designing a graph benchmarking task for language models.While their task represents an exciting initial foray into measuring LLMs graph reasoning capabilities, there are still many open questions due to the omission of several natural graph tasks and a lack of variety in the type of graph structure considered.Other recent work seeks to replace graph-structured data with LLMs (Ye et al., 2023), but this does not address fundamental challenges with LLMs.</p>
<p>In this work, we perform the first comprehensive study about reasoning over graph-structured data as text for consumption by LLMs.To analyze graph reasoning more closely, we decompose the problem into graph encoding and graph prompt engineering.Varying graph encoding methods allows us to understand how LLM's learned representations are leveraged in graph tasks.While  , 2, 3, 4, 5, 6, 7, and 8.In this graph: Node 0 is connected to nodes 2 and 3. Node 1 is connected to nodes 2 and 8. … Question: What is the degree of node 4? Answer: A Figure 1: Overview of our framework for reasoning with graphs using LLMs.</p>
<p>studying prompt engineering techniques finds the most suitable way to get a desired solution to a question from an LLM.Our experimental results seek to uncover the situations where different prompt heuristics work well.To that end, we propose a new set of benchmarks GraphQA for measuring LLM performance reasoning over graph data.GraphQA is distinguished by using graphs with much more varied and realistic graph structure than has previously been studied with LLMs.</p>
<p>Our Contributions: Specifically, the contributions of our work are the following:</p>
<p>1.An extensive study of graph-structure prompting techniques for use in LLMs. 2. Insights and best practices for encoding graphs as text for use in LLMs.3. A new graph benchmark (GraphQA) to aid the community in studying the effects of graph structure on LLM prompting further.</p>
<p>PROMPTING LLMS FOR GRAPH REASONING</p>
<p>Notation.Let f be the interface function to a generative AI model, which takes high-dimensional discrete input tokens W and produces output in the same token space (f : W → W ). Without loss of generality, we will colloquially refer to f as a pre-trained Large Language Model (LLM) throughout this work, but note that our discussion here applies to any generative AI model with such a discrete interface.In this work, we consider encoding graphs G = (V, E), where V is the set of vertices (or nodes) and E ∈ (V × V ) is the set of edges connecting them.</p>
<p>PROMPT ENGINEERING</p>
<p>The goal in prompt engineering is to find the correct way to phrase a question Q such that an LLM f (or other generative model) will return the corresponding answer A, (Q ∈ W, A ∈ W ). In other words: A = f (Q) In this work, our goal is to provide the LLM f with graph information, so that it can better reason about question/answer pairs that require access to arbitrarily structured relational information.
A = f (G, Q)
A variety of approaches exist for modifying the LLM f (.) so that it could better perform on tasks with graph data such as fine-tuning (Clark et al., 2020), soft prompting (Lester et al., 2021), andLoRA (Hu et al., 2021).In addition, many approaches modify the model to include graph information (Müller et al., 2023;Zhang et al., 2020;Dwivedi &amp; Bresson, 2020).However, these methods all require access to the internals of the model (either its weights or gradients), which can limit their applicability in many real-world settings.In this work, we are instead interested in the case where f (.) and its parameters are fixed, and the system is available only for use in a black box setup where the LLM only consumes and produces text (i.e., the LLM f : W → W ). We believe this setting to be particularly valuable as the number of proprietary models available and their hardware demands increase.</p>
<p>To this end, we introduce the graph encoding function g(G) and question rephrasing function q(Q), where g : G → W and q : W → W (where W is the large discrete domain of tokens used to train the LLM).</p>
<p>A = f (g(G), q(Q))</p>
<p>(1) Our training input D to the graph-based prompt system is a set of G, Q, S triples, where G is a graph, Q is a question, and S, S ∈ W , is a solution to Q.We seek to find a g(.) and q(.) that maximize the expected score from the model (score f ) of the answers over the training dataset D.
max g,q E G,Q,S∈D score f (g(G), q(Q), S)(2)
As W is a very large discrete space, many current approaches use heuristics for this optimization (by changing the prompt Q).The novel contribution of this work is to consider the role of the graph encoding function g(.), q(.) question rephrasing function, and the graph structure G in the optimization of Equation (2).</p>
<p>PROMPTING HEURISTICS</p>
<p>The vast majority of prompting heuristics operate by optimizing the prompt text Q used to query the model.We briefly introduce the methods we examine further in the paper here: Zero-shot prompting (ZERO-SHOT): This approach simply provides the model with a task description and asks it to generate the desired output, without any prior training on the task.Few-shot in-context learning (FEW-SHOT) (Brown et al., 2020b): This approach provides the model with a small number of examples of the task, along with the desired outputs.The model then learns from these examples to perform the task on new inputs.Chain-of-thought (CoT) prompting (COT) (Wei et al., 2022): This approach provides the model with a sequence of examples, each of which shows how to solve the task step-by-step.The model then learns to generate its CoTs to solve new problems.Zero-shot CoT prompting (ZERO-COT) (Kojima et al., 2022): This approach is similar to CoT prompting, but it does not require any prior training examples.Instead, the model uses a simple prompt to generate its own CoTs.As suggested by the original paper, we used "Let's think step by step".Bag prompting (COT-BAG) (Wang et al., 2023): This technique is proposed to improve the performance of LLMs on graph-related tasks.It works by appending "Let's construct a graph with the nodes and edges first" to the graph description.</p>
<p>We note that there is also a popular recent extension of this family of methods, based on iterative prompting.These methods use a series of iterative LLM queries to optimize the prompt question (e.g., (Zhou et al., 2022b;Pryzant et al., 2023;Yang et al., 2023)).However, our initial experiments showed that iterative prompting methods performed much worse for our tasks, due to cascading errors.Consequently, we chose to concentrate our efforts on the methods outlined above.</p>
<p>In this study, the goal is to optimize the graph encoding function on basic graph tasks.Such basic tasks are essential intermediate steps for more complex reasoning tasks on graphs.We conduct extensive experiments on graph encoding function, question, and graph generator functions, providing a study of graph encoding methods for black-box LLM usage.</p>
<p>TALK LIKE A GRAPH: ENCODING GRAPHS VIA TEXT</p>
<p>Graph encoding is a necessary step for turning graph-structured information into a sequence for consumption by language models.In this section, we will study the details of a graph encoding function g(.) which maps graph data into tokens for consumption by an LLM.Our experimental results in this section seek to understand the best form of graph encoding and prompt engineering to maximize the performance on graph reasoning tasks.</p>
<p>We begin by highlighting some of the most exciting results from our analysis here:</p>
<p>• R1: LLMs perform poorly on basic graph tasks ( §3.1).</p>
<p>• R2: The graph encoding function has a significant impact on LLM graph reasoning ( §3.1).</p>
<p>• R3: Model capacity has a significant effect on graph reasoning capabilities of LLMs ( §3.4).</p>
<p>Graph encoding function.This section is an investigation into various methodologies for representing graphs as text.This process of encoding graphs as text can be separated into two key inquiries: First, the encoding of nodes in the graph, and second the encoding of edges between the nodes.Regarding the encoding of nodes and edges, we examine several techniques.Figure 2 shows an overview of the graph encoding functions used.For brevity's sake, a full description and examples of the graph encoding functions considered are explained in Appendix A.1.</p>
<p>Graph structure.We briefly note that the design of this experiment follows that of Wang et al. (2023), who use Erdős-Rényi (ER) graphs (Erdős &amp; Rényi, 1959).One contribution of our work is to consider the effect of more complex graph structures on reasoning in LLMs (covered in Section 4).</p>
<p>Figure 2: Overview of our framework for encoding graphs via text.</p>
<p>EXPERIMENT 1: VARYING GRAPH ENCODING FUNCTIONS</p>
<p>In this experiment, we measure the performance of pre-trained LLMs on graph tasks: edge existence, node degree, node count, edge count, connected nodes, and cycle check.We describe these tasks and our graph benchmark that contains them (GraphQA) in detail in Appendix A.2.</p>
<p>RESULTS</p>
<p>Table 1 shows the results of this experiment varying graph encoding and prompting techniques.These results show several interesting conclusions, which we briefly summarize here:</p>
<p>LLMs perform poorly on basic graph tasks.Let's start by examining the overall results.LLMs performed poorly on almost all the basic graph tasks we experimented with.This is especially interesting for the edge existence and cycle check tasks, where there is not an edge 53.96% of the time for the edge existence task and there is a cycle 81.96% of the time for the cycle check task.Therefore.LLMs perform worse than the majority baseline.Note that we experimented with ER graphs in this experiment, and it is very likely for an ER graph to have a cycle.</p>
<p>Simple prompts are best for simple tasks.We see that ZERO-COT prompting has worse model performance than ZERO-SHOT prompting on basic graph tasks.This is likely because ZERO-SHOT prompting is sufficient for these tasks, which do not require multi-hop reasoning.ZERO-COT prompting can be effective for tasks that require multi-hop reasoning, such as arithmetic problems, but it is not necessary for most basic graph tasks, which only require the LLM to have an understanding of the graph structure (nodes, edges, paths, etc.) and the graph task.However for more complex tasks, adding few-shot examples and CoT prompting generally improved the performance of the model.This is mainly because few-shot examples provide the LLM with a better understanding of the task it is solving.CoT prompting can also improve performance by helping the LLM to find out how to get to the answer to the problem.</p>
<p>graph encoding functions have significant impact on LLM reasoning.As the results indicate, the choice of the graph encoding function has a significant impact on the performance of LLMs on graph-related tasks.This is because different encoder functions capture different aspects of the graph structure.For instance, for finding connected nodes to a node in a graph, adjacency achieves 19.8% accuracy and incident achieves 53.8% accuracy.For both node degree and connected nodes, incident encoding outperforms the rest of the encoder functions.This is likely because the incident encoder encodes the graph structure in a way that makes the relevant information more accessible, i.e., in close proximity, to the LLM.</p>
<p>Integer node encoding improves arithmetic performance.Another finding here is that integer encoding of nodes (e.g., node 0) can improve the performance of LLMs on integer output tasks, such as predicting node degree, node count, and edge count.This is because the input and output of the LLM are then in the same space, making it easier for the model to learn the relationship between the two.Interestingly however, encoder functions with specific names (e.g., David) worked better in non-integer output tasks such as GOT for edge existence or Friendship for cycle check.Summary: Choosing the right graph encoding function significantly affects the performance of LLMs on basic graph algorithms.Therefore, it is important to select a function carefully and appropriately for the specific task.This finding is especially important because many reasoning tasks involve graph problems.For example, finding influential nodes in a social network is similar to finding the degree of the nodes in the graph.Encoding such graphs in the right way for the task can improve the task.We examine the relative rankings of graph encodings more in Appendix A.3.</p>
<p>EXPERIMENT 2: VARYING PROMPT QUESTIONS</p>
<p>In this experiment, we maintained the graph encoding function as a constant for the concept of friendship and conducted experiments using two distinct question encoder functions: the graph question encoder and the application question encoder.The graph question encoder is responsible for encoding graph-related tasks, such as determining the degree of a specific node (e.g., "What is the degree of node i?").This encoder is used for obtaining results in Section 3.1.On the other hand, the application question encoder interprets graph questions in a more practical, day-to-day context.In the application scenario, we used a friendship-based scenario where we transformed the tasks as follows: edge existence became "assessing friendship existence", node degree became "counting the number of friends for an individual", node count became "counting the number of people mentioned", edge count became "counting the number of friendships mentioned", and connected nodes became "listing friends".</p>
<p>Results: Table 2 summarizes the results of our experiment on question encoder functions.As the results show, the application encoder outperforms the graph encoding on almost all tasks, despite both encoders having the same graph encoding function and only differing slightly in how they ask the question.For example, on the ZERO-SHOT edge existence task using PALM 2 XXS, the graph encoding obtained 42.8% accuracy, while the application encoder obtained 60.8%.Summary: The selection of the question encoder function affects the performance of LLMs when handling basic graph algorithms.As a result, it becomes important to translate a given task into more contextually meaningful textual information when employing LLMs for inference.</p>
<p>EXPERIMENT 3: MULTIPLE RELATION ENCODING</p>
<p>In this experimental setup, we introduce a modification to the friendship graph encoding function, which characterizes edges based on a range of distinct relation types, including friends, colleagues, spouses, siblings, neighbors, acquaintances, teammates, classmates, coworkers, or roommates.The selection of the relation type is randomized from this predefined set, thereby using multiple words to reference the existence of a relationship between nodes.This is a departure from using the same token(s) for edge representation in prior graph encoding experiments.</p>
<p>Results: As Table 3 shows, using multiple words to represent relationships did not hurt LLM performance and even improved it in some cases.This improvement is likely because the diverse set of relations provides the LLM with more textual information to perform the task, and the final encoding is closer to the text that the LLM may have seen during training, compared to the prior setup.Results: Model capacity has a significant effect on the graph reasoning ability of an LLM.The results of this experiment, reported in Figure 3, show the larger model is generally better at graph reasoning tasks.This is because it has more capacity to learn and store complex information.The model capacity has less effect on edge existence.The results also show that the model was not able to beat the majority baseline for edge existence even with a large capacity.</p>
<p>EXPERIMENT 5: REASONING IN THE ABSENCE OF EDGES</p>
<p>In this experiment, we evaluate the performance of LLMs on the disconnected nodes task.This task differs from the previous ones in that it requires reasoning about information that is implicit in the graph, i.e., information that is not explicitly mentioned in the output of the graph encoding function.</p>
<p>Results: LLMs lack a global model of a graph.The ZERO-SHOT prompting method achieved an accuracy of 0.5%, while the ZERO-COT, FEW-SHOT, COT, and COT-BAG methods achieved close to 0.0% accuracy.These results suggest that LLMs perform significantly worse on the disconnected nodes task than on the connected nodes task.We believe that this is because the graph encoding functions primarily encode information about connected nodes, while not explicitly encoding information about nodes that are not connected.As a result, LLMs are better at processing relationships among connected nodes than at capturing the absence of connections, leading to sub-optimal performance in disconnectivity-related tasks.</p>
<p>DOES THE STRUCTURE OF THE GRAPH MATTER FOR THE LLM?</p>
<p>It is natural to wonder if the structure of the graph itself might effect LLM's ability to reason over it.Inspired by recent work in analyzing graph neural networks (Palowitch et al., 2022;Yasir et al., 2023) this section seeks to measure a LLM's reasoning capabilities over graph with distinct structures.In this section, we show that graph structure can have significance influence on an LLM's reasoning performance.Figure 4 illustrates graphs created through different generative processes.</p>
<p>RANDOM GRAPH GENERATION</p>
<p>To be able to experiment with LLMs on graphs, we generate random graphs using various graph generator algorithms.This allows us to:</p>
<p>Cover a wide range of properties.Different graph generators produce graphs with different properties.For example, Erdős-Rényi graphs tend to be sparse and have a small average degree, while Barabási-Albert graphs tend to be dense and have a power-law degree distribution.By using a diverse set of generators, we ensure that the GraphQA benchmark includes graphs with a wide range of properties.</p>
<p>Avoid bias in graph problem evaluation.The goal of generating such graphs is to test the ability of LLMs to solve graph problems.Graph problems can vary in difficulty depending on the properties of the graphs, so we use a diverse set of graphs to avoid bias.</p>
<p>Provide realistic benchmarks.Real-world graphs exhibit a wide range of properties, and no single graph generator can capture all of these properties perfectly.By using a diverse set of generators, we create a benchmark that is more representative of real-world graphs.To generate random graphs, we use Erdős-Rényi (ER) graphs (Erdős &amp; Rényi, 1959), scale-free networks (SFN) (Barabási &amp; Albert, 1999), Barabási-Albert (BA) model (Albert &amp; Barabási, 2002), and stochastic block model (SBM) (Holland et al., 1983), in addition to star, path, and complete graph generators.We use NetworkX (Hagberg et al., 2008) to generate the random graphs.The details are reported in Appendix A.4.</p>
<p>RESULTS ON RANDOM GRAPH GENERATORS</p>
<p>Previous experiments have studied the performance of LLMs on basic graph tasks using random graphs generated using the Erdős-Rényi (ER) model.However, ER graphs often do not accurately represent the characteristics of real-world graphs.In this experiment, we investigate the effect of different random graph generators on the performance of LLMs on graph reasoning tasks.To make the experiment more realistic, we sample the few-shot examples randomly from graphs generated using different algorithms.We report the results of this experiment in Table 4.</p>
<p>Graph structure has a significant impact on the LLM's performance.The results show that the algorithm used to generate the graph has a significant impact on the performance of the LLM on graph tasks.For example, the cycle check task achieves 91.7% accuracy on complete graphs and 5.9% accuracy on path graphs.This is because the LLM has a strong prior towards graphs having cycles.Therefore, the accuracy is high for complete graphs, which always have cycles, and very low for path graphs, which never have cycles.By adding few-shot examples some having a cycle and some not, the accuracy of cycle check on path graphs increased from 5.9% to 19.7%.As another example, on the edge existence task, the LLM achieves 60.0% accuracy on path graphs, which are less likely to have an edge between two nodes, and 19.8% accuracy on complete graphs, which have edges between all pairs of nodes.This shows that the LLM has a prior that two nodes in a graph are more likely to be disconnected.</p>
<p>Distractive statements in the graph encoding function disrupt the performance of the LLM.</p>
<p>The accuracy of node degree, node count, and connected nodes tasks is highest for star and path graphs.This is likely because the star and path graphs are more likely to have fewer edges and their graph encoding is most likely shorter with less distracting statements to these tasks.This is also evident from the accuracy of these tasks being among the lowest in complete graphs, which have many edges to specify and therefore many distractors.</p>
<p>Adding out-of-distribution few-shot examples helped the LLM.Similarly to the experiment in Section 3.1, adding few-shot examples and their chain of thought in COT prompting helped on most tasks.The key difference between the few-shot examples in this experiment and the previous one is that in this case, the examples are not required to come from the same graph generator algorithm.This shows that few-shot examples do not need to come from the same generator for the LLM to be helpful, and their main role is to explain the task to the LLM.</p>
<p>Summary:</p>
<p>The performance of large language models (LLMs) on graph tasks is significantly impacted by the graph structure and the distracting statements in the graph encoding function.Graphs with fewer edges and less complex encodings tend to perform better on most tasks.Adding few-shot examples, even if they are out-of-distribution, can help the LLM to perform better on most tasks.</p>
<p>RELATED WORK</p>
<p>In-context learning.One common approach for reasoning with LLMs is to pre-train it on a large corpus of text that is closely related to the reasoning task.This has been shown to improve the performance (Hendrycks et al., 2021;Shen et al., 2021), but it can be computationally expensive, especially for larger models.Additionally, fine-tuning often demands domain-specific data and human expertise, adding to the cost.Brown et al. (2020b) has demonstrated the capabilities of LLMs in tackling novel tasks with little or no training data.The FEW-SHOT method inserts k incontext input-output pairs before the test input and has been shown to significantly improve the performance of the LLM on unseen tasks.Recent research has proposed strategies to improve the selection of in-context demonstrations, such as retrieving semantically similar examples (Liu et al., 2021), employing chain-of-thought reasoning (Wei et al., 2022), and decomposing tasks into subproblems using least-to-most prompting (Zhou et al., 2022a).In this work, we focus on evaluating and enhancing LLMs on basic graph reasoning tasks.We exploit some of the ideas in the literature and compare their results.</p>
<p>Text-based reasoning with LLMs.Numerous models have been proposed for text-based reasoning employing LLMs (see (Huang &amp; Chang, 2022) for a survey).One approach to reasoning with LLMs is modular reasoning.This methodology divides the problem into smaller modules, utilizing distinct LMs to address each module (Zhou et al., 2022a;Kazemi et al., 2022;Khot et al., 2022).Another approach to reasoning with LLMs aims to predict the output of a question in a single LM call.This study primarily focuses on the latter method.</p>
<p>Knowledge-Augmented LLMs.Another body of work is concerned with the use of knowledge (frequently stored in knowledge graphs (KGs)) to improve LLM understanding of the world (Pan et al., 2023).Several different methodologies have been proposed which range from generating additional training data from KGs (Guu et al., 2020;Lewis et al., 2020;Agarwal et al., 2021) to extending pretraining (Yasunaga et al., 2022;Jin et al., 2023).</p>
<p>Reasoning on graphs using LLMs.The combination of graph learning and reasoning with LLMs is a rapidly growing area.InstructGLM (Ye et al., 2023) proposed an instruction-finetuned LLM for performing node classification.Chen et al. (2023) used LLMs as enhancers to exploit text attributes to be used in a graph learning model or as predictors for node classification on text-attributed graphs.</p>
<p>The closest work to ours is Wang et al. (2023), which proposed a set of tasks for benchmarking LLMs on graphs.However, this work omitted several natural graph tasks, lacked variety in the type of graph structure considered, and fixed the graph and question encoder function.They conclude that LLMs have preliminary graph reasoning abilities on somewhat complex graph tasks.</p>
<p>Present work.In this study, we focus on basic graph tasks, which are essential intermediate steps for more complex reasoning tasks on graphs.We conduct extensive experiments on graph and question encoder functions, as well as a wide range of graph generator functions.We provide an extensive study of graph encoding methods for black-box LLM usage, and introduce GraphQA, a new graph benchmark that illustrates the effect of graph structure on LLM encoding.We also provide insights and best practices for encoding graphs as text for use in LLMs.</p>
<p>CONCLUSIONS</p>
<p>In this work, we have presented the first comprehensive study of encoding graph-structured data as text for consumption by LLMs.We show that LLM performance on graph reasoning tasks varies on three fundamental levels: (1) the graph encoding method, (2) the nature of the graph task itself, and (3) interestingly, the very structure of the graph considered.These novel results provide valuable insight on strategies for encoding graphs as text -which can boost performance on graph reasoning tasks inside LLMs by 4.8% to 61.8%.We believe that this is a fruitful avenue for further investigation, and hope that our GraphQA benchmark tasks inspire additional work in the area.</p>
<p>A APPENDIX A.1 GRAPH ENCODING FUNCTION</p>
<p>We conducted an investigation into various methodologies for representing graphs as text.This process of encoding graphs as text can be separated into two key inquiries: First, the encoding of nodes within the graph, and second the encoding of edges between the nodes.</p>
<p>Encoding Nodes.Regarding the encoding of nodes, we examined several techniques, including:</p>
<p>• Integer encoding (e.g., Node 0).</p>
<p>• Utilizing well-known English first names (e.g., David).</p>
<p>• Utilizing popular character names in television series Game of Thrones and South Park.</p>
<p>• Incorporating the first names of American politicians.</p>
<p>• Employing alphabet letters for representation.</p>
<p>Representing Edges.Regarding the encoding of the edges, we examined the following techniques:</p>
<p>• Parenthesis: describing edges as (source node, target node).</p>
<p>• Friendship: source node and target node are friends.</p>
<p>• Coauthorship: source node and target node wrote a paper together.</p>
<p>• Social network: source node and target node are connected.</p>
<p>• Arrows: source node − → target node.</p>
<p>• Incident: source node is connected to target nodes.</p>
<p>Combining the node and edge encoding, we start with the following list of graph encoding functions:</p>
<p>• Adjacency.using integer node encoding and parenthesis edge encoding.</p>
<p>• Incident.using integer node encoding and incident edge encoding.</p>
<p>• Friendship.using well-known english first names as node encoding and friendship edge encoding.</p>
<p>• Co-authorship.using well-known english first names as node encoding and coauthorship edge encoding.</p>
<p>• SP. using South Park character names as node encoding and friendship as edge encoding.</p>
<p>• GOT. using Game of Thrones character names as node encoding and friendship as edge encoding.</p>
<p>• Social network.using well-known English first names and social network edge encoding.</p>
<p>• Politician.using politician American politician first names and social network edge encoding.</p>
<p>• Expert.employing alphabet letters for node encoding and arrows as edge encoding.The encoding starts with "You are a graph analyst" (expert prompting (Zhang et al., 2023a)).</p>
<p>Here, we provide the full details for the graph encoding functions for the graph example in Figure 5.</p>
<p>Adjacency: In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.G describes a graph among nodes 0, 1, 2, 3, 4, 5, 6, 7, and 8.The edges in G are: (0, 1) (0, 2) (1, 2) (2, 3) (2, 4) (2, 5) (2, 7) (3, 8) (5, 6) (6, 7) (7, 8).Incident: G describes a graph among 0, 1, 2, 3, 4, 5, 6, 7, and 8.In this graph: Node 0 is connected to nodes 1, 2. Node 1 is connected to nodes 0, 2. Node 2 is connected to nodes 0, 1, 3, 4, 5, 7. Node 3 is connected to nodes 2, 8. Node 4 is connected to node 2. Node 5 is connected to nodes 2, 6.Node 6 is connected to nodes 7, 5. Node 7 is connected to nodes 2, 8, 6.Node 8 is connected to nodes 3, 7.</p>
<p>Expert: You are a graph analyst and you have been given a graph G among A, B, C, D, E, F, G, H, and I. G has the following undirected edges:
A -&gt; B A -&gt; C B -&gt; C C -&gt; D C -&gt; E C -&gt; F C -&gt; H D -&gt; I F -&gt; G G -&gt; H H -&gt; I A.2 GRAPH TASKS
GraphQA consists of a diverse set of basic graph problems, including:</p>
<p>• Edge existence.Determine whether a given edge exists in a graph.</p>
<p>• Node degree.Calculate the degree of a given node in a graph.</p>
<p>• Node count.Count the number of nodes in a graph.</p>
<p>• Edge count.Count the number of edges in a graph.</p>
<p>• Connected nodes.Find all the nodes that are connected to a given node in a graph.</p>
<p>• Cycle check.Determine whether a graph contains a cycle.</p>
<p>• Disconnected nodes.Find all the nodes that are not connected to a given node in a graph.</p>
<p>These tasks are all relatively simple, but they require LLMs to be able to reason about the relationships between nodes and edges in a graph.While adhering to basic graph tasks, we aimed for a diverse set of tasks, including discriminative (e.g., cycle check) and generative (e.g., connected or disconnected nodes) challenges.These tasks covered various aspects of graph analysis, from existence checks (e.g., edge existence) to quantitative assessments (e.g., node count), path analysis (e.g., cycle check), recall-based tasks (e.g., connected nodes), and null space exploration (e.g., disconnected nodes).</p>
<p>The basic graph tasks listed above are all essential intermediate steps for more complex reasoning tasks on graphs.For example, to determine the shortest path between two nodes in a graph, we must first be able to find all the nodes that are connected to a given node.To detect communities in a graph, we must first be able to identify all the cycles in the graph.To find the most influential node in a graph, we must first be able to calculate the degree of each node.These tasks are essential building blocks for more complex reasoning tasks on graphs.</p>
<p>A.3 GRAPH ENCODING RANKINGS</p>
<p>To provide recommendations about the best graph encoding function to use for each prompt type, we rank the encoders by their average standing (in rank order) on each graph task.The results are presented in Table 5, where a lower number is better (the encoder ranked higher on average).We note that for most prompting methods, incident encoding performed the best.However, for</p>
<p>A.4 IMPLEMENTATION DETAILS</p>
<p>For our experiments, we used PaLM 62B and PaLM 2 (various sizes) served on a 4 × 4 TPU v4 architecture.The decoding temperature was set to zero.We used the NetworkX library (Hagberg et al., 2008) to generate the random graphs and to find the answers to the graph tasks.To generate random graphs, we use Erdős-Rényi (ER) graphs (Erdős &amp; Rényi, 1959), scale-free networks (SFN) (Barabási &amp; Albert, 1999), Barabási-Albert model (BA) (Albert &amp; Barabási, 2002), and stochastic block model (SBM) (Holland et al., 1983), in addition to star, path, and complete graph generators.To generate graphs, we sampled 500 graphs for each of the following algorithms: ER, BA, SFN, and SBM.We sampled 100 graphs for path, complete, and star graphs, as these have less variety.All graphs had between 5 and 20 nodes.For ER graphs, we sampled the probability for edge creation from [0, 1].For SBM graphs, number of communities has been sampled from 2 to 10.</p>
<p>We are committed to open-sourcing both our code and data upon the acceptance of our paper.</p>
<p>A.5 EVALUATING MORE LLMS FOR GRAPH TASKS WITH DIFFERENT GRAPH ENCODING FUNCTIONS</p>
<p>We compared different graph encoding functions on a PaLM 62B (Chowdhery et al., 2022) in Section 3.1.Here, we provide the results of the same experiment on PaLM 2 XXS, XS, S, and L (Anil et al., 2023) in Tables 6, 8, 10 and 11.We also provide results for some instruction-finetuned Flan (Chung et al., 2022) checkpoints of the same models in Tables 7 and 9.</p>
<p>Figure 3 :
3
Figure 3: Effect of Model Capacity on graph reasoning task for PaLM 2-XXS, XS, S, and L.</p>
<p>Figure 4 :
4
Figure 4: Samples of graphs generated with different graph generators in our framework.</p>
<p>Figure 5 :
5
Figure 5: Running example graph for all graph encoding functions.</p>
<p>Table 1 :
1
Comparison of various graph encoder functions based on their accuracy on different graph tasks using PaLM 62B.The most effective prompting heuristic is highlighted with an underline, and the top-performing graph encoder function for it is highlighted in bold.The overall result is represented its average (µ) and an absolute difference (δ) of its best and worst graph encoder.
Overall (µ/δ)44.5 / 9.414.0/16.021.73 / 8.6 12.4 / 4.814.7 / 11.076.0 / 13.2Adjacency45.812.418.814.019.871.6ZERO-SHOTIncident Co-authorship Friendship SP GOT39.6 44.0 46.6 46.4 49.025.0 13.8 11.2 9.0 13.615.6 22.0 23.0 22.4 22.810.6 11.4 10.2 15.0 13.253.8 7.6 4.0 6.2 7.668.8 70.8 82.0 80.4 79.0Social network43.216.022.810.88.281.2Politician44.615.224.211.68.881.0Expert41.210.024.014.816.469.6Overall (µ/δ)33.5 / 11.610.4 / 22.414.6 / 9.49.4 / 4.88.8 / 9.232.3 / 23.2Adjacency34.215.411.012.26.046.2ZERO-COTIncident Co-authorship Friendship SP GOT41.4 29.8 28.4 32.6 34.626.6 9.8 7.0 9.2 8.410.0 15.6 19.4 15.6 16.212.2 8.2 7.4 8.4 8.435.2 3.0 3.0 5.0 5.439.0 28.2 31.2 34.8 33.4Social network30.86.614.09.23.826.0Politician38.04.214.68.63.223.0Expert31.66.014.810.014.228.8Overall (µ/δ)36.8 / 13.817.4 / 23.4 25.3 / 35.6 12.0 / 9.012.4 / 15.237.4 / 24.0Adjacency42.815.447.218.622.247.8FEW-SHOTIncident Co-authorship Friendship SP GOT38.8 29.4 40.6 34.6 40.633.6 15.6 12.2 18.0 17.251.2 15.6 18.4 18.0 14.214.6 10.2 9.8 12.0 12.036.6 9.0 6.4 6.8 3.445.0 46.8 41.4 38.2 28.6Social network37.415.021.210.27.834.2Politician38.013.421.49.67.830.8Expert29.016.620.411.211.823.8Overall (µ/δ)42.8 / 7.029.2 / 60.4 27.6 / 42.4 12.8 / 17.413.1 / 18.058.0 / 16.4Adjacency42.871.257.025.222.456.6Incident41.675.057.621.430.262.6COTCo-authorship Friendship SP43.2 46.6 42.616.4 14.6 17.415.2 23.0 17.08.8 7.8 10.68.4 9.6 8.254.8 61.8 59.4GOT44.017.816.211.87.260.4Social network42.616.421.68.48.060.6Politician42.216.622.69.29.459.4Expert39.617.418.012.414.446.2Overall (µ/δ)37.3 / 16.628.0 / 61.8 26.9 / 33.8 12.5 / 17.815.8 / 31.852.1 / 26.0Adjacency45.866.848.625.020.656.8COT-BAGIncident Co-authorship Friendship SP GOT45.6 25.0 39.0 33.6 32.675.2 14.6 16.2 17.0 15.651.2 17.4 21.8 21.6 18.021.8 7.2 7.4 11.4 11.041.0 9.2 9.8 11.4 10.063.0 37.0 52.0 52.2 54.6Social network44.813.419.69.010.051.2Politician40.417.622.88.210.257.2Expert29.215.820.811.620.445.0
MethodEncodingEdge Existence Node degree Node count Edge count Connected nodes Cycle check</p>
<p>Table 2 :
2
Comparing two question encoders based on their accuracy for PaLM 2 XXS and PaLM 62B.The top-performing question encoder for the respective LLM is highlighted in bold.
Method Question encoderLLMEdge Existence Node degree Node count Edge count Connected nodesGraphPaLM 2-XXS42.810.85.45.61.6ZERO-SHOTApplication GraphPaLM 2-XXS PaLM 62B60.8 46.614.0 11.29.4 23.04.4 10.211.4 4.0ApplicationPaLM 62B47.816.617.813.26.0GraphPaLM2 XXS50.48.88.44.210.2COTApplication GraphPaLM2 XXS PaLM 62B56.4 46.612.2 14.68.6 23.05.4 7.811.0 9.6ApplicationPaLM 62B38.616.616.012.210.0TaskSame relationMultiple relationsZERO-SHOTEdge Existence Node degree Node count Edge count Connected nodes42.8 10.8 5.4 5.6 1.639.8 11.6 6.6 5.4 3.4Cycle Check65.284.4Edge Existence50.450.8Node degree8.810.0COTNode count Edge count8.4 4.25.8 5.0Connected nodes10.27.2Cycle Check77.474.4</p>
<p>Table 3 :
3
Results on multiple relations for edge encoding with PaLM 2 XXS.
100Edge ExistenceNode DegreeNode CountAccuracy (%)0 25 50 75100Edge CountConnected NodesCycle CheckAccuracy (%)XXS XS S PaLM 2 Size 25 50 75 0LXXS XS S PaLM 2 SizeLXXS XS S PaLM 2 SizeLZero-shot Zero-COTFew-shot COTCOT-Bag Baseline</p>
<p>Table 4 :
4
Method Graph generator Edge Existence Node degree Node count Edge count Connected nodes Cycle check Comparing different graph generators on different graph tasks on PaLM 62B.The most effective prompting heuristic is highlighted with an underline, and the top-performing graph generator algorithm for the respective heuristic is highlighted in bold.
Overall49.117.623.012.123.375.2ZERO-SHOTER BA SBM Star SFN45.1 50.2 45.0 58.0 57.613.6 18.0 13.8 34.0 23.122.1 24.9 21.9 32.8 19.911.7 13.6 9.2 31.7 8.014.9 20.1 13.8 61.7 38.176.3 72.0 86.5 8.1 90.0Path60.914.831.928.826.65.9Complete19.812.620.76.213.391.7Overall40.429.631.712.224.359.5ER41.228.428.812.612.861.2COTBA SBM Star40.0 40.3 40.330.0 26.5 38.035.0 30.2 41.814.3 8.7 31.620.8 13.0 68.658.5 65.8 21.3SFN40.232.230.87.143.266.0Path42.035.135.331.127.619.7Complete39.621.928.93.914.669.3</p>
<p>Table 5 :
5
Ranking of graph encodings from experiment in Section 3.1 (lower better).
ZERO-</p>
<p>Table 6 :
6
Method Encoding function Edge Existence Node degree Node count Edge count Connected nodes Cycle check Comparing different graph encoding functions on different graph tasks for PaLM 2 XXS.The most effective prompting heuristic is highlighted with an underline, and the top-performing graph function encoder for the respective heuristic is highlighted in bold.
Overall47.211.38.76.47.261.5Adjacency48.414.46.24.017.682.6ZERO-SHOTIncident Co-authorship Friendship SP GOT45.2 45.4 42.8 56.6 56.413.4 10.8 10.8 11.0 7.87.2 7.4 5.4 7.2 6.05.2 4.6 5.6 5.8 7.011.2 5.2 1.6 3.0 2.068.4 66.4 65.2 26.6 51.8Social Network51.211.07.85.45.274.4Politician40.612.09.46.810.073.2Expert38.010.421.412.89.045.2Overall34.18.61.72.26.013.7Adjacency20.219.02.42.09.016.4ZERO-COTIncident Co-authorship Friendship SP GOT45.0 48.8 43.2 30.8 21.836.0 22.0 0.2 0 01.2 0.8 0.6 1.2 1.26.0 4.4 1.6 0.6 0.616.0 11.8 2.0 1.0 2.637.8 31.6 10.8 3.0 4.8Social Network39.405.01.84.86.2Politician40.602.22.65.27.0Expert16.800.40.61.66.0Overall42.710.323.910.213.326.0Adjacency50.211.877.627.017.483.4FEW-SHOTIncident Co-authorship Friendship SP GOT46.6 44.2 42.8 29.4 26.012.8 7.6 9.6 10.4 10.058.4 31.0 8.8 9.6 8.219.8 11.8 7.4 4.6 5.418.4 11.4 11.8 11.6 9.057.8 31.0 7.2 7.0 9.8Social Network40.49.48.44.212.011.2Politician50.68.27.26.012.612.0Expert54.012.66.06.015.814.6Overall50.624.722.89.313.377.0Adjacency51.080.872.222.019.684.0Incident48.655.054.417.217.281.6COTCo-authorship Friendship51.4 50.431.2 8.829.8 8.410.0 4.212.2 10.280.6 77.4SP52.29.410.06.612.074.6GOT51.49.28.05.610.470.4Social Network53.88.67.85.88.476.0Politician47.09.48.46.413.875.8Expert49.610.26.45.615.672.6Overall50.323.719.49.213.668.4Adjacency49.673.057.822.817.682.4COT-BAGIncident Co-authorship Friendship SP49.6 50.4 48.8 50.453.4 30.4 8.4 7.046.6 28.4 6.2 6.817.6 10.2 5.2 5.014.4 14.6 9.2 12.477.2 74.0 65.8 61.2GOT51.811.06.05.013.257.2Social Network55.810.69.44.611.059.4Politician49.29.46.06.616.069.6Expert47.410.27.46.214.268.6</p>
<p>Table 7 :
7
Comparing different graph encoding functions on different graph tasks for Flan-PaLM 2 XXS.The most effective prompting heuristic is highlighted with an underline, and the topperforming graph function encoder for the respective heuristic is highlighted in bold.
Method Encoding function Edge Existence Node degree Node count Edge count Connected nodes Cycle checkOverall49.923.028.721.310.115.6Adjacency50.822.411.422.225.821.8ZERO-SHOTIncident Co-authorship Friendship SP GOT50.6 48.2 49.2 52.4 53.836.6 21.4 20.6 22.6 17.811.2 31.0 36.2 38.4 32.211.0 17.8 24.0 25.8 25.831.0 11.6 4.2 2.8 1.830.6 6.8 0 0.4 0Social Network44.622.435.824.42.00Politician49.021.432.821.85.215.2Expert50.222.029.618.66.665.4Overall43.73.816.99.915.214.2Adjacency48.216.63.018.426.640.4ZERO-COTIncident Co-authorship Friendship SP GOT53.6 46.8 32.8 40.2 41.210.6 2.6 0.4 0.4 0.22.6 9.2 18.4 21.4 20.86.2 2.2 12.6 4.0 3.850.8 19.6 3.2 4.8 3.643.6 8.6 3.6 7.6 2.8Social Network47.2025.412.43.81.4Politician47.00.827.615.64.810.0Expert36.03.023.814.019.410.2Overall40.422.326.018.716.527.2Adjacency42.223.243.229.621.458.0FEW-SHOTIncident Co-authorship Friendship SP GOT48.6 42.6 45.0 36.6 32.435.4 24.0 17.4 23.6 19.658.8 22.2 16.8 16.2 17.231.8 18.2 13.8 16.0 17.834.0 15.2 13.2 13.0 10.641.2 29.4 18.2 20.2 17.0Social Network41.620.818.414.412.821.0Politician43.016.217.612.811.626.0Expert31.420.223.213.817.013.4Overall57.830.228.217.019.736.4Adjacency43.463.043.026.833.069.8Incident55.863.854.424.644.238.8COTCo-authorship Friendship59.6 64.227.2 19.025.2 20.213.4 12.817.2 13.040.6 40.8SP62.019.218.016.615.010.2GOT62.419.620.617.412.26.2Social Network61.021.423.013.210.442.6Politician55.218.421.414.013.661.4Expert56.420.027.614.418.817.4Overall58.929.630.015.820.037.1Adjacency49.857.843.026.432.871.2COT-BAGIncident Co-authorship Friendship SP57.4 59.0 66.2 61.261.8 27.0 22.6 18.450.0 25.8 22.6 23.823.8 15.6 10.0 15.241.8 17.6 10.2 13.455.8 34.8 38.2 15.6GOT61.220.427.215.013.69.8Social Network60.619.224.810.813.435.8Politician54.817.823.211.215.453.6Expert60.021.429.614.421.819.2</p>
<p>Table 8 :
8
Comparing different graph encoding functions on different graph tasks for PaLM 2 XS.The most effective prompting heuristic is highlighted with an underline, and the top-performing graph function encoder for the respective heuristic is highlighted in bold.Method Encoding function Edge Existence Node degree Node count Edge count Connected nodes Cycle check
Overall68.410.226.84.423.084.4Adjacency78.017.639.07.234.487.2ZERO-SHOTIncident Co-authorship Friendship SP GOT76.2 64.8 63.4 59.2 62.629.6 11.2 5.4 5.4 4.646.0 23.6 23.4 16.8 19.63.8 3.4 3.2 2.8 3.245.8 20.8 15.2 16.0 18.284.4 84.6 84.0 84.0 83.2Social Network72.04.417.64.017.884.0Politician69.05.620.04.417.284.6Expert70.67.635.47.221.484.0Overall54.316.432.213.425.159.9Adjacency68.634.823.016.636.882.0ZERO-COTIncident Co-authorship Friendship SP GOT59.4 51.8 53.8 49.4 47.051.2 15.0 6.2 5.8 7.624.2 25.8 41.6 33.6 27.611.0 11.8 12.2 13.8 12.855.8 26.6 19.6 14.4 16.667.4 41.4 70.6 37.0 38.6Social Network51.48.034.412.418.474.0Politician55.68.835.612.814.653.8Expert51.810.644.217.023.274.6Overall70.913.221.410.010.487.2Adjacency72.022.433.214.412.286.6FEW-SHOTIncident Co-authorship Friendship SP GOT81.8 68.0 66.8 67.6 67.627.0 17.8 7.2 7.0 5.033.6 20.2 17.0 15.8 15.27.2 11.2 9.0 10.0 9.222.0 8.0 4.8 6.0 6.883.4 89.4 86.8 88.6 88.0Social Network70.610.214.69.06.688.2Politician71.28.616.49.06.687.6Expert72.413.626.211.220.886.4Overall71.923.820.712.614.086.7Adjacency76.072.430.225.616.685.4Incident77.063.432.818.023.282.2COTCo-authorship Friendship67.4 69.022.6 7.419.0 17.613.8 7.89.4 10.284.2 88.8SP71.27.415.49.69.487.4GOT71.09.816.47.410.289.4Social Network75.06.811.48.08.088.4Politician72.410.215.411.013.489.8Expert68.214.628.411.825.284.8Overall74.725.027.914.114.888.8Adjacency73.073.837.825.816.286.4COT-BAGIncident Co-authorship Friendship SP80.0 72.4 74.6 74.463.4 25.2 8.6 9.035.0 28.8 25.0 23.619.8 13.8 11.4 10.623.4 11.2 8.6 9.684.2 86.0 90.4 90.0GOT75.68.024.810.212.491.8Social Network76.89.219.69.612.290.4Politician71.212.622.211.813.491.8Expert74.415.434.613.826.688.0</p>
<p>Table 9 :
9
Comparing different graph encoding functions on different graph tasks for Flan-PaLM 2 XS.The most effective prompting heuristic is highlighted with an underline, and the top-performing graph function encoder for the respective heuristic is highlighted in bold.</p>
<p>Co-authorship: G describes a co-authorship graph among James, Robert, John, Michael, David, Mary, Patricia, Jennifer, and Linda.In this co-authorship graph: James and Robert wrote a paper together.James and John wrote a paper together.Robert and John wrote a paper together.John and Michael wrote a paper together.John and David wrote a paper together.John and Mary wrote a paper together.John and Jennifer wrote a paper together.Michael and Linda wrote a paper together.Mary and Patricia wrote a paper together.Patricia and Jennifer wrote a paper together.Jennifer and Linda wrote a paper together.Friendship: G describes a friendship graph among James, Robert, John, Michael, David, Mary, Patricia, Jennifer, and Linda.We have the following edges in G: James and Robert are friends.James and John are friends.Robert and John are friends.John and Michael are friends.John and David are friends.John and Mary are friends.John and Jennifer are friends.Michael and Linda are friends.Mary and Patricia are friends.Patricia and Jennifer are friends.Jennifer and Linda are friends.SP: G describes a friendship graph among Eric, Kenny, Kyle, Stan, Tolkien, Heidi, Bebe, Liane, and Sharon.In this friendship graph: Eric and Kenny are friends, Eric and Kyle are friends, Kenny and Kyle are friends, Kyle and Stan are friends, Kyle and Tolkien are friends, Kyle and Heidi are friends, Kyle and Liane are friends, Stan and Sharon are friends, Heidi and Bebe are friends, Bebe and Liane are friends, Liane and Sharon are friends.GOT: G describes a friendship graph among Ned, Cat, Daenerys, Jon, Bran, Sansa, Arya, Cersei, and Jaime.In this friendship graph: Ned and Cat are friends, Ned and Daenerys are friends, Cat and Daenerys are friends, Daenerys and Jon are friends, Daenerys and Bran are friends, Daenerys and Sansa are friends, Daenerys and Cersei are friends, Jon and Jaime are friends, Sansa and Arya are friends, Arya and Cersei are friends, Cersei and Jaime are friends.Social Network: G describes a social network graph among James, Robert, John, Michael, David, Mary, Patricia, Jennifer, and Linda.We have the following edges in G: James and Robert are connected.James and John are connected.Robert and John are connected.John and Michael are connected.John and David are connected.John and Mary are connected.John and Jennifer are connected.Michael and Linda are connected.Mary and Patricia are connected.Patricia and Jennifer are connected.Jennifer and Linda are connected.Politician: G describes a social network graph among Barack, Jimmy, Arnold, Bernie, Bill, Kamala, Hillary, Elizabeth, and John.We have the following edges in G: Barack and Jimmy are connected.Barack and Arnold are connected.Jimmy and Arnold are connected.Arnold and Bernie are connected.Arnold and Bill are connected.Arnold and Kamala are connected.Arnold and Elizabeth are connected.Bernie and John are connected.Kamala and Hillary are connected.Hillary and Elizabeth are connected.Elizabeth and John are connected.You are a graph analyst and you have been given a graph G among A, B, C, D, E, F, G, H, and I. G has the following undirected edges: A -&gt; B, A -&gt; C, …, H -&gt; I.Graph G Adjacency: In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.G describes a graph among nodes 0, 1, 2, 3, 4, 5, 6, 7, and 8.The edges in G are: (0, 1) (0, 2) … (6, 7) (7, 8).
Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pre-training. Oshin Agarwal, Heming Ge, Siamak Shakeri, Rami Al-Rfou, 2021</p>
<p>Statistical mechanics of complex networks. Réka Albert, Albert-László Barabási, Reviews of modern physics. 741472002</p>
<p>. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.104032023Palm 2 technical report. arXiv preprint</p>
<p>Emergence of scaling in random networks. Albert-László Barabási, Réka Albert, science. 28654391999</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 2020a33</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 2020b33</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Exploring the potential of large language models (llms) in learning on graphs. Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, arXiv:2307.033932023arXiv preprint</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>Scaling instruction-finetuned language models. Chung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, arXiv:2210.114162022arXiv preprint</p>
<p>Peter Clark, Oyvind Tafjord, Kyle Richardson, arXiv:2002.05867Transformers as soft reasoners over language. 2020arXiv preprint</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>A generalization of transformer networks to graphs. Vijay Prakash, Dwivedi , Xavier Bresson, arXiv:2012.096992020arXiv preprint</p>
<p>On random graphs. Paul Erdős, Alfred Rényi, Publicationes Mathematicae Debrecen. 61959</p>
<p>Retrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, International conference on machine learning. PMLR2020</p>
<p>Exploring network structure, dynamics, and function using networkx. Aric Hagberg, Pieter Swart, Daniel S Chult, 2008Los Alamos, NM (United StatesLos Alamos National Lab.(LANL)Technical report</p>
<p>Measuring mathematical problem solving with the math dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, arXiv:2103.038742021arXiv preprint</p>
<p>Stochastic blockmodels: First steps. Kathryn Blackmond Paul W Holland, Samuel Laskey, Leinhardt, Social networks. 521983</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint</p>
<p>Jie Huang, Kevin Chen, -Chuan Chang, arXiv:2212.10403Towards reasoning in large language models: A survey. 2022arXiv preprint</p>
<p>Wentao Bowen Jin, Yu Zhang, Yu Zhang, Xinyang Meng, Qi Zhang, Jiawei Zhu, Han, Patton, arXiv:2305.12268Language model pretraining on text-rich networks. 2023arXiv preprint</p>
<p>Najoung Seyed Mehran Kazemi, Deepti Kim, Xin Bhatia, Deepak Xu, Ramachandran, Lambada, arXiv:2212.13894Backward chaining for automated reasoning in natural language. 2022arXiv preprint</p>
<p>Decomposed prompting: A modular approach for solving complex tasks. Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, Ashish Sabharwal, arXiv:2210.024062022arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>The power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, arXiv:2104.086912021arXiv preprint</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, Weizhu Chen, arXiv:2101.06804What makes good in-context examples for gpt-3?. 2021arXiv preprint</p>
<p>Attending to graph transformers. Luis Müller, Mikhail Galkin, Christopher Morris, Ladislav Rampášek, arXiv:2302.041812023arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>Graphworld: Fake graphs bring real insights for gnns. John Palowitch, Anton Tsitsulin, Brandon Mayer, Bryan Perozzi, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2022</p>
<p>Unifying large language models and knowledge graphs: A roadmap. Linhao Shirui Pan, Yufei Luo, Chen Wang, Jiapu Chen, Xindong Wang, Wu, 2023</p>
<p>Automatic prompt optimization with" gradient descent" and beam search. Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael Zeng, arXiv:2305.034952023arXiv preprint</p>
<p>A decade of knowledge graphs in natural language processing: A survey. Phillip Schneider, Tim Schopf, Juraj Vladika, Mikhail Galkin, Elena Simperl, Florian Matthes, arXiv:2210.001052022arXiv preprint</p>
<p>Jianhao Shen, Yichun Yin, Lin Li, Lifeng Shang, Xin Jiang, Ming Zhang, Qun Liu, arXiv:2109.03034Generate &amp; rank: A multi-task framework for math word problems. 2021arXiv preprint</p>
<p>Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 201730Attention is all you need</p>
<p>Can language models solve graph problems in natural language?. Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, Yulia Tsvetkov, arXiv:2305.100372023arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Denny Quoc V Le, Xinyun Zhou, Chen, arXiv:2309.03409Large language models as optimizers. 2023arXiv preprint</p>
<p>Examining the effects of degree distribution and homophily in graph learning models. Mustafa Yasir, John Palowitch, Anton Tsitsulin, Long Tran-Thanh, Bryan Perozzi, 2023</p>
<p>Deep bidirectional language-knowledge graph pretraining. Michihiro Yasunaga, Antoine Bosselut, Hongyu Ren, Xikun Zhang, Christopher D Manning, Percy Liang, Jure Leskovec, 2022</p>
<p>Natural language is all a graph needs. Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang, arXiv:2308.071342023arXiv preprint</p>
<p>Graph-bert: Only attention is needed for learning graph representations. Jiawei Zhang, Haopeng Zhang, Congying Xia, Li Sun, arXiv:2001.051402020arXiv preprint</p>
<p>Exploring the mit mathematics and eecs curriculum using large language models. Sarah J Zhang, Samuel Florin, Ariel N Lee, Eamon Niknafs, Andrei Marginean, Annie Wang, Keith Tyser, Zad Chin, Yann Hicke, Nikhil Singh, arXiv:2306.089972023aarXiv preprint</p>
<p>Siren's song in the ai ocean: A survey on hallucination in large language models. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, arXiv:2309.012192023barXiv preprint</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>Least-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, arXiv:2205.106252022aarXiv preprint</p>
<p>Large language models are human-level prompt engineers. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba, arXiv:2211.019102022barXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>