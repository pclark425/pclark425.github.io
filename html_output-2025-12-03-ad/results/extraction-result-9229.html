<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9229 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9229</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9229</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-232147202</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2103.03943v2.pdf" target="_blank">Novelty Detection in Sequential Data by Informed Clustering and Modeling</a></p>
                <p><strong>Paper Abstract:</strong> Novelty detection in discrete sequences is a challenging task, since deviations from the process generating the normal data are often small or intentionally hidden. Novelties can be detected by modeling normal sequences and measuring the deviations of a new sequence from the model predictions. However, in many applications data is generated by several distinct processes so that models trained on all the data tend to over-generalize and novelties remain undetected. We propose to approach this challenge through decomposition: by clustering the data we break down the problem, obtaining simpler modeling task in each cluster which can be modeled more accurately. However, this comes at a trade-off, since the amount of training data per cluster is reduced. This is a particular problem for discrete sequences where state-of-the-art models are data-hungry. The success of this approach thus depends on the quality of the clustering, i.e., whether the individual learning problems are sufficiently simpler than the joint problem. While clustering discrete sequences automatically is a challenging and domain-specific task, it is often easy for human domain experts, given the right tools. In this paper, we adapt a state-of-the-art visual analytics tool for discrete sequence clustering to obtain informed clusters from domain experts and use LSTMs to model each cluster individually. Our extensive empirical evaluation indicates that this informed clustering outperforms automatic ones and that our approach outperforms state-of-the-art novelty detection methods for discrete sequences in three real-world application scenarios. In particular, decomposition outperforms a global model despite less training data on each individual cluster.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9229.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9229.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IC-LSTMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Informed Clustering + Per-Cluster LSTM Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A novelty-detection framework that first obtains semantically informed clusters (via an interactive LDA-based visual analytics tool) and then trains an LSTM language model per cluster; novelties are detected by computing sequence perplexity under the cluster model assigned to a new sequence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>custom per-cluster LSTM language models</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM (recurrent neural network language model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>discrete sequences (categorical token sequences); also applied to discretized real-valued time series (binned windows)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>cybersecurity (system-call/session logs), fake reviews (text), server usage/time-series (CPU utilization discretized into bins)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>novelties / point anomalies in sequences (attacks/intrusions, fake reviews, anomalous time-windowed time series points)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cluster normal-training sequences using an informed visual-analytics workflow built on multiple LDA runs; train one LSTM language model per cluster. For inference, assign a new sequence to the most probable informed cluster (via topic probabilities) and compute model perplexity across prefixes; flag as novelty if perplexity exceeds a threshold θ.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Global LSTM (single LSTM on all data); k-means Cluster LSTMs; LDA Cluster LSTMs; kNN (Minkowski), kNN (LCS for time series), HDBSCAN (density clustering), one-class SVM (OC-SVM), Isolation Forests (IsoForests) applied on BoW / sequential-pattern (SP) features or BoW+SP.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>ROC AUC, sensitivity (Sens.), specificity (Spec.), and the mean of sensitivity and specificity (reported as balanced Sens./Spec. score); ROC curves and threshold sweeping used to compute AUC.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Across three real-world datasets IC-LSTMs achieved top performance overall. On the fake-reviews task IC-LSTMs reported AUC = 0.99 (compare: Global LSTM AUC = 0.96; LDA Cluster LSTMs AUC = 0.98; k-means Cluster LSTMs AUC = 0.97). On discretized server-time-series per-cluster results reported for two clusters (sizes 322 and 137) gave IC-LSTM AUCs 0.97 and 1.0 respectively, while the Global LSTM had AUCs 0.97 and 0.94 on those clusters. For the cybersecurity dataset, IC-LSTMs are reported to substantially outperform all listed baselines (AUC numbers not printed in the paper excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>IC-LSTMs outperform a Global LSTM trained on all data and outperform several standard anomaly-detection baselines (kNN, HDBSCAN, OC-SVM, Isolation Forests on BoW/SP features); informed visual clustering generally outperforms automatic clusterings (k-means, plain LDA) in the evaluated tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance depends strongly on clustering quality; clustering reduces per-cluster training data which can risk underfitting but authors observed good performance even on small clusters; the pipeline assigns each new sequence strictly to one cluster which may be suboptimal (authors note combining predictions from multiple clusters could improve results); informed clustering requires human-in-the-loop (domain experts or data scientists) via the visual tool; discretization is needed to apply framework to real-valued time series; some baselines were hyperparameter-optimized on test data (results optimistic); fake-review labels used are imperfect; small anomaly counts (e.g., in NAB subset) make results noisy; LCS-based kNN tuning is extremely costly (reported ~120 hours for tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Decomposing heterogeneous sequence data into semantically coherent clusters before training language models increases sensitivity to subtle novelties compared to global modeling; surprisingly, per-cluster LSTM models perform well even with much less training data per cluster (authors conjecture that slight local overfitting can be beneficial for novelty detection); using perplexity from an LSTM language model on sequence prefixes is an effective novelty score for discrete sequences; human-informed LDA topic grouping (via visual analytics) can produce better clusterings for the detection task than automated clustering methods.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9229.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9229.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Global LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Global LSTM Language Model (single-model baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A single LSTM language model trained on the entire training dataset (no decomposition); used as a baseline to assess whether per-cluster modeling improves novelty detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>global LSTM language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM (recurrent neural network language model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>discrete sequences (categorical token sequences); also applied to discretized time series</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>cybersecurity session logs, fake review text, server CPU time series (binned)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>novelties in sequences (attacks, fake reviews, anomalous time windows)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train a single LSTM on all normal sequences and use sequence perplexity to score novelties (same perplexity scoring as per-cluster models).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared directly to per-cluster LSTMs (IC-LSTMs), and to classical anomaly-detection methods (kNN, HDBSCAN, OC-SVM, IsoForests) on transformed features.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>ROC AUC, sensitivity, specificity, mean of sensitivity and specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Examples: Fake reviews task: Global LSTM AUC = 0.96 (IC-LSTMs reported AUC = 0.99). Time-series clusters: Global LSTM per-cluster AUCs reported as 0.97 and 0.94 on two clusters vs. IC-LSTM 0.97 and 1.0 respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Global LSTM is consistently outperformed by the per-cluster (IC-LSTM) approach in the evaluated datasets; global modeling tends to overgeneralize across heterogeneous processes and becomes less sensitive to subtle anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Over-generalization when multiple underlying processes generate the data (mixture distributions) reduces sensitivity; less effective when data contains distinct behavior/process clusters.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Serves to demonstrate that decomposition (even at cost of less training data per model) can improve novelty detection sensitivity relative to a single high-capacity model trained on heterogeneous data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9229.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9229.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tuor2018</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent neural network language models for open vocabulary event-level cyber anomaly detection (Tuor et al., 2018)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related-work example where character-level RNN language modeling is applied to log-file lines for anomaly detection in network security; demonstrates the use of language models on log data but notes sensitivity to log formatting and limited session-context use.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent neural network language models for open vocabulary event-level cyber anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>character-level RNN language model (in referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>RNN / language model (character-level)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log-file lines (textual sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>network security / log analysis</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>fraudulent or anomalous log events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Apply character-level language modeling to individual log lines and use the model's likelihoods to identify anomalous events.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Referenced paper reportedly performed well on a public dataset, but was sensitive to log formatting and did not exploit multi-action sequences (session context).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Sensitive to log format specifics (e.g., presence of IP addresses or status codes), and does not incorporate information about sequences of actions within a session according to the present paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Shows prior use of language-model likelihoods for anomaly detection in logging contexts and motivated authors' emphasis on modeling full sessions (sequences) rather than isolated log lines.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9229.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9229.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kim2016</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LSTM-based system-call language modeling and robust ensemble method for designing host-based intrusion detection systems (Kim et al., 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related-work reference that applies LSTM-based language models to system-call sequences and uses ensembles; mentions need for separate modeling for groups of behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Lstm-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM language models (ensemble in referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM (recurrent neural network language model) and ensemble methods</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>system-call sequences (discrete sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>host-based intrusion detection / cybersecurity</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>intrusions / anomalous system-call sequences</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train LSTM language models on system-call sequences and combine via ensemble techniques for robust intrusion detection (as described in referenced paper).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Cited as an example where language modeling works for system-call anomaly detection; the present paper notes Kim et al. mention the need for separate modeling for particular groups of behaviors but do not partition the data themselves (they use ensembles instead).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Does not partition data into behavior-specific clusters; uses ensemble rather than per-cluster decomposition, which the present paper contrasts with their decomposition-before-modeling approach.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Cited to support the utility of LSTM language modeling for discrete-sequence anomaly detection and to motivate per-cluster modeling as an alternative to ensembles.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Recurrent neural network language models for open vocabulary event-level cyber anomaly detection. <em>(Rating: 2)</em></li>
                <li>Lstm-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems. <em>(Rating: 2)</em></li>
                <li>A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional lstm neural networks. <em>(Rating: 1)</em></li>
                <li>Deep learning for anomaly detection: A survey. <em>(Rating: 1)</em></li>
                <li>Robust anomaly detection for multivariate time series through stochastic recurrent neural network. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9229",
    "paper_id": "paper-232147202",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "IC-LSTMs",
            "name_full": "Informed Clustering + Per-Cluster LSTM Language Models",
            "brief_description": "A novelty-detection framework that first obtains semantically informed clusters (via an interactive LDA-based visual analytics tool) and then trains an LSTM language model per cluster; novelties are detected by computing sequence perplexity under the cluster model assigned to a new sequence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "custom per-cluster LSTM language models",
            "model_type": "LSTM (recurrent neural network language model)",
            "model_size": null,
            "data_type": "discrete sequences (categorical token sequences); also applied to discretized real-valued time series (binned windows)",
            "data_domain": "cybersecurity (system-call/session logs), fake reviews (text), server usage/time-series (CPU utilization discretized into bins)",
            "anomaly_type": "novelties / point anomalies in sequences (attacks/intrusions, fake reviews, anomalous time-windowed time series points)",
            "method_description": "Cluster normal-training sequences using an informed visual-analytics workflow built on multiple LDA runs; train one LSTM language model per cluster. For inference, assign a new sequence to the most probable informed cluster (via topic probabilities) and compute model perplexity across prefixes; flag as novelty if perplexity exceeds a threshold θ.",
            "baseline_methods": "Global LSTM (single LSTM on all data); k-means Cluster LSTMs; LDA Cluster LSTMs; kNN (Minkowski), kNN (LCS for time series), HDBSCAN (density clustering), one-class SVM (OC-SVM), Isolation Forests (IsoForests) applied on BoW / sequential-pattern (SP) features or BoW+SP.",
            "performance_metrics": "ROC AUC, sensitivity (Sens.), specificity (Spec.), and the mean of sensitivity and specificity (reported as balanced Sens./Spec. score); ROC curves and threshold sweeping used to compute AUC.",
            "performance_results": "Across three real-world datasets IC-LSTMs achieved top performance overall. On the fake-reviews task IC-LSTMs reported AUC = 0.99 (compare: Global LSTM AUC = 0.96; LDA Cluster LSTMs AUC = 0.98; k-means Cluster LSTMs AUC = 0.97). On discretized server-time-series per-cluster results reported for two clusters (sizes 322 and 137) gave IC-LSTM AUCs 0.97 and 1.0 respectively, while the Global LSTM had AUCs 0.97 and 0.94 on those clusters. For the cybersecurity dataset, IC-LSTMs are reported to substantially outperform all listed baselines (AUC numbers not printed in the paper excerpt).",
            "comparison_to_baseline": "IC-LSTMs outperform a Global LSTM trained on all data and outperform several standard anomaly-detection baselines (kNN, HDBSCAN, OC-SVM, Isolation Forests on BoW/SP features); informed visual clustering generally outperforms automatic clusterings (k-means, plain LDA) in the evaluated tasks.",
            "limitations_or_failure_cases": "Performance depends strongly on clustering quality; clustering reduces per-cluster training data which can risk underfitting but authors observed good performance even on small clusters; the pipeline assigns each new sequence strictly to one cluster which may be suboptimal (authors note combining predictions from multiple clusters could improve results); informed clustering requires human-in-the-loop (domain experts or data scientists) via the visual tool; discretization is needed to apply framework to real-valued time series; some baselines were hyperparameter-optimized on test data (results optimistic); fake-review labels used are imperfect; small anomaly counts (e.g., in NAB subset) make results noisy; LCS-based kNN tuning is extremely costly (reported ~120 hours for tuning).",
            "unique_insights": "Decomposing heterogeneous sequence data into semantically coherent clusters before training language models increases sensitivity to subtle novelties compared to global modeling; surprisingly, per-cluster LSTM models perform well even with much less training data per cluster (authors conjecture that slight local overfitting can be beneficial for novelty detection); using perplexity from an LSTM language model on sequence prefixes is an effective novelty score for discrete sequences; human-informed LDA topic grouping (via visual analytics) can produce better clusterings for the detection task than automated clustering methods.",
            "uuid": "e9229.0"
        },
        {
            "name_short": "Global LSTM",
            "name_full": "Global LSTM Language Model (single-model baseline)",
            "brief_description": "A single LSTM language model trained on the entire training dataset (no decomposition); used as a baseline to assess whether per-cluster modeling improves novelty detection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "global LSTM language model",
            "model_type": "LSTM (recurrent neural network language model)",
            "model_size": null,
            "data_type": "discrete sequences (categorical token sequences); also applied to discretized time series",
            "data_domain": "cybersecurity session logs, fake review text, server CPU time series (binned)",
            "anomaly_type": "novelties in sequences (attacks, fake reviews, anomalous time windows)",
            "method_description": "Train a single LSTM on all normal sequences and use sequence perplexity to score novelties (same perplexity scoring as per-cluster models).",
            "baseline_methods": "Compared directly to per-cluster LSTMs (IC-LSTMs), and to classical anomaly-detection methods (kNN, HDBSCAN, OC-SVM, IsoForests) on transformed features.",
            "performance_metrics": "ROC AUC, sensitivity, specificity, mean of sensitivity and specificity.",
            "performance_results": "Examples: Fake reviews task: Global LSTM AUC = 0.96 (IC-LSTMs reported AUC = 0.99). Time-series clusters: Global LSTM per-cluster AUCs reported as 0.97 and 0.94 on two clusters vs. IC-LSTM 0.97 and 1.0 respectively.",
            "comparison_to_baseline": "Global LSTM is consistently outperformed by the per-cluster (IC-LSTM) approach in the evaluated datasets; global modeling tends to overgeneralize across heterogeneous processes and becomes less sensitive to subtle anomalies.",
            "limitations_or_failure_cases": "Over-generalization when multiple underlying processes generate the data (mixture distributions) reduces sensitivity; less effective when data contains distinct behavior/process clusters.",
            "unique_insights": "Serves to demonstrate that decomposition (even at cost of less training data per model) can improve novelty detection sensitivity relative to a single high-capacity model trained on heterogeneous data.",
            "uuid": "e9229.1"
        },
        {
            "name_short": "Tuor2018",
            "name_full": "Recurrent neural network language models for open vocabulary event-level cyber anomaly detection (Tuor et al., 2018)",
            "brief_description": "Related-work example where character-level RNN language modeling is applied to log-file lines for anomaly detection in network security; demonstrates the use of language models on log data but notes sensitivity to log formatting and limited session-context use.",
            "citation_title": "Recurrent neural network language models for open vocabulary event-level cyber anomaly detection.",
            "mention_or_use": "mention",
            "model_name": "character-level RNN language model (in referenced work)",
            "model_type": "RNN / language model (character-level)",
            "model_size": null,
            "data_type": "log-file lines (textual sequences)",
            "data_domain": "network security / log analysis",
            "anomaly_type": "fraudulent or anomalous log events",
            "method_description": "Apply character-level language modeling to individual log lines and use the model's likelihoods to identify anomalous events.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": "Referenced paper reportedly performed well on a public dataset, but was sensitive to log formatting and did not exploit multi-action sequences (session context).",
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Sensitive to log format specifics (e.g., presence of IP addresses or status codes), and does not incorporate information about sequences of actions within a session according to the present paper's discussion.",
            "unique_insights": "Shows prior use of language-model likelihoods for anomaly detection in logging contexts and motivated authors' emphasis on modeling full sessions (sequences) rather than isolated log lines.",
            "uuid": "e9229.2"
        },
        {
            "name_short": "Kim2016",
            "name_full": "LSTM-based system-call language modeling and robust ensemble method for designing host-based intrusion detection systems (Kim et al., 2016)",
            "brief_description": "Related-work reference that applies LSTM-based language models to system-call sequences and uses ensembles; mentions need for separate modeling for groups of behaviors.",
            "citation_title": "Lstm-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems.",
            "mention_or_use": "mention",
            "model_name": "LSTM language models (ensemble in referenced work)",
            "model_type": "LSTM (recurrent neural network language model) and ensemble methods",
            "model_size": null,
            "data_type": "system-call sequences (discrete sequences)",
            "data_domain": "host-based intrusion detection / cybersecurity",
            "anomaly_type": "intrusions / anomalous system-call sequences",
            "method_description": "Train LSTM language models on system-call sequences and combine via ensemble techniques for robust intrusion detection (as described in referenced paper).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": "Cited as an example where language modeling works for system-call anomaly detection; the present paper notes Kim et al. mention the need for separate modeling for particular groups of behaviors but do not partition the data themselves (they use ensembles instead).",
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Does not partition data into behavior-specific clusters; uses ensemble rather than per-cluster decomposition, which the present paper contrasts with their decomposition-before-modeling approach.",
            "unique_insights": "Cited to support the utility of LSTM language modeling for discrete-sequence anomaly detection and to motivate per-cluster modeling as an alternative to ensembles.",
            "uuid": "e9229.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Recurrent neural network language models for open vocabulary event-level cyber anomaly detection.",
            "rating": 2,
            "sanitized_title": "recurrent_neural_network_language_models_for_open_vocabulary_eventlevel_cyber_anomaly_detection"
        },
        {
            "paper_title": "Lstm-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems.",
            "rating": 2,
            "sanitized_title": "lstmbased_systemcall_language_modeling_and_robust_ensemble_method_for_designing_hostbased_intrusion_detection_systems"
        },
        {
            "paper_title": "A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional lstm neural networks.",
            "rating": 1,
            "sanitized_title": "a_novel_approach_for_automatic_acoustic_novelty_detection_using_a_denoising_autoencoder_with_bidirectional_lstm_neural_networks"
        },
        {
            "paper_title": "Deep learning for anomaly detection: A survey.",
            "rating": 1,
            "sanitized_title": "deep_learning_for_anomaly_detection_a_survey"
        },
        {
            "paper_title": "Robust anomaly detection for multivariate time series through stochastic recurrent neural network.",
            "rating": 1,
            "sanitized_title": "robust_anomaly_detection_for_multivariate_time_series_through_stochastic_recurrent_neural_network"
        }
    ],
    "cost": 0.013377249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Informed Novelty Detection in Sequential Data by Per-Cluster Modeling</p>
<p>Linara Adilova 
Siming Chen 
Michael Kamp 
Informed Novelty Detection in Sequential Data by Per-Cluster Modeling</p>
<p>Novelty detection in discrete sequences is a challenging task, since deviations from the process generating the normal data are often small or intentionally hidden. In many applications data is generated by several distinct processes so that models trained on all the data tend to overgeneralize and novelties remain undetected. We propose to approach this challenge through decomposition: by clustering the data we break down the problem, obtaining simpler modeling tasks in each cluster which can be modeled more accurately. However, this comes at a cost, since the amount of training data per cluster is reduced. This is a particular problem for discrete sequences where state-of-the-art models are data-hungry. The success of this approach thus depends on the quality of the clustering, i.e., whether the individual learning problems are sufficiently simpler than the joint problem. In this paper we adapt a state-of-the-art visual analytics tool for discrete sequence clustering to obtain informed clusters from domain experts, since clustering discrete sequences automatically is a challenging and domain-specific task. We use LSTMs to further model each of the clusters. Our empirical evaluation indicates that this informed clustering outperforms automatic ones and that our approach outperforms standard novelty detection methods for discrete sequences in three real-world application scenarios.</p>
<p>Introduction</p>
<p>The task of identifying point anomalies, as classified by (Chandola et al., 2009), with respect to previously observed 1 Ruhr-University Bochum, Bochum, Germany 2 School of Data Science, Fudan University, Shanghai, China 3 Institute for AI in medicine (IKIM) at University Hospital Essen, Essen, Germany 4 Monash University, Melbourne Australia. Correspondence to: Linara Adilova <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#108;&#105;&#110;&#97;&#114;&#97;&#46;&#97;&#100;&#105;&#108;&#111;&#118;&#97;&#64;&#114;&#117;&#98;&#46;&#100;&#101;">&#108;&#105;&#110;&#97;&#114;&#97;&#46;&#97;&#100;&#105;&#108;&#111;&#118;&#97;&#64;&#114;&#117;&#98;&#46;&#100;&#101;</a>. data is at the core of many applications: in cybersecurity, a novel kind of interaction with a web service can indicate an attack, and in news verification, detecting a deviation in the writing style can hint at an article being fake. If a dataset of previously observed instances without anomalies is available, this form of anomaly detection is called novelty detection. This task is particularly challenging for discrete sequential data, since deviations may occur only in the order of elements or in the frequency of patterns within the sequence. Usually anomaly and novelty detection methods are based on some form of similarity measure between instances, but approaches that only compare sequences by the elements that they contain will fail in such cases. Instead, the state-of-the-art approach is to use metrics designed for sequences, such as the longest common sub-sequence distance (Chandola et al., 2008;Budalakoti et al., 2006), or to use sequential pattern mining to extract features to be used with Euclidean distances (Feremans et al., 2019). Nevertheless, it is always hard to choose the features that will suit the task at hand or the distance measure that captures the novel behavior best. A more general approach is to model the process that generates the sequences (Marchi et al., 2015;Warrender et al., 1999;Florez-Larrahondo et al., 2005) and check whether an observed sequence is likely under that model. For this predictive modeling to work, it is paramount that the process is imitated accurately, since novelties often deviate only slightly from previously observed sequences. Recurrent neural networks, such as long short-term memory networks (LSTMs) or gated recurrent unit networks (GRUs), achieve high accuracy, outperforming both sequential metrics and pattern mining approaches (Chalapathy &amp; Chawla, 2019). However, often sequences are generated not by a single process, but by several distinct processes, e.g., different behavioral patterns of users of a system or separate topics of news that will vary in the domain-specific language used. Modeling all of them jointly can lead to over-generalization which results in a lower sensitivity to small deviations. In predictive modeling, an approach to improve the modeling accuracy is decomposition: the data is decomposed into parts that are supposed to constitute easier sub-problems. The idea is that models trained on each part-sometimes referred to as local experts (Nowlan &amp; Hinton, 1991)-outperform the global model (Sharkey, 1999a). Even though this decomposition reduces the available training data per model, it has been observed that given a good arXiv:2103.03943v2 [cs.LG] 10 Jul 2023 decomposition, this approach is beneficial. For example, in natural language processing, domain-specific modeling outperforms global models, even for high-capacity model classes such as recurrent neural networks (Joshi et al., 2012). This paper proposes to use decomposition in novelty detection in discrete sequences. That is, the training data  is decomposed into clusters, on each of which a model is trained (Fig. 1). During inference, a new data point is assigned to a cluster and the likelihood under the respective model is used to determine whether it is a novelty (Fig. 2). This general framework allows for many choices of decomposition and modeling techniques. A major challenge is identifying the right decomposition automatically. This is hard for sequential data, in particular, due to its high dimensionality and structure. However, for a human it is often quite simple to find meaningful groups in data. Visual analytics tools for including a human in the loop are widely employed directly for anomaly detection (Janetzko et al., 2014;Leite et al., 2018) and also for analysis of behavior as sequences of actions in various applications (Shi et al., 2020). This paper uses visual analytics to obtain a human knowledge based, semantically informed clustering. For that, we extend a visual analytics tool developed for finding user behavior clusters (Chen et al., 2019). This interface was evaluated by domain experts and got very positive feedback as a clustering technique allowing for deep insights into the sequential data and flexible decomposition of sequences into semantically sound clusters 1 . We derive a method for assigning new incoming sequences to clusters obtained by this tool in order to use it in our framework. We then train LSTMs (Hochreiter &amp; Schmidhuber, 1997) per cluster and use them to determine whether a new sequence is a novelty based on the perplexity score of their predictions-a widely applied technique for evaluating the quality of language models in natural language processing application (Jurafsky, 2000). This decomposition framework for novelty detection in dis-1 For a detailed demonstration see http://simingchen. me/docs/tvcg19_lda.mp4 crete sequences differs fundamentally from the classical use of clustering to identify anomalies directly (Pavlov, 2003;Chandola et al., 2008;Cadez et al., 2000). It also differs from approaches that use modeling only to obtain a representation of the data, e.g., the use of the transformation by an autoencoder neural network as feature vector for classical anomaly detection methods (Yuan et al., 2017;Corizzo et al., 2020). We show that this approach outperforms a global model trained on all data in three real-world applications, despite the fact that the amount of training data for the global model is substantially larger than for the cluster models. We also show that the human-knowledge based informed clustering can outperform automatic clustering techniques, e.g., k-nearest neighbor (kNN) or Latent Dirichlet Allocation (LDA). Moreover, this approach substantially outperforms standard approaches for novelty detection in discrete sequential data based on sequence metrics and sequential pattern mining. Thus, this technique can improve the detection of fake news or attacks in cybersecurity.</p>
<p>In summary, the contributions are: (i) a novel framework that combines informed decomposition and modeling for novelty detection in discrete sequential data, (ii) an extension of a visual analytics tool that allows human experts to easily identify meaningful clusters of discrete sequences, and (iii) an evaluation of the framework for novelty detection in sequential data in three real-world scenarios.</p>
<p>Related Work</p>
<p>Novelty Detection in Discrete Sequences</p>
<p>Novelty and anomaly detection are particularly challenging for discrete sequences (Domingues et al., 2019;Chandola et al., 2010), since anomalies often only deviate in the order of elements or the frequency of patterns. State-of-the-art approaches use common outliers detection algorithms in combination with sequence specific metrics, or sequence specific features (e.g., sequential patterns). However, these approaches are computationally expensive and become infeasible for large amounts of data and long sequences: computing the longest common sub-sequence of two sequences has a runtime linear in the product of their lengths, and sequential pattern mining is in #P (Dong &amp; Pei, 2007). Note that detecting novel discrete sequences is fundamentally different from outlier detection in time-series, where a single time point constitutes an outlier. Therefore, approaches for outlier detection in time series (Ren et al., 2019;Zhang et al., 2019, cf.) cannot be straight-forwardly applied.</p>
<p>A different way is to model the normal sequences and use the models for novelty detection. A successful approach to discrete sequence modeling is adapting tools from natural language processing, particularly LSTM-based neural language models (Chalapathy &amp; Chawla, 2019). The task of a language model is to identify the likelihood of a sequence of words and it is usually trained in an unsupervised way on a vast amount of unlabeled data, therefore it allows to understand which sequences do not belong to the learned language distribution. In the general case of discrete sequences, objects organized in sequences are treated as words, and the model learns the probability distribution over the space of object sequences. Language modeling was already employed in anomaly detection for network security. For example, (Tuor et al., 2018) applied character level language modeling for separate lines of logging files in order to identify fraudulent actions. This approach was shown to perform well on one of the publicly available datasets, but is rather sensitive to the format of logging information, e.g., having information about the IP address of the request and success of the performed action. It also does not employ the information of the sequences of actions performed in each interaction. (Kim et al., 2016) instead use an ensemble of language models that are learning normal user behavior from sequences of actions. Both (Tuor et al., 2018) and (Kim et al., 2016) mention the need of separate modeling for particular groups of behaviors. However, (Tuor et al., 2018) only partitions data based on the timespan of sessions and (Kim et al., 2016) does not partition data at all, but instead uses an ensemble of different models. Our goal is to demonstrate that modeling applied after clustering is more beneficial than straightforward modeling or other non-modeling based approaches. The model (here LSTMs) can be replaced with specialized approaches, based e.g., on GRUs or VAEs (Su et al., 2019).</p>
<p>Decomposition for Modeling</p>
<p>This paper proposes to decompose data by informed clustering and model each cluster separately. Clustering has previously been used directly for outlier detection, either performed in the space of items themselves (Campello et al., 2013), in the space of models (Cadez et al., 2000), or in the space of features (Liu et al., 2008). It groups data points together based on a notion of density, or connectivity. Outliers are data points that cannot be assigned to any cluster. However, these methods are oblivious to the modeling task, the goal is only to get clusters directly pointing to anomalies. At the same time in data mining and knowledge extraction from data, decomposition has been empirically shown to be beneficial for modeling unlabeled interesting features (Baxt, 1990;Buntine, 1996). Indeed, (Sharkey, 1999b) argues that the decomposition is mainly motivated by the performance improvement gained through a better bias-variance trade-off for the models.</p>
<p>Our paper considers decomposition in the space of items (i.e., sequences). In the literature (cf. Maimon &amp; Rokach, 2005) this is termed space decomposition or horizontal decomposition. Examples are mixture of experts (Nowlan &amp; Hinton, 1991), local linear regression (Draper &amp; Smith, 1981), or adaptive subspace models (Ramamurti &amp; Ghosh, 1999). Such decomposition is performed during training, while our approach is to cluster beforehand. Up to our knowledge, decomposition has not yet been used for novelty detection by modeling the data generating process. This proposed approach differs from previous methods, such as local modeling and ensembles, in that it decouples decomposition from modeling and thus is more likely to avoid overfitting. The approach is similar in spirit to the work of (Bergman &amp; Hoshen, 2019), where multiple transformations of a dataset are created and an outlier detection model is learned for each transformation, but aims at finding such subspaces within the initial space itself.</p>
<p>Note that the additional runtime due to decomposition is often negligible, since it is performed only once, while individual models in this case process less training data which can actually improve the runtime. Moreover, in some applications, lower-capacity models can be chosen as local models to further improve the runtime.</p>
<p>In this work, we choose high-capacity models for each cluster for which it might be an issue that decomposition leads to parts of the data having so few training examples that no meaningful model will be learned. Surprisingly, our empirical evaluation shows that for the task of novelty detection well-performing models can be trained even on very limited amounts of data, depending on the clustering method. We conjecture that in this case the decomposition through clustering indeed reduces the complexity of the learning task, and that for novelty detection slight overfitting on a local dataset is not as detrimental as in predictive modeling. Moreover, in many applications data is abundant so that local cluster size will not be an issue. For example, in cybersecurity (Faraoun &amp; Boukelif, 2006) note that the amount of data is constantly growing, e.g., log files of network monitoring systems are constantly updated.</p>
<p>It should be noted that for sequence modeling, where sequences are generated from different processes, a global model trained on the entire data may perform poorly, since it is difficult to identify these processes automatically (unless additional information, such as labels, is given) (Joshi et al., 2012). Similarly, automatic decomposition would be a challenging task. However, for human experts it is often easy to cluster data. Visual analytics provides a natural interface that allows to extract this implicit and intuitive knowledge of human experts (Liu et al., 2017).</p>
<p>Combining Clustering and Novelty Detection</p>
<p>We assume a dataset X of n ∈ N normal sequences s ∈ V * over a finite vocabulary V of words, i.e., s = (v 1 , . . . , v len(s) ) with v i ∈ V. We assume the sequences s are drawn iid. according to a distribution D over V * . For this distribution, we assume that it is a mixture of m ∈ N distributions D 1 , . . . , D m , where each D i corresponds to a different process generating the sequences. For example, each D i can represent different types of user behavior in the interaction with a web service, or different news topics. The task is to decide for a new sequence s ∈ V * , s ∈ X if it is an anomaly with respect to D, i.e., if it is a novelty.</p>
<p>A sequence clustering is a function C : V * → [k] that assigns each sequence to one of k ∈ N clusters. We assume clustering algorithms that take as input a dataset X and the parameter k and output a clustering C. We further assume that each data point has a unique cluster assigned to it-that is, the clustering is a partition of X into sets
G 1 , . . . , G k ⊆ X, i.e., k i=1 G i = X and for all i, j ∈ [k] it holds that G i ∩ G j = ∅.
Ideally, k = m and each cluster i corresponds to a distribution D i in the mixture.</p>
<p>Novelty detection on sequences is an unsupervised learning task. A powerful modelling technique for sequences are LSTM-based neural networks that model the process that generates the sequences. This, however, is a supervised task: given a prefix of a sequence the model h : V * → [0, 1] card(V) predicts the next element in a sequence by assigning each possible element from V a likelihood score. That is, given the prefix
p i = (v 1 , . . . , v i ) of a sequence s = (v 1 , . . . , v len(s) ) ∈ V * , where i ∈ [len(s)], the model outputs the likelihoods h(p i ) ∈ [0, 1] card(V) .
The predicted next element is the one with the highest likelihood. The true label for training is a vector with a likelihood of 1 assigned to the correct element at that place and 0 to all other elements. Note that an LSTM can predict further elements j &gt; i + 1 in the sequence, but we do not make use of this, here. After training on a given set of normal sequences, we can use such a process model for novelty detection: instead of using the predicted elements, we compute for each prefix p i the probability the model h assigns to the actual element v i+1 in s, i.e., h(p i ) vi+1 . If one or multiple elements in a sequence are predicted to be very unlikely given their prefix, then these elements are unusual given the modeled distribution. We combine the individual probabilities into a novelty score using the perplexity score (Jurafsky, 2000) P P (h, s) := len(s)
len(s) i=1 1 h(p i ) vi+1(1)
where len(s) is the number of words in a sequence and h(p i ) vi+1 is the predicted likelihood of v i+1 , the (i + 1)th element in s. The larger the perplexity score, the less probable it is that the sequence has originated from the same distribution that the model was trained on. Thus, a high perplexity score indicates novelty.</p>
<p>Algorithm 1 Novelty Detection via Per-Cluster Modelling</p>
<p>Input dataset X ⊂ V * , threshold θ ∈ R, sequence s ∈ V * Output {0, 1} (0 for a normal sequence, 1 for a novelty) 1: Training: 2: obtain clustering C with k clusters of X 3: for G i = {s ∈ X | C(s) = i} with i = 1, . . . , k do 4:</p>
<p>train process model h i on G i 5: end for 6: Inference: 7: compute cluster C(s ) of s 8: if P P (h C(s ) , s ) &gt; θ then Modelling on a sample X from D requires the model to generalize over all m distributions D i in the mixture which can result in lower sensitivity to small deviations. Ideally, we want to train an individual model for each D i . Since the actual mixture is typically unknown, we use the clustering as an approximation. The proposed approach, given in Algorithm 1, first using a clustering algorithm on the input data X to obtain a clustering C. The optimal number of clusters k can be determined via the standard silhouette value (Rousseeuw, 1987). Then, a model h i is trained for each cluster i. The novelty score of a sequence s is obtained by first assigning s to a cluster C(s ) and then computing P P (h C(s ) , s ). If P P (h C(s ) , s ) &gt; θ, s is reported as novelty.</p>
<p>As described above, this approach follows the intuition that a model trained for each individual distribution D i in the mixture is more precise for that distribution, such that novelties will be detected more accurately. Given a good clustering, i.e., one for which clusters correspond to distributions in the mixture, the novelty detection capabilities of the models should improve over a model trained on the entire mixture. At the same time, the clustering reduces the effective training set size for the individual models, in turn reducing their capabilities. In Section 5 we show empirically on a variety of different applications that the advantage of per-cluster modelling substantially outweighs the reduction in training set size. Since the success of this approach highly depends on the quality of clustering, we propose to use a visual analytics based approach for human experts to inform an LDA-based clustering in the following section.</p>
<p>Visual Informed Clustering</p>
<p>To obtain a good decomposition of sequences, the input data has to be clustered in a meaningful way. Techniques like k-means or topic modeling with LDA are able to cluster sequences, but often fail to find application-domain specific partitions and to be meaningful for high-dimensional data. Experts often have domain knowledge that can improve clustering, but it is non-trivial to extract this knowledge. We adapt a visual analytics tool that is proven to enable domain experts to cluster data in an intuitive and comfortable way (Chen et al., 2019). With this tool, semantically meaningful informed clusters can be defined without setting any parameters a priori. The interactive visual analytics tool was introduced by (Chen et al., 2019) for behavior clustering. It was thoroughly evaluated in case studies with security management system and amusement park visiting behaviors. The domain expert's feedback confirmed the usefulness and efficiency of the visual approach for identifying meaningful groups of behaviors. Based on this positive evaluation, we incorporate the tool into the novelty detection framework and extend it with an inference technique for identifying the cluster of a new sequence based on the analysis performed by experts. The tool performs multiple topic modeling runs on the normal data X = {s 1 , . . . , s n }. For that, each of the sequences is transformed into a bag of words: each sequence s is represented by a vector b ∈ N card(V) , where b i is the count of word w i ∈ V in s. In the following we refer to any kind of discrete objects organized into sequences as words (for consistensy with NLP terminology). Then, multiple rounds of LDA (Blei et al., 2003), each with a different setting of the number of topics, are used to produce a set of topics T = {t 1 , ..., t card(T ) }. From that we produce an initial visualization based on a topic-word matrix (i.e., probabilities corresponding to each of the words in V for each of the topics in T ), and a sequence-topic matrix (i.e., probabilities corresponding to each of the topics in T according to the corresponding LDA model for each of the sequences from X).</p>
<p>On startup, the interface displays the initial visualization based on the topic-word and sequence-topic matrix obtained from the multiple runs of LDA. The tool projects the generated topics (as vectors of word probabilities) on 2D space using t-SNE (Maaten &amp; Hinton, 2008) in order to provide an overview of their distribution and similarities (Fig. 3,  top part). A pie chart glyph represents each of the topics. The colors in the glyph encode the word classes labeled by the experts which allows for more coarse coloring of the topics compared to the word level. By investigating and comparing the glyphs, experts can gain an interpretable information about the topics and assess their similarity. This part of the interface provides an overview that allow experts to investigate different granularities of the clustering, e.g., a small number of topics will lead to more general feature clusters, while a large number of topics helps to obtain a finer clustering. This interface also serves as an interactive panel in which experts can unite similar topics and by this compose informed clusters. The topic-word matrix is also displayed in the interface by means of a matrix visualization. The goal of the view is to enable an understanding of the topic features in terms of the word probabilities. A chord diagram visualizes the similarity between topics according to the sequence-topic matrix (Fig. 3, bottom part). The separate parts of the circle represent topics, and their sizes indicate the number of associated sequences. The color encodes the word class that has the highest probability in the topic. Interconnections between them represent shared associated sequences.</p>
<p>Using the interactive interface human experts select a group of topics. The identified topic groups correspond to a partition of the data X and are considered to be informed clusters. As a result of the visual analysis, we obtain k ∈ N clusters composed of topics T . We propose the following method to perform inference of the cluster for a new sequence s: (i) produce probabilities for each of the topics in T for s (ii) identify the cluster of topics that has the largest average probability. Applying this scheme, we obtain a clustering C that partitions the initial data into G i ⊆ X and allows us to infer the cluster C(s) of a novel sequence s. Due to the visual interface the clusters can be identified even by non-experts just visually and it does not require any effort, while still giving a benefit of easy sequences separation. We empirically verify the performance of informed clustering in the following section.</p>
<p>Empirical Evaluation</p>
<p>We evaluate the proposed novelty detection framework on three real-world datasets with diverse areas of application: cybersecurity, fake reviews, and server usage monitoring 2 . We show that per-cluster modeling is beneficial when compared to modelling an LSTM on all data (Global LSTM) and that informed clustering (IC-LSTMs) outperforms automatic clustering. Since the informed clustering is based on LDA, we use standard LDA as a baseline (LDA Cluster LSTMs), as well as standard k-means (k-means Cluster LSTMs). Note that for the cybersecurity dataset the informed clusters are produced by domain experts, while for the other two use cases clusters were produced by data scientists from our group. The LSTMs per cluster are trained with parameters obtained via a parameter evaluation on an independent subset of the data. Furthermore, we compare per-cluster modelling to the natural baseline of using a clustering for outlier detection, in particualr the standard kNN with Minkowski distance and density-based clustering (HDBSCAN (McInnes et al., 2017)). We also compare to the standard outlier detection approaches one-class SVM (OC-SVM) (Schölkopf et al., 2001), and isolation forests (IsoForests) (Liu et al., 2008). HDBSCAN, OC-SVM, and IsoForests are designed for tabular data and not sequences. Thus, we use the two common approaches for obtaining such features from sequences, the bag of words (BoW) approach, and using the top-800 sequence patters (SP) (obtained using the prefixspan algorithm (Han et al., 2001)), as well as the combination of both (BoW+SP). Hyper-parameter of HDB-SCAN (min. cluster size, min. samples amount), OC-SVM (γ and ν for RBF kernel), and isolation forests (max. number of features, number of estimators, and max. number of samples) are optimized on the test set (see published code for details), so that their results can be optimistic. We report ROC AUC computed over all choices of the threshold θ, and the sensitivity (Sens.) and specificity (Spec.) scores for the optimal value of θ in ROC space. We report mean of Sens. and Spec., i.e., a score that gives equal importance to both.</p>
<p>Cybersecurity</p>
<p>We first evaluate the proposed approach on a network intrusion detection task. We use the public ADFA-LD (Creech &amp; Hu, 2013) dataset. This dataset is considered to be the state-of-the-art benchmarking collection for evaluating intrusion detection approaches. The sequences of actions are logged from system calls in the Ubuntu Linux operating system. The normal behavior sequences are logged from usual activity, e.g., browsing through web pages or document editing. Attack sessions are generated according to 2 The code is available at github.  Table 1: Results for Cybersecurity Data known vulnerabilities of the system, e.g., brute force of user passwords. This application from cybersecurity is quite challenging, because attackers that want to infiltrate a network try to disguise their attacks as normal behavior (Sommer &amp; Paxson, 2010). Thus, accurately modeling normal behavior is crucial. Behavioral patterns were shown to provide important insights into the possibilities of attacks (Ussath et al., 2017;Pannell &amp; Ashman, 2010). In this task, sequences are sessions of users accessing a system consisting of actions that they perform while being in this session.</p>
<p>Using the visual analytics tool, we partition historical logs of activities into semantically sound behavior clusters. We obtained the clustering for our experiments in collaboration with security operators from an industrial partner. Table 1 shows the baseline results for the dataset. We report AUC for all the baselines together with mixture of sensitivity and specificity, as discussed in the introduction to the section. According to these two criteria our approach outperforms all the baselines. The ROC curve for all methods is shown in Figures 4 and 5. Our approach substantially outperforms baseline anomaly detection approaches, as well as a global model trained on all data. Moreover, the informed clustering performs better than automatic clustering using k-means or LDA. Thus, we conclude that LSTM-based methods are a suitable technique for this task and clustering before modeling is beneficial. Figure 6 (left) shows the comparison of area under the ROC curve (AUC) per cluster compared to the AUC of the global model on that cluster. Interestingly, the size of the cluster seems not to impact the outliers detection performance of the model. Rather, the performance of both local and global model are correlated over clusters. This suggests that the lower amount of training data has only little impact on the performance, whereas the quality of decomposition has a stronger effect.     The second task is identifying fake reviews. The dataset we use is collected from Yelp (Mukherjee et al., 2013). The data includes reviews of hotels and restaurants in the Chicago area. Reviews include meta-information, as well as the text of the review itself, but for our experiments we use only the text. The labels are produced by a filtering algorithm that is used by Yelp. The labels are not perfect, but are proven to be sufficiently accurate (Weise, 2011). There are 13.23% reviews evaluated as fake in this dataset. The texts were preprocessed using spacy (https://spacy.io/), i.e., lemmatized and having pronouns, punctuation and numbers replaced with uniform tokens. The overall vocabulary was cut to the frequency threshold 40, meaning that all words that appear less than 40 times are treated as unknown words. The amount of data was reduced for experiments in order to save preprocessing time, i.e., we use 10% of the 50000 restaurant reviews.</p>
<p>The results in Table 2 show an advantage of our approach, but not as pronounced as in the other tasks. It nevertheless outperforms all baselines, except for LDA Cluster LSTMs. Since the informed clustering uses LDA topics as well and LDA clustering is very successful in natural language processing, this is not surprising. The k-means clustering LSTMs performs worse-even worse than the global LSTM-which is a further evidence that the clustering has to be chosen carefully. Note that we have used the same one layered LSTM architecture with embeddings learned together with the task as in the other experiments. Thus, the results of the LSTM-based methods could be further improved by tuning the architecture. Also note that the kNN applied on this data has a best AUC score lower than 0.5, so the labels have been inverted (i.e., we treat the model as an oracle that is always mistaken). The per cluster evaluation in Figure 6 (right) shows that the proposed approach substantially outperforms the global LSTM on all clusters. This supports the idea that especially in vast and various data, a global model will become too general to notice the subtle deviations of novelties.</p>
<p>Time Series</p>
<p>The third task is detecting novelties in real-valued time series. Since our approach is designed for discrete sequences, we need to discretize the time series by binning, and then cut them into non-overlapping windows. Each window that contains a time point marked as an anomaly is labeled as a novelty. All others are considered to be normal. As an example of univariate real-valued time series we select data from the Numenta Anomaly Benchmark (NAB) (Lavin &amp; Ahmad, 2015). NAB is a benchmark for evaluating algorithms for anomaly detection in streaming, real-time applications. It is composed of over 50 labeled real-world and artificial time series data files plus a novel scoring mechanism designed for real-time applications. We considered the dataset of the AWS server metrics as collected by the AmazonCloudwatch service, in particular CPU Utilization numbers. Since the range of values in the sequences was from 0.062 to 99.898 we binned them uniformly into 1000 bins from 0 to 100 with step 0.1. The length of the window was chosen to be 40 in order to have enough sequences in the training set.</p>
<p>The results are displayed in Table 3. Note that taking into account the simplicity of the task (because of the rather short sequences) all the LSTM based methods perform similarly. Also, due to having only 13 anomalies to test on, the scores are very erratic-differing in 1 example can change the AUC a lot. However, due to the small size, this dataset was the only one for which we can run kNN with the longest common sub-sequence (LCS) metric. The results obtained with it are 0.94 AUC, sensitivity 0.85 and specificity is 0.60, but the hyper-parameter tuning alone took almost 120 hours. As with all non-LSTM baselines, tuning was performed with test data, so it is optimistic. Again, the proposed IC-LSTM substantially outperforms all baselines; in general, LSTMbased approaches outperform the other baselines. Only kNN with Minkowski distance achieve competitive results. Note that the per-cluster comparison here is restricted to two clusters-the AUC of the last cluster could not be calculated, since it does not contain any novelties. These two clusters of size 322 and 137 have AUC 0.97 and 1.0 with our approach and 0.97 and 0.94 for the global LSTM model, indicating that the proposed approach is applicable to real-valued time series as well.</p>
<p>Conclusion</p>
<p>The paper proposes a framework for novelty detection in discrete sequences combining decomposition and modeling. The empirical evaluation shows that decomposition improves the novelty detection accuracy substantially and that an informed clustering outperforms automatic ones on three different real-world datasets. Surprisingly, the models performed well even on smaller clusters where only little training data is available. A reason could be that slight overfitting due to a lack of training data is actually beneficial for novelty detection. Further studying the trade-off between decomposition and training set size is an interesting future task. In our experiments, domain experts were involved for  the analysis of cybersecurity data, the reviews and server usage data was clustered by data scientists from our group. This is possible, since the visual interface is intuitive enough to perform meaningful clustering even without substantial domain knowledge. The strong performance of IC-LSTMs on the cybersecurity dataset indicates that using actual domain experts for clustering is still preferable.</p>
<p>The proposed framework is designed for novelty detection in discrete sequences. The flexible framework allows us to use a wide range of clustering and modelling techniques.</p>
<p>In this paper, we restricted ourselves to LSTMs with the same architecture and parameters on all clusters, since they are well-suited for sequential data. An interesting future direction is to choose models for each cluster individually by tuning the models for an optimal bias-variance trade-off.</p>
<p>In this paper we assign a new sequence strictly to the closest cluster and use only the corresponding model for novelty detection. This approach could be improved by combining the predictions of multiple models. For most clustering techniques, including the informed clustering proposed in this paper, it is possible to infer a score for a new sequence that indicates the similarity to each cluster. This similarity score could be used to weigh the predictions of cluster models which might further improve the novelty detection accuracy. (Sharkey, 1999a) shows that the combination of models trained on decomposed subtasks can be beneficial, but the way to combine predictions has to be selected carefully: opposed to ensemble techniques, the models might perform very poorly on other clusters and thus a simple averaging of predictions can be detrimental. Developing such combinations for our tasks is left for future work. Overall, we conjecture, that decomposition before modeling is beneficial for novelty detection in discrete sequences, on the condition that the clustering is of high quality and that often this can best be achieved with a knowledgeable human in the loop.</p>
<p>Warrender, C., Forrest, S., and Pearlmutter, B. Detecting intrusions using system calls: Alternative data models. </p>
<p>AI&amp;HCI
Workshop at the 40 th International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023. Copyright 2023 by the author(s).</p>
<p>Figure 1 .
1Schematic illustration of the training phase.</p>
<p>Figure 2 .
2Schematic illustration of the inference phase.</p>
<p>Figure 3 .
3Partial exemplary view of the visual interface for the domain experts for understanding the distribution of data, creating and exploring properties of clusters. The topics with highlighted strokes are the medians of the informed clusters. In this case, 3 clusters were created (leftover examples in gray glyph).</p>
<p>Figure 4 .
4K-means, LDA and informed clustering (using LSTMs).</p>
<p>Figure 5 .
5Anomaly detection baselines compared to the proposed approach.</p>
<p>Figure 6 .
6AUC per Cluster</p>
<p>Table 2 :
2Results for Fake Reviews Data</p>
<p>MethodAUC Sens.+Spec.2 </p>
<p>Sens. Spec. 
IC-LSTMs 
0.99 
0.87 
0.77 0.97 
Global LSTM 
0.96 
0.86 
0.77 0.94 
k-means Cluster LSTMs 0.97 
0.84 
0.85 0.82 
LDA Cluster LSTMs 
0.98 
0.87 
0.77 0.97 
kNN with Mink. dist. 
0.97 
0.76 
1.00 0.51 
HDBSCAN on BoW 
0.78 
0.66 
0.31 1.00 
HDBSCAN on SP 
0.51 
0.31 
0.23 0.39 
HDBSCAN on BoW+SP 0.52 
0.32 
0.23 0.41 
OC-SVM on BoW 
0.85 
0.4 
0.08 0.72 
OC-SVM on SP 
0.79 
0.5 
1.00 0.00 
OC-SVM on BoW+SP 
0.79 
0.5 
1.00 0.00 
IsoForests on BoW 
0.55 
0.5 
0.00 1.00 
IsoForests on SP 
0.76 
0.25 
0.00 0.49 
IsoForests on BoW+SP 0.76 
0.27 
0.08 0.46 </p>
<p>Table 3 :
3Results for Time series Data</p>
<p>In Proceedings of the 1999 IEEE symposium on security and privacy, pp. 133-145. IEEE, 1999. 1 Weise, K. A lie detector test for online reviewers. Bloomberg Business Week, 2011. 7 Yuan, G., Li, B., Yao, Y., and Zhang, S. A deep learning enabled subspace spectral ensemble clustering approach for web anomaly detection. In 2017 International Joint Conference on Neural Networks (IJCNN), pp. 3896-3903. IEEE, 2017. 2 Zhang, C. et al. A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pp. 1409-1416, 2019. 2
Labels have been inverted.
A. Algorithm of the Framework Algorithm 2 Training phase Result: Set of informed clusters; LSTM for each of the clusters create input for the visual analytics tool present experts the interface for work download the set of informed clusters identify hyperparameters for LSTM on an independent subset for clusters in the set of informed clusters do train an LSTM end for Algorithm 3 Inference phase Result: Novelty score get new sequence s infer informed cluster most probable for s calculate perplexity score from the model corresponding to it
Use of an artificial neural network for data analysis in clinical decision-making: the diagnosis of acute coronary occlusion. W G Baxt, Neural computation. 24Baxt, W. G. Use of an artificial neural network for data analysis in clinical decision-making: the diagnosis of acute coronary occlusion. Neural computation, 2(4):480- 489, 1990. 3</p>
<p>Classification-based anomaly detection for general data. L Bergman, Y Hoshen, International Conference on Learning Representations. Bergman, L. and Hoshen, Y. Classification-based anomaly detection for general data. In International Conference on Learning Representations, 2019. 3</p>
<p>Latent dirichlet allocation. D M Blei, A Y Ng, Jordan , M I , Journal of machine Learning research. 35Blei, D. M., Ng, A. Y., and Jordan, M. I. Latent dirichlet allocation. Journal of machine Learning research, 3(Jan): 993-1022, 2003. 5</p>
<p>Anomaly detection in large sets of high-dimensional symbol sequences. S Budalakoti, A N Srivastava, R Akella, E Turkov, NASA TM-2006-214553. NASA Ames Research CenterTechnical reportBudalakoti, S., Srivastava, A. N., Akella, R., and Turkov, E. Anomaly detection in large sets of high-dimensional symbol sequences. Technical report, NASA TM-2006- 214553, NASA Ames Research Center, 2006. 1</p>
<p>Graphical models for discovering knowledge. W Buntine, Advances in knowledge discovery and data mining. AAAI/MIT PressBuntine, W. Graphical models for discovering knowledge. In Advances in knowledge discovery and data mining, pp. 59-82. AAAI/MIT Press, 1996. 3</p>
<p>Visualization of navigation patterns on a web site using model-based clustering. I Cadez, Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining. the sixth ACM SIGKDD international conference on Knowledge discovery and data mining23Cadez, I. et al. Visualization of navigation patterns on a web site using model-based clustering. In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 280-284, 2000. 2, 3</p>
<p>Densitybased clustering based on hierarchical density estimates. R J Campello, D Moulavi, J Sander, Pacific-Asia conference on knowledge discovery and data mining. SpringerCampello, R. J., Moulavi, D., and Sander, J. Density- based clustering based on hierarchical density estimates. In Pacific-Asia conference on knowledge discovery and data mining, pp. 160-172. Springer, 2013. 3</p>
<p>Deep learning for anomaly detection: A survey. R Chalapathy, S Chawla, arXiv:1901.034071arXiv preprintChalapathy, R. and Chawla, S. Deep learning for anomaly detection: A survey. arXiv preprint arXiv:1901.03407, 2019. 1, 2</p>
<p>Comparative evaluation of anomaly detection techniques for sequence data. V Chandola, V Mithal, V Kumar, Eighth IEEE international conference on data mining. IEEE1Chandola, V., Mithal, V., and Kumar, V. Comparative evalu- ation of anomaly detection techniques for sequence data. In 2008 Eighth IEEE international conference on data mining, pp. 743-748. IEEE, 2008. 1, 2</p>
<p>Anomaly detection: A survey. V Chandola, A Banerjee, V Kumar, ACM computing surveys (CSUR). 413Chandola, V., Banerjee, A., and Kumar, V. Anomaly detec- tion: A survey. ACM computing surveys (CSUR), 41(3): 1-58, 2009. 1</p>
<p>Anomaly detection for discrete sequences: A survey. V Chandola, A Banerjee, V Kumar, IEEE Transactions on Knowledge and Data Engineering. 245Chandola, V., Banerjee, A., and Kumar, V. Anomaly detec- tion for discrete sequences: A survey. IEEE Transactions on Knowledge and Data Engineering, 24(5):823-839, 2010. 2</p>
<p>Lda ensembles for interactive exploration and categorization of behaviors. S Chen, N Andrienko, G Andrienko, L Adilova, J Barlet, J Kindermann, P H Nguyen, O Thonnard, C Turkay, IEEE transactions on visualization and computer graphics. 25Chen, S., Andrienko, N., Andrienko, G., Adilova, L., Barlet, J., Kindermann, J., Nguyen, P. H., Thonnard, O., and Turkay, C. Lda ensembles for interactive exploration and categorization of behaviors. IEEE transactions on visualization and computer graphics, 2019. 2, 5</p>
<p>Scalable auto-encoders for gravitational waves detection from time series data. R Corizzo, M Ceci, E Zdravevski, Japkowicz , N , Expert Systems with Applications. 2113378Corizzo, R., Ceci, M., Zdravevski, E., and Japkowicz, N. Scalable auto-encoders for gravitational waves detection from time series data. Expert Systems with Applications, pp. 113378, 2020. 2</p>
<p>Generation of a new ids test dataset: Time to retire the kdd collection. G Creech, J Hu, 2013 IEEE Wireless Communications and Networking Conference (WCNC). IEEECreech, G. and Hu, J. Generation of a new ids test dataset: Time to retire the kdd collection. In 2013 IEEE Wireless Communications and Networking Conference (WCNC), pp. 4487-4492. IEEE, 2013. 6</p>
<p>A comparative evaluation of novelty detection algorithms for discrete sequences. R Domingues, P Michiardi, J Barlet, M Filippone, Artificial Intelligence Review. 2Domingues, R., Michiardi, P., Barlet, J., and Filippone, M. A comparative evaluation of novelty detection algorithms for discrete sequences. Artificial Intelligence Review, pp. 1-26, 2019. 2</p>
<p>Sequence data mining. G Dong, J Pei, Springer Science &amp; Business Media33Dong, G. and Pei, J. Sequence data mining, volume 33. Springer Science &amp; Business Media, 2007. 2</p>
<p>Applied regression analysis, john wiley and sons. N R Draper, H Smith, 407New YorkDraper, N. R. and Smith, H. Applied regression analysis, john wiley and sons. New York, 407, 1981. 3</p>
<p>Neural networks learning improvement using the k-means clustering algorithm to detect network intrusions. K Faraoun, A Boukelif, INFOCOMP. 53Faraoun, K. and Boukelif, A. Neural networks learning im- provement using the k-means clustering algorithm to de- tect network intrusions. INFOCOMP, 5(3):28-36, 2006. 3</p>
<p>Pattern-based anomaly detection in mixedtype time series. L Feremans, V Vercruyssen, B Cule, W Meert, B Goethals, Lecture Notes in Artificial Intelligence. 1Feremans, L., Vercruyssen, V., Cule, B., Meert, W., and Goethals, B. Pattern-based anomaly detection in mixed- type time series. Lecture Notes in Artificial Intelligence, 2019. 1</p>
<p>Efficient modeling of discrete events for anomaly detection using hidden markov models. G Florez-Larrahondo, International Conference on Information Security. SpringerFlorez-Larrahondo, G. et al. Efficient modeling of discrete events for anomaly detection using hidden markov mod- els. In International Conference on Information Security, pp. 506-514. Springer, 2005. 1</p>
<p>Mining sequential patterns efficiently by prefix-projected pattern growth. J Han, J Pei, B Mortazavi-Asl, H Pinto, Q Chen, U Dayal, M Hsu, Prefixspan, proceedings of the 17th international conference on data engineering. the 17th international conference on data engineeringCiteseerHan, J., Pei, J., Mortazavi-Asl, B., Pinto, H., Chen, Q., Dayal, U., and Hsu, M. Prefixspan: Mining sequential patterns efficiently by prefix-projected pattern growth. In proceedings of the 17th international conference on data engineering, pp. 215-224. Citeseer, 2001. 6</p>
<p>Long short-term memory. S Hochreiter, J Schmidhuber, 0899-7667. 2Neural Comput. 98Hochreiter, S. and Schmidhuber, J. Long short-term memory. Neural Comput., 9(8):1735-1780, November 1997. ISSN 0899-7667. 2</p>
<p>Anomaly detection for visual analytics of power consumption data. H Janetzko, F Stoffel, S Mittelstädt, D A Keim, Computers &amp; Graphics. 382Janetzko, H., Stoffel, F., Mittelstädt, S., and Keim, D. A. Anomaly detection for visual analytics of power con- sumption data. Computers &amp; Graphics, 38:27-37, 2014. 2</p>
<p>Multi-domain learning: when do domains matter. M Joshi, W W Cohen, M Dredze, C P Rosé, Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics23Joshi, M., Cohen, W. W., Dredze, M., and Rosé, C. P. Multi-domain learning: when do domains mat- ter? In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 1302-1312. Association for Computational Linguistics, 2012. 2, 3</p>
<p>Speech &amp; language processing. D Jurafsky, Pearson Education India. 24Jurafsky, D. Speech &amp; language processing. Pearson Edu- cation India, 2000. 2, 4</p>
<p>Lstm-based system-call language modeling and robust ensemble method for designing hostbased intrusion detection systems. G Kim, arXiv:1611.01726arXiv preprintKim, G. et al. Lstm-based system-call language mod- eling and robust ensemble method for designing host- based intrusion detection systems. arXiv preprint arXiv:1611.01726, 2016. 3</p>
<p>Evaluating real-time anomaly detection algorithms-the numenta anomaly benchmark. A Lavin, S Ahmad, IEEE 14th International Conference on Machine Learning and Applications. IEEELavin, A. and Ahmad, S. Evaluating real-time anomaly detection algorithms-the numenta anomaly benchmark. In 2015 IEEE 14th International Conference on Machine Learning and Applications, pp. 38-44. IEEE, 2015. 8</p>
<p>Visual analytics for event detection: Focusing on fraud. R A Leite, T Gschwandtner, S Miksch, E Gstrein, J Kuntner, Visual Informatics. 2Leite, R. A., Gschwandtner, T., Miksch, S., Gstrein, E., and Kuntner, J. Visual analytics for event detection: Focusing on fraud. Visual Informatics, 2(4):198-212, 2018. 2</p>
<p>Isolation forest. F T Liu, K M Ting, Z.-H Zhou, Eighth IEEE International Conference on Data Mining. IEEE36Liu, F. T., Ting, K. M., and Zhou, Z.-H. Isolation forest. In 2008 Eighth IEEE International Conference on Data Mining, pp. 413-422. IEEE, 2008. 3, 6</p>
<p>Towards better analysis of machine learning models: A visual analytics perspective. S Liu, Visual Informatics. 11Liu, S. et al. Towards better analysis of machine learn- ing models: A visual analytics perspective. Visual Informatics, 1(1):48-56, 2017. 3</p>
<p>Visualizing data using t-sne. L V Maaten, G Hinton, Journal of Machine Learning Research. 95Maaten, L. v. d. and Hinton, G. Visualizing data using t-sne. Journal of Machine Learning Research, 9:2579- 2605, 2008. 5</p>
<p>Decomposition methodology for knowledge discovery and data mining. O Maimon, L Rokach, Data mining and knowledge discovery handbook. SpringerMaimon, O. and Rokach, L. Decomposition methodol- ogy for knowledge discovery and data mining. In Data mining and knowledge discovery handbook, pp. 981- 1003. Springer, 2005. 3</p>
<p>A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional lstm neural networks. E Marchi, F Vesperini, F Eyben, S Squartini, B Schuller, 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEEMarchi, E., Vesperini, F., Eyben, F., Squartini, S., and Schuller, B. A novel approach for automatic acoustic nov- elty detection using a denoising autoencoder with bidirec- tional lstm neural networks. In 2015 IEEE international conference on acoustics, speech and signal processing (ICASSP), pp. 1996-2000. IEEE, 2015. 1</p>
<p>Hierarchical density based clustering. L Mcinnes, J Healy, S Astels, Hdbscan, The Journal of Open Source Software. 211205McInnes, L., Healy, J., and Astels, S. hdbscan: Hierarchical density based clustering. The Journal of Open Source Software, 2(11):205, 2017. 6</p>
<p>What yelp fake review filter might be doing?. A Mukherjee, V Venkataraman, B Liu, N Glance, Seventh international AAAI conference on weblogs and social media. Mukherjee, A., Venkataraman, V., Liu, B., and Glance, N. What yelp fake review filter might be doing? In Seventh international AAAI conference on weblogs and social media, 2013. 7</p>
<p>Evaluation of adaptive mixtures of competing experts. S Nowlan, G Hinton, Advances in neural information processing systems. 13Nowlan, S. and Hinton, G. Evaluation of adaptive mixtures of competing experts. In Advances in neural information processing systems, pp. 774-780, 1991. 1, 3</p>
<p>User modelling for exclusion and anomaly detection: a behavioural intrusion detection system. G Pannell, H Ashman, International Conference on User Modeling, Adaptation, and Personalization. SpringerPannell, G. and Ashman, H. User modelling for exclusion and anomaly detection: a behavioural intrusion detection system. In International Conference on User Modeling, Adaptation, and Personalization, pp. 207-218. Springer, 2010. 6</p>
<p>Sequence modeling with mixtures of conditional maximum entropy distributions. D Pavlov, International Conference on Data Mining. Pavlov, D. Sequence modeling with mixtures of condi- tional maximum entropy distributions. In International Conference on Data Mining, pp. 251-258. IEEE, 2003. 2</p>
<p>Structurally adaptive modular networks for nonstationary environments. V Ramamurti, J Ghosh, IEEE Transactions on Neural Networks. 101Ramamurti, V. and Ghosh, J. Structurally adaptive mod- ular networks for nonstationary environments. IEEE Transactions on Neural Networks, 10(1):152-160, 1999. 3</p>
<p>Time-series anomaly detection service at microsoft. H Ren, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data miningRen, H. et al. Time-series anomaly detection service at microsoft. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining, pp. 3009-3017, 2019. 2</p>
<p>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. P J Rousseeuw, Journal of computational and applied mathematics. 204Rousseeuw, P. J. Silhouettes: a graphical aid to the inter- pretation and validation of cluster analysis. Journal of computational and applied mathematics, 20:53-65, 1987. 4</p>
<p>Estimating the support of a highdimensional distribution. B Schölkopf, J C Platt, J Shawe-Taylor, A J Smola, R C Williamson, Neural computation. 137Schölkopf, B., Platt, J. C., Shawe-Taylor, J., Smola, A. J., and Williamson, R. C. Estimating the support of a high- dimensional distribution. Neural computation, 13(7): 1443-1471, 2001. 6</p>
<p>Linear and order statistics combiners for pattern classification. A J Sharkey, Combining artificial neural nets. Springer1Sharkey, A. J. Linear and order statistics combiners for pattern classification. In Combining artificial neural nets, pp. 127-161. Springer, 1999a. 1, 8</p>
<p>Multi-net systems. A J Sharkey, Combining artificial neural nets. SpringerSharkey, A. J. Multi-net systems. In Combining artificial neural nets, pp. 1-30. Springer, 1999b. 3</p>
<p>Visual analytics of anomalous user behaviors: A survey. Y Shi, Y Liu, H Tong, J He, G Yan, N Cao, IEEE Transactions on Big Data. 2Shi, Y., Liu, Y., Tong, H., He, J., Yan, G., and Cao, N. Visual analytics of anomalous user behaviors: A survey. IEEE Transactions on Big Data, 2020. 2</p>
<p>Outside the closed world: On using machine learning for network intrusion detection. R Sommer, V Paxson, 2010 IEEE symposium on security and privacy. IEEESommer, R. and Paxson, V. Outside the closed world: On using machine learning for network intrusion detection. In 2010 IEEE symposium on security and privacy, pp. 305-316. IEEE, 2010. 6</p>
<p>Robust anomaly detection for multivariate time series through stochastic recurrent neural network. Y Su, Y Zhao, C Niu, R Liu, W Sun, Pei , D , Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data miningSu, Y., Zhao, Y., Niu, C., Liu, R., Sun, W., and Pei, D. Robust anomaly detection for multivariate time se- ries through stochastic recurrent neural network. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining, pp. 2828-2837, 2019. 3</p>
<p>Recurrent neural network language models for open vocabulary event-level cyber anomaly detection. A R Tuor, R Baerwolf, N Knowles, B Hutchinson, N Nichols, Jasper , R , Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence. Tuor, A. R., Baerwolf, R., Knowles, N., Hutchinson, B., Nichols, N., and Jasper, R. Recurrent neural network language models for open vocabulary event-level cyber anomaly detection. In Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence, 2018. 3</p>
<p>Identifying suspicious user behavior with neural networks. M Ussath, D Jaeger, F Cheng, C Meinel, 2017 IEEE 4th International Conference on Cyber Security and Cloud Computing. IEEEUssath, M., Jaeger, D., Cheng, F., and Meinel, C. Identifying suspicious user behavior with neural networks. In 2017 IEEE 4th International Conference on Cyber Security and Cloud Computing, pp. 255-263. IEEE, 2017. 6</p>            </div>
        </div>

    </div>
</body>
</html>