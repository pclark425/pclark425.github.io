<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9337 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9337</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9337</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-69f6c8c0ffeab29bc0fd5f16e53cb9beff164113</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/69f6c8c0ffeab29bc0fd5f16e53cb9beff164113" target="_blank">STOUT: SMILES to IUPAC names using neural machine translation</a></p>
                <p><strong>Paper Venue:</strong> Journal of Cheminformatics</p>
                <p><strong>Paper TL;DR:</strong> This work presents STOUT, a deep-learning neural machine translation approach to generate the IUPAC name for a given molecule from its SMILES string as well as the reverse translation, i.e. predicting the SMilES string from the IupAC name.</p>
                <p><strong>Paper Abstract:</strong> Chemical compounds can be identified through a graphical depiction, a suitable string representation, or a chemical name. A universally accepted naming scheme for chemistry was established by the International Union of Pure and Applied Chemistry (IUPAC) based on a set of rules. Due to the complexity of this ruleset a correct chemical name assignment remains challenging for human beings and there are only a few rule-based cheminformatics toolkits available that support this task in an automated manner. Here we present STOUT ( S MILES- TO -I U PAC-name t ranslator), a deep-learning neural machine translation approach to generate the IUPAC name for a given molecule from its SMILES string as well as the reverse translation, i.e. predicting the SMILES string from the IUPAC name. In both cases, the system is able to predict with an average BLEU score of about 90% and a Tanimoto similarity index of more than 0.9. Also incorrect predictions show a remarkable similarity between true and predicted compounds.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9337.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9337.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STOUT NMT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>STOichiometry / SMILES-TO-IUPAC-name Translator (neural machine translation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GRU-based encoder–decoder neural machine translation model with soft attention that translates between molecular string representations (SELFIES/SMILES) and systematic IUPAC names; trained on tens of millions of molecule pairs and evaluated by string and structure similarity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>STOUT NMT (GRU encoder–decoder with attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent neural network (encoder–decoder) using Gated Recurrent Units (GRU) with a Luong/Bahdanau-style attention mechanism, implemented in TensorFlow 2.3. Trained on tokenized SELFIES ↔ IUPAC-name sentence pairs derived from Chemaxon molconvert output; datasets of 30,000,128 and 60,000,256 molecule examples were used. Training used batch sizes 256 (GPU) / global 1024 (TPU) and was accelerated on TPU V3-8 and V3-32 hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Cheminformatics / organic chemistry (chemical nomenclature and molecular representation translation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based simulation/translation of molecular representations: converting SELFIES (derived from SMILES) to IUPAC systematic chemical names and the reverse (IUPAC names to SELFIES/SMILES).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU scores (sentence BLEU, BLEU-1..BLEU-4) for string-level similarity; Tanimoto similarity (PubChem fingerprints) and counts of exact structural matches (Tanimoto = 1.0) for structure-level equivalence; OPSIN success rate used to determine whether predicted IUPAC names are valid (convertible back to SMILES).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>SELFIES→IUPAC: average BLEU 0.89 (30M) and 0.94 (60M); BLEU-1..4 also reported (see paper). Valid IUPAC-name fractions: 78.59% (30M) and 85.50% (60M). Average Tanimoto (measured on total test dataset): 0.75 (30M) and 0.83 (60M). Tanimoto 1.0 counts on total test dataset: 58.36% (30M) and 72.33% (60M). For IUPAC→SELFIES: average BLEU 0.90 (30M) and 0.94 (60M); average Tanimoto similarity index 0.89 (30M) and 0.94 (60M); Tanimoto 1.0 counts 52.27% (30M) and 73.26% (60M). The paper additionally reports that ~98% of Tanimoto 1.0 cases were full graph isomorphisms.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Training dataset size and coverage (models trained on 60M examples outperform 30M examples across BLEU and Tanimoto metrics).', 'Molecular string representation choice: SELFIES preferred over raw SMILES for tokenization robustness and model performance.', 'Token set complexity: IUPAC-name token vocabulary is much larger and more complex than SELFIES tokens, affecting model learning and training speed.', 'Quality of training labels (deterministic generator Chemaxon molconvert provided target IUPAC names) and downstream parser (OPSIN) validity checks influence measured structural accuracy (invalid predicted IUPAC names are excluded from Tanimoto calculations).', 'Model architecture and training regime: GRU-based encoder–decoder with attention; number of epochs and availability of TPU hardware (V3-8 / V3-32) affect ability to train to convergence.', 'Tokenization and splitting rules applied to IUPAC names (delimiters and vocabulary choices) influence learning and prediction quality.', 'Length and syntactic complexity of IUPAC names (very long names, repeating words) increase error rates.']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Deterministic rule-based IUPAC name generator (ChemAxon molconvert) was used to produce the ground-truth training labels; OPSIN (open parser) was used as a validation/comparison tool to check if predicted IUPAC names are syntactically valid and convertible to SMILES. The paper does not present a direct quantitative head-to-head comparison of STOUT vs molconvert as an alternative generator, but states deterministic tools remain the preferred practical baseline and STOUT aims to approach their performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Predicted IUPAC names occasionally invalid (rejected by OPSIN) due to missing commas, unmatched brackets, incorrect atom valences, uninterpretable text blocks, incorrect bond assignments, disagreements in bridge/alkyl chain lengths, or very long repetitive names. Discrepancies between string-level BLEU scores and structure-level Tanimoto scores occur (cases with low BLEU but Tanimoto = 1.0 and rare cases with BLEU = 1.0 but Tanimoto < 1.0). Large-scale uncurated application should be handled with care according to authors.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Increase training data coverage and perform additional training epochs to further improve accuracy; use TPU infrastructure to speed up training (enabling more epochs in practical time); prefer robust string representations like SELFIES for tokenization; consider more sophisticated language models (authors suggest extension to transformer-based models such as BERT or other modern NMT/transformer architectures) and ensure sufficient token coverage to improve results; and treat current STOUT predictions cautiously for large-scale uncurated use.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'STOUT: SMILES to IUPAC names using neural machine translation', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Struct2IUPAC transformer-based artificial neural network for the conversion between chemical notations <em>(Rating: 2)</em></li>
                <li>Translating the molecules: adapting neural machine translation to predict IUPAC names from a chemical identifier <em>(Rating: 2)</em></li>
                <li>DECIMER: towards deep learning for chemical image recognition <em>(Rating: 1)</em></li>
                <li>Chemical name to structure: OPSIN, an open source solution <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9337",
    "paper_id": "paper-69f6c8c0ffeab29bc0fd5f16e53cb9beff164113",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "STOUT NMT",
            "name_full": "STOichiometry / SMILES-TO-IUPAC-name Translator (neural machine translation)",
            "brief_description": "A GRU-based encoder–decoder neural machine translation model with soft attention that translates between molecular string representations (SELFIES/SMILES) and systematic IUPAC names; trained on tens of millions of molecule pairs and evaluated by string and structure similarity metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "STOUT NMT (GRU encoder–decoder with attention)",
            "model_description": "Recurrent neural network (encoder–decoder) using Gated Recurrent Units (GRU) with a Luong/Bahdanau-style attention mechanism, implemented in TensorFlow 2.3. Trained on tokenized SELFIES ↔ IUPAC-name sentence pairs derived from Chemaxon molconvert output; datasets of 30,000,128 and 60,000,256 molecule examples were used. Training used batch sizes 256 (GPU) / global 1024 (TPU) and was accelerated on TPU V3-8 and V3-32 hardware.",
            "scientific_subdomain": "Cheminformatics / organic chemistry (chemical nomenclature and molecular representation translation)",
            "simulation_task": "Text-based simulation/translation of molecular representations: converting SELFIES (derived from SMILES) to IUPAC systematic chemical names and the reverse (IUPAC names to SELFIES/SMILES).",
            "evaluation_metric": "BLEU scores (sentence BLEU, BLEU-1..BLEU-4) for string-level similarity; Tanimoto similarity (PubChem fingerprints) and counts of exact structural matches (Tanimoto = 1.0) for structure-level equivalence; OPSIN success rate used to determine whether predicted IUPAC names are valid (convertible back to SMILES).",
            "simulation_accuracy": "SELFIES→IUPAC: average BLEU 0.89 (30M) and 0.94 (60M); BLEU-1..4 also reported (see paper). Valid IUPAC-name fractions: 78.59% (30M) and 85.50% (60M). Average Tanimoto (measured on total test dataset): 0.75 (30M) and 0.83 (60M). Tanimoto 1.0 counts on total test dataset: 58.36% (30M) and 72.33% (60M). For IUPAC→SELFIES: average BLEU 0.90 (30M) and 0.94 (60M); average Tanimoto similarity index 0.89 (30M) and 0.94 (60M); Tanimoto 1.0 counts 52.27% (30M) and 73.26% (60M). The paper additionally reports that ~98% of Tanimoto 1.0 cases were full graph isomorphisms.",
            "factors_affecting_accuracy": [
                "Training dataset size and coverage (models trained on 60M examples outperform 30M examples across BLEU and Tanimoto metrics).",
                "Molecular string representation choice: SELFIES preferred over raw SMILES for tokenization robustness and model performance.",
                "Token set complexity: IUPAC-name token vocabulary is much larger and more complex than SELFIES tokens, affecting model learning and training speed.",
                "Quality of training labels (deterministic generator Chemaxon molconvert provided target IUPAC names) and downstream parser (OPSIN) validity checks influence measured structural accuracy (invalid predicted IUPAC names are excluded from Tanimoto calculations).",
                "Model architecture and training regime: GRU-based encoder–decoder with attention; number of epochs and availability of TPU hardware (V3-8 / V3-32) affect ability to train to convergence.",
                "Tokenization and splitting rules applied to IUPAC names (delimiters and vocabulary choices) influence learning and prediction quality.",
                "Length and syntactic complexity of IUPAC names (very long names, repeating words) increase error rates."
            ],
            "comparison_baseline": "Deterministic rule-based IUPAC name generator (ChemAxon molconvert) was used to produce the ground-truth training labels; OPSIN (open parser) was used as a validation/comparison tool to check if predicted IUPAC names are syntactically valid and convertible to SMILES. The paper does not present a direct quantitative head-to-head comparison of STOUT vs molconvert as an alternative generator, but states deterministic tools remain the preferred practical baseline and STOUT aims to approach their performance.",
            "limitations_or_failure_cases": "Predicted IUPAC names occasionally invalid (rejected by OPSIN) due to missing commas, unmatched brackets, incorrect atom valences, uninterpretable text blocks, incorrect bond assignments, disagreements in bridge/alkyl chain lengths, or very long repetitive names. Discrepancies between string-level BLEU scores and structure-level Tanimoto scores occur (cases with low BLEU but Tanimoto = 1.0 and rare cases with BLEU = 1.0 but Tanimoto &lt; 1.0). Large-scale uncurated application should be handled with care according to authors.",
            "author_recommendations_or_insights": "Increase training data coverage and perform additional training epochs to further improve accuracy; use TPU infrastructure to speed up training (enabling more epochs in practical time); prefer robust string representations like SELFIES for tokenization; consider more sophisticated language models (authors suggest extension to transformer-based models such as BERT or other modern NMT/transformer architectures) and ensure sufficient token coverage to improve results; and treat current STOUT predictions cautiously for large-scale uncurated use.",
            "uuid": "e9337.0",
            "source_info": {
                "paper_title": "STOUT: SMILES to IUPAC names using neural machine translation",
                "publication_date_yy_mm": "2020-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Struct2IUPAC transformer-based artificial neural network for the conversion between chemical notations",
            "rating": 2
        },
        {
            "paper_title": "Translating the molecules: adapting neural machine translation to predict IUPAC names from a chemical identifier",
            "rating": 2
        },
        {
            "paper_title": "DECIMER: towards deep learning for chemical image recognition",
            "rating": 1
        },
        {
            "paper_title": "Chemical name to structure: OPSIN, an open source solution",
            "rating": 1
        }
    ],
    "cost": 0.010117000000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>STOUT: SMILES to IUPAC names using neural machine translation</h1>
<p>Kohulan Rajan ${ }^{1}$, Achim Zielesny ${ }^{2}$ and Christoph Steinbeck ${ }^{1 *}$</p>
<h4>Abstract</h4>
<p>Chemical compounds can be identified through a graphical depiction, a suitable string representation, or a chemical name. A universally accepted naming scheme for chemistry was established by the International Union of Pure and Applied Chemistry (IUPAC) based on a set of rules. Due to the complexity of this ruleset a correct chemical name assignment remains challenging for human beings and there are only a few rule-based cheminformatics toolkits available that support this task in an automated manner. Here we present STOUT (SMILES-TO-IUPAC-name translator), a deep-learning neural machine translation approach to generate the IUPAC name for a given molecule from its SMILES string as well as the reverse translation, i.e. predicting the SMILES string from the IUPAC name. In both cases, the system is able to predict with an average BLEU score of about 90\% and a Tanimoto similarity index of more than 0.9. Also incorrect predictions show a remarkable similarity between true and predicted compounds.</p>
<p>Keywords: Neural machine translation, Chemical language, IUPAC names, SMILES, DeepSMILES, SELFIES, Deep neural network, Attention mechanism, Recurrent neural network</p>
<h2>Introduction</h2>
<p>Assigning names to chemical compounds so that an author can refer to them in the text of a scientific article, book or patent has a long history. In the early days and even still today, such names were often chosen based on physicochemical or perceptible properties, but also named after species, people, named after fictional characters, related to sex, bodily functions, death and decay, religion or legend, or other [1]. Usually, this makes it impossible to conclude from the name to the chemical structure of the compound. To overcome this dilemma, the International Union of Pure and Applied Chemistry (IUPAC) established a set of rules and guidelines for chemical nomenclature [2-5] so that a systematic name can be generated from the structure and substructures of a chemical compound and vice versa. Often, more than one systematic IUPAC name can be generated for the</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>same compound: Therefore, the IUPAC introduced the IUPAC preferred name in their current edition of the Blue Book, preferring one of the possible names over all others.</p>
<p>Other types of string representations of molecules, such as SMILES [6], InChI [7], SYBYL line notation [8], Wiswesser line notation [9], and SMARTS [10] are more concise forms of line representations. While in principle being human-readable, these representations are primarily designed to be understood by machines. Thus, they are not commonly used in text to denominate chemical compounds for recognition by human readers, but have been incorporated into many major open-source and proprietary cheminformatics toolkits.</p>
<p>IUPAC name generation, due to its algorithmic complexity and the large set of rules, is missing in many cheminformatics toolkits in general. For a human, IUPAC name generation for more than a handful of molecules is cumbersome. People, therefore, resort to the few available automatic tools for IUPAC name generation.</p>
<p>Among the available and reliable solutions are the "molconvert" software, a command-line program in</p>
<p>Marvin Suite 20.15 from ChemAxon (https://www. chemaxon.com) [11]. It is available for researchers under an academic license. Open-source programs such as the Chemistry Development Kit (CDK) [12], RDKit [13], or Open Babel [14] do not (yet) provide any algorithms that can automate the process of IUPAC naming for molecules.</p>
<p>With this work, we report a proof-of-concept application of Neural Machine Translation (NMT) for the conversion of machine-readable chemical line notations into IUPAC names and vice versa. A large training set was generated with ChemAxon's molconvert software and we would like to emphasise that this work would not have been possible without the generous offer by ChemAxon for the academic scientific community to use their software for free. We also like to point out that the purpose of this work is not to make ChemAxon's tool obsolete. As a deterministic tool, it will continue to be the first choice for practical naming tasks in databases.</p>
<p>For the work presented here, we were inspired by Google's multiple NMT models and came up with the idea to build a SMILES-TO-IUPAC-name translator called STOUT. STOUT was developed based on language translation and language understanding. We treated the two chemical representations as two different languages-each SMILES string and corresponding IUPAC name was treated as two different sentences that have the same meaning in reality.</p>
<p>All these language models can only achieve greater than $90 \%$ accuracy with sufficient data to train them on. The majority of state-of-the-art language translation models are trained on millions of words and sentences to achieve such high levels of accuracy. Moreover, to train such large models in an adequate amount of time dedicated and powerful machine learning hardware is required. In this work, we report substantially shortened training times for our models using Google's Tensor Processing Units (TPU).</p>
<h2>Methods</h2>
<p>Using deep machine learning methods such as NMT for SMILES-to-IUPAC-name translation is a completely data-driven task so that high-quality data from a reliable source is mandatory. In this work, datasets were created for SMILES-to-IUPAC-name translation as well as for IUPAC-name-to-SMILES translation respectively.</p>
<h2>Data</h2>
<p>All molecules were obtained from PubChem [15], one of the openly available large small molecule databases, where the entire PubChem database was downloaded from its FTP site in SDF format. Using the CDK, explicit hydrogens were removed from the molecules and their
topological structures were converted to canonical SMILES strings. The obtained 111 million molecules were filtered according to the ruleset of our previous DECIMER work [16], i.e. molecules must</p>
<ul>
<li>have a molecular weight of fewer than 1500 Da ,</li>
<li>not possess any counter ions,</li>
<li>contain only C, H, O, N, P, S, F, Cl, Br, I, Se and B,</li>
<li>not contain any hydrogen isotopes (D, T),</li>
<li>have between 3 and 40 bonds,</li>
<li>not contain any charged group,</li>
<li>contain implicit hydrogens only, except in functional groups,
to arrive at a dataset of 81 million molecules. These selected SMILES strings were converted into IUPAC names using Chemaxon's molconvert software, a com-mand-line program in Marvin Suite 20.15 from ChemAxon (https://www.chemaxon.com).</li>
</ul>
<p>Using SMILES strings directly for training Neural Networks (NN) may cause various problems due to their intricate structure which is difficult to split into separate meaningful tokens necessary for the machine input. To tackle this problem, two other representations are available, DeepSMILES [17] and SELFIES [18]. For a discussion of the problems of string tokenization for deep learning, we refer our readers to those two publications. Our results confirm the superiority of SELFIES for the task discussed here and in our work on Optical Chemical Entity Recognition [16]. Thus, for this work all SMILES strings were converted into SELFIES using a custom python script (Fig. 1).</p>
<p>Two datasets were constructed, a 30 million and 60 million molecule set with SELFIES and corresponding IUPAC names, where the 60 million sets contained all 30 million molecule entries of the former. Every SELFIES string and IUPAC name was split into separate tokens using the space character as a delimiter. SELFIES were split according to a closed square bracket " $]$ " and an open square bracket " $]$. For IUPAC names a small set of rules was applied to split them uniformly: After every,</p>
<ul>
<li>open bracket " $($ ", "[" and "[",</li>
<li>close bracket ")", "]" and "]",</li>
<li>dash symbol "-",</li>
<li>full stop "",</li>
<li>comma ",
and after every word in the following list,</li>
<li>mono,di,tri,tetra,penta,hexa,hepta,octa,nona</li>
<li>deca,oxo,methyl,hydroxy,benzene,oxy,chloro,cyclo,a mino,bromo,hydro,fluoro</li>
</ul>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<ul>
<li>methane, cyano, amido, ethene, phospho, amide, butane, carbono, hydro, sulfane, butane, sulfino</li>
<li>iodo, ethane, ethyne, bi, imino, nitro, butan, idene, sulfo, carbon, propane, ethen, acetaldehyde, benzo, oxa, nitroso, hydra, iso</li>
</ul>
<p>a space character was added as a delimiter. After adding the delimiter, the dataset was padded to fit the maximum length of 48 characters for SELFIES strings and 78 characters for IUPAC name strings, a "start" token was added to each string to indicate its beginning, and an "end" token was added at the end of the string. The strings were tokenized and saved into small TFRecord files for training with GPUs or TPUs. Finally, two SELFIES-to-IUPAC-name datasets and two IUPAC-name-to-SELFIES datasets—with 30 million (exactly 30,000,128) and 60 million (exactly 60,000,256) molecules each - were generated.</p>
<h3>Network</h3>
<p>The NMT network follows the implementation reported by Google for their language translation models, which itself is built on the network designed by Luong et al. [19] for neural machine translation, using a soft attention mechanism developed by Bahdanau et al. [20]. It is based on an autoencoder–decoder architecture and is written on Python 3 with Tensorflow 2.3.0 [21] at the backend. The encoder network and the decoder network use Recurrent Neural Networks (RNNs) with Gated Recurrent Units (GRU). The input strings are passed to the encoder and the output strings to the decoder. The encoder network generates the encoder output and the encoder hidden state. The attention weight is calculated by the attention mechanism implemented in the network. Encoder output with attention weights then creates the context vector. Meanwhile, the decoder output is passed through an embedding layer. The output generated by the embedding layer and the context vector is concatenated and passed on to the GRUs of the decoder. An Adam optimizer with a learning rate of 0.0005 is applied and sparse categorical cross-entropy is used to calculate the loss with a modified loss function. A batch size of 256 Strings is used for a GPU and a global batch size of 1024 Strings for a TPU where the global batch size is divided between the nodes.</p>
<p>For SELFIES-to-IUPAC-name and IUPAC-name-to-SELFIES translation the same network architecture is used with the input/output datasets simply being swapped. Figure 2 shows the STOUT architecture for SMILES-to-IUPAC-name translation.</p>
<h3>Model training</h3>
<p>For large datasets, training a neural network efficiently is a challenging task. As an initial test, the network was trained with 15 million molecules on a server with an nVidia Tesla V100 GPU, 384GB of RAM, and two Intel(R) Xeon(R) Gold 6230 processors. The average training epoch was evaluated to be about 27 h so that training of larger datasets appeared to be prohibitive. With more than 100 epochs of training time used in our training described below, those 27 h per epoch translate into almost 4 months of training time, with multiples of that for training with 30 million or 60 million structures. Thus, the training scripts were modified to use Tensor Processing Units (TPUs) available on the Google cloud using the Tensorflow distributed training API. A corresponding training with TPU V3-8 units (with 8 nodes each) reduced the average training epoch to about 2 h.</p>
<h3>Model testing</h3>
<p>To evaluate the models' performance, a test set of 2.2 Million molecules was used, which was not present in the 30</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>million and the 60 million molecules training sets. A uniform and highly similar frequency distribution of unique SELFIES tokens in training and test data were ensured by corresponding test molecule selection. The SELFIES-to-IUPAC-name translation and the reverse IUPAC-name-to-SELFIES translation were tested with the same set.</p>
<p>To assess the predictive accuracy BLEU scoring [22] was used (see Appendix for details). Also, Tanimoto similarities were calculated between original and predicted strings using PubChem fingerprints. For the predictions of IUPAC names as an output, the IUPAC names were reconverted to SMILES using OPSIN 2.5 [23] and canonicalised using the CDK, with the resulting SMILES being utilized for Tanimoto similarity calculations.</p>
<h2>Results and discussion</h2>
<h3>Computational considerations</h3>
<p>Table 1 shows the number of unique SELFIES/IUPAC-name tokens for both data sets. Note that the 30 million and the larger 60 million molecules datasets have the same number of tokens. To keep the same number of tokens we removed the least occurring tokens from both sets using a cutoff. In contrast, the SELFIES token set size is smaller than that of the IUPAC name tokens because the IUPAC names cover a far greater language space.</p>
<p>We used a 15 Mio training dataset to compare the training speed between a GPU and TPUs. Training 15 Million molecules on a TPU V3-8 requires 2 h per epoch which is 13 times faster than using a GPU V100. Using a TPU V3-32 allows for an additional 4 times faster performance in comparison to a TPU V3-8 and is 54 times faster compared to a GPU V100, see Fig. 3.</p>
<p>Figure 4 shows the different training times per epoch of the different datasets on TPU V3-8 units where all</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3 Average training time per epoch on different hardware (lower is better)</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4 Average training time per epoch for different datasets using TPU V3-8</p>
<p>models were trained for more than 100 epochs until convergence. The difference between the SELFIES-to-IUPAC-name and IUPAC-name-to-SELFIES training is caused by the different number of I/O tokens of each dataset: For the SELFIES-to-IUPAC-name translation, the output tokens are derived from the IUPAC names</p>
<p>Table 2 BLEU scores analysis</p>
<table>
<thead>
<tr>
<th>Training dataset size</th>
<th>30 Mio</th>
<th>60 Mio</th>
</tr>
</thead>
<tbody>
<tr>
<td>Average BLEU score</td>
<td>0.89</td>
<td>0.94</td>
</tr>
<tr>
<td>Total number of strings with BLEU 1.0</td>
<td>52.48%</td>
<td>66.65%</td>
</tr>
<tr>
<td>BLEU-1</td>
<td>0.92</td>
<td>0.95</td>
</tr>
<tr>
<td>BLEU-2</td>
<td>0.90</td>
<td>0.94</td>
</tr>
<tr>
<td>BLEU-3</td>
<td>0.88</td>
<td>0.93</td>
</tr>
<tr>
<td>BLEU-4</td>
<td>0.86</td>
<td>0.92</td>
</tr>
</tbody>
</table>
<p>whereas for the IUPAC-name-to-SELFIES translation the output tokens are taken from SELFIES strings. Since SELFIES strings are smaller and less complex than IUPAC name strings the IUPAC-name-to-SELFIES translation is faster.</p>
<h2>Test results</h2>
<h3>SELFIES-to-IUPAC-name translation</h3>
<p>Table 2 summarizes the average and individual BLEU scores for the 30 million and the 60 million molecules dataset. A predicted string with a BLEU score of 1.0 means a score of 1.0 using the NLTK sentence BLEU scoring function[24] and they are mostly identical strings (see Appendix).</p>
<p>Compared to the 30 million molecules dataset, a model trained with 60 million molecules makes better predictions, as demonstrated by all BLEU score types.</p>
<p>To assess the network's ability to learn “chemistry” we calculated the Tanimoto similarities between the predicted and the original molecules by translating the original and the predicted IUPAC names back to SMILES strings using OPSIN and canonicalised the retranslated SMILES using the CDK. We used the CDK with Pubchem fingerprints to calculate the Tanimoto similarity indices. The IUPAC names that OPSIN was able to translate back to SMILES strings were counted as valid IUPAC names while the others were counted as invalid. Only the valid IUPAC-name-to-SMILES translations were used for the Tanimoto similarity calculations. The average Tanimoto similarity was measured on valid IUPAC-name-to-SMILES translations. Additionally, both Tanimoto similarity calculations were readjusted to the number of data points present on the test dataset (see Table 3). We also computed full isomorphism matches using InChIs and found that 98% of all Tanimoto similarity 1.0 cases were full graph isomorphisms.</p>
<p>The invalid IUPAC names are the ones that were rejected by OPSIN and could not be converted into SMILES. This inability is the result of errors of the IUPAC names being predicted. In most cases, the IUPAC-name-to-SMILES translation failed because</p>
<ul>
<li>they did not contain a comma,</li>
</ul>
<p>Table 3 Tanimoto similarities</p>
<table>
<thead>
<tr>
<th>Training dataset size</th>
<th>30 Mio</th>
<th>60 Mio</th>
</tr>
</thead>
<tbody>
<tr>
<td>Invalid IUPAC names</td>
<td>$21.41 \%$</td>
<td>$14.50 \%$</td>
</tr>
<tr>
<td>Valid IUPAC names</td>
<td>$78.59 \%$</td>
<td>$85.50 \%$</td>
</tr>
<tr>
<td>Tanimoto 1.0 count on the total test dataset</td>
<td>$58.36 \%$</td>
<td>$72.33 \%$</td>
</tr>
<tr>
<td>Tanimoto 1.0 count on valid IUPAC names</td>
<td>$74.26 \%$</td>
<td>$84.59 \%$</td>
</tr>
<tr>
<td>Average Tanimoto (measured for total test dataset)</td>
<td>0.75</td>
<td>0.83</td>
</tr>
<tr>
<td>Average Tanimoto (measured for valid IUPAC names)</td>
<td>0.96</td>
<td>0.98</td>
</tr>
</tbody>
</table>
<ul>
<li>some of them were missing a close bracket symbol corresponding to the open bracket symbol,</li>
<li>the valence of an atom was wrong,</li>
<li>a certain block of text was uninterpretable,</li>
<li>they failed to assign all bonds correctly,</li>
<li>of a disagreement between lengths of bridges and alkyl chain length</li>
<li>of long names with repeating words.</li>
</ul>
<p>Table 4 presents a few examples of IUPAC names that could not be converted to SMILES strings with an explanation of the failure.</p>
<p>The Tanimoto similarity index 1.0 count with $72 \%$ ( 60 million molecules set) of the test data is already remarkable but the average Tanimoto similarity of 0.83 ( 60 million molecules set) suggests that an “understanding” of the “language of chemistry” emerged. Also, it becomes obvious that the number of predictions with a Tanimoto similarity of 1.0 is greater than the number of predictions with a BLEU score of 1.0, see Table 5: Although there are different IUPAC names, using OPSIN to re-translate these names led to SMILES representations with similar or even identical chemical graphs, see Figure 5. This also illustrates the extent to which the model is capable to successfully generalise the information of the training data. We found that only five predictions had a Tanimoto similarity index less than 1.0 but a BLEU score of 1.0, see Table 6 and Fig. 6.</p>
<h2>IUPAC-name-to-SELFIES translation</h2>
<p>The IUPAC-name-to-SELFIES translation was tested with the same 2.2 million test molecules as the SELFIES-to-IUPAC-name model before, but in reverse order. To use OPSIN as a performance measure, we analyzed our test set using OPSIN. It was able to convert $98.31 \%$ of IUPAC names generated by the molconvert algorithm back to SMILES and $96.24 \%$ were found to show a Tanimoto 1.0 similarity, see Table 7 for details. Table 8 summarizes the average BLEU score, the calculated BLEU</p>
<p>Table 4 Failed IUPAC-name-to-SMILES translations</p>
<table>
<thead>
<tr>
<th>IUPAC names</th>
<th>Reason for failure (OPSIN error messages)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. $N$-[6-(2,3-diaminopropylidene)-1-methyl-1,2,4a,5,6,8a-hexahydroquinolin-6-yl]-$N$-methylpropanamide</td>
<td>Atoms are in an unphysical valency state. Element: C valency: 5</td>
</tr>
<tr>
<td>2. 2-[(([(3-ethoxypropyl)amino)(([(2-(2-fluorophenyl)ethyl]amino))methylidene) amino)- $N, N$-dimethylacetamide</td>
<td>Unmatched opening bracket found</td>
</tr>
<tr>
<td>3. 3'-(propan-2-yl)-2',3',4',5',6',7',8',8'a-octahydro-2'H-spiro[imidazole-4,1'-indolizin]-2amine</td>
<td>The following being uninterpretable: $2,3,4,5,6,7,8,8$</td>
</tr>
<tr>
<td>4. ((2',6'-difluoro-2',6'-dimethyl-[1,1'-biphenyl]-4-yl)methyl)(propyl)amine</td>
<td>Failed to assign all double bonds</td>
</tr>
<tr>
<td>5. 1,4,5-trimethyl-1-[1,2-dimethylpropyl]-2-methyl-1-propylbicyclo[12.2.1]tetradeca-1,5-diene</td>
<td>Disagreement between lengths of bridges and alkyl chain length</td>
</tr>
</tbody>
</table>
<p>Table 5 Predicted IUPAC name strings with a Tanimoto similarity index of 1.0 but a low BLEU score</p>
<table>
<thead>
<tr>
<th>No.</th>
<th>IUPAC names</th>
<th></th>
<th>BLEU Score</th>
<th>IUPAC names translated into SMILES using OPSIN</th>
<th></th>
<th>Tanimoto similarity Index</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>butyl3-methyl-12-methylidene-2,4,7,10-tetraoxatridecan-13-oate</td>
<td>butyl2-[(2-[2-(1-methoxyethoxy)ethoxy]ethoxy)methyl]prop-2-enoate</td>
<td>0.00</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{CCCCC}\right) \mathrm{C}=\mathrm{C}\left(\mathrm{CCCCCCCCC}\right)$</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{CCCCC}\right) \mathrm{C}=\mathrm{C}\left(\mathrm{CCCCCCC}\right)$</td>
<td>1.0</td>
</tr>
<tr>
<td>2</td>
<td>ethyl3-[1,10-diiodo-9-(iodosulfanyl)-1,10-dithia-2,9-diazadecan-2-yl] propanoate</td>
<td>ethyl3-[(6-[bis(iodosulfanyl)amino] hexyl)(iodosulfanyl)amino]propanoate</td>
<td>0.10</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{CCC}\right) \mathrm{CCN}(\mathrm{S}) \mathrm{CCCCCN}(\mathrm{S}) \mathrm{SI}$</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{CCC}\right) \mathrm{CCN}(\mathrm{S}) \mathrm{CCCCCN}(\mathrm{S}) \mathrm{SI}$</td>
<td>1.0</td>
</tr>
<tr>
<td>3</td>
<td>N,Ndimethyl-1-(prop-2-enamido)cyclopentane-1-carboxamide</td>
<td>N-[1-(dimethylcarbamoyl)cyclopentyl]prop-2-enamide</td>
<td>0.24</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{C}=\mathrm{C}\right) \mathrm{NC} 1(\mathrm{C})=\mathrm{O}\left(\mathrm{N}(\mathrm{C}) \mathrm{C}\right) \mathrm{CCCC1}$</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{C}=\mathrm{C}\right) \mathrm{NC} 1(\mathrm{C})=\mathrm{O}\left(\mathrm{N}(\mathrm{C}) \mathrm{C}\right) \mathrm{CCCC1}$</td>
<td>1.0</td>
</tr>
<tr>
<td>4</td>
<td>6-[4-(2-cyanoethyl)phenyl]-N-[1-(hydroxycarbamoyl)ethyl] hexanamide</td>
<td>2-(6-[4-(3-cyanopropyl)phenyl] hexanamido)-N-hydroxypropanamide</td>
<td>0.32</td>
<td>$\mathrm{N} \mathrm{CCCC1}=\mathrm{CC}=\mathrm{C}\left(\mathrm{C}=\mathrm{C} 1\right) \mathrm{CCCCCC}(\mathrm{O})$ $\mathrm{NC}(\mathrm{C})=\mathrm{O}\left(\mathrm{NO}\right) \mathrm{C}$</td>
<td>$\mathrm{N} \mathrm{CCCCC1}=\mathrm{CC}=\mathrm{C}\left(\mathrm{C}=\mathrm{C} 1\right) \mathrm{CCCCCC}(\mathrm{O})$ $\mathrm{NC}(\mathrm{C})=\mathrm{O}\left(\mathrm{NO}\right) \mathrm{C}$</td>
<td>1.0</td>
</tr>
<tr>
<td>5</td>
<td>12-aminochrysene-6-carboxylicacid</td>
<td>6-aminotetraphene-11-carboxylicacid</td>
<td>0.41</td>
<td>$\mathrm{O}=\mathrm{C}(\mathrm{O}) \mathrm{C} 1=\mathrm{CC}=2 \mathrm{C}=3 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 3 \mathrm{C}(\mathrm{N})$ $=\mathrm{CC} 2 \mathrm{C}=4 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 41$</td>
<td>$\mathrm{O}=\mathrm{C}(\mathrm{O}) \mathrm{C} 1=\mathrm{CC}=\mathrm{CC} 2=\mathrm{CC}=3 \mathrm{C}(\mathrm{N})=\mathrm{CC}=$ $4 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 4 \mathrm{C} 3 \mathrm{C}=\mathrm{C} 21$</td>
<td>1.0</td>
</tr>
<tr>
<td>6</td>
<td>1,3-bis[(6-bromopyridin-2-yl)methyl]-1,3-diazinane</td>
<td>2-bromo-6-[(3-[(6-bromopyridin-2-yl) methyl]-1,3-diazinan-1-yl]methyl] pyridine</td>
<td>0.50</td>
<td>$\mathrm{BrC}=1 \mathrm{~N}=\mathrm{C}\left(\mathrm{C}=\mathrm{CC} 1\right)$ $\mathrm{CN} 2 \mathrm{CN}\left(\mathrm{CC} 3=\mathrm{NC}\right)\left(\mathrm{Br}\right)=\mathrm{CC}=\mathrm{C} 3 \mid \mathrm{CCC} 2$</td>
<td>$\mathrm{BrC}=1 \mathrm{~N}=\mathrm{C}\left(\mathrm{C}=\mathrm{CC} 1\right)$ $\mathrm{CN} 2 \mathrm{CN}\left(\mathrm{CC} 3=\mathrm{NC}\right)\left(\mathrm{Br}\right)=\mathrm{CC}=\mathrm{C} 3 \mid \mathrm{CCC} 2$</td>
<td>1.0</td>
</tr>
<tr>
<td>7</td>
<td>2,3,7-trifluoro-5-methylocta-1,3,5triene</td>
<td>2,5-difluoro-3-methylocta-1,3,5-triene</td>
<td>0.61</td>
<td>$\mathrm{FC}(=\mathrm{C}) \mathrm{C}(\mathrm{F})=\mathrm{CC}(=\mathrm{CC}(\mathrm{F}) \mathrm{C}) \mathrm{C}$</td>
<td>$\mathrm{FC}(=\mathrm{C}) \mathrm{C}(=\mathrm{CC}(\mathrm{F})=\mathrm{CCC}) \mathrm{C}$</td>
<td>1.0</td>
</tr>
<tr>
<td>8</td>
<td>tert-butyl4-acetyl-2-[(acetyloxy) methyl]piperazine-1-carboxylate</td>
<td>tert-butyl2-[(acetyloxy)methyl]-4-acetylpiperazine-1-carboxylate</td>
<td>0.72</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{OC}\right) \mathrm{C}\left(\mathrm{C}\right) \mathrm{C}\left(\mathrm{N}\right) \mathrm{CCN}(\mathrm{C})=\mathrm{O}\left(\mathrm{C}\right)$ $\mathrm{CC} 1 \mathrm{COC}=\mathrm{O} \mathrm{C}$</td>
<td>$\mathrm{O}=\mathrm{C}\left(\mathrm{OC}\right) \mathrm{C}\left(\mathrm{C}\right) \mathrm{C}\left(\mathrm{N}\right) \mathrm{CCN}(\mathrm{C})=\mathrm{O}\left(\mathrm{C}\right)$ $\mathrm{CC} 1 \mathrm{COC}=\mathrm{O} \mathrm{C}$</td>
<td>1.0</td>
</tr>
<tr>
<td>9</td>
<td>N-[(3-cyanophenyl)methyl] pyrimido[4,5-b]indolizine-10-carboxamide</td>
<td>N-[(3-cyanophenyl)methyl]-5H-pyrimido[4,5-b]indolizine-10-carboxamide</td>
<td>0.83</td>
<td>$\mathrm{N} \mathrm{CCC} 1=\mathrm{CC}=\mathrm{CC}(=\mathrm{C} 1) \mathrm{CNC}(=\mathrm{O})$ $\mathrm{C}=2 \mathrm{C}=3 \mathrm{~N}=\mathrm{CN}=\mathrm{CC} 3 \mathrm{~N} 4 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 24$</td>
<td>$\mathrm{N} \mathrm{CC} 1=\mathrm{CC}=\mathrm{CC}(=\mathrm{C} 1) \mathrm{CNC}(=\mathrm{O})$ $\mathrm{C}=2 \mathrm{C}=3 \mathrm{~N}=\mathrm{CN}=\mathrm{CC} 3 \mathrm{~N} 4 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 24$</td>
<td>1.0</td>
</tr>
<tr>
<td>10</td>
<td>(5-benzyllhexa-3,5-dien-2-ylidene) aminomethanesulfonate</td>
<td>(6-benzyllhexa-3,5-dien-2-ylidene) aminomethanesulfonate</td>
<td>0.92</td>
<td>$\mathrm{O}=\mathrm{S}(=\mathrm{O})(\mathrm{D}-)] \mathrm{CN}=\mathrm{C}\left(\mathrm{C}=\mathrm{CC}\right)=\mathrm{C}$ $\mathrm{CC}=1 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 1) \mathrm{C}$</td>
<td>$\mathrm{O}=\mathrm{S}(=\mathrm{O})(\mathrm{D}-)]$ $\mathrm{CN}=\mathrm{C}\left(\mathrm{C}=\mathrm{CC}=\mathrm{CCC}=1 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 1\right) \mathrm{C}$</td>
<td>1.0</td>
</tr>
</tbody>
</table>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5 Chemical structures depicted with the CDK depiction generator for predictions with Tanimoto similarity 1.0 but low BLEU score</p>
<p>Table 6 Predicted IUPAC name strings with a BLEU score of 1.0 but a low Tanimoto similarity index</p>
<p>| No. | IUPAC names | | BLEU Score | IUPAC names translated into SMILES using OPSIN | | Tanimoto similarity Index |
| | Original | Predicted | | Original | Predicted | |
| --- | --- | --- | --- | --- | --- | --- |
| 1 | 4-[(4-amino-2,3,6-trimethylphenyl)methyl]-2,3,5-trimethylaniline | 4-[(4-amino-2,3,5-trimethylphenyl)methyl]-2,3,6-trimethylaniline | 1.0 | NC=1C=C(C(=C(C1C)C) CC=2C(=CC(N)=C(C2C) C)C)C | NC1=C(C=C(C(=C1C)C) CC2=CC(=C(N)C(=C2C) C)C)C | 0.97 |
| 2 | 3-[(3-amino-2,6-diethylphenyl)methyl]-2,4-diethylaniline | 3-[(3-amino-2,4-diethylphenyl)methyl]-2,6-diethylaniline | 1.0 | NC1=CC=C(C(=C1CC) CC=2C(=CC=C(N)C2CC) CC)CC | NC=1C(=CC=C(C1CC) CC2=CC=C(C(N)=C2CC) CC)CC | 0.92 |
| 3 | 2-(4-[(dimethylamino) methyl]-6-[(2,6-dimethylphenoxy)methyl]-6-hydroxycyclohexa-2,4-dien-1-yl)acetonitrile | 2-(4-[(2,6-dimethylphenoxy)methyl]-6-[(dimethylamino) methyl]-6-hydroxycyclohexa-2,4-dien-1-yl)acetonitrile | 1.0 | N#CCC1C=CC(=CC1(O) COC=2C(=CC=CC2C)C) CN(C)C | N#CCC1C=CC(=CC1(O) CN(C)C) COC=2C(=CC=CC2C)C | 0.93 |
| 4 | 4-[4-(3-hydroxycyclo-hepta-1,3,6-trien-1-yl) phenyl]-N-(7-methylcy-clohepta-1,4,6-trien-1-yl) butanamide | 4-[4-(3-hydroxycyclo-hepta-1,4,6-trien-1-yl) phenyl]-N-(7-methylcy-clohepta-1,3,6-trien-1-yl) butanamide | 1.0 | O=C(NC1=CCC=CC=C1C) CCCC=2C=CC(=CC2) C=3C=CCC=C(O)C3 | O=C(NC1=CC=CCC=C1C) CCCC=2C=CC(=CC2) C=3C=CC=CC(O)C3 | 0.95 |
| 5 | (but-1-en-2-yl)(prop-1-en-1-yl)amine | (but-1-en-1-yl)(prop-1-en-2-yl)amine | 1.0 | C=C(NC=CC)CC | C=C(NC=CCC)C | 0.97 |</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Table 7 Analysis on test set using OPSIN</p>
<table>
<thead>
<tr>
<th>OPSIN analysis on test set</th>
<th>Values</th>
</tr>
</thead>
<tbody>
<tr>
<td>Invalid IUPAC names</td>
<td>$1.69 \%$</td>
</tr>
<tr>
<td>Valid IUPAC names</td>
<td>$98.31 \%$</td>
</tr>
<tr>
<td>Tanimoto 1.0 count on the total test dataset</td>
<td>$97.89 \%$</td>
</tr>
<tr>
<td>Tanimoto 1.0 count on valid IUPAC names</td>
<td>$96.24 \%$</td>
</tr>
<tr>
<td>Average Tanimoto (measured for total test dataset)</td>
<td>0.99</td>
</tr>
<tr>
<td>Average Tanimoto (measured for valid IUPAC names)</td>
<td>0.98</td>
</tr>
</tbody>
</table>
<p>scores, and the Tanimoto similarities that were carried out on the test molecules for IUPAC-name-to-SELFIES translation.</p>
<p>The larger 60 million molecules dataset again performs better than the 30 million molecules dataset. Invalid SELFIES do not occur because all the predicted SELFIES were retranslated into SMILES without any error. Again, the predictions with Tanimoto similarity index 1.0 exceed those with BLEU scores 1.0. The reason for this is that BLEU is</p>
<p>Table 8 Average BLEU scores, BLEU Scores, and Tanimoto similarity calculations</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">30 Mio</th>
<th style="text-align: center;">60 Mio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Average BLEU score</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.94</td>
</tr>
<tr>
<td style="text-align: left;">Total number of predicted strings with BLEU 1.0</td>
<td style="text-align: center;">$46.78 \%$</td>
<td style="text-align: center;">$68.47 \%$</td>
</tr>
<tr>
<td style="text-align: left;">BLEU-1</td>
<td style="text-align: center;">0.94</td>
<td style="text-align: center;">0.97</td>
</tr>
<tr>
<td style="text-align: left;">BLEU-2</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.95</td>
</tr>
<tr>
<td style="text-align: left;">BLEU-3</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.94</td>
</tr>
<tr>
<td style="text-align: left;">BLEU-4</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.92</td>
</tr>
<tr>
<td style="text-align: left;">Tanimoto calculations</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Average Tanimoto similarity index</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.94</td>
</tr>
<tr>
<td style="text-align: left;">Number of predicted strings with Tanimoto 1.0</td>
<td style="text-align: center;">$52.27 \%$</td>
<td style="text-align: center;">$73.26 \%$</td>
</tr>
</tbody>
</table>
<p>calculated by mapping word to word for an original and predicted SELFIES string while Tanimoto similarity is calculated according to the corresponding chemical structure, see Table 9 and Figure 7. To improve these results, more molecules with the same set of unique tokens would be needed. We also saw that 860 out of 2.2 million molecules ( $0.0003 \%$ ) had BLEU 1.0 but a slightly lower Tanimoto similarity index because of slight differences in the chemical structures.</p>
<h2>Conclusion</h2>
<p>With this work, purely data-driven deep learning models for translation between different chemical entity representations are reported. We show that deep learning models are able to capture the essence of SMILES to IUPAC name string conversion (and vice versa) with reaching the $90 \%$ accuracy threshold. Despite this promising finding, any large scale and uncurated application should be currently handled with care.</p>
<p>With more data and additional training epochs STOUT is expected to further improve its prediction accuracy in the future. At best, it may finally play in the ballpark of the rule-based systems which further on define the possible top performance. Using the TPU platform will enable the models to be trained in an acceptable amount of time in the order of a few weeks. In addition, STOUT may be extended to alternative sophisticated models used in language translation and understanding, such as BERT [25].</p>
<p>During our revisions, there were two similar preprints, Struct2IUPAC [26] and Translating the Molecules [27], which has been published, reflecting an increase of interest in the translation of SMILES into IUPAC names and vice versa.</p>
<p>Table 9 Predicted SELFIES with low BLEU scores and Tanimoto similarity 1.0</p>
<table>
<thead>
<tr>
<th>No.</th>
<th>SELFIES</th>
<th></th>
<th>BLEU Score</th>
<th>SELFIES decoded back into SMILES</th>
<th></th>
<th>Tanimoto similarity Index</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
</tr>
<tr>
<td>1.</td>
<td>[I][C][C][Branch1_2][Branch1_3][=C][N][C][Exp1=Ring1][Branch1_1][C][C]</td>
<td>[I][C][=C][Branch1_1][Branch1_3][N][C][=C][Ring1][Branch1_1][C][C]:</td>
<td>0.00</td>
<td>IC=1C(=CNC1C)C</td>
<td>IC=1C(=CNC1C)C</td>
<td>1.0</td>
</tr>
<tr>
<td>2.</td>
<td>[O][C][C][=C][C][=C][Branch1_1][Ring2][C][Exp1=Ring1][Branch1_2][C][N][=N][C][=C][Branch1_1][Ring2][C][Exp1=Ring1][Branch1_2][C]</td>
<td>[O][C][=C][C][=C][C][Branch1_2][Ring2][=C][Ring1][Branch1_2][C][=N][N][=C][C][Branch1_2][Ring2][=C][Ring1][Branch1_2][C]:</td>
<td>0.18</td>
<td>OC=1C=CC=C(C1)C=2N=NCC=C(C2)C</td>
<td>OC=1C=CC=C(C1)C=2N=NCC=C(C2)C</td>
<td>1.0</td>
</tr>
<tr>
<td>3.</td>
<td>[C][Branch1_2][=C][=C][C][C][Branch1_2][Branch2_1][=C][C][Branch1_2][Ring1][=C][C][C][C][C]</td>
<td>[C][Branch1_1][=N][C][=C][Branch1_1][Branch1_3][C][=C][Branch1_1][C][C][C][C][C][=C][C]:</td>
<td>0.21</td>
<td>C(=CCC(=CC(=CC(C)C)C</td>
<td>C(C=C(C=C(C)C)CC) =CC</td>
<td>1.0</td>
</tr>
<tr>
<td>4.</td>
<td>[N][=C][C][Branch1_2][N][=C][C][=C][Ring1][Branch1_2][O][C][Branch1_1][C][C][C][C][C][=N][N][C][C][=C][C][Branch1_1][Ring2][N][=C][N][=C][C][Ring1][N][Exp1=Ring1][Branch2_2]</td>
<td>[N][Branch1_2][Ring1][=C][N][C][C][=C][C][N][N][=C][Branch1_1][P][C][C][=N][C][Branch1_1][Branch1_3][O][C][Branch1_1][C][C][C][=C][C][Exp1=Ring1][Branch2_3][C][Exp1=Ring1][#C][C][Exp1=Ring2][Ring1][Ring1]:</td>
<td>0.32</td>
<td>N1=CC(=CC=C1OC(C)C)C2=NNC=3C=CC(N=CN)=CC23</td>
<td>N1=CC(=CC=C1OC(C)C)C2=NNC=3C=CC(N=CN)=CC23</td>
<td>1.0</td>
</tr>
<tr>
<td>5.</td>
<td>[O][=C][N][C][=C][Branch1_1][Branch1_2][N][=C][Ring1][Branch1_2][C][C][=C][C][=C][C][Ring1][Branch2_3]</td>
<td>[O][=C][N][C][C][=C][C][=C][C][C][Exp1=Ring1][Branch1_3][N][=C][Ring1][O][C]:</td>
<td>0.45</td>
<td>O=C1NC2=C(N=C1C)C=CC=CC2</td>
<td>O=C1NC=2C=CC=CCC2N=C1C</td>
<td>1.0</td>
</tr>
<tr>
<td>6.</td>
<td>[O][=N][C][Branch1_2][C][=O][C][C][=C][C][=C][C][Branch1_2][Branch2_2][=C][C][=C][Ring1][Branch1_2][C][Exp1=Ring1][Branch1_2][C][Exp1=Ring1][Branch2_3][C]</td>
<td>[O][=N][C][Branch1_2][C][=O][C][=C][C][=C][C][=C][Branch1_1][Branch2_2][C][=C][C][Ring1][Branch1_2][C][Exp1=Ring1][Branch2_3][C]:</td>
<td>0.53</td>
<td>O=NCC=O)C=1C=CC2=CC(=CC=C2C1)C</td>
<td>O=NCC=O)C=1C=CC2=CC(=CC=C2C1)C</td>
<td>1.0</td>
</tr>
<tr>
<td>7.</td>
<td>[O][B][Branch1_1][C][O][C][=C][C][Branch1_2][=C][=C][C][=C][Ring1][Branch1_2][C][=C][C][=C][C][=C][Ring1][Branch1_2][C][=C][N][=C][C][=C][Ring1][Branch1_2]</td>
<td>[O][B][Branch1_1][C][O][C][C][=C][Branch1_1][=C][C][=C][C][Exp1=Ring1][Branch1_2][C][C][=C][C][=C][C][Exp1=Ring1][Branch2_2][C][=C][N][=C][C][=C][Ring1][Branch1_2]:</td>
<td>0.60</td>
<td>OB(O)C1=CC(=CC=C1C2=CC=CC=C2)C3=CN=CC=C3</td>
<td>OB(O)C1=CC(=CC=C1C2=CC=CC=C2)C3=CN=CC=C3</td>
<td>1.0</td>
</tr>
<tr>
<td>8.</td>
<td>[O][=C][N][C][Branch2_1][Ring1][C][C][C][=C][C][Branch1_1][Ring1][O][C][=C][C][Exp1=Ring1][Branch2_1][N][Branch1_1][C][C][C][=C][Branch1_1][Branch1_2][C][=C][Ring1][P][C][C][C]</td>
<td>[O][=C][N][C][Branch2_1][Ring1][C][C][=C][C][=C][Branch1_1][Ring1][O][C][C][=C][Ring1][Branch2_1][N][Branch1_1][C][C][C][=C][Branch1_1][Branch1_2][C][=C][Ring1][P][C][C][C]</td>
<td>0.71</td>
<td>O=C1NC(C=2C=CC(OC)=CC2N(C)C)=CC(C=C1C)CC</td>
<td>O=C1NC(C=2C=CC(OC)=CC2N(C)C)=CC(C=C1CC)C</td>
<td>1.0</td>
</tr>
</tbody>
</table>
<p>Table 9 (continued)</p>
<table>
<thead>
<tr>
<th>No.</th>
<th>SELFIES</th>
<th></th>
<th>BLEU Score</th>
<th>SELFIES decoded back into SMILES</th>
<th></th>
<th>Tanimoto similarity Index</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
<td>Original</td>
<td>Predicted</td>
<td></td>
</tr>
<tr>
<td>9.</td>
<td>$[O][=P][\operatorname{Branch} 2 _1][\operatorname{Ring} 1][\operatorname{Branch} 1 _2]$</td>
<td>$[O][=P][\operatorname{Branch} 1 _1][\operatorname{Branch} 2 _2][C]$</td>
<td>0.86</td>
<td>$\mathrm{O}=\mathrm{P}(\mathrm{C} 1=\mathrm{NNC})=\mathrm{C} 1$ C(F)(F)C(F)F)</td>
<td>$\mathrm{O}=\mathrm{P}(\mathrm{C} 1=\mathrm{NNC})=C 1$ C(F)(F)C(F)F)</td>
<td>1.0</td>
</tr>
<tr>
<td></td>
<td>$[C][=N][N][C][\operatorname{Branch} 1 _2][\operatorname{Ring} 2][=C]$</td>
<td>$[C][=C][C][=C][C][\operatorname{Expl}=\operatorname{Ring} 1]$</td>
<td></td>
<td>$[C=2 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 2 \mathrm{C}=\mathrm{3C}=\mathrm{CC}=\mathrm{CC} 3$</td>
<td>$(C=2 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 2) \mathrm{C}=3 \mathrm{C}=\mathrm{CC}=\mathrm{CC} 3$</td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[\mathrm{F}][\operatorname{Branch} 1 _1][\mathrm{C}[F][C][\operatorname{Branch} 1 _1]$</td>
<td>$[C][C][=C][C][=C][C][\operatorname{Expl}=\operatorname{Ring} 1]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[C][F][F][\operatorname{Branch} 1 _1][\operatorname{Branch} 2 _2]$</td>
<td>$[C][C][=N][N][C][\operatorname{Branch} 1 _2]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[C][C][=C][C][=C][C][\operatorname{Expl}=\operatorname{Ring} 1]$</td>
<td>$[C][C][=N][N][C][\operatorname{Branch} 1 _2]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[\operatorname{Branch} 1 _2][C][C][=C][C][=C][C]$</td>
<td>$[\operatorname{Branch} 1 _1][C][F][\operatorname{Branch} 1 _1][C][F][C]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[\operatorname{Expl}=\operatorname{Ring} 1][\operatorname{Branch} 1 _2]$</td>
<td>$[\operatorname{Branch} 1 _1][C][F][\operatorname{Branch} 1 _1][C][F][F]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>10.</td>
<td>$[O][=C][\operatorname{Branch} 2 _1][\operatorname{Ring} 1][=N][O][C]$</td>
<td>$[O][=C][\operatorname{Branch} 2 _1][\operatorname{Ring} 1][=C][O][C]$</td>
<td>0.93</td>
<td>$\mathrm{O}=\mathrm{C}(\mathrm{OC} 1=\mathrm{CC}=\mathrm{CC})=C 1$ OC $(=O) C C C$</td>
<td>$\mathrm{O}=\mathrm{C}(\mathrm{OC} 1=\mathrm{CC}=\mathrm{CC})=C 1$ OC $(=O) C C C$</td>
<td>1.0</td>
</tr>
<tr>
<td></td>
<td>$[=C][C][=C][C][\operatorname{Branch} 1 _2][N][=C]$</td>
<td>$[=C][C][=C][C][\operatorname{Branch} 1 _2][N][=C]$</td>
<td></td>
<td>$[C=2 \mathrm{C}=\mathrm{CC}=\mathrm{CC}]=C 1$ OC $(=O) C C C$</td>
<td>$C C C C C C C C C C C C C$</td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[\operatorname{Ring} 1][\operatorname{Branch} 1 _2][O][C][\operatorname{Branch} 1 _2]$</td>
<td>$[\operatorname{Ring} 1][\operatorname{Branch} 1 _2][O][C][\operatorname{Branch} 1 _2]$</td>
<td></td>
<td>$[C=O][C][C][C][C][C][C][C][C][C][C][C]$</td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[C][=O][C][C][C][C][C][C][C][C][C][C]$</td>
<td>$[C][=O][C][C][C][C][C][C][C][C][C][C][C]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>$[C][C][C][C][C]$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p><strong>Fig. 7</strong> Chemical structures depicted with the CDK depiction generator for predictions with Tanimoto similarity 1.0 and low BLEU score</p>
<h2>Appendix</h2>
<p>BLEU scoring for machine translations is a scoring metric introduced in 2002 used to compare a predicted sentence with the original sentence. Each predicted word is compared with the original, and each word is called an unigram or a 1-gram. In longer sentences we can also compare word pairs or bigrams. Here, we calculated BLEU-1 for unigram comparison, BLEU-2 for the bigram comparison, BLEU-3 for 3-gram comparison and BLEU-4 for 4-gram comparison.</p>
<p>In order to compare the predicted IUPAC name with the original IUPAC name a sentence to sentence comparison should be done, so we used the sentence BLEU scoring function inbuilt in Python Natural Language Toolkit [28]. We use the original IUPAC name as the reference string and the predicted IUPAC name as the candidate string to calculate the BLEU scores.</p>
<p>For all BLEU calculations we used the NLTK sentence BLEU scoring function [24].</p>
<p>Weight distributions for different BLEU scores,</p>
<ul>
<li>BLEU-1: weights = (1.0, 0, 0, 0)</li>
<li>BLEU-2: weights = (0.5, 0.5, 0, 0)</li>
<li>BLEU-3: weights = (0.3, 0.3, 0.3, 0)</li>
<li>BLEU-4: weights = (0.25, 0.25, 0.25, 0.25).</li>
</ul>
<p>BLEU score can reduce according to the following,</p>
<ul>
<li>each wrong word match</li>
<li>each wrong n-gram matches</li>
<li>length of the candidate string is longer/shorter than reference string</li>
<li>order of the predicted words are wrong.</li>
</ul>
<p>For these a penalty will be awarded so the overall score will decrease. A few examples are given below.</p>
<p>Reference: 1,3,7-trimethylpurine-2,6-dione
Candidate: 1,3,7-trimethylpurine-2,6-dione
BLEU score: 1.0
BLEU-1: 1.00</p>
<p>BLEU-2: 1.00
BLEU-3: 1.00
BLEU-4: 1.00</p>
<h2>Wrong word</h2>
<p>Reference: 1,3,7-tri methyl purine-2,6-di one Candidate: 1,3,7-tri methyl purine-2,6-tri one BLEU score: 0.87
BLEU-1: 0.94
BLEU-2: 0.90
BLEU-3: 0.90
BLEU-4: 0.88</p>
<h2>Wrong word pair</h2>
<p>Reference: 1,3,7-tri methyl purine-2,6-di one Candidate: 1,3,7-tri methyl purine-2,6,tri one BLEU score: 0.81
BLEU-1: 0.88
BLEU-2: 0.84
BLEU-3: 0.84
BLEU-4: 0.81</p>
<h2>Shorter prediction</h2>
<p>Reference: 1,3,7-tri methyl purine-2,6-di one Candidate: 1,3,7-tri methyl purine-2
BLEU score: 0.63
BLEU-1: 0.63
BLEU-2: 0.63
BLEU-3: 0.63
BLEU-4: 0.63</p>
<h2>Longer prediction</h2>
<p>Reference: 1,3,7-tri methyl purine-2,6-di one
Candidate: 1,3,7-tri methyl purine-2,6-di one, 6-di one, 6 -di one
BLEU score: 0.52
BLEU-1: 0.63
BLEU-2: 0.59
BLEU-3: 0.59
BLEU-4: 0.52</p>
<h2>Wrong order of predictions</h2>
<p>Reference: 1,3,7-tri methyl purine-2,6-di one
Candidate: 1,3,7-tri methyl purine-6,2-di one
BLEU score: 0.71
BLEU-1: 1.00
BLEU-2: 0.86
BLEU-3: 0.80
BLEU-4: 0.71
For the BLEU score calculation, we are using the default settings of sentence BLEU. This corresponds to a fourgram comparison. The weights are distributed evenly. In very few cases as reported in the Results section, we
encountered the predictions with BLEU 1.0 where the strings were not identical. The problem can be rectified using more N -gram comparisons with different weight distributions. In our results these cases were very low in number so we used the default settings.</p>
<p>Reference: 4-[(4-amino-2,3,6-tri methyl phenyl) methyl]-2,3,5-tri methyl aniline</p>
<p>Candidate: 4-[(4-amino-2,3,5-tri methyl phenyl) methyl]-2,3,6-tri methyl aniline</p>
<p>With sentence BLEU, 4 -gram (weights $=$ $(0.25,0.25,0.25,0.25))$</p>
<p>BLEU score: 1.00
With sentence BLEU, 5 -gram (weights $=$ $(0.2,0.2,0.2,0.2,0.2))$</p>
<p>BLEU score: 0.98
With sentence BLEU, 8 -gram (weights $=(0.125,0.125$, $0.125,0.125,0.125,0.125,0.125,0.125))$</p>
<p>BLEU score: 0.88 .</p>
<h2>Abbreviations</h2>
<p>BLEU: Bilingual, Evaluation Understudy; BERT: Bidirectional encoder representations from transformers; CDK: Chemistry development kit; DECIMER: Deep lEarning for Chemical Image Recognition; FTP: File transfer protocol; GPU: Graphics processing unit; IUPAC: International Union of Pure and Applied Chemistry; InChI: International chemical identifier; NMT: Neural machine translation; OPSIN: Open parser for systematic IUPAC nomenclature; RAM: Random access memory; RNN: Recurrent neural network; SDF: Structure data file; SELFIES: Self-referencing embedded strings; SMARTS: SMILES arbitrary target specification; SMILES: Simplified molecular-input line-entry system; STOUT: Smiles TO iUpac Translator; TPU: Tensor processing units; TFRecord: TensorFlow Record file; VRAM: Video random access memory.</p>
<p>We cordially acknowledge the company ChemAxon for making their deterministic IUPAC name generator available for free for academic purposes, without which this project would not have been possible. We are also grateful for the company Google making free computing time on their Tensorflow Research Cloud infrastructure available to us.</p>
<h2>Authors' contributions</h2>
<p>KR developed the software and performed the data analysis. CS and AZ conceived the project and supervised the work. All authors contributed to the manuscript. All authors read and approved the final manuscript.</p>
<h2>Funding</h2>
<p>Open Access funding enabled and organized by Projekt DEAL. The authors acknowledge funding by the Carl-Zeiss-Foundation.</p>
<h2>Availability of data and materials</h2>
<p>The code for STOUT and the trained models are available at https://github. com/Kohulan/Smiles-TO-iUpac-Translator.</p>
<h2>Declarations</h2>
<h2>Competing interests</h2>
<p>AZ is co-founder of GNWI-Gesellschaft für naturwissenschaftliche Informatik mbH, Dortmund, Germany.</p>
<h2>Author details</h2>
<p>${ }^{1}$ Institute for Inorganic and Analytical Chemistry, Friedrich-Schiller-University Jena, Lessingstr. 8, 07743 Jena, Germany. ${ }^{2}$ Institute for Bioinformatics and Chemoinformatics, Westphalian University of Applied Sciences, August-Schmidt-Ring 10, 45665 Recklinghausen, Germany.</p>
<p>Received: 21 December 2020 Accepted: 19 April 2021Published online: 27 April 2021</p>
<h2>References</h2>
<ol>
<li>Contributors to Wikimedia projects (2004) List of chemical compounds with unusual names. https://en.wikipedia.org/wiki/List_of_chemical_ compounds_with_unusual_names. Accessed 1 Dec 2020</li>
<li>Favre HA, Powell WH (2013) Nomenclature of Organic Chemistry: IUPAC Recommendations and Preferred Names 2013. Royal Society of Chemistry, London</li>
<li>Nomenclature of Inorganic Chemistry - IUPAC Recommendations 2005. Chem Int 27:25-26</li>
<li>Inczedy J, Lengyel T, Ure AM, Gelencsér A, Hulanicki A, Others, (1998) Compendium of analytical nomenclature. Blackwell Science, Hoboken</li>
<li>Union internationale de chimie pure et appliquée. Physical, International Union of Pure and Applied Chemistry. Physical and Biophysical Chemistry Division (2007) Quantities, Units and Symbols in Physical Chemistry. Royal Society of Chemistry</li>
<li>Weininger D (1988) SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. J Chem Inf Comput Sci 28:31-36</li>
<li>Heller SR, McNaught A, Pletnev I, Stein S, Tchekhovskoi D (2015) InChI, the IUPAC international chemical identifier. J Cheminform 7:23</li>
<li>Homer RW, Swanson J, Jilek RJ, Hurst T, Clark RD (2008) SYBYL line notation (SLN): a single notation to represent chemical structures, queries, reactions, and virtual libraries. J ChemInf Model 48:2294-2307</li>
<li>Wiswesser WJ (1954) A line-formula chemical notation. Thomas Crowell Company publishers, Washington</li>
<li>Website. Daylight Inc. 4. SMARTS—a language for describing molecular patterns. http://www.daylight.com/dayhtml/doc/theory/theory.smarts. html. Accessed 16 Dec 2020</li>
<li>ChemAxon - Software Solutions and Services for Chemistry \&amp; Biology. https://www.chemaxon.com. Accessed 23 Nov 2020</li>
<li>Steinbeck C, Han Y, Kuhn S, Horlacher O, Luttmann E, Willighagen E (2003) The chemistry development kit (CDK): an open-source Java library for chemo- and bioinformatics. J Chem Inf Comput Sci 43:493-500</li>
<li>Website. RDKit: open-source cheminformatics. https://www.rdkit.org. Accessed 26 Nov 2020</li>
<li>O'Boyle NM, Banck M, James CA, Morley C, Vandermeersch T, Hutchison GR (2011) Open Babel: an open chemical toolbox. J Cheminform 3:33</li>
<li>Kim S, Chen J, Cheng T et al (2019) PubChem 2019 update: improved access to chemical data. Nucleic Acids Res 47:D1102-D1109</li>
<li>Rajan K, Zielesny A, Steinbeck C (2020) DECIMER: towards deep learning for chemical image recognition. J Cheminform 12:65. https://doi.org/10. 1186/s13321-020-00469-w</li>
<li>O'Boyle N, Dalke A DeepSMILES: An Adaptation of SMILES for Use in Machine-Learning of Chemical Structures. Doi: https://doi.org/10.26434/ chemrxiv. 7097960</li>
<li>Krenn M, Häse F, Nigam A, Friederich P, Aspuru-Guzik A (2020) Selfreferencing embedded strings (SELFIES): A 100\% robust molecular string representation. Mach Learn: Sci Technol 1:045024</li>
<li>Luong M-T, Pham H, Manning CD (2015) Effective Approaches to Attention-based Neural Machine Translation. arXiv:1508.04025[cs.CL]</li>
<li>Bahdanau D, Cho K, Bengio Y (2014) Neural Machine Translation by Jointly Learning to Align and Translate. arXiv:1409.0473[cs.CL]</li>
<li>Abadi M, Agarwal A, Barham P, et al (2016) TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv:1603. 04467[cs.DC]</li>
<li>Papineni K, Roukos S, Ward T, Zhu W-J (2002) BLEU: a method for automatic evaluation of machine translation. In: Proceedings of the 40th annual meeting of the Association for Computational Linguistics. pp 311-318</li>
<li>Lowe DM, Corbett PT, Murray-Rust P, Glen RC (2011) Chemical name to structure: OPSIN, an open source solution. J ChemInf Model 51:739-753</li>
<li>nltk.translate package - NLTK 3.5 documentation. https://www.nltk.org/ api/nltk.translate.html. Accessed 18 Mar 2021</li>
<li>Devlin J, Chang M-W, Lee K, Toutanova K (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810. 04805v2[cs.CL]</li>
<li>Krasnov L, Khokhlov I, Fedorov M, Sosnin S (2021) Struct2IUPAC transformer-based artificial neural network for the conversion between chemical notations. ChemRxiv. https://doi.org/10.26434/chemrxiv. 13274 732.v2</li>
<li>Handsel J, Matthews B, Knight N, Coles S (2021) Translating the molecules: adapting neural machine translation to predict IUPAC names from a chemical identifier. ChemRxiv. https://doi.org/10.26434/chemrxiv. 14170 472.v1</li>
<li>Bird S, Klein E, Loper E (2009) Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit. O'Reilly Media Inc, Newton</li>
</ol>
<h2>Publisher's Note</h2>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
<h2>Ready to submit your research! Choose BMC and benefit from:</h2>
<ul>
<li>fast, convenient online submission</li>
<li>thorough peer review by experienced researchers in your field</li>
<li>rapid publication on acceptance</li>
<li>support for research data, including large and complex data types</li>
<li>gold Open Access which fosters wider collaboration and increased citations</li>
<li>maximum visibility for your research: over 100M website views per year</li>
</ul>
<p>At BMC, research is always in progress.
Learn more biomedcentral.com/submissions</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Correspondence: christoph.steinbeck@uni-jena.de
${ }^{1}$ Institute for Inorganic and Analytical Chemistry, Friedrich-SchillerUniversity Jena, Lessingstr. 8, 07743 Jena, Germany
Full list of author information is available at the end of the article&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>