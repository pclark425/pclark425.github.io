<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4636 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4636</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4636</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-103.html">extraction-schema-103</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <p><strong>Paper ID:</strong> paper-267027775</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.08315v2.pdf" target="_blank">Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening</a></p>
                <p><strong>Paper Abstract:</strong> The automation of resume screening is a crucial aspect of the recruitment process in organizations. Automated resume screening systems often encompass a range of natural language processing (NLP) tasks. This paper introduces a novel Large Language Models (LLMs) based agent framework for resume screening, aimed at enhancing efficiency and time management in recruitment processes. Our framework is distinct in its ability to efficiently summarize and grade each resume from a large dataset. Moreover, it utilizes LLM agents for decision-making. To evaluate our framework, we constructed a dataset from actual resumes and simulated a resume screening process. Subsequently, the outcomes of the simulation experiment were compared and subjected to detailed analysis. The results demonstrate that our automated resume screening framework is 11 times faster than traditional manual methods. Furthermore, by fine-tuning the LLMs, we observed a significant improvement in the F1 score, reaching 87.73\%, during the resume sentence classification phase. In the resume summarization and grading phase, our fine-tuned model surpassed the baseline performance of the GPT-3.5 model. Analysis of the decision-making efficacy of the LLM agents in the final offer stage further underscores the potential of LLM agents in transforming resume screening processes.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4636.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4636.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM HR Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based Human Resources (HR) Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-configured agent role-playing an experienced HR professional that performs resume sentence classification, grading, summarization, and candidate selection within an automated resume screening framework; the agent architecture is described as having Character, Memory, Planning, and Action components.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>HR Agent (LLM Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An agent constructed around an LLM (GPT-3.5 / LLaMA2 variants) assigned a 'character' (experienced HR professional) that performs planning (decomposes tasks) and actions (classify sentences, grade, summarize, select candidates); implemented by role prompts/instruction-tuning and (where applied) fine-tuning on domain datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>internal / role-specific knowledge (conceptual memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Memory is conceptualized as a role-specific internal knowledge base (employee skill requirements, salary management, laws/regulations) exposed to the LLM via role assignment and prompts/instruction tuning; there is no external retrieval store or explicit episodic memory implementation—memory is effectively the model's internal parameters and in-context role prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Automated resume screening (sentence classification, grading & summarization, decision-making)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>A pipeline that (1) segments resumes into sentences and classifies sentences into categories (personal info, experience, education, skills, etc.), (2) grades and summarizes each resume (role-played HR scores and ~100-word summaries), and (3) selects finalists from top-N graded resumes (CEO role prompt for final choice).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>resume_seven_class dataset; GSR (Grade & Summarization Resume) dataset (GPT-4-annotated)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>The paper describes 'Memory' as a conceptual component of the agent architecture but does not perform ablations or controlled comparisons isolating the effect of memory (role-based or internal) versus no memory. Instead, experiments focus on instruction format, fine-tuning, and model/backbone comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Memory is only conceptualized (role/knowledge provided via prompts); no explicit external memory store or retrieval mechanism is implemented. The study does not measure the isolated contribution of this memory component. Other reported limitations include token length limits of some models (which required excluding long resumes), privacy/data-collection constraints, and grading-format errors (non-numeric grades) in some LLaMA2 outputs prior to fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Assigning a clear character/role and providing domain-specific instruction (i.e., role prompts and instruction-format inputs) is important; LLM agents can approximate human HR decision patterns when role/context is provided, but the paper does not empirically evaluate separate memory mechanisms—role/context is treated as the practical 'memory' supply to the agent.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4636.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4636.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details about the agent, the type of memory used, the tasks or benchmarks, performance with and without memory, comparisons, and any reported insights or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Long-context LLM Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long-context LLMs for over-length resume screening (GPT-4-Turbo, GPT-3.5-Turbo-16k)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of large-context-capable LLMs to process resumes that exceed the token limits of smaller models (e.g., LLaMA2 4,096 token limit) so that full, content-rich resumes can be evaluated end-to-end without truncation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Long-context LLM Agent (GPT-4-Turbo / GPT-3.5-Turbo-16k)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agents using LLM backbones with extended input windows to ingest very long resume documents (up to 128k tokens for GPT-4-Turbo, 16k for GPT-3.5-Turbo-16k) so grading and summarization consider complete resume text rather than truncated excerpts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>extended context window (contextual / short-term memory via input buffer)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_description</strong></td>
                            <td>Memory here is implemented by supplying the model with the entire or much larger portions of the resume in its input context (long-context / extended window), allowing the model to 'remember' and reason over full document content during a single forward pass instead of relying on external retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-length resume grading & summarization and decision-making</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Evaluation of resumes that exceed smaller-model token limits; models must summarize, grade, and support selection decisions given large documents (experiments on 162 resumes >4,000 tokens). The task tests the capacity to handle long context inputs without truncation.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>162 over-length resumes (annotated using GPT-4-Turbo) drawn from the same corpus; GPT-4-Turbo used as benchmark/gold for these long resumes</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>For GPT-3.5-Turbo-16k (long-context model) reported results on the 162 over-length resumes: ROUGE-1 = 36.05, ROUGE-2 = 12.62, ROUGE-L = 32.61, BLEU = 6.78, Grade Accuracy = 72.22%. (These are reported in Table 9.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_comparison_summary</strong></td>
                            <td>The paper does not present a controlled ablation comparing the same model with and without extended context memory; however, it documents that models with limited token windows (LLaMA2 at 4,096 tokens) were unable to process over-length resumes and thus were excluded, motivating the use of GPT-4-Turbo / GPT-3.5-16k to handle long documents. Reported metrics for GPT-3.5-16k show promising grade accuracy (~72.22%) relative to the GPT-4-Turbo benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Resource constraints limited long-resume experiments to 162 examples; GPT-3.5-16k was evaluated against GPT-4-Turbo as benchmark but direct numeric comparisons to GPT-4-Turbo were not fully reported in the table. Token limits of some backbone models required excluding long resumes, and using long-context APIs is computationally heavier and potentially more costly. No external persistent memory/store or multi-step retrieval pipeline was implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insights</strong></td>
                            <td>Extended context windows effectively serve as a form of memory for document-heavy tasks: using models with larger input windows enables processing of long, content-rich resumes and yields reasonable grading accuracy. The paper recommends using models with sufficient context capacity (or truncation/segmentation strategies) when resume length would otherwise exceed model limits; it also highlights that role-based instruction and fine-tuning remain important alongside context size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ReAct: Synergizing reasoning and acting in language models <em>(Rating: 2)</em></li>
                <li>Introspective Tips: Large language model for in-context decision making <em>(Rating: 2)</em></li>
                <li>How far are we on the decision-making of LLMs? evaluating LLMs' gaming ability in multi-agent environments <em>(Rating: 2)</em></li>
                <li>Towards Human-AI Deliberation: Design and evaluation of LLM-empowered deliberative AI for AI-assisted decision-making <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4636",
    "paper_id": "paper-267027775",
    "extraction_schema_id": "extraction-schema-103",
    "extracted_data": [
        {
            "name_short": "LLM HR Agent",
            "name_full": "LLM-based Human Resources (HR) Agent",
            "brief_description": "An LLM-configured agent role-playing an experienced HR professional that performs resume sentence classification, grading, summarization, and candidate selection within an automated resume screening framework; the agent architecture is described as having Character, Memory, Planning, and Action components.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "HR Agent (LLM Agent)",
            "agent_description": "An agent constructed around an LLM (GPT-3.5 / LLaMA2 variants) assigned a 'character' (experienced HR professional) that performs planning (decomposes tasks) and actions (classify sentences, grade, summarize, select candidates); implemented by role prompts/instruction-tuning and (where applied) fine-tuning on domain datasets.",
            "memory_type": "internal / role-specific knowledge (conceptual memory)",
            "memory_description": "Memory is conceptualized as a role-specific internal knowledge base (employee skill requirements, salary management, laws/regulations) exposed to the LLM via role assignment and prompts/instruction tuning; there is no external retrieval store or explicit episodic memory implementation—memory is effectively the model's internal parameters and in-context role prompt.",
            "task_name": "Automated resume screening (sentence classification, grading & summarization, decision-making)",
            "task_description": "A pipeline that (1) segments resumes into sentences and classifies sentences into categories (personal info, experience, education, skills, etc.), (2) grades and summarizes each resume (role-played HR scores and ~100-word summaries), and (3) selects finalists from top-N graded resumes (CEO role prompt for final choice).",
            "benchmark_name": "resume_seven_class dataset; GSR (Grade & Summarization Resume) dataset (GPT-4-annotated)",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "The paper describes 'Memory' as a conceptual component of the agent architecture but does not perform ablations or controlled comparisons isolating the effect of memory (role-based or internal) versus no memory. Instead, experiments focus on instruction format, fine-tuning, and model/backbone comparisons.",
            "limitations_or_challenges": "Memory is only conceptualized (role/knowledge provided via prompts); no explicit external memory store or retrieval mechanism is implemented. The study does not measure the isolated contribution of this memory component. Other reported limitations include token length limits of some models (which required excluding long resumes), privacy/data-collection constraints, and grading-format errors (non-numeric grades) in some LLaMA2 outputs prior to fine-tuning.",
            "key_insights": "Assigning a clear character/role and providing domain-specific instruction (i.e., role prompts and instruction-format inputs) is important; LLM agents can approximate human HR decision patterns when role/context is provided, but the paper does not empirically evaluate separate memory mechanisms—role/context is treated as the practical 'memory' supply to the agent.",
            "uuid": "e4636.0",
            "source_info": {
                "paper_title": "Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Long-context LLM Agent",
            "name_full": "Long-context LLMs for over-length resume screening (GPT-4-Turbo, GPT-3.5-Turbo-16k)",
            "brief_description": "Use of large-context-capable LLMs to process resumes that exceed the token limits of smaller models (e.g., LLaMA2 4,096 token limit) so that full, content-rich resumes can be evaluated end-to-end without truncation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Long-context LLM Agent (GPT-4-Turbo / GPT-3.5-Turbo-16k)",
            "agent_description": "Agents using LLM backbones with extended input windows to ingest very long resume documents (up to 128k tokens for GPT-4-Turbo, 16k for GPT-3.5-Turbo-16k) so grading and summarization consider complete resume text rather than truncated excerpts.",
            "memory_type": "extended context window (contextual / short-term memory via input buffer)",
            "memory_description": "Memory here is implemented by supplying the model with the entire or much larger portions of the resume in its input context (long-context / extended window), allowing the model to 'remember' and reason over full document content during a single forward pass instead of relying on external retrieval.",
            "task_name": "Long-length resume grading & summarization and decision-making",
            "task_description": "Evaluation of resumes that exceed smaller-model token limits; models must summarize, grade, and support selection decisions given large documents (experiments on 162 resumes &gt;4,000 tokens). The task tests the capacity to handle long context inputs without truncation.",
            "benchmark_name": "162 over-length resumes (annotated using GPT-4-Turbo) drawn from the same corpus; GPT-4-Turbo used as benchmark/gold for these long resumes",
            "performance_with_memory": "For GPT-3.5-Turbo-16k (long-context model) reported results on the 162 over-length resumes: ROUGE-1 = 36.05, ROUGE-2 = 12.62, ROUGE-L = 32.61, BLEU = 6.78, Grade Accuracy = 72.22%. (These are reported in Table 9.)",
            "performance_without_memory": null,
            "has_performance_with_without_memory": false,
            "memory_comparison_summary": "The paper does not present a controlled ablation comparing the same model with and without extended context memory; however, it documents that models with limited token windows (LLaMA2 at 4,096 tokens) were unable to process over-length resumes and thus were excluded, motivating the use of GPT-4-Turbo / GPT-3.5-16k to handle long documents. Reported metrics for GPT-3.5-16k show promising grade accuracy (~72.22%) relative to the GPT-4-Turbo benchmark.",
            "limitations_or_challenges": "Resource constraints limited long-resume experiments to 162 examples; GPT-3.5-16k was evaluated against GPT-4-Turbo as benchmark but direct numeric comparisons to GPT-4-Turbo were not fully reported in the table. Token limits of some backbone models required excluding long resumes, and using long-context APIs is computationally heavier and potentially more costly. No external persistent memory/store or multi-step retrieval pipeline was implemented.",
            "key_insights": "Extended context windows effectively serve as a form of memory for document-heavy tasks: using models with larger input windows enables processing of long, content-rich resumes and yields reasonable grading accuracy. The paper recommends using models with sufficient context capacity (or truncation/segmentation strategies) when resume length would otherwise exceed model limits; it also highlights that role-based instruction and fine-tuning remain important alongside context size.",
            "uuid": "e4636.1",
            "source_info": {
                "paper_title": "Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ReAct: Synergizing reasoning and acting in language models",
            "rating": 2,
            "sanitized_title": "react_synergizing_reasoning_and_acting_in_language_models"
        },
        {
            "paper_title": "Introspective Tips: Large language model for in-context decision making",
            "rating": 2,
            "sanitized_title": "introspective_tips_large_language_model_for_incontext_decision_making"
        },
        {
            "paper_title": "How far are we on the decision-making of LLMs? evaluating LLMs' gaming ability in multi-agent environments",
            "rating": 2,
            "sanitized_title": "how_far_are_we_on_the_decisionmaking_of_llms_evaluating_llms_gaming_ability_in_multiagent_environments"
        },
        {
            "paper_title": "Towards Human-AI Deliberation: Design and evaluation of LLM-empowered deliberative AI for AI-assisted decision-making",
            "rating": 2,
            "sanitized_title": "towards_humanai_deliberation_design_and_evaluation_of_llmempowered_deliberative_ai_for_aiassisted_decisionmaking"
        }
    ],
    "cost": 0.010087249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening
13 Aug 2024</p>
<p>Chengguang Gan gan-chengguan-pw@ynu.jp 
Yokohama National University
Japan</p>
<p>Qinghao Zhang zhangqinghao@pusan.ac.kr 
Department of Information Convergence Engineering
Pusan National University
South Korea</p>
<p>Tatsunori Mori tmori@ynu.ac.jp 
Yokohama National University
Japan</p>
<p>Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening
13 Aug 2024C1662D21817BCE52C8D0989A51C591B7arXiv:2401.08315v2[cs.CL]
The automation of resume screening is a crucial aspect of the recruitment process in organizations.Automated resume screening systems often encompass a range of natural language processing (NLP) tasks.This paper introduces a novel Large Language Models (LLMs) based agent framework for resume screening, aimed at enhancing efficiency and time management in recruitment processes.Our framework is distinct in its ability to efficiently summarize and grade each resume from a large dataset.Moreover, it utilizes LLM agents for decisionmaking.To evaluate our framework, we constructed a dataset from actual resumes and simulated a resume screening process.Subsequently, the outcomes of the simulation experiment were compared and subjected to detailed analysis.The results demonstrate that our automated resume screening framework is 11 times faster than traditional manual methods.Furthermore, by fine-tuning the LLMs, we observed a significant improvement in the F1 score, reaching 87.73%, during the resume sentence classification phase.In the resume summarization and grading phase, our fine-tuned model surpassed the baseline performance of the GPT-3.5 model(Ouyang et al., 2022).Analysis of the decision-making efficacy of the LLM agents in the final offer stage further underscores the potential of LLM agents in transforming resume screening processes.</p>
<p>Introduction</p>
<p>Resume screening is a crucial aspect of recruitment for all companies, particularly larger ones, where it becomes a labor-intensive and time-consuming endeavor.In contrast to smaller firms, a large corporation might receive thousands of resumes during a hiring phase, making efficient screening of these numerous applications a significant challenge.To reduce labor costs associated with resume screening, developing an automated framework is essential.Utilizing natural language processing (NLP) technology for this purpose is increasingly becoming the preferred approach.</p>
<p>The automated resume screening (Singh et al., 2010a) process encompasses two primary components: information extraction (Singhal et al., 2001) and evaluation.As illustrated in Figure 1, resumes typically exist as unstructured or semi-structured text, varying in format.The initial step of the automated framework is to convert this unstructured text into a structured format.This process involves a key NLP task: text classification (Bayer et al., 2022), specifically sentence classification (Minaee et al., 2021).It entails extracting and classifying sentences related to personal information, education, and work experience, transforming them into structured data that is easily stored and manipulated.</p>
<p>Upon structuring the resume text, it must then be summarized and evaluated.The lower part of Figure 1 depicts this process, which includes both automatic and manual screening.Manual screening involves grading and summarizing extensive sections of the resume text, after which the graded and summarized resumes are presented to HR for review, leading to the selection of qualified candidates.This approach significantly reduces the time HR personnel spend perusing resumes and deliberating decisions by shortening the resume text and implementing a grading system for ranking.</p>
<p>The aim is to enhance the efficiency of the screening process.NLP technology can also automate this process, culminating in the output of qualified resumes.</p>
<p>Corpus</p>
<p>Langugae Model</p>
<p>Unsupervised Learning</p>
<p>Pre-trained Langugae Model</p>
<p>Task-specific PLM</p>
<p>Fine-tune Donwstream Task Dataset</p>
<p>Figure 2: The illustration reprehsents the process of pre-training a language model and applying the pretrained language model to a downstream task through fine-tuning method.</p>
<p>In the preceding discussion, we elucidated two NLP tasks pertinent to the automated extraction of information from resumes.Addressing these tasks necessitates the employment of Language Models (LMs) .Presently, the most prevalent infrastructure for LMs is the transformer architecture (Vaswani et al., 2017), distinguished by its attention mechanism.These LMs are predominantly trained on extensive corpora, endowing them with a broad spectrum of knowledge.The seq2seq (sequenceto-sequence) (Sutskever et al., 2014) structure is instrumental in this context, enabling the conversion of an input sequence into a predicted output sequence.This mechanism facilitates the adaptability of LMs to a diverse range of NLP tasks.</p>
<p>As illustrated in Figure 2, the process of LMs spans from their training to their application in various downstream NLP tasks.The initial phase involves assembling a substantial corpus for unsupervised learning, encompassing a broad array of general knowledge.This corpus is typically derived from sources such as Wikipedia1 and extensive web content.Subsequently, these voluminous, unlabeled corpora serve as the foundation for training LMs.Through this process, LMs acquire foundational linguistic competencies and general knowledge autonomously.Following the pre-training phase, Pre-trained Language Models (PLMs) (Min et al., 2023) undergo fine-tuning (Ding et al., 2023) with different datasets tailored to specific downstream tasks.The culmination of this process is the development of task-specific PLMs, capable of effectively predicting or processing relevant NLP tasks.</p>
<p>The initial PLMs, such as BERT (Devlin et al., 2018), T5 (Raffel et al., 2020), and GPT-2 (Radford et al., 2019), were characterized by their relatively modest size, containing only several hundred million parameters.However, the advent of GPT-3 (Brown et al., 2020) marked a significant leap in this field, boasting an impressive 135 billion parameters.This escalation was not merely quantitative but also qualitative, as evidenced by the subsequent development of ChatGPT (Ouyang et al., 2022).ChatGPT underscored how expanding the pre-trained corpus and increasing the parameter count of PLMs could substantially enhance their capabilities, thereby heralding a new era in the development of Large Language Models (LLMs) (Zhao et al., 2023).</p>
<p>Despite these advancements, concerns have arisen regarding the closed-source models developed by major corporations, particularly in terms of user security.The primary issue lies in the potential for private information leakage.Utilizing these LLMs typically requires users to upload their data, creating a risk of data compromise.This is especially pertinent in applications like resume screening, where sensitive personal information is involved.In contrast to closed-source models like GPT-3.5 and GPT-4 (OpenAI et al., 2023), there are open-source LLMs available, such as LLaMA1/2 (Touvron et al., 2023a,b).While these open-source models may not yet match the capabilities of their closed-source counterparts, they offer a significant advantage: the ability to run locally on a user's machine.This local execution ensures greater security for private data, making these models a more secure option for handling sensitive information.</p>
<p>The preceding overview delineates the particular NLP tasks essential for the automated resume screening framework.Additionally, it is highlighted that the tasks, as marked by the blue blocks in Figure 1, are manageable through PLMs and LLMs.A succinct explanation of the fundamental principles of LMs is also provided.Subsequent paragraphs will offer a comprehensive exposition on the implementation of an automated resume screening system utilizing agents derived from LLMs.</p>
<p>LLM Agent</p>
<p>Character Memory Figure 3 presents a schematic representation of a fundamental agent system.This diagram illustrates the segmentation of Language Model (LLM) agents into four core components: Character, Memory, Planning, and Action.Initially, the LLM agent is assigned a distinct character, essentially defining its role or function.For instance, in this study, the LLM agent is designated as an adept Human Resources (HR) professional.This role encapsulates the responsibilities and duties expected of the LLM agent.Subsequently, 'Memory' pertains to the requisite knowledge base necessary for the agent to execute its role effectively.In the context of an HR professional, this encompasses a comprehensive understanding of employee skill requirements, salary management, and relevant laws and regulations.This aspect is analogous to an LLM's capability to access and utilize its internal knowledge database.The next phase involves 'Planning,' where the LLM agent strategizes the execution of tasks.This process entails decomposing a complex task into smaller, manageable subtasks, thereby enhancing the efficiency in addressing intricate assignments.This stage is indicative of an LLM's reasoning and problem-solving abilities.Finally, the 'Action' component represents the implementation stage.In the context of an automated resume screening system, this would involve the LLM agent filtering and selecting resumes that align with specific job requirements.This final stage exemplifies the practical application of the LLM agent's planning and reasoning in a real-world scenario.</p>
<p>Planning Action</p>
<p>In this study, we integrate a LLM agent into the process of automated resume screening.We propose an innovative framework that leverages the LLM agent for automated extraction and analysis of resumes.This framework streamlines the entire process, from initial resume screening to the final selection of qualified candidates, significantly enhancing the efficiency of this task.For our analysis, we utilized a publicly available IT industry-specific resume dataset2 , optimized for sentence classification.Through fine-tuning of the LLM, we achieved an F1 score of 87.73 in sentence classification.This improvement is particularly notable in the model's ability to identify and exclude personal information from resumes, thereby mitigating the risk of privacy breaches when employing models like GPT-3.5/4.Additionally, we developed an HR Agent, designed to both grade and summarize resumes.We created a specialized Grade &amp; Summarization Resume (GSR) dataset, derived from the initial dataset, using the GPT-4 model.This GSR dataset was instrumental in evaluating other LLMs.In these evaluations, the LLaMA2-13B model, once fine-tuned, achieved a ROUGE-1 score of 37.30 in summarization and a Grade accuracy of 81.35, significantly surpassing the baseline GPT-3.5-Turbomodel.Finally, we deployed the HR Agent to select suitable candidates, further analyzing the decisionmaking outcomes.</p>
<p>In addition, we conducted experiments using GPT-4-Turbo and GPT-3.5-Turbo-16k to demonstrate that LLMs are capable of processing longcontext resume information effectively.To further validate the effectiveness of our proposed LLMbased resume screening framework, we randomly selected 50 resumes for manual summarization and evaluation.The performance of the LLMs was benchmarked against this manually labeled dataset.Our analysis of the experiments and specific samples indicated that LLMs' evaluations and decisions closely resemble those of human reviewers.Additionally, to assess the framework's ability to meet complex recruitment requirements, we incorporated additional criteria beyond the basic requirements into the framework.The decisionmaking outcomes were then analyzed to determine the adaptability of the LLMs to these enhanced requirements.</p>
<p>Our comprehensive experiments and analysis demonstrate the LLM agent's robust capability in resume screening.As an HR agent, it effectively facilitates the candidate selection process.</p>
<p>2 Related Work</p>
<p>Resume Information Extraction</p>
<p>Resume screening is a classic application of information extraction, evolving from rule-based methods (Mooney, 1999) to the use of toolkits for automating these rules (Ciravegna and Lavelli, 2004).Over time, techniques such as Hidden Markov Models (HMM) and Support Vector Machines (SVM) developed into Cascaded Hybrid Models for segment classification in resumes (Yu et al., 2005).The adoption of deep learning, utilizing Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs), further enhanced extraction methods (Harsha et al., 2022;Sinha et al., 2021;Kinge et al., 2022;Ali et al., 2022;Bharadwaj et al., 2022;Zu and Wang, 2019;Barducci et al., 2022), with Conditional Random Fields (CRFs) improving LSTM models by refining sequence labeling (Ayishathahira et al., 2018).</p>
<p>Recent advances incorporate pre-trained language models like BERT, integrated with LSTMs and CRFs, significantly enhancing contextual understanding for resume information extraction (Tallapragada et al., 2023).This has been applied in developing algorithms for automating recruitment, with applications in ranking candidates for specific jobs (Erdem, 2023).</p>
<p>Additionally, new tools such as PROSPECT have been developed to support resume screening by extracting and ranking candidate skills and experiences using CRFs (Singh et al., 2010b).Another approach involves using NLP and similarity measures to improve the efficiency of job candidate selection through automated systems that match re-sumes with job descriptions (Daryani et al., 2020).</p>
<p>Large Language Model in Recruit Application</p>
<p>After the advent of LLM, there were other jobs that used LLM in the recruitment process.The work (Du et al., 2024)</p>
<p>Decision Making with LLM Agent</p>
<p>In addition, the LLM agent is employed in decisionmaking processes across various applications.This paper (Huang et al., 2024) evaluates the decisionmaking capabilities of LLMs in complex multiagent environments using a novel framework.This paper (Ma et al., 2024) introduces a novel framework, Human-AI Deliberation, designed to enhance AI-assisted decision-making by fostering a deliberative dialogue between humans and AI.(Chen et al., 2023) introduces "Introspective Tips," a novel approach for enhancing the decisionmaking capabilities of LLMs without the need for fine-tuning.(Wei et al., 2022) highlights that enhanced decision-making abilities can be achieved by incorporating a series of intermediate reasoning steps.(Yao et al., 2022) presents ReAct, a novel method that integrates reasoning with action generation, enhancing the synergy between language comprehension and decision-making in interactive tasks.</p>
<p>Compare LLM-based Resume Screening and Traditional Methods</p>
<p>The application of LLMs to resume screening frameworks offers significant advantages over traditional methods.Firstly, unlike PLMs which are constrained to processing a maximum of 512 tokens, LLMs can manage considerably longer texts.This capability allows LLMs to effectively handle resumes of virtually any length, enhancing the comprehensiveness of the screening process.Secondly, LLMs possess a broader knowledge base, enabling</p>
<p>Resume</p>
<p>Segment to Sentence</p>
<p>Sentence 1 Sentence 2 Sentence 3 ... ...</p>
<p>Open Source LLMs Segmented Resume Sentence Label Sentence</p>
<p>Expreinece Exprience in IT ...</p>
<p>Personal Information</p>
<p>Name: Mike ... their deployment across various industries for resume data processing without the need for specific fine-tuning.Furthermore, LLMs demonstrate enhanced performance compared to traditional PLMs, providing evaluations and judgments that are more aligned with human reasoning.This makes LLMs particularly valuable in contexts where nuanced understanding and decision-making are crucial.</p>
<p>Education</p>
<p>Resume Screening Framework Based on LLM Agents</p>
<p>This section provides a comprehensive overview of the workflow within an novel automated resume screening framework that utilizes a LLM agent.It focuses on the application of the LLM agent in efficiently identifying and selecting qualified resumes from a substantial pool of candidates.To maintain clarity, this overview condenses some aspects, retaining only the essential steps.Detailed discussions of these steps are presented in the subsequent three subsections.Figure 4 illustrates the architecture of our innovative automated resume screening system, which is underpinned by a LLM agent.The process begins with the transformation of a multitude of re-sumes, each in disparate formats like PDF, DOCX, and TXT, into a uniform JSON format.This is achieved through a rule-based algorithm designed to standardize the diverse formatting and file types into coherent, individual sentences.Such preprocessing is crucial for enabling consistent analysis in later stages.The next step involves segmenting these uniformly formatted resumes into distinct sentences, based on criteria like line breaks.This segmentation is vital for the effective functioning of the open-source LLM, which operates locally to classify each sentence.Critical to this process is the categorization of various sentence types, ranging from personal information, which is earmarked for removal to protect privacy, to other categories like work experience, education, and skills.This categorization is particularly significant because it allows for a tailored analysis based on the specific requirements of a job position.For instance, certain roles may prioritize a candidate's skills over their educational background.By extracting and focusing on the segments of a resume that detail relevant skills, the system can more effectively screen candidates for such positions.While our framework currently focuses primarily on the basic function-ality of removing personal information, it lays the groundwork for more nuanced and customized resume screening processes in the future.</p>
<p>Upon removed personal information from resumes, the next step involves utilizing the GPT-3.5 model for grading and summarizing these documents.This task primarily falls under the purview of the HR agent.The grading system serves as a mechanism to rank candidates, streamlining the process of identifying top applicants.Summarization, on the other hand, is aimed at conserving time for the decision-making agent, who must evaluate these summaries.The brevity of summarized content not only expedites the process but also benefits human HR professionals by reducing the time required for initial resume screening.Once resumes are assigned grades and summaries, the decision regarding the candidates' progression can be made either by an HR agent or a human HR professional.Utilizing grades as a comprehensive metric allows for an efficient ranking of candidates.Depending on the specific requirements, a selection of the top 10 or 100 candidates can be made for the next stage of the screening process.This step, whether performed by an HR agent or a human, significantly reduces the time and effort involved in decisionmaking.The final stage involves choosing candidates for interviews or extending job offers directly, based on the refined pool of qualified resumes.This method optimizes the recruitment process, ensuring efficiency and effectiveness in candidate selection.</p>
<p>The preceding section outlined the comprehensive procedure for automated resume screening utilizing open source LLM and LLM agents.Subsequent subsections will elaborate on the implementation of the three pivotal steps: sentence classification, grade &amp; summarization, and decision-making.</p>
<p>Sentence Classification</p>
<p>In our methodology, the LLaMA2 model serves as the foundational base for sentence classification.We enhanced this base model through finetuning, specifically targeting the classification of resume sentences.Unlike previous Pretrained Language Models (PLMs), the LLaMA2 model does not straightforwardly accept a sentence as input and produce a corresponding predicted label.This limitation stems from the model's architecture, as depicted in Figure 5.The LLaMA2-chat variant, developed from the original LLaMA2 model, undergoes a specialized instruction tuning process using an instruction dataset, followed by further refinement through Reinforcement Learning from Human Feedback (RLHF).This approach presents a challenge: simply inputting a sentence into the model does not guarantee the generation of the appropriate prediction label, a phenomenon also evidenced in our subsequent experimental results.</p>
<p>The underlying reason for this is the model's design to respond according to the instruction dataset's guidelines.To elaborate, the input not only contains the query sentence but also incorporates specific textual instructions guiding the model's response.As illustrated in Figure 6, to address this, we append a question to the resume sentence requiring classification.This question instructs the model to categorize the preceding sentence into one of seven predefined labels.Alongside this, we introduce the "Answer:" prompt as part of the input text sequence.Consequently, we utilize the LLaMA2 model, fine-tuned with a specially curated resume sentence instruction dataset, for the effective classification of resume sentences.This fine-tuned LLaMA2 model demonstrates enhanced performance in the task at hand.</p>
<p>Grade &amp; Summarization</p>
<p>Upon extracting the resume text with personal details redacted, our objective is to assess and encapsulate each resume.This process involves a shared component: both evaluation and summarization require a comprehensive understanding of the resume's content.Consequently, we amalgamated these two processes into a singular question and answer task.Figure 7 illustrates this integration, where the red block denotes the assigned role to the LLM agent, exemplified as an HR professional in an IT firm with over a decade of HR experience.This role-play empowers the HR agent to conduct an analysis with the insight of a seasoned HR expert.</p>
<p>Then, briefly summarize the resume in one paragraph (not exceeding 100 words).Answer:</p>
<p>Resume: Sentence1 Sentence2 ...</p>
<p>Input</p>
<p>Question: You are currently an HR in an IT company.You have more than ten years of HR experience.The initial task involves the HR agent appraising the resume, striving for precision and variety in assessment.For guidance, a scoring example (e.g., Grade: XX/100) is provided, deliberately without a predetermined score to avoid biasing the agent's evaluation.Following this, the agent is tasked with summarizing the resume in a concise paragraph, limited to 100 words.The culmination of this process is the agent presenting both the grade and a succinct summary of the resume.</p>
<p>Decision Making</p>
<p>The concluding phase of the resume screening system involves evaluating candidates based on their assigned grades and summaries.In this study, we have bifurcated this stage into two distinct processes: automatic and manual.This bifurcation allows for flexibility to cater to various requirements.Even when the ultimate selection is executed manually by human HR personnel, the highly-rated resumes can be efficiently sifted through utilizing grade rankings.Additionally, the provided summaries facilitate a rapid comprehension of the key elements in each resume by the HR staff, thereby significantly reducing the time required for resume</p>
<p>Input</p>
<p>You are now a CEO of an IT company.The above are the best candidates selected from hundreds of resumes.You now need to decide on one candidate and give him a formal offer.</p>
<p>Please make a judgment based on grade and summary of the resume.</p>
<p>Assignment Roles</p>
<p>Grade  screening.</p>
<p>On the other hand, the process of automated decision-making can be further pursued through the use of a LLM agent.As depicted in Figure 8, each resume is initially provided with a formatted identifier, grade, and summary.This procedure simulates the selection of final candidates.Consequently, the role assignments in the red block are altered, transitioning from an experienced HR professional to a CEO.The task involves selecting one candidate out of ten, based on the provided grades and summaries.Following this, the agent will identify the chosen resume by its ID and articulate the rationale behind this particular selection.</p>
<p>Consequently, a multitude of resumes undergo a series of evaluative processes to identify the most suitable candidates.The automated resume screening framework employed in this process is versatile, allowing customization to meet various requirements and real-world scenarios.For instance, this research replicates the resume evaluation criteria of IT companies, which prioritize candidates' technical skills.Accordingly, the screening process emphasizes skill-related information in the resumes.This approach is adaptable to other sectors such as Marketing, Education, Finance, etc., by modifying the keywords and criteria.Furthermore, the system can be designed to mitigate educational bias by prioritizing skills and work experience, thus focusing on the candidates' competencies.Additionally, the framework's screening parameters are flexible; for example, it can be set to select the top 10% of candidates based on specific criteria.In summary, this adaptability enhances the overall effectiveness and applicability of the screening framework.</p>
<p>Experiment Setup</p>
<p>In this section, we will introduce how to simulate a resume screening process to verify the effectiveness of the automated resume screening framework based on LLM agent.This includes the preparation of the resume dataset and some settings for simulating the resume screening 4.1.The selection of LLM for the backbone of the LLM agent, and the parameter settings for model inference and fine-tuning 4.2.And description of the evaluation method 4.3.</p>
<p>Resume Dataset and Screening Simulation</p>
<p>In the initial phase of our study, we opted for a classification dataset comprising sentences from resumes (Gan and Mori, 2022).This dataset encompasses seven categories: personal information, experience, summary, education, qualification certification, skill, and objectives.It includes a total of 1,000 resumes, amounting to 78,668 sentences, predominantly from the IT sector.Thus, the simulation of resume screening in this research is contextualized within an IT company recruitment framework.And we set that the person who is used to grade each resume is an experienced HR stuff.Then, we set that the top 10 resumes of grade go to the final round of decision making.Finally, the CEO is set to screen the resume grades and summaries of these 10 candidates in order to select a final qualified candidate.</p>
<p>Conversely, given the lack of grade and summarization annotations in the original resume dataset, the GPT-4 model, which currently exhibits superior performance, was employed for annotating these resumes.The annotations generated by GPT-4 served as a benchmark for evaluating the performance of other models, essentially treating GPT-4's output as a gold standard (100% performance) against which to measure other LLMs.This approach facilitated the creation of a comprehensive dataset for simulating resume screening processes.Moreover, due to the token limit of 4096 in the LLaMA2 model, resumes exceeding this token count were excluded.Consequently, a refined dataset of 838 resumes remained, which was then utilized for the second phase of testing.</p>
<p>To enhance the validation of our proposed resume screening framework, we randomly selected 50 resumes, which were then summarized and evaluated manually.This process mirrored the previous method of labeling using GPT-4, where each resume was concisely summarized in approximately 100 words and assessed on a 100-point scale.</p>
<p>We enlisted three graduate students to annotate the resumes manually.Before beginning the annotation process, these evaluators received comprehensive training and were provided with several exemplars to standardize their markings.Specifically, the summaries required detailed inclusion of the candidate's work experience, years in the field, educational achievements (including undergraduate and graduate degrees), skills, experience at major companies, and any other notable experiences, while adhering strictly to 100 word limit.</p>
<p>During the grading phase, we establish specific criteria for evaluation.For instance, we consider skills that may not be directly relevant to the needs of an IT company, such as marketing management.Candidates with limited work experience typically receive grades between 50 and 65.Conversely, candidates who possess several years of IT experience along with undergraduate and graduate degrees in computer science are usually scored within the range of 80 to 95.Due to the inherent imprecision of the scoring process, we adopt a scoring interval of 5 points.Ultimately, the grades are averaged across three evaluators.We then review three different summaries of each resume and select the one that most accurately reflects the original document as the final labeled result.</p>
<p>Prepare Backbone LLMs and Parameter Sets</p>
<p>In the initial phase of the sentence classification task, the LLaMA2-7B model was chosen for finetuning.The dataset, comprising 78,668 sentences, was partitioned into training, validation, and testing sets in a 7:1.5:1.5 ratio.A random seed of 42 was set to ensure reproducibility.This configuration aligns with the experimental setup described in the original paper pertaining to the resume dataset, enabling direct comparisons with other PLMs.For the training process, each GPU was assigned a batch size of 32, and the model underwent training for 2 epochs using 32-bit floating-point precision.</p>
<p>In the subsequent phase, specifically the second stage of grading and summarization, we selected LLaMA2-7B/13/70B and GPT-3.5-turbo-0614 as the backbone LLMs for the HR agent.Initially, we employed a zero-shot methodology to grade and summarize 838 resumes using four different LLMs, aiming to assess and compare their efficacy.During this process, we meticulously configured the parameters for model generation.The maximum number of new tokens was set at 200.This parameter choice was informed by the requirement that each resume should be graded and summarized in over 100 words.Additionally, we incorporated the 'do sample' and 'early stopping' features to optimize the summarization process.Except for these specific adjustments, all other parameters were maintained at their default settings.</p>
<p>In additional, we involved enhancing LLaMA2-7B/13B's capabilities by fine-tuning it with a specialized dataset focused on resume grading and summarization.Initially, this dataset was partitioned into two distinct subsets: a training set with 500 resumes and a test set comprising 383 resumes.Subsequently, the model underwent a training pro-cess where each GPU was allocated a batch size of eight.This training was conducted over 2 epochs, utilizing BF16 precision to optimize performance and computational efficiency.</p>
<p>In conclusion, our experimental setup involved conducting the inference tests for LLaMA2-7B/13B using a dual RTX 3090 24G GPU configuration with float16 precision.In contrast, both the fine-tuning procedures for LLaMA2-7B/13B and the inference tests for LLaMA2-70B were executed on an RTX A800 80G * 8 GPU server.</p>
<p>Evaluation</p>
<p>In the initial phase of resume sentence classification, we utilize the F1 score as the primary evaluation metric.This score comprehensively reflects the model's performance by harmonizing precision and recall into a balanced mean.This approach offers a more accurate representation of the model's effectiveness.</p>
<p>For the resume summarization segment, our evaluation employs two predominant metrics: ROUGE-1/2/L (Lin and Och, 2004) and BLEU.These metrics are extensively recognized in the automatic evaluation of summarization tasks.Although BLEU is traditionally associated with translation evaluations, its application in summarization tasks provides valuable insights.By incorporating BLEU, we aim to achieve a more holistic assessment of the summarization quality.</p>
<p>Regarding the evaluation of grade scores, our methodology focuses on accuracy.This is particularly crucial given the significant variance in grade distribution across different models.We adopt a tolerance range approach in calculating accuracy: a generated grade is deemed accurate if it falls within a margin of ±5 from the actual grade.The calculation adheres to the following principle: if the absolute difference between the predicted and the actual grade is 5 or less, the prediction is considered correct (recorded as 1, with 0 indicating an error).To derive the final grade accuracy, we divide the total count of correct predictions by the total number of actual grades (PG is denote Predict Grade, TG is denote True Grade).
Accuracy = N i=1 1 (|PG i − TG i | ≤ 5) N</p>
<p>Results</p>
<p>In the results of sentence classification for resumes, we conducted comparative experiments on the performances of several large-scale models: BERT Large, ALBERT Large, RoBERTa Large, and T5 Large.The results, detailed in Table 1, reveal a notable enhancement in the F1 score of the LLaMA2-7B-chat model, which reaches 87.73, attributed to the implementation of the instruction format for both input and output.Interestingly, a direct fine-tuning of the LLaMA2-7B-chat model, using the conventional approach of inputting sentences and outputting labels as done with previous PLMs, resulted in a significant drop in the F1 score to 78.16.This outcome undergrades the efficacy of the instruction format we proposed.Furthermore, it highlights a critical consideration for fine-tuning LLMs in sentence classification tasks: adhering to the instruction format used during the instruction learning phase is crucial for optimizing the models' sentence classification capabilities.</p>
<p>In the evaluation of the grading and summarization component of the automated resume screening framework, we conducted tests using three different model sizes of LLaMA2 and GPT-3.5-Turbo.The results, as presented in Table 2, indicate that GPT-3.5-Turbooutperformed the others across all three ROUGE metrics: ROUGE-1 (34.75), , significantly surpassing the LLaMA2-70B model.Furthermore, under the BLEU evaluation metric (Table 3), GPT-3.5-Turboachieved a score of 7.31, nearly tripling the performance of its counterparts.This suggests that, if not using the fine-tuning method (0-shot inference).Utilizing closed-source models like GPT-3.5-Turbo and GPT-4 as the backbone for HR agents is crucial for enhanced performance.Interestingly, in the aspect of grading accuracy, LLaMA2-13B outshined the other models with a score of 59.31, notably exceeding the LLaMA2-70B model by 23.27.This anomaly and its implications will be further analyzed and discussed in the following subsection.</p>
<p>Finally, the LLaMA2-7B/13B model was subjected to fine-tuning, yielding notable improvements as documented in Table 4. Specifically, the refined LLaMA2-13B model demonstrated remarkable grades of 37.30, 13.90, and 33.93 in ROUGE-1/2/L metrics, respectively.This performance notably surpassed that of the 0-shot GPT-3.5 Turbo model in the test set evaluations.Furthermore, Table 5 presents the enhancements in BLEU grades, where the LLaMA2-7B and LLaMA2-13B models recorded increments to 8.45 and 8.62, respectively.Correspondingly, there was a significant improvement in grade accuracy, reaching 76.19 and 81.35</p>
<p>Normal Distribution of Grade</p>
<p>Figure 9 &amp; 10 presents the normal distribution plots for the evaluations assigned by five different LLMs.Notably, the GPT-4 model generally aligns with the normal distribution across all grades, with a marked preference for assigning grades within the 85-90 range.This skew towards higher grades may stem from GPT-4's inclination to award more favorable ratings during fine-tuning processes, such as RLHF.Despite this, the impact on final resume screening remains minimal, as the system consistently prioritizes the top 10 resumes based on grades.While there may be some uncertainty regarding the extent to which these LLM-based HR agents accurately reflect the actual quality of each resume, the simulation experiment suggests that the grading patterns of all five LLMs largely adhere to a normal distribution.This indicates that the application of LLMs in resume evaluation is a successful experiment, with outcomes mirroring those expected in real-world scenarios.</p>
<p>The data presented in Figure 9 &amp; 10 and Table 6 reveals that the three LLaMA2 models exhibit instances of zero grading.This phenomenon occurs because these models assign grades that are not exclusively two-digit grades (such as 'A', 'B+++', etc.), leading to misclassification.Consequently, we have classified all such instances as zero grades.It is noteworthy that the incidence of grading er-</p>
<p>Model</p>
<p>Total Number of Errors
LLaMA2-7B 190 LLaMA2-13B 22 LLaMA2-70B 8 LLaMA2-7B FT 1 LLaMA2-13B FT 0
rors in the LLaMA2 model is significantly reduced following fine-tuning.Additionally, the GPT-3.5-Turbo/4model demonstrates an absence of grade errors, which can be attributed to the differences in the capabilities of various LLMs in terms of understanding and adherence to instructions.</p>
<p>Analysis of Decision Making</p>
<p>In our study, we utilized the GPT-3.5-Turboand GPT-4 models as autonomous HR agents to evaluate the top 10 resumes based on their grades.The rationale behind their decisions is detailed.As illustrated in Figure 11, both models consistently identified resume ID 308 as the top candidate.The justification for this selection was not only the high grade of resume ID 308 but also its alignment with the specific needs of an IT company, including relevant work experience and managerial skills.This analysis demonstrates a remarkable congruence with the cognitive processes and judgment criteria typically employed by human HR professionals in decision-making.Furthermore, these findings underscore the potential of integrating LLM based HR agents into future automated resume screening systems.</p>
<p>To further investigate the decision-making capabilities of the HR agent, particularly in handling complex recruitment requirements, we refined the criteria within this stage and conducted an additional experiment.This experiment utilized a dataset of 50 manually annotated resumes, summarized and graded for relevance.We configured the hiring criteria to target three individuals with expertise in database development.This requirement was incorporated into the input prompt template as follows: "You are now recruiting three individuals for database development roles in your company."As depicted in Figure 12, the HR agent successfully identified three candidates, providing detailed justifications for each selection.Notably, all candidates demonstrated relevant database development skills and substantial professional experience.The reasoning for their selection was well-articulated and convincing.Subsequent manual review of the candidates' resumes confirmed that these individuals were indeed the most suitable for the positions.</p>
<p>This experiment underscores the adaptability of the LLM-based resume screening framework, highlighting its ability to accommodate a diverse array of job specifications.It demonstrates that the model can be effectively tailored to meet varying recruitment needs of different companies for various positions, thus proving its generalizability and utility in complex HR scenarios.</p>
<p>Comparison with Manual Resume Screening</p>
<p>We conducted a thorough evaluation of various LLMs by manually annotated 50 resumes to serve as a benchmark.The results of these tests are de-Given the need for professionals in database development-related roles at your IT company, it's crucial to select candidates who demonstrate strong database management skills, proficiency in relevant programming languages, and experience in database-driven projects.Based on the grades and summaries provided:</p>
<ol>
<li>
<p>ID: 892 -Grade: 95 Summary: This candidate stands out with an extensive 8-year experience in Java/J2EE technologies and expertise with relational databases like Oracle.The experience in web application development might be directly beneficial for backend system integration and effective data handling tasks in our projects.The knowledge of cloud deployment using AWS is also an advantage, as modern database solutions often integrate with cloud services.</p>
</li>
<li>
<p>ID: 30 -Grade: 90 Summary: This candidate has a solid background in Oracle SQL and PL/SQL, focusing on database optimization, maintenance, and implementation.Their experience with companies like Liquidhub and Hewlett Packard, and their demonstrated technical skills in database management and performance tuning, makes them particularly fitting for database development roles.</p>
</li>
</ol>
<p>ID: 416 -Grade: 90</p>
<p>Summary: Though primarily a firmware developer, this candidate's background in Electronics and Communication Engineering, and their proficiency with real-time operating systems and device driver development, offer useful crossover skills for database and system architecture projects.Their understanding of hardware protocols might provide fresh insights into how our database solutions can be optimized for performance at the lowest level.</p>
<p>These selections prioritize a balance of relevant technical skills, proven experience in handling complex databases, and the ability to contribute uniquely to the development and optimization of advanced database systems at your IT company.7 and 8, with the GPT-3.5-Turboand GPT-4 models demonstrating superior performance.Notably, while the accuracy of the grade assignments was not perfect, a subsequent analysis of the top ten resumes ranked by grades revealed significant insights.The resumes that received the highest grades from GPT-4 exhibited a striking resemblance to those scored manually, underscoring the effectiveness of the model in mimicking human evaluative patterns.</p>
<p>As depicted in Figure 13, we compiled the IDs and grades of the top ten resumes according to the final grades from GPT-4 and manual scoring.In this figure, underlined text indicates where the two sets of rankings overlap, highlighting a strong correlation in the evaluation outcomes.Remarkably, both manually and by GPT-4, resumes ID 801 and ID 892 received the highest grades.Furthermore, 11 out of the 12 resumes that ranked highly in the manual assessment also featured prominently in the GPT-4 rankings, further validating the model's evaluative consistency.Finally, we selected a final qualified resume using both manual and GPT-4 methods.Both selected resume ID 801 as the hiring candidate.Detailed analysis of this candidate's credentials revealed not only a robust six years of professional experience but also a comprehensive repertoire of IT-related skills.The individual is a versatile full-stack Java developer, proficient in a range of technologies spanning from front-end to back-end development, including networking.This skill set renders the candidate highly suitable for a developer role within an IT organization.In conclusion, our findings affirm the efficacy of the proposed resume screening framework that leverages LLMs.This comparison with traditional manual methods substantiates the potential for LLMs to effectively replace manual resume screening processes in the future.Our analysis also included a comparison between the score distributions of the most advanced GPT-4 model and manual grading.Figure 14 illustrates this comparison, revealing a high degree of similarity between the two distributions.We quantified this similarity by calculating the cosine similarity, which yielded a value of 0.9944, approaching 1.This high similarity score further supports the consistency between GPT-4-generated grades and manual grades.This consistency is likely attributable to the model's use of instruction tuning and reinforcement learning with human feedback (RLHF).We also computed the correlation between the two rankings using Spearman's rho (ρ) and Kendall's tau (τ ).The values obtained were 0.7574 for Spearman's ρ and 0.6252 for Kendall's τ , indicating a strong positive correlation between the manual rankings and the predicted rankings produced by the LLM.</p>
<p>Analysis of Long Length Resume Screening</p>
<p>In addition, for resumes that exceed the LLaMA2 model's processing limit of 4,096 tokens, we conducted further experiments using more advanced models from the GPT family.Specifically, we utilized the GPT-4-Turbo and GPT-3.5-Turbo-16kmodels, which are capable of processing up to 128,000 and 16,000 tokens, respectively.These models are well-suited to handle the length of most resumes.Due to resource limitations, our experiments were confined to 162 resumes that exceeded 4,000 tokens in length.</p>
<p>We used the results from the GPT-4-Turbo model as a benchmark for evaluating the performance of the GPT-3.5-Turbo-16kmodel.As indicated in Table 9, the GPT-3.5-Turbo-16kmodel demonstrated promising results, with a notable grade accuracy of 72.22%.This high level of accuracy can be attributed to the model's ability to effectively analyze content-rich resumes, which typically contain extensive text detailing numerous skills and work experiences.Common sense suggests that resumes with more detailed information about a candidate's skills and experiences are likely to score higher, indicating a potentially stronger candidate.This principle was affirmed by our findings, which showed a direct correlation between the depth of resume content and the accuracy of the model's grading.We measured the time expenditure for each phase, culminating in an aggregate duration assessment.Notably, in the Classification stage, we accounted for the time span from initiation to conclusion of the inference process, excluding the fine-tuning duration.This approach mirrors the actual operational timeline of the automated screening framework.In the Decision Making stage, our focus was on the time required to evaluate the top ten resumes.Additionally, we assessed the time investment for the semi-automated method, wherein human HR personnel undertake the final decision-making step, while preceding stages are managed by LLMs.For the manual screening conducted by Human HR, we based our calculations on the average adult reading speed of 238 words per minute, as indicated by survey literature (Brysbaert, 2019).Consequently, we deduced that reviewing all 838 resumes, encompassing a total of 442,047 words, would approximately take 31 hours (Please note that this is an estimated calculated based on the average human reading speed.).</p>
<p>Table 10 illustrates that the fully automated resume screening framework, utilizing an LLM agent, completes the entire process set in approximately 2 hours and 55 minutes.This efficiency represents a speed 11 times faster than manual resume screening.Additionally, the semi-automatic approach is 9 times quicker than the manual method.While this comparison may lack rigorous precision, as it does not account for the possibility that human HR personnel might not read every word in a resume to reach a decision, the significant time reduction observed with the automated framework underscores its high efficiency.</p>
<p>Conclusion</p>
<p>In this study, we explore the feasibility of using an LLM agent for automated resume screening.We propose an innovative framework for this purpose and validate it using a real-world resume dataset, as well as through simulation of the resume screening process.Our results, derived from a series of comparative tests and analyses, demonstrate that the LLM agent can effectively perform the role of a human HR professional in resume screening.Notably, in terms of time efficiency, the LLM agent significantly surpasses traditional manual screening methods.</p>
<p>This work is subject to certain limitations.Primarily, it employs a controlled experimental design to maximize result accuracy, which restricts the scope of application to basic requirements of LLMs agent within IT companies.Consequently, this approach does not account for the varied requirements of other industries.Additionally, the collection of resume data is challenging due to privacy concerns.In future work, we aim to gather a broader array of resumes from diverse industries to enhance the representativeness of our study and further refine the LLM resume screening framework.</p>
<p>Figure 1 :
1
Figure 1: The Process of automated resume screening.</p>
<p>Figure 3 :
3
Figure 3: The illustration depict LLM as the backbone of the agent system.</p>
<p>Figure 4 :
4
Figure 4: The illustration depict the workflow of LLM agent base Automated Resume Screening Framework.</p>
<p>Figure 5 :Figure 6 :
56
Figure 5: The illustration depict the process of instruction tuning and RLHF for the LLaMA2 model.</p>
<p>Figure 7 :
7
Figure 7: The illustration depict assignment of roles and tasks to the LLM agent.</p>
<p>Figure 8 :
8
Figure 8: The illustration depict the HR agent making a final Decision to select a qualified candidate.</p>
<p>Figure 9 :Figure 11 :
911
Figure 9: Compare the Grade Distribution of LLaMA2-7B/13B/70B models.</p>
<p>Figure 12 :
12
Figure12: The text of Decision Making with HR agents (GPT4-Turbo Models).</p>
<p>Figure 14 :
14
Figure 14: The comparison of manual and GPT-4 in grades distributions (Base 50 samples dataset).</p>
<p>Table 1 :
1
Results of resume sentence classification dataset.
ModelF1 ScoreBERT Large86.67ALBERT Large86.40RoBERTa Large87.00T5 Large87.35LLaMA2-7B-chat78.16LLaMA2-7B-chat (Instruction Format)87.73</p>
<p>Table 2 :
2
Results of resume grade and summarization dataset (ROUGE-1/2/L).
ModelROUGE-1 ROUGE-2 ROUGE-LLLaMA2-7B26.356.2224.00LLaMA2-13B25.315.8322.99LLaMA2-70B28.127.7025.68GPT-3.5-Turbo34.7512.3431.92</p>
<p>Table 3 :
3
Results of resume grade and summarization dataset (BLEU and Grade Accuracy).
ModelBLEU Grade AccuracyLLaMA2-7B2.6647.49LLaMA2-13B2.5659.31LLaMA2-70B3.7323.27GPT-3.5-Turbo7.3147.61</p>
<p>Table 4 :
4
Results of fine-tuned LLaMA2-7B/13B in resume grade and summarization dataset (ROUGE-1/2/L).
ModelROUGE-1 ROUGE-2 ROUGE-LGPT-3.5-Turbo34.6112.1831.83LLaMA2-7B36.5013.3233.48LLaMA2-13B37.3013.9033.93Table 5: Results of fine-tuned LLaMA2-7B/13B inresume grade and summarization dataset (BLEU andGrade Accuracy).ModelBLEU Grade AccuracyGPT-3.5-Turbo7.4045.24LLaMA2-7B8.4576.19LLaMA2-13B8.6281.35for each model. These results clearly indicate that,with adequate resume datasets for fine-tuning, opt-ing for open-source LLaMA2-7B/13B models asthe foundation for HR agent systems is a moreeffective strategy.</p>
<p>Table 6 :
6
Number of grading errors (The grade is not a two-digit number) by different LLMs.</p>
<p>Table 7 :
7
Experimental results of LLMs evaluated based on manually annotated 50 sample datasets (ROUGE-1/2/L).
ModelROUGE-1 ROUGE-2 ROUGE-LLLaMA2-7B27.037.1124.28LLaMA2-13B24.965.9622.62LLaMA2-70B27.277.6925.00GPT-3.5-Turbo34.5512.3731.94GPT-439.8716.4435.89</p>
<p>Table 8 :
8
Experimental results of LLMs evaluated based on manually annotated 50 sample datasets (BLEU and Grade Accuracy).
ModelBLEU Grade AccuracyLLaMA2-7B3.2822.00LLaMA2-13B2.7140.00LLaMA2-70B3.7338.00GPT-3.5-Turbo7.1658.00GPT-411.0650.00tailed in Tables</p>
<p>Table 9 :
9
Model experiment results.Evaluated based on GPT-4-Turbo (Max input length 128K) annotated 162 over length resume datasets .Our study entailed a meticulous time comparison of three distinct resume screening methods: Automated, Semi-Automated, and Manual.To this end, we deconstructed the automated screening process into three discrete stages: Classification, Grading &amp; Summarization, and Decision Making.
ModelROUGE-1ROUGE-2ROUGE-LGPT-3.5-Turbo-16k36.0512.6232.61ModelBLEUGrade AccuracyGPT-3.5-Turbo-16k6.7872.225.5 Time comparison between automated andhuman resume screening</p>
<p>Table 10 :
10
Follow each step to compare the time consumed by automated and manual resume screening.Sergio Zavota.2022.An end-to-end framework for information extraction from italian resumes.Expert Systems with Applications, 210:118487.Markus Bayer, Marc-André Kaufhold, and Christian Reuter.2022.A survey on data augmentation for text classification.ACM Comput.Surv., 55(7).S Bharadwaj, Rudra Varun, Potukuchi Sreeram Aditya, Macherla Nikhil, and G Charles Babu.2022.Resume screening using nlp and lstm.In 2022 international conference on inventive computation technologies (ICICT), pages 238-241.IEEE.Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020.Language models are few-shot learners.Advances in neural information processing systems, 33:1877-1901.Marc Brysbaert.2019.How many words do we read per minute?a review and meta-analysis of reading rate.Journal of memory and language, 109:104047.
ModelClassificationGrade &amp; Summary Decision MakingGPT-4 API25 min (FT LLaMA2-7B)2 h 30 min0.4 minLLM withEstimated Human 25 min (FT LLaMA2-7B) 2 h 30 min (GPT-4) 22 min (Manual)Screening TimeEstimatedHuman Screening---TimeModelTotal Time Multiple Automatic or ManualGPT-4 API2 h 55.4 minx 11AutomaticLLM with Estimated3 h 17 minx 9Semi-automaticHuman Screening TimeEstimated Humanx 1ManualScreening Time31 h
https://www.wikipedia.org/
https://huggingface.co/datasets/ ganchengguang/resume_seven_class</p>
<p>Resume classification system using natural language processing and machine learning techniques. Irfan Ali, Nimra Mughal, Zahid Hussain Khand, Javed Ahmed, Ghulam Mujtaba, Mehran University Research Journal of Engineering &amp; Technology. 4112022</p>
<p>Combination of neural networks and conditional random fields for efficient resume parsing. Ch Ayishathahira, Sreejith, Raseek, 2018 International CET Conference on Control, Communication, and Computing (IC4). IEEE2018</p>
<p>. Alessandro Barducci, Simone Iannaccone, La Valerio, Vincenzo Gatta, Giancarlo Moscato, Sperlì, </p>
<p>Liting Chen, Lu Wang, Hang Dong, Yali Du, Jie Yan, Fangkai Yang, Shuang Li, Pu Zhao, Si Qin, Saravan Rajmohan, arXiv:2305.11598Introspective tips: Large language model for in-context decision making. 2023arXiv preprint</p>
<p>Learningpinocchio: Adaptive information extraction for real world applications. Fabio Ciravegna, Alberto Lavelli, Natural Language Engineering. 1022004</p>
<p>An automated resume screening system using natural language processing and similarity. Chirag Daryani, Gurneet Singh Chhabra, Harsh Patel, ETHICS AND INFORMATION TECHNOLOGY. 2020VOLK-SON PRESSIndrajeet Kaur Chhabra, and Ruchi Patel. Internet</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. Bert2018arXiv preprint</p>
<p>Parameter-efficient fine-tuning of large-scale pretrained language models. Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Nature Machine Intelligence. 532023</p>
<p>Enhancing job recommendation through llm-based generative adversarial networks. Yingpeng Du, Di Luo, Rui Yan, Xiaopei Wang, Hongzhi Liu, Hengshu Zhu, Yang Song, Jie Zhang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Automatic resume screening with content matching. Merve Elmas, Erdem , 10.1109/UBMK59864.2023.102865782023 8th International Conference on Computer Science and Engineering (UBMK). 2023</p>
<p>Construction of english resume corpus and test with pre-trained language models. Chengguang Gan, Tatsunori Mori, arXiv:2208.03219arXiv:2309.11805Preetam Ghosh and Vaishali Sadaphal. 2023. Jobrecogpt-explainable job recommendations using llms. 2022arXiv preprint</p>
<p>Automated resume screener using natural language processing (nlp). 2022 6th international conference on trends in electronics and informatics (ICOEI). Tumula Mani Harsha, Gangaraju Sai Moukthika, Dudipalli Siva Sai, Mannuru Naga Rajeswari, Satish Pravallika, Muralikrishna Anamalamudi, Enduri, IEEE2022</p>
<p>How far are we on the decision-making of llms? evaluating llms' gaming ability in multi-agent environments. Jen-Tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R Lyu, arXiv:2403.118072024arXiv preprint</p>
<p>Resume screening using machine learning and nlp: A proposed system. Bhushan Kinge, Shrinivas Mandhare, Pranali Chavan, Chaware, 20228International Journal of Scientific Research in Computer Science, Engineering and Information Technology (IJSRCSEIT)</p>
<p>Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. Chin-Yew Lin, Franz Josef, Och , Proceedings of the 42nd annual meeting of the association for computational linguistics (ACL-04). the 42nd annual meeting of the association for computational linguistics (ACL-04)2004</p>
<p>Towards human-ai deliberation: Design and evaluation of llm-empowered deliberative ai for ai-assisted decision-making. Shuai Ma, Qiaoyi Chen, Xinru Wang, Chengbo Zheng, Zhenhui Peng, Ming Yin, Xiaojuan Ma, arXiv:2403.168122024arXiv preprint</p>
<p>Recent advances in natural language processing via large pre-trained language models: A survey. Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran, Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, Dan Roth, ACM Computing Surveys. 5622023</p>
<p>Narjes Nikzad, Meysam Chenaghlu, and Jianfeng Gao. 2021. Deep learning-based text classification: A comprehensive review. Shervin Minaee, Nal Kalchbrenner, Erik Cambria, 10.1145/3439726ACM Comput. Surv. 543</p>
<p>Relational learning of pattern-match rules for information extraction. Mooney, Proceedings of the sixteenth national conference on artificial intelligence. the sixteenth national conference on artificial intelligence1999328334</p>
<p>Giambattista Parascandolo. : Openai, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shane Shixiang, Yufei Gu, Chris Guo, Jesse Hallacy, Jeff Han, Yuchen Harris, Mike He, Johannes Heaton, Chris Heidecke, Alan Hesse, Wade Hickey, Peter Hickey, Brandon Hoeschele, Kenny Houghton, Shengli Hsu, Xin Hu, Joost Hu, Shantanu Huizinga, Shawn Jain, Joanne Jain, Angela Jang, Roger Jiang, Haozhun Jiang, Denny Jin, Shino Jin, Billie Jomoto, Heewoo Jonn, Tomer Jun, Łukasz Kaftan, Ali Kaiser, Ingmar Kamali, Nitish Kanitscheider, Tabarak Shirish Keskar, Logan Khan, Jong Wook Kilpatrick, Christina Kim, Yongjik Kim, Hendrik Kim, Jamie Kirchner, Matt Kiros, Daniel Knight, Łukasz Kokotajlo, Andrew Kondraciuk, Aris Kondrich, Kyle Konstantinidis, Gretchen Kosic, Vishal Krueger, Michael Kuo, Ikai Lampe, Teddy Lan, Jan Lee, Jade Leike, Daniel Leung, Levy, Ming Chak, Rachel Li, Molly Lim, Stephanie Lin, Mateusz Lin, Theresa Litwin, Ryan Lopez, Patricia Lowe, Anna Lue, Kim Makanju, Sam Malfacini, Todor Manning, Yaniv Markov, Bianca Markovski, Katie Martin, Andrew Mayer, Mayne ; Aalok, Jacob Mehta, Luke Menick, Andrey Metz, Pamela Mishchenko, Vinnie Mishkin, Evan Monaco, Daniel Morikawa, Tong Mossing, Mira Mu, Oleg Murati, David Murk, Ashvin Mély, Reiichiro Nair, Rajeev Nakano, Arvind Nayak, Richard Neelakantan, Hyeonwoo Ngo, Long Noh, Ouyang, O' Cullen, Jakub Keefe, Alex Pachocki, Joe Paino, Ashley Palermo, Daniel Pantuliano ; John Schulman, Kyla Selsam, Toki Sheppard, Jessica Sherbakov, Sarah Shieh, Pranav Shoker, Szymon Shyam, Eric Sidor, Maddie Sigler, Jordan Simens, Katarina Sitkin, Ian Slama, Benjamin Sohl, Yang Sokolowsky, ; Song, Wei, Akila Cj Weinmann, Peter Welihinda, Jiayi Welinder, Lilian Weng, Matt Weng, Dave Wiethoff, Clemens Willner, Samuel Winter, Hannah Wolrich, Lauren Wong, Sherwin Workman, Jeff Wu, Michael Wu, Kai Wu, Tao Xiao, Sarah Xu, Yoo, Adam Perelman, Filipe de Avila Belbute Peres. Michael Petrov, Henrique Ponde De Oliveira, Pinto, Michael, Michelle Pokorny, Vitchyr Pokrass, Tolly Pong, Alethea Powell, Boris Power, Elizabeth Power, Raul Proehl, Alec Puri, Jack Radford, Aditya Rae, Cameron Ramesh, Francis Raymond, Kendra Real, Carl Rimbach, Bob Ross, Henri Rotsted, Nick Roussez, Mario Ryder, Ted Saltarelli, Shibani Sanders, Girish Santurkar, Heather Sastry, David Schmidt, Schnurr, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina,; Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng; Natalie Staudacher; Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine Thompson, Phil Tillet; Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek; Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason; Kevin YuJuan Felipe Cerón UribeAndrea Vallone, Arun VijayvergiyaFelipe Petroski Such. Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2023. Gpt-4 technical report</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 2112020</p>
<p>Prospect: a system for screening candidates for recruitment. Amit Singh, Rose Catherine, Karthik Venkat Ramanan, Vijil Chenthamarakshan, Nanda Kambhatla, Proceedings of the 19th ACM international conference on Information and knowledge management. the 19th ACM international conference on Information and knowledge management2010a</p>
<p>Prospect: a system for screening candidates for recruitment. Amit Singh, Catherine Rose, Karthik Visweswariah, Nandakishore Vijil Chenthamarakshan, Kambhatla, Proceedings of the 19th ACM international conference on Information and knowledge management. the 19th ACM international conference on Information and knowledge management2010b</p>
<p>Modern information retrieval: A brief overview. Amit Singhal, IEEE Data Eng. Bull. 2442001</p>
<p>Resume screening using natural language processing and machine learning: A systematic review. Arvind Kumar Sinha, Md Amir Khusru, Ashwani Akhtar, Kumar, Machine Learning and Information Processing: Proceedings of ICMLIP 2020. 2021</p>
<p>Improved resume parsing based on contextual meaning extraction using bert. Ilya Sutskever, Oriol Vinyals, Quoc V Le, ; V Sushma Raj, Divya Deepak, Sai, Mallikarjuna, arXiv:2302.139712023 7th International Conference on Intelligent Computing and Control Systems (ICICCS). Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, 2014. 2023arXiv preprintFaisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023barXiv preprint</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. 201730</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Resume information extraction with cascaded hybrid model. Kun Yu, Gang Guan, Ming Zhou, Proceedings of the 43rd annual meeting of the Association for Computational Linguistics (ACL'05). the 43rd annual meeting of the Association for Computational Linguistics (ACL'05)2005</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Dong, arXiv:2303.18223A survey of large language models. 2023arXiv preprint</p>
<p>Resume information extraction with a novel text block segmentation algorithm. Shicheng Zu, Xiulai Wang, Int J Nat Lang Comput. 82019. 2019</p>            </div>
        </div>

    </div>
</body>
</html>