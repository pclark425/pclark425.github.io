<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5193 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5193</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5193</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-5041161</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1804.08299v1.pdf" target="_blank">Representational Issues in the Debate on the Standard Model of the Mind</a></p>
                <p><strong>Paper Abstract:</strong> In this paper we discuss some of the issues concerning the Memory and Content aspects in the recent debate on the identification of a Standard Model of the Mind (Laird, Lebiere, and Rosenbloom in press). In particular, we focus on the representational models concerning the Declarative Memories of current Cognitive Architectures (CAs). In doing so we outline some of the main problems affecting the current CAs and suggest that the Conceptual Spaces, a representational framework developed by Gardenfors, is worth-considering to address such problems. Finally, we briefly analyze the alternative representational assumptions employed in the three CAs constituting the current baseline for the Standard Model (i.e. SOAR, ACT-R and Sigma). In doing so, we point out the respective differences and discuss their implications in the light of the analyzed problems.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5193.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5193.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual Spaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Spaces (Gärdenfors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometrical, intermediate representational level between subsymbolic and symbolic formats where entities are points in a metric space of quality dimensions and concepts are convex regions; prototypes map to centroids and exemplars to points whose similarity is distance-based.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual spaces: The geometry of thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Conceptual Spaces</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents concepts as regions in a metric, multidimensional space whose dimensions correspond to quality/feature axes; prototypes are region centroids, exemplars are individual points, and similarity/typicality are functions of distance within the space.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>geometric / metric (intermediate between symbolic and subsymbolic)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>metric similarity, convex-concept regions, prototypes as centroids, exemplars as points, supports continuous trajectories for object identity over time, interpretable mapping to perceptual dimensions</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites psychological findings about prototypes and exemplars that naturally map to geometric interpretations; cites applications across perception, robotics and QA and system implementations (e.g., DUAL PECCS) that operationalize conceptual spaces for categorization and integration with ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper acknowledges the difficulty of producing wide-coverage Conceptual Spaces KBs comparable in size to large ontologies and notes open gaps in scaling automatic learning of spaces; some neural/connectionist mappings remain interpretative rather than direct empirical demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization (prototype and exemplar-based), concept combination (composition), perceptual anchoring, robotic perception, question answering, integrating with ontologies for symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Presented as unifying between symbolic (logical) and subsymbolic (neural) approaches by providing interpretable geometric layer; better at encoding typicality and prototype phenomena than strict symbolic/classical approaches and more interpretable than opaque connectionist hidden layers.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity computed as metric distance; prototypes used via centroid distances, exemplars as nearest-point comparisons; concepts correspond to convex regions enabling membership and typicality; temporal changes modeled as trajectories in space enabling identity tracking and interpolation/extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Scaling to wide-coverage KBs remains incomplete; practical integration/harmonization of conceptual spaces with large symbolic ontologies and heterogeneous reasoning processes needs further work; how best to learn high-dimensional quality dimensions from data at scale is open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5193.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype-based representation / Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where concepts are organized around prototypical feature clusters; categorization uses similarity to a prototype rather than necessary-and-sufficient conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The big book of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented functionally by a prototype (an idealized central tendency of features); category membership and typicality are determined by similarity between stimulus and prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype / feature-central tendency</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>graded membership, typicality effects, similarity-based categorization, non-binary membership, naturally geometric when mapped to conceptual spaces (prototypes as centroids).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Psychological literature documents typicality effects and prototype-based categorization; the paper references standard cognitive science findings and systems (e.g., mappings in Conceptual Spaces and DUAL PECCS) that model prototype behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Fails to account for certain compositionality phenomena (pet fish example) and cannot straightforwardly produce compositional prototypes from component prototypes (cited via Fodor 1981 and Osherson & Smith 1981); exemplar 'old-item advantage' effects sometimes favor exemplar representations over prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, concept learning, modeling typicality judgments, integration with conceptual spaces for geometric prototype interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with exemplar and classical/symbolic theories; easier to model typicality than classical symbolic rules but weaker for compositional semantics unless augmented (e.g., via conceptual spaces).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Compute similarity between stimulus and prototype center to produce graded category membership and typicality-driven inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Handling compositionality/combination of prototypes and interaction with rule-based/classical representations remains problematic without intermediate geometric or hybrid mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5193.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar-based representation / Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where concepts are collections of stored individual exemplars and categorization proceeds by similarity comparisons to these exemplars rather than to an abstract prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The big book of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is functionally stored as individual exemplars (instances); categorization chooses category based on similarity to nearest exemplars or aggregation of exemplar similarities.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar / instance-based (point set in similarity space)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>instance-based similarity comparisons, supports memory effects (e.g., old-item advantage), flexible with exceptions, naturally represented as points in conceptual spaces with distance metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites cognitive evidence where exemplar judgments (e.g., old-item advantage) predict human classification behavior; systems (e.g., DUAL PECCS) model exemplar processes in conceptual spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>May be computationally demanding for large numbers of exemplars; does not by itself explain generalization as compactly as prototypes; integration with symbolic/classical reasoning is nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization, modeling memory effects in classification, tasks where instance similarity dominates decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Complementary/competing with prototype theory; the paper advocates heterogeneous approaches that allow both prototypes and exemplars to coexist and interact.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity-based retrieval of stored exemplars and aggregation or nearest-neighbor decision rules to yield categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to harmonize exemplar processes with prototype and rule-based processes for the same concept and how to scale exemplar storage and retrieval in architectures remain open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5193.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A view that concepts are structured like mini-theories: complex mental structures encoding causal, explanatory, and domain knowledge supporting typicality and category judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The big book of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Proposes that conceptual knowledge is organized as theory-like networks of causal and explanatory relations rather than mere feature lists; typicality arises from explanatory relations and domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>theory-structured / causal-explanatory / relational</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>causal/explanatory structure, context-sensitive, supports richer inferences beyond similarity, encodes domain rules and experience-based knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper references psychological literature (Murphy) that motivates theory-theory as explaining typicality effects not reducible to feature similarity; suggests potential alignment with graphical-model style representations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Integration with similarity-based prototype/exemplar accounts is nontrivial; implementing full theory-like structures in current CAs is difficult and not widely operationalized.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Explaining causal and explanatory judgments, concept learning where causal structure matters, reasoning about functions and capacities.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Unlike prototype/exemplar models which use similarity, theory-theory emphasizes causal/explanatory relations; Sigma's graphical models might align with theory-theory representations in principle according to the paper but integration is not yet realized.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Inference via causal/explanatory links, use of experience-based rules to determine category membership and typicality.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to efficiently encode and integrate theory-like structures with prototype/exemplar processes and symbolic ontologies in cognitive architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5193.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical / Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical (symbolic) theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational format where concepts are defined by explicit necessary and sufficient conditions (features/rules); reasoning is rule-based and compositional.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Representing concepts in formal ontologies: Compositionality vs. typicality effects</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Classical (symbolic) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are defined extensionally/intensionally by symbolic predicates or rules specifying necessary and sufficient conditions; reasoning is logical and compositional.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / rule-based / logical</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>compositionality, syntactic generativity, explicit logical structure, clear inference rules, supports symbolic reasoning over categories</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Well-suited to tasks that require rule-like, compositional reasoning and explicit taxonomy (ontologies); widely used in knowledge bases and CAs for classical conceptual information.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Cannot naturally capture typicality/graded membership effects observed in human cognition (prototype/exemplar phenomena) and struggles with compositional typicality (pet fish problem) without augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Ontologies, semantic web, logic-based inference, tasks requiring compositional symbolic manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Stronger for compositional and generative tasks relative to prototype/exemplar models but weaker at modeling typicality and similarity-based human judgments; Conceptual Spaces proposed as an intermediate layer to reconcile them.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Rule application and symbolic inference, taxonomic classification via necessary/sufficient feature checks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to incorporate graded, typicality-based reasoning and non-monotonic/case-based effects within purely symbolic frameworks remains unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5193.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Connectionist / Subsymbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Connectionist / subsymbolic (neural network) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Distributed representations encoded in neural-network-style units and weights, well suited for perceptual processing but often opaque in functional interpretation and criticized for limited compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Connectionism and cognitive architecture: A critical analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Connectionist / subsymbolic representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are encoded in patterns of activation across distributed units; processing is emergent from network dynamics rather than explicit symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed / subsymbolic / connectionist</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>robust perceptual mapping, graceful degradation, learning from data, distributed encoding, typically opaque internal representations</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Strong performance in perceptual tasks and machine learning; frequently used within CAs for perception modules; mappings to Conceptual Spaces (e.g., RBF units as prototypes) have been proposed to make representations more interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Criticized for limited systematic compositionality (Fodor & Pylyshyn 1988), opacity of hidden layers makes conceptual-level interpretation difficult, and pure connectionist models struggle to capture symbolic compositionality without hybrid mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perceptual classification, pattern recognition, feature extraction in CAs; when interpreted via Conceptual Spaces, used for prototype/exemplar-style categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Complementary to symbolic approaches: good at perception and pattern learning, weak at explicit symbolic compositionality; Conceptual Spaces proposed as an interpretative bridge to render connectionist hidden representations more semantically transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Activation dynamics, similarity via RBF/prototype units interpreted as centroids, retrieval via activation similarity; when hybridized, symbolic rules can be invoked on top of learned representations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to achieve robust compositionality and transparent high-level concept formation within purely connectionist frameworks without hybridization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5193.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heterogeneous representational stance</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heterogeneous representational stance / Heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The approach that a single concept is represented by multiple coexisting representational formats (prototypes, exemplars, symbolic frames, theories), each with its own reasoning mechanism, requiring integration/harmonization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Heterogeneous representational stance (heterogeneous proxytypes)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functionally, concepts are multi-representational: different types of knowledge (prototype, exemplar, symbolic frame, theory-like structures) coexist and are used by different reasoning processes; the architecture must coordinate which representation and process is active.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>hybrid / multi-representational (prototype, exemplar, symbolic, theory-like)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>coexistence of multiple representations, dedicated reasoning mechanisms per representation type, need for harmonization and control to choose appropriate mechanism, supports diverse cognitive phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites cognitive findings showing both prototype and exemplar effects and references implemented systems (e.g., DUAL PECCS) that couple conceptual spaces and ontologies to operationalize heterogeneous handling.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Designing mechanisms to integrate and arbitrate among heterogeneous representations and their reasoning processes is largely unsolved and highlighted as a major open problem for CAs.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Common-sense categorization, tasks exhibiting mixed typicality and rule-based behavior, dual-process reasoning scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Synthesizes strengths of prototype, exemplar, symbolic and theory-theory accounts by allowing them to coexist, at the cost of added complexity in integration relative to single-format models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Multiple parallel representations linked to different retrieval/decision procedures; interaction protocols (as in DUAL PECCS) mediate whether prototype, exemplar or symbolic inference is used for a given task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to implement scalable, autonomous arbitration and harmonization among representations; how to learn and synchronize representations across formats remains open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5193.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chorus of Prototypes / RBF interpretation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chorus of Prototypes / RBF-network interpretation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An interpretation that neural network units (e.g., RBF units) can act as prototypes in a conceptual space, enabling similarity-based retrieval and interpretation of hidden-layer representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Representation, similarity, and the chorus of prototypes</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Chorus of Prototypes / RBF interpretation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional claim that units in radial-basis-function (RBF) networks correspond to prototype exemplars in a conceptual space; similarity to inputs is computed via distance to unit-centers enabling prototype-like categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype-as-unit mapping within connectionist / geometric framework</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>interpretable mapping of network units to prototypes, distance-based similarity, supports handling of chimeric/ambiguous stimuli, bridges neural networks and conceptual spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper references Balkenius & Gärdenfors (2016) and Edelman's chorus of prototypes as formal interpretations mapping RBF networks to conceptual-space dimensions and prototypes, offering interpretability for NN hidden layers.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Interpretation is conceptual and modeling-based rather than direct empirical proof that biological networks implement such mappings; granularity and learning of appropriate prototype units at scale remain to be shown.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perceptual categorization, modeling ambiguous/chimeric stimuli, interpreting hidden representations in neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides interpretability advantages over opaque connectionist hidden layers and connects to explicit prototype/exemplar models via geometric semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Prototype-like units respond to inputs by distance activation; category decisions derive from relative activations across prototype units.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Extent to which real biological networks instantiate RBF-like prototype units and how to derive or learn such units in large-scale systems are open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5193.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Diagrammatic / picture-like</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diagrammatic / picture-like (analog) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representational family where mental representations are picture-like or spatially analogous to what they represent, useful for spatial reasoning and identity tracking via trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Diagrammatic reasoning: Cognitive and computational perspectives</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Diagrammatic / picture-like representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts and situations can be represented as spatial/analog structures that resemble their referents; reasoning proceeds by manipulating these picture-like representations rather than purely symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>diagrammatic / analog / picture-like</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>spatial resemblance, supports identity tracking via trajectories, useful for spatial and dynamic scenarios, intuitive mapping to perceptual spaces</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites prior work in diagrammatic reasoning and argues conceptual spaces can unify many picture-like representations and support identity-tracking by representing objects as trajectories in space indexed by time.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Diagrammatic representations lack a single general theory and are heterogeneous; integrating them with symbolic and subsymbolic systems in CAs is underdeveloped.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Spatial reasoning, visual imagery, tracking object identity through occlusion (interpolation of trajectories), robotics and perceptual anchoring.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Conceptual Spaces can provide a principled geometric framework to subsume many diagrammatic representations, offering more theory than ad-hoc picture-like schemes.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Manipulation of spatial/analog structures; modeling objects as temporal trajectories in conceptual spaces for interpolation/extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Heterogeneity and lack of unified theory; practical integration with symbolic reasoning and learning remains incomplete.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5193.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ACT-R representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ACT-R declarative/subsymbolic representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ACT-R encodes declarative knowledge as symbolic chunks (type + attribute-value pairs) with subsymbolic activation values guiding retrieval; supports prototype and exemplar processes but requires manual selection between them.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An integrated theory of the mind</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>ACT-R hybrid symbolic/subsymbolic representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Declarative knowledge is stored as symbolic chunks; retrieval is guided by subsymbolic activations, enabling graded access and probabilistic retrieval; prototype/exemplar strategies can be represented but are not automatically integrated.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>hybrid symbolic with subsymbolic activation (chunk-based)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>symbolic chunk structure, subsymbolic activation-based retrieval, supports both exemplar and prototype implementations (manually specified), connection to procedural production rules</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>ACT-R is explicitly inspired by human cognition and has been used to model a wide range of cognitive phenomena; the paper cites efforts to extend its declarative memory with large KBs (e.g., DBpedia, Cyc) and experiments using exemplar/prototype processes.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Does not natively integrate multiple heterogeneous representations for the same concept or autonomously arbitrate which categorization mechanism (prototype vs exemplar) to use; extensions to scale declarative memory to general world knowledge are ongoing but incomplete.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Modeling human cognition tasks, categorization, memory retrieval, language comprehension, extended to integrate external KBs in some projects.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More cognitively grounded than purely symbolic SOAR on some subsymbolic points and more symbolic than purely connectionist approaches; lacks the built-in heterogeneous multi-representation coordination proposed by Conceptual Spaces + heterogeneous stance.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Production system fires based on matching chunks whose retrieval is modulated by subsymbolic activation values; modeler can implement prototype or exemplar-based decision rules.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to autonomously choose and harmonize multiple common-sense categorization mechanisms and how to scale declarative memory with heterogeneous representation types.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5193.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SOAR representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SOAR symbolic chunk-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SOAR represents declarative knowledge as symbolic chunks in semantic memory and uses production rules for problem-solving; it tends to assume a monolithic conceptual structure and lacks an integrated model for typicality-based representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Soar cognitive architecture</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>SOAR symbolic chunk representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are functionally encoded as symbolic chunks (frames) accessed via pattern matching and production rules; spreading activation mechanisms may be used for retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic / chunk-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>explicit symbolic frames/chunks, production-rule reasoning, potential spreading activation for retrieval, suited for classical logical representations</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>SOAR has been used as a general cognitive architecture and supports visual imagery modules; paper cites extensions to integrate lexical resources (e.g., WordNet) and acknowledges SOAR's historical role in unified cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Does not specify how to integrate typicality-based representations (prototypes/exemplars) with symbolic chunks, leading to inability to handle heterogeneous conceptual knowledge in an integrated way; limited general cross-domain knowledge is noted.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Problem solving via search in problem spaces, symbolic reasoning, cognitive modeling where rule-based manipulation is central.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More purely symbolic than ACT-R and Sigma; weaker at modeling typicality and heterogeneous common-sense representations compared to Conceptual Spaces approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Production-rule firing based on pattern matching over symbolic chunks; selection of operators/search over problem spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to model and integrate prototype/exemplar reasoning and other typicality effects within SOAR's symbolic framework remains unresolved.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5193.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sigma representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sigma (graphical model / factor graph based) representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sigma grounds memory and processing in graphical models (factor graphs) where relations are weighted and statistical computations support approximate reasoning; it promises efficient approximate inference but currently lacks integrated typicality mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Sigma graphical-model (factor graph) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents knowledge functionally as factor-graph based graphical models with weighted relations enabling probabilistic/approximate inference across components of memory and perception.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>graphical models / probabilistic / weighted symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>weighted relations, efficient approximate inference, unifying substrate for multiple components (memory, perception), statistical computations for relation strengths</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper notes Sigma's grounding in graphical models and its theoretical capacity for approximate reasoning; suggests potential alignment with theory-theory style representations due to graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Currently not equipped for large-scale KB integration or for handling typicality-based heterogeneous reasoning (prototype/exemplar) in an integrated way, according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Approximate reasoning tasks, architectures aiming at unifying mechanisms via factor graphs, potential common-sense reasoning where probabilistic weights help.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Sigma lies between symbolic and probabilistic approaches, potentially capturing aspects of theory-theory via graphs; unlike Conceptual Spaces, it does not naturally represent geometric typicality unless augmented.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Message passing and factor graph inference compute marginal/most-likely configurations; relations represented as weighted factors shape inference.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to incorporate typicality-based conceptual processes and integrate with large symbolic KBs; empirical evaluation of heterogeneous concept handling is pending.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e5193.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DUAL PECCS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DUAL PECCS (Dual Process PECCS system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational system that couples Conceptual Spaces representations for prototype/exemplar processes with symbolic ontologies to enable interaction between common-sense and classical categorization mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dual peccs: a cognitive system for conceptual representation and categorization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>DUAL PECCS hybrid categorization system</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Implements heterogeneous representation by using Conceptual Spaces to model prototype/exemplar categorization and ontological symbolic systems for classical deductive categorization, and provides explicit interaction mechanisms between them.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>hybrid (conceptual spaces + symbolic ontologies)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>explicit coupling of prototype/exemplar processes with symbolic deduction, operational mechanisms for interaction, demonstrates feasibility of heterogeneous stance in practice</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Paper cites DUAL PECCS as an implemented system integrated with ACT-R and CLARION and shows that it can model interplay between prototype/exemplar categorization and classical ontology-based reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Scaling to very large KBs and fully autonomous arbitration among heterogeneous processes remain open; DUAL PECCS demonstrates approach rather than solving all integration problems.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Common-sense conceptual categorization, integration with cognitive architectures for reasoning tasks, experiments modeling typicality vs rule-based categorization interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides an operational instantiation of the heterogeneous stance and is presented as more capable than pure symbolic or pure prototype/exemplar systems for integrated categorization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Runs prototype and exemplar similarity-based categorization in conceptual spaces and triggers symbolic deductive classification on ontological representations, with interaction protocols to reconcile outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Generalization to wide-coverage KB scales and automating arbitration among multiple reasoning strategies are open research directions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5193.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e5193.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pet-fish / compositionality problem</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Compositionality vs typicality (pet fish example)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A well-known problem showing prototypes are not straightforwardly compositional: the prototype of a composed concept (pet fish) does not derive from composition of component prototypes (pet, fish).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The present status of the innateness controversy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Compositionality vs. typicality challenge</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Functional critique: prototype representations fail to compose predictively (pet fish's typical features differ from those of pet and fish prototypes), highlighting tension between generativity/compositionality and typicality-based representation.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>argument about limitations of prototype representation (conceptual/compositional issue)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>illustrates non-compositionality of prototypes, motivates need for hybrid or intermediate representational layers</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Psychological observations and thought experiments (pet fish) motivate the empirical phenomenon and theoretical critique; cited classical literature (Fodor 1981, Osherson & Smith 1981).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Demonstrates empirical mismatch between prototype-based predictions and observed conceptual composition behavior; challenge motivates Conceptual Spaces and hierarchical approaches as potential solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Concept combination, metaphor, creativity, compositional semantics tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Used to argue that pure prototype models are insufficient and must be augmented (e.g., with conceptual spaces or hybrid symbolic mechanisms) to support compositional generativity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Not a mechanism but a diagnostic challenge: composition of feature-centroid representations does not yield correct composed prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to systematically derive composed concept representations that capture typicality effects while preserving compositionality remains an active research problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Representational Issues in the Debate on the Standard Model of the Mind', 'publication_date_yy_mm': '2018-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conceptual spaces: The geometry of thought <em>(Rating: 2)</em></li>
                <li>The big book of concepts <em>(Rating: 2)</em></li>
                <li>Representation, similarity, and the chorus of prototypes <em>(Rating: 2)</em></li>
                <li>Dual peccs: a cognitive system for conceptual representation and categorization <em>(Rating: 2)</em></li>
                <li>An integrated theory of the mind <em>(Rating: 2)</em></li>
                <li>A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes <em>(Rating: 2)</em></li>
                <li>Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs <em>(Rating: 1)</em></li>
                <li>Connectionism and cognitive architecture: A critical analysis <em>(Rating: 1)</em></li>
                <li>On the adequacy of prototype theory as a theory of concepts <em>(Rating: 1)</em></li>
                <li>Spaces in the brain: From neurons to meanings <em>(Rating: 1)</em></li>
                <li>Diagrammatic reasoning: Cognitive and computational perspectives <em>(Rating: 1)</em></li>
                <li>Cliques of neurons bound into cavities provide a missing link between structure and function <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5193",
    "paper_id": "paper-5041161",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Conceptual Spaces",
            "name_full": "Conceptual Spaces (Gärdenfors)",
            "brief_description": "A geometrical, intermediate representational level between subsymbolic and symbolic formats where entities are points in a metric space of quality dimensions and concepts are convex regions; prototypes map to centroids and exemplars to points whose similarity is distance-based.",
            "citation_title": "Conceptual spaces: The geometry of thought",
            "mention_or_use": "use",
            "theory_or_model_name": "Conceptual Spaces",
            "theory_or_model_description": "Represents concepts as regions in a metric, multidimensional space whose dimensions correspond to quality/feature axes; prototypes are region centroids, exemplars are individual points, and similarity/typicality are functions of distance within the space.",
            "representation_format_type": "geometric / metric (intermediate between symbolic and subsymbolic)",
            "key_properties": "metric similarity, convex-concept regions, prototypes as centroids, exemplars as points, supports continuous trajectories for object identity over time, interpretable mapping to perceptual dimensions",
            "empirical_support": "Paper cites psychological findings about prototypes and exemplars that naturally map to geometric interpretations; cites applications across perception, robotics and QA and system implementations (e.g., DUAL PECCS) that operationalize conceptual spaces for categorization and integration with ontologies.",
            "empirical_challenges": "Paper acknowledges the difficulty of producing wide-coverage Conceptual Spaces KBs comparable in size to large ontologies and notes open gaps in scaling automatic learning of spaces; some neural/connectionist mappings remain interpretative rather than direct empirical demonstrations.",
            "applied_domains_or_tasks": "Categorization (prototype and exemplar-based), concept combination (composition), perceptual anchoring, robotic perception, question answering, integrating with ontologies for symbolic reasoning.",
            "comparison_to_other_models": "Presented as unifying between symbolic (logical) and subsymbolic (neural) approaches by providing interpretable geometric layer; better at encoding typicality and prototype phenomena than strict symbolic/classical approaches and more interpretable than opaque connectionist hidden layers.",
            "functional_mechanisms": "Similarity computed as metric distance; prototypes used via centroid distances, exemplars as nearest-point comparisons; concepts correspond to convex regions enabling membership and typicality; temporal changes modeled as trajectories in space enabling identity tracking and interpolation/extrapolation.",
            "limitations_or_open_questions": "Scaling to wide-coverage KBs remains incomplete; practical integration/harmonization of conceptual spaces with large symbolic ontologies and heterogeneous reasoning processes needs further work; how best to learn high-dimensional quality dimensions from data at scale is open.",
            "uuid": "e5193.0",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype-based representation / Prototype theory",
            "brief_description": "A representational format where concepts are organized around prototypical feature clusters; categorization uses similarity to a prototype rather than necessary-and-sufficient conditions.",
            "citation_title": "The big book of concepts",
            "mention_or_use": "mention",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Concepts are represented functionally by a prototype (an idealized central tendency of features); category membership and typicality are determined by similarity between stimulus and prototype.",
            "representation_format_type": "prototype / feature-central tendency",
            "key_properties": "graded membership, typicality effects, similarity-based categorization, non-binary membership, naturally geometric when mapped to conceptual spaces (prototypes as centroids).",
            "empirical_support": "Psychological literature documents typicality effects and prototype-based categorization; the paper references standard cognitive science findings and systems (e.g., mappings in Conceptual Spaces and DUAL PECCS) that model prototype behavior.",
            "empirical_challenges": "Fails to account for certain compositionality phenomena (pet fish example) and cannot straightforwardly produce compositional prototypes from component prototypes (cited via Fodor 1981 and Osherson & Smith 1981); exemplar 'old-item advantage' effects sometimes favor exemplar representations over prototypes.",
            "applied_domains_or_tasks": "Categorization, concept learning, modeling typicality judgments, integration with conceptual spaces for geometric prototype interpretation.",
            "comparison_to_other_models": "Contrasted with exemplar and classical/symbolic theories; easier to model typicality than classical symbolic rules but weaker for compositional semantics unless augmented (e.g., via conceptual spaces).",
            "functional_mechanisms": "Compute similarity between stimulus and prototype center to produce graded category membership and typicality-driven inferences.",
            "limitations_or_open_questions": "Handling compositionality/combination of prototypes and interaction with rule-based/classical representations remains problematic without intermediate geometric or hybrid mechanisms.",
            "uuid": "e5193.1",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Exemplar model",
            "name_full": "Exemplar-based representation / Exemplar theory",
            "brief_description": "A representational format where concepts are collections of stored individual exemplars and categorization proceeds by similarity comparisons to these exemplars rather than to an abstract prototype.",
            "citation_title": "The big book of concepts",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar model",
            "theory_or_model_description": "Conceptual knowledge is functionally stored as individual exemplars (instances); categorization chooses category based on similarity to nearest exemplars or aggregation of exemplar similarities.",
            "representation_format_type": "exemplar / instance-based (point set in similarity space)",
            "key_properties": "instance-based similarity comparisons, supports memory effects (e.g., old-item advantage), flexible with exceptions, naturally represented as points in conceptual spaces with distance metrics.",
            "empirical_support": "Paper cites cognitive evidence where exemplar judgments (e.g., old-item advantage) predict human classification behavior; systems (e.g., DUAL PECCS) model exemplar processes in conceptual spaces.",
            "empirical_challenges": "May be computationally demanding for large numbers of exemplars; does not by itself explain generalization as compactly as prototypes; integration with symbolic/classical reasoning is nontrivial.",
            "applied_domains_or_tasks": "Categorization, modeling memory effects in classification, tasks where instance similarity dominates decisions.",
            "comparison_to_other_models": "Complementary/competing with prototype theory; the paper advocates heterogeneous approaches that allow both prototypes and exemplars to coexist and interact.",
            "functional_mechanisms": "Similarity-based retrieval of stored exemplars and aggregation or nearest-neighbor decision rules to yield categorization.",
            "limitations_or_open_questions": "How to harmonize exemplar processes with prototype and rule-based processes for the same concept and how to scale exemplar storage and retrieval in architectures remain open.",
            "uuid": "e5193.2",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Theory-theory",
            "name_full": "Theory-theory of concepts",
            "brief_description": "A view that concepts are structured like mini-theories: complex mental structures encoding causal, explanatory, and domain knowledge supporting typicality and category judgments.",
            "citation_title": "The big book of concepts",
            "mention_or_use": "mention",
            "theory_or_model_name": "Theory-theory",
            "theory_or_model_description": "Proposes that conceptual knowledge is organized as theory-like networks of causal and explanatory relations rather than mere feature lists; typicality arises from explanatory relations and domain knowledge.",
            "representation_format_type": "theory-structured / causal-explanatory / relational",
            "key_properties": "causal/explanatory structure, context-sensitive, supports richer inferences beyond similarity, encodes domain rules and experience-based knowledge",
            "empirical_support": "Paper references psychological literature (Murphy) that motivates theory-theory as explaining typicality effects not reducible to feature similarity; suggests potential alignment with graphical-model style representations.",
            "empirical_challenges": "Integration with similarity-based prototype/exemplar accounts is nontrivial; implementing full theory-like structures in current CAs is difficult and not widely operationalized.",
            "applied_domains_or_tasks": "Explaining causal and explanatory judgments, concept learning where causal structure matters, reasoning about functions and capacities.",
            "comparison_to_other_models": "Unlike prototype/exemplar models which use similarity, theory-theory emphasizes causal/explanatory relations; Sigma's graphical models might align with theory-theory representations in principle according to the paper but integration is not yet realized.",
            "functional_mechanisms": "Inference via causal/explanatory links, use of experience-based rules to determine category membership and typicality.",
            "limitations_or_open_questions": "How to efficiently encode and integrate theory-like structures with prototype/exemplar processes and symbolic ontologies in cognitive architectures.",
            "uuid": "e5193.3",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Classical / Symbolic",
            "name_full": "Classical (symbolic) theory of concepts",
            "brief_description": "A representational format where concepts are defined by explicit necessary and sufficient conditions (features/rules); reasoning is rule-based and compositional.",
            "citation_title": "Representing concepts in formal ontologies: Compositionality vs. typicality effects",
            "mention_or_use": "mention",
            "theory_or_model_name": "Classical (symbolic) representation",
            "theory_or_model_description": "Concepts are defined extensionally/intensionally by symbolic predicates or rules specifying necessary and sufficient conditions; reasoning is logical and compositional.",
            "representation_format_type": "symbolic / rule-based / logical",
            "key_properties": "compositionality, syntactic generativity, explicit logical structure, clear inference rules, supports symbolic reasoning over categories",
            "empirical_support": "Well-suited to tasks that require rule-like, compositional reasoning and explicit taxonomy (ontologies); widely used in knowledge bases and CAs for classical conceptual information.",
            "empirical_challenges": "Cannot naturally capture typicality/graded membership effects observed in human cognition (prototype/exemplar phenomena) and struggles with compositional typicality (pet fish problem) without augmentation.",
            "applied_domains_or_tasks": "Ontologies, semantic web, logic-based inference, tasks requiring compositional symbolic manipulation.",
            "comparison_to_other_models": "Stronger for compositional and generative tasks relative to prototype/exemplar models but weaker at modeling typicality and similarity-based human judgments; Conceptual Spaces proposed as an intermediate layer to reconcile them.",
            "functional_mechanisms": "Rule application and symbolic inference, taxonomic classification via necessary/sufficient feature checks.",
            "limitations_or_open_questions": "How to incorporate graded, typicality-based reasoning and non-monotonic/case-based effects within purely symbolic frameworks remains unresolved.",
            "uuid": "e5193.4",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Connectionist / Subsymbolic",
            "name_full": "Connectionist / subsymbolic (neural network) representations",
            "brief_description": "Distributed representations encoded in neural-network-style units and weights, well suited for perceptual processing but often opaque in functional interpretation and criticized for limited compositionality.",
            "citation_title": "Connectionism and cognitive architecture: A critical analysis",
            "mention_or_use": "mention",
            "theory_or_model_name": "Connectionist / subsymbolic representations",
            "theory_or_model_description": "Concepts are encoded in patterns of activation across distributed units; processing is emergent from network dynamics rather than explicit symbolic rules.",
            "representation_format_type": "distributed / subsymbolic / connectionist",
            "key_properties": "robust perceptual mapping, graceful degradation, learning from data, distributed encoding, typically opaque internal representations",
            "empirical_support": "Strong performance in perceptual tasks and machine learning; frequently used within CAs for perception modules; mappings to Conceptual Spaces (e.g., RBF units as prototypes) have been proposed to make representations more interpretable.",
            "empirical_challenges": "Criticized for limited systematic compositionality (Fodor & Pylyshyn 1988), opacity of hidden layers makes conceptual-level interpretation difficult, and pure connectionist models struggle to capture symbolic compositionality without hybrid mechanisms.",
            "applied_domains_or_tasks": "Perceptual classification, pattern recognition, feature extraction in CAs; when interpreted via Conceptual Spaces, used for prototype/exemplar-style categorization.",
            "comparison_to_other_models": "Complementary to symbolic approaches: good at perception and pattern learning, weak at explicit symbolic compositionality; Conceptual Spaces proposed as an interpretative bridge to render connectionist hidden representations more semantically transparent.",
            "functional_mechanisms": "Activation dynamics, similarity via RBF/prototype units interpreted as centroids, retrieval via activation similarity; when hybridized, symbolic rules can be invoked on top of learned representations.",
            "limitations_or_open_questions": "How to achieve robust compositionality and transparent high-level concept formation within purely connectionist frameworks without hybridization.",
            "uuid": "e5193.5",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Heterogeneous representational stance",
            "name_full": "Heterogeneous representational stance / Heterogeneous proxytypes",
            "brief_description": "The approach that a single concept is represented by multiple coexisting representational formats (prototypes, exemplars, symbolic frames, theories), each with its own reasoning mechanism, requiring integration/harmonization.",
            "citation_title": "A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes",
            "mention_or_use": "use",
            "theory_or_model_name": "Heterogeneous representational stance (heterogeneous proxytypes)",
            "theory_or_model_description": "Functionally, concepts are multi-representational: different types of knowledge (prototype, exemplar, symbolic frame, theory-like structures) coexist and are used by different reasoning processes; the architecture must coordinate which representation and process is active.",
            "representation_format_type": "hybrid / multi-representational (prototype, exemplar, symbolic, theory-like)",
            "key_properties": "coexistence of multiple representations, dedicated reasoning mechanisms per representation type, need for harmonization and control to choose appropriate mechanism, supports diverse cognitive phenomena.",
            "empirical_support": "Paper cites cognitive findings showing both prototype and exemplar effects and references implemented systems (e.g., DUAL PECCS) that couple conceptual spaces and ontologies to operationalize heterogeneous handling.",
            "empirical_challenges": "Designing mechanisms to integrate and arbitrate among heterogeneous representations and their reasoning processes is largely unsolved and highlighted as a major open problem for CAs.",
            "applied_domains_or_tasks": "Common-sense categorization, tasks exhibiting mixed typicality and rule-based behavior, dual-process reasoning scenarios.",
            "comparison_to_other_models": "Synthesizes strengths of prototype, exemplar, symbolic and theory-theory accounts by allowing them to coexist, at the cost of added complexity in integration relative to single-format models.",
            "functional_mechanisms": "Multiple parallel representations linked to different retrieval/decision procedures; interaction protocols (as in DUAL PECCS) mediate whether prototype, exemplar or symbolic inference is used for a given task.",
            "limitations_or_open_questions": "How to implement scalable, autonomous arbitration and harmonization among representations; how to learn and synchronize representations across formats remains open.",
            "uuid": "e5193.6",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Chorus of Prototypes / RBF interpretation",
            "name_full": "Chorus of Prototypes / RBF-network interpretation",
            "brief_description": "An interpretation that neural network units (e.g., RBF units) can act as prototypes in a conceptual space, enabling similarity-based retrieval and interpretation of hidden-layer representations.",
            "citation_title": "Representation, similarity, and the chorus of prototypes",
            "mention_or_use": "mention",
            "theory_or_model_name": "Chorus of Prototypes / RBF interpretation",
            "theory_or_model_description": "Functional claim that units in radial-basis-function (RBF) networks correspond to prototype exemplars in a conceptual space; similarity to inputs is computed via distance to unit-centers enabling prototype-like categorization.",
            "representation_format_type": "prototype-as-unit mapping within connectionist / geometric framework",
            "key_properties": "interpretable mapping of network units to prototypes, distance-based similarity, supports handling of chimeric/ambiguous stimuli, bridges neural networks and conceptual spaces.",
            "empirical_support": "Paper references Balkenius & Gärdenfors (2016) and Edelman's chorus of prototypes as formal interpretations mapping RBF networks to conceptual-space dimensions and prototypes, offering interpretability for NN hidden layers.",
            "empirical_challenges": "Interpretation is conceptual and modeling-based rather than direct empirical proof that biological networks implement such mappings; granularity and learning of appropriate prototype units at scale remain to be shown.",
            "applied_domains_or_tasks": "Perceptual categorization, modeling ambiguous/chimeric stimuli, interpreting hidden representations in neural networks.",
            "comparison_to_other_models": "Provides interpretability advantages over opaque connectionist hidden layers and connects to explicit prototype/exemplar models via geometric semantics.",
            "functional_mechanisms": "Prototype-like units respond to inputs by distance activation; category decisions derive from relative activations across prototype units.",
            "limitations_or_open_questions": "Extent to which real biological networks instantiate RBF-like prototype units and how to derive or learn such units in large-scale systems are open.",
            "uuid": "e5193.7",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Diagrammatic / picture-like",
            "name_full": "Diagrammatic / picture-like (analog) representations",
            "brief_description": "Representational family where mental representations are picture-like or spatially analogous to what they represent, useful for spatial reasoning and identity tracking via trajectories.",
            "citation_title": "Diagrammatic reasoning: Cognitive and computational perspectives",
            "mention_or_use": "mention",
            "theory_or_model_name": "Diagrammatic / picture-like representations",
            "theory_or_model_description": "Concepts and situations can be represented as spatial/analog structures that resemble their referents; reasoning proceeds by manipulating these picture-like representations rather than purely symbolic rules.",
            "representation_format_type": "diagrammatic / analog / picture-like",
            "key_properties": "spatial resemblance, supports identity tracking via trajectories, useful for spatial and dynamic scenarios, intuitive mapping to perceptual spaces",
            "empirical_support": "Paper cites prior work in diagrammatic reasoning and argues conceptual spaces can unify many picture-like representations and support identity-tracking by representing objects as trajectories in space indexed by time.",
            "empirical_challenges": "Diagrammatic representations lack a single general theory and are heterogeneous; integrating them with symbolic and subsymbolic systems in CAs is underdeveloped.",
            "applied_domains_or_tasks": "Spatial reasoning, visual imagery, tracking object identity through occlusion (interpolation of trajectories), robotics and perceptual anchoring.",
            "comparison_to_other_models": "Conceptual Spaces can provide a principled geometric framework to subsume many diagrammatic representations, offering more theory than ad-hoc picture-like schemes.",
            "functional_mechanisms": "Manipulation of spatial/analog structures; modeling objects as temporal trajectories in conceptual spaces for interpolation/extrapolation.",
            "limitations_or_open_questions": "Heterogeneity and lack of unified theory; practical integration with symbolic reasoning and learning remains incomplete.",
            "uuid": "e5193.8",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "ACT-R representation",
            "name_full": "ACT-R declarative/subsymbolic representations",
            "brief_description": "ACT-R encodes declarative knowledge as symbolic chunks (type + attribute-value pairs) with subsymbolic activation values guiding retrieval; supports prototype and exemplar processes but requires manual selection between them.",
            "citation_title": "An integrated theory of the mind",
            "mention_or_use": "mention",
            "theory_or_model_name": "ACT-R hybrid symbolic/subsymbolic representation",
            "theory_or_model_description": "Declarative knowledge is stored as symbolic chunks; retrieval is guided by subsymbolic activations, enabling graded access and probabilistic retrieval; prototype/exemplar strategies can be represented but are not automatically integrated.",
            "representation_format_type": "hybrid symbolic with subsymbolic activation (chunk-based)",
            "key_properties": "symbolic chunk structure, subsymbolic activation-based retrieval, supports both exemplar and prototype implementations (manually specified), connection to procedural production rules",
            "empirical_support": "ACT-R is explicitly inspired by human cognition and has been used to model a wide range of cognitive phenomena; the paper cites efforts to extend its declarative memory with large KBs (e.g., DBpedia, Cyc) and experiments using exemplar/prototype processes.",
            "empirical_challenges": "Does not natively integrate multiple heterogeneous representations for the same concept or autonomously arbitrate which categorization mechanism (prototype vs exemplar) to use; extensions to scale declarative memory to general world knowledge are ongoing but incomplete.",
            "applied_domains_or_tasks": "Modeling human cognition tasks, categorization, memory retrieval, language comprehension, extended to integrate external KBs in some projects.",
            "comparison_to_other_models": "More cognitively grounded than purely symbolic SOAR on some subsymbolic points and more symbolic than purely connectionist approaches; lacks the built-in heterogeneous multi-representation coordination proposed by Conceptual Spaces + heterogeneous stance.",
            "functional_mechanisms": "Production system fires based on matching chunks whose retrieval is modulated by subsymbolic activation values; modeler can implement prototype or exemplar-based decision rules.",
            "limitations_or_open_questions": "How to autonomously choose and harmonize multiple common-sense categorization mechanisms and how to scale declarative memory with heterogeneous representation types.",
            "uuid": "e5193.9",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "SOAR representation",
            "name_full": "SOAR symbolic chunk-based representation",
            "brief_description": "SOAR represents declarative knowledge as symbolic chunks in semantic memory and uses production rules for problem-solving; it tends to assume a monolithic conceptual structure and lacks an integrated model for typicality-based representations.",
            "citation_title": "The Soar cognitive architecture",
            "mention_or_use": "mention",
            "theory_or_model_name": "SOAR symbolic chunk representation",
            "theory_or_model_description": "Concepts are functionally encoded as symbolic chunks (frames) accessed via pattern matching and production rules; spreading activation mechanisms may be used for retrieval.",
            "representation_format_type": "symbolic / chunk-based",
            "key_properties": "explicit symbolic frames/chunks, production-rule reasoning, potential spreading activation for retrieval, suited for classical logical representations",
            "empirical_support": "SOAR has been used as a general cognitive architecture and supports visual imagery modules; paper cites extensions to integrate lexical resources (e.g., WordNet) and acknowledges SOAR's historical role in unified cognition.",
            "empirical_challenges": "Does not specify how to integrate typicality-based representations (prototypes/exemplars) with symbolic chunks, leading to inability to handle heterogeneous conceptual knowledge in an integrated way; limited general cross-domain knowledge is noted.",
            "applied_domains_or_tasks": "Problem solving via search in problem spaces, symbolic reasoning, cognitive modeling where rule-based manipulation is central.",
            "comparison_to_other_models": "More purely symbolic than ACT-R and Sigma; weaker at modeling typicality and heterogeneous common-sense representations compared to Conceptual Spaces approaches.",
            "functional_mechanisms": "Production-rule firing based on pattern matching over symbolic chunks; selection of operators/search over problem spaces.",
            "limitations_or_open_questions": "How to model and integrate prototype/exemplar reasoning and other typicality effects within SOAR's symbolic framework remains unresolved.",
            "uuid": "e5193.10",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Sigma representation",
            "name_full": "Sigma (graphical model / factor graph based) representation",
            "brief_description": "Sigma grounds memory and processing in graphical models (factor graphs) where relations are weighted and statistical computations support approximate reasoning; it promises efficient approximate inference but currently lacks integrated typicality mechanisms.",
            "citation_title": "Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs",
            "mention_or_use": "mention",
            "theory_or_model_name": "Sigma graphical-model (factor graph) representation",
            "theory_or_model_description": "Represents knowledge functionally as factor-graph based graphical models with weighted relations enabling probabilistic/approximate inference across components of memory and perception.",
            "representation_format_type": "graphical models / probabilistic / weighted symbolic",
            "key_properties": "weighted relations, efficient approximate inference, unifying substrate for multiple components (memory, perception), statistical computations for relation strengths",
            "empirical_support": "Paper notes Sigma's grounding in graphical models and its theoretical capacity for approximate reasoning; suggests potential alignment with theory-theory style representations due to graph structure.",
            "empirical_challenges": "Currently not equipped for large-scale KB integration or for handling typicality-based heterogeneous reasoning (prototype/exemplar) in an integrated way, according to the paper.",
            "applied_domains_or_tasks": "Approximate reasoning tasks, architectures aiming at unifying mechanisms via factor graphs, potential common-sense reasoning where probabilistic weights help.",
            "comparison_to_other_models": "Sigma lies between symbolic and probabilistic approaches, potentially capturing aspects of theory-theory via graphs; unlike Conceptual Spaces, it does not naturally represent geometric typicality unless augmented.",
            "functional_mechanisms": "Message passing and factor graph inference compute marginal/most-likely configurations; relations represented as weighted factors shape inference.",
            "limitations_or_open_questions": "How to incorporate typicality-based conceptual processes and integrate with large symbolic KBs; empirical evaluation of heterogeneous concept handling is pending.",
            "uuid": "e5193.11",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "DUAL PECCS",
            "name_full": "DUAL PECCS (Dual Process PECCS system)",
            "brief_description": "A computational system that couples Conceptual Spaces representations for prototype/exemplar processes with symbolic ontologies to enable interaction between common-sense and classical categorization mechanisms.",
            "citation_title": "Dual peccs: a cognitive system for conceptual representation and categorization",
            "mention_or_use": "mention",
            "theory_or_model_name": "DUAL PECCS hybrid categorization system",
            "theory_or_model_description": "Implements heterogeneous representation by using Conceptual Spaces to model prototype/exemplar categorization and ontological symbolic systems for classical deductive categorization, and provides explicit interaction mechanisms between them.",
            "representation_format_type": "hybrid (conceptual spaces + symbolic ontologies)",
            "key_properties": "explicit coupling of prototype/exemplar processes with symbolic deduction, operational mechanisms for interaction, demonstrates feasibility of heterogeneous stance in practice",
            "empirical_support": "Paper cites DUAL PECCS as an implemented system integrated with ACT-R and CLARION and shows that it can model interplay between prototype/exemplar categorization and classical ontology-based reasoning.",
            "empirical_challenges": "Scaling to very large KBs and fully autonomous arbitration among heterogeneous processes remain open; DUAL PECCS demonstrates approach rather than solving all integration problems.",
            "applied_domains_or_tasks": "Common-sense conceptual categorization, integration with cognitive architectures for reasoning tasks, experiments modeling typicality vs rule-based categorization interactions.",
            "comparison_to_other_models": "Provides an operational instantiation of the heterogeneous stance and is presented as more capable than pure symbolic or pure prototype/exemplar systems for integrated categorization tasks.",
            "functional_mechanisms": "Runs prototype and exemplar similarity-based categorization in conceptual spaces and triggers symbolic deductive classification on ontological representations, with interaction protocols to reconcile outputs.",
            "limitations_or_open_questions": "Generalization to wide-coverage KB scales and automating arbitration among multiple reasoning strategies are open research directions.",
            "uuid": "e5193.12",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        },
        {
            "name_short": "Pet-fish / compositionality problem",
            "name_full": "Compositionality vs typicality (pet fish example)",
            "brief_description": "A well-known problem showing prototypes are not straightforwardly compositional: the prototype of a composed concept (pet fish) does not derive from composition of component prototypes (pet, fish).",
            "citation_title": "The present status of the innateness controversy",
            "mention_or_use": "mention",
            "theory_or_model_name": "Compositionality vs. typicality challenge",
            "theory_or_model_description": "Functional critique: prototype representations fail to compose predictively (pet fish's typical features differ from those of pet and fish prototypes), highlighting tension between generativity/compositionality and typicality-based representation.",
            "representation_format_type": "argument about limitations of prototype representation (conceptual/compositional issue)",
            "key_properties": "illustrates non-compositionality of prototypes, motivates need for hybrid or intermediate representational layers",
            "empirical_support": "Psychological observations and thought experiments (pet fish) motivate the empirical phenomenon and theoretical critique; cited classical literature (Fodor 1981, Osherson & Smith 1981).",
            "empirical_challenges": "Demonstrates empirical mismatch between prototype-based predictions and observed conceptual composition behavior; challenge motivates Conceptual Spaces and hierarchical approaches as potential solutions.",
            "applied_domains_or_tasks": "Concept combination, metaphor, creativity, compositional semantics tasks.",
            "comparison_to_other_models": "Used to argue that pure prototype models are insufficient and must be augmented (e.g., with conceptual spaces or hybrid symbolic mechanisms) to support compositional generativity.",
            "functional_mechanisms": "Not a mechanism but a diagnostic challenge: composition of feature-centroid representations does not yield correct composed prototypes.",
            "limitations_or_open_questions": "How to systematically derive composed concept representations that capture typicality effects while preserving compositionality remains an active research problem.",
            "uuid": "e5193.13",
            "source_info": {
                "paper_title": "Representational Issues in the Debate on the Standard Model of the Mind",
                "publication_date_yy_mm": "2018-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conceptual spaces: The geometry of thought",
            "rating": 2,
            "sanitized_title": "conceptual_spaces_the_geometry_of_thought"
        },
        {
            "paper_title": "The big book of concepts",
            "rating": 2,
            "sanitized_title": "the_big_book_of_concepts"
        },
        {
            "paper_title": "Representation, similarity, and the chorus of prototypes",
            "rating": 2,
            "sanitized_title": "representation_similarity_and_the_chorus_of_prototypes"
        },
        {
            "paper_title": "Dual peccs: a cognitive system for conceptual representation and categorization",
            "rating": 2,
            "sanitized_title": "dual_peccs_a_cognitive_system_for_conceptual_representation_and_categorization"
        },
        {
            "paper_title": "An integrated theory of the mind",
            "rating": 2,
            "sanitized_title": "an_integrated_theory_of_the_mind"
        },
        {
            "paper_title": "A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes",
            "rating": 2,
            "sanitized_title": "a_computational_framework_for_concept_representation_in_cognitive_systems_and_architectures_concepts_as_heterogeneous_proxytypes"
        },
        {
            "paper_title": "Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs",
            "rating": 1,
            "sanitized_title": "towards_a_new_cognitive_hourglass_uniform_implementation_of_cognitive_architecture_via_factor_graphs"
        },
        {
            "paper_title": "Connectionism and cognitive architecture: A critical analysis",
            "rating": 1,
            "sanitized_title": "connectionism_and_cognitive_architecture_a_critical_analysis"
        },
        {
            "paper_title": "On the adequacy of prototype theory as a theory of concepts",
            "rating": 1,
            "sanitized_title": "on_the_adequacy_of_prototype_theory_as_a_theory_of_concepts"
        },
        {
            "paper_title": "Spaces in the brain: From neurons to meanings",
            "rating": 1,
            "sanitized_title": "spaces_in_the_brain_from_neurons_to_meanings"
        },
        {
            "paper_title": "Diagrammatic reasoning: Cognitive and computational perspectives",
            "rating": 1,
            "sanitized_title": "diagrammatic_reasoning_cognitive_and_computational_perspectives"
        },
        {
            "paper_title": "Cliques of neurons bound into cavities provide a missing link between structure and function",
            "rating": 1,
            "sanitized_title": "cliques_of_neurons_bound_into_cavities_provide_a_missing_link_between_structure_and_function"
        }
    ],
    "cost": 0.020181249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Representational Issues in the Debate on the Standard Model of the Mind
23 Apr 2018</p>
<p>Antonio Chella antonio.chella@unipa.it 
University of Palermo
ICAR-CNR
Italy</p>
<p>Marcello Frixione marcello.frixione@unige.it 
University of Genoa
Italy</p>
<p>Antonio Lieto lieto@di.unito.it 
University of Turin
ICAR-CNR
Italy</p>
<p>Representational Issues in the Debate on the Standard Model of the Mind
23 Apr 2018
In this paper we discuss some of the issues concerning the Memory and Content aspects in the recent debate on the identification of a Standard Model of the Mind (Laird, Lebiere, and Rosenbloom in press). In particular we focus on the representational models concerning the Declarative Memories of current Cognitive Architectures (CAs). In doing so we outline some of the main problems affecting the current CAs and suggest that the Conceptual Spaces, a representational framework developed by Gärdenfors, is worthconsidering to address such problems. Finally we briefly analyze the alternative representational assumptions employed in the three CAs constituting the current baseline for the Standard Model (i.e. SOAR, ACT-R and Sigma). In doing so, we point out the respective differences and discuss their implications in the light of the analyzed problems.</p>
<p>Introduction</p>
<p>In the last decades, many Cognitive Architectures (CAs) have been realized adopting different assumptions about the organization and the representation of their knowledge level. Some of them adopt a symbolic approach, some are based on a purely connectionist model, while others adopt a hybrid approach combining connectionist and symbolic representational levels. In this paper we suggest that, among the different approaches that are worth-considering in the debate concerning the identification of a standard representational model in artificial minds, the framework of Conceptual Spaces can play an important role for connecting symbolic, subsymbolic and diagrammatic representations and for dealing with some problematic aspects affecting the knowledge level in CAs. Finally, we analyze the alternative representational models that have been employed in the three CAs constituting the baseline of the current Standard Model, by pointing out the respective differences and their implications.</p>
<p>Representational Limits of current CAs</p>
<p>It has been recently argued that two of the main current limitations of the knowledge level of the CAs are represented by the limited size and the homogeneous typology of the encoded and processed knowledge Copyright c 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. (Lieto, Lebiere, and Oltramari 2017). While the size problem corresponds to the fact that CAs usually operate with very limited and ad-hoc built knowledge bases, the problem concerning the homogeneity issue concerns the fact that usually the type of knowledge represented and manipulated by most CAs (including those provided with extended knowledge modules) mainly covers the so called classical part of conceptual information (i.e. that one representing concepts in terms of necessary and sufficient conditions, see (Frixione and Lieto 2012) on these aspects). On the other hand, the so called common-sense knowledge components (i.e. those that, based on the results from the cognitive science, allow to characterize concepts in terms of prototypes, exemplars or theories, see (Murphy 2002)) is largely absent in such computational frameworks 1 .</p>
<p>As a consequence of this representational aspect, these systems have also a limited capacity of handling, in an integrated way, the heterogeneous amount of co-existing common-sense reasoning mechanisms which are, on the other hand, well established in the psychological literature. Such mechanisms belongs to the class of typicalitybased reasoning (and includes, for example, prototype and exemplar-based categorization). 2 1 There are, however, some proposals explicitly suggesting to deal with this problem by assuming a heterogeneous representational stance (Lieto 2014). According to the heterogeneous approach a given concept is endowed by different types of potentially co-existing representations (e.g. prototypes, exemplars etc.). In addition, to each type of representation is associated a corresponding reasoning mechanisms. Handling the interaction between all these reasoning mechanisms represents a crucial aspect of the heterogeneous proposal. In the rest of the paper we assume the heterogeneous representational stance as a way to deal with the knowledge homogeneity problem. 2 A prototype-based categorization is obtained, for example, when a stimulus with the following features: "it has fur, woofs and wags its tail" is categorized ad a DOG, since these cues are associated to the prototype of dog. Prototype-based reasoning, however, is not the only type of reasoning based on typicality. In fact, if an exemplar corresponding to the stimulus being categorized is available, too, it is acknowledged that humans use to classify it by evaluating its similarity w.r.t. the exemplar, rather than w.r.t. the prototype associated to the underlying concepts. This type of common sense categorization is known in literature as exemplars-based categorization (and the phenomenon according to which the exem-</p>
<p>An Intermediate Conceptual Spaces Level</p>
<p>In our opinion, a possible way to deal with the above mentioned problems can be provided by the adoption of Conceptual Space representations (integrated with other representational formalisms). Conceptual Spaces (Gärdenfors 2000) have been proposed as an intermediate level of representation between the subsymbolic and symbolic levels. It has been argued that the integration of this level enables to overcome some classical problems specifically related to the subsymbolic and symbolic representations considered in isolation (Gärdenfors 2000). Conceptual Spaces are a geometrical framework for the representation of knowledge 3 and can be thought as a metric space in which entities are characterized by quality dimensions (Gärdenfors 2000). To each quality dimension is associated a geometrical (topological or metrical) structure. In some cases, such dimensions can be directly related to perceptual mechanisms; examples of this kind are temperature, weight, brightness, pitch. In other cases, dimensions can be more abstract in nature. In this setting, concepts correspond to convex regions, and regions with different geometrical properties correspond to different sorts of concepts (Gärdenfors 2000). Here, prototypes and prototypical reasoning have a natural geometrical interpretation: prototypes correspond to the geometrical center of a convex region (the centroid). Also exemplar-based representation can be represented as points in a multidimensional space, and their similarity can be computed as the intervening distance between two points, based on some suitable metrics (such as Euclidean and Manhattan distance etc.).</p>
<p>Recently some available conceptual categorization systems, explicitly assuming the heterogeneous representational hypothesis and coupling Conceptual Spaces representations and symbolic knowledge bases (i.e. ontologies), have been developed. The DUAL PECCS system (Lieto, Radicioni, and Rho 2017), for example, relies on both such assumptions. Such system has been integrated with the Declarative Memories and the knowledge processing mechanisms of different CAs (ACT-R and CLARION). In DUAL PECCS, the interaction of the common-sense categorization strategies (based on prototypes and exemplars representation and operating on Conceptual Spaces representations) and classical deductive categorization mechanisms (executed on the ontological representations) is explicitly provided. This aspect is of particular interest in light of the problem concerning the homogeneity of the encoded knowledge. In fact, since the design of the interaction of the different processes operating with heterogeneous representations still represents a largely ignored problem in current CAs, this system shows that Conceptual Spaces represent a relatively effortless framework to both i) model the dynamics between prototype and exemplar-based processes and ii) plar is favoured with respect to the prototype is known as old-item advantage effect). See (Frixione and Lieto 2013) on this aspect. 3 In the last fifteen years, such framework has been employed in a vast range of AI applications spanning from visual perception (Chella, Frixione, and Gaglio 1997) to robotics (Chella, Frixione, and Gaglio 2003), question answering (Lieto, Radicioni, and Rho 2015) etc. See (Zenker and Gärdenfors 2015) for a recent overview. connect such mechanisms with processes operating on different types of representational formalisms (i.e. the symbolic or logic-oriented ones) that are more suitable to represent conceptual information in classical terms.</p>
<p>Concerning the size problem, the possible grounding of the Conceptual Spaces representational framework with symbolic structures enables their integration with wide-coverage knowledge bases such CYC (as provided, for example, in DUAL PECCS (Lieto, Radicioni, and Rho 2017)), DBpedia or similar. Additionally, there are also some initial attempts to automatically learn and encode wide-coverage Conceptual Spaces knowledge bases (Derrac and Schockaert 2015) also starting by wide-coverage linguistic resources such as BabelNet (http://babelnet.org/) and ConceptNet (http://conceptnet5.media.mit.edu/), see (Lieto, Mensa, and Radicioni 2016). Despite the recent progresses in this sense, however, we acknowledge that there is still a gap to cover in order to produce knowledge bases encoded in terms of Conceptual Spaces that can be comparable with the sizes of the wide-coverage ontological Knowledge Bases (KBs) mentioned above. In principle, however, this framework seems suitable to deal with both the size and the knowledge homogeneity issues.</p>
<p>An additional element of interest concerning the advantages provided by introducing the Conceptual Spaces as an intermediate representational level in CAs regards its capability to address a classical problem in conceptualization: namely the problem of reconciling compositionally and typicality effects 4 . This aspect does not affect, per se, the size problem but the problem concerning the knowledge homogeneity (since it assumes the existence of typicalitybased representations). Such aspect has been shown to be problematic for both symbolic/logic-oriented approaches (Osherson and Smith 1981)) and for classical connectionist approaches (Fodor and Pylyshyn 1988). On the other hand, this aspect can be formally handled by recurring to Conceptual Spaces (as shown in (Lieto, Chella, and Frixione 2017;Lewis and Lawry 2016).). In the next sections we briefly outline some arguments additionally supporting the adoption of a Conceptual Spaces representational level in CAs. 4 Broadly speaking this aspect regards the problem of dealing, in a coherent way, with the compositionality of prototypical representations. According to a well-known argument (Fodor 1981), prototypes are not compositional. In brief, the argument runs as follows: consider a concept like pet fish. It results from the composition of the concept pet and the concept fish. However, the prototype of pet fish cannot result from the composition of the prototypes of a pet and a fish: a typical pet is furry and warm, a typical fish is grayish, but a typical pet fish is neither furry and warm nor grayish. The possibility of explaining, in a coherent way, this type of combinatorial and generative phenomenon highlights a crucial aspect of the conceptual processing capabilities in human cognition and concerns some crucial high-level cognitive abilities such as that ones concerning conceptual composition, metaphor generation and creative thinking. Dealing with this problem requires the harmonization of two conflicting requirements in representational systems: the need of syntactic, generative, compositionality (typical of logical and symbolic-oriented systems) and that one concerning the exhibition of typicality effects.</p>
<p>Interpretation of Neural Networks</p>
<p>A relevant issue suggesting the adoption of Conceptual Space in CAs is represented by the possibility of using this representational layer as an interpreter of underlying opaque artificial neural networks (ANN) representations, that, on the other hand, are very well suited for tasks concerning perceptual abilities and are widely used in current CAs. We claim that the theory of Conceptual Spaces can be considered as a sort of designing style that helps to model more transparent neural networks, and it can facilitate the grounding and the interpretation of the hidden layers of units. As a consequence, the interpretation of neural network representations in terms of Conceptual Spaces provides a more abstract and transparent view on the underlying behavior of the networks.</p>
<p>Gärdenfors (Gärdenfors 2000) offers a simple analysis of the relationship between Conceptual Spaces and Self Organising Maps. Hereafter, (Balkenius and Gärdenfors 2016) propose a more articulate interpretation of the widely adopted RBF networks in terms of dimensions of a suitable Conceptual Space According to this approach, a neural network built by a set of RBF units can be interpreted as a simple Conceptual Space described by a set of integral quality dimensions. Consequently, a neural network built by a set of sets of RBF units may be geometrically interpreted by a conceptual space made up by sets of integral dimensions.</p>
<p>Additionally, following the Chorus of Prototypes approach proposed by Edelman (Edelman 1995), the units of an RBF network can be interpreted as prototypes in a suitable Conceptual Space. This interpretation enables the measurement of similarity between the input of the network and the prototypes corresponding to the units. Such an interpretation would have been much more problematic by considering the neural network alone, since this information would have been implicit and hidden. Moreover, it is possible to take into account, for example, the delicate cases of Chimeric entities, which are almost equidistant between two or more prototypes (i.e. the lion and the goat) (see (Edelman 1995)). This aspect is related to the PET FISH example described in the previous section (footnote 4). In this respect, the capability of accounting for the compositionally based on typicality traits seems to be a crucial feature of the Conceptual Spaces empowering both symbolic and sub-symbolic representations 5 . An additional element 5 It is worth-noting that also some forms of neuro-symbolic integration currently developed in CAs like ACT-R, and belonging to the class of the neo-connectionist approaches, allows to deal with the the above mentioned problem by providing a series of mechanisms that are able to deal with limited forms of compositionality in neural networks (O'Reilly et al. 2013) and that can be integrated with additional processes allowing the compatibility with typicality effects. In this respect, such approaches play an equivalent role w.r.t that one played by the Conceptual Spaces on these issues. In addition, however, we claim that Conceptual Spaces can offer a unifying framework for interpreting many kinds of diagrammatic and analogical representations (see the next section). On these classes of representations, limited work has been done by these hybrid neuro-symbolic systems (including ACT-R). This is a symptom that the treatment of their representational and reasoning mechanisms is not trivial in these environments and that often of interests come from the research in computational neuroscience. According to a recent study (Reimann et al. 2017), the brain processes information involving cliques of neurons bound into cavities and reacts to external stimuli by building increasingly complex and multidimensional representations starting with rods (1D), then planks (2D), then cubes (3D), and then more complex geometries with 4D, 5D, etc. While the intuitive connection of this finding with the Conceptual Spaces framework is quite evident, this anoalogy in our opinion, deserves further attention.</p>
<p>Unifying Picture-Like Representations</p>
<p>Many pictorial, analog or diagrammatic models have been proposed in various fields of Cognitive Science, which take advantage of forms of representations that are picture-like, in the sense that they spatially resemble to what they represent (Glasgow, Narayanan, and Chandrasekaran 1995).</p>
<p>This class of representations is heterogeneous, and it is surely not majoritarian if compared to the main streams of symbolic/logic based systems and of neural networks. Moreover, they lack a general theory, and, despite their intuitive appeal, a common and well understood theoretical framework does not exist.</p>
<p>Conceptual Spaces, thanks to their geometrical nature, allow the representation of this sort of information and offer, at the same time a general, well understood and theoretically grounded framework that could enable to encompass most of the existing diagrammatic representations.</p>
<p>The geometrical nature of conceptual spaces can be useful also in representing more abstract and non-specifically spatial domains and phenomena. A typical problem of both symbolic and neural representations regards the ability to track the identity of individual entities over time. The properties of an entity change across the time. At which condition can we re-identify an entity as the same, despite its changes? In many cases the answer is not easy. Conceptual Spaces suggest a way to face the problem. We said that individual objects are represented by points in Conceptual Spaces. However, in a dynamic perspective, objects can be rather seen as trajectories in a suitable Conceptual Space indexed by time, since the properties of objects usually change with time. Objects may move, may age, an object can alter its shape or color, and so on. As the properties of an object are modified, the point, representing it in the Conceptual Space, moves according to a certain trajectory. Since usually this modifications happens smoothly and not abruptly, several assumptions can be made on this trajectory, e.g., smoothness, and obedience to physical laws (Chella et al. 2004).</p>
<p>Figuring out the evolution of an object as its future position, or the way in which its features are going to change, can be seen as the extrapolation of a trajectory in a Conceptual Space. To identify again an object that has been occluded for a certain time interval amounts to interpolate its past and present trajectories. In general, this characteristic represents a powerful heuristic to track the identity of an individual object. Also in this case, crucial aspects of diagrammatic repthey need to be integrated with external diagrammatic representation systems, see (Lieto, Lebiere, and Oltramari 2017). resentations find a more general and unifying interpretation regarding Conceptual Spaces.</p>
<p>In the next sections we provide a brief overview of the representational hypotheses adopted by the three different CAs constituting the current baseline for the Standard Model of Mind. In doing so we try to analyze to what extent such systems deal with the problematic aspects discussed above. SOAR SOAR was considered by Newell a candidate for a Unified Theory of Cognition (Newell 1994). In such architecture, all the cognitive tasks can be represented by problem spaces that are searched by production rules grouped into operators. These production rules are fired in parallel to produce reasoning cycles. From a representational perspective, SOAR exploits symbolic representations of knowledge (called chunks) in its the declarative memory (called Semantic Memory) and use pattern matching, and in the more recent versions also spreading activation mechanisms (Jones, Wandzel, and Laird 2016), to select relevant knowledge elements.</p>
<p>With respect to the knowledge homogeneity issue, the main problem of this architecture relies on the fact that it does not specify how the typical knowledge components of a concept (that can eventually be represented by adopting a frame-like structure) and the corresponding non monotonicreasoning strategy can interact with possibly conflicting representational and reasoning procedures characterizing other conceptualisation of the same conceptual entity 6 . In short it assumes, like most of the symbolic-oriented CAs, the availability of a monolithic conceptual structure (e.g., a framelike prototype or a "classical" concept) without specifying how such information can be integrated and harmonized with other knowledge components to form the whole knowledge spectrum characterizing a given concept. Therefore the current version of the system is not able to deal, in an integrated perspective, with prototype and exemplar-based categorization. With respect to to the size problem, the SOAR knowledge level is also problematic. SOAR agents, in fact, are not endowed with general knowledge. This problem is acknowledged in (Laird 2012) but there is no available literature attesting progress in this respect 7 . With respect to the diagrammatic representations, finally, SOAR is equipped with a visual imagery module.</p>
<p>ACT-R</p>
<p>ACT-R (Anderson et al. 2004) is a cognitive architecture explicitly inspired by theories and experimental results coming from human cognition. Here the cognitive mechanisms concerning the knowledge level emerge from the interaction of two types of knowledge: declarative knowledge, which encodes explicit facts that the system knows, and procedural knowledge, which encodes rules for processing declarative knowledge. In particular, the declarative module is used to store and retrieve pieces of information (called chunks, composed of a type and a set of attribute-value pairs, similar to frame slots) in declarative memory. ACT-R employs a subsymbolic activation of symbolic conceptual chunks representing the encoded knowledge. Finally, the central production system connects these modules by using a set of IF-THEN production rules.</p>
<p>Differently from SOAR, ACT-R allows to represent the information in terms of prototypes and exemplars and allow to perform, selectively, either prototype or exemplarbased categorization. This means that the architecture allows the modeller to manually specify which kind of categorization strategy to employ according to his specific needs. Such an architecture, however, only partially addresses the homogeneity problem since it does not allow to represent, jointly, these different types of common-sense representations conveying different types of information for the same conceptual entity (i.e. it does not assume a heterogeneous perspective). As a consequence, it is also not able to autonomously decide which of the corresponding reasoning procedures to activate (e.g. prototypes or exemplars) and to provide a framework able to manage the interaction of such different reasoning strategies (however its overall architectural environment provides, at least in principle, the possibility of implementing cascade reasoning processes triggering one another).</p>
<p>Even if some attempts exist concerning the design of harmonization strategies between different types of commonsense conceptual categorizations (e.g. exemplar-based and rule-based, see (Anderson and Betz 2001)) however they do not handle the problem concerning the interaction of the prototype or exemplar-based processes according to the results coming from experimental cognitive science (for example: the old item effect, privileging exemplars w.r.t. prototypes is not modeled. See footnote 2 on this aspect.). Summing up: w.r.t. the homogeneity problem, the components needed to fully reconcile the Heterogeneity approach with ACT-R are available, however they have not been fully exploited yet.</p>
<p>Regarding the size problem: as for SOAR, ACT-R agents are usually equipped with task-specific knowledge and not with general cross-domain knowledge. In this respect some relevant attempts to overcome this limitation have been recently done by extending the Declarative Memory of the architecture. They will be discussed below along with their current implications.</p>
<p>Sigma</p>
<p>Sigma is a novel cognitive architecture that starts with the same basic assumption of SOAR (Rosenbloom 2009) and that blends lessons from ACT-R and SOAR with what has been learned separately about graphical models (Laird, Lebiere, and Rosenbloom in press).</p>
<p>In Sigma the long term memory, as well as the working memory and perceptual and motor components is grounded in graphical models and, in particular, in factor graphs (a particular type of very efficient graphical models).</p>
<p>In general, the graphical models can be considered as a class of symbolic representations, where the relations between concepts are weighted by their strength, calculated through statistical computations. Within the symbolic AI tradition, these models can be seen an attempt to mitigate, for example, the problems concerning common-sense knowledge reasoning 8 . With respect to the size and the homogeneity issues the current version of the architecture (being also quite new w.r.t the others) seems to encounter problems for both the aspects. At the best of our knowledge, in fact, currently Sigma is not equipped for being extended or integrated with large scale general knowledge bases. With respect to the heterogeneity issues, on the other hand, it allows -in principle -to model forms of approximate reasoning in an efficient way due to the underlying graphical model used as a representational basis. Currently, however, it is not equipped for dealing with, in an integrated way, typicality based reasoning (combining prototypes and exemplars) with standard, "classical", reasoning mechanisms. An interesting aspect, that in our opinion, would be interesting to investigate is to what extent the representational assumption used in Sigma allows align this framework with another well known-theory about the typicality of conceptual knowledge and that is known as theory-theory 9 . As for SOAR, finally, also SIGMA supports picture-like visual imagery representations.</p>
<p>Extended Declarative Memories</p>
<p>Some initial efforts to deal with the size problem have been done (notably all these efforts have been done with ACT-R). To this class of works belongs that one proposed by (Oltramari and Lebiere 2012), aiming at extending the knowledge layer of ACT-R with external ontological content related to the event modelling; that one by Salvucci (Salvucci 2014), aiming at enriching the knowledge model of the Declarative Memory (DM) of ACT-R with a world-level knowledge base such as DBpedia (i.e. the semantic version of Wikipedia represented in terms of ontological formalisms), and that one proposed in (Ball, Rodgers, and Gluck 2004) presenting an integration of the ACT-R Declarative and Procedural Memory with the Cyc ontology http://www.opencyc.org/ (one of the widest ontological resources currently available containing more than 230,000 concepts). The main problematic aspect concerning the extension of the DM with such widecoverage integrated ontological resources, however, is in that the underlying formalisms of the ontological seman-8 It is also worth-noting, however, despite the success of the recent statistical approaches in reproducing many cognitive phenomena, that many forms of common-sense knowledge in human cognition do not require predictions about what will happen or, in general, to reason probabilistically (Sloman 2014). It would be interesting to investigate how such architecture manages these cases. 9 Theory-theory approaches (see (Murphy 2002) for details) explain the typicality effects by assuming that concepts consist of more or less complex mental structures representing (among other things) causal and explanatory relations. Common-sense concepts are mostly characterized in terms of theories which are based on arbitrary, i.e. experience-based, rules. tics are mainly biased towards the representation of conceptual information in classical terms (for a more detailed discussion we remind to (Lieto, Lebiere, and Oltramari 2017). Other attempts, aimed at extending the DM with knowledge systems able to perform forms of common sense reasoning (such as in in the integration of ACR-R with the SCONE Knowledge Base, see (Oltramari and Lebiere 2012)), encounter different problematic issues. For example: with respect to the extensions provided with wide-coverage KBs, the latter approach needs to face the problem concerning the size aspect (since KBs such as SCONE are not comparable in size with Cyc or DBpedia). Concerning the homogeneity problem, on the other hand, such integration seems to provide a straightforward way to combine common-sense reasoning operating with frame-like symbolic knowledge structures. Still, however, the problem concerning the integration of heterogeneous processes acting on different bodies of knowledge is not currently addressed.</p>
<p>In the light of the arguments briefly presented above, it can be argued that the current proposed solutions for dealing with the size and the homogeneity knowledge problems in CAs are not completely satisfactory. In particular, the integrations with huge world-level ontological knowledge bases can be considered a necessary solution for solving the size problem. It is, however, insufficient for dealing with the knowledge homogeneity issue and with the integration of the common-sense conceptual mechanisms that, as assumed in the heterogeneous representational perspective, are activated on heterogeneous bodies of knowledge</p>
<p>Conclusion</p>
<p>We have provided some arguments supporting the idea that Conceptual Spaces can be a powerful representational framework for dealing with some problematic aspects affecting the knowledge level in the current Long-Term Memories of the CAs (i.e. the size and the knowledge homogeneity problem). We have also sketched the advantages that such framework, used in combination with symbolic, connectionist and diagrmmatic representations, may provide in general CAs. In our opinion, such evidences support our claim that any standard representational model of mind should be equipped with a geometrical representational levelà la Conceptual Spaces. In the final part of the paper we have proposed an analysis of the representational level of the three CAs currently considered for the development of a Standard Model of the Mind. The analysis shows that, given the size and the knowledge homogeneity problems, the current state of the art is not completely satisfactory and could therefore benefit from the adoption of Conceptual Spaces.
 Let us think to the case of WHALE. A prototypical conceptualization would classify whales as a FISH (since a whale share many typical traits with fishes). On the other hand, a classical conceptualization would classify a whale as a MAMMAL.7  There are, however, attempts to extend in a efficient way the Semantic Memory of SOAR with external lexical resources such as, for example, Wordnet(Derbinsky, Laird, and Smith 2010).</p>
<p>A hybrid model of categorization. J R Anderson, J Betz, Psychonomic Bulletin &amp; Review. 84and Betz 2001] Anderson, J. R., and Betz, J. 2001. A hybrid model of categorization. Psychonomic Bul- letin &amp; Review 8(4):629-647.</p>
<p>Integrating act-r and cyc in a largescale model of language comprehension for use in intelligent agents. Anderson , Spaces in the brain: From neurons to meanings. Frontiers in psychology 7. 111AAAI workshop[Anderson et al. 2004] Anderson, J. R.; Bothell, D.; Byrne, M. D.; Douglass, S.; Lebiere, C.; and Qin, Y. 2004. An integrated theory of the mind. Psychological review 111(4):1036. [Balkenius and Gärdenfors 2016] Balkenius, C., and Gärdenfors, P. 2016. Spaces in the brain: From neurons to meanings. Frontiers in psychology 7. [Ball, Rodgers, and Gluck 2004] Ball, J.; Rodgers, S.; and Gluck, K. 2004. Integrating act-r and cyc in a large- scale model of language comprehension for use in intelligent agents. In AAAI workshop, 19-25.</p>
<p>Anchoring symbols to conceptual spaces: the case of dynamic scenarios. [ Chella, Proceedings of the AAAI-04 Workshop on Anchoring Symbols to Sensor Data. the AAAI-04 Workshop on Anchoring Symbols to Sensor Data89Artificial Intelligence[Chella et al. 2004] Chella, A.; Coradeschi, S.; Frixione, M.; and Saffiotti, A. 2004. Perceptual anchoring via concep- tual spaces. In Proceedings of the AAAI-04 Workshop on Anchoring Symbols to Sensor Data, 40-45. [Chella, Frixione, and Gaglio 1997] Chella, A.; Frixione, M.; and Gaglio, S. 1997. A cognitive architecture for artificial vision. Artificial Intelligence 89(1):73-111. [Chella, Frixione, and Gaglio 2003] Chella, A.; Frixione, M.; and Gaglio, S. 2003. Anchoring symbols to conceptual spaces: the case of dynamic scenarios. Robotics and Autonomous Systems 43(2):175-188.</p>
<p>Inducing semantic relations from conceptual spaces: a data-driven approach to plausible reasoning. Laird Derbinsky, N Smith ; Derbinsky, J E Laird, B Smith, J Derrac, S Schockaert, Artificial Intelligence. 1001Towards efficiently supporting large symbolic declarative memoriesDerbinsky, Laird, and Smith 2010] Derbinsky, N.; Laird, J. E.; and Smith, B. 2010. Towards efficiently supporting large symbolic declarative memories. 1001:48109-2121. [Derrac and Schockaert 2015] Derrac, J., and Schockaert, S. 2015. Inducing semantic relations from conceptual spaces: a data-driven approach to plausible reasoning. Artificial In- telligence 228:66-94.</p>
<p>Representation, similarity, and the chorus of prototypes. S Edelman, Minds and Machines. 51Edelman, S. 1995. Representation, simi- larity, and the chorus of prototypes. Minds and Machines 5(1):45-68.</p>
<p>Connectionism and cognitive architecture: A critical analysis. J A Fodor, Z W Pylyshyn, Cognition. 281-2and Pylyshyn 1988] Fodor, J. A., and Pylyshyn, Z. W. 1988. Connectionism and cognitive architecture: A critical analysis. Cognition 28(1-2):3-71.</p>
<p>Representing concepts in formal ontologies: Compositionality vs. typicality effects. J A Fodor, M Frixione, A Lieto, Representations: Philosophical Essays on the Foundations of Cognitive Science. Fodor, J. A., ed.Cambridge, MAMIT Press10The present status of the innateness controversy[Fodor 1981] Fodor, J. A. 1981. The present status of the in- nateness controversy. In Fodor, J. A., ed., Representations: Philosophical Essays on the Foundations of Cognitive Sci- ence. Cambridge, MA: MIT Press. chapter 10, 257 -316. [Frixione and Lieto 2012] Frixione, M., and Lieto, A. 2012. Representing concepts in formal ontologies: Composition- ality vs. typicality effects. Logic and Logical Philosophy 21(4):391-414.</p>
<p>Representing non classical concepts in formal ontologies: Prototypes and exemplars. M Frixione, A Lieto, P Gärdenfors, New Challenges in Distributed Information Filtering and Retrieval. MIT pressConceptual spaces: The geometry of thought[Frixione and Lieto 2013] Frixione, M., and Lieto, A. 2013. Representing non classical concepts in formal ontologies: Prototypes and exemplars. In New Challenges in Distributed Information Filtering and Retrieval. Springer. 171-182. [Gärdenfors 2000] Gärdenfors, P. 2000. Conceptual spaces: The geometry of thought. MIT press.</p>
<p>Diagrammatic reasoning: Cognitive and computational perspectives. Narayanan Glasgow, J Glasgow, N H Narayanan, B Chandrasekaran, Mit PressGlasgow, Narayanan, and Chandrasekaran 1995] Glasgow, J.; Narayanan, N. H.; and Chandrasekaran, B. 1995. Diagrammatic reasoning: Cognitive and computational perspectives. Mit Press.</p>
<p>Efficient computation of spreading activation using lazy evaluation. Wandzel Jones, Laird ; Jones , S J Wandzel, A R Laird, J E , Ann Arbor. 1001Jones, Wandzel, and Laird 2016] Jones, S. J.; Wandzel, A. R.; and Laird, J. E. 2016. Efficient computation of spreading activation using lazy evaluation. Ann Arbor 1001:48109-2121.</p>
<p>A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics. Lebiere Laird, J E Laird, C Lebiere, P S Rosenbloom, Press, AI Magazine 1-19Laird, Lebiere, and Rosenbloom in press] Laird, J. E.; Lebiere, C.; and Rosenbloom, P. S. in press. A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics. AI Magazine 1-19.</p>
<p>Hierarchical conceptual spaces for concept combination. J Laird, M Lewis, J Lawry, Artificial Intelligence. 237MIT PressThe Soar cognitive architectureLaird, J. 2012. The Soar cognitive architecture. MIT Press. [Lewis and Lawry 2016] Lewis, M., and Lawry, J. 2016. Hi- erarchical conceptual spaces for concept combination. Arti- ficial Intelligence 237:204-227.</p>
<p>The knowledge level in cognitive architectures: Current limitations and possible developments. Cognitive Systems Research. Chella Lieto, A Lieto, A Chella, M Frixione, Lebiere Lieto, A Lieto, C Lebiere, A Oltramari, A Lieto, E Mensa, D P Radicioni, AI<em> IA 2016 Advances in Artificial Intelligence. Springer19A resource-driven approach for anchoring linguistic resources to conceptual spacesLieto, Chella, and Frixione 2017] Lieto, A.; Chella, A.; and Frixione, M. 2017. Conceptual spaces for cognitive archi- tectures: A lingua franca for different levels of representa- tion. Biologically Inspired Cognitive Architectures 19:1-9. [Lieto, Lebiere, and Oltramari 2017] Lieto, A.; Lebiere, C.; and Oltramari, A. 2017. The knowledge level in cogni- tive architectures: Current limitations and possible develop- ments. Cognitive Systems Research. [Lieto, Mensa, and Radicioni 2016] Lieto, A.; Mensa, E.; and Radicioni, D. P. 2016. A resource-driven approach for anchoring linguistic resources to conceptual spaces. In AI</em> IA 2016 Advances in Artificial Intelligence. Springer. 435- 449.</p>
<p>A common-sense conceptual categorization system integrating heterogeneous proxytypes and the dual process of reasoning. Radicioni Lieto, A Lieto, D P Radicioni, V Rho, Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). the International Joint Conference on Artificial Intelligence (IJCAI)Buenos AiresAAAI PressLieto, Radicioni, and Rho 2015] Lieto, A.; Radicioni, D. P.; and Rho, V. 2015. A common-sense conceptual categoriza- tion system integrating heterogeneous proxytypes and the dual process of reasoning. In In Proceedings of the Inter- national Joint Conference on Artificial Intelligence (IJCAI), Buenos Aires, AAAI Press, 875-881.</p>
<p>A computational framework for concept representation in cognitive systems and architectures: Concepts as heterogeneous proxytypes. Radicioni Lieto, A Lieto, D P Radicioni, V Rho, A Lieto, G L Murphy, The big book of concepts. Lieto; MurphyMIT press29Procedia Computer ScienceLieto, Radicioni, and Rho 2017] Lieto, A.; Radicioni, D. P.; and Rho, V. 2017. Dual peccs: a cognitive system for con- ceptual representation and categorization. Journal of Exper- imental &amp; Theoretical Artificial Intelligence 29(2):433-452. [Lieto 2014] Lieto, A. 2014. A computational framework for concept representation in cognitive systems and archi- tectures: Concepts as heterogeneous proxytypes. Procedia Computer Science 41:6-14. [Murphy 2002] Murphy, G. L. 2002. The big book of con- cepts. MIT press.</p>
<p>Pursuing artificial general intelligence by leveraging the knowledge capabilities of act-r. In Artificial General Intelligence. A Newell, A Oltramari, C Lebiere, SpringerUnified theories of cognitionNewell, A. 1994. Unified theories of cogni- tion. Harvard University Press. [Oltramari and Lebiere 2012] Oltramari, A., and Lebiere, C. 2012. Pursuing artificial general intelligence by leveraging the knowledge capabilities of act-r. In Artificial General In- telligence. Springer. 199-208.</p>
<p>How limited systematicity emerges: A computational cognitive neuroscience approach. O&apos;reilly, Cognition. 91On the adequacy of prototype theory as a theory of conceptsO'Reilly et al. 2013] O'Reilly, R. C.; Petrov, A. A.; Cohen, J. D.; Lebiere, C. J.; Herd, S. A.; Kriete, T.; Calvo, I. P.; and Symons, J. 2013. How limited systematicity emerges: A computational cognitive neuroscience approach. [Osherson and Smith 1981] Osherson, D. N., and Smith, E. E. 1981. On the adequacy of prototype theory as a theory of concepts. Cognition 9(1):35-58.</p>
<p>Cliques of neurons bound into cavities provide a missing link between structure and function. Reimann, Frontiers in Computational Neuroscience. 1148[Reimann et al. 2017] Reimann, M. W.; Nolte, M.; Sco- lamiero, M.; Turner, K.; Perin, R.; Chindemi, G.; Dłotko, P.; Levi, R.; Hess, K.; and Markram, H. 2017. Cliques of neurons bound into cavities provide a missing link between structure and function. Frontiers in Computational Neuro- science 11:48.</p>
<p>Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs. P S Rosenbloom, D D Salvucci, Proceedings of the 9th international conference on cognitive modeling. the 9th international conference on cognitive modelingProcs. of the 36th Annual Meeting of the Cognitive Science Society. Sloman 2014] Sloman, A. 2014. How can we reduce the gulf between artificial and natural intelligence? In AIC[Rosenbloom 2009] Rosenbloom, P. S. 2009. Towards a new cognitive hourglass: Uniform implementation of cognitive architecture via factor graphs. In Proceedings of the 9th in- ternational conference on cognitive modeling, 116-121. [Salvucci 2014] Salvucci, D. D. 2014. Endowing a cognitive architecture with world knowledge. In Procs. of the 36th Annual Meeting of the Cognitive Science Society. [Sloman 2014] Sloman, A. 2014. How can we reduce the gulf between artificial and natural intelligence? In AIC, 1- 13.</p>
<p>Applications of conceptual spaces -The case for geometric knowledge representation. F Zenker, P Gärdenfors, SpringerZenker and Gärdenfors[Zenker and Gärdenfors 2015] Zenker, F., and Gärdenfors, P. 2015. Applications of conceptual spaces -The case for geo- metric knowledge representation. Springer.</p>            </div>
        </div>

    </div>
</body>
</html>